"title","authors","link","date","source","subject","abstract","initial_decision","q0","q1","q2","q3","q4","q5","q6","q7","q8","q9","q10","q11","q12","q13","q14","q15","q16","q17","q18","q19","q20","q21","q22","q23","q24","q25","q26","q27","q28","q29","q30","q31","q32","q33","q34","q35","q36","q37","q38","q39","q40","q41","q42","q43","q44","q45","q46","q47","q48","q49","q50","q51","q52","q53","q54","q55","q56","q57","q58","q59","q60","exclusion_reason","extraction_date","expert_decision","ID","o1"
"Implementing Ethics in Healthcare AI-Based Applications: A Scoping Review","Magali Goirand; Elizabeth Austin; Robyn Clay-Williams","https://doi.org/10.1007/s11948-021-00336-3","2021-09-20","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20562,""
"Correction to: A systematic review of emerging feature selection optimization methods for optimal text classification: the present state and prospective opportunities","Esther Omolara Abiodun; Abdulatif Alabdulatif; Oludare Isaac Abiodun; Moatsum Alawida; Abdullah Alabdulatif; Rami S. Alkhawaldeh","https://doi.org/10.1007/s00521-021-06561-y","2021-10-27","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20563,""
"A systematic review of emerging feature selection optimization methods for optimal text classification: the present state and prospective opportunities","Esther Omolara Abiodun; Abdulatif Alabdulatif; Oludare Isaac Abiodun; Moatsum Alawida; Abdullah Alabdulatif; Rami S. Alkhawaldeh","https://doi.org/10.1007/s00521-021-06406-8","2021-10-27","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20564,""
"Applications of artificial intelligence in COVID-19 pandemic: A comprehensive review","Muzammil Khan; Muhammad Taqi Mehran; Zeeshan Ul Haq; Zahid Ullah; Salman Raza Naqvi; Mehreen Ihsan; Haider Abbass","https://doi.org/10.1016/j.eswa.2021.115695","2021-09-29","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20565,""
"A decision support system for automating document retrieval and citation screening","Raymon van Dinter; Cagatay Catal; Bedir Tekinerdogan","https://doi.org/10.1016/j.eswa.2021.115261","2021-10-05","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20566,""
"Detection of sleep apnea using Machine learning algorithms based on ECG Signals: A comprehensive systematic review","Nader Salari; Amin Hosseinian Far; Masoud Mohammadi; Hooman Ghasemi; Habibolah Khazaie; Alireza Daneshkhah; Arash Ahmadi","https://doi.org/10.1016/j.eswa.2021.115950","2021-10-29","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20567,""
"Learning deep relevance couplings for ad-hoc document retrieval","Shufeng Hao; Chongyang Shi; Longbing Cao; Zhendong Niu; Ping Guo","https://doi.org/10.1016/j.eswa.2021.115335","2021-09-29","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20568,""
"Vulnerable road user safety: A systematic review and mesh-networking based vehicle ad hoc system using hybrid of neuro-fuzzy and genetic algorithms","Insha Altaf; Ajay Kaul","https://doi.org/10.1002/dac.4907","2021-09-01","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20569,""
"Convergence of Gamification and Machine Learning: A Systematic Literature Review","Alireza Khakpour; Ricardo Colomo Palacios","https://doi.org/10.1007/s10758-020-09456-4","2021-08-12","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20570,""
"The Combination of Artificial Intelligence and Extended Reality: A Systematic Review","Dirk Reiners; Mohammad Reza Davahli; Waldemar Karwowski; Carolina Cruz-Neira","https://doi.org/10.3389/frvir.2021.721933","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20571,""
"Literature Review about Intention Mining in Information Systems","Oswaldo E. Diaz; MarÃ­a Gabriela Perez 0001; Jorge Edison Lascano","https://doi.org/10.1080/08874417.2019.1633569","2021-09-23","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20572,""
"Effect of Attention Mechanism in Deep Learning-Based Remote Sensing Image Processing: A Systematic Literature Review","Saman Ghaffarian; JoÃ£o Valente; Mariska van der Voort; Bedir Tekinerdogan","https://doi.org/10.3390/rs13152965","2021-09-16","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20573,""
"The Impact of Machine Learning on 2D/3D Registration for Image-Guided Interventions: A Systematic Review and Perspective","Mathias Unberath; Cong Gao 0003; Yicheng Hu; Max Judish; Russell H. Taylor; Mehran Armand; Robert B. Grupp","https://doi.org/10.3389/frobt.2021.716007","2021-09-07","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20574,""
"Automating Reproducible, Collaborative Clinical Trial Document Generation with the listdown Package","Michael J. Kane; Xun Jiang; Simon Urbanek","https://doi.org/10.32614/rj-2021-051","2021-09-06","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20575,""
"Semantic data mining in the information age: A systematic review","Chanmee Sirichanya; Kraisak Kesorn","https://doi.org/10.1002/int.22443","2021-09-01","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20576,""
"A Comprehensive Review on 3D Object Detection and 6D Pose Estimation With Deep Learning","Sabera Hoque; Md. Yasir Arafat; Shuxiang Xu; Ananda Maiti; Yuchen Wei","https://doi.org/10.1109/ACCESS.2021.3114399","2021-11-02","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20577,""
"Video Processing Using Deep Learning Techniques: A Systematic Literature Review","Vijeta Sharma; Manjari Gupta; Ajai Kumar; Deepti Mishra","https://doi.org/10.1109/ACCESS.2021.3118541","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20578,""
"A Systematic Review of Deep Learning for Silicon Wafer Defect Recognition","Uzma Batool; Mohd Ibrahim Shapiai; Muhammad Tahir; Zool Hilmi Ismail; Noor Jannah Zakaria; Ahmed Elfakharany","https://doi.org/10.1109/ACCESS.2021.3106171","2021-09-01","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20579,""
"On the Use of Machine Learning for Classifying Auditory Brainstem Responses: A Scoping Review","Rida Al Osman; Hussein Al Osman","https://doi.org/10.1109/ACCESS.2021.3102096","2021-09-16","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20580,""
"Deep Learning-Based Fault Diagnosis of Photovoltaic Systems: A Comprehensive Review and Enhancement Prospects","Majdi Mansouri; Mohamed Trabelsi 0001; Hazem N. Nounou; Mohamed N. Nounou","https://doi.org/10.1109/ACCESS.2021.3110947","2021-10-06","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20581,""
"Automated Diagnosis of Leukemia: A Comprehensive Review","Afshan Shah; Syed Saud Naqvi; Khuram Naveed; Nema Salem; Mohammad A. U. Khan; Khurram Saleem Alimgeer","https://doi.org/10.1109/ACCESS.2021.3114059","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20582,""
"A Comprehensive Review of Metaheuristic Methods for the Reconfiguration of Electric Power Distribution Systems and Comparison With a Novel Approach Based on Efficient Genetic Algorithm","Meisam Mahdavi; Hassan Haes Alhelou; Amir Bagheri; Sasa Z. Djokic; Ricardo Alan VerdÃº Ramos","https://doi.org/10.1109/ACCESS.2021.3109247","2021-10-06","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20583,""
"Machine Learning Techniques for Biomedical Natural Language Processing: A Comprehensive Review","Essam H. Houssein; Rehab E. Mohamed; Abdelmgeid A. Ali","https://doi.org/10.1109/ACCESS.2021.3119621","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20584,""
"Analysis of Deep Neural Networks for Human Activity Recognition in Videos - A Systematic Literature Review","Hadiqa Aman Ullah; Sukumar Letchmunan; M. Sultan Zia; Umair Muneer Butt; Fadratul Hafinaz Hassan","https://doi.org/10.1109/ACCESS.2021.3110610","2021-10-06","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20585,""
"Systematic Review on Machine-Learning Algorithms Used in Wearable-Based eHealth Data Analysis","Aditi Site; Jari Nurmi; Elena Simona Lohan","https://doi.org/10.1109/ACCESS.2021.3103268","2021-09-16","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20586,""
"A Literature Review of Using Machine Learning in Software Development Life Cycle Stages","Saad Shafiq; Atif Mashkoor; Christoph Mayr-Dorn; Alexander Egyed","https://doi.org/10.1109/ACCESS.2021.3119746","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20587,""
"Artificial intelligence in information systems research: A systematic literature review and research agenda","Christopher Collins; Denis Dennehy; Kieran Conboy; Patrick Mikalef","https://doi.org/10.1016/j.ijinfomgt.2021.102383","2021-10-14","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20588,""
"Algorithms and software for data mining and machine learning: a critical comparative view from a systematic review of the literature","Gilda Taranto-Vera; PurificaciÃ³n Galindo Villardon; Javier MerchÃ¡n SÃ¡nchez-Jara; Julio Salazar-Pozo; Alex Moreno-Salazar; Vanessa Salazar-Villalva","https://doi.org/10.1007/s11227-021-03708-5","2021-09-20","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20589,""
"Blockchain management and machine learning adaptation for IoT environment in 5G and beyond networks: A systematic review","Arzoo Miglani; Neeraj Kumar 0001","https://doi.org/10.1016/j.comcom.2021.07.009","2021-10-08","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20590,""
"Application of Machine Learning Methods on Patient Reported Outcome Measurements for Predicting Outcomes: A Literature Review","Deepika Verma; Kerstin Bach; Paul Jarle Mork","https://doi.org/10.3390/informatics8030056","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20591,""
"Artificial intelligence applied to support medical decisions for the automatic analysis of echocardiogram images: A systematic review","Vilson Soares de Siqueira; MoisÃ©s Marcos Borges; RogÃ©rio Gomes Furtado; Colandy Nunes Dourado; Ronaldo Martins da Costa","https://doi.org/10.1016/j.artmed.2021.102165","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20592,""
"Artificial intelligence in gynecologic cancers: Current status and future challenges - A systematic review","Munetoshi Akazawa; Kazunori Hashimoto","https://doi.org/10.1016/j.artmed.2021.102164","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20593,""
"Dengue models based on machine learning techniques: A systematic literature review","William Hoyos; Jose Aguilar; Mauricio Toro","https://doi.org/10.1016/j.artmed.2021.102157","2021-09-20","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20594,""
"Artificial intelligence maturity model: a systematic literature review","Raghad Baker Sadiq; Nurhizam Safie; Abdul Hadi Abd Rahman; Shidrokh Goudarzi","https://doi.org/10.7717/peerj-cs.661","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20595,""
"Prediction models applying machine learning to oral cavity cancer outcomes: A systematic review","John Adeoye; Jia Yan Tan; Siu-Wai Choi; Peter Thomson","https://doi.org/10.1016/j.ijmedinf.2021.104557","2021-10-14","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20596,""
"Big Data Management of Hospital Data using Deep Learning and Block-chain Technology: A Systematic Review","Nawaz Ejaz; Raza Ramzan; Tooba Maryam; Shazia Saqib","https://doi.org/10.4108/eai.23-3-2021.169072","2021-09-17","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20597,""
"Machine learning through the lens of e-commerce initiatives: An up-to-date systematic literature review","Lucas Micol Policarpo; DiÃ³rgenes EugÃªnio da Silveira; Rodrigo da Rosa Righi; Rodolfo Stoffel Antunes; Cristiano AndrÃ© da Costa; Jorge Luis VictÃ³ria Barbosa; Rodrigo Scorsatto; Tanuj Arcot","https://doi.org/10.1016/j.cosrev.2021.100414","2021-10-14","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20598,""
"A systematic review of machine learning-based missing value imputation techniques","Tressy Thomas; Enayat Rajabi","https://doi.org/10.1108/DTA-12-2020-0298","2021-09-16","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20599,""
"A Systematic Literature Review of Automated Query Reformulations in Source Code Search","Mohammad Masudur Rahman 0001; Chanchal K. Roy","https://arxiv.org/abs/2108.09646","2021-08-27","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20600,""
"Ethics of AI: A Systematic Literature Review of Principles and Challenges","Arif Ali Khan; Sher Badshah; Peng Liang 0001; Bilal Khan; Muhammad Waseem; Mahmood Niazi; Muhammad Azeem Akbar","https://arxiv.org/abs/2109.07906","2021-09-22","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20601,""
"Trustworthy AI and Robotics and the Implications for the AEC Industry: A Systematic Literature Review and Future Potentials","Newsha Emaminejad; Reza Akhavian","https://arxiv.org/abs/2109.13373","2021-10-04","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20602,""
"Applications of Artificial Neural Networks in Microorganism Image Analysis: A Comprehensive Review from Conventional Multilayer Perceptron to Popular Convolutional Neural Network and Potential Visual Transformer","Jinghua Zhang; Chen Li 0028; Marcin Grzegorzek","https://arxiv.org/abs/2108.00358","2021-08-05","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20603,""
"Human-Robot Collaboration and Machine Learning: A Systematic Review of Recent Research","Francesco Semeraro; Alexander Griffiths; Angelo Cangelosi","https://arxiv.org/abs/2110.07448","2021-10-22","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20604,""
"A Mining Software Repository Extended Cookbook: Lessons learned from a literature review","Daniel D. R. Barros; FlÃ¡vio E. A. Horita; Igor Wiese; Kanan Silva","https://arxiv.org/abs/2110.04095","2021-10-21","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20605,""
"A comprehensive review of Binary Neural Network","Chunyu Yuan; Sos S. Agaian","https://arxiv.org/abs/2110.06804","2021-10-22","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20606,""
"Machine learning for modeling the progression of Alzheimer disease dementia using clinical data: a systematic literature review","Sayantan Kumar; Inez Oh; Suzanne E. Schindler; Albert M. Lai; Philip R. O. Payne; Aditi Gupta","https://arxiv.org/abs/2108.04174","2021-08-11","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20607,""
"Finding Critical Scenarios for Automated Driving Systems: A Systematic Literature Review","Xinhai Zhang; Jianbo Tao; Kaige Tan; Martin TÃ¶rngren; JosÃ© Manuel Gaspar SÃ¡nchez; Muhammad Rusyadi Ramli; Xin Tao; Magnus Gyllenhammar; Franz Wotawa; Naveen Mohan; Mihai Nica; Hermann Felbinger","https://arxiv.org/abs/2110.08664","2021-10-22","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20608,""
"A Comprehensive Review on Summarizing Financial News Using Deep Learning","Saurabh Kamal; Sahil Sharma","https://arxiv.org/abs/2109.10118","2021-09-27","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20609,""
"Text Mining in Cybersecurity: A Systematic Literature Review","Luciano Ignaczak; Guilherme Goldschmidt; Cristiano AndrÃ© da Costa; Rodrigo da Rosa Righi","https://doi.org/10.1145/3462477","2021-09-27","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20610,""
"Machine Learning in Medical Emergencies: a Systematic Review and Analysis","InÃ©s Robles Mendo; GonÃ§alo Marques; Isabel de la Torre DÃ­ez; Miguel LÃ³pez Coronado; Francisco MartÃ­n-RodrÃ­guez","https://doi.org/10.1007/s10916-021-01762-3","2021-10-14","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20611,""
"A systematic literature review on obesity: Understanding the causes & consequences of obesity and reviewing various machine learning approaches used to predict obesity","Mahmood Safaei; Elankovan A. Sundararajan; Maha Driss; Wadii Boulila; Azrulhizam Shapi'i","https://doi.org/10.1016/j.compbiomed.2021.104754","2021-10-05","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20612,""
"General crime from the data mining point of view A systematic literature review","Maria Antonia Walteros-AlcÃ¡zar; Nicolas Aguirre-Yacup; Sandra Patricia Castillo-LandÃ­nez; Pablo Caicedo-RodrÃ­guez","https://doi.org/10.1504/IJBIDM.2021.118186","2021-11-02","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20613,""
"Latest Research Trends in Fall Detection and Prevention Using Machine Learning: A Systematic Review","Sara Usmani; Abdul Saboor; Muhammad Haris; Muneeb A. Khan; Heemin Park","https://doi.org/10.3390/s21155134","2021-08-13","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20614,""
"Intelligent cost estimation by machine learning in supply management: A structured literature review","Frank Bodendorf; Philipp Merkl; JÃ¶rg Franke","https://doi.org/10.1016/j.cie.2021.107601","2021-09-24","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20615,""
"Hand gesture recognition using machine learning and infrared information: a systematic literature review","RubÃ©n Nogales; Marco E. BenalcÃ¡zar","https://doi.org/10.1007/s13042-021-01372-y","2021-09-16","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20616,""
"Deep Learning Approach in DOA Estimation: A Systematic Literature Review","Shengguo Ge; Kuo Li; Siti Nurulain Binti Mohd Rum","https://doi.org/10.1155/2021/6392875","2021-10-06","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20617,""
"The reporting quality of natural language processing studies: systematic review of studies of radiology reports","Emma M. Davidson; Michael T. C. Poon; Arlene Casey; Andreas Grivas; Daniel Duma; Hang Dong; VÃ­ctor SuÃ¡rez-Paniagua; Claire Grover; Richard Tobin; Heather Whalley; Honghan Wu; Beatrice Alex; William Whiteley","https://doi.org/10.1186/s12880-021-00671-8","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20618,""
"Interpretable Prediction of Diabetes from Tabular Health Screening Records Using an Attentional Neural Network","Yuki Oba; Taro Tezuka; Masaru Sanuki; Yukiko Wagatsuma","https://doi.org/10.1109/DSAA53316.2021.9564151","2021-10-22","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20619,""
"Applications of Deep Learning Augmented Systems for Covid-19 Predictions- A Literature Review","Cherie Bakker Noteboom; David Zeng; Rajesh Godasu; Kruttika Sutrave","https://aisel.aisnet.org/amcis2021/adv_info_systems_general_track/adv_info_systems_general_track/31","2021-08-30","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20620,""
"Natural Language Processing in Internal Auditing - a Structured Literature Review","Gerrit Schumann; Jorge Marx GÃ³mez","https://aisel.aisnet.org/amcis2021/sig_acctinfosystem_asys/sig_acctinfosystem_asys/1","2021-08-30","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20621,""
"Data-driven Student Advisory and Potential Direct Discrimination: A Literature Review on Machine Learning for Predicting Students' Academic Success","Daniel Schoemer; Sven Laumer; Karl Wilbers; Tobias Wolbring; Jonas Weigert; Edgar Treischl","https://aisel.aisnet.org/amcis2021/social_inclusion/social_inclusion/10","2021-08-30","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20622,""
"Success Factors for the Adoption of Artificial Intelligence in Organizations: A Literature Review","Pascal Hamm; Michael Klesel","https://aisel.aisnet.org/amcis2021/art_intel_sem_tech_intelligent_systems/art_intel_sem_tech_intelligent_systems/10","2021-08-30","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20623,""
"Explainable Artificial Intelligence in the Medical Domain: A Systematic Review","Shuvro Chakrobartty; Omar F. El-Gayar","https://aisel.aisnet.org/amcis2021/art_intel_sem_tech_intelligent_systems/art_intel_sem_tech_intelligent_systems/1","2021-08-30","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20624,""
"Towards a Semi-Automated Approach for Systematic Literature Reviews","Tim Denzler; Martin Robert Enders; Patricia Akello","https://aisel.aisnet.org/amcis2021/art_intel_sem_tech_intelligent_systems/art_intel_sem_tech_intelligent_systems/4","2021-08-30","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20625,""
"Human-AI Complementarity in Hybrid Intelligence Systems: A Structured Literature Review","Patrick Hemmer; Max Schemmer; Michael VÃ¶ssing; Niklas KÃ¼hl","https://aisel.aisnet.org/pacis2021/78","2021-08-30","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20626,""
"Implementation of Artificial Intelligence in Organisations: A Systematic Literature Review","Maggie C. M. Lee; Helana Scheepers; Ariel K. H. Lui; Eric W. T. Ngai","https://aisel.aisnet.org/pacis2021/215","2021-08-30","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20627,""
"State-of-the-Art Analysis of Adopting AI-based Conversational Agents in Organizations: A Systematic Literature Review","Tom Lewandowski; Jasmin Delling; Christian Grotherr; Tilo BÃ¶hmann","https://aisel.aisnet.org/pacis2021/167","2021-08-30","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20628,""
"On Building Benchmark Datasets for Understudied Information Retrieval Tasks: the Case of Semantic Query Labeling","Elias Bassani; Gabriella Pasi","http://ceur-ws.org/Vol-2947/paper16.pdf","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20629,""
"Towards Supporting Complex Retrieval Tasks Through Graph-Based Information Retrieval and Visual Analytics","Aleksandar Bobic; Jean-Marie Le Goff; Christian GÃ¼tl","http://ceur-ws.org/Vol-2950/paper-04.pdf","2021-10-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20630,""
"Mode Awareness Interfaces in Automated Vehicles, Robotics, and Aviation: A Literature Review","Yasemin DÃ¶nmez Ã–zkan; Alexander G. Mirnig; Alexander Meschtscherjakov; Cansu Demir; Manfred Tscheligi","https://doi.org/10.1145/3409118.3475125","2021-09-22","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20631,""
"A Systematic Review of Fairness in Artificial Intelligence Algorithms","Khensani Xivuri; Hossana Twinomurinzi","https://doi.org/10.1007/978-3-030-85447-8_24","2021-09-01","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20632,""
"Preliminary Literature Review of Machine Learning System Development Practices","Yasuhiro Watanabe; Hironori Washizaki; Kazunori Sakamoto; Daisuke Saito; Kiyoshi Honda; Naohiko Tsuda; Yoshiaki Fukazawa; Nobukazu Yoshioka","https://doi.org/10.1109/COMPSAC51774.2021.00207","2021-09-23","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20633,""
"Learning To Rank Relevant Documents for Information Retrieval in Bioengineering Text Corpora","Kwok Sun Cheng; Myoungkyu Song","https://doi.org/10.1109/COMPSAC51774.2021.00233","2021-09-23","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20634,""
"Artificial intelligence-assisted personalized language learning: systematic review and co-citation analysis","Xieling Chen; Di Zou; Gary Cheng 0001; Haoran Xie 0001","https://doi.org/10.1109/ICALT52272.2021.00079","2021-08-06","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20635,""
"NLytics at CheckThat!Â 2021: Multi-class fake news detection of news articles and domain identification with RoBERTa - a baseline model","Albert Pritzkau","http://ceur-ws.org/Vol-2936/paper-46.pdf","2021-08-25","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20636,""
"Failures Forecast in Monitoring Datacenter Infrastructure Through Machine Learning Techniques: A Systematic Review","Walter Lopes Neto; Itamir de Morais Barroca Filho","https://doi.org/10.1007/978-3-030-87013-3_3","2021-09-20","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20637,""
"Conceptual Modeling Interacts with Machine Learning - A Systematic Literature Review","Moayid Ali Zaidi","https://doi.org/10.1007/978-3-030-87013-3_39","2021-09-17","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20638,""
"A Systematic Literature Review on Transfer Learning for 3D-CNNs","Marco Klaiber; Daniel Sauter; Hermann Baumgartl; Ricardo Buettner","https://doi.org/10.1109/IJCNN52387.2021.9533302","2021-09-29","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20639,""
"Social Recommendation for Social Networks Using Deep Learning Approach: A Systematic Review","Muhammad Alrashidi; Ali Selamat; Roliana Ibrahim; Ondrej Krejcar","https://doi.org/10.1007/978-3-030-88113-9_2","2021-10-07","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20640,""
"A-VLAD: An End-to-End Attention-Based Neural Network for Writer Identification in Historical Documents","Trung Tan Ngo; Hung Tuan Nguyen; Masaki Nakagawa","https://doi.org/10.1007/978-3-030-86331-9_26","2021-09-16","DBLP","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20641,""
"Advances in adversarial attacks and defenses in computer vision: A   survey","['Naveed Akhtar', 'Ajmal Mian', 'Navid Kardan', 'Mubarak Shah']","https://export.arxiv.org/abs/2108.00401","2021-08-01","arXiv","cs.CV cs.CR cs.CY cs.LG","Deep Learning (DL) is the most widely used tool in the contemporary field of computer vision. Its ability to accurately solve complex problems is employed in vision research to learn deep neural models for a variety of tasks, including security critical applications. However, it is now known that DL is vulnerable to adversarial attacks that can manipulate its predictions by introducing visually imperceptible perturbations in images and videos. Since the discovery of this phenomenon in 2013~[1], it has attracted significant attention of researchers from multiple sub-fields of machine intelligence. In [2], we reviewed the contributions made by the computer vision community in adversarial attacks on deep learning (and their defenses) until the advent of year 2018. Many of those contributions have inspired new directions in this area, which has matured significantly since witnessing the first generation methods. Hence, as a legacy sequel of [2], this literature review focuses on the advances in this area since 2018. To ensure authenticity, we mainly consider peer-reviewed contributions published in the prestigious sources of computer vision and machine learning research. Besides a comprehensive literature review, the article also provides concise definitions of technical terminologies for non-experts in this domain. Finally, this article discusses challenges and future outlook of this direction based on the literature reviewed herein and [2].","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20642,""
"The Impact of Machine Learning on 2D/3D Registration for Image-guided   Interventions: A Systematic Review and Perspective","['Mathias Unberath', 'Cong Gao', 'Yicheng Hu', 'Max Judish', 'Russell H Taylor', 'Mehran Armand', 'Robert Grupp']","https://export.arxiv.org/abs/2108.02238","2021-08-04","arXiv","cs.CV cs.RO physics.med-ph","Image-based navigation is widely considered the next frontier of minimally invasive surgery. It is believed that image-based navigation will increase the access to reproducible, safe, and high-precision surgery as it may then be performed at acceptable costs and effort. This is because image-based techniques avoid the need of specialized equipment and seamlessly integrate with contemporary workflows. Further, it is expected that image-based navigation will play a major role in enabling mixed reality environments and autonomous, robotic workflows. A critical component of image guidance is 2D/3D registration, a technique to estimate the spatial relationships between 3D structures, e.g., volumetric imagery or tool models, and 2D images thereof, such as fluoroscopy or endoscopy. While image-based 2D/3D registration is a mature technique, its transition from the bench to the bedside has been restrained by well-known challenges, including brittleness of the optimization objective, hyperparameter selection, and initialization, difficulties around inconsistencies or multiple objects, and limited single-view performance. One reason these challenges persist today is that analytical solutions are likely inadequate considering the complexity, variability, and high-dimensionality of generic 2D/3D registration problems. The recent advent of machine learning-based approaches to imaging problems that, rather than specifying the desired functional mapping, approximate it using highly expressive parametric models holds promise for solving some of the notorious challenges in 2D/3D registration. In this manuscript, we review the impact of machine learning on 2D/3D registration to systematically summarize the recent advances made by introduction of this novel technology. Grounded in these insights, we then offer our perspective on the most pressing needs, significant open problems, and possible next steps.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20643,""
"Improved Retrieval of Programming Solutions With Code Examples Using a   Multi-featured Score","['Rodrigo F. Silva', 'M. Masudur Rahman', 'Carlos Eduardo Dantas', 'Chanchal Roy', 'Foutse Khomh', 'Marcelo A. Maia']","https://export.arxiv.org/abs/2108.02702","2021-08-05","arXiv","cs.SE","Developers often depend on code search engines to obtain solutions for their programming tasks. However, finding an expected solution containing code examples along with their explanations is challenging due to several issues. There is a vocabulary mismatch between the search keywords (the query) and the appropriate solutions. Semantic gap may increase for similar bag of words due to antonyms and negation. Moreover, documents retrieved by search engines might not contain solutions containing both code examples and their explanations. So, we propose CRAR (Crowd Answer Recommender) to circumvent those issues aiming at improving retrieval of relevant answers from Stack Overflow containing not only the expected code examples for the given task but also their explanations. Given a programming task, we investigate the effectiveness of combining information retrieval techniques along with a set of features to enhance the ranking of important threads (i.e., the units containing questions along with their answers) for the given task and then selects relevant answers contained in those threads, including semantic features, like word embeddings and sentence embeddings, for instance, a Convolutional Neural Network (CNN). CRAR also leverages social aspects of Stack Overflow discussions like popularity to select relevant answers for the tasks. Our experimental evaluation shows that the combination of the different features performs better than each one individually. We also compare the retrieval performance with the state-of-art CROKAGE (Crowd Knowledge Answer Generator), which is also a system aimed at retrieving relevant answers from Stack Overflow. We show that CRAR outperforms CROKAGE in Mean Reciprocal Rank and Mean Recall with small and medium effect sizes, respectively.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20644,""
"AI-based Aortic Vessel Tree Segmentation for Cardiovascular Diseases   Treatment: Status Quo","['Yuan Jin', 'Antonio Pepe', 'Jianning Li', 'Christina Gsaxner', 'Fen-hua Zhao', 'Jens Kleesiek', 'Alejandro F. Frangi', 'Jan Egger']","https://export.arxiv.org/abs/2108.02998","2021-08-06","arXiv","eess.IV cs.CV cs.LG physics.med-ph","The aortic vessel tree is composed of the aorta and its branching arteries, and plays a key role in supplying the whole body with blood. Aortic diseases, like aneurysms or dissections, can lead to an aortic rupture, whose treatment with open surgery is highly risky. Therefore, patients commonly undergo drug treatment under constant monitoring, which requires regular inspections of the vessels through imaging. The standard imaging modality for diagnosis and monitoring is computed tomography (CT), which can provide a detailed picture of the aorta and its branching vessels if combined with a contrast agent, resulting in a CT angiography (CTA). Optimally, the whole aortic vessel tree geometry from consecutive CTAs, are overlaid and compared. This allows to not only detect changes in the aorta, but also more peripheral vessel tree changes, caused by the primary pathology or newly developed. When performed manually, this reconstruction requires slice by slice contouring, which could easily take a whole day for a single aortic vessel tree and, hence, is not feasible in clinical practice. Automatic or semi-automatic vessel tree segmentation algorithms, on the other hand, can complete this task in a fraction of the manual execution time and run in parallel to the clinical routine of the clinicians. In this paper, we systematically review computing techniques for the automatic and semi-automatic segmentation of the aortic vessel tree. The review concludes with an in-depth discussion on how close these state-of-the-art approaches are to an application in clinical practice and how active this research field is, taking into account the number of publications, datasets and challenges.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20645,""
"VitaLITy: Promoting Serendipitous Discovery of Academic Literature with   Transformers & Visual Analytics","['Arpit Narechania', 'Alireza Karduni', 'Ryan Wesslen', 'Emily Wall']","https://export.arxiv.org/abs/2108.03366","2021-08-07","arXiv","cs.HC","There are a few prominent practices for conducting reviews of academic literature, including searching for specific keywords on Google Scholar or checking citations from some initial seed paper(s). These approaches serve a critical purpose for academic literature reviews, yet there remain challenges in identifying relevant literature when similar work may utilize different terminology (e.g., mixed-initiative visual analytics papers may not use the same terminology as papers on model-steering, yet the two topics are relevant to one another). In this paper, we introduce a system, VitaLITy, intended to complement existing practices. In particular, VitaLITy promotes serendipitous discovery of relevant literature using transformer language models, allowing users to find semantically similar papers in a word embedding space given (1) a list of input paper(s) or (2) a working abstract. VitaLITy visualizes this document-level embedding space in an interactive 2-D scatterplot using dimension reduction. VitaLITy also summarizes meta information about the document corpus or search query, including keywords and co-authors, and allows users to save and export papers for use in a literature review. We present qualitative findings from an evaluation of VitaLITy, suggesting it can be a promising complementary technique for conducting academic literature reviews. Furthermore, we contribute data from 38 popular data visualization publication venues in VitaLITy, and we provide scrapers for the open-source community to continue to grow the list of supported venues.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20646,""
"Research on Third-Party Libraries in AndroidApps: A Taxonomy and   Systematic LiteratureReview","['Xian Zhan', 'Tianming Liu', 'Lingling Fan', 'Li Li', 'Sen Chen', 'Xiapu Luo', 'Yang Liu']","https://export.arxiv.org/abs/2108.03787","2021-08-08","arXiv","cs.SE","Third-party libraries (TPLs) have been widely used in mobile apps, which play an essential part in the entire Android ecosystem. However, TPL is a double-edged sword. On the one hand, it can ease the development of mobile apps. On the other hand, it also brings security risks such as privacy leaks or increased attack surfaces (e.g., by introducing over-privileged permissions) to mobile apps. Although there are already many studies for characterizing third-party libraries, including automated detection, security and privacy analysis of TPLs, TPL attributes analysis, etc., what strikes us odd is that there is no systematic study to summarize those studies' endeavors. To this end, we conduct the first systematic literature review on Android TPL-related research. Following a well-defined systematic literature review protocol, we collected 74 primary research papers closely related to the Android third-party library from 2012 to 2020. After carefully examining these studies, we designed a taxonomy of TPL-related research studies and conducted a systematic study to summarize current solutions, limitations, challenges and possible implications of new research directions related to third-party library analysis. We hope that these contributions can give readers a clear overview of existing TPL-related studies and inspire them to go beyond the current status quo by advancing the discipline with innovative approaches.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20647,""
"DoSSIER@COLIEE 2021: Leveraging dense retrieval and summarization-based   re-ranking for case law retrieval","['Sophia Althammer', 'Arian Askari', 'Suzan Verberne', 'Allan Hanbury']","https://export.arxiv.org/abs/2108.03937","2021-08-09","arXiv","cs.IR","In this paper, we present our approaches for the case law retrieval and the legal case entailment task in the Competition on Legal Information Extraction/Entailment (COLIEE) 2021. As first stage retrieval methods combined with neural re-ranking methods using contextualized language models like BERT achieved great performance improvements for information retrieval in the web and news domain, we evaluate these methods for the legal domain. A distinct characteristic of legal case retrieval is that the query case and case description in the corpus tend to be long documents and therefore exceed the input length of BERT. We address this challenge by combining lexical and dense retrieval methods on the paragraph-level of the cases for the first stage retrieval. Here we demonstrate that the retrieval on the paragraph-level outperforms the retrieval on the document-level. Furthermore the experiments suggest that dense retrieval methods outperform lexical retrieval. For re-ranking we address the problem of long documents by summarizing the cases and fine-tuning a BERT-based re-ranker with the summaries. Overall, our best results were obtained with a combination of BM25 and dense passage retrieval using domain-specific embeddings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20648,""
"Using Deep Learning for Visual Decoding and Reconstruction from Brain   Activity: A Review","['Madison Van Horn']","https://export.arxiv.org/abs/2108.04169","2021-08-09","arXiv","cs.CV cs.LG","This literature review will discuss the use of deep learning methods for image reconstruction using fMRI data. More specifically, the quality of image reconstruction will be determined by the choice in decoding and reconstruction architectures. I will show that these structures can struggle with adaptability to various input stimuli due to complicated objects in images. Also, the significance of feature representation will be evaluated. This paper will conclude the use of deep learning within visual decoding and reconstruction is highly optimal when using variations of deep neural networks and will provide details of potential future work.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20649,""
"Machine learning for modeling the progression of Alzheimer disease   dementia using clinical data: a systematic literature review","['Sayantan Kumar', 'Inez Oh', 'Suzanne Schindler', 'Albert M Lai', 'Philip R O Payne', 'Aditi Gupta']","https://export.arxiv.org/abs/2108.04174","2021-08-05","arXiv","q-bio.QM cs.LG","Objective Alzheimer disease (AD) is the most common cause of dementia, a syndrome characterized by cognitive impairment severe enough to interfere with activities of daily life. We aimed to conduct a systematic literature review (SLR) of studies that applied machine learning (ML) methods to clinical data derived from electronic health records in order to model risk for progression of AD dementia.   Materials and Methods: We searched for articles published between January 1, 2010, and May 31, 2020, in PubMed, Scopus, ScienceDirect, IEEE Explore Digital Library, Association for Computing Machinery Digital Library, and arXiv. We used predefined criteria to select relevant articles and summarized them according to key components of ML analysis such as data characteristics, computational algorithms, and research focus.   Results: There has been a considerable rise over the past 5 years in the number of research papers using ML-based analysis for AD dementia modeling. We reviewed 64 relevant articles in our SLR. The results suggest that majority of existing research has focused on predicting progression of AD dementia using publicly available datasets containing both neuroimaging and clinical data (neurobehavioral status exam scores, patient demographics, neuroimaging data, and laboratory test values).   Discussion: Identifying individuals at risk for progression of AD dementia could potentially help to personalize disease management to plan future care. Clinical data consisting of both structured data tables and clinical notes can be effectively used in ML-based approaches to model risk for AD dementia progression. Data sharing and reproducibility of results can enhance the impact, adaptation, and generalizability of this research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20650,""
"Privacy-Preserving Machine Learning: Methods, Challenges and Directions","['Runhua Xu', 'Nathalie Baracaldo', 'James Joshi']","https://export.arxiv.org/abs/2108.04417","2021-08-09","arXiv","cs.LG cs.AI cs.CR","Machine learning (ML) is increasingly being adopted in a wide variety of application domains. Usually, a well-performing ML model relies on a large volume of training data and high-powered computational resources. Such a need for and the use of huge volumes of data raise serious privacy concerns because of the potential risks of leakage of highly privacy-sensitive information; further, the evolving regulatory environments that increasingly restrict access to and use of privacy-sensitive data add significant challenges to fully benefiting from the power of ML for data-driven applications. A trained ML model may also be vulnerable to adversarial attacks such as membership, attribute, or property inference attacks and model inversion attacks. Hence, well-designed privacy-preserving ML (PPML) solutions are critically needed for many emerging applications. Increasingly, significant research efforts from both academia and industry can be seen in PPML areas that aim toward integrating privacy-preserving techniques into ML pipeline or specific algorithms, or designing various PPML architectures. In particular, existing PPML research cross-cut ML, systems and applications design, as well as security and privacy areas; hence, there is a critical need to understand state-of-the-art research, related challenges and a research roadmap for future research in PPML area. In this paper, we systematically review and summarize existing privacy-preserving approaches and propose a Phase, Guarantee, and Utility (PGU) triad based model to understand and guide the evaluation of various PPML solutions by decomposing their privacy-preserving functionalities. We discuss the unique characteristics and challenges of PPML and outline possible research directions that leverage as well as benefit multiple research communities such as ML, distributed systems, security and privacy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20651,""
"Industrial Digital Twins at the Nexus of NextG Wireless Networks and   Computational Intelligence: A Survey","['Shah Zeb', 'Aamir Mahmood', 'Syed Ali Hassan', 'MD. Jalil Piran', 'Mikael Gidlund', 'Mohsen Guizani']","https://export.arxiv.org/abs/2108.04465","2021-08-10","arXiv","cs.IT math.IT","By amalgamating recent communication and control technologies, computing and data analytics techniques, and modular manufacturing, Industry~4.0 promotes integrating cyber-physical worlds through cyber-physical systems (CPS) and digital twin (DT) for monitoring, optimization, and prognostics of industrial processes. A DT is an emerging but conceptually different construct than CPS. Like CPS, DT relies on communication to create a highly-consistent, synchronized digital mirror image of the objects or physical processes. DT, in addition, uses built-in models on this precise image to simulate, analyze, predict, and optimize their real-time operation using feedback. DT is rapidly diffusing in the industries with recent advances in the industrial Internet of things (IIoT), edge and cloud computing, machine learning, artificial intelligence, and advanced data analytics. However, the existing literature lacks in identifying and discussing the role and requirements of these technologies in DT-enabled industries from the communication and computing perspective. In this article, we first present the functional aspects, appeal, and innovative use of DT in smart industries. Then, we elaborate on this perspective by systematically reviewing and reflecting on recent research in next-generation (NextG) wireless technologies (e.g., 5G and beyond networks), various tools (e.g., age of information, federated learning, data analytics), and other promising trends in networked computing (e.g., edge and cloud computing). Moreover, we discuss the DT deployment strategies at different industrial communication layers to meet the monitoring and control requirements of industrial applications. We also outline several key reflections and future research challenges and directions to facilitate industrial DT's adoption.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20652,""
"Researcher or Crowd Member? Why not both! The Open Research Knowledge   Graph for Applying and Communicating CrowdRE Research","['Oliver Karras', 'Eduard C. Groen', 'Javed Ali Khan', 'SÃ¶ren Auer']","https://export.arxiv.org/abs/2108.05085","2021-08-11","arXiv","cs.DL cs.SE","In recent decades, there has been a major shift towards improved digital access to scholarly works. However, even now that these works are available in digital form, they remain document-based, making it difficult to communicate the knowledge they contain. The next logical step is to extend these works with more flexible, fine-grained, semantic, and context-sensitive representations of scholarly knowledge. The Open Research Knowledge Graph (ORKG) is a platform that structures and interlinks scholarly knowledge, relying on crowdsourced contributions from researchers (as a crowd) to acquire, curate, publish, and process this knowledge. In this experience report, we consider the ORKG in the context of Crowd-based Requirements Engineering (CrowdRE) from two perspectives: (1) As CrowdRE researchers, we investigate how the ORKG practically applies CrowdRE techniques to involve scholars in its development to make it align better with their academic work. We determined that the ORKG readily provides social and financial incentives, feedback elicitation channels, and support for context and usage monitoring, but that there is improvement potential regarding automated user feedback analyses and a holistic CrowdRE approach. (2) As crowd members, we explore how the ORKG can be used to communicate scholarly knowledge about CrowdRE research. For this purpose, we curated qualitative and quantitative scholarly knowledge in the ORKG based on papers contained in two previously published systematic literature reviews (SLRs) on CrowdRE. This knowledge can be explored and compared interactively, and with more data than what the SLRs originally contained. Therefore, the ORKG improves access and communication of the scholarly knowledge about CrowdRE research. For both perspectives, we found the ORKG to be a useful multi-tool for CrowdRE research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20653,""
"TextBenDS: a generic Textual data Benchmark for Distributed Systems","['Ciprian-Octavian Truica', 'Elena Apostol', 'JÃ©rÃ´me Darmont', 'Ira Assent']","https://export.arxiv.org/abs/2108.05689","2021-08-12","arXiv","cs.DB","Extracting top-k keywords and documents using weighting schemes are popular techniques employed in text mining and machine learning for different analysis and retrieval tasks. The weights are usually computed in the data preprocessing step, as they are costly to update and keep track of all the modifications performed on the dataset. Furthermore, computation errors are introduced when analyzing only subsets of the dataset. Therefore, in a Big Data context, it is crucial to lower the runtime of computing weighting schemes, without hindering the analysis process and the accuracy of the machine learning algorithms. To address this requirement for the task of top-k keywords and documents, it is customary to design benchmarks that compare weighting schemes within various configurations of distributed frameworks and database management systems. Thus, we propose a generic document-oriented benchmark for storing textual data and constructing weighting schemes (TextBenDS). Our benchmark offers a generic data model designed with a multidimensional approach for storing text documents. We also propose using aggregation queries with various complexities and selectivities for constructing term weighting schemes, that are utilized in extracting top-k keywords and documents. We evaluate the computing performance of the queries on several distributed environments set within the Apache Hadoop ecosystem. Our experimental results provide interesting insights. As an example, MongoDB proves to have the best overall performance, while Spark's execution time remains almost the same, regardless of the weighting schemes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20654,""
"GQE-PRF: Generative Query Expansion with Pseudo-Relevance Feedback","['Minghui Huang', 'Dong Wang', 'Shuang Liu', 'Meizhen Ding']","https://export.arxiv.org/abs/2108.06010","2021-08-12","arXiv","cs.IR cs.AI cs.CL","Query expansion with pseudo-relevance feedback (PRF) is a powerful approach to enhance the effectiveness in information retrieval. Recently, with the rapid advance of deep learning techniques, neural text generation has achieved promising success in many natural language tasks. To leverage the strength of text generation for information retrieval, in this article, we propose a novel approach which effectively integrates text generation models into PRF-based query expansion. In particular, our approach generates augmented query terms via neural text generation models conditioned on both the initial query and pseudo-relevance feedback. Moreover, in order to train the generative model, we adopt the conditional generative adversarial nets (CGANs) and propose the PRF-CGAN method in which both the generator and the discriminator are conditioned on the pseudo-relevance feedback. We evaluate the performance of our approach on information retrieval tasks using two benchmark datasets. The experimental results show that our approach achieves comparable performance or outperforms traditional query expansion methods on both the retrieval and reranking tasks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20655,""
"MobileCaps: A Lightweight Model for Screening and Severity Analysis of   COVID-19 Chest X-Ray Images","['S J Pawan', 'Rahul Sankar', 'Amithash M Prabhudev', 'P A Mahesh', 'K Prakashini', 'Sudha Kiran Das', 'Jeny Rajan']","https://export.arxiv.org/abs/2108.08775","2021-08-19","arXiv","eess.IV cs.CV cs.LG","The world is going through a challenging phase due to the disastrous effect caused by the COVID-19 pandemic on the healthcare system and the economy. The rate of spreading, post-COVID-19 symptoms, and the occurrence of new strands of COVID-19 have put the healthcare systems in disruption across the globe. Due to this, the task of accurately screening COVID-19 cases has become of utmost priority. Since the virus infects the respiratory system, Chest X-Ray is an imaging modality that is adopted extensively for the initial screening. We have performed a comprehensive study that uses CXR images to identify COVID-19 cases and realized the necessity of having a more generalizable model. We utilize MobileNetV2 architecture as the feature extractor and integrate it into Capsule Networks to construct a fully automated and lightweight model termed as MobileCaps. MobileCaps is trained and evaluated on the publicly available dataset with the model ensembling and Bayesian optimization strategies to efficiently classify CXR images of patients with COVID-19 from non-COVID-19 pneumonia and healthy cases. The proposed model is further evaluated on two additional RT-PCR confirmed datasets to demonstrate the generalizability. We also introduce MobileCaps-S and leverage it for performing severity assessment of CXR images of COVID-19 based on the Radiographic Assessment of Lung Edema (RALE) scoring technique. Our classification model achieved an overall recall of 91.60, 94.60, 92.20, and a precision of 98.50, 88.21, 92.62 for COVID-19, non-COVID-19 pneumonia, and healthy cases, respectively. Further, the severity assessment model attained an R$^2$ coefficient of 70.51. Owing to the fact that the proposed models have fewer trainable parameters than the state-of-the-art models reported in the literature, we believe our models will go a long way in aiding healthcare systems in the battle against the pandemic.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20656,""
"LoOp: Looking for Optimal Hard Negative Embeddings for Deep Metric   Learning","['Bhavya Vasudeva', 'Puneesh Deora', 'Saumik Bhattacharya', 'Umapada Pal', 'Sukalpa Chanda']","https://export.arxiv.org/abs/2108.09335","2021-08-20","arXiv","cs.CV cs.LG","Deep metric learning has been effectively used to learn distance metrics for different visual tasks like image retrieval, clustering, etc. In order to aid the training process, existing methods either use a hard mining strategy to extract the most informative samples or seek to generate hard synthetics using an additional network. Such approaches face different challenges and can lead to biased embeddings in the former case, and (i) harder optimization (ii) slower training speed (iii) higher model complexity in the latter case. In order to overcome these challenges, we propose a novel approach that looks for optimal hard negatives (LoOp) in the embedding space, taking full advantage of each tuple by calculating the minimum distance between a pair of positives and a pair of negatives. Unlike mining-based methods, our approach considers the entire space between pairs of embeddings to calculate the optimal hard negatives. Extensive experiments combining our approach and representative metric learning losses reveal a significant boost in performance on three benchmark datasets.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20657,""
"A Systematic Literature Review of Automated Query Reformulations in   Source Code Search","['Mohammad Masudur Rahman', 'Chanchal K. Roy']","https://export.arxiv.org/abs/2108.09646","2021-08-22","arXiv","cs.SE cs.IR cs.LG cs.NE","Software developers often fix critical bugs to ensure the reliability of their software. They might also need to add new features to their software at a regular interval to stay competitive in the market. These bugs and features are reported as change requests (i.e., technical documents written by software users). Developers consult these documents to implement the required changes in the software code. As a part of change implementation, they often choose a few important keywords from a change request as an ad hoc query. Then they execute the query with a code search engine (e.g., Lucene) and attempt to find out the exact locations within the software code that need to be changed. Unfortunately, even experienced developers often fail to choose the right queries. As a consequence, the developers often experience difficulties in detecting the appropriate locations within the code and spend the majority of their time in numerous trials and errors. There have been many studies that attempt to support developers in constructing queries by automatically reformulating their ad hoc queries. In this systematic literature review, we carefully select 70 primary studies on query reformulations from 2,970 candidate studies, perform an in-depth qualitative analysis using the Grounded Theory approach, and then answer six important research questions. Our investigation has reported several major findings. First, to date, eight major methodologies (e.g., term weighting, query-term co-occurrence analysis, thesaurus lookup) have been adopted in query reformulation. Second, the existing studies suffer from several major limitations (e.g., lack of generalizability, vocabulary mismatch problem, weak evaluation, the extra burden on the developers) that might prevent their wide adoption. Finally, we discuss several open issues in search query reformulations and suggest multiple future research opportunities.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20658,""
"Credit Card Fraud Detection using Machine Learning: A Study","['Pooja Tiwari', 'Simran Mehta', 'Nishtha Sakhuja', 'Jitendra Kumar', 'Ashutosh Kumar Singh']","https://export.arxiv.org/abs/2108.10005","2021-08-23","arXiv","cs.AI","As the world is rapidly moving towards digitization and money transactions are becoming cashless, the use of credit cards has rapidly increased. The fraud activities associated with it have also been increasing which leads to a huge loss to the financial institutions. Therefore, we need to analyze and detect the fraudulent transaction from the non-fraudulent ones. In this paper, we present a comprehensive review of various methods used to detect credit card fraud. These methodologies include Hidden Markov Model, Decision Trees, Logistic Regression, Support Vector Machines (SVM), Genetic algorithm, Neural Networks, Random Forests, Bayesian Belief Network. A comprehensive analysis of various techniques is presented. We conclude the paper with the pros and cons of the same as stated in the respective papers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20659,""
"Legal Search in Case Law and Statute Law","['Julien Rossi', 'Evangelos Kanoulas']","https://export.arxiv.org/abs/2108.10127","2021-08-23","arXiv","cs.CL","In this work we describe a method to identify document pairwise relevance in the context of a typical legal document collection: limited resources, long queries and long documents. We review the usage of generalized language models, including supervised and unsupervised learning. We observe how our method, while using text summaries, overperforms existing baselines based on full text, and motivate potential improvement directions for future work.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20660,""
"Query Embedding Pruning for Dense Retrieval","['Nicola Tonellotto', 'Craig Macdonald']","https://export.arxiv.org/abs/2108.10341","2021-08-23","arXiv","cs.IR","Recent advances in dense retrieval techniques have offered the promise of being able not just to re-rank documents using contextualised language models such as BERT, but also to use such models to identify documents from the collection in the first place. However, when using dense retrieval approaches that use multiple embedded representations for each query, a large number of documents can be retrieved for each query, hindering the efficiency of the method. Hence, this work is the first to consider efficiency improvements in the context of a dense retrieval approach (namely ColBERT), by pruning query term embeddings that are estimated not to be useful for retrieving relevant documents. Our proposed query embeddings pruning reduces the cost of the dense retrieval operation, as well as reducing the number of documents that are retrieved and hence require to be fully scored. Experiments conducted on the MSMARCO passage ranking corpus demonstrate that, when reducing the number of query embeddings used from 32 to 3 based on the collection frequency of the corresponding tokens, query embedding pruning results in no statistically significant differences in effectiveness, while reducing the number of documents retrieved by 70%. In terms of mean response time for the end-to-end to end system, this results in a 2.65x speedup.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20661,""
"Learning Sparse Analytic Filters for Piano Transcription","['Frank Cwitkowitz', 'Mojtaba Heydari', 'Zhiyao Duan']","https://export.arxiv.org/abs/2108.10382","2021-08-23","arXiv","eess.AS cs.LG cs.SD eess.SP","In recent years, filterbank learning has become an increasingly popular strategy for various audio-related machine learning tasks. This is partly due to its ability to discover task-specific audio characteristics which can be leveraged in downstream processing. It is also a natural extension of the nearly ubiquitous deep learning methods employed to tackle a diverse array of audio applications. In this work, several variations of a frontend filterbank learning module are investigated for piano transcription, a challenging low-level music information retrieval task. We build upon a standard piano transcription model, modifying only the feature extraction stage. The filterbank module is designed such that its complex filters are unconstrained 1D convolutional kernels with long receptive fields. Additional variations employ the Hilbert transform to render the filters intrinsically analytic and apply variational dropout to promote filterbank sparsity. Transcription results are compared across all experiments, and we offer visualization and analysis of the filterbanks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20662,""
"Energy time series forecasting-Analytical and empirical assessment of   conventional and machine learning models","['Hala Hamdoun', 'Alaa Sagheer', 'Hassan Youness']","https://export.arxiv.org/abs/2108.10663","2021-08-24","arXiv","cs.LG","Machine learning methods have been adopted in the literature as contenders to conventional methods to solve the energy time series forecasting (TSF) problems. Recently, deep learning methods have been emerged in the artificial intelligence field attaining astonishing performance in a wide range of applications. Yet, the evidence about their performance in to solve the energy TSF problems, in terms of accuracy and computational requirements, is scanty. Most of the review articles that handle the energy TSF problem are systematic reviews, however, a qualitative and quantitative study for the energy TSF problem is not yet available in the literature. The purpose of this paper is twofold, first it provides a comprehensive analytical assessment for conventional,machine learning, and deep learning methods that can be utilized to solve various energy TSF problems. Second, the paper carries out an empirical assessment for many selected methods through three real-world datasets. These datasets related to electrical energy consumption problem, natural gas problem, and electric power consumption of an individual household problem.The first two problems are univariate TSF and the third problem is a multivariate TSF. Com-pared to both conventional and machine learning contenders, the deep learning methods attain a significant improvement in terms of accuracy and forecasting horizons examined. In the mean-time, their computational requirements are notably greater than other contenders. Eventually,the paper identifies a number of challenges, potential research directions, and recommendations to the research community may serve as a basis for further research in the energy forecasting domain.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20663,""
"Sharing Practices for Datasets Related to Accessibility and Aging","['Rie Kamikubo', 'Utkarsh Dwivedi', 'Hernisa Kacorri']","https://export.arxiv.org/abs/2108.10665","2021-08-24","arXiv","cs.HC","Datasets sourced from people with disabilities and older adults play an important role in innovation, benchmarking, and mitigating bias for both assistive and inclusive AI-infused applications. However, they are scarce. We conduct a systematic review of 137 accessibility datasets manually located across different disciplines over the last 35 years. Our analysis highlights how researchers navigate tensions between benefits and risks in data collection and sharing. We uncover patterns in data collection purpose, terminology, sample size, data types, and data sharing practices across communities of focus. We conclude by critically reflecting on challenges and opportunities related to locating and sharing accessibility datasets calling for technical, legal, and institutional privacy frameworks that are more attuned to concerns from these communities.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20664,""
"Using BERT Encoding and Sentence-Level Language Model for Sentence   Ordering","['Melika Golestani', 'Seyedeh Zahra Razavi', 'Zeinab Borhanifard', 'Farnaz Tahmasebian', 'Hesham Faili']","https://export.arxiv.org/abs/2108.10986","2021-08-24","arXiv","cs.CL","Discovering the logical sequence of events is one of the cornerstones in Natural Language Understanding. One approach to learn the sequence of events is to study the order of sentences in a coherent text. Sentence ordering can be applied in various tasks such as retrieval-based Question Answering, document summarization, storytelling, text generation, and dialogue systems. Furthermore, we can learn to model text coherence by learning how to order a set of shuffled sentences. Previous research has relied on RNN, LSTM, and BiLSTM architecture for learning text language models. However, these networks have performed poorly due to the lack of attention mechanisms. We propose an algorithm for sentence ordering in a corpus of short stories. Our proposed method uses a language model based on Universal Transformers (UT) that captures sentences' dependencies by employing an attention mechanism. Our method improves the previous state-of-the-art in terms of Perfect Match Ratio (PMR) score in the ROCStories dataset, a corpus of nearly 100K short human-made stories. The proposed model includes three components: Sentence Encoder, Language Model, and Sentence Arrangement with Brute Force Search. The first component generates sentence embeddings using SBERT-WK pre-trained model fine-tuned on the ROCStories data. Then a Universal Transformer network generates a sentence-level language model. For decoding, the network generates a candidate sentence as the following sentence of the current sentence. We use cosine similarity as a scoring function to assign scores to the candidate embedding and the embeddings of other sentences in the shuffled set. Then a Brute Force Search is employed to maximize the sum of similarities between pairs of consecutive sentences.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20665,""
"On Approximate Nearest Neighbour Selection for Multi-Stage Dense   Retrieval","['Craig Macdonald', 'Nicola Tonellotto']","https://export.arxiv.org/abs/2108.11480","2021-08-25","arXiv","cs.IR","Dense retrieval, which describes the use of contextualised language models such as BERT to identify documents from a collection by leveraging approximate nearest neighbour (ANN) techniques, has been increasing in popularity. Two families of approaches have emerged, depending on whether documents and queries are represented by single or multiple embeddings. ColBERT, the exemplar of the latter, uses an ANN index and approximate scores to identify a set of candidate documents for each query embedding, which are then re-ranked using accurate document representations. In this manner, a large number of documents can be retrieved for each query, hindering the efficiency of the approach. In this work, we investigate the use of ANN scores for ranking the candidate documents, in order to decrease the number of candidate documents being fully scored. Experiments conducted on the MSMARCO passage ranking corpus demonstrate that, by cutting of the candidate set by using the approximate scores to only 200 documents, we can still obtain an effective ranking without statistically significant differences in effectiveness, and resulting in a 2x speedup in efficiency.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20666,""
"A Statutory Article Retrieval Dataset in French","['Antoine Louis', 'Gerasimos Spanakis', 'Gijs Van Dijck']","https://export.arxiv.org/abs/2108.11792","2021-08-26","arXiv","cs.CL","Statutory article retrieval is the task of automatically retrieving law articles relevant to a legal question. While recent advances in natural language processing have sparked considerable interest in many legal tasks, statutory article retrieval remains primarily untouched due to the scarcity of large-scale and high-quality annotated datasets. To address this bottleneck, we introduce the Belgian Statutory Article Retrieval Dataset (BSARD), which consists of 1,100+ French native legal questions labeled by experienced jurists with relevant articles from a corpus of 22,600+ Belgian law articles. Using BSARD, we benchmark several unsupervised information retrieval methods based on term weighting and pooled embeddings. Our best performing baseline achieves 50.8% R@100, which is promising for the feasibility of the task and indicates that there is still substantial room for improvement. By the specificity of the data domain and addressed task, BSARD presents a unique challenge problem for future research on legal information retrieval.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20667,""
"Security and privacy for 6G: A survey on prospective technologies and   challenges","['Van-Linh Nguyen', 'Po-Ching Lin', 'Bo-Chao Cheng', 'Ren-Hung Hwang', 'Ying-Dar Lin']","https://export.arxiv.org/abs/2108.11861","2021-08-26","arXiv","cs.CR cs.NI","Sixth-generation (6G) mobile networks will have to cope with diverse threats on a space-air-ground integrated network environment, novel technologies, and an accessible user information explosion. However, for now, security and privacy issues for 6G remain largely in concept. This survey provides a systematic overview of security and privacy issues based on prospective technologies for 6G in the physical, connection, and service layers, as well as through lessons learned from the failures of existing security architectures and state-of-the-art defenses. Two key lessons learned are as follows. First, other than inheriting vulnerabilities from the previous generations, 6G has new threat vectors from new radio technologies, such as the exposed location of radio stripes in ultra-massive MIMO systems at Terahertz bands and attacks against pervasive intelligence. Second, physical layer protection, deep network slicing, quantum-safe communications, artificial intelligence (AI) security, platform-agnostic security, real-time adaptive security, and novel data protection mechanisms such as distributed ledgers and differential privacy are the top promising techniques to mitigate the attack magnitude and personal data breaches substantially.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20668,""
"Anomaly Detection in Medical Imaging -- A Mini Review","['Maximilian E. Tschuchnig', 'Michael Gadermayr']","https://export.arxiv.org/abs/2108.11986","2021-08-25","arXiv","eess.IV cs.CV cs.LG","The increasing digitization of medical imaging enables machine learning based improvements in detecting, visualizing and segmenting lesions, easing the workload for medical experts. However, supervised machine learning requires reliable labelled data, which is is often difficult or impossible to collect or at least time consuming and thereby costly. Therefore methods requiring only partly labeled data (semi-supervised) or no labeling at all (unsupervised methods) have been applied more regularly. Anomaly detection is one possible methodology that is able to leverage semi-supervised and unsupervised methods to handle medical imaging tasks like classification and segmentation. This paper uses a semi-exhaustive literature review of relevant anomaly detection papers in medical imaging to cluster into applications, highlight important results, establish lessons learned and give further advice on how to approach anomaly detection in medical imaging. The qualitative analysis is based on google scholar and 4 different search terms, resulting in 120 different analysed papers. The main results showed that the current research is mostly motivated by reducing the need for labelled data. Also, the successful and substantial amount of research in the brain MRI domain shows the potential for applications in further domains like OCT and chest X-ray.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20669,""
"Query-Focused Extractive Summarisation for Finding Ideal Answers to   Biomedical and COVID-19 Questions","['Diego MollÃ¡', 'Urvashi Khanna', 'Dima Galat', 'Vincent Nguyen', 'Maciej Rybinski']","https://export.arxiv.org/abs/2108.12189","2021-08-27","arXiv","cs.CL cs.IR","This paper presents Macquarie University's participation to the BioASQ Synergy Task, and BioASQ9b Phase B. In each of these tasks, our participation focused on the use of query-focused extractive summarisation to obtain the ideal answers to medical questions. The Synergy Task is an end-to-end question answering task on COVID-19 where systems are required to return relevant documents, snippets, and answers to a given question. Given the absence of training data, we used a query-focused summarisation system that was trained with the BioASQ8b training data set and we experimented with methods to retrieve the documents and snippets. Considering the poor quality of the documents and snippets retrieved by our system, we observed reasonably good quality in the answers returned. For phase B of the BioASQ9b task, the relevant documents and snippets were already included in the test data. Our system split the snippets into candidate sentences and used BERT variants under a sentence classification setup. The system used the question and candidate sentence as input and was trained to predict the likelihood of the candidate sentence being part of the ideal answer. The runs obtained either the best or second best ROUGE-F1 results of all participants to all batches of BioASQ9b. This shows that using BERT in a classification setup is a very strong baseline for the identification of ideal answers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20670,""
"Machine Learning Methods for Management UAV Flocks -- a Survey","['Rina Azoulay', 'Yoram Haddad', 'Shulamit Reches']","https://export.arxiv.org/abs/2108.13448","2021-08-30","arXiv","cs.LG cs.NI cs.RO cs.SY eess.SY","The development of unmanned aerial vehicles (UAVs) has been gaining momentum in recent years owing to technological advances and a significant reduction in their cost. UAV technology can be used in a wide range of domains, including communication, agriculture, security, and transportation. It may be useful to group the UAVs into clusters/flocks in certain domains, and various challenges associated with UAV usage can be alleviated by clustering. Several computational challenges arise in UAV flock management, which can be solved by using machine learning (ML) methods. In this survey, we describe the basic terms relating to UAVS and modern ML methods, and we provide an overview of related tutorials and surveys. We subsequently consider the different challenges that appear in UAV flocks. For each issue, we survey several machine learning-based methods that have been suggested in the literature to handle the associated challenges. Thereafter, we describe various open issues in which ML can be applied to solve the different challenges of flocks, and we suggest means of using ML methods for this purpose. This comprehensive review may be useful for both researchers and developers in providing a wide view of various aspects of state-of-the-art ML technologies that are applicable to flock management.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20671,""
"Improving Query Representations for Dense Retrieval with Pseudo   Relevance Feedback","['HongChien Yu', 'Chenyan Xiong', 'Jamie Callan']","https://export.arxiv.org/abs/2108.13454","2021-08-30","arXiv","cs.IR cs.AI","Dense retrieval systems conduct first-stage retrieval using embedded representations and simple similarity metrics to match a query to documents. Its effectiveness depends on encoded embeddings to capture the semantics of queries and documents, a challenging task due to the shortness and ambiguity of search queries. This paper proposes ANCE-PRF, a new query encoder that uses pseudo relevance feedback (PRF) to improve query representations for dense retrieval. ANCE-PRF uses a BERT encoder that consumes the query and the top retrieved documents from a dense retrieval model, ANCE, and it learns to produce better query embeddings directly from relevance labels. It also keeps the document index unchanged to reduce overhead. ANCE-PRF significantly outperforms ANCE and other recent dense retrieval systems on several datasets. Analysis shows that the PRF encoder effectively captures the relevant and complementary information from PRF documents, while ignoring the noise with its learned attention mechanism.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20672,""
"Hypergraph-of-Entity: A General Model for Entity-Oriented Search","['JosÃ© Devezas', 'SÃ©rgio Nunes']","https://export.arxiv.org/abs/2109.00450","2021-09-01","arXiv","cs.IR","The hypergraph-of-entity was conceptually proposed as a general model for entity-oriented search. However, only the performance for ad hoc document retrieval had been assessed. We continue this line of research by also evaluating ad hoc entity retrieval, and entity list completion. We also attempt to scale the model, so that it can support the complete INEX 2009 Wikipedia collection. We do this by indexing the top keywords for each document, reducing complexity by partially lowering the number of nodes and, indirectly, the number of hyperedges linking terms to entities. This enables us to compare the effectiveness of the hypergraph-of-entity with the results obtained by the participants of the INEX tracks for the considered tasks. We find this to be a viable model that is, to our knowledge, the first attempt at a generalization in information retrieval, in particular by supporting a universal ranking function for multiple entity-oriented search tasks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20673,""
"Multi-Agent Inverse Reinforcement Learning: Suboptimal Demonstrations   and Alternative Solution Concepts","['Sage Bergerson']","https://export.arxiv.org/abs/2109.01178","2021-09-02","arXiv","cs.AI cs.LG cs.MA","Multi-agent inverse reinforcement learning (MIRL) can be used to learn reward functions from agents in social environments. To model realistic social dynamics, MIRL methods must account for suboptimal human reasoning and behavior. Traditional formalisms of game theory provide computationally tractable behavioral models, but assume agents have unrealistic cognitive capabilities. This research identifies and compares mechanisms in MIRL methods which a) handle noise, biases and heuristics in agent decision making and b) model realistic equilibrium solution concepts. MIRL research is systematically reviewed to identify solutions for these challenges. The methods and results of these studies are analyzed and compared based on factors including performance accuracy, efficiency, and descriptive quality. We found that the primary methods for handling noise, biases and heuristics in MIRL were extensions of Maximum Entropy (MaxEnt) IRL to multi-agent settings. We also found that many successful solution concepts are generalizations of the traditional Nash Equilibrium (NE). These solutions include the correlated equilibrium, logistic stochastic best response equilibrium and entropy regularized mean field NE. Methods which use recursive reasoning or updating also perform well, including the feedback NE and archive multi-agent adversarial IRL. Success in modeling specific biases and heuristics in single-agent IRL and promising results using a Theory of Mind approach in MIRL imply that modeling specific biases and heuristics may be useful. Flexibility and unbiased inference in the identified alternative solution concepts suggest that a solution concept which has both recursive and generalized characteristics may perform well at modeling realistic social interactions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20674,""
"Artificial Intelligence in Dry Eye Disease","['Andrea M. StorÃ¥s', 'Inga StrÃ¼mke', 'Michael A. Riegler', 'Jakob Grauslund', 'Hugo L. Hammer', 'Anis Yazidi', 'PÃ¥l Halvorsen', 'Kjell G. Gundersen', 'Tor P. Utheim', 'Catherine Jackson']","https://export.arxiv.org/abs/2109.01658","2021-09-02","arXiv","cs.LG cs.AI eess.IV","Dry eye disease (DED) has a prevalence of between 5 and 50\%, depending on the diagnostic criteria used and population under study. However, it remains one of the most underdiagnosed and undertreated conditions in ophthalmology. Many tests used in the diagnosis of DED rely on an experienced observer for image interpretation, which may be considered subjective and result in variation in diagnosis. Since artificial intelligence (AI) systems are capable of advanced problem solving, use of such techniques could lead to more objective diagnosis. Although the term `AI' is commonly used, recent success in its applications to medicine is mainly due to advancements in the sub-field of machine learning, which has been used to automatically classify images and predict medical outcomes. Powerful machine learning techniques have been harnessed to understand nuances in patient data and medical images, aiming for consistent diagnosis and stratification of disease severity. This is the first literature review on the use of AI in DED. We provide a brief introduction to AI, report its current use in DED research and its potential for application in the clinic. Our review found that AI has been employed in a wide range of DED clinical tests and research applications, primarily for interpretation of interferometry, slit-lamp and meibography images. While initial results are promising, much work is still needed on model development, clinical testing and standardisation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20675,""
"Deep Person Generation: A Survey from the Perspective of Face, Pose and   Cloth Synthesis","['Tong Sha', 'Wei Zhang', 'Tong Shen', 'Zhoujun Li', 'Tao Mei']","https://export.arxiv.org/abs/2109.02081","2021-09-05","arXiv","cs.CV","Deep person generation has attracted extensive research attention due to its wide applications in virtual agents, video conferencing, online shopping and art/movie production. With the advancement of deep learning, visual appearances (face, pose, cloth) of a person image can be easily generated or manipulated on demand. In this survey, we first summarize the scope of person generation, and then systematically review recent progress and technical trends in deep person generation, covering three major tasks: talking-head generation (face), pose-guided person generation (pose) and garment-oriented person generation (cloth). More than two hundred papers are covered for a thorough overview, and the milestone works are highlighted to witness the major technical breakthrough. Based on these fundamental tasks, a number of applications are investigated, e.g., virtual fitting, digital human, generative data augmentation. We hope this survey could shed some light on the future prospects of deep person generation, and provide a helpful foundation for full applications towards digital human.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20676,""
"Automatic Segmentation of the Optic Nerve Head Region in Optical   Coherence Tomography: A Methodological Review","['Rita Marques', 'Danilo Andrade De Jesus', 'JoÃ£o Barbosa Breda', 'Jan Van Eijgen', 'Ingeborg Stalmans', 'Theo van Walsum', 'Stefan Klein', 'Pedro G. Vaz', 'Luisa SÃ¡nchez Brea']","https://export.arxiv.org/abs/2109.02322","2021-09-06","arXiv","eess.IV cs.CV physics.med-ph","The optic nerve head represents the intraocular section of the optic nerve (ONH), which is prone to damage by intraocular pressure. The advent of optical coherence tomography (OCT) has enabled the evaluation of novel optic nerve head parameters, namely the depth and curvature of the lamina cribrosa (LC). Together with the Bruch's membrane opening minimum-rim-width, these seem to be promising optic nerve head parameters for diagnosis and monitoring of retinal diseases such as glaucoma. Nonetheless, these optical coherence tomography derived biomarkers are mostly extracted through manual segmentation, which is time-consuming and prone to bias, thus limiting their usability in clinical practice. The automatic segmentation of optic nerve head in OCT scans could further improve the current clinical management of glaucoma and other diseases.   This review summarizes the current state-of-the-art in automatic segmentation of the ONH in OCT. PubMed and Scopus were used to perform a systematic review. Additional works from other databases (IEEE, Google Scholar and ARVO IOVS) were also included, resulting in a total of 27 reviewed studies.   For each algorithm, the methods, the size and type of dataset used for validation, and the respective results were carefully analyzed. The results show that deep learning-based algorithms provide the highest accuracy, sensitivity and specificity for segmenting the different structures of the ONH including the LC. However, a lack of consensus regarding the definition of segmented regions, extracted parameters and validation approaches has been observed, highlighting the importance and need of standardized methodologies for ONH segmentation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20677,""
"Mixed Attention Transformer for Leveraging Word-Level Knowledge to   Neural Cross-Lingual Information Retrieval","['Zhiqi Huang', 'Hamed Bonab', 'Sheikh Muhammad Sarwar', 'Razieh Rahimi', 'James Allan']","https://export.arxiv.org/abs/2109.02789","2021-09-06","arXiv","cs.IR cs.CL","Pretrained contextualized representations offer great success for many downstream tasks, including document ranking. The multilingual versions of such pretrained representations provide a possibility of jointly learning many languages with the same model. Although it is expected to gain big with such joint training, in the case of cross lingual information retrieval (CLIR), the models under a multilingual setting are not achieving the same level of performance as those under a monolingual setting. We hypothesize that the performance drop is due to the translation gap between query and documents. In the monolingual retrieval task, because of the same lexical inputs, it is easier for model to identify the query terms that occurred in documents. However, in the multilingual pretrained models that the words in different languages are projected into the same hyperspace, the model tends to translate query terms into related terms, i.e., terms that appear in a similar context, in addition to or sometimes rather than synonyms in the target language. This property is creating difficulties for the model to connect terms that cooccur in both query and document. To address this issue, we propose a novel Mixed Attention Transformer (MAT) that incorporates external word level knowledge, such as a dictionary or translation table. We design a sandwich like architecture to embed MAT into the recent transformer based deep neural models. By encoding the translation knowledge into an attention matrix, the model with MAT is able to focus on the mutually translated words in the input sequence. Experimental results demonstrate the effectiveness of the external knowledge and the significant improvement of MAT embedded neural reranking model on CLIR task.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20678,""
"Towards Natural Language Interfaces for Data Visualization: A Survey","['Leixian Shen', 'Enya Shen', 'Yuyu Luo', 'Xiaocong Yang', 'Xuming Hu', 'Xiongshuai Zhang', 'Zhiwei Tai', 'Jianmin Wang']","https://export.arxiv.org/abs/2109.03506","2021-09-08","arXiv","cs.HC","Utilizing Visualization-oriented Natural Language Interfaces (V-NLI) as a complementary input modality to direct manipulation for visual analytics can provide an engaging user experience. It enables users to focus on their tasks rather than worrying about operating the interface to visualization tools. In the past two decades, leveraging advanced natural language processing technologies, numerous V-NLI systems have been developed both within academic research and commercial software, especially in recent years. In this article, we conduct a comprehensive review of the existing V-NLIs. In order to classify each paper, we develop categorical dimensions based on a classic information visualization pipeline with the extension of a V-NLI layer. The following seven stages are used: query understanding, data transformation, visual mapping, view transformation, human interaction, context management, and presentation. Finally, we also shed light on several promising directions for future work in the community.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20679,""
"Truth Discovery in Sequence Labels from Crowds","['Nasim Sabetpour', 'Adithya Kulkarni', 'Sihong Xie', 'Qi Li']","https://export.arxiv.org/abs/2109.04470","2021-09-09","arXiv","cs.HC cs.LG","Annotations quality and quantity positively affect the performance of sequence labeling, a vital task in Natural Language Processing. Hiring domain experts to annotate a corpus set is very costly in terms of money and time. Crowdsourcing platforms, such as Amazon Mechanical Turk (AMT), have been deployed to assist in this purpose. However, these platforms are prone to human errors due to the lack of expertise; hence, one worker's annotations cannot be directly used to train the model. Existing literature in annotation aggregation more focuses on binary or multi-choice problems. In recent years, handling the sequential label aggregation tasks on imbalanced datasets with complex dependencies between tokens has been challenging. To conquer the challenge, we propose an optimization-based method that infers the best set of aggregated annotations using labels provided by workers. The proposed Aggregation method for Sequential Labels from Crowds ($AggSLC$) jointly considers the characteristics of sequential labeling tasks, workers' reliabilities, and advanced machine learning techniques. We evaluate $AggSLC$ on different crowdsourced data for Named Entity Recognition (NER), Information Extraction tasks in biomedical (PICO), and the simulated dataset. Our results show that the proposed method outperforms the state-of-the-art aggregation methods. To achieve insights into the framework, we study $AggSLC$ components' effectiveness through ablation studies by evaluating our model in the absence of the prediction module and inconsistency loss function. Theoretical analysis of our algorithm's convergence points that the proposed $AggSLC$ halts after a finite number of iterations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20680,""
"EfficientCLIP: Efficient Cross-Modal Pre-training by Ensemble Confident   Learning and Language Modeling","['Jue Wang', 'Haofan Wang', 'Jincan Deng', 'Weijia Wu', 'Debing Zhang']","https://export.arxiv.org/abs/2109.04699","2021-09-10","arXiv","cs.CL cs.CV cs.LG","While large scale pre-training has achieved great achievements in bridging the gap between vision and language, it still faces several challenges. First, the cost for pre-training is expensive. Second, there is no efficient way to handle the data noise which degrades model performance. Third, previous methods only leverage limited image-text paired data, while ignoring richer single-modal data, which may result in poor generalization to single-modal downstream tasks. In this work, we propose an EfficientCLIP method via Ensemble Confident Learning to obtain a less noisy data subset. Extra rich non-paired single-modal text data is used for boosting the generalization of text branch. We achieve the state-of-the-art performance on Chinese cross-modal retrieval tasks with only 1/10 training resources compared to CLIP and WenLan, while showing excellent generalization to single-modal tasks, including text retrieval and text classification.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20681,""
"Heterogeneous Graph Neural Networks for Keyphrase Generation","['Jiacheng Ye', 'Ruijian Cai', 'Tao Gui', 'Qi Zhang']","https://export.arxiv.org/abs/2109.04703","2021-09-10","arXiv","cs.CL cs.AI","The encoder-decoder framework achieves state-of-the-art results in keyphrase generation (KG) tasks by predicting both present keyphrases that appear in the source document and absent keyphrases that do not. However, relying solely on the source document can result in generating uncontrollable and inaccurate absent keyphrases. To address these problems, we propose a novel graph-based method that can capture explicit knowledge from related references. Our model first retrieves some document-keyphrases pairs similar to the source document from a pre-defined index as references. Then a heterogeneous graph is constructed to capture relationships of different granularities between the source document and its references. To guide the decoding process, a hierarchical attention and copy mechanism is introduced, which directly copies appropriate words from both the source document and its references based on their relevance and significance. The experimental results on multiple KG benchmarks show that the proposed model achieves significant improvements against other baseline models, especially with regard to the absent keyphrase prediction.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20682,""
"Keyword Extraction for Improved Document Retrieval in Conversational   Search","['Oleg Borisov', 'Mohammad Aliannejadi', 'Fabio Crestani']","https://export.arxiv.org/abs/2109.05979","2021-09-13","arXiv","cs.CL cs.IR","Recent research has shown that mixed-initiative conversational search, based on the interaction between users and computers to clarify and improve a query, provides enormous advantages. Nonetheless, incorporating additional information provided by the user from the conversation poses some challenges. In fact, further interactions could confuse the system as a user might use words irrelevant to the information need but crucial for correct sentence construction in the context of multi-turn conversations. To this aim, in this paper, we have collected two conversational keyword extraction datasets and propose an end-to-end document retrieval pipeline incorporating them. Furthermore, we study the performance of two neural keyword extraction models, namely, BERT and sequence to sequence, in terms of extraction accuracy and human annotation. Finally, we study the effect of keyword extraction on the end-to-end neural IR performance and show that our approach beats state-of-the-art IR models. We make the two datasets publicly available to foster research in this area.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20683,""
"Statistical Inference: The Missing Piece of RecSys Experiment   Reliability Discourse","['Ngozi Ihemelandu', 'Michael D. Ekstrand']","https://export.arxiv.org/abs/2109.06424","2021-09-14","arXiv","cs.IR","This paper calls attention to the missing component of the recommender system evaluation process: Statistical Inference. There is active research in several components of the recommender system evaluation process: selecting baselines, standardizing benchmarks, and target item sampling. However, there has not yet been significant work on the role and use of statistical inference for analyzing recommender system evaluation results. In this paper, we argue that the use of statistical inference is a key component of the evaluation process that has not been given sufficient attention. We support this argument with systematic review of recent RecSys papers to understand how statistical inference is currently being used, along with a brief survey of studies that have been done on the use of statistical inference in the information retrieval community. We present several challenges that exist for inference in recommendation experiment which buttresses the need for empirical studies to aid with appropriately selecting and applying statistical inference techniques.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20684,""
"Co-Embedding: Discovering Communities on Bipartite Graphs through   Projection","['GaÃ«lle Candel', 'David Naccache']","https://export.arxiv.org/abs/2109.07135","2021-09-15","arXiv","cs.IR cs.AI","Many datasets take the form of a bipartite graph where two types of nodes are connected by relationships, like the movies watched by a user or the tags associated with a file. The partitioning of the bipartite graph could be used to fasten recommender systems, or reduce the information retrieval system's index size, by identifying groups of items with similar properties. This type of graph is often processed by algorithms using the Vector Space Model representation, where a binary vector represents an item with 0 and 1. The main problem with this representation is the dimension relatedness, like words' synonymity, which is not considered. This article proposes a co-clustering algorithm using items projection, allowing the measurement of features similarity. We evaluated our algorithm on a cluster retrieval task. Over various datasets, our algorithm produced well balanced clusters with coherent items in, leading to high retrieval scores on this task..","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20685,""
"Network representation learning systematic review: ancestors and current   development state","['Amina Amara', 'Mohamed Ali Hadj Taieb', 'Mohamed Ben Aouicha']","https://export.arxiv.org/abs/2109.07583","2021-09-14","arXiv","cs.LG cs.AI","Real-world information networks are increasingly occurring across various disciplines including online social networks and citation networks. These network data are generally characterized by sparseness, nonlinearity and heterogeneity bringing different challenges to the network analytics task to capture inherent properties from network data. Artificial intelligence and machine learning have been recently leveraged as powerful systems to learn insights from network data and deal with presented challenges. As part of machine learning techniques, graph embedding approaches are originally conceived for graphs constructed from feature represented datasets, like image dataset, in which links between nodes are explicitly defined. These traditional approaches cannot cope with network data challenges. As a new learning paradigm, network representation learning has been proposed to map a real-world information network into a low-dimensional space while preserving inherent properties of the network. In this paper, we present a systematic comprehensive survey of network representation learning, known also as network embedding, from birth to the current development state. Through the undertaken survey, we provide a comprehensive view of reasons behind the emergence of network embedding and, types of settings and models used in the network embedding pipeline. Thus, we introduce a brief history of representation learning and word representation learning ancestor of network embedding. We provide also formal definitions of basic concepts required to understand network representation learning followed by a description of network embedding pipeline. Most commonly used downstream tasks to evaluate embeddings, their evaluation metrics and popular datasets are highlighted. Finally, we present the open-source libraries for network embedding.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20686,""
"Ethics of AI: A Systematic Literature Review of Principles and   Challenges","['Arif Ali Khan', 'Sher Badshah', 'Peng Liang', 'Bilal Khan', 'Muhammad Waseem', 'Mahmood Niazi', 'Muhammad Azeem Akbar']","https://export.arxiv.org/abs/2109.07906","2021-09-12","arXiv","cs.CY cs.AI","Ethics in AI becomes a global topic of interest for both policymakers and academic researchers. In the last few years, various research organizations, lawyers, think tankers and regulatory bodies get involved in developing AI ethics guidelines and principles. However, there is still debate about the implications of these principles. We conducted a systematic literature review (SLR) study to investigate the agreement on the significance of AI principles and identify the challenging factors that could negatively impact the adoption of AI ethics principles. The results reveal that the global convergence set consists of 22 ethical principles and 15 challenges. Transparency, privacy, accountability and fairness are identified as the most common AI ethics principles. Similarly, lack of ethical knowledge and vague principles are reported as the significant challenges for considering ethics in AI. The findings of this study are the preliminary inputs for proposing a maturity model that assess the ethical capabilities of AI systems and provide best practices for further improvements.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20687,""
"FOMO: Topics versus documents in legal eDiscovery","['Herbert Roitblat']","https://export.arxiv.org/abs/2109.08059","2021-09-16","arXiv","cs.IR","In the United States, the parties to a lawsuit are required to search through their electronically stored information to find documents that are relevant to the specific case and produce them to their opposing party. Negotiations over the scope of these searches often reflect a fear that something will be missed (Fear of Missing Out: FOMO). A Recall level of 80%, for example, means that 20% of the relevant documents will be left unproduced. This paper makes the argument that eDiscovery is the process of identifying responsive information, not identifying documents. Documents are the carriers of the information; they are not the direct targets of the process. A given document may contain one or more topics or factoids and a factoid may appear in more than one document. The coupon collector's problem, Heaps law, and other analyses provide ways to model the problem of finding information from among documents. In eDiscovery, however, the parties do not know how many factoids there might be in a collection or their probabilities. This paper describes a simple model that estimates the confidence that a fact will be omitted from the produced set (the identified set), while being contained in the missed set. Two data sets are then analyzed, a small set involving microaggressions and larger set involving classification of web pages. Both show that it is possible to discover at least one example of each available topic within a relatively small number of documents, meaning the further effort will not return additional novel information. The smaller data set is also used to investigate whether the non-random order of searching for responsive documents commonly used in eDiscovery (called continuous active learning) affects the distribution of topics-it does not.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20688,""
"Phrase Retrieval Learns Passage Retrieval, Too","['Jinhyuk Lee', 'Alexander Wettig', 'Danqi Chen']","https://export.arxiv.org/abs/2109.08133","2021-09-16","arXiv","cs.CL cs.IR","Dense retrieval methods have shown great promise over sparse retrieval methods in a range of NLP problems. Among them, dense phrase retrieval-the most fine-grained retrieval unit-is appealing because phrases can be directly used as the output for question answering and slot filling tasks. In this work, we follow the intuition that retrieving phrases naturally entails retrieving larger text blocks and study whether phrase retrieval can serve as the basis for coarse-level retrieval including passages and documents. We first observe that a dense phrase-retrieval system, without any retraining, already achieves better passage retrieval accuracy (+3-5% in top-5 accuracy) compared to passage retrievers, which also helps achieve superior end-to-end QA performance with fewer passages. Then, we provide an interpretation for why phrase-level supervision helps learn better fine-grained entailment compared to passage-level supervision, and also show that phrase retrieval can be improved to achieve competitive performance in document-retrieval tasks such as entity linking and knowledge-grounded dialogue. Finally, we demonstrate how phrase filtering and vector quantization can reduce the size of our index by 4-10x, making dense phrase retrieval a practical and versatile solution in multi-granularity retrieval.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20689,""
"An Open-Publishing Response to the COVID-19 Infodemic","['Halie M. Rando', 'Simina M. Boca', ""Lucy D'Agostino McGowan"", 'Daniel S. Himmelstein', 'Michael P. Robson', 'Vincent Rubinetti', 'Ryan Velazquez', 'COVID-19 Review Consortium', 'Casey S. Greene', 'Anthony Gitter']","https://export.arxiv.org/abs/2109.08633","2021-09-17","arXiv","cs.DL q-bio.QM","The COVID-19 pandemic catalyzed the rapid dissemination of papers and preprints investigating the disease and its associated virus, SARS-CoV-2. The multifaceted nature of COVID-19 demands a multidisciplinary approach, but the urgency of the crisis combined with the need for social distancing measures present unique challenges to collaborative science. We applied a massive online open publishing approach to this problem using Manubot. Through GitHub, collaborators summarized and critiqued COVID-19 literature, creating a review manuscript. Manubot automatically compiled citation information for referenced preprints, journal publications, websites, and clinical trials. Continuous integration workflows retrieved up-to-date data from online sources nightly, regenerating some of the manuscript's figures and statistics. Manubot rendered the manuscript into PDF, HTML, LaTeX, and DOCX outputs, immediately updating the version available online upon the integration of new content. Through this effort, we organized over 50 scientists from a range of backgrounds who evaluated over 1,500 sources and developed seven literature reviews. While many efforts from the computational community have focused on mining COVID-19 literature, our project illustrates the power of open publishing to organize both technical and non-technical scientists to aggregate and disseminate information in response to an evolving crisis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20690,""
"Computational Imaging and Artificial Intelligence: The Next Revolution   of Mobile Vision","['Jinli Suo', 'Weihang Zhang', 'Jin Gong', 'Xin Yuan', 'David J. Brady', 'Qionghai Dai']","https://export.arxiv.org/abs/2109.08880","2021-09-18","arXiv","cs.CV cs.AI eess.IV","Signal capture stands in the forefront to perceive and understand the environment and thus imaging plays the pivotal role in mobile vision. Recent explosive progresses in Artificial Intelligence (AI) have shown great potential to develop advanced mobile platforms with new imaging devices. Traditional imaging systems based on the ""capturing images first and processing afterwards"" mechanism cannot meet this unprecedented demand. Differently, Computational Imaging (CI) systems are designed to capture high-dimensional data in an encoded manner to provide more information for mobile vision systems.Thanks to AI, CI can now be used in real systems by integrating deep learning algorithms into the mobile vision platform to achieve the closed loop of intelligent acquisition, processing and decision making, thus leading to the next revolution of mobile vision.Starting from the history of mobile vision using digital cameras, this work first introduces the advances of CI in diverse applications and then conducts a comprehensive review of current research topics combining CI and AI. Motivated by the fact that most existing studies only loosely connect CI and AI (usually using AI to improve the performance of CI and only limited works have deeply connected them), in this work, we propose a framework to deeply integrate CI and AI by using the example of self-driving vehicles with high-speed communication, edge computing and traffic planning. Finally, we outlook the future of CI plus AI by investigating new materials, brain science and new computing techniques to shed light on new directions of mobile vision systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20691,""
"BERT Has Uncommon Sense: Similarity Ranking for Word Sense BERTology","['Luke Gessler', 'Nathan Schneider']","https://export.arxiv.org/abs/2109.09780","2021-09-20","arXiv","cs.CL","An important question concerning contextualized word embedding (CWE) models like BERT is how well they can represent different word senses, especially those in the long tail of uncommon senses. Rather than build a WSD system as in previous work, we investigate contextualized embedding neighborhoods directly, formulating a query-by-example nearest neighbor retrieval task and examining ranking performance for words and senses in different frequency bands. In an evaluation on two English sense-annotated corpora, we find that several popular CWE models all outperform a random baseline even for proportionally rare senses, without explicit sense supervision. However, performance varies considerably even among models with similar architectures and pretraining regimes, with especially large differences for rare word senses, revealing that CWE models are not all created equal when it comes to approximating word senses in their native representations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20692,""
"A Comprehensive Review on Summarizing Financial News Using Deep Learning","['Saurabh Kamal', 'Sahil Sharma']","https://export.arxiv.org/abs/2109.10118","2021-09-21","arXiv","cs.CL","Investors make investment decisions depending on several factors such as fundamental analysis, technical analysis, and quantitative analysis. Another factor on which investors can make investment decisions is through sentiment analysis of news headlines, the sole purpose of this study. Natural Language Processing techniques are typically used to deal with such a large amount of data and get valuable information out of it. NLP algorithms convert raw text into numerical representations that machines can easily understand and interpret. This conversion can be done using various embedding techniques. In this research, embedding techniques used are BoW, TF-IDF, Word2Vec, BERT, GloVe, and FastText, and then fed to deep learning models such as RNN and LSTM. This work aims to evaluate these model's performance to choose the robust model in identifying the significant factors influencing the prediction. During this research, it was expected that Deep Leaming would be applied to get the desired results or achieve better accuracy than the state-of-the-art. The models are compared to check their outputs to know which one has performed better.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20693,""
"Homography augumented momentum constrastive learning for SAR image   retrieval","['Seonho Park', 'Maciej Rysz', 'Kathleen M. Dipple', 'Panos M. Pardalos']","https://export.arxiv.org/abs/2109.10329","2021-09-21","arXiv","cs.CV cs.IR cs.LG","Deep learning-based image retrieval has been emphasized in computer vision. Representation embedding extracted by deep neural networks (DNNs) not only aims at containing semantic information of the image, but also can manage large-scale image retrieval tasks. In this work, we propose a deep learning-based image retrieval approach using homography transformation augmented contrastive learning to perform large-scale synthetic aperture radar (SAR) image search tasks. Moreover, we propose a training method for the DNNs induced by contrastive learning that does not require any labeling procedure. This may enable tractability of large-scale datasets with relative ease. Finally, we verify the performance of the proposed method by conducting experiments on the polarimetric SAR image datasets.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20694,""
"RETRONLU: Retrieval Augmented Task-Oriented Semantic Parsing","['Vivek Gupta', 'Akshat Shrivastava', 'Adithya Sagar', 'Armen Aghajanyan', 'Denis Savenkov']","https://export.arxiv.org/abs/2109.10410","2021-09-21","arXiv","cs.CL cs.IR cs.LG","While large pre-trained language models accumulate a lot of knowledge in their parameters, it has been demonstrated that augmenting it with non-parametric retrieval-based memory has a number of benefits from accuracy improvements to data efficiency for knowledge-focused tasks, such as question answering. In this paper, we are applying retrieval-based modeling ideas to the problem of multi-domain task-oriented semantic parsing for conversational assistants. Our approach, RetroNLU, extends a sequence-to-sequence model architecture with a retrieval component, used to fetch existing similar examples and provide them as an additional input to the model. In particular, we analyze two settings, where we augment an input with (a) retrieved nearest neighbor utterances (utterance-nn), and (b) ground-truth semantic parses of nearest neighbor utterances (semparse-nn). Our technique outperforms the baseline method by 1.5% absolute macro-F1, especially at the low resource setting, matching the baseline model accuracy with only 40% of the data. Furthermore, we analyze the nearest neighbor retrieval component's quality, model sensitivity and break down the performance for semantic parses of different utterance complexity.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20695,""
"Attacks on Visualization-Based Malware Detection: Balancing   Effectiveness and Executability","['Hadjer Benkraouda', 'Jingyu Qian', 'Hung Quoc Tran', 'Berkay Kaplan']","https://export.arxiv.org/abs/2109.10417","2021-09-21","arXiv","cs.CR","With the rapid development of machine learning for image classification, researchers have found new applications of visualization techniques in malware detection. By converting binary code into images, researchers have shown satisfactory results in applying machine learning to extract features that are difficult to discover manually. Such visualization-based malware detection methods can capture malware patterns from many different malware families and improve malware detection speed. On the other hand, recent research has also shown adversarial attacks against such visualization-based malware detection. Attackers can generate adversarial examples by perturbing the malware binary in non-reachable regions, such as padding at the end of the binary. Alternatively, attackers can perturb the malware image embedding and then verify the executability of the malware post-transformation. One major limitation of the first attack scenario is that a simple pre-processing step can remove the perturbations before classification. For the second attack scenario, it is hard to maintain the original malware's executability and functionality. In this work, we provide literature review on existing malware visualization techniques and attacks against them. We summarize the limitation of the previous work, and design a new adversarial example attack against visualization-based malware detection that can evade pre-processing filtering and maintain the original malware functionality. We test our attack on a public malware dataset and achieve a 98% success rate.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20696,""
"Predicting Efficiency/Effectiveness Trade-offs for Dense vs Sparse   Retrieval Strategy Selection","['Negar Arabzadeh', 'Xinyi Yan', 'Charles L. A. Clarke']","https://export.arxiv.org/abs/2109.10739","2021-09-22","arXiv","cs.IR","Over the last few years, contextualized pre-trained transformer models such as BERT have provided substantial improvements on information retrieval tasks. Recent approaches based on pre-trained transformer models such as BERT, fine-tune dense low-dimensional contextualized representations of queries and documents in embedding space. While these dense retrievers enjoy substantial retrieval effectiveness improvements compared to sparse retrievers, they are computationally intensive, requiring substantial GPU resources, and dense retrievers are known to be more expensive from both time and resource perspectives. In addition, sparse retrievers have been shown to retrieve complementary information with respect to dense retrievers, leading to proposals for hybrid retrievers. These hybrid retrievers leverage low-cost, exact-matching based sparse retrievers along with dense retrievers to bridge the semantic gaps between query and documents. In this work, we address this trade-off between the cost and utility of sparse vs dense retrievers by proposing a classifier to select a suitable retrieval strategy (i.e., sparse vs. dense vs. hybrid) for individual queries. Leveraging sparse retrievers for queries which can be answered with sparse retrievers decreases the number of calls to GPUs. Consequently, while utility is maintained, query latency decreases. Although we use less computational resources and spend less time, we still achieve improved performance. Our classifier can select between sparse and dense retrieval strategies based on the query alone. We conduct experiments on the MS MARCO passage dataset demonstrating an improved range of efficiency/effectiveness trade-offs between purely sparse, purely dense or hybrid retrieval strategies, allowing an appropriate strategy to be selected based on a target latency and resource budget.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20697,""
"Recent Advances of Continual Learning in Computer Vision: An Overview","['Haoxuan Qu', 'Hossein Rahmani', 'Li Xu', 'Bryan Williams', 'Jun Liu']","https://export.arxiv.org/abs/2109.11369","2021-09-23","arXiv","cs.CV","In contrast to batch learning where all training data is available at once, continual learning represents a family of methods that accumulate knowledge and learn continuously with data available in sequential order. Similar to the human learning process with the ability of learning, fusing, and accumulating new knowledge coming at different time steps, continual learning is considered to have high practical significance. Hence, continual learning has been studied in various artificial intelligence tasks. In this paper, we present a comprehensive review of the recent progress of continual learning in computer vision. In particular, the works are grouped by their representative techniques, including regularization, knowledge distillation, memory, generative replay, parameter isolation, and a combination of the above techniques. For each category of these techniques, both its characteristics and applications in computer vision are presented. At the end of this overview, several subareas, where continuous knowledge accumulation is potentially helpful while continual learning has not been well studied, are discussed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20698,""
"A survey of Bayesian Network structure learning","['Neville K. Kitson', 'Anthony C. Constantinou', 'Zhigao Guo', 'Yang Liu', 'Kiattikun Chobtham']","https://export.arxiv.org/abs/2109.11415","2021-09-23","arXiv","cs.LG cs.AI","Bayesian Networks (BNs) have become increasingly popular over the last few decades as a tool for reasoning under uncertainty in fields as diverse as medicine, biology, epidemiology, economics and the social sciences. This is especially true in real-world areas where we seek to answer complex questions based on hypothetical evidence to determine actions for intervention. However, determining the graphical structure of a BN remains a major challenge, especially when modelling a problem under causal assumptions. Solutions to this problem include the automated discovery of BN graphs from data, constructing them based on expert knowledge, or a combination of the two. This paper provides a comprehensive review of combinatoric algorithms proposed for learning BN structure from data, describing 61 algorithms including prototypical, well-established and state-of-the-art approaches. The basic approach of each algorithm is described in consistent terms, and the similarities and differences between them highlighted. Methods of evaluating algorithms and their comparative performance are discussed including the consistency of claims made in the literature. Approaches for dealing with data noise in real-world datasets and incorporating expert knowledge into the learning process are also covered.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20699,""
"Document Automation Architectures and Technologies: A Survey","['Mohammad Ahmadi Achachlouei', 'Omkar Patil', 'Tarun Joshi', 'Vijayan N. Nair']","https://export.arxiv.org/abs/2109.11603","2021-09-23","arXiv","cs.CL cs.LG","This paper surveys the current state of the art in document automation (DA). The objective of DA is to reduce the manual effort during the generation of documents by automatically integrating input from different sources and assembling documents conforming to defined templates. There have been reviews of commercial solutions of DA, particularly in the legal domain, but to date there has been no comprehensive review of the academic research on DA architectures and technologies. The current survey of DA reviews the academic literature and provides a clearer definition and characterization of DA and its features, identifies state-of-the-art DA architectures and technologies in academic research, and provides ideas that can lead to new research opportunities within the DA field in light of recent advances in artificial intelligence and deep neural networks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20700,""
"Entity Linking Meets Deep Learning: Techniques and Solutions","['Wei Shen', 'Yuhan Li', 'Yinan Liu', 'Jiawei Han', 'Jianyong Wang', 'Xiaojie Yuan']","https://export.arxiv.org/abs/2109.12520","2021-09-26","arXiv","cs.CL cs.AI","Entity linking (EL) is the process of linking entity mentions appearing in web text with their corresponding entities in a knowledge base. EL plays an important role in the fields of knowledge engineering and data mining, underlying a variety of downstream applications such as knowledge base population, content analysis, relation extraction, and question answering. In recent years, deep learning (DL), which has achieved tremendous success in various domains, has also been leveraged in EL methods to surpass traditional machine learning based methods and yield the state-of-the-art performance. In this survey, we present a comprehensive review and analysis of existing DL based EL methods. First of all, we propose a new taxonomy, which organizes existing DL based EL methods using three axes: embedding, feature, and algorithm. Then we systematically survey the representative EL methods along the three axes of the taxonomy. Later, we introduce ten commonly used EL data sets and give a quantitative performance analysis of DL based EL methods over these data sets. Finally, we discuss the remaining limitations of existing methods and highlight some promising future directions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20701,""
"From internal models toward metacognitive AI","['Mitsuo Kawato', 'Aurelio Cortese']","https://export.arxiv.org/abs/2109.12798","2021-09-27","arXiv","q-bio.NC cs.AI","In several papers published in Biological Cybernetics in the 1980s and 1990s, Kawato and colleagues proposed computational models explaining how internal models are acquired in the cerebellum. These models were later supported by neurophysiological experiments using monkeys and neuroimaging experiments involving humans. These early studies influenced neuroscience from basic, sensory-motor control to higher cognitive functions. One of the most perplexing enigmas related to internal models is to understand the neural mechanisms that enable animals to learn large-dimensional problems with so few trials. Consciousness and metacognition -- the ability to monitor one's own thoughts, may be part of the solution to this enigma. Based on literature reviews of the past 20 years, here we propose a computational neuroscience model of metacognition. The model comprises a modular hierarchical reinforcement-learning architecture of parallel and layered, generative-inverse model pairs. In the prefrontal cortex, a distributed executive network called the ""cognitive reality monitoring network"" (CRMN) orchestrates conscious involvement of generative-inverse model pairs in perception and action. Based on mismatches between computations by generative and inverse models, as well as reward prediction errors, CRMN computes a ""responsibility signal"" that gates selection and learning of pairs in perception, action, and reinforcement learning. A high responsibility signal is given to the pairs that best capture the external world, that are competent in movements (small mismatch), and that are capable of reinforcement learning (small reward prediction error). CRMN selects pairs with higher responsibility signals as objects of metacognition, and consciousness is determined by the entropy of responsibility signals across all pairs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20702,""
"Graph Neural Networks for Recommender Systems: Challenges, Methods, and   Directions","['Chen Gao', 'Yu Zheng', 'Nian Li', 'Yinfeng Li', 'Yingrong Qin', 'Jinghua Piao', 'Yuhan Quan', 'Jianxin Chang', 'Depeng Jin', 'Xiangnan He', 'Yong Li']","https://export.arxiv.org/abs/2109.12843","2021-09-27","arXiv","cs.IR","Recommender system is one of the most important information services on today's Internet. Recently, graph neural networks have become the new state-of-the-art approach of recommender systems. In this survey, we conduct a comprehensive review of the literature in graph neural network-based recommender systems. We first introduce the background and the history of the development of both recommender systems and graph neural networks. For recommender systems, in general, there are four aspects for categorizing existing works: stage, scenario, objective, and application. For graph neural networks, the existing methods consist of two categories, spectral models and spatial ones. We then discuss the motivation of applying graph neural networks into recommender systems, mainly consisting of the high-order connectivity, the structural property of data, and the enhanced supervision signal. We then systematically analyze the challenges in graph construction, embedding propagation/aggregation, model optimization, and computation efficiency. Afterward and primarily, we provide a comprehensive overview of a multitude of existing works of graph neural network-based recommender systems, following the taxonomy above. Finally, we raise discussions on the open problems and promising future directions of this area. We summarize the representative papers along with their codes repositories in https://github.com/tsinghua-fib-lab/GNN-Recommender-Systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20703,""
"Trustworthy AI and Robotics and the Implications for the AEC Industry: A   Systematic Literature Review and Future Potentials","['Newsha Emaminejad', 'Reza Akhavian']","https://export.arxiv.org/abs/2109.13373","2021-09-27","arXiv","cs.HC cs.AI cs.LG","Human-technology interaction deals with trust as an inevitable requirement for user acceptance. As the applications of artificial intelligence (AI) and robotics emerge and with their ever-growing socio-economic influence in various fields of research and practice, there is an imminent need to study trust in such systems. With the opaque work mechanism of AI-based systems and the prospect of intelligent robots as workers' companions, context-specific interdisciplinary studies on trust are key in increasing their adoption. Through a thorough systematic literature review on (1) trust in AI and robotics (AIR) and (2) AIR applications in the architecture, engineering, and construction (AEC) industry, this study identifies common trust dimensions in the literature and uses them to organize the paper. Furthermore, the connections of the identified dimensions to the existing and potential AEC applications are determined and discussed. Finally, major future directions on trustworthy AI and robotics in AEC research and practice are outlined.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20704,""
"Intelligent Decision Assistance Versus Automated Decision-Making:   Enhancing Knowledge Work Through Explainable Artificial Intelligence","['Max Schemmer', 'Niklas KÃ¼hl', 'Gerhard Satzger']","https://export.arxiv.org/abs/2109.13827","2021-09-28","arXiv","cs.HC cs.AI","While recent advances in AI-based automated decision-making have shown many benefits for businesses and society, they also come at a cost. It has for long been known that a high level of automation of decisions can lead to various drawbacks, such as automation bias and deskilling. In particular, the deskilling of knowledge workers is a major issue, as they are the same people who should also train, challenge and evolve AI. To address this issue, we conceptualize a new class of DSS, namely Intelligent Decision Assistance (IDA) based on a literature review of two different research streams -- DSS and automation. IDA supports knowledge workers without influencing them through automated decision-making. Specifically, we propose to use techniques of Explainable AI (XAI) while withholding concrete AI recommendations. To test this conceptualization, we develop hypotheses on the impacts of IDA and provide first evidence for their validity based on empirical studies in the literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20705,""
"Intelligence Complements from the Built Environment: A review of Smart   Building Technologies for Cognitively Declined Occupants","['Saeid Alimoradi', 'Xinghua Gao']","https://export.arxiv.org/abs/2109.13852","2021-09-28","arXiv","cs.HC","Traditionally, caregivers, whether formal or informal, have taken the responsibility of providing assistance and care to patients with cognitive decline. Usually, both the caregiver and the patient are subjected to financial and emotional burdens, which impact the patient's life quality. To overcome this issue, Ambient Assistive Living (AAL) technologies have been adopted to replace the caregivers and complement patients' lack of intelligence. Technologies such as Internet of Things (IoT) and Artificial Intelligence (AI) have enabled intelligent ubiquitous learning for smart buildings to monitor the cognitively declined occupants and provide in-home assistive services and solutions. This paper aims to summarize and evaluate the intelligence complements provided by smart buildings that can increase the cognitively declined occupants' quality of life and autonomy. Through a systematic literature review, the authors find that most of the existing contributions are towards identifying the occupants' behavior, and thus, to determine corresponding assistive services and solutions. Five key research gaps are identified, including the lack of adequate adoption of technological interventions to fully support the occupants' autonomy and independence. The authors also propose a conceptual framework to highlight the research gaps in smart building applications for cognitively declined occupants and to map the future research directions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20706,""
"A Review of Text Style Transfer using Deep Learning","['Martina Toshevska', 'Sonja Gievska']","https://export.arxiv.org/abs/2109.15144","2021-09-30","arXiv","cs.CL cs.AI","Style is an integral component of a sentence indicated by the choice of words a person makes. Different people have different ways of expressing themselves, however, they adjust their speaking and writing style to a social context, an audience, an interlocutor or the formality of an occasion. Text style transfer is defined as a task of adapting and/or changing the stylistic manner in which a sentence is written, while preserving the meaning of the original sentence.   A systematic review of text style transfer methodologies using deep learning is presented in this paper. We point out the technological advances in deep neural networks that have been the driving force behind current successes in the fields of natural language understanding and generation. The review is structured around two key stages in the text style transfer process, namely, representation learning and sentence generation in a new style. The discussion highlights the commonalities and differences between proposed solutions as well as challenges and opportunities that are expected to direct and foster further research in the field.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20707,""
"Asking questions on handwritten document collections","['Minesh Mathew', 'Lluis Gomez', 'Dimosthenis Karatzas', 'CV Jawahar']","https://export.arxiv.org/abs/2110.00711","2021-10-01","arXiv","cs.CV","This work addresses the problem of Question Answering (QA) on handwritten document collections. Unlike typical QA and Visual Question Answering (VQA) formulations where the answer is a short text, we aim to locate a document snippet where the answer lies. The proposed approach works without recognizing the text in the documents. We argue that the recognition-free approach is suitable for handwritten documents and historical collections where robust text recognition is often difficult. At the same time, for human users, document image snippets containing answers act as a valid alternative to textual answers. The proposed approach uses an off-the-shelf deep embedding network which can project both textual words and word images into a common sub-space. This embedding bridges the textual and visual domains and helps us retrieve document snippets that potentially answer a question. We evaluate results of the proposed approach on two new datasets: (i) HW-SQuAD: a synthetic, handwritten document image counterpart of SQuAD1.0 dataset and (ii) BenthamQA: a smaller set of QA pairs defined on documents from the popular Bentham manuscripts collection. We also present a thorough analysis of the proposed recognition-free approach compared to a recognition-based approach which uses text recognized from the images using an OCR. Datasets presented in this work are available to download at docvqa.org","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20708,""
"TopiOCQA: Open-domain Conversational Question Answeringwith Topic   Switching","['Vaibhav Adlakha', 'Shehzaad Dhuliawala', 'Kaheer Suleman', 'Harm de Vries', 'Siva Reddy']","https://export.arxiv.org/abs/2110.00768","2021-10-02","arXiv","cs.CL","In a conversational question answering scenario, a questioner seeks to extract information about a topic through a series of interdependent questions and answers. As the conversation progresses, they may switch to related topics, a phenomenon commonly observed in information-seeking search sessions. However, current datasets for conversational question answering are limiting in two ways: 1) they do not contain topic switches; and 2) they assume the reference text for the conversation is given, i.e., the setting is not open-domain. We introduce TopiOCQA (pronounced Tapioca), an open-domain conversational dataset with topic switches on Wikipedia. TopiOCQA contains 3,920 conversations with information-seeking questions and free-form answers. TopiOCQA poses a challenging test-bed for models, where efficient retrieval is required on multiple turns of the same conversation, in conjunction with constructing valid responses using conversational history. We evaluate several baselines, by combining state-of-the-art document retrieval methods with neural reader models. Our best models achieves F1 of 51.9, and BLEU score of 42.1 which falls short of human performance by 18.3 points and 17.6 points respectively, indicating the difficulty of our dataset. Our dataset and code will be available at https://mcgill-nlp.github.io/topiocqa","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20709,""
"Spatio-Temporal Video Representation Learning for AI Based Video   Playback Style Prediction","['Rishubh Parihar', 'Gaurav Ramola', 'Ranajit Saha', 'Ravi Kini', 'Aniket Rege', 'Sudha Velusamy']","https://export.arxiv.org/abs/2110.01015","2021-10-03","arXiv","cs.CV cs.AI cs.LG","Ever-increasing smartphone-generated video content demands intelligent techniques to edit and enhance videos on power-constrained devices. Most of the best performing algorithms for video understanding tasks like action recognition, localization, etc., rely heavily on rich spatio-temporal representations to make accurate predictions. For effective learning of the spatio-temporal representation, it is crucial to understand the underlying object motion patterns present in the video. In this paper, we propose a novel approach for understanding object motions via motion type classification. The proposed motion type classifier predicts a motion type for the video based on the trajectories of the objects present. Our classifier assigns a motion type for the given video from the following five primitive motion classes: linear, projectile, oscillatory, local and random. We demonstrate that the representations learned from the motion type classification generalizes well for the challenging downstream task of video retrieval. Further, we proposed a recommendation system for video playback style based on the motion type classifier predictions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20710,""
"Learning Structural Representations for Recipe Generation and Food   Retrieval","['Hao Wang', 'Guosheng Lin', 'Steven C. H. Hoi', 'Chunyan Miao']","https://export.arxiv.org/abs/2110.01209","2021-10-04","arXiv","cs.CV","Food is significant to human daily life. In this paper, we are interested in learning structural representations for lengthy recipes, that can benefit the recipe generation and food retrieval tasks. We mainly investigate an open research task of generating cooking instructions based on food images and ingredients, which is similar to the image captioning task. However, compared with image captioning datasets, the target recipes are lengthy paragraphs and do not have annotations on structure information. To address the above limitations, we propose a novel framework of Structure-aware Generation Network (SGN) to tackle the food recipe generation task. Our approach brings together several novel ideas in a systematic framework: (1) exploiting an unsupervised learning approach to obtain the sentence-level tree structure labels before training; (2) generating trees of target recipes from images with the supervision of tree structure labels learned from (1); and (3) integrating the inferred tree structures into the recipe generation procedure. Our proposed model can produce high-quality and coherent recipes, and achieve the state-of-the-art performance on the benchmark Recipe1M dataset. We also validate the usefulness of our learned tree structures in the food cross-modal retrieval task, where the proposed model with tree representations can outperform state-of-the-art benchmark results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20711,""
"A Survey On Neural Word Embeddings","['Erhan Sezerer', 'Selma Tekir']","https://export.arxiv.org/abs/2110.01804","2021-10-04","arXiv","cs.CL cs.AI cs.LG cs.NE","Understanding human language has been a sub-challenge on the way of intelligent machines. The study of meaning in natural language processing (NLP) relies on the distributional hypothesis where language elements get meaning from the words that co-occur within contexts. The revolutionary idea of distributed representation for a concept is close to the working of a human mind in that the meaning of a word is spread across several neurons, and a loss of activation will only slightly affect the memory retrieval process.   Neural word embeddings transformed the whole field of NLP by introducing substantial improvements in all NLP tasks. In this survey, we provide a comprehensive literature review on neural word embeddings. We give theoretical foundations and describe existing work by an interplay between word embeddings and language modelling. We provide broad coverage on neural word embeddings, including early word embeddings, embeddings targeting specific semantic relations, sense embeddings, morpheme embeddings, and finally, contextual representations. Finally, we describe benchmark datasets in word embeddings' performance evaluation and downstream tasks along with the performance results of/due to word embeddings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20712,""
"SDR: Efficient Neural Re-ranking using Succinct Document Representation","['Nachshon Cohen', 'Amit Portnoy', 'Besnik Fetahu', 'Amir Ingber']","https://export.arxiv.org/abs/2110.02065","2021-10-03","arXiv","cs.IR cs.LG","BERT based ranking models have achieved superior performance on various information retrieval tasks. However, the large number of parameters and complex self-attention operation come at a significant latency overhead. To remedy this, recent works propose late-interaction architectures, which allow pre-computation of intermediate document representations, thus reducing the runtime latency. Nonetheless, having solved the immediate latency issue, these methods now introduce storage costs and network fetching latency, which limits their adoption in real-life production systems.   In this work, we propose the Succinct Document Representation (SDR) scheme that computes highly compressed intermediate document representations, mitigating the storage/network issue. Our approach first reduces the dimension of token representations by encoding them using a novel autoencoder architecture that uses the document's textual content in both the encoding and decoding phases. After this token encoding step, we further reduce the size of entire document representations using a modern quantization technique.   Extensive evaluations on passage re-reranking on the MSMARCO dataset show that compared to existing approaches using compressed document representations, our method is highly efficient, achieving 4x-11.6x better compression rates for the same ranking quality.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20713,""
"Models for Narrative Information: A Study","['Udaya Varadarajan', 'Biswanath Dutta']","https://export.arxiv.org/abs/2110.02084","2021-09-23","arXiv","cs.DL cs.AI","The major objective of this work is to study and report the existing ontology-driven models for narrative information. The paper aims to analyze these models across various domains. The goal of this work is to bring the relevant literature, and ontology models under one umbrella, and perform a parametric comparative study. A systematic literature review methodology was adopted for an extensive literature selection. A random stratified sampling technique was used to select the models from the literature. The findings explicate a comparative view of the narrative models across domains. The differences and similarities of knowledge representation across domains, in case of narrative information models based on ontology was identified. There are significantly fewer studies that reviewed the ontology-based narrative models. This work goes a step further by evaluating the ontologies using the parameters from narrative components. This paper will explore the basic concepts and top-level concepts in the models. Besides, this study provides a comprehensive study of the narrative theories in the context of ongoing research. The findings of this work demonstrate the similarities and differences among the elements of the ontology across domains. It also identifies the state of the art literature for ontology-based narrative information.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20714,""
"Optimized Recommender Systems with Deep Reinforcement Learning","['Lucas Farris']","https://export.arxiv.org/abs/2110.03039","2021-10-06","arXiv","cs.IR cs.LG","Recommender Systems have been the cornerstone of online retailers. Traditionally they were based on rules, relevance scores, ranking algorithms, and supervised learning algorithms, but now it is feasible to use reinforcement learning algorithms to generate meaningful recommendations. This work investigates and develops means to setup a reproducible testbed, and evaluate different state of the art algorithms in a realistic environment. It entails a proposal, literature review, methodology, results, and comments.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20715,""
"GeSERA: General-domain Summary Evaluation by Relevance Analysis","['Jessica LÃ³pez Espejel', 'GaÃ«l de Chalendar', 'Jorge Garcia Flores', 'Thierry Charnois', 'Ivan Vladimir Meza Ruiz']","https://export.arxiv.org/abs/2110.03567","2021-10-07","arXiv","cs.CL cs.IR","We present GeSERA, an open-source improved version of SERA for evaluating automatic extractive and abstractive summaries from the general domain. SERA is based on a search engine that compares candidate and reference summaries (called queries) against an information retrieval document base (called index). SERA was originally designed for the biomedical domain only, where it showed a better correlation with manual methods than the widely used lexical-based ROUGE method. In this paper, we take out SERA from the biomedical domain to the general one by adapting its content-based method to successfully evaluate summaries from the general domain. First, we improve the query reformulation strategy with POS Tags analysis of general-domain corpora. Second, we replace the biomedical index used in SERA with two article collections from AQUAINT-2 and Wikipedia. We conduct experiments with TAC2008, TAC2009, and CNNDM datasets. Results show that, in most cases, GeSERA achieves higher correlations with manual evaluation methods than SERA, while it reduces its gap with ROUGE for general-domain summary evaluation. GeSERA even surpasses ROUGE in two cases of TAC2009. Finally, we conduct extensive experiments and provide a comprehensive study of the impact of human annotators and the index size on summary evaluation with SERA and GeSERA.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20716,""
"Quantifying the Suicidal Tendency on Social Media: A Survey","['Muskan Garg']","https://export.arxiv.org/abs/2110.03663","2021-10-04","arXiv","cs.SI cs.CL cs.IR","Amid lockdown period more people express their feelings over social media platforms due to closed third-place and academic researchers have witnessed strong associations between the mental healthcare and social media posts. The stress for a brief period may lead to clinical depressions and the long-lasting traits of prevailing depressions can be life threatening with suicidal ideation as the possible outcome. The increasing concern towards the rise in number of suicide cases is because it is one of the leading cause of premature but preventable death. Recent studies have shown that mining social media data has helped in quantifying the suicidal tendency of users at risk. This potential manuscript elucidates the taxonomy of mental healthcare and highlights some recent attempts in examining the potential of quantifying suicidal tendency on social media data. This manuscript presents the classification of heterogeneous features from social media data and handling feature vector representation. Aiming to identify the new research directions and advances in the development of Machine Learning (ML) and Deep Learning (DL) based models, a quantitative synthesis and a qualitative review was carried out with corpus of over 77 potential research articles related to stress, depression and suicide risk from 2013 to 2021.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20717,""
"A Mining Software Repository Extended Cookbook: Lessons learned from a   literature review","['Daniel Barros', 'Flavio Horita', 'Igor Wiese', 'Kanan Silva']","https://export.arxiv.org/abs/2110.04095","2021-10-08","arXiv","cs.SE cs.AI","The main purpose of Mining Software Repositories (MSR) is to discover the latest enhancements and provide an insight into how to make improvements in a software project. In light of it, this paper updates the MSR findings of the original MSR Cookbook, by first conducting a systematic mapping study to elicit and analyze the state-of-the-art, and then proposing an extended version of the Cookbook. This extended Cookbook was built on four high-level themes, which were derived from the analysis of a list of 112 selected studies. Hence, it was used to consolidate the extended Cookbook as a contribution to practice and research in the following areas by: 1) including studies published in all available and relevant publication venues; 2) including and updating recommendations in all four high-level themes, with an increase of 84% in comments in this study when compared with the original MSR Cookbook; 3) summarizing the tools employed for each high-level theme; and 4) providing lessons learned for future studies. Thus, the extended Cookbook examined in this work can support new research projects, as upgraded recommendations and the lessons learned are available with the aid of samples and tools.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20718,""
"Human Factors Considerations in Satellite Operation's Human-Computer   Interaction Technologies: A Review of Current Applications and Theory","['David G. I. Heinrich', 'Ian McAndrew', 'Jeremy Pretty']","https://export.arxiv.org/abs/2110.04880","2021-10-10","arXiv","cs.HC","Satellite operations are a subset of remote operations that draw similarities with remotely piloted aircraft (RPA) and uncrewed aerial vehicle (UAV) operations. Increased research into boredom, complacency, habituation, and vigilance as they relate to satellite operations is required due to a lack of prevalence in the literature. Circadian rhythms, crew resource management, and shift work dynamics may exacerbate complacency-driven automation bias and social loafing errors in satellite operations. This overview of theory and applications aims to specifically focus on satellite operations literature within human factors research to identify areas requiring an expansion of knowledge. The human-in-the-loop commonality enables human factors lessons to be passed to satellite operations from unrelated sectors to mitigate catastrophic human error potentially. As such, this literature review details the need for increased research in satellite operations human factors.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20719,""
"Pre-trained Language Models in Biomedical Domain: A Systematic Survey","['Benyou Wang', 'Qianqian Xie', 'Jiahuan Pei', 'Prayag Tiwari', 'Zhao Li', 'Jie fu']","https://export.arxiv.org/abs/2110.05006","2021-10-11","arXiv","cs.CL","Pre-trained language models (PLMs) have been the de facto paradigm for most natural language processing (NLP) tasks. This also benefits biomedical domain: researchers from informatics, medicine, and computer science (CS) communities propose various PLMs trained on biomedical datasets, e.g., biomedical text, electronic health records, protein, and DNA sequences for various biomedical tasks. However, the cross-discipline characteristics of biomedical PLMs hinder their spreading among communities; some existing works are isolated from each other without comprehensive comparison and discussions. It expects a survey that not only systematically reviews recent advances of biomedical PLMs and their applications but also standardizes terminology and benchmarks. In this paper, we summarize the recent progress of pre-trained language models in the biomedical domain and their applications in biomedical downstream tasks. Particularly, we discuss the motivations and propose a taxonomy of existing biomedical PLMs. Their applications in biomedical downstream tasks are exhaustively discussed. At last, we illustrate various limitations and future trends, which we hope can provide inspiration for the future research of the research community.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20720,""
"Deep Video Anomaly Detection: Opportunities and Challenges","['Jing Ren', 'Feng Xia', 'Yemeng Liu', 'Ivan Lee']","https://export.arxiv.org/abs/2110.05086","2021-10-11","arXiv","cs.CV cs.SI","Anomaly detection is a popular and vital task in various research contexts, which has been studied for several decades. To ensure the safety of people's lives and assets, video surveillance has been widely deployed in various public spaces, such as crossroads, elevators, hospitals, banks, and even in private homes. Deep learning has shown its capacity in a number of domains, ranging from acoustics, images, to natural language processing. However, it is non-trivial to devise intelligent video anomaly detection systems cause anomalies significantly differ from each other in different application scenarios. There are numerous advantages if such intelligent systems could be realised in our daily lives, such as saving human resources in a large degree, reducing financial burden on the government, and identifying the anomalous behaviours timely and accurately. Recently, many studies on extending deep learning models for solving anomaly detection problems have emerged, resulting in beneficial advances in deep video anomaly detection techniques. In this paper, we present a comprehensive review of deep learning-based methods to detect the video anomalies from a new perspective. Specifically, we summarise the opportunities and challenges of deep learning models on video anomaly detection tasks, respectively. We put forth several potential future research directions of intelligent video anomaly detection system in various application domains. Moreover, we summarise the characteristics and technical problems in current deep learning methods for video anomaly detection.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20721,""
"Artificial Intelligence in Electric Machine Drives: Advances and Trends","['Shen Zhang']","https://export.arxiv.org/abs/2110.05403","2021-10-11","arXiv","eess.SY cs.AI cs.SY","This review paper systematically summarizes the existing literature on applying classical AI techniques and advanced deep learning algorithms to electric machine drives. It is anticipated that with the rapid progress in deep learning models and embedded hardware platforms, AI-based data-driven approaches will become increasingly popular for the automated high-performance control of electric machines. Additionally, this paper also provides some outlook towards promoting its widespread application in the industry, such as implementing advanced RL algorithms with good domain adaptation and transfer learning capabilities and deploying them onto low-cost SoC FPGA devices.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20722,""
"An In-depth Summary of Recent Artificial Intelligence Applications in   Drug Design","['Yi Zhang']","https://export.arxiv.org/abs/2110.05478","2021-10-09","arXiv","q-bio.QM cs.AI cs.LG","As a promising tool to navigate in the vast chemical space, artificial intelligence (AI) is leveraged for drug design. From the year 2017 to 2021, the number of applications of several recent AI models (i.e. graph neural network (GNN), recurrent neural network (RNN), variation autoencoder (VAE), generative adversarial network (GAN), flow and reinforcement learning (RL)) in drug design increases significantly. Many relevant literature reviews exist. However, none of them provides an in-depth summary of many applications of the recent AI models in drug design. To complement the existing literature, this survey includes the theoretical development of the previously mentioned AI models and detailed summaries of 42 recent applications of AI in drug design. Concretely, 13 of them leverage GNN for molecular property prediction and 29 of them use RL and/or deep generative models for molecule generation and optimization. In most cases, the focus of the summary is the models, their variants, and modifications for specific tasks in drug design. Moreover, 60 additional applications of AI in molecule generation and optimization are briefly summarized in a table. Finally, this survey provides a holistic discussion of the abundant applications so that the tasks, potential solutions, and challenges in AI-based drug design become evident.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20723,""
"A Taxonomy and Archetypes of Business Analytics in Smart Manufacturing","['Jonas Wanner', 'Christopher Wissuchek', 'Giacomo Welsch', 'Christian Janiesch']","https://export.arxiv.org/abs/2110.06124","2021-10-12","arXiv","cs.CY","Fueled by increasing data availability and the rise of technological advances for data processing and communication, business analytics is a key driver for smart manufacturing. However, due to the multitude of different local advances as well as its multidisciplinary complexity, both researchers and practitioners struggle to keep track of the progress and acquire new knowledge within the field, as there is a lack of a holistic conceptualization. To address this issue, we performed an extensive structured literature review, yielding 904 relevant hits, to develop a quadripartite taxonomy as well as to derive archetypes of business analytics in smart manufacturing. The taxonomy comprises the following meta-characteristics: application domain, orientation as the objective of the analysis, data origins, and analysis techniques. Collectively, they comprise eight dimensions with a total of 52 distinct characteristics. Using a cluster analysis, we found six archetypes that represent a synthesis of existing knowledge on planning, maintenance (reactive, offline, and online predictive), monitoring, and quality management. A temporal analysis highlights the push beyond predictive approaches and confirms that deep learning already dominates novel applications. Our results constitute an entry point to the field but can also serve as a reference work and a guide with which to assess the adequacy of one's own instruments.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20724,""
"A comprehensive review of Binary Neural Network","['Chunyu Yuan', 'Sos S. Agaian']","https://export.arxiv.org/abs/2110.06804","2021-10-11","arXiv","cs.NE cs.AI cs.CV cs.PF","Binary Neural Network (BNN) method is an extreme application of convolutional neural network (CNN) parameter quantization. As opposed to the original CNN methods which employed floating-point computation with full-precision weights and activations, BBN uses 1-bit activations and weights. With BBNs, a significant amount of storage, network complexity and energy consumption can be reduced, and neural networks can be implemented more efficiently in embedded applications. Unfortunately, binarization causes severe information loss. A gap still exists between full-precision CNN models and their binarized counterparts. The recent developments in BNN have led to a lot of algorithms and solutions that have helped address this issue. This article provides a full overview of recent developments in BNN. The present paper focuses exclusively on 1-bit activations and weights networks, as opposed to previous surveys in which low-bit works are mixed in. In this paper, we conduct a complete investigation of BNN's development from their predecessors to the latest BNN algorithms and techniques, presenting a broad design pipeline, and discussing each module's variants. Along the way, this paper examines BNN (a) purpose: their early successes and challenges; (b) BNN optimization: selected representative works that contain key optimization techniques; (c) deployment: open-source frameworks for BNN modeling and development; (d) terminal: efficient computing architectures and devices for BNN and (e) applications: diverse applications with BNN. Moreover, this paper discusses potential directions and future research opportunities for the latest BNN algorithms and techniques, presents a broad design pipeline, and discusses each module's variants.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20725,""
"Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a   Sparse One?","['Xilun Chen', 'Kushal Lakhotia', 'Barlas Oguz', 'Anchit Gupta', 'Patrick Lewis', 'Stan Peshterliev', 'Yashar Mehdad', 'Sonal Gupta', 'Wen-tau Yih']","https://export.arxiv.org/abs/2110.06918","2021-10-13","arXiv","cs.CL cs.IR cs.LG","Despite their recent popularity and well known advantages, dense retrievers still lag behind sparse methods such as BM25 in their ability to reliably match salient phrases and rare entities in the query. It has been argued that this is an inherent limitation of dense models. We disprove this claim by introducing the Salient Phrase Aware Retriever (SPAR), a dense retriever with the lexical matching capacity of a sparse model. In particular, we show that a dense retriever {\Lambda} can be trained to imitate a sparse one, and SPAR is built by augmenting a standard dense retriever with {\Lambda}. When evaluated on five open-domain question answering datasets and the MS MARCO passage retrieval task, SPAR sets a new state of the art for dense and sparse retrievers and can match or exceed the performance of more complicated dense-sparse hybrid systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20726,""
"Human-Robot Collaboration and Machine Learning: A Systematic Review of   Recent Research","['Francesco Semeraro', 'Alexander Griffiths', 'Angelo Cangelosi']","https://export.arxiv.org/abs/2110.07448","2021-10-14","arXiv","cs.RO cs.LG","Technological progress increasingly envisions the use of robots interacting with people in everyday life. Human-robot collaboration (HRC) is the approach that explores the interaction between a human and a robot, during the completion of an actual physical task. Such interplay is explored both at the cognitive and physical level, by respectively analysing the mutual exchange of information and mechanical power. In HRC works, a cognitive model is typically built, which collects inputs from the environment and from the user, elaborates and translates these into information that can be used by the robot itself. HRC studies progressively employ machine learning algorithms to build the cognitive models and behavioural block that elaborates the acquired external inputs. This is a promising approach still in its early stages and with the potential of significant benefit from the growing field of machine learning. Consequently, this paper proposes a thorough literature review of the use of machine learning techniques in the context of human-robot collaboration. The collection,selection and analysis of the set of 45 key papers, selected from the wide review of the literature on robotics and machine learning, allowed the identification of the current trends in HRC. In particular, a clustering of works based on the type of collaborative tasks, evaluation metrics and cognitive variables modelled is proposed. With these premises, a deep analysis on different families of machine learning algorithms and their properties, along with the sensing modalities used, was carried out. The salient aspects of the analysis are discussed to show trends and suggest possible challenges to tackle in the future research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20727,""
"Spoken ObjectNet: A Bias-Controlled Spoken Caption Dataset","['Ian Palmer', 'Andrew Rouditchenko', 'Andrei Barbu', 'Boris Katz', 'James Glass']","https://export.arxiv.org/abs/2110.07575","2021-10-14","arXiv","cs.CL cs.CV cs.MM eess.AS","Visually-grounded spoken language datasets can enable models to learn cross-modal correspondences with very weak supervision. However, modern audio-visual datasets contain biases that undermine the real-world performance of models trained on that data. We introduce Spoken ObjectNet, which is designed to remove some of these biases and provide a way to better evaluate how effectively models will perform in real-world scenarios. This dataset expands upon ObjectNet, which is a bias-controlled image dataset that features similar image classes to those present in ImageNet. We detail our data collection pipeline, which features several methods to improve caption quality, including automated language model checks. Lastly, we show baseline results on image retrieval and audio retrieval tasks. These results show that models trained on other datasets and then evaluated on Spoken ObjectNet tend to perform poorly due to biases in other datasets that the models have learned. We also show evidence that the performance decrease is due to the dataset controls, and not the transfer setting.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20728,""
"PolyNet: Polynomial Neural Network for 3D Shape Recognition with   PolyShape Representation","['Mohsen Yavartanoo', 'Shih-Hsuan Hung', 'Reyhaneh Neshatavar', 'Yue Zhang', 'Kyoung Mu Lee']","https://export.arxiv.org/abs/2110.07882","2021-10-15","arXiv","cs.CV","3D shape representation and its processing have substantial effects on 3D shape recognition. The polygon mesh as a 3D shape representation has many advantages in computer graphics and geometry processing. However, there are still some challenges for the existing deep neural network (DNN)-based methods on polygon mesh representation, such as handling the variations in the degree and permutations of the vertices and their pairwise distances. To overcome these challenges, we propose a DNN-based method (PolyNet) and a specific polygon mesh representation (PolyShape) with a multi-resolution structure. PolyNet contains two operations; (1) a polynomial convolution (PolyConv) operation with learnable coefficients, which learns continuous distributions as the convolutional filters to share the weights across different vertices, and (2) a polygonal pooling (PolyPool) procedure by utilizing the multi-resolution structure of PolyShape to aggregate the features in a much lower dimension. Our experiments demonstrate the strength and the advantages of PolyNet on both 3D shape classification and retrieval tasks compared to existing polygon mesh-based methods and its superiority in classifying graph representations of images. The code is publicly available from https://myavartanoo.github.io/polynet/.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20729,""
"Few-Shot Bot: Prompt-Based Learning for Dialogue Systems","['Andrea Madotto', 'Zhaojiang Lin', 'Genta Indra Winata', 'Pascale Fung']","https://export.arxiv.org/abs/2110.08118","2021-10-15","arXiv","cs.CL cs.AI","Learning to converse using only a few examples is a great challenge in conversational AI. The current best conversational models, which are either good chit-chatters (e.g., BlenderBot) or goal-oriented systems (e.g., MinTL), are language models (LMs) fine-tuned on large conversational datasets. Training these models is expensive, both in terms of computational resources and time, and it is hard to keep them up to date with new conversational skills. A simple yet unexplored solution is prompt-based few-shot learning (Brown et al. 2020) which does not require gradient-based fine-tuning but instead uses a few examples in the LM context as the only source of learning. In this paper, we explore prompt-based few-shot learning in dialogue tasks. We benchmark LMs of different sizes in nine response generation tasks, which include four knowledge-grounded tasks, a task-oriented generations task, three open-chat tasks, and controlled stylistic generation, and five conversational parsing tasks, which include dialogue state tracking, graph path generation, persona information extraction, document retrieval, and internet query generation. The current largest released LM (GPT-J-6B) using prompt-based few-shot learning, and thus requiring no training, achieves competitive performance to fully trained state-of-the-art models. Moreover, we propose a novel prompt-based few-shot classifier, that also does not require any fine-tuning, to select the most appropriate prompt given a dialogue history. Finally, by combining the power of prompt-based few-shot learning and a Skill Selector, we create an end-to-end chatbot named the Few-Shot Bot (FSB), which automatically selects the most appropriate conversational skill, queries different knowledge bases or the internet, and uses the retrieved knowledge to generate a human-like response, all using only few dialogue examples per skill.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20730,""
"Finding Critical Scenarios for Automated Driving Systems: A Systematic   Literature Review","['Xinhai Zhang', 'Jianbo Tao', 'Kaige Tan', 'Martin TÃ¶rngren', 'JosÃ© Manuel Gaspar SÃ¡nchez', 'Muhammad Rusyadi Ramli', 'Xin Tao', 'Magnus Gyllenhammar', 'Franz Wotawa', 'Naveen Mohan', 'Mihai Nica', 'Hermann Felbinger']","https://export.arxiv.org/abs/2110.08664","2021-10-16","arXiv","cs.SE cs.AI cs.SY eess.SY","Scenario-based approaches have been receiving a huge amount of attention in research and engineering of automated driving systems. Due to the complexity and uncertainty of the driving environment, and the complexity of the driving task itself, the number of possible driving scenarios that an ADS or ADAS may encounter is virtually infinite. Therefore it is essential to be able to reason about the identification of scenarios and in particular critical ones that may impose unacceptable risk if not considered. Critical scenarios are particularly important to support design, verification and validation efforts, and as a basis for a safety case. In this paper, we present the results of a systematic literature review in the context of autonomous driving. The main contributions are: (i) introducing a comprehensive taxonomy for critical scenario identification methods; (ii) giving an overview of the state-of-the-art research based on the taxonomy encompassing 86 papers between 2017 and 2020; and (iii) identifying open issues and directions for further research. The provided taxonomy comprises three main perspectives encompassing the problem definition (the why), the solution (the methods to derive scenarios), and the assessment of the established scenarios. In addition, we discuss open research issues considering the perspectives of coverage, practicability, and scenario space explosion.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20731,""
"Low-Precision Quantization for Efficient Nearest Neighbor Search","['Anthony Ko', 'Iman Keivanloo', 'Vihan Lakshman', 'Eric Schkufza']","https://export.arxiv.org/abs/2110.08919","2021-10-17","arXiv","cs.IR cs.DB","Fast k-Nearest Neighbor search over real-valued vector spaces (KNN) is an important algorithmic task for information retrieval and recommendation systems. We present a method for using reduced precision to represent vectors through quantized integer values, enabling both a reduction in the memory overhead of indexing these vectors and faster distance computations at query time. While most traditional quantization techniques focus on minimizing the reconstruction error between a point and its uncompressed counterpart, we focus instead on preserving the behavior of the underlying distance metric. Furthermore, our quantization approach is applied at the implementation level and can be combined with existing KNN algorithms. Our experiments on both open source and proprietary datasets across multiple popular KNN frameworks validate that quantized distance metrics can reduce memory by 60% and improve query throughput by 30%, while incurring only a 2% reduction in recall.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20732,""
"A Sociotechnical View of Algorithmic Fairness","['Mateusz Dolata', 'Stefan Feuerriegel', 'Gerhard Schwabe']","https://export.arxiv.org/abs/2110.09253","2021-09-27","arXiv","cs.CY cs.LG stat.ML","Algorithmic fairness has been framed as a newly emerging technology that mitigates systemic discrimination in automated decision-making, providing opportunities to improve fairness in information systems (IS). However, based on a state-of-the-art literature review, we argue that fairness is an inherently social concept and that technologies for algorithmic fairness should therefore be approached through a sociotechnical lens. We advance the discourse on algorithmic fairness as a sociotechnical phenomenon. Our research objective is to embed AF in the sociotechnical view of IS. Specifically, we elaborate on why outcomes of a system that uses algorithmic means to assure fairness depends on mutual influences between technical and social structures. This perspective can generate new insights that integrate knowledge from both technical fields and social studies. Further, it spurs new directions for IS debates. We contribute as follows: First, we problematize fundamental assumptions in the current discourse on algorithmic fairness based on a systematic analysis of 310 articles. Second, we respond to these assumptions by theorizing algorithmic fairness as a sociotechnical construct. Third, we propose directions for IS researchers to enhance their impacts by pursuing a unique understanding of sociotechnical algorithmic fairness. We call for and undertake a holistic approach to AF. A sociotechnical perspective on algorithmic fairness can yield holistic solutions to systemic biases and discrimination.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20733,""
"Carbon Neutrality in Data Center","['Zhiwei Cao', 'Xin Zhou', 'Han Hu', 'Zhi Wang', 'Yonggang Wen']","https://export.arxiv.org/abs/2110.09284","2021-10-15","arXiv","cs.CY","Data centers are carbon-intensive enterprises due to their massive energy consumption, and it is estimated that data center industry will account for 8\% of global carbon emissions by 2030. However, both technological and policy instruments for reducing or even neutralizing data center carbon emissions have not been thoroughly investigated. To bridge this gap, this survey paper proposes a roadmap towards carbon-neutral data centers that takes into account both policy instruments and technological methodologies. We begin by presenting the carbon footprint of data centers, as well as some insights into the major sources of carbon emissions. Following that, carbon neutrality plans for major global cloud providers are discussed to summarize current industrial efforts in this direction. In what follows, we introduce the carbon market as a policy instrument to explain how to offset data center carbon emissions in a cost-efficient manner. On the technological front, we propose achieving carbon-neutral data centers by increasing renewable energy penetration, improving energy efficiency, and boosting energy circulation simultaneously. A comprehensive review of existing technologies on these three topics is elaborated subsequently. Based on this, a multi-pronged approach towards carbon neutrality is envisioned and a digital twin-powered industrial artificial intelligence (AI) framework is proposed to make this solution a reality. Furthermore, three key scientific challenges for putting such a framework in place are discussed. Finally, several applications for this framework are presented to demonstrate its enormous potential.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20734,""
"Clinical Trial Information Extraction with BERT","['Xiong Liu', 'Greg L. Hersch', 'Iya Khalil', 'Murthy Devarakonda']","https://export.arxiv.org/abs/2110.10027","2021-09-11","arXiv","q-bio.QM cs.CL cs.LG","Natural language processing (NLP) of clinical trial documents can be useful in new trial design. Here we identify entity types relevant to clinical trial design and propose a framework called CT-BERT for information extraction from clinical trial text. We trained named entity recognition (NER) models to extract eligibility criteria entities by fine-tuning a set of pre-trained BERT models. We then compared the performance of CT-BERT with recent baseline methods including attention-based BiLSTM and Criteria2Query. The results demonstrate the superiority of CT-BERT in clinical trial NLP.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20735,""
"Interpreting Deep Learning Models in Natural Language Processing: A   Review","['Xiaofei Sun', 'Diyi Yang', 'Xiaoya Li', 'Tianwei Zhang', 'Yuxian Meng', 'Han Qiu', 'Guoyin Wang', 'Eduard Hovy', 'Jiwei Li']","https://export.arxiv.org/abs/2110.10470","2021-10-20","arXiv","cs.CL","Neural network models have achieved state-of-the-art performances in a wide range of natural language processing (NLP) tasks. However, a long-standing criticism against neural network models is the lack of interpretability, which not only reduces the reliability of neural NLP systems but also limits the scope of their applications in areas where interpretability is essential (e.g., health care applications). In response, the increasing interest in interpreting neural NLP models has spurred a diverse array of interpretation methods over recent years. In this survey, we provide a comprehensive review of various interpretation methods for neural models in NLP. We first stretch out a high-level taxonomy for interpretation methods in NLP, i.e., training-based approaches, test-based approaches, and hybrid approaches. Next, we describe sub-categories in each category in detail, e.g., influence-function based methods, KNN-based methods, attention-based models, saliency-based methods, perturbation-based methods, etc. We point out deficiencies of current methods and suggest some avenues for future research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20736,""
"Text-Based Person Search with Limited Data","['Xiao Han', 'Sen He', 'Li Zhang', 'Tao Xiang']","https://export.arxiv.org/abs/2110.10807","2021-10-20","arXiv","cs.CV","Text-based person search (TBPS) aims at retrieving a target person from an image gallery with a descriptive text query. Solving such a fine-grained cross-modal retrieval task is challenging, which is further hampered by the lack of large-scale datasets. In this paper, we present a framework with two novel components to handle the problems brought by limited data. Firstly, to fully utilize the existing small-scale benchmarking datasets for more discriminative feature learning, we introduce a cross-modal momentum contrastive learning framework to enrich the training data for a given mini-batch. Secondly, we propose to transfer knowledge learned from existing coarse-grained large-scale datasets containing image-text pairs from drastically different problem domains to compensate for the lack of TBPS training data. A transfer learning method is designed so that useful information can be transferred despite the large domain gap. Armed with these components, our method achieves new state of the art on the CUHK-PEDES dataset with significant improvements over the prior art in terms of Rank-1 and mAP. Our code is available at https://github.com/BrandonHanx/TextReID.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20737,""
"A Systematic Review on the Detection of Fake News Articles","['Nathaniel Hoy', 'Theodora Koulouri']","https://export.arxiv.org/abs/2110.11240","2021-10-18","arXiv","cs.CL cs.AI cs.LG","It has been argued that fake news and the spread of false information pose a threat to societies throughout the world, from influencing the results of elections to hindering the efforts to manage the COVID-19 pandemic. To combat this threat, a number of Natural Language Processing (NLP) approaches have been developed. These leverage a number of datasets, feature extraction/selection techniques and machine learning (ML) algorithms to detect fake news before it spreads. While these methods are well-documented, there is less evidence regarding their efficacy in this domain. By systematically reviewing the literature, this paper aims to delineate the approaches for fake news detection that are most performant, identify limitations with existing approaches, and suggest ways these can be mitigated. The analysis of the results indicates that Ensemble Methods using a combination of news content and socially-based features are currently the most effective. Finally, it is proposed that future research should focus on developing approaches that address generalisability issues (which, in part, arise from limitations with current datasets), explainability and bias.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20738,""
"Multimodal Semi-Supervised Learning for 3D Objects","['Zhimin Chen', 'Longlong Jing', 'Yang Liang', 'YingLi Tian', 'Bing Li']","https://export.arxiv.org/abs/2110.11601","2021-10-22","arXiv","cs.CV","In recent years, semi-supervised learning has been widely explored and shows excellent data efficiency for 2D data. There is an emerging need to improve data efficiency for 3D tasks due to the scarcity of labeled 3D data. This paper explores how the coherence of different modelities of 3D data (e.g. point cloud, image, and mesh) can be used to improve data efficiency for both 3D classification and retrieval tasks. We propose a novel multimodal semi-supervised learning framework by introducing instance-level consistency constraint and a novel multimodal contrastive prototype (M2CP) loss. The instance-level consistency enforces the network to generate consistent representations for multimodal data of the same object regardless of its modality. The M2CP maintains a multimodal prototype for each class and learns features with small intra-class variations by minimizing the feature distance of each object to its prototype while maximizing the distance to the others. Our proposed framework significantly outperforms all the state-of-the-art counterparts for both classification and retrieval tasks by a large margin on the modelNet10 and ModelNet40 datasets.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20739,""
"A Comprehensive Survey of Logging in Software: From Logging Statements   Automation to Log Mining and Analysis","['Sina Gholamian', 'Paul A. S. Ward']","https://export.arxiv.org/abs/2110.12489","2021-10-24","arXiv","cs.SE cs.LG","Logs are widely used to record runtime information of software systems, such as the timestamp and the importance of an event, the unique ID of the source of the log, and a part of the state of a task's execution. The rich information of logs enables system developers (and operators) to monitor the runtime behaviors of their systems and further track down system problems and perform analysis on log data in production settings. However, the prior research on utilizing logs is scattered and that limits the ability of new researchers in this field to quickly get to the speed and hampers currently active researchers to advance this field further. Therefore, this paper surveys and provides a systematic literature review of the contemporary logging practices and log statements' mining and monitoring techniques and their applications such as in system failure detection and diagnosis. We study a large number of conference and journal papers that appeared on top-level peer-reviewed venues. Additionally, we draw high-level trends of ongoing research and categorize publications into subdivisions. In the end, and based on our holistic observations during this survey, we provide a set of challenges and opportunities that will lead the researchers in academia and industry in moving the field forward.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20740,""
"Normative Epistemology for Lethal Autonomous Weapons Systems","['Susannah Kate Devitt']","https://export.arxiv.org/abs/2110.12935","2021-10-25","arXiv","cs.HC cs.AI","The rise of human-information systems, cybernetic systems, and increasingly autonomous systems requires the application of epistemic frameworks to machines and human-machine teams. This chapter discusses higher-order design principles to guide the design, evaluation, deployment, and iteration of Lethal Autonomous Weapons Systems (LAWS) based on epistemic models. Epistemology is the study of knowledge. Epistemic models consider the role of accuracy, likelihoods, beliefs, competencies, capabilities, context, and luck in the justification of actions and the attribution of knowledge. The aim is not to provide ethical justification for or against LAWS, but to illustrate how epistemological frameworks can be used in conjunction with moral apparatus to guide the design and deployment of future systems. The models discussed in this chapter aim to make Article 36 reviews of LAWS systematic, expedient, and evaluable. A Bayesian virtue epistemology is proposed to enable justified actions under uncertainty that meet the requirements of the Laws of Armed Conflict and International Humanitarian Law. Epistemic concepts can provide some of the apparatus to meet explainability and transparency requirements in the development, evaluation, deployment, and review of ethical AI.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20741,""
"Adversarial Attacks and Defenses for Social Network Text Processing   Applications: Techniques, Challenges and Future Research Directions","['Izzat Alsmadi', 'Kashif Ahmad', 'Mahmoud Nazzal', 'Firoj Alam', 'Ala Al-Fuqaha', 'Abdallah Khreishah', 'Abdulelah Algosaibi']","https://export.arxiv.org/abs/2110.13980","2021-10-26","arXiv","cs.CL","The growing use of social media has led to the development of several Machine Learning (ML) and Natural Language Processing(NLP) tools to process the unprecedented amount of social media content to make actionable decisions. However, these MLand NLP algorithms have been widely shown to be vulnerable to adversarial attacks. These vulnerabilities allow adversaries to launch a diversified set of adversarial attacks on these algorithms in different applications of social media text processing. In this paper, we provide a comprehensive review of the main approaches for adversarial attacks and defenses in the context of social media applications with a particular focus on key challenges and future research directions. In detail, we cover literature on six key applications, namely (i) rumors detection, (ii) satires detection, (iii) clickbait & spams identification, (iv) hate speech detection, (v)misinformation detection, and (vi) sentiment analysis. We then highlight the concurrent and anticipated future research questions and provide recommendations and directions for future work.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20742,""
"A Unified Survey on Anomaly, Novelty, Open-Set, and Out-of-Distribution   Detection: Solutions and Future Challenges","['Mohammadreza Salehi', 'Hossein Mirzaei', 'Dan Hendrycks', 'Yixuan Li', 'Mohammad Hossein Rohban', 'Mohammad Sabokrou']","https://export.arxiv.org/abs/2110.14051","2021-10-26","arXiv","cs.CV cs.LG","Machine learning models often encounter samples that are diverged from the training distribution. Failure to recognize an out-of-distribution (OOD) sample, and consequently assign that sample to an in-class label significantly compromises the reliability of a model. The problem has gained significant attention due to its importance for safety deploying models in open-world settings. Detecting OOD samples is challenging due to the intractability of modeling all possible unknown distributions. To date, several research domains tackle the problem of detecting unfamiliar samples, including anomaly detection, novelty detection, one-class learning, open set recognition, and out-of-distribution detection. Despite having similar and shared concepts, out-of-distribution, open-set, and anomaly detection have been investigated independently. Accordingly, these research avenues have not cross-pollinated, creating research barriers. While some surveys intend to provide an overview of these approaches, they seem to only focus on a specific domain without examining the relationship between different domains. This survey aims to provide a cross-domain and comprehensive review of numerous eminent works in respective areas while identifying their commonalities. Researchers can benefit from the overview of research advances in different fields and develop future methodology synergistically. Furthermore, to the best of our knowledge, while there are surveys in anomaly detection or one-class learning, there is no comprehensive or up-to-date survey on out-of-distribution detection, which our survey covers extensively. Finally, having a unified cross-domain perspective, we discuss and shed light on future lines of research, intending to bring these fields closer together.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20743,""
"Abstract, Rationale, Stance: A Joint Model for Scientific Claim   Verification","['Zhiwei Zhang', 'Jiyi Li', 'Fumiyo Fukumoto', 'Yanming Ye']","https://export.arxiv.org/abs/2110.15116","2021-09-13","arXiv","cs.CL","Scientific claim verification can help the researchers to easily find the target scientific papers with the sentence evidence from a large corpus for the given claim. Some existing works propose pipeline models on the three tasks of abstract retrieval, rationale selection and stance prediction. Such works have the problems of error propagation among the modules in the pipeline and lack of sharing valuable information among modules. We thus propose an approach, named as ARSJoint, that jointly learns the modules for the three tasks with a machine reading comprehension framework by including claim information. In addition, we enhance the information exchanges and constraints among tasks by proposing a regularization term between the sentence attention scores of abstract retrieval and the estimated outputs of rational selection. The experimental results on the benchmark dataset SciFact show that our approach outperforms the existing works.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20744,""
"Multi-stage Clarification in Conversational AI: The case of   Question-Answering Dialogue Systems","['Hadrien Lautraite', 'Nada Naji', 'Louis Marceau', 'Marc Queudot', 'Eric Charton']","https://export.arxiv.org/abs/2110.15235","2021-10-28","arXiv","cs.CL","Clarification resolution plays an important role in various information retrieval tasks such as interactive question answering and conversational search. In such context, the user often formulates their information needs as short and ambiguous queries, some popular search interfaces then prompt the user to confirm her intent (e.g. ""Did you mean ... ?"") or to rephrase if needed. When it comes to dialogue systems, having fluid user-bot exchanges is key to good user experience. In the absence of such clarification mechanism, one of the following responses is given to the user: 1) A direct answer, which can potentially be non-relevant if the intent was not clear, 2) a generic fallback message informing the user that the retrieval tool is incapable of handling the query. Both scenarios might raise frustration and degrade the user experience. To this end, we propose a multi-stage clarification mechanism for prompting clarification and query selection in the context of a question answering dialogue system. We show that our proposed mechanism improves the overall user experience and outperforms competitive baselines with two datasets, namely the public in-scope out-of-scope dataset and a commercial dataset based on real user logs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20745,""
"Dense Hierarchical Retrieval for Open-Domain Question Answering","['Ye Liu', 'Kazuma Hashimoto', 'Yingbo Zhou', 'Semih Yavuz', 'Caiming Xiong', 'Philip S. Yu']","https://export.arxiv.org/abs/2110.15439","2021-10-28","arXiv","cs.IR","Dense neural text retrieval has achieved promising results on open-domain Question Answering (QA), where latent representations of questions and passages are exploited for maximum inner product search in the retrieval process. However, current dense retrievers require splitting documents into short passages that usually contain local, partial, and sometimes biased context, and highly depend on the splitting process. As a consequence, it may yield inaccurate and misleading hidden representations, thus deteriorating the final retrieval result. In this work, we propose Dense Hierarchical Retrieval (DHR), a hierarchical framework that can generate accurate dense representations of passages by utilizing both macroscopic semantics in the document and microscopic semantics specific to each passage. Specifically, a document-level retriever first identifies relevant documents, among which relevant passages are then retrieved by a passage-level retriever. The ranking of the retrieved passages will be further calibrated by examining the document-level relevance. In addition, hierarchical title structure and two negative sampling strategies (i.e., In-Doc and In-Sec negatives) are investigated. We apply DHR to large-scale open-domain QA datasets. DHR significantly outperforms the original dense passage retriever and helps an end-to-end QA system outperform the strong baselines on multiple open-domain QA benchmarks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20746,""
"Visual Spatio-temporal Relation-enhanced Network for Cross-modal   Text-Video Retrieval","['Ning Han', 'Jingjing Chen', 'Guangyi Xiao', 'Yawen Zeng', 'Chuhao Shi', 'Hao Chen']","https://export.arxiv.org/abs/2110.15609","2021-10-29","arXiv","cs.CV cs.IR","The task of cross-modal retrieval between texts and videos aims to understand the correspondence between vision and language. Existing studies follow a trend of measuring text-video similarity on the basis of textual and video embeddings. In common practice, video representation is constructed by feeding video frames into 2D/3D-CNN for global visual feature extraction or only learning simple semantic relations by using local-level fine-grained frame regions via graph convolutional network. However, these video representations do not fully exploit spatio-temporal relation among visual components in learning video representations, resulting in their inability to distinguish videos with the same visual components but with different relations. To solve this problem, we propose a Visual Spatio-temporal Relation-enhanced Network (VSR-Net), a novel cross-modal retrieval framework that enhances visual representation with spatio-temporal relations among components. Specifically, visual spatio-temporal relations are encoded using a multi-layer spatio-temporal transformer to learn visual relational features. We combine fine-grained local relation and global features in bridging text-video modalities. Extensive experimental are conducted on both MSR-VTT and MSVD datasets. The results demonstrate the effectiveness of our proposed model.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20747,""
"Deep Learning for Bias Detection: From Inception to Deployment","['Md Abul Bashar', 'Richi Nayak', 'Anjor Kothare', 'Vishal Sharma', 'Kesavan Kandadai']","https://export.arxiv.org/abs/2110.15728","2021-10-12","arXiv","cs.CL cs.AI cs.LG cs.NE cs.SI","To create a more inclusive workplace, enterprises are actively investing in identifying and eliminating unconscious bias (e.g., gender, race, age, disability, elitism and religion) across their various functions. We propose a deep learning model with a transfer learning based language model to learn from manually tagged documents for automatically identifying bias in enterprise content. We first pretrain a deep learning-based language-model using Wikipedia, then fine tune the model with a large unlabelled data set related with various types of enterprise content. Finally, a linear layer followed by softmax layer is added at the end of the language model and the model is trained on a labelled bias dataset consisting of enterprise content. The trained model is thoroughly evaluated on independent datasets to ensure a general application. We present the proposed method and its deployment detail in a real-world application.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20748,""
"From Theories on Styles to their Transfer in Text: Bridging the Gap with   a Hierarchical Survey","['Enrica Troiano', 'Aswathy Velutharambath', 'and Roman Klinger']","https://export.arxiv.org/abs/2110.15871","2021-10-29","arXiv","cs.CL","Humans are naturally endowed with the ability to write in a particular style. They can, for instance, rephrase a formal letter in an informal way, convey a literal message with the use of figures of speech, edit a novel mimicking the style of some well-known authors. Automating this form of creativity constitutes the goal of style transfer. As a natural language generation task, style transfer aims at re-writing existing texts, and specifically, it creates paraphrases that exhibit some desired stylistic attributes. From a practical perspective, it envisions beneficial applications, like chat-bots that modulate their communicative style to appear empathetic, or systems that automatically simplify technical articles for a non-expert audience.   Style transfer has been dedicated several style-aware paraphrasing methods. A handful of surveys give a methodological overview of the field, but they do not support researchers to focus on specific styles. With this paper, we aim at providing a comprehensive discussion of the styles that have received attention in the transfer task. We organize them into a hierarchy, highlighting the challenges for the definition of each of them, and pointing out gaps in the current research landscape. The hierarchy comprises two main groups. One encompasses styles that people modulate arbitrarily, along the lines of registers and genres. The other group corresponds to unintentionally expressed styles, due to an author's personal characteristics. Hence, our review shows how the groups relate to one another, and where specific styles, including some that have never been explored, belong in the hierarchy. Moreover, we summarize the methods employed for different stylistic families, hinting researchers towards those that would be the most fitting for future research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20749,""
"Robot Learning from Randomized Simulations: A Review","['Fabio Muratore', 'Fabio Ramos', 'Greg Turk', 'Wenhao Yu', 'Michael Gienger', 'Jan Peters']","https://export.arxiv.org/abs/2111.00956","2021-11-01","arXiv","cs.RO cs.LG","The rise of deep learning has caused a paradigm shift in robotics research, favoring methods that require large amounts of data. It is prohibitively expensive to generate such data sets on a physical platform. Therefore, state-of-the-art approaches learn in simulation where data generation is fast as well as inexpensive and subsequently transfer the knowledge to the real robot (sim-to-real). Despite becoming increasingly realistic, all simulators are by construction based on models, hence inevitably imperfect. This raises the question of how simulators can be modified to facilitate learning robot control policies and overcome the mismatch between simulation and reality, often called the 'reality gap'. We provide a comprehensive review of sim-to-real research for robotics, focusing on a technique named 'domain randomization' which is a method for learning from randomized simulations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20750,""
"Stakeholder Participation in AI: Beyond ""Add Diverse Stakeholders and   Stir""","['Fernando Delgado', 'Stephen Yang', 'Michael Madaio', 'Qian Yang']","https://export.arxiv.org/abs/2111.01122","2021-11-01","arXiv","cs.AI cs.CY cs.HC","There is a growing consensus in HCI and AI research that the design of AI systems needs to engage and empower stakeholders who will be affected by AI. However, the manner in which stakeholders should participate in AI design is unclear. This workshop paper aims to ground what we dub a 'participatory turn' in AI design by synthesizing existing literature on participation and through empirical analysis of its current practices via a survey of recent published research and a dozen semi-structured interviews with AI researchers and practitioners. Based on our literature synthesis and empirical research, this paper presents a conceptual framework for analyzing participatory approaches to AI design and articulates a set of empirical findings that in ensemble detail out the contemporary landscape of participatory practice in AI design. These findings can help bootstrap a more principled discussion on how PD of AI should move forward across AI, HCI, and other research communities.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20751,""
"Classification of Goods Using Text Descriptions With Sentences Retrieval","['Eunji Lee', 'Sundong Kim', 'Sihyun Kim', 'Sungwon Park', 'Meeyoung Cha', 'Soyeon Jung', 'Suyoung Yang', 'Yeonsoo Choi', 'Sungdae Ji', 'Minsoo Song', 'Heeja Kim']","https://export.arxiv.org/abs/2111.01663","2021-11-02","arXiv","cs.AI cs.IR","The task of assigning and validating internationally accepted commodity code (HS code) to traded goods is one of the critical functions at the customs office. This decision is crucial to importers and exporters, as it determines the tariff rate. However, similar to court decisions made by judges, the task can be non-trivial even for experienced customs officers. The current paper proposes a deep learning model to assist this seemingly challenging HS code classification. Together with Korea Customs Service, we built a decision model based on KoELECTRA that suggests the most likely heading and subheadings (i.e., the first four and six digits) of the HS code. Evaluation on 129,084 past cases shows that the top-3 suggestions made by our model have an accuracy of 95.5% in classifying 265 subheadings. This promising result implies algorithms may reduce the time and effort taken by customs officers substantially by assisting the HS code classification task.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20752,""
"Assessing Effectiveness of Using Internal Signals for Check-Worthy Claim   Identification in Unlabeled Data for Automated Fact-Checking","['Archita Pathak', 'Rohini K. Srihari']","https://export.arxiv.org/abs/2111.01706","2021-11-02","arXiv","cs.CL cs.AI cs.IR","While recent work on automated fact-checking has focused mainly on verifying and explaining claims, for which the list of claims is readily available, identifying check-worthy claim sentences from a text remains challenging. Current claim identification models rely on manual annotations for each sentence in the text, which is an expensive task and challenging to conduct on a frequent basis across multiple domains. This paper explores methodology to identify check-worthy claim sentences from fake news articles, irrespective of domain, without explicit sentence-level annotations. We leverage two internal supervisory signals - headline and the abstractive summary - to rank the sentences based on semantic similarity. We hypothesize that this ranking directly correlates to the check-worthiness of the sentences. To assess the effectiveness of this hypothesis, we build pipelines that leverage the ranking of sentences based on either the headline or the abstractive summary. The top-ranked sentences are used for the downstream fact-checking tasks of evidence retrieval and the article's veracity prediction by the pipeline. Our findings suggest that the top 3 ranked sentences contain enough information for evidence-based fact-checking of a fake news article. We also show that while the headline has more gisting similarity with how a fact-checking website writes a claim, the summary-based pipeline is the most promising for an end-to-end fact-checking system.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20753,""
"Are online mental health interventions for youth effective? A systematic review","Zhou, Edirippulige, Bai, Bambling","https://doi.org/10.1177/1357633X211047285","20211102","PubMed","Telehealth; adolescent; effectiveness; mental health; systematic review; telemedicine; youth","This systematic review aims to examine the effectiveness of online mental health interventions for youth. We searched seven electronic databases (PubMed, PsycINFO, Medline, Embase, CINAHL, Web of Science and SCOPUS) for the past 10 years to identify randomized controlled trials which have evaluated the use of telehealth interventions for young people with mental health problems. The included studies were assessed for quality and risk of bias. Forty-five randomized controlled trials (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°13,291 participants) were eligible for this review. Most studies (35 trials) evaluated the use of web-based self-help platforms to deliver cognitive behavioural therapy (14 trials), mindfulness (four trials), acceptance commitment therapy (five trials) and positive psychology (two trials). Mobile/computer applications were used to deliver cognitive behavioural therapy (four trials) and coping strategies training (two trials). Web-based synchronous chat (one trial) was used to assist communication between counsellors and participants. Three studies used artificial intelligence-based conversational agents to deliver cognitive behavioural therapy (two trials) and problem-solving-strategy training (one trial). Eighty-two percent (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°37) identified the participants as student population (i.e. university students, high school students). Sixty-four percent (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°29) of the telehealth interventions were found to be effective in managing depression, anxiety, stress, insomnia and improving quality of life when compared with control conditions. Online mental health interventions were found to be effective in managing diverse mental health conditions among youth. Online self-help platforms were the most frequently used modality and artificial intelligence-based chatbots are merging as potential solutions. Future research is warranted to investigate the solutions to improve the retention rate and satisfaction of telehealth interventions among this population.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20754,""
"mHealth Apps for Gestational Diabetes Mellitus that provide Clinical Decision Support or Artificial Intelligence: A Scoping Review","Daley, Ni'Man, Neves, Huda, Marsh, Fenton, Hitman, McLachlan","https://doi.org/10.1111/dme.14735","20211102","PubMed","Apps; artificial intelligence; clinical decision system support; gestational diabetes; mHealth; scoping review","Gestational diabetes (GDM) is the most common metabolic disorder of pregnancy, requiring complex management and empowerment of those affected. Mobile health (mHealth) applications (Apps) are proposed for streamlining healthcare service delivery, extending care relationships into the community, and empowering those affected by prolonged medical disorders to be equal collaborators in their healthcare. This review investigates mHealth apps intended for use with GDM; specifically those powered by artificial intelligence (AI) or providing decision support. A scoping review using the novel Survey Tool approach for collaborative literature Reviews (STaR) process was performed. From 18 papers, 11 discreet GDM-based mHealth apps were identified but only 3 were reasonably mature with only one currently in use in a clinical setting. Two-thirds of the apps provided condition-relevant contextual user feedback that could aid in patient self-care. However, while each app targeted one or more components of the GDM clinical pathway, no app addressed the entirety from diagnosis to post-partum. There are limited mHealth apps for GDM that incorporate AI or AI-based decision support. Many exist only to record patient information like blood glucose readings or diet, provide generic patient education or advice, or to reduce adverse events by providing medication or appointment alerts. Significant barriers remain that continue to limit the adoption of mHealth apps in clinical care settings. Further research and development are needed to deliver intelligent holistic mHealth apps using AI that can truly reduce healthcare resource use and improve outcomes by enabling patient self-care in the community.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20755,""
"Blockchain Integration With Digital Technology and the Future of Health Care Ecosystems: Systematic Review","Fatoum, Hanna, Halamka, Sicker, Spangenberg, Hashmi","https://doi.org/10.2196/19846","20211102","PubMed","artificial intelligence; blockchain, Internet of Things; digital; distributed ledger technology; eHealth; ledger; machine learning","In the era of big data, artificial intelligence (AI), and the Internet of Things (IoT), digital data have become essential for our everyday functioning and in health care services. The sensitive nature of health care data presents several crucial issues such as privacy, security, interoperability, and reliability that must be addressed in any health care data management system. However, most of the current health care systems are still facing major obstacles and are lacking in some of these areas. This is where decentralized, secure, and scalable databases, most notably blockchains, play critical roles in addressing these requirements without compromising security, thereby attracting considerable interest within the health care community. A blockchain can be maintained and widely distributed using a large network of nodes, mostly computers, each of which stores a full replica of the data. A blockchain protocol is a set of predefined rules or procedures that govern how the nodes interact with the network, view, verify, and add data to the ledger. In this article, we aim to explore blockchain technology, its framework, current applications, and integration with other innovations, as well as opportunities in diverse areas of health care and clinical research, in addition to clarifying its future impact on the health care ecosystem. We also elucidate 2 case studies to instantiate the potential role of blockchains in health care. To identify related existing work, terms based on Medical Subject Headings were used. We included studies focusing mainly on health care and clinical research and developed a functional framework for implementation and testing with data. The literature sources for this systematic review were PubMed, Medline, and the Cochrane library, in addition to a preliminary search of IEEE Xplore. The included studies demonstrated multiple framework designs and various implementations in health care including chronic disease diagnosis, management, monitoring, and evaluation. We found that blockchains exhibit many promising applications in clinical trial management such as smart-contract application, participant-controlled data access, trustless protocols, and data validity. Electronic health records (EHRs), patient-centered interoperability, remote patient monitoring, and clinical trial data management were found to be major areas for blockchain usage, which can become a key catalyst for health care innovations. The potential benefits of blockchains are limitless; however, concrete data on long-term clinical outcomes based on blockchains powered and supplemented by AI and IoT are yet to be obtained. Nonetheless, implementing blockchains as a novel way to integrate EHRs nationwide and manage common clinical problems in an algorithmic fashion has the potential for improving patient outcomes, health care experiences, as well as the overall health and well-being of individuals.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20756,""
"The effectiveness of non-pharmacological interventions on cancer related fatigue in breast cancer patients: A protocol for systematic review and network meta-analysis","Liu, Xu, Song, Jiang, Liu, Shi","https://doi.org/10.1002/nop2.1118","20211102","PubMed","breast cancer; cancer-related fatigue; effectiveness; network; non-pharmacological interventions; systematic review","To assess the effect of different non-pharmacological interventions on cancer-related fatigue (CRF) in breast cancer (BC) patients and identify the most effective method for improving CRF. A systematic review and network meta-analysis. Literature will be searched in the ongoing trail in the Clinical Trials.gov, World Health Organization, the International Clinical Trials Registry Platform, Cochrane Library, PubMed, EMBASE, Web of Science and CINAHL, from the inception until December 31, 2020. Two independent researchers will rigorously screen the literature according to the inclusion and exclusion criteria and assess the risk of bias based on the Cochrane Collaboration's Tool of RCTs. Stata 13.0 and Aggregate Data Drug Information System will be used for data analysis. This protocol has been registered on the PROSPERO website (registration number is CRD42020222093). This study will provide the reliable evidence of the most effective non-pharmacological intervention to improving CRF.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20757,""
"Trust in AI: why we should be designing for APPROPRIATE reliance","Benda, Novak, Reale, Ancker","https://doi.org/10.1093/jamia/ocab238","20211102","PubMed","algorithms; artificial intelligence; machine learning; trust","Use of artificial intelligence in healthcare, such as machine learning-based predictive algorithms, holds promise for advancing outcomes, but few systems are used in routine clinical practice. Trust has been cited as an important challenge to meaningful use of artificial intelligence in clinical practice. Artificial intelligence systems often involve automating cognitively challenging tasks. Therefore, previous literature on trust in automation may hold important lessons for artificial intelligence applications in healthcare. In this perspective, we argue that informatics should take lessons from literature on trust in automation such that the goal should be to foster appropriate trust in artificial intelligence based on the purpose of the tool, its process for making recommendations, and its performance in the given context. We adapt a conceptual model to support this argument and present recommendations for future work.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20758,""
"A systematic review on natural language processing systems for eligibility prescreening in clinical research","Idnay, Dreisbach, Weng, Schnall","https://doi.org/10.1093/jamia/ocab228","20211102","PubMed","clinical research; clinical trial matching; cohort identification; eligibility prescreening; natural language processing","We conducted a systematic review to assess the effect of natural language processing (NLP) systems in improving the accuracy and efficiency of eligibility prescreening during the clinical research recruitment process. Guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) standards of quality for reporting systematic reviews, a protocol for study eligibility was developed a priori and registered in the PROSPERO database. Using predetermined inclusion criteria, studies published from database inception through February 2021 were identified from 5 databases. The Joanna Briggs Institute Critical Appraisal Checklist for Quasi-experimental Studies was adapted to determine the study quality and the risk of bias of the included articles. Eleven studies representing 8 unique NLP systems met the inclusion criteria. These studies demonstrated moderate study quality and exhibited heterogeneity in the study design, setting, and intervention type. All 11 studies evaluated the NLP system's performance for identifying eligible participants; 7 studies evaluated the system's impact on time efficiency; 4 studies evaluated the system's impact on workload; and 2 studies evaluated the system's impact on recruitment. NLP systems in clinical research eligibility prescreening are an understudied but promising field that requires further research to assess its impact on real-world adoption. Future studies should be centered on continuing to develop and evaluate relevant NLP systems to improve enrollment into clinical studies. Understanding the role of NLP systems in improving eligibility prescreening is critical to the advancement of clinical research recruitment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20759,""
"Impact of GAN-based lesion-focused medical image super-resolution on the robustness of radiomic features","de Farias, di Noia, Han, Sala, Castelli, Rundo","https://doi.org/10.1038/s41598-021-00898-z","20211102","PubMed","","Robust machine learning models based on radiomic features might allow for accurate diagnosis, prognosis, and medical decision-making. Unfortunately, the lack of standardized radiomic feature extraction has hampered their clinical use. Since the radiomic features tend to be affected by low voxel statistics in regions of interest, increasing the sample size would improve their robustness in clinical studies. Therefore, we propose a Generative Adversarial Network (GAN)-based lesion-focused framework for Computed Tomography (CT) image Super-Resolution (SR); for the lesion (i.e., cancer) patch-focused training, we incorporate Spatial Pyramid Pooling (SPP) into GAN-Constrained by the Identical, Residual, and Cycle Learning Ensemble (GAN-CIRCLE). At [Formula: see text] SR, the proposed model achieved better perceptual quality with less blurring than the other considered state-of-the-art SR methods, while producing comparable results at [Formula: see text] SR. We also evaluated the robustness of our model's radiomic feature in terms of quantization on a different lung cancer CT dataset using Principal Component Analysis (PCA). Intriguingly, the most important radiomic features in our PCA-based analysis were the most robust features extracted on the GAN-super-resolved images. These achievements pave the way for the application of GAN-based image Super-Resolution techniques for studies of radiomics for robust biomarker discovery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20760,""
"The role of machine learning applications in diagnosing and assessing critical and non-critical CHD: a scoping review","Helman, Herrup, Christopher, Al-Zaiti","https://doi.org/10.1017/S1047951121004212","20211102","PubMed","CHD; Machine learning","Machine learning uses historical data to make predictions about new data. It has been frequently applied in healthcare to optimise diagnostic classification through discovery of hidden patterns in data that may not be obvious to clinicians. Congenital Heart Defect (CHD) machine learning research entails one of the most promising clinical applications, in which timely and accurate diagnosis is essential. The objective of this scoping review is to summarise the application and clinical utility of machine learning techniques used in paediatric cardiology research, specifically focusing on approaches aiming to optimise diagnosis and assessment of underlying CHD. Out of 50 full-text articles identified between 2015 and 2021, 40% focused on optimising the diagnosis and assessment of CHD. Deep learning and support vector machine were the most commonly used algorithms, accounting for an overall diagnostic accuracy &gt; 0.80. Clinical applications primarily focused on the classification of auscultatory heart sounds, transthoracic echocardiograms, and cardiac MRIs. The range of these applications and directions of future research are discussed in this scoping review.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20761,""
"Prognostic models of diabetic microvascular complications: a systematic review and meta-analysis","Saputro, Pattanaprateep, Pattanateepapon, Karmacharya, Thakkinstian","https://doi.org/10.1186/s13643-021-01841-z","20211102","PubMed","Meta-analysis; Microvascular complications; Prognostic model; Type 2 diabetes","Many prognostic models of diabetic microvascular complications have been developed, but their performances still varies. Therefore, we conducted a systematic review and meta-analysis to summarise the performances of the existing models. Prognostic models of diabetic microvascular complications were retrieved from PubMed and Scopus up to 31 December 2020. Studies were selected, if they developed or internally/externally validated models of any microvascular complication in type 2 diabetes (T2D). In total, 71 studies were eligible, of which 32, 30 and 18 studies initially developed prognostic model for diabetic retinopathy (DR), chronic kidney disease (CKD) and end stage renal disease (ESRD) with the number of derived equations of 84, 96 and 51, respectively. Most models were derived-phases, some were internal and external validations. Common predictors were age, sex, HbA1c, diabetic duration, SBP and BMI. Traditional statistical models (i.e. Cox and logit regression) were mostly applied, otherwise machine learning. In cohorts, the discriminative performance in derived-logit was pooled with C statistics of 0.82 (0.73Ã¢â‚¬â€˜0.92) for DR and 0.78 (0.74Ã¢â‚¬â€˜0.83) for CKD. Pooled Cox regression yielded 0.75 (0.74Ã¢â‚¬â€˜0.77), 0.78 (0.74Ã¢â‚¬â€˜0.82) and 0.87 (0.84Ã¢â‚¬â€˜0.89) for DR, CKD and ESRD, respectively. External validation performances were sufficiently pooled with 0.81 (0.78Ã¢â‚¬â€˜0.83), 0.75 (0.67Ã¢â‚¬â€˜0.84) and 0.87 (0.85Ã¢â‚¬â€˜0.88) for DR, CKD and ESRD, respectively. Several prognostic models were developed, but less were externally validated. A few studies derived the models by using appropriate methods and were satisfactory reported. More external validations and impact analyses are required before applying these models in clinical practice. PROSPERO CRD42018105287.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20762,""
"A neural network for glomerulus classification based on histological images of kidney biopsy","Cascarano, Debitonto, Lemma, Brunetti, Buongiorno, De Feudis, Guerriero, Venere, Matino, Rocchetti, Rossini, Pesce, Gesualdo, Bevilacqua","https://doi.org/10.1186/s12911-021-01650-3","20211102","PubMed","ANN; CKD; Glomerulus classification; Kidney; Morphological features; Texture features","Computer-aided diagnosis (CAD) systems based on medical images could support physicians in the decision-making process. During the last decades, researchers have proposed CAD systems in several medical domains achieving promising results. CAD systems play an important role in digital pathology supporting pathologists in analyzing biopsy slides by means of standardized and objective workflows. In the proposed work, we designed and tested a novel CAD system module based on image processing techniques and machine learning, whose objective was to classify the condition affecting renal corpuscles (glomeruli) between sclerotic and non-sclerotic. Such discrimination is useful for the biopsy slides evaluation performed by pathologists. We collected 26 digital slides taken from the kidneys of 19 donors with Periodic Acid-Schiff staining. Expert pathologists have conducted the slides preparation, digital acquisition and glomeruli annotations. Before setting the classifiers, we evaluated several feature extraction techniques from the annotated regions. Then, a feature reduction procedure followed by a shallow artificial neural network allowed discriminating between the glomeruli classes. We evaluated the workflow considering an independent dataset (i.e., processing images not used in the training procedure). Ten independent runs of the training algorithm, and evaluation, allowed achieving MCC and Accuracy of 0.95 (Ã‚Â±Ã¢â‚¬â€°0.01) and 0.99 (standard deviationÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.00), respectively. We also obtained good precision (0.9844Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°0.0111) and recall (0.9310Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°0.0153). Results on the test set confirm that the proposed workflow is consistent and reliable for the investigated domain, and it can support the clinical practice of discriminating the two classes of glomeruli. Analyses on misclassifications show that the involved images are usually affected by staining artefacts or present partial sections due to slice preparation and staining processes. In clinical practice, however, pathologists discard images showing such artefacts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20763,""
"Biomedical Ontologies to Guide AI Development in Radiology","Filice, Kahn","https://doi.org/10.1007/s10278-021-00527-1","20211101","PubMed","Artificial intelligence; Controlled vocabulary; Knowledge representation; Ontology; Terminology","The advent of deep learning has engendered renewed and rapidly growing interest in artificial intelligence (AI) in radiology to analyze images, manipulate textual reports, and plan interventions. Applications of deep learning and other AI approaches must be guided by sound medical knowledge to assure that they are developed successfully and that they address important problems in biomedical research or patient care. To date, AI has been applied to a limited number of real-world radiology applications. As AI systems become more pervasive and are applied more broadly, they will benefit from medical knowledge on a larger scale, such as that available through computer-based approaches. A key approach to represent computer-based knowledge in a particular domain is an ontology. As defined in informatics, an ontology defines a domain's terms through their relationships with other terms in the ontology. Those relationships, then, define the terms' semantics, or ""meaning."" Biomedical ontologies commonly define the relationships between terms and more general terms, and can express causal, part-whole, and anatomic relationships. Ontologies express knowledge in a form that is both human-readable and machine-computable. Some ontologies, such as RSNA's RadLex radiology lexicon, have been applied to applications in clinical practice and research, and may be familiar to many radiologists. This article describes how ontologies can support research and guide emerging applications of AI in radiology, including natural language processing, image-based machine learning, radiomics, and planning.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20764,""
"Stroke Outcome Measurements From Electronic Medical Records: Cross-sectional Study on the Effectiveness of Neural and Nonneural Classifiers","Zanotto, Beck da Silva Etges, Dal Bosco, Cortes, Ruschel, De Souza, Andrade, Viegas, Canuto, Luiz, Ouriques Martins, Vieira, Polanczyk, AndrÃƒÂ© GonÃƒÂ§alves","https://doi.org/10.2196/29120","20211101","PubMed","EHR; data mining; electronic health records; electronic medical records; natural language processing; outcomes; patient outcomes; stroke; text classification; text processing","With the rapid adoption of electronic medical records (EMRs), there is an ever-increasing opportunity to collect data and extract knowledge from EMRs to support patient-centered stroke management. This study aims to compare the effectiveness of state-of-the-art automatic text classification methods in classifying data to support the prediction of clinical patient outcomes and the extraction of patient characteristics from EMRs. Our study addressed the computational problems of information extraction and automatic text classification. We identified essential tasks to be considered in an ischemic stroke value-based program. The 30 selected tasks were classified (manually labeled by specialists) according to the following value agenda: tier 1 (achieved health care status), tier 2 (recovery process), care related (clinical management and risk scores), and baseline characteristics. The analyzed data set was retrospectively extracted from the EMRs of patients with stroke from a private Brazilian hospital between 2018 and 2019. A total of 44,206 sentences from free-text medical records in Portuguese were used to train and develop 10 supervised computational machine learning methods, including state-of-the-art neural and nonneural methods, along with ontological rules. As an experimental protocol, we used a 5-fold cross-validation procedure repeated 6 times, along with subject-wise sampling. A heatmap was used to display comparative result analyses according to the best algorithmic effectiveness (F1 score), supported by statistical significance tests. A feature importance analysis was conducted to provide insights into the results. The top-performing models were support vector machines trained with lexical and semantic textual features, showing the importance of dealing with noise in EMR textual representations. The support vector machine models produced statistically superior results in 71% (17/24) of tasks, with an F1 score &gt;80% regarding care-related tasks (patient treatment location, fall risk, thrombolytic therapy, and pressure ulcer risk), the process of recovery (ability to feed orally or ambulate and communicate), health care status achieved (mortality), and baseline characteristics (diabetes, obesity, dyslipidemia, and smoking status). Neural methods were largely outperformed by more traditional nonneural methods, given the characteristics of the data set. Ontological rules were also effective in tasks such as baseline characteristics (alcoholism, atrial fibrillation, and coronary artery disease) and the Rankin scale. The complementarity in effectiveness among models suggests that a combination of models could enhance the results and cover more tasks in the future. Advances in information technology capacity are essential for scalability and agility in measuring health status outcomes. This study allowed us to measure effectiveness and identify opportunities for automating the classification of outcomes of specific tasks related to clinical conditions of stroke victims, and thus ultimately assess the possibility of proactively using these machine learning techniques in real-world situations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20765,""
"Cost-effective Analysis of Subcutaneous vs Sublingual Immunotherapy From the Payor's Perspective","Hardin, Eskander, Franzese","https://doi.org/10.1177/2473974X211052955","20211102","PubMed","PS/QI; SCIT; SLIT; allergen; allergic; conjunctivitis; cost-effectiveness; immunotherapy; rhinitis; systematic review","Compare the cost-effectiveness of subcutaneous immunotherapy (SCIT) and aqueous sublingual immunotherapy (SLIT) as treatment modalities for adult patients with allergic rhinitis and conjunctivitis who undergo testing and qualify for allergen immunotherapy (AIT). A systematic review was performed to identify key statistics for analysis, including the compliance and efficacy rates for each treatment. The body of literature on this topic is highly heterogeneous, so ranges were obtained and assumptions stated clearly where they were made. Charges were derived from average commercial payor charges from a single hospital institution. A hypothetical 100 patients are examined for the study. A cost-effectiveness sensitivity analysis was then performed using a decision tree model to compare the modalities. A sensitivity and threshold analysis was then performed to assess the strength of recommendations after identifying results at baseline. Assuming an 80% compliance rate with allergen immunotherapy and an estimated efficacy (assumed to be clinically significant improvement in symptoms) of 70% for SLIT and 80% for SCIT, at the 12-month mark, the baseline total cost to the payor of SLIT per successful treatment outcome is $1196 while the charge of SCIT per successful treatment outcome is $2691. Our analysis favors SLIT as the more cost-effective modality per successful outcome. When compared to SCIT, SLIT is economically favorable and should be considered the financially conscious option for patients with &gt;40% adherence to therapy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20766,""
"Literature-based discovery approaches for evidence-based healthcare: a systematic review","Cheerkoot-Jalim, Khedo","https://doi.org/10.1007/s12553-021-00605-y","20211102","PubMed","Evidence-based healthcare; Knowledge translation; Literature-based discovery; Systematic review","Literature-Based Discovery (LBD) is a text mining technique used to generate novel hypotheses from vast amounts of literature sources, by identifying links between concepts from disparate sources. One of the main areas where it has been predominantly applied is the healthcare domain, whereby promising results, in the form of novel hypotheses, have been reported. The purpose of this work was to conduct a systematic literature review of recent publications on LBD in the healthcare domain in order to assess the trends in the approaches used and to identify issues and challenges for such systems. The review was conducted following the principles of the Kitchenham method. The selected studies have been scrutinized and the derived findings have been reported following the PRISMA guidelines. The review results reveal useful information regarding the application areas, the data sources considered, the approaches used, the performance in terms of accuracy and reliability and future research challenges. The results of this review will be beneficial to LBD researchers and other stakeholders in the healthcare domain, by providing them with useful insights on the approaches to adopt, data sources to consider, evaluation model to use and challenges to reflect on. The synthesis of the results of this work has shed light on recent issues and challenges that drive new LBD models and provides avenues for their application in other diverse areas in the healthcare domain. To the best of our knowledge, no such recent review has been conducted.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20767,""
"Peripheral Blood-Based Gene Expression Studies in Schizophrenia: A Systematic Review","Wagh, Vyas, Agrawal, Pachpor, Paralikar, Khare","https://doi.org/10.3389/fgene.2021.736483","20211102","PubMed","biomarkers; gene expression; genomics; peripheral blood; schizophrenia","Schizophrenia is a disorder that is characterized by delusions, hallucinations, disorganized speech or behavior, and socio-occupational impairment. The duration of observation and variability in symptoms can make the accurate diagnosis difficult. Identification of biomarkers for schizophrenia (SCZ) can help in early diagnosis, ascertaining the diagnosis, and development of effective treatment strategies. Here we review peripheral blood-based gene expression studies for identification of gene expression biomarkers for SCZ. A literature search was carried out in PubMed and Web of Science databases for blood-based gene expression studies in SCZ. A list of differentially expressed genes (DEGs) was compiled and analyzed for overlap with genetic markers, differences based on drug status of the participants, functional enrichment, and for effect of antipsychotics. This literature survey identified 61 gene expression studies. Seventeen out of these studies were based on expression microarrays. A comparative analysis of the DEGs (<i>n</i> = 227) from microarray studies revealed differences between drug-naive and drug-treated SCZ participants. We found that of the 227 DEGs, 11 genes (<i>ACOT7, AGO2, DISC1, LDB1, RUNX3, SIGIRR, SLC18A1, NRG1, CHRNB2, PRKAB2, and ZNF74</i>) also showed genetic and epigenetic changes associated with SCZ. Functional enrichment analysis of the DEGs revealed dysregulation of proline and 4-hydroxyproline metabolism. Also, arginine and proline metabolism was the most functionally enriched pathway for SCZ in our analysis. Follow-up studies identified effect of antipsychotic treatment on peripheral blood gene expression. Of the 27 genes compiled from the follow-up studies <i>AKT1, DISC1, HP</i>, and <i>EIF2D</i> had no effect on their expression status as a result of antipsychotic treatment. Despite the differences in the nature of the study, ethnicity of the population, and the gene expression analysis method used, we identified several coherent observations. An overlap, though limited, of genetic, epigenetic and gene expression changes supports interplay of genetic and environmental factors in SCZ. The studies validate the use of blood as a surrogate tissue for biomarker analysis. We conclude that well-designed cohort studies across diverse populations, use of high-throughput sequencing technology, and use of artificial intelligence (AI) based computational analysis will significantly improve our understanding and diagnostic capabilities for this complex disorder.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20768,""
"A Comparison of Clinical, Electro-Diagnostic, Laboratory, and Treatment Outcome Differences in a Cohort of HIV-Infected and HIV-Uninfected Patients With Myasthenia Gravis","Moodley, Bill, Patel","https://doi.org/10.3389/fneur.2021.738813","20211102","PubMed","AIDS; HIV; IV cyclophosphamide (CY); Myasthenia Gravis; Plasma exchange (PLEX, PE); intravenous immunoglobulin (IVIG)","There is limited literature comparing the clinical parameters and treatment outcomes in HIV-infected and HIV-uninfected myasthenia gravis (MG) patients. The aim of the study was to investigate the clinical differences and treatment outcomes in the two categories of patients, particularly the safe use of immunosuppressive therapy in immunocompromised patients. The study was a retrospective analysis of medical records of MG patients from the neuromuscular unit at Inkosi Albert Luthuli Central Hospital in Kwa-Zulu Natal between 2003 and 2019. One hundred and seventy-eight (178) patients fulfilled the clinical criteria for MG. Twenty-four (13.4%) were HIV-infected and 154 (86.5%) were HIV-uninfected. There were 116 (65%) females, median 45 years, (IQR 40-62), 90 (50.5%) black African, 66 (37%) Indian, 20 (11.2%) white, and 2 (1.1%) of mixed ancestry. In the HIV-infected cohort, 20 (87%) had generalized MG, 12 (50%) bulbar, and 14 (60.9%) respiratory onset MG, 12 (50%) presented with MG Foundation of America (MGFA) class five diseases at diagnosis, six (25%) presented with MG crisis during the 5-year follow-up. Thirteen (54%) of the HIV-infected group required rescue therapy using (plasma exchange or IV immunoglobulin) combined with pulse cyclophosphamide compared with 17 (11%) in the HIV-uninfected cohort, respectively. At 5 years, 8 (33%) of the HIV-infected group remained refractory to treatment compared with 10 (6.5%) HIV-uninfected cohort, respectively. No adverse events were documented in HIV-infected patients receiving combination rescue therapy (PLEX or IVIG combined with IV cyclophosphamide). In conclusion HIV-infected MG patients are more likely to require combination rescue therapy with PE/IVIG and IV cyclophosphamide compared with those who were HIV-uninfected. No side effects were documented in the HIV-infected group receiving the above therapy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20769,""
"Automatic Seizure Classification Based on Domain-Invariant Deep Representation of EEG","Cao, Yao, Chen, Sun, Tan","https://doi.org/10.3389/fnins.2021.760987","20211102","PubMed","deep learning; domain-invariant representation; electroencephalography; hybrid deep model; seizure classification","Accurate identification of the type of seizure is very important for the treatment plan and drug prescription of epileptic patients. Artificial intelligence has shown considerable potential in the fields of automated EEG analysis and seizure classification. However, the highly personalized representation of epileptic seizures in EEG has led to many research results that are not satisfactory in clinical applications. In order to improve the clinical adaptability of the algorithm, this paper proposes an adversarial learning-driven domain-invariant deep feature representation method, which enables the hybrid deep networks (HDN) to reliably identify seizure types. In the train phase, we first use the labeled multi-lead EEG short samples to train squeeze-and-excitation networks (SENet) to extract short-term features, and then use the compressed samples to train the long short-term memory networks (LSTM) to extract long-time features and construct a classifier. In the inference phase, we first adjust the feature mapping of LSTM through the adversarial learning between LSTM and clustering subnet so that the EEG of the target patient and the EEG in the database obey the same distribution in the deep feature space. Finally, we use the adjusted classifier to identify the type of seizure. Experiments were carried out based on the TUH EEG Seizure Corpus and CHB-MIT seizure database. The experimental results show that the proposed domain adaptive deep feature representation improves the classification accuracy of the hybrid deep model in the target set by 5%. It is of great significance for the clinical application of EEG automatic analysis equipment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20770,""
"Challenges of evidence synthesis during the 2020 COVID pandemic: a scoping review","Khalil, Tamara, Rada, Akl","https://doi.org/10.1016/j.jclinepi.2021.10.017","20211102","PubMed","Evidence synthesis; data sharing; international collaboration; methodology","The objectives of this scoping review are to identify the challenges to conducting evidence synthesis during the COVID-19 pandemic and to propose some recommendations addressing the identified gaps. A scoping review methodology was followed to map the literature published on the challenges and solutions of conducting evidence synthesis using the Joanna Briggs Methodology of performing scoping review. We searched several databases from the start of the Pandemic in December 2019 until 10th June 2021. A total of 28 publications was included in the review. The challenges cited in the included studies have been categorised into four distinct but interconnected themes including: upstream, Evidence synthesis, downstream and contextual challenges. These challenges have been further refined into issues with primary studies, databases, team capacity, process, resources, and context. Several proposals to improve the above challenges included: transparency in primary studies registration and reporting, establishment of online platforms that enables collaboration, data sharing and searching, the use of computable evidence and coordination of efforts at an international level. This review has highlighted the importance of including artificial intelligence, a framework for international collaboration and a sustained funding model to address many of the shortcomings and ensure we are ready for similar challenges in the future.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20771,""
"srBERT: automatic article classification model for systematic review using BERT","Aum, Choe","https://doi.org/10.1186/s13643-021-01763-w","20211031","PubMed","Deep learning; Process automation; Systematic review; Text mining","Systematic reviews (SRs) are recognized as reliable evidence, which enables evidence-based medicine to be applied to clinical practice. However, owing to the significant efforts required for an SR, its creation is time-consuming, which often leads to out-of-date results. To support SR tasks, tools for automating these SR tasks have been considered; however, applying a general natural language processing model to domain-specific articles and insufficient text data for training poses challenges. The research objective is to automate the classification of included articles using the Bidirectional Encoder Representations from Transformers (BERT) algorithm. In particular, srBERT models based on the BERT algorithm are pre-trained using abstracts of articles from two types of datasets, and the resulting model is then fine-tuned using the article titles. The performances of our proposed models are compared with those of existing general machine-learning models. Our results indicate that the proposed srBERT<sub>my</sub> model, pre-trained with abstracts of articles and a generated vocabulary, achieved state-of-the-art performance in both classification and relation-extraction tasks; for the first task, it achieved an accuracy of 94.35% (89.38%), F1 score of 66.12 (78.64), and area under the receiver operating characteristic curve of 0.77 (0.9) on the original and (generated) datasets, respectively. In the second task, the model achieved an accuracy of 93.5% with a loss of 27%, thereby outperforming the other evaluated models, including the original BERT model. Our research shows the possibility of automatic article classification using machine-learning approaches to support SR tasks and its broad applicability. However, because the performance of our model depends on the size and class ratio of the training dataset, it is important to secure a dataset of sufficient quality, which may pose challenges.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20772,""
"Machine learning to guide clinical decision-making in abdominal surgery-a systematic literature review","Henn, Buness, Schmid, Kalff, Matthaei","https://doi.org/10.1007/s00423-021-02348-w","20211030","PubMed","Abdominal surgery; Clinical decision-making; Digitalization; Machine learning; Postoperative complications; Risk prediction","An indication for surgical therapy includes balancing benefits against risk, which remains a key task in all surgical disciplines. Decisions are oftentimes based on clinical experience while guidelines lack evidence-based background. Various medical fields capitalized the application of machine learning (ML), and preliminary research suggests promising implications in surgeons' workflow. Hence, we evaluated ML's contemporary and possible future role in clinical decision-making (CDM) focusing on abdominal surgery. Using the PICO framework, relevant keywords and research questions were identified. Following the PRISMA guidelines, a systemic search strategy in the PubMed database was conducted. Results were filtered by distinct criteria and selected articles were manually full text reviewed. Literature review revealed 4,396 articles, of which 47 matched the search criteria. The mean number of patients included was 55,843. A total of eight distinct ML techniques were evaluated whereas AUROC was applied by most authors for comparing ML predictions vs. conventional CDM routines. Most authors (NÃ¢â‚¬â€°=Ã¢â‚¬â€°30/47, 63.8%) stated ML's superiority in the prediction of benefits and risks of surgery. The identification of highly relevant parameters to be integrated into algorithms allowing a more precise prognosis was emphasized as the main advantage of ML in CDM. A potential value of ML for surgical decision-making was demonstrated in several scientific articles. However, the low number of publications with only few collaborative studies between surgeons and computer scientists underpins the early phase of this highly promising field. Interdisciplinary research initiatives combining existing clinical datasets and emerging techniques of data processing may likely improve CDM in abdominal surgery in the future.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20773,""
"[Artificial intelligence in ex vivo confocal laser scanning microscopy]","Hartmann","https://doi.org/10.1007/s00105-021-04908-z","20211030","PubMed","Artificial intelligence; Machine learning; Mohs surgery; Neoplasms; Skin diseases","Visual data, such as clinical photographs or pictures from imaging examination methods, such as ex vivo confocal laser scanning microscopy (CLSM), are particularly suitable for machine learning techniques. The aim was to find out whether data have already been published on this innovative application in ex vivo CLSM and what potential challenges and limitations could arise. Review of the literature and summary of current knowledge and personal experience on the use of artificial intelligence (AI) in ex vivo CLSM. Successful integration of digital hematoxylin-eosin-like staining has made ex vivo CLSM significantly more accessible for digital assessments. Several machine learning techniques have been developed to date in such aÃ‚Â way that they have been able to identify malignant skin lesions on clinical photographs and pathological microscopic images with similar accuracy compared to experts, or even find visual patterns that have been overlooked by experts and that correlate with certain dermatological diseases. One study on the use of AI in ex vivo CLSM for automated tumor detection has been published to date. Several challenges and limitations can arise when using AI in ex vivo CLSM. The already digitized ex vivo CLSM, which was established for rapid section examination purposes, is aÃ‚Â predestined method for the development and use of new applications with machine learning in the healthcare sector. The results of further studies on this topic are anticipated with great hope. HINTERGRUND: Visuelle Daten, wie klinische Fotografien oder Bilder von bildgebenden Untersuchungsmethoden wie z.Ã¢â‚¬Â¯B. der ex-vivo konfokalen Laserscanmikroskopie (KLM), eignen sich besonders gut fÃƒÂ¼r maschinelle Lerntechniken. Ziel war es herauszufinden, ob es bereits Daten zu diesem innovativen Einsatz in der Ex-vivo-KLM gibt und welche potenziellen Herausforderungen und Limitationen dabei auftreten kÃƒÂ¶nnen. Literaturbeurteilung und Zusammenfassung der derzeitigen Kenntnisse und eigene Erfahrungen zum Einsatz der kÃƒÂ¼nstlichen Intelligenz (KI) bei der Ex-vivo-KLM. Die erfolgreiche Integration der digitalen HÃƒÂ¤matoxylin-Eosin-ÃƒÂ¤hnlichen-FÃƒÂ¤rbung hat die Ex-vivo-KLM deutlich zugÃƒÂ¤nglicher fÃƒÂ¼r digitale Verfahren gemacht. Mehrere maschinelle Lerntechniken konnten bis heute so entwickelt werden, dass sie auf klinischen Fotographien und pathologischen Mikroskopiebildern maligne HautlÃƒÂ¤sionen mit ÃƒÂ¤hnlicher Genauigkeit wie Experten erkennen konnten oder sogar von Experten ÃƒÂ¼bersehene visuelle Muster, die mit bestimmten dermatologischen Erkrankungen korrelieren, finden konnten. Es wurde bisher eine Studie zum Einsatz der KI in der Ex-vivo-KLM zur automatisierten Tumorerkennung verÃƒÂ¶ffentlicht. Es kÃƒÂ¶nnen mehrere Herausforderungen und EinschrÃƒÂ¤nkungen beim Einsatz der KI in der Ex-vivo-KLM auftreten. Die bereits digitalisierte Ex-vivo-KLM, die fÃƒÂ¼r Schnellschnittuntersuchungszwecke etabliert wurde, ist ein prÃƒÂ¤destinierter Fall fÃƒÂ¼r die Entwicklung und Anwendung neuer Applikationen mit maschinellem Lernen im Gesundheitswesen. Auf die Ergebnisse weiterer Studien zu diesem Thema wird mit groÃƒÅ¸er Hoffnung gewartet.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20774,""
"Super-resolution of Pneumocystis carinii pneumonia CT via self-attention GAN","Xie, Zhang, Song, Wang, Zhu, Zhang, Zhang, Yu, Zhao","https://doi.org/10.1016/j.cmpb.2021.106467","20211102","PubMed","Convolutional neural network; Generative adversarial network; Pneumocystis carinii pneumonia; Self-attention mechanism; Super-resolution","Computed tomography (CT) examination plays an important role in screening suspected and confirmed patients in pneumocystis carinii pneumonia (PCP), and the efficient acquisition of high-quality medical CT images is essential for the clinical application of computer-aided diagnosis technology. Therefore, improving the resolution of CT images of pneumonia is a very important task. Aiming at the problem of how to recover the texture details of the reconstructed PCP CT super-resolution image, we propose the image super-resolution reconstruction model based on self-attention generation adversarial network (SAGAN). In the SAGAN algorithm, a generator based on self-attention mechanism and residual module is used to transform a low-resolution image into a super-resolution image. A discriminator based on depth convolution network tries to distinguish the difference between the reconstructed super-resolution image and the real super-resolution image. In terms of loss function construction, on the one hand, the Charbonnier content loss function is used to improve the accuracy of image reconstruction, and on the other hand, the feature value before activation of the pre-trained VGGNet is used to calculate the perceptual loss to achieve accurate texture detail reconstruction of super-resolution images. Experimental results show that our SAGAN algorithm is superior to other state-of-the-art algorithms in both peak signal-to-noise ratio (PSNR) and structural similarity score (SSIM). Specifically, our SAGAN method can obtain 31.94 dB which is 1.53 dB better than SRGAN on Set5 dataset for 4 enlargements. Our SAGAN method can reconstruct more realistic PCP CT images with clear texture, which can help experts diagnose the condition of PCP.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20775,""
"Dynamic causal modeling on the identification of interacting networks in the brain: a systematic review","Wang, Liang","https://doi.org/10.1109/TNSRE.2021.3123964","20211029","PubMed","","Dynamic causal modeling (DCM) has long been used to characterize effective connectivity within networks of distributed neuronal responses. Previous reviews have highlighted the understanding of the conceptual basis behind DCM and its variants from different aspects. However, no detailed summary or classification research on the task-related effective connectivity of various brain regions has been made formally available so far, and there is also a lack of application analysis of DCM for hemodynamic and electrophysiological measurements. This review aims to analyze the effective connectivity of different brain regions using DCM for different measurement data. We found that, in general, most studies focused on the networks between different cortical regions, and the research on the networks between other deep subcortical nuclei or between them and the cerebral cortex are receiving increasing attention, but far from the same scale. Our analysis also reveals a clear bias towards some task types. Based on these results, we identify and discuss several promising research directions that may help the community to attain a clear understanding of the brain network interactions under different tasks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20776,""
"Deep Learning for HDR Imaging: State-of-the-Art and Future Trends","Wang, Yoon","https://doi.org/10.1109/TPAMI.2021.3123686","20211101","PubMed","","High dynamic range (HDR) imaging is a technique to allow a greater dynamic range of exposures, which is a very important field in image processing, computer graphics, and vision. Recent years have witnessed a striking advancement of HDR imaging using deep learning. This paper aims to provide a systematic review and analysis of the recent development of deep HDR imaging methodologies. Overall, we hierarchically and structurally group existing deep HDR imaging methods into five categories based on the number/domain of input exposures in HDR imaging, the number of learning tasks in HDR imaging, HDR imaging using the novel sensor data, HDR imaging using novel learning strategies, and the applications. Importantly, we provide constructive discussions for each category regarding its potential and challenges. Moreover, we cover some crucial issues for deep HDR imaging, such as datasets and evaluation metrics. Lastly, we highlight some open issues and point out future directions by sharing some new perspectives.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20777,""
"Developing a RadLex-Based Named Entity Recognition Tool for Mining Textual Radiology Reports: Development and Performance Evaluation Study","Tsuji, Wen, Takahashi, Zhang, Ogasawara, Jiang","https://doi.org/10.2196/25378","20211101","PubMed","RadLex; named entity recognition (NER); natural language processing (NLP); ontology; stem term","Named entity recognition (NER) plays an important role in extracting the features of descriptions such as the name and location of a disease for mining free-text radiology reports. However, the performance of existing NER tools is limited because the number of entities that can be extracted depends on the dictionary lookup. In particular, the recognition of compound terms is very complicated because of the variety of patterns. The aim of this study is to develop and evaluate an NER tool concerned with compound terms using RadLex for mining free-text radiology reports. We leveraged the clinical Text Analysis and Knowledge Extraction System (cTAKES) to develop customized pipelines using both RadLex and SentiWordNet (a general purpose dictionary). We manually annotated 400 radiology reports for compound terms in noun phrases and used them as the gold standard for performance evaluation (precision, recall, and F-measure). In addition, we created a compound terms-enhanced dictionary (CtED) by analyzing false negatives and false positives and applied it to another 100 radiology reports for validation. We also evaluated the stem terms of compound terms by defining two measures: occurrence ratio (OR) and matching ratio (MR). The F-measure of cTAKES+RadLex+general purpose dictionary was 30.9% (precision 73.3% and recall 19.6%) and that of the combined CtED was 63.1% (precision 82.8% and recall 51%). The OR indicated that the stem terms of effusion, node, tube, and disease were used frequently, but it still lacks capturing compound terms. The MR showed that 71.85% (9411/13,098) of the stem terms matched with that of the ontologies, and RadLex improved approximately 22% of the MR from the cTAKES default dictionary. The OR and MR revealed that the characteristics of stem terms would have the potential to help generate synonymous phrases using the ontologies. We developed a RadLex-based customized pipeline for parsing radiology reports and demonstrated that CtED and stem term analysis has the potential to improve dictionary-based NER performance with regard to expanding vocabularies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20778,""
"[Specificity study of visualization analysis of electroencephalogram diagnosis of depression based on CiteSpace]","Zhang, Liu, Zhong, Li, Jin, Zheng, Li","https://doi.org/10.7507/1001-5515.202101058","20211101","PubMed","CiteSpace; depressive disorder; electroencephalogram; visual analysis; Databases, Factual; Depression; Electroencephalography; Humans; Publications; Software; United States","This paper analyzed literatures on the specificity study of electroencephalogram (EEG) in the diagnosis of depression since 2010 to 2020, summarized the recent research directions in this field and prospected the future research hotspots at home and abroad. Based on databases of China National Knowledge Infrastructure (CNKI) and the core collection of Web of Science (WOS), CiteSpace software was used to analyze the relevant literatures in this research field. The number of relevant literatures, countries, authors, research institutions, key words, cited literatures and periodicals related to this research were analyzed, respectively, to explore research hotspots and development trends in this field. A total of 2 155 articles were included in the WOS database. The most published institution was the University of Toronto, the most published country was the United States, China occupied the third place, and the hot keywords were anxiety, disorder, brain and so on. A total of 529 literatures were included and analyzed in CNKI database. The institution with the most publications was the Mental Health Center of West China Hospital of Sichuan University, and the hot keywords were EEG signal, event-related potential, convolutional neural network, schizophrenia, etc <b>.</b> This study finds that EEG study of depression is developing rapidly at home and abroad. Research directions in the world mainly focus on exploring the characteristics of spontaneous EEG rhythm and nonlinear dynamic parameters during sleep in depressed patients. In addition, synchronous transcranial magnetic stimulation (TMS) and EEG technologies also attract much attention abroad, and the future research hotspot will be on the mechanism of EEG on patients with major depression. Domestic research directions mainly focus on the classification of resting EEG and the control study of resting EEG power spectrum entropy in patients with schizophrenia and depression, and future research hotspot is the basic and clinical EEG study of depressed patients complicated with anxiety. Ã¦Å“Â¬Ã¦â€“â€¡Ã¥Ë†â€ Ã¦Å¾ÂÃ¤Âºâ€ Ã¥â€ºÂ½Ã¥â€ â€¦Ã¥Â¤â€“ 2010 Ã¥Â¹Â´Ã¨â€¡Â³ 2020 Ã¥Â¹Â´Ã¨â€žâ€˜Ã§â€ÂµÃ¥â€ºÂ¾Ã¨Â¯Å Ã¦â€“Â­Ã¦Å â€˜Ã©Æ’ÂÃ§â€”â€¡Ã§â€°Â¹Ã¥Â¼â€šÃ¦â‚¬Â§Ã§Â â€Ã§Â©Â¶Ã§Å¡â€žÃ§â€ºÂ¸Ã¥â€¦Â³Ã¦â€“â€¡Ã§Å’Â®Ã¯Â¼Å’Ã¦â‚¬Â»Ã§Â»â€œÃ¤Âºâ€ Ã¨Â¯Â¥Ã©Â¢â€ Ã¥Å¸Å¸Ã§Â â€Ã§Â©Â¶Ã¦â€“Â¹Ã¥Ââ€˜Ã¥ÂÅ Ã¥Â±â€¢Ã¦Å“â€ºÃ¥â€ºÂ½Ã¥â€ â€¦Ã¥Â¤â€“Ã¦Å“ÂªÃ¦ÂÂ¥Ã§Â â€Ã§Â©Â¶Ã§Æ’Â­Ã§â€šÂ¹Ã£â‚¬â€šÃ¥Å¸ÂºÃ¤ÂºÅ½Ã¤Â¸Â­Ã¥â€ºÂ½Ã§Å¸Â¥Ã§Â½â€˜Ã¥â€™Å’ Web of Science Ã¦Â Â¸Ã¥Â¿Æ’Ã¥ÂË†Ã©â€ºâ€ Ã¦â€¢Â°Ã¦ÂÂ®Ã¥Âºâ€œÃ¯Â¼Å’Ã¨Â¿ÂÃ§â€Â¨ CiteSpace Ã¨Â½Â¯Ã¤Â»Â¶Ã¥Â¯Â¹Ã¨Â¿â„¢Ã¤Â¸â‚¬Ã§Â â€Ã§Â©Â¶Ã©Â¢â€ Ã¥Å¸Å¸Ã§Å¡â€žÃ§â€ºÂ¸Ã¥â€¦Â³Ã¦â€“â€¡Ã§Å’Â®Ã¨Â¿â€ºÃ¨Â¡Å’Ã¥ÂÂ¯Ã¨Â§â€ Ã¥Å’â€“Ã¥Ë†â€ Ã¦Å¾ÂÃ£â‚¬â€šÃ¥Â¯Â¹Ã¥Ââ€˜Ã¦â€“â€¡Ã¦â€¢Â°Ã©â€¡ÂÃ£â‚¬ÂÃ¥â€ºÂ½Ã¥Â®Â¶Ã£â‚¬ÂÃ¤Â½Å“Ã¨â‚¬â€¦Ã£â‚¬ÂÃ§Â â€Ã§Â©Â¶Ã¦Å“ÂºÃ¦Å¾â€žÃ£â‚¬ÂÃ¥â€¦Â³Ã©â€Â®Ã¨Â¯ÂÃ£â‚¬ÂÃ¨Â¢Â«Ã¥Â¼â€¢Ã¦â€“â€¡Ã§Å’Â®Ã¥ÂÅ Ã¦Å“Å¸Ã¥Ë†Å Ã¨Â¿â€ºÃ¨Â¡Å’Ã¥Ë†â€ Ã¦Å¾ÂÃ¯Â¼Å’Ã¦Å½Â¢Ã§Â´Â¢Ã¦Â­Â¤Ã©Â¢â€ Ã¥Å¸Å¸Ã§Â â€Ã§Â©Â¶Ã§Æ’Â­Ã§â€šÂ¹Ã¥ÂÅ Ã¥Ââ€˜Ã¥Â±â€¢Ã¨Â¶â€¹Ã¥Å Â¿Ã£â‚¬â€šWeb of Science Ã¦â€¢Â°Ã¦ÂÂ®Ã¥Âºâ€œÃ¥â€¦Â±Ã§ÂºÂ³Ã¥â€¦Â¥ 2 155 Ã§Â¯â€¡Ã¦â€“â€¡Ã§Å’Â®Ã£â‚¬â€šÃ¥Ââ€˜Ã¦â€“â€¡Ã¦Å“â‚¬Ã¥Â¤Å¡Ã§Å¡â€žÃ¦Å“ÂºÃ¦Å¾â€žÃ¦ËœÂ¯Ã¥Â¤Å¡Ã¤Â¼Â¦Ã¥Â¤Å¡Ã¥Â¤Â§Ã¥Â­Â¦Ã¯Â¼Å’Ã¥Ââ€˜Ã¦â€“â€¡Ã¦Å“â‚¬Ã¥Â¤Å¡Ã§Å¡â€žÃ¥â€ºÂ½Ã¥Â®Â¶Ã¦ËœÂ¯Ã§Â¾Å½Ã¥â€ºÂ½Ã¯Â¼Å’Ã¤Â¸Â­Ã¥â€ºÂ½Ã§Å¡â€žÃ¥Ââ€˜Ã¦â€“â€¡Ã©â€¡ÂÃ¥ÂÂ Ã¦ÂÂ®Ã§Â¬Â¬Ã¤Â¸â€°Ã¤Â½ÂÃ¯Â¼â€ºÃ§Æ’Â­Ã§â€šÂ¹Ã¥â€¦Â³Ã©â€Â®Ã¨Â¯ÂÃ¦ËœÂ¯Ã§â€žÂ¦Ã¨â„¢â€˜Ã£â‚¬ÂÃ¥Â¤Â±Ã¨Â°Æ’Ã£â‚¬ÂÃ¥Â¤Â§Ã¨â€žâ€˜Ã§Â­â€°Ã£â‚¬â€šÃ¤Â¸Â­Ã¥â€ºÂ½Ã§Å¸Â¥Ã§Â½â€˜Ã¦â€¢Â°Ã¦ÂÂ®Ã¥Âºâ€œÃ¥â€¦Â±Ã§ÂºÂ³Ã¥â€¦Â¥ 529 Ã§Â¯â€¡Ã¦â€“â€¡Ã§Å’Â®Ã£â‚¬â€šÃ¥â€¦Â¶Ã¤Â¸Â­Ã¥Ââ€˜Ã¦â€“â€¡Ã©â€¡ÂÃ¦Å“â‚¬Ã¥Â¤Å¡Ã§Å¡â€žÃ¦Å“ÂºÃ¦Å¾â€žÃ¦ËœÂ¯Ã¥â€ºâ€ºÃ¥Â·ÂÃ¥Â¤Â§Ã¥Â­Â¦Ã¥ÂÅ½Ã¨Â¥Â¿Ã¥Å’Â»Ã©â„¢Â¢Ã¥Â¿Æ’Ã§Ââ€ Ã¥ÂÂ«Ã§â€Å¸Ã¤Â¸Â­Ã¥Â¿Æ’Ã¯Â¼â€ºÃ§Æ’Â­Ã§â€šÂ¹Ã¥â€¦Â³Ã©â€Â®Ã¨Â¯ÂÃ¦ËœÂ¯Ã¨â€žâ€˜Ã§â€ÂµÃ¤Â¿Â¡Ã¥ÂÂ·Ã£â‚¬ÂÃ¤Âºâ€¹Ã¤Â»Â¶Ã§â€ºÂ¸Ã¥â€¦Â³Ã§â€ÂµÃ¤Â½ÂÃ£â‚¬ÂÃ¥ÂÂ·Ã§Â§Â¯Ã§Â¥Å¾Ã§Â»ÂÃ§Â½â€˜Ã§Â»Å“Ã£â‚¬ÂÃ§Â²Â¾Ã§Â¥Å¾Ã¥Ë†â€ Ã¨Â£â€šÃ§â€”â€¡Ã§Â­â€°Ã£â‚¬â€šÃ¦Å“Â¬Ã§Â â€Ã§Â©Â¶Ã¥Ââ€˜Ã§Å½Â°Ã¥â€ºÂ½Ã¥â€ â€¦Ã¥Â¤â€“Ã¥Å“Â¨Ã¦Å â€˜Ã©Æ’ÂÃ§â€”â€¡Ã¨â€žâ€˜Ã§â€ÂµÃ§Â â€Ã§Â©Â¶Ã©Â¢â€ Ã¥Å¸Å¸Ã¥Ââ€˜Ã¥Â±â€¢Ã¨Â¿â€¦Ã©â‚¬Å¸Ã£â‚¬â€šÃ¥â€ºÂ½Ã©â„¢â€¦Ã¤Â¸Å Ã§Å¡â€žÃ§Â â€Ã§Â©Â¶Ã¦â€“Â¹Ã¥Ââ€˜Ã¤Â¸Â»Ã¨Â¦ÂÃ©â€ºâ€ Ã¤Â¸Â­Ã¤ÂºÅ½Ã¦Å½Â¢Ã§Â©Â¶Ã¦Å â€˜Ã©Æ’ÂÃ¦â€šÂ£Ã¨â‚¬â€¦Ã§ÂÂ¡Ã§Å“Â Ã¦â€”Â¶Ã§Å¡â€žÃ¨â€¡ÂªÃ¥Ââ€˜Ã¨â€žâ€˜Ã§â€ÂµÃ¨Å â€šÃ¥Â¾â€¹Ã§â€°Â¹Ã¥Â¾ÂÃ¥ÂÅ Ã©ÂÅ¾Ã§ÂºÂ¿Ã¦â‚¬Â§Ã¥Å Â¨Ã¥Å â€ºÃ¥Â­Â¦Ã¥Ââ€šÃ¦â€¢Â°Ã¤Â¸Å Ã£â‚¬â€šÃ¦Â­Â¤Ã¥Â¤â€“Ã¯Â¼Å’Ã¥â€ºÂ½Ã¥Â¤â€“Ã¥Â¯Â¹Ã¤ÂºÅ½Ã¥ÂÅ’Ã¦Â­Â¥Ã§Â»ÂÃ©Â¢â€¦Ã§Â£ÂÃ¥Ë†ÂºÃ¦Â¿â‚¬Ã¥â€™Å’Ã¨â€žâ€˜Ã§â€ÂµÃ¨Â¿â„¢Ã©Â¡Â¹Ã¦Å â‚¬Ã¦Å“Â¯Ã¤Â¹Å¸Ã¥Â¾Ë†Ã¥â€¦Â³Ã¦Â³Â¨Ã¯Â¼Å’Ã©Â¢â€žÃ¦Âµâ€¹Ã¦Å“ÂªÃ¦ÂÂ¥Ã§Å¡â€žÃ§Â â€Ã§Â©Â¶Ã§Æ’Â­Ã§â€šÂ¹Ã¤Â¸ÂºÃ©â€¡ÂÃ¦â‚¬Â§Ã¦Å â€˜Ã©Æ’ÂÃ§â€”â€¡Ã¦â€šÂ£Ã¨â‚¬â€¦Ã§Å¡â€žÃ¨â€žâ€˜Ã§â€ÂµÃ¨Â¯Å Ã¦â€“Â­Ã¦Å“ÂºÃ¥Ë†Â¶Ã§Â­â€°Ã¥Å¸ÂºÃ§Â¡â‚¬Ã§Â â€Ã§Â©Â¶Ã£â‚¬â€šÃ¥â€ºÂ½Ã¥â€ â€¦Ã¥Å“Â¨Ã¨Â¯Â¥Ã©Â¢â€ Ã¥Å¸Å¸Ã§Å¡â€žÃ§Â â€Ã§Â©Â¶Ã¥Ââ€˜Ã¥Â±â€¢Ã¥Â½Â¢Ã¥Â¼ÂÃ¨â€°Â¯Ã¥Â¥Â½Ã¯Â¼Å’Ã§Â â€Ã§Â©Â¶Ã¦â€“Â¹Ã¥Ââ€˜Ã¤Â¸Â»Ã¨Â¦ÂÃ©â€ºâ€ Ã¤Â¸Â­Ã¤ÂºÅ½Ã§Â²Â¾Ã§Â¥Å¾Ã¥Ë†â€ Ã¨Â£â€šÃ§â€”â€¡Ã¥â€™Å’Ã¦Å â€˜Ã©Æ’ÂÃ§â€”â€¡Ã¦â€šÂ£Ã¨â‚¬â€¦Ã©Ââ„¢Ã¦ÂÂ¯Ã¦â‚¬ÂÃ¨â€žâ€˜Ã§â€ÂµÃ¥Ë†â€ Ã§Â±Â»Ã¥ÂÅ Ã©Ââ„¢Ã¦ÂÂ¯Ã¦â‚¬ÂÃ¨â€žâ€˜Ã§â€ÂµÃ¥Å Å¸Ã§Å½â€¡Ã¨Â°Â±Ã§â€ ÂµÃ§Å¡â€žÃ¥Â¯Â¹Ã§â€¦Â§Ã§Â â€Ã§Â©Â¶Ã¤Â¸Å Ã¯Â¼Å’Ã©Â¢â€žÃ¦Âµâ€¹Ã¦Å“ÂªÃ¦ÂÂ¥Ã§Å¡â€žÃ§Â â€Ã§Â©Â¶Ã§Æ’Â­Ã§â€šÂ¹Ã¤Â¸ÂºÃ¦Å â€˜Ã©Æ’ÂÃ¦â€šÂ£Ã¨â‚¬â€¦Ã¥Â¹Â¶Ã¥Ââ€˜Ã§â€žÂ¦Ã¨â„¢â€˜Ã§â€”â€¡Ã§Å¡â€žÃ¥Å¸ÂºÃ§Â¡â‚¬Ã¥ÂÅ Ã¤Â¸Â´Ã¥ÂºÅ Ã¨â€žâ€˜Ã§â€ÂµÃ§Â â€Ã§Â©Â¶Ã£â‚¬â€š.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20779,""
"[Texture filtering based unsupervised registration methods and its application in liver computed tomography images]","Wang, Yan, Qian, Suo, Guo, Xu, Wang","https://doi.org/10.7507/1001-5515.202102001","20211101","PubMed","cascaded network; liver computed tomography images; texture filtering; texture similarity; unsupervised registration; Algorithms; Humans; Image Processing, Computer-Assisted; Liver Diseases; Tomography, X-Ray Computed","Image registration is of great clinical importance in computer aided diagnosis and surgical planning of liver diseases. Deep learning-based registration methods endow liver computed tomography (CT) image registration with characteristics of real-time and high accuracy. However, existing methods in registering images with large displacement and deformation are faced with the challenge of the texture information variation of the registered image, resulting in subsequent erroneous image processing and clinical diagnosis. To this end, a novel unsupervised registration method based on the texture filtering is proposed in this paper to realize liver CT image registration. Firstly, the texture filtering algorithm based on L0 gradient minimization eliminates the texture information of liver surface in CT images, so that the registration process can only refer to the spatial structure information of two images for registration, thus solving the problem of texture variation. Then, we adopt the cascaded network to register images with large displacement and large deformation, and progressively align the fixed image with the moving one in the spatial structure. In addition, a new registration metric, the histogram correlation coefficient, is proposed to measure the degree of texture variation after registration. Experimental results show that our proposed method achieves high registration accuracy, effectively solves the problem of texture variation in the cascaded network, and improves the registration performance in terms of spatial structure correspondence and anti-folding capability. Therefore, our method helps to improve the performance of medical image registration, and make the registration safely and reliably applied in the computer-aided diagnosis and surgical planning of liver diseases. Ã¥â€ºÂ¾Ã¥Æ’ÂÃ©â€¦ÂÃ¥â€¡â€ Ã¥Å“Â¨Ã¨â€šÂÃ¨â€žÂÃ§â€“Â¾Ã§â€”â€¦Ã§Å¡â€žÃ¨Â®Â¡Ã§Â®â€”Ã¦Å“ÂºÃ¨Â¾â€¦Ã¥Å Â©Ã¨Â¯Å Ã¦â€“Â­Ã¥â€™Å’Ã¦â€°â€¹Ã¦Å“Â¯Ã¨Â§â€žÃ¥Ë†â€™Ã¦â€“Â¹Ã©ÂÂ¢Ã¥â€¦Â·Ã¦Å“â€°Ã©â€¡ÂÃ¨Â¦ÂÃ§Å¡â€žÃ¤Â¸Â´Ã¥ÂºÅ Ã¦â€žÂÃ¤Â¹â€°Ã£â‚¬â€šÃ¥Å¸ÂºÃ¤ÂºÅ½Ã¦Â·Â±Ã¥ÂºÂ¦Ã¥Â­Â¦Ã¤Â¹Â Ã§Å¡â€žÃ©â€¦ÂÃ¥â€¡â€ Ã¦â€“Â¹Ã¦Â³â€¢Ã¤Â½Â¿Ã¥Â¾â€”Ã¨â€šÂÃ¨â€žÂÃ§â€ÂµÃ¥Â­ÂÃ¨Â®Â¡Ã§Â®â€”Ã¦Å“ÂºÃ¦â€“Â­Ã¥Â±â€šÃ¦â€°Â«Ã¦ÂÂÃ¯Â¼Ë†CTÃ¯Â¼â€°Ã¥â€ºÂ¾Ã¥Æ’ÂÃ©â€¦ÂÃ¥â€¡â€ Ã¥â€¦Â·Ã¦Å“â€°Ã¨Â¾Æ’Ã©Â«ËœÃ§Å¡â€žÃ¥Â®Å¾Ã¦â€”Â¶Ã¦â‚¬Â§Ã¥â€™Å’Ã¥â€¡â€ Ã§Â¡Â®Ã¥ÂºÂ¦Ã£â‚¬â€šÃ§â€žÂ¶Ã¨â‚¬Å’Ã¯Â¼Å’Ã§Å½Â°Ã¦Å“â€°Ã¦â€“Â¹Ã¦Â³â€¢Ã¥Å“Â¨Ã©â€¦ÂÃ¥â€¡â€ Ã¥â€¦Â·Ã¦Å“â€°Ã¥Â¤Â§Ã¤Â½ÂÃ§Â§Â»Ã¥â€™Å’Ã¥Â¤Â§Ã¥Â½Â¢Ã¥ÂËœÃ§Å¡â€žÃ¥â€ºÂ¾Ã¥Æ’ÂÃ¦â€”Â¶Ã¯Â¼Å’Ã¥Â­ËœÃ¥Å“Â¨Ã©â€¦ÂÃ¥â€¡â€ Ã¥ÂÅ½Ã¥â€ºÂ¾Ã¥Æ’ÂÃ§Å¡â€žÃ§ÂºÂ¹Ã§Ââ€ Ã¤Â¿Â¡Ã¦ÂÂ¯Ã¥Ââ€˜Ã§â€Å¸Ã¦â€Â¹Ã¥ÂËœÃ§Å¡â€žÃ©â€”Â®Ã©Â¢ËœÃ¯Â¼Å’Ã¥â€ºÂ Ã¨â‚¬Å’Ã©Å¡Â¾Ã¤Â»Â¥Ã¥Â°â€ Ã¥â€¦Â¶Ã¥Âºâ€Ã§â€Â¨Ã¥Å“Â¨Ã¥ÂÅ½Ã§Â»Â­Ã§Å¡â€žÃ¥â€ºÂ¾Ã¥Æ’ÂÃ¥Â¤â€žÃ§Ââ€ Ã¤Â¸Å½Ã¤Â¸Â´Ã¥ÂºÅ Ã¨Â¯Å Ã¦â€“Â­Ã¤Â¸Â­Ã£â‚¬â€šÃ¥Å¸ÂºÃ¤ÂºÅ½Ã¦Â­Â¤Ã¯Â¼Å’Ã¦Å“Â¬Ã¦â€“â€¡Ã¦ÂÂÃ¥â€¡ÂºÃ¤Â¸â‚¬Ã§Â§ÂÃ¦â€“Â°Ã©Â¢â€“Ã§Å¡â€žÃ¥Å¸ÂºÃ¤ÂºÅ½Ã§ÂºÂ¹Ã§Ââ€ Ã¦Â»Â¤Ã¦Â³Â¢Ã§Å¡â€žÃ¦â€”Â Ã§â€ºâ€˜Ã§ÂÂ£Ã©â€¦ÂÃ¥â€¡â€ Ã¦â€“Â¹Ã¦Â³â€¢Ã¯Â¼Å’Ã¥Â®Å¾Ã§Å½Â°Ã¤Âºâ€ Ã¨â€šÂÃ¨â€žÂ CT Ã¥â€ºÂ¾Ã¥Æ’ÂÃ§Å¡â€žÃ©â€¦ÂÃ¥â€¡â€ Ã£â‚¬â€šÃ¨Â¯Â¥Ã¦â€“Â¹Ã¦Â³â€¢Ã©Â¦â€“Ã¥â€¦Ë†Ã¥Å¸ÂºÃ¤ÂºÅ½ L0 Ã¦Â¢Â¯Ã¥ÂºÂ¦Ã¦Å“â‚¬Ã¥Â°ÂÃ¥Å’â€“Ã§Å¡â€žÃ§ÂºÂ¹Ã§Ââ€ Ã¦Â»Â¤Ã¦Â³Â¢Ã§Â®â€”Ã¦Â³â€¢Ã¦Â¶Ë†Ã©â„¢Â¤ CT Ã¥â€ºÂ¾Ã¥Æ’ÂÃ¤Â¸Â­Ã¨â€šÂÃ¨â€žÂÃ¨Â¡Â¨Ã©ÂÂ¢Ã§Å¡â€žÃ§ÂºÂ¹Ã§Ââ€ Ã¤Â¿Â¡Ã¦ÂÂ¯Ã¯Â¼Å’Ã¤Â½Â¿Ã¥Â¾â€”Ã©â€¦ÂÃ¥â€¡â€ Ã¨Â¿â€¡Ã§Â¨â€¹Ã¤Â»â€¦Ã¥Ââ€šÃ¨â‚¬Æ’Ã¤Â¸Â¤Ã¥Â¹â€¦Ã¥â€ºÂ¾Ã¥Æ’ÂÃ§Å¡â€žÃ§Â©ÂºÃ©â€”Â´Ã§Â»â€œÃ¦Å¾â€žÃ¤Â¿Â¡Ã¦ÂÂ¯Ã¨Â¿â€ºÃ¨Â¡Å’Ã©â€¦ÂÃ¥â€¡â€ Ã¯Â¼Å’Ã¤Â»Å½Ã¨â‚¬Å’Ã¨Â§Â£Ã¥â€ Â³Ã§ÂºÂ¹Ã§Ââ€ Ã¦â€Â¹Ã¥ÂËœÃ§Å¡â€žÃ©â€”Â®Ã©Â¢ËœÃ£â‚¬â€šÃ§â€žÂ¶Ã¥ÂÅ½Ã¯Â¼Å’Ã¥Å¸ÂºÃ¤ÂºÅ½Ã§ÂºÂ§Ã¨Ââ€Ã§Â½â€˜Ã§Â»Å“Ã©â€¦ÂÃ¥â€¡â€ Ã¥â€¦Â·Ã¦Å“â€°Ã¥Â¤Â§Ã¤Â½ÂÃ§Â§Â»Ã¥â€™Å’Ã¥Â¤Â§Ã¥Â½Â¢Ã¥ÂËœÃ§Å¡â€žÃ¥â€ºÂ¾Ã¥Æ’ÂÃ¯Â¼Å’Ã¥Â¾ÂªÃ¥ÂºÂÃ¦Â¸ÂÃ¨Â¿â€ºÃ¥Å“Â°Ã¥Â°â€ Ã¥Â¾â€¦Ã©â€¦ÂÃ¥â€¡â€ Ã¥â€ºÂ¾Ã¥Æ’ÂÃ¤Â¸Å½Ã¥Ââ€šÃ¨â‚¬Æ’Ã¥â€ºÂ¾Ã¥Æ’ÂÃ¥Å“Â¨Ã§Â©ÂºÃ©â€”Â´Ã§Â»â€œÃ¦Å¾â€žÃ¤Â¸Å Ã¥Â¯Â¹Ã©Â½ÂÃ£â‚¬â€šÃ¦Â­Â¤Ã¥Â¤â€“Ã¦Å“Â¬Ã¦â€“â€¡Ã¨Â¿ËœÃ¦ÂÂÃ¥â€¡ÂºÃ¤Â¸â‚¬Ã§Â§ÂÃ¦â€“Â°Ã§Å¡â€žÃ¨Â¡Â¡Ã©â€¡ÂÃ¦Å’â€¡Ã¦Â â€¡Ã¢â‚¬â€Ã¢â‚¬â€Ã§â€ºÂ´Ã¦â€“Â¹Ã¥â€ºÂ¾Ã§â€ºÂ¸Ã¥â€¦Â³Ã§Â³Â»Ã¦â€¢Â°Ã¯Â¼Å’Ã¤Â»Â¥Ã¨Â¡Â¡Ã©â€¡ÂÃ©â€¦ÂÃ¥â€¡â€ Ã¥ÂÅ½Ã§ÂºÂ¹Ã§Ââ€ Ã¦â€Â¹Ã¥ÂËœÃ§Å¡â€žÃ§Â¨â€¹Ã¥ÂºÂ¦Ã£â‚¬â€šÃ¥Â®Å¾Ã©ÂªÅ’Ã§Â»â€œÃ¦Å¾Å“Ã¨Â¡Â¨Ã¦ËœÅ½Ã¯Â¼Å’Ã¦Å“Â¬Ã¦â€“â€¡Ã¦â€°â‚¬Ã¦ÂÂÃ¥â€¡ÂºÃ§Å¡â€žÃ¦â€“Â¹Ã¦Â³â€¢Ã¥â€¦Â·Ã¦Å“â€°Ã¨Â¾Æ’Ã©Â«ËœÃ§Å¡â€žÃ©â€¦ÂÃ¥â€¡â€ Ã§Â²Â¾Ã¥ÂºÂ¦Ã¯Â¼Å’Ã¦Å“â€°Ã¦â€¢Ë†Ã¥Å“Â°Ã¦â€Â¹Ã¥â€“â€žÃ¤Âºâ€ Ã§ÂºÂ§Ã¨Ââ€Ã§Â½â€˜Ã§Â»Å“Ã¤Â¸Â­Ã¥Â­ËœÃ¥Å“Â¨Ã§ÂºÂ¹Ã§Ââ€ Ã¦â€Â¹Ã¥ÂËœÃ§Å¡â€žÃ©â€”Â®Ã©Â¢ËœÃ¯Â¼Å’Ã¥Â¹Â¶Ã¤Â¸â€Ã¦ÂÂÃ¥Ââ€¡Ã¤Âºâ€ Ã¥Å“Â¨Ã§Â©ÂºÃ©â€”Â´Ã§Â»â€œÃ¦Å¾â€žÃ¥Â¯Â¹Ã¥Âºâ€Ã¥â€™Å’Ã¦Å â€”Ã¦Å ËœÃ¥ÂÂ Ã¦â‚¬Â§Ã¨Æ’Â½Ã¤Â¸Â¤Ã¦â€“Â¹Ã©ÂÂ¢Ã§Å¡â€žÃ©â€¦ÂÃ¥â€¡â€ Ã¦â€¢Ë†Ã¦Å¾Å“Ã£â‚¬â€šÃ¥â€ºÂ Ã¦Â­Â¤Ã¯Â¼Å’Ã¦Å“Â¬Ã¦â€“â€¡Ã¦â€°â‚¬Ã¦ÂÂÃ¦â€“Â¹Ã¦Â³â€¢Ã¦Ë†â€“Ã¦Å“â€°Ã¥Å Â©Ã¤ÂºÅ½Ã¦ÂÂÃ¥Ââ€¡Ã¥Å’Â»Ã¥Â­Â¦Ã¥â€ºÂ¾Ã¥Æ’ÂÃ©â€¦ÂÃ¥â€¡â€ Ã§Å¡â€žÃ§Â§â€˜Ã¥Â­Â¦Ã¦â‚¬Â§Ã¯Â¼Å’Ã¤Â¿Æ’Ã¨Â¿â€ºÃ¥Å’Â»Ã¥Â­Â¦Ã¥â€ºÂ¾Ã¥Æ’ÂÃ©â€¦ÂÃ¥â€¡â€ Ã¥Â®â€°Ã¥â€¦Â¨Ã¥ÂÂ¯Ã©ÂÂ Ã¥Å“Â°Ã¥Âºâ€Ã§â€Â¨Ã¥Å“Â¨Ã¨â€šÂÃ¨â€žÂÃ§â€“Â¾Ã§â€”â€¦Ã§Å¡â€žÃ¨Â®Â¡Ã§Â®â€”Ã¦Å“ÂºÃ¨Â¾â€¦Ã¥Å Â©Ã¨Â¯Å Ã¦â€“Â­Ã¥â€™Å’Ã¦â€°â€¹Ã¦Å“Â¯Ã¨Â§â€žÃ¥Ë†â€™Ã¦â€“Â¹Ã©ÂÂ¢Ã£â‚¬â€š.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20780,""
"Cognitive Impairments in Schizophrenia: A Study in a Large Clinical Sample Using Natural Language Processing","Mascio, Stewart, Botelle, Williams, Mirza, Patel, Pollak, Dobson, Roberts","https://doi.org/10.3389/fdgth.2021.711941","20211030","PubMed","cognition; data mining; electronic health records; natural language processing; schizophrenia","<b>Background:</b> Cognitive impairments are a neglected aspect of schizophrenia despite being a major factor of poor functional outcome. They are usually measured using various rating scales, however, these necessitate trained practitioners and are rarely routinely applied in clinical settings. Recent advances in natural language processing techniques allow us to extract such information from unstructured portions of text at a large scale and in a cost effective manner. We aimed to identify cognitive problems in the clinical records of a large sample of patients with schizophrenia, and assess their association with clinical outcomes. <b>Methods:</b> We developed a natural language processing based application identifying cognitive dysfunctions from the free text of medical records, and assessed its performance against a rating scale widely used in the United Kingdom, the cognitive component of the Health of the Nation Outcome Scales (HoNOS). Furthermore, we analyzed cognitive trajectories over the course of patient treatment, and evaluated their relationship with various socio-demographic factors and clinical outcomes. <b>Results:</b> We found a high prevalence of cognitive impairments in patients with schizophrenia, and a strong correlation with several socio-demographic factors (gender, education, ethnicity, marital status, and employment) as well as adverse clinical outcomes. Results obtained from the free text were broadly in line with those obtained using the HoNOS subscale, and shed light on additional associations, notably related to attention and social impairments for patients with higher education. <b>Conclusions:</b> Our findings demonstrate that cognitive problems are common in patients with schizophrenia, can be reliably extracted from clinical records using natural language processing, and are associated with adverse clinical outcomes. Harvesting the free text from medical records provides a larger coverage in contrast to neurocognitive batteries or rating scales, and access to additional socio-demographic and clinical variables. Text mining tools can therefore facilitate large scale patient screening and early symptoms detection, and ultimately help inform clinical decisions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20781,""
"Trends in COVID-19 Publications: Streamlining Research Using NLP and LDA","Gupta, Aeron, Agrawal, Gupta","https://doi.org/10.3389/fdgth.2021.686720","20211030","PubMed","COVID-19; LitCovid; Pubmed; latent dirichlet allocation; natural language processing; topic model; trends","<b>Background:</b> Research publications related to the novel coronavirus disease COVID-19 are rapidly increasing. However, current online literature hubs, even with artificial intelligence, are limited in identifying the complexity of COVID-19 research topics. We developed a comprehensive Latent Dirichlet Allocation (LDA) model with 25 topics using natural language processing (NLP) techniques on PubMedÃ‚Â® research articles about ""COVID."" We propose a novel methodology to develop and visualise temporal trends, and improve existing online literature hubs. Our results for temporal evolution demonstrate interesting trends, for example, the prominence of ""Mental Health"" and ""Socioeconomic Impact"" increased, ""Genome Sequence"" decreased, and ""Epidemiology"" remained relatively constant. Applying our methodology to LitCovid, a literature hub from the National Center for Biotechnology Information, we improved the breadth and depth of research topics by subdividing their pre-existing categories. Our topic model demonstrates that research on ""masks"" and ""Personal Protective Equipment (PPE)"" is skewed toward clinical applications with a lack of population-based epidemiological research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20782,""
"How to Design a Relevant Corpus for Sleepiness Detection Through Voice?","Martin, Rouas, Micoulaud-Franchi, Philip, Krajewski","https://doi.org/10.3389/fdgth.2021.686068","20211030","PubMed","corpus design; guidelines; methodological issue; sleepiness; speech processing","This article presents research on the detection of pathologies affecting speech through automatic analysis. Voice processing has indeed been used for evaluating several diseases such as Parkinson, Alzheimer, or depression. If some studies present results that seem sufficient for clinical applications, this is not the case for the detection of sleepiness. Even two international challenges and the recent advent of deep learning techniques have still not managed to change this situation. This article explores the hypothesis that the observed average performances of automatic processing find their cause in the design of the corpora. To this aim, we first discuss and refine the concept of <i>sleepiness</i> related to the ground-truth labels. Second, we present an in-depth study of four corpora, bringing to light the methodological choices that have been made and the underlying biases they may have induced. Finally, in light of this information, we propose guidelines for the design of new corpora.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20783,""
"The Potential of Research Drawing on Clinical Free Text to Bring Benefits to Patients in the United Kingdom: A Systematic Review of the Literature","Ford, Curlewis, Squires, Griffiths, Stewart, Jones","https://doi.org/10.3389/fdgth.2021.606599","20211030","PubMed","clinical free text; data governance; natural language processing; patient benefit; privacy; text analysis","<b>Background:</b> The analysis of clinical free text from patient records for research has potential to contribute to the medical evidence base but access to clinical free text is frequently denied by data custodians who perceive that the privacy risks of data-sharing are too high. Engagement activities with patients and regulators, where views on the sharing of clinical free text data for research have been discussed, have identified that stakeholders would like to understand the potential clinical benefits that could be achieved if access to free text for clinical research were improved. We aimed to systematically review all UK research studies which used clinical free text and report direct or potential benefits to patients, synthesizing possible benefits into an easy to communicate taxonomy for public engagement and policy discussions. <b>Methods:</b> We conducted a systematic search for articles which reported primary research using clinical free text, drawn from UK health record databases, which reported a benefit or potential benefit for patients, actionable in a clinical environment or health service, and not solely methods development or data quality improvement. We screened eligible papers and thematically analyzed information about clinical benefits reported in the paper to create a taxonomy of benefits. <b>Results:</b> We identified 43 papers and derived five themes of benefits: health-care quality or services improvement, observational risk factor-outcome research, drug prescribing safety, case-finding for clinical trials, and development of clinical decision support. Five papers compared study quality with and without free text and found an improvement of accuracy when free text was included in analytical models. <b>Conclusions:</b> Findings will help stakeholders weigh the potential benefits of free text research against perceived risks to patient privacy. The taxonomy can be used to aid public and policy discussions, and identified studies could form a public-facing repository which will help the health-care text analysis research community better communicate the impact of their work.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20784,""
"Machine Learning for Localizing Epileptogenic-Zone in the Temporal Lobe: Quantifying the Value of Multimodal Clinical-Semiology and Imaging Concordance","Alim-Marvasti, PÃƒÂ©rez-GarcÃƒÂ­a, Dahele, Romagnoli, Diehl, Sparks, Ourselin, Clarkson, Duncan","https://doi.org/10.3389/fdgth.2021.559103","20211030","PubMed","epilepsy surgery; epileptogenic zone; gradient boost classifier; hippocampal sclerosis; linear support vector classifier; machine learning; semiology; temporal lobe epilepsy","<b>Background:</b> Epilepsy affects 50 million people worldwide and a third are refractory to medication. If a discrete cerebral focus or network can be identified, neurosurgical resection can be curative. Most excisions are in the temporal-lobe, and are more likely to result in seizure-freedom than extra-temporal resections. However, less than half of patients undergoing surgery become entirely seizure-free. Localizing the epileptogenic-zone and individualized outcome predictions are difficult, requiring detailed evaluations at specialist centers. <b>Methods:</b> We used bespoke natural language processing to text-mine 3,800 electronic health records, from 309 epilepsy surgery patients, evaluated over a decade, of whom 126 remained entirely seizure-free. We investigated the diagnostic performances of machine learning models using set-of-semiology (SoS) with and without hippocampal sclerosis (HS) on MRI as features, using STARD criteria. <b>Findings:</b> Support Vector Classifiers (SVC) and Gradient Boosted (GB) decision trees were the best performing algorithms for temporal-lobe epileptogenic zone localization (cross-validated Matthews correlation coefficient (MCC) SVC 0.73 Ã‚Â± 0.25, balanced accuracy 0.81 Ã‚Â± 0.14, AUC 0.95 Ã‚Â± 0.05). Models that only used seizure semiology were not always better than internal benchmarks. The combination of multimodal features, however, enhanced performance metrics including MCC and normalized mutual information (NMI) compared to either alone (<i>p</i> &lt; 0.0001). This combination of semiology and HS on MRI increased both cross-validated MCC and NMI by over 25% (NMI, SVC SoS: 0.35 Ã‚Â± 0.28 vs. SVC SoS+HS: 0.61 Ã‚Â± 0.27). <b>Interpretation:</b> Machine learning models using only the set of seizure semiology (SoS) cannot unequivocally perform better than benchmarks in temporal epileptogenic-zone localization. However, the combination of SoS with an imaging feature (HS) enhance epileptogenic lobe localization. We quantified this added NMI value to be 25% in absolute terms. Despite good performance in localization, no model was able to predict seizure-freedom better than benchmarks. The methods used are widely applicable, and the performance enhancements by combining other clinical, imaging and neurophysiological features could be similarly quantified. Multicenter studies are required to confirm generalizability. <b>Funding:</b> Wellcome/EPSRC Center for Interventional and Surgical Sciences (WEISS) (203145Z/16/Z).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20785,""
"Toward an Ethical Framework for the Text Mining of Social Media for Health Research: A Systematic Review","Ford, Shepherd, Jones, Hassan","https://doi.org/10.3389/fdgth.2020.592237","20211030","PubMed","ethics; health research; natural language processing; social media; text-mining","<b>Background:</b> Text-mining techniques are advancing all the time and vast corpora of social media text can be analyzed for users' views and experiences related to their health. There is great promise for new insights into health issues such as drug side effects and spread of disease, as well as patient experiences of health conditions and health care. However, this emerging field lacks ethical consensus and guidance. We aimed to bring together a comprehensive body of opinion, views, and recommendations in this area so that academic researchers new to the field can understand relevant ethical issues. <b>Methods:</b> After registration of a protocol in PROSPERO, three parallel systematic searches were conducted, to identify academic articles comprising commentaries, opinion, and recommendations on ethical practice in social media text mining for health research and gray literature guidelines and recommendations. These were integrated with social media users' views from qualitative studies. Papers and reports that met the inclusion criteria were analyzed thematically to identify key themes, and an overarching set of themes was deduced. <b>Results:</b> A total of 47 reports and articles were reviewed, and eight themes were identified. Commentators suggested that publicly posted social media data could be used without consent and formal research ethics approval, provided that the anonymity of users is ensured, although we note that privacy settings are difficult for users to navigate on some sites. Even without the need for formal approvals, we note ethical issues: to actively identify and minimize possible harms, to conduct research for public benefit rather than private gain, to ensure transparency and quality of data access and analysis methods, and to abide by the law and terms and conditions of social media sites. <b>Conclusion:</b> Although social media text mining can often legally and reasonably proceed without formal ethics approvals, we recommend improving ethical standards in health-related research by increasing transparency of the purpose of research, data access, and analysis methods; consultation with social media users and target groups to identify and mitigate against potential harms that could arise; and ensuring the anonymity of social media users.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20786,""
"Applying Artificial Intelligence Methods for the Estimation of Disease Incidence: The Utility of Language Models","Zhang, Walecki, Winter, Bragman, Lourenco, Hart, Baker, Perov, Johri","https://doi.org/10.3389/fdgth.2020.569261","20211030","PubMed","deep learning; disease incidence; health statistic data; machine learning; natural language processing","<b>Background:</b> AI-driven digital health tools often rely on estimates of disease incidence or prevalence, but obtaining these estimates is costly and time-consuming. We explored the use of machine learning models that leverage contextual information about diseases from unstructured text, to estimate disease incidence. <b>Methods:</b> We used a class of machine learning models, called language models, to extract contextual information relating to disease incidence. We evaluated three different language models: BioBERT, Global Vectors for Word Representation (GloVe), and the Universal Sentence Encoder (USE), as well as an approach which uses all jointly. The output of these models is a mathematical representation of the underlying data, known as ""embeddings."" We used these to train neural network models to predict disease incidence. The neural networks were trained and validated using data from the Global Burden of Disease study, and tested using independent data sourced from the epidemiological literature. <b>Findings:</b> A variety of language models can be used to encode contextual information of diseases. We found that, on average, BioBERT embeddings were the best for disease names across multiple tasks. In particular, BioBERT was the best performing model when predicting specific disease-country pairs, whilst a fusion model combining BioBERT, GloVe, and USE performed best on average when predicting disease incidence in unseen countries. We also found that GloVe embeddings performed better than BioBERT embeddings when applied to country names. However, we also noticed that the models were limited in view of predicting previously unseen diseases. Further limitations were also observed with substantial variations across age groups and notably lower performance for diseases that are highly dependent on location and climate. <b>Interpretation:</b> We demonstrate that context-aware machine learning models can be used for estimating disease incidence. This method is quicker to implement than traditional epidemiological approaches. We therefore suggest it complements existing modeling efforts, where data is required more rapidly or at larger scale. This may particularly benefit AI-driven digital health products where the data will undergo further processing and a validated approximation of the disease incidence is adequate.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20787,""
"Detection of Mild Cognitive Impairment Through Natural Language and Touchscreen Typing Processing","Ntracha, Iakovakis, Hadjidimitriou, Charisis, Tsolaki, Hadjileontiadis","https://doi.org/10.3389/fdgth.2020.567158","20211030","PubMed","Alzheimer's disease; deep learning; fine motor impairment; keystroke dynamics; machine learning; natural language processing; remote screening; smartphone","Mild cognitive impairment (MCI), an identified prodromal stage of Alzheimer's Disease (AD), often evades detection in the early stages of the condition, when existing diagnostic methods are employed in the clinical setting. From an alternative perspective, smartphone interaction behavioral data, unobtrusively acquired in a non-clinical setting, can assist the screening and monitoring of MCI and its symptoms' progression. In this vein, the diagnostic ability of digital biomarkers, drawn from Fine Motor Impairment (FMI)- and Spontaneous Written Speech (SWS)-related data analysis, are examined here. In particular, keystroke dynamics derived from touchscreen typing activities, using Convolutional Neural Networks, along with linguistic features of SWS through Natural Language Processing (NLP), were used to distinguish amongst MCI patients and healthy controls (HC). Analytically, three indices of FMI (rigidity, bradykinesia and alternate finger tapping) and nine NLP features, related with lexical richness, grammatical, syntactical complexity, and word deficits, formed the feature space. The proposed approach was tested on two demographically matched groups of 11 MCI patients and 12 HC, having undergone the same neuropsychological tests, producing 4,930 typing sessions and 78 short texts, within 6 months, for analysis. A cascaded-classifier scheme was realized under three different feature combinations and validated via a Leave-One-Subject-Out cross-validation scheme. The acquired results have shown: (a) keystroke features with a k-NN classifier achieved an Area Under Curve (AUC) of 0.78 [95% confidence interval (CI):0.68-0.88; specificity/sensitivity (SP/SE): 0.64/0.92], (b) NLP features with a Logistic regression classifier achieved an AUC of 0.76 (95% CI: 0.65-0.85; SP/SE: 0.80/0.71), and (c) an ensemble model with the fusion of keystroke and NLP features resulted in AUC of 0.75 (95% CI:0.63-0.86; SP/SE 0.90/0.60). The current findings indicate the potentiality of new digital biomarkers to capture early stages of cognitive decline, providing a highly specific remote screening tool in-the-wild.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20788,""
"Development and validation of an automated methodology to assess perceptual <i>in vivo</i> noise texture in liver CT","Smith, Abadi, Sauer, Fu, Solomon, Samei","https://doi.org/10.1117/1.JMI.8.5.052113","20211030","PubMed","computed tomography; image quality; noise texture; patient-specific","<b>Purpose</b>: Developing, validating, and evaluating a method for measuring noise texture directly from patient liver CT images (i.e., <i>in vivo</i>). <b>Approach</b>: The method identifies target regions within patient scans that are least likely to have major contribution of patient anatomy, detrends them locally, and measures noise power spectrum (NPS) there using a previously phantom-validated technique targeting perceptual noise-non-anatomical fluctuations in the image that may interfere with the detection of focal lesions. Method development and validation used scanner-specific CT simulations of computational, anthropomorphic phantom (XCAT phantom, three phases of contrast-enhancement) with known ground truth of the NPS. Simulations were based on a clinical scanner (Definition Flash, Siemens) and clinically relevant settings (tube voltage of 120Ã‚Â kV at three dose levels). Images were reconstructed with filtered backprojection (kernel: B31, B41, and B50) and Sinogram Affirmed Iterative Reconstruction (kernel: I31, I41, and I50) using a manufacturer-specific reconstruction software (ReconCT, Siemens). All NPS measurements were made in the liver. Ground-truth NPS were taken as the sum of (1)Ã‚Â a measurement in parenchymal regions of anatomy-subtracted (i.e., noise only) scans, and (2)Ã‚Â a measurement in the same region of noise-free (pre-noise-insertion) images. To assess <i>in vivo</i> NPS performance, correlation of NPS average frequency ( <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:mrow> <mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow> <mml:mrow><mml:mi>avg</mml:mi></mml:mrow> </mml:msub> </mml:mrow> </mml:math> ), was reported. Sensitivity of accuracy [root-mean-square-error (RMSE)] to number of pixels included in measurement was conducted via bootstrapped pixel-dropout. Sensitivity of NPS to dose and reconstruction kernel was assessed to confirm that ground truth NPS similarities were maintained in patient-specific measurements. <b>Results</b>: Pearson and Spearman correlation coefficients 0.97 and 0.96 for <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:mrow> <mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow> <mml:mrow><mml:mi>avg</mml:mi></mml:mrow> </mml:msub> </mml:mrow> </mml:math> indicated good correlation. Results suggested accurate NPS measurements (within 5% total RMSE) could be acquired with <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mrow><mml:mo>Ã¢Ë†Â¼</mml:mo> <mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow> <mml:mrow><mml:mn>6</mml:mn></mml:mrow> </mml:msup> <mml:mtext>Ã¢â‚¬â€°Ã¢â‚¬â€°</mml:mtext> <mml:mtext>pixels</mml:mtext></mml:mrow> </mml:math> . <b>Conclusions</b>: Relationships of similar NPS due to reconstruction kernel and dose were preserved between gold standard and observed <i>in vivo</i> estimations. The NPS estimation method was further deployed on clinical cases to demonstrate the feasibility of clinical analysis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20789,""
"Applied machine learning in cancer research: A systematic review for patient diagnosis, classification and prognosis","Kourou, Exarchos, Papaloukas, Sakaloglou, Exarchos, Fotiadis","https://doi.org/10.1016/j.csbj.2021.10.006","20211030","PubMed","Artificial intelligence; Cancer prognosis; Clinical outcome prediction; Explainability; Machine learning; Survival; Transparency; Trustworthiness","Artificial Intelligence (AI) has recently altered the landscape of cancer research and medical oncology using traditional Machine Learning (ML) algorithms and cutting-edge Deep Learning (DL) architectures. In this review article we focus on the ML aspect of AI applications in cancer research and present the most indicative studies with respect to the ML algorithms and data used. The PubMed and dblp databases were considered to obtain the most relevant research works of the last five years. Based on a comparison of the proposed studies and their research clinical outcomes concerning the medical ML application in cancer research, three main clinical scenarios were identified. We give an overview of the well-known DL and Reinforcement Learning (RL) methodologies, as well as their application in clinical practice, and we briefly discuss Systems Biology in cancer research. We also provide a thorough examination of the clinical scenarios with respect to disease diagnosis, patient classification and cancer prognosis and survival. The most relevant studies identified in the preceding year are presented along with their primary findings. Furthermore, we examine the effective implementation and the main points that need to be addressed in the direction of robustness, explainability and transparency of predictive models. Finally, we summarize the most recent advances in the field of AI/ML applications in cancer research and medical oncology, as well as some of the challenges and open issues that need to be addressed before data-driven models can be implemented in healthcare systems to assist physicians in their daily practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20790,""
"Clinical impact and quality of randomized controlled trials involving interventions evaluating artificial intelligence prediction tools: a systematic review","Zhou, Chen, Cao, Peng","https://doi.org/10.1038/s41746-021-00524-2","20211101","PubMed","","The evidence of the impact of traditional statistical (TS) and artificial intelligence (AI) tool interventions in clinical practice was limited. This study aimed to investigate the clinical impact and quality of randomized controlled trials (RCTs) involving interventions evaluating TS, machine learning (ML), and deep learning (DL) prediction tools. A systematic review on PubMed was conducted to identify RCTs involving TS/ML/DL tool interventions in the past decade. A total of 65 RCTs from 26,082 records were included. A majority of them had model development studies and generally good performance was achieved. The function of TS and ML tools in the RCTs mainly included assistive treatment decisions, assistive diagnosis, and risk stratification, but DL trials were only conducted for assistive diagnosis. Nearly two-fifths of the trial interventions showed no clinical benefit compared to standard care. Though DL and ML interventions achieved higher rates of positive results than TS in the RCTs, in trials with low risk of bias (17/65) the advantage of DL to TS was reduced while the advantage of ML to TS disappeared. The current applications of DL were not yet fully spread performed in medicine. It is predictable that DL will integrate more complex clinical problems than ML and TS tools in the future. Therefore, rigorous studies are required before the clinical application of these tools.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20791,""
"Automated caries detection in vivo using a 3D intraoral scanner","Michou, Lambach, Ntovas, Benetti, Bakhshandeh, Rahiotis, Ekstrand, Vannahme","https://doi.org/10.1038/s41598-021-00259-w","20211102","PubMed","","The use of 3D intraoral scanners (IOS) and software that can support automated detection and objective monitoring of oral diseases such as caries, tooth wear or periodontal diseases, is increasingly receiving attention from researchers and industry. This study clinically validates an automated caries scoring system for occlusal caries detection and classification, previously defined for an IOS system featuring fluorescence (TRIOS 4, 3Shape TRIOS A/S, Denmark). Four algorithms (ALG1, ALG2, ALG3, ALG4) are assessed for the IOS; the first three are based only on fluorescence information, while ALG4 also takes into account the tooth color information. The diagnostic performance of these automated algorithms is compared with the diagnostic performance of the clinical visual examination, while histological assessment is used as reference. Additionally, possible differences between in vitro and in vivo diagnostic performance of the IOS system are investigated. The algorithms show comparable in vivo diagnostic performance to the visual examination with no significant difference in the area under the ROC curves ([Formula: see text]). Only minor differences between their in vitro and in vivo diagnostic performance are noted but no significant differences in the area under the ROC curves, ([Formula: see text]). This novel IOS system exhibits encouraging performance for clinical application on occlusal caries detection and classification. Different approaches can be investigated for possible optimization of the system.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20792,""
"Systematic review of current natural language processing methods and applications in cardiology","Reading Turchioe, Volodarskiy, Pathak, Wright, Tcheng, Slotwiner","https://doi.org/10.1136/heartjnl-2021-319769","20211029","PubMed","coronary artery disease; electronic health records; electrophysiology; heart failure","Natural language processing (NLP) is a set of automated methods to organise and evaluate the information contained in unstructured clinical notes, which are a rich source of real-world data from clinical care that may be used to improve outcomes and understanding of disease in cardiology. The purpose of this systematic review is to provide an understanding of NLP, review how it has been used to date within cardiology and illustrate the opportunities that this approach provides for both research and clinical care. We systematically searched six scholarly databases (ACM Digital Library, Arxiv, Embase, IEEE Explore, PubMed and Scopus) for studies published in 2015-2020 describing the development or application of NLP methods for clinical text focused on cardiac disease. Studies not published in English, lacking a description of NLP methods, non-cardiac focused and duplicates were excluded. Two independent reviewers extracted general study information, clinical details and NLP details and appraised quality using a checklist of quality indicators for NLP studies. We identified 37 studies developing and applying NLP in heart failure, imaging, coronary artery disease, electrophysiology, general cardiology and valvular heart disease. Most studies used NLP to identify patients with a specific diagnosis and extract disease severity using rule-based NLP methods. Some used NLP algorithms to predict clinical outcomes. A major limitation is the inability to aggregate findings across studies due to vastly different NLP methods, evaluation and reporting. This review reveals numerous opportunities for future NLP work in cardiology with more diverse patient samples, cardiac diseases, datasets, methods and applications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20793,""
"Emerging technologies in brachytherapy","Song, Robar, MorÃƒÂ©n, Larsson, Carlsson Tedgren, Jia","https://doi.org/10.1088/1361-6560/ac344d","20211028","PubMed","3D Printing; Deep Learning; Emerging Technologies in Brachytherapy; Intensity Modulated Brachytherapy; Plan Optimization","Brachytherapy is a mature treatment modality. The literature is abundant in terms of review articles and comprehensive books on the latest established as well as evolving clinical practices. The intent of this article is to part ways and look beyond the current state-of-the-art and review emerging technologies that are noteworthy and perhaps may drive the future innovations in the field. There are plenty of candidate topics that deserve a deeper look, of course, but with practical limits in this communicative platform, we explore four topics that perhaps is worthwhile to review in detail at this time. First, intensity modulated brachytherapy (IMBT) is reviewed. The IMBT takes advantage of anisotropic radiation profile generated through intelligent high-density shielding designs incorporated onto sources and applicators such to achieve high quality plans. Second, emerging applications of 3D printing (i.e., additive manufacturing) in brachytherapy are reviewed. With the advent of 3D printing, interest in this technology in brachytherapy has been immense and translation swift due to their potential to tailor applicators and treatments customizable to each individual patient. This is followed by, in third, innovations in treatment planning concerning catheter placement and dwell times where new modelling approaches, solution algorithms, and technological advances are reviewed. And, fourth and lastly, applications of a new machine learning technique, called deep learning, which has the potential to improve and automate all aspects of brachytherapy workflow, are reviewed. We do not expect that all ideas and innovations reviewed in this article will ultimately reach clinic but, nonetheless, this review provides a decent glimpse of what is to come. It would be exciting to monitor as IMBT, 3D printing, novel optimization algorithms, and deep learning technologies evolve over time and translate into pilot testing and sensibly phased clinical trials, and ultimately make a difference for cancer patients. Today's fancy is tomorrow's reality. The future is bright for brachytherapy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20794,""
"Narrative review of artificial intelligence in diabetic macular edema: Diagnosis and predicting treatment response using optical coherence tomography","Chakroborty, Gupta, Devishamani, Patel, Ankit, Ganesh Babu, Raman","https://doi.org/10.4103/ijo.IJO_1482_21","20211102","PubMed","Anti-VEGF treatment options; CNN; DME detection; Lucentis; RF; SVM; deep learning; diabetic macular edema; diabetic population; machine learning; ranibizumab; regression; visual outcomes","Diabetic macular edema (DME), being a frequent manifestation of DR, disrupts the retinal symmetry. This event is particularly triggered by vascular endothelial growth factors (VEGF). Intravitreal injections of anti-VEGFs have been the most practiced treatment but an expensive option. A major challenge associated with this treatment is determining an optimal treatment regimen and differentiating patients who do not respond to anti-VEGF. As it has a significant burden for both the patient and the health care providers if the patient is not responding, any clinically acceptable method to predict the treatment outcomes holds huge value in the efficient management of DME. In such situations, artificial intelligence (AI) or machine learning (ML)-based algorithms come useful as they can analyze past clinical details of the patients and help clinicians to predict the patient's response to an anti-VEGF agent. The work presented here attempts to review the literature that is available from the peer research community to discuss solutions provided by AI/ML methodologies to tackle challenges in DME management. Lastly, a possibility for using two different types of data has been proposed, which is believed to be the key differentiators as compared to the similar and recent contributions from the peer research community.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20795,""
"Capacity building in screening and treatment of diabetic retinopathy in Asia-Pacific region","Silpa-Archa, Limwattanayingyong, Tadarati, Amphornphruet, Ruamviboonsuk","https://doi.org/10.4103/ijo.IJO_1075_21","20211102","PubMed","Capacity building; diabetic retinopathy screening; diabetic retinopathy treatment; health workforce; nurse-led intravitreal injection","The focus of capacity building for screening and treatment of diabetic retinopathy (DR) is on health professionals who are nonophthalmologists. Both physicians and nonphysicians are recruited for screening DR. Although there is no standardization of the course syllabus for the capacity building, it is generally accepted to keep their sensitivity &gt;80%, specificity &gt;95%, and clinical failure rate &lt;5% for the nonophthalmologists, if possible. A systematic literature search was performed using the PubMed database and the following search terms: diabetic retinopathy, diabetic retinopathy screening, Asia, diabetic retinopathy treatment, age-related macular degeneration, capacity building, deep learning, artificial intelligence (AI), nurse-led clinic, and intravitreal injection (IVI). AI may be a tool for improving their capacity. Capacity building on IVIs of antivascular endothelial growth factors for DR is focused on nurses. There is evidence that, after a supervision of an average of 100 initial injections, the trained nurses can do the injections effectively and safely, the rate of endophthalmitis ranges from 0.03 to 0.07%, comparable to ophthalmologists. However, laws and regulations, which are different among countries, are challenges and barriers for nonophthalmologists, particularly for nonphysicians, for both screening and treatment of DR. Even if nonphysicians or physicians who are nonophthalmologists are legally approved for these tasks, sustainability of the capacity is another important challenge, this may be achieved if the capacity building can be part of their career development. Patient acceptability is another important barrier for initiating care provided by nonophthalmologists, particularly in Asia. There are also collaborations between national eye institutes of high-income countries, nongovernment organizations, and local eye institutes to improve both the quality and quantity of ophthalmologists and retinal specialists in low-income countries in Asia. This approach may require more labor, cost, and time consuming than training nonophthalmologists.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20796,""
"Exploring the ""Dark Matter"" of Social Interaction: Systematic Review of a Decade of Research in Spontaneous Interpersonal Coordination","Ayache, Connor, Marks, Kuss, Rhodes, Sumich, Heym","https://doi.org/10.3389/fpsyg.2021.718237","20211030","PubMed","<CopyrightInformation>Copyright Ã‚Â© 2021 Ayache, Connor, Marks, Kuss, Rhodes, Sumich and Heym.</CopyrightInformation></Abstract><AuthorList CompleteYN=""Y""><Author ValidYN=""Y""><LastName>Ayache</LastName><ForeName>Julia</ForeName><Initials>J</Initials><AffiliationInfo><Affiliation>Department of Psychology, Nottingham Trent University, Nottingham, United Kingdom.</Affiliation></AffiliationInfo></Author><Author ValidYN=""Y""><LastName>Connor</LastName><ForeName>Andy</ForeName><Initials>A</Initials><AffiliationInfo><Affiliation>School of Future Environments, Auckland University of Technology, Auckland, New Zealand.</Affiliation></AffiliationInfo></Author><Author ValidYN=""Y""><LastName>Marks</LastName><ForeName>Stefan</ForeName><Initials>S</Initials><AffiliationInfo><Affiliation>School of Future Environments, Auckland University of Technology, Auckland, New Zealand.</Affiliation></AffiliationInfo></Author><Author ValidYN=""Y""><LastName>Kuss</LastName><ForeName>Daria J</ForeName><Initials>DJ</Initials><AffiliationInfo><Affiliation>Department of Psychology, Nottingham Trent University, Nottingham, United Kingdom.</Affiliation></AffiliationInfo></Author><Author ValidYN=""Y""><LastName>Rhodes</LastName><ForeName>Darren</ForeName><Initials>D</Initials><AffiliationInfo><Affiliation>Department of Psychology, Nottingham Trent University, Nottingham, United Kingdom.</Affiliation></AffiliationInfo></Author><Author ValidYN=""Y""><LastName>Sumich</LastName><ForeName>Alexander</ForeName><Initials>A</Initials><AffiliationInfo><Affiliation>Department of Psychology, Nottingham Trent University, Nottingham, United Kingdom.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Department of Psychology, Auckland University of Technology, Auckland, New Zealand.</Affiliation></AffiliationInfo></Author><Author ValidYN=""Y""><LastName>Heym</LastName><ForeName>Nadja</ForeName><Initials>N</Initials><AffiliationInfo><Affiliation>Department of Psychology, Nottingham Trent University, Nottingham, United Kingdom.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI=""D016428"">Journal Article</PublicationType><PublicationType UI=""D016454"">Review</PublicationType></PublicationTypeList><ArticleDate DateType=""Electronic""><Year>2021</Year><Month>10</Month><Day>11</Day></ArticleDate></Article><MedlineJournalInfo><Country>Switzerland</Country><MedlineTA>Front Psychol</MedlineTA><NlmUniqueID>101550902</NlmUniqueID><ISSNLinking>1664-1078</ISSNLinking></MedlineJournalInfo><KeywordList Owner=""NOTNLM""><Keyword MajorTopicYN=""N"">behavioral matching; interactional synchrony; interpersonal coordination; systematic review; two-body neurosciences","Interpersonal coordination is a research topic that has attracted considerable attention this last decade both due to a theoretical shift from intra-individual to inter-individual processes and due to the development of new methods for recording and analyzing movements in ecological settings. Encompassing spatiotemporal behavioral matching, interpersonal coordination is considered as ""social glue"" due to its capacity to foster social bonding. However, the mechanisms underlying this effect are still unclear and recent findings suggest a complex picture. Goal-oriented joint action and spontaneous coordination are often conflated, making it difficult to disentangle the role of joint commitment from unconscious mutual attunement. Consequently, the goals of the present article are twofold: (1) to illustrate the rapid expansion of interpersonal coordination as a research topic and (2) to conduct a systematic review of spontaneous interpersonal coordination, summarizing its latest developments and current challenges this last decade. By applying Rapid Automatic Keyword Extraction and Latent Dirichlet Allocation algorithms, keywords were extracted from PubMed and Scopus databases revealing the large diversity of research topics associated with spontaneous interpersonal coordination. Using the same databases and the keywords ""behavioral matching,"" ""interactional synchrony,"" and ""interpersonal coordination,"" 1,213 articles were identified, extracted, and screened following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses protocol. A total of 19 articles were selected using the following inclusion criteria: (1) dynamic and spontaneous interactions between two unacquainted individuals (2) kinematic analyses, and (3) non-clinical and non-expert adult populations. The results of this systematic review stress the proliferation of various definitions and experimental paradigms that study perceptual and/or social influences on the emergence of spontaneous interpersonal coordination. As methods and indices used to quantify interpersonal coordination differ from one study to another, it becomes difficult to establish a coherent picture. This review highlights the need to reconsider interpersonal coordination not as the pinnacle of social interactions but as a complex dynamical process that requires cautious interpretation. An interdisciplinary approach is necessary for building bridges across scattered research fields through opening a dialogue between different theoretical frameworks and consequently provides a more ecological and holistic understanding of human social cognition.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20797,""
"Application of BOLD<b>-</b>MRI<b>-</b>based radiomics in differentiating malignant from benign renal tumors","Deng, Pan, Xing, Zhou, Chen","https://doi.org/10.11817/j.issn.1672-7347.2021.200827","20211029","PubMed","blood oxygen level dependent magnetic resonance imaging; radiomics; renal tumors; Artificial Intelligence; Female; Humans; Kidney Neoplasms; Magnetic Resonance Imaging; Male; ROC Curve; Retrospective Studies","Blood oxygen level dependent magnetic resonance imaging (BOLD-MRI) is a kind of non-invasive MRI technology which reflects the tissue blood oxyen levels. This stuy aims to explore the value of radiomics based on BOLD-MRI in differentiating malignant from benign renal tumors. A total of 141 patients with renal tumors confirmed by pathology were retrospectively analyzed. Seventy-four men and sixty-seven women, aged 26-78 years, with a median age of 56, were included. In all patients, 118 with malignant tumors and 23 with benign tumors were confirmed. All the patients underwent renal T<sub>1</sub> weighted imaging (T<sub>1</sub>WI), T<sub>2</sub> weighted imaging (T<sub>2</sub>WI), and BOLD-MRI scan within 2 weeks before surgery. The patients were randomly assigned into a training group (benign, <i>n</i>=17; malignant, <i>n</i>=83) and a test group (benign, <i>n</i>=6; malignant, <i>n</i>=35). Two radiologists (A and B), who were blind to the pathological results, delineated the regions of interest (ROI) on the maximum axial slices of the tumors. Radiologist B delineated the ROI again at an interval of one month. The intra-class correlation coefficient (ICC) was used to evaluate inter-observer and intra-observer repeatability and ICC&gt;0.75 represented as a good consistency. All the T<sub>2</sub>* Mapping images and the related ROI files were loaded into the Artificial Intelligence Kit software. A total of 396 texture features, which were calculated based on morphology, histogram, gray level co-occurrence matrix, gray-scale run length matrix, gray-scale area size matrix and gray-scale dependent matrix, were extracted from each ROI. The lowest redundancy and the highest correlation were filtered using minimum redundancy maximum relevance (mRMR) algorithm. Then least absolute shrinkage and selection operator (LASSO) algorithm was used to screened out the most predictive features. Multivariate logistic regression was performed to develop the prediction model after feature selection. The radiomics signature score (Radscore) of each case was calculated. The Wilcoxon test was used to compare the difference in the Radscore between benign and malignant renal tumors in the training and test groups. The diagnostic performance of the model in differentiating malignant from benign renal tumors was evaluated with receiver operating characteristic (ROC) curve and leave group out cross validation. The clinical application value of the model was evaluated by decision curve analysis (DCA). There was significant difference in the age between the patients with benign and those with malignant tumors (<i>t</i>=4.383, <i>P</i>&lt;0.001). There were no significant differences in gender composition and in the largest tumor diameter between the 2 groups (Ãâ€¡<sup>2</sup>=3.452, <i>P</i>=0.063; <i>t</i>=1.432, <i>P</i>=0.154). The ICC values of all the texture features for the inter-observer repeatability were ranged from 0.71 to 0.87, and the ICC values for the intra-observer repeatability were ranged from 0.76 to 0.91. Thirty features with the lowest redundancy and the highest correlation were screened out. The most predictive 12 features were filtered out. The Radscores of malignant tumors in the training and test groups were higher than those of benign tumors (<i>P</i>&lt;0.001 and <i>P</i>=0.006, respectively). The areas under the ROC curve of the model developed by multivariable logistic regression for differentiating malignant from benign renal tumors in the training and test groups were 0.881 and 0.706, with the accuracy at 82.93% and 79.00%, the sensitivity at 82.86% and 77.11%, and the specificities at 83.33% and 88.24%, respectively. The results of decision curve analysis showed that the net benefit of the radiomics model was higher than that of ""all malignant"" or ""all benign"" when the threshold was higher than 0.3. BOLD-MRI-based radiomics can be a reliable non-invasive approach for differentiating renal malignant tumors from benign tumors. <b>Ã§â€ºÂ®Ã§Å¡â€ž</b>: Ã¨Â¡â‚¬Ã¦Â°Â§Ã¦Â°Â´Ã¥Â¹Â³Ã¤Â¾ÂÃ¨Âµâ€“Ã§Â£ÂÃ¥â€¦Â±Ã¦Å’Â¯Ã¦Ë†ÂÃ¥Æ’Â(blood oxygen level dependent magnetic resonance imagingÃ¯Â¼Å’BOLD-MRI)Ã¦Å â‚¬Ã¦Å“Â¯Ã¦ËœÂ¯Ã¤Â¸â‚¬Ã§Â§ÂÃ¥ÂÂÃ¦ËœÂ Ã§Â»â€žÃ§Â»â€¡Ã¥â€™Å’Ã§Â»â€ Ã¨Æ’Å¾Ã¨Â¡â‚¬Ã¦Â°Â§Ã¦Â°Â´Ã¥Â¹Â³Ã§Å¡â€žÃ¦â€”Â Ã¥Ë†â€ºÃ§Â£ÂÃ¥â€¦Â±Ã¦Å’Â¯Ã¦Ë†ÂÃ¥Æ’ÂÃ¦â€“Â¹Ã¦Â³â€¢Ã¯Â¼Å’Ã¦Å“Â¬Ã§Â â€Ã§Â©Â¶Ã¦Å½Â¢Ã¨Â®Â¨Ã¥Å¸ÂºÃ¤ÂºÅ½BOLD-MRIÃ§Å¡â€žÃ¥Â½Â±Ã¥Æ’ÂÃ§Â»â€žÃ¥Â­Â¦Ã©â€°Â´Ã¥Ë†Â«Ã¨â€šÂ¾Ã¨â€°Â¯Ã£â‚¬ÂÃ¦ÂÂ¶Ã¦â‚¬Â§Ã¨â€šÂ¿Ã§ËœÂ¤Ã§Å¡â€žÃ¤Â»Â·Ã¥â‚¬Â¼Ã£â‚¬â€š<b>Ã¦â€“Â¹Ã¦Â³â€¢</b>: Ã¥â€ºÅ¾Ã©Â¡Â¾Ã¦â‚¬Â§Ã¥Ë†â€ Ã¦Å¾ÂÃ§Â»ÂÃ¦â€°â€¹Ã¦Å“Â¯Ã§â€”â€¦Ã§Ââ€ Ã¨Â¯ÂÃ¥Â®Å¾Ã¥Â¹Â¶Ã¤ÂºÅ½Ã¦Å“Â¯Ã¥â€°Â2Ã¥â€˜Â¨Ã¥â€ â€¦Ã¨Â¡Å’Ã¨â€šÂ¾T<sub>1</sub>Ã¥Å Â Ã¦ÂÆ’Ã¦Ë†ÂÃ¥Æ’Â(T<sub>1</sub> weighted imagingÃ¯Â¼Å’T<sub>1</sub>WI)Ã£â‚¬ÂT<sub>2</sub>Ã¥Å Â Ã¦ÂÆ’Ã¦Ë†ÂÃ¥Æ’Â(T<sub>2</sub> weighted imagingÃ¯Â¼Å’T<sub>2</sub>WI)Ã¥ÂÅ BOLD-MRIÃ¦â€°Â«Ã¦ÂÂÃ§Å¡â€ž141Ã¤Â¾â€¹Ã¨â€šÂ¾Ã¨â€šÂ¿Ã§ËœÂ¤Ã¦â€šÂ£Ã¨â‚¬â€¦Ã§Å¡â€žÃ¨Âµâ€žÃ¦â€“â„¢Ã£â‚¬â€šÃ¥â€¦Â¶Ã¤Â¸Â­Ã§â€Â·74Ã¤Â¾â€¹Ã¯Â¼Å’Ã¥Â¥Â³67Ã¤Â¾â€¹Ã¯Â¼â€ºÃ¥Â¹Â´Ã©Â¾â€ž26~78(Ã¤Â¸Â­Ã¤Â½ÂÃ¥Â¹Â´Ã©Â¾â€ž56)Ã¥Â²ÂÃ¯Â¼â€ºÃ¦ÂÂ¶Ã¦â‚¬Â§Ã¨â€šÂ¿Ã§ËœÂ¤118Ã¤Â¾â€¹Ã¯Â¼Å’Ã¨â€°Â¯Ã¦â‚¬Â§Ã¨â€šÂ¿Ã§ËœÂ¤23Ã¤Â¾â€¹Ã£â‚¬â€šÃ¥Â°â€ Ã¨â€°Â¯Ã£â‚¬ÂÃ¦ÂÂ¶Ã¦â‚¬Â§Ã¨â€šÂ¿Ã§ËœÂ¤Ã¥Ë†â€ Ã¦Ë†ÂÃ¨Â®Â­Ã§Â»Æ’Ã§Â»â€ž(Ã¨â€°Â¯Ã¦â‚¬Â§17Ã¤Â¾â€¹Ã¯Â¼Å’Ã¦ÂÂ¶Ã¦â‚¬Â§83Ã¤Â¾â€¹)Ã¥â€™Å’Ã©ÂªÅ’Ã¨Â¯ÂÃ§Â»â€ž(Ã¨â€°Â¯Ã¦â‚¬Â§6Ã¤Â¾â€¹Ã¯Â¼Å’Ã¦ÂÂ¶Ã¦â‚¬Â§35Ã¤Â¾â€¹)Ã£â‚¬â€šÃ§â€Â±Ã¤Â¸Â¤Ã¤Â½ÂÃ¦Å“ÂªÃ§Å¸Â¥Ã¨â€šÂ¿Ã§ËœÂ¤Ã§â€”â€¦Ã§Ââ€ Ã§Â±Â»Ã¥Å¾â€¹Ã§Å¡â€žÃ¥Â½Â±Ã¥Æ’ÂÃ§Â§â€˜Ã¥Å’Â»Ã¥Â¸Ë†(AÃ£â‚¬ÂB)Ã§â€¹Â¬Ã§Â«â€¹Ã¥â€¹Â¾Ã§â€Â»Ã¨â€šÂ¿Ã§ËœÂ¤Ã¦Å“â‚¬Ã¥Â¤Â§Ã¥Â±â€šÃ©ÂÂ¢Ã§Å¡â€žÃ¨Â¾Â¹Ã§Â¼ËœÃ¯Â¼Å’Ã§â€Å¸Ã¦Ë†ÂÃ¦â€žÅ¸Ã¥â€¦Â´Ã¨Â¶Â£Ã¥Å’Âº(regions of interestÃ¯Â¼Å’ROI)Ã¯Â¼Å’Ã¥Å’Â»Ã¥Â¸Ë†BÃ©â€”Â´Ã©Å¡â€1Ã¤Â¸ÂªÃ¦Å“Ë†Ã¥â€ ÂÃ¦Â¬Â¡Ã¥â€¹Â¾Ã§â€Â»ROIÃ¯Â¼Å’Ã§â€Â¨Ã§Â»â€žÃ¥â€ â€¦Ã§â€ºÂ¸Ã¥â€¦Â³Ã§Â³Â»Ã¦â€¢Â°(intra-class correlation coefficientÃ¯Â¼Å’ICC)Ã¨Â¯â€žÃ¤Â¼Â°Ã¨Â§â€šÃ¥Â¯Å¸Ã¨â‚¬â€¦Ã©â€”Â´Ã¥ÂÅ Ã¨Â§â€šÃ¥Â¯Å¸Ã¨â‚¬â€¦Ã¥â€ â€¦Ã¤Â¸â‚¬Ã¨â€¡Â´Ã¦â‚¬Â§(ICC&gt;0.75Ã¤Â¸ÂºÃ¤Â¸â‚¬Ã¨â€¡Â´Ã¦â‚¬Â§Ã¨Â¾Æ’Ã¥Â¥Â½)Ã£â‚¬â€šÃ¥Â°â€ T<sub>2</sub><sup>*</sup> MappingÃ¥â€ºÂ¾Ã¥Æ’ÂÃ¥ÂÅ ROIÃ¥â€ºÂ¾Ã¥Æ’ÂÃ¥Â¯Â¼Ã¥â€¦Â¥Artificial Intelligence KitÃ¨Â½Â¯Ã¤Â»Â¶Ã¯Â¼Å’Ã¤Â»Å½Ã¦Â¯ÂÃ¤Â¸ÂªROIÃ¤Â¸Â­Ã¦ÂÂÃ¥Ââ€“Ã¥â€¡ÂºÃ¥Å¸ÂºÃ¤ÂºÅ½Ã¥Â½Â¢Ã¦â‚¬ÂÃ¥Â­Â¦Ã£â‚¬ÂÃ§â€ºÂ´Ã¦â€“Â¹Ã¥â€ºÂ¾Ã£â‚¬ÂÃ§ÂÂ°Ã¥ÂºÂ¦Ã¥â€¦Â±Ã§â€Å¸Ã§Å¸Â©Ã©ËœÂµÃ£â‚¬ÂÃ§ÂÂ°Ã¥ÂºÂ¦Ã¦Â¸Â¸Ã§Â¨â€¹Ã©â€¢Â¿Ã¥ÂºÂ¦Ã§Å¸Â©Ã©ËœÂµÃ£â‚¬ÂÃ§ÂÂ°Ã¥ÂºÂ¦Ã¥Å’ÂºÃ¥Å¸Å¸Ã¥Â¤Â§Ã¥Â°ÂÃ§Å¸Â©Ã©ËœÂµÃ£â‚¬ÂÃ§ÂÂ°Ã¥ÂºÂ¦Ã¤Â¾ÂÃ¨Âµâ€“Ã¦â‚¬Â§Ã§Å¸Â©Ã©ËœÂµÃ§Å¡â€ž396Ã¤Â¸ÂªÃ¥Â½Â±Ã¥Æ’ÂÃ§Â»â€žÃ¥Â­Â¦Ã§â€°Â¹Ã¥Â¾ÂÃ£â‚¬â€šÃ¥Â¯Â¹Ã¨Â®Â­Ã§Â»Æ’Ã§Â»â€žÃ©â€¡â€¡Ã§â€Â¨Ã¦Å“â‚¬Ã¥Â°ÂÃ¥â€ â€”Ã¤Â½â„¢Ã¦Å“â‚¬Ã¥Â¤Â§Ã§â€ºÂ¸Ã¥â€¦Â³Ã¦â‚¬Â§(minimum redundancy maximum relevanceÃ¯Â¼Å’mRMR)Ã§Â®â€”Ã¦Â³â€¢Ã§Â­â€ºÃ©â‚¬â€°Ã¥â€¡ÂºÃ¥â€ â€”Ã¤Â½â„¢Ã¥ÂºÂ¦Ã¦Å“â‚¬Ã¤Â½Å½Ã§â€ºÂ¸Ã¥â€¦Â³Ã¦â‚¬Â§Ã¦Å“â‚¬Ã©Â«ËœÃ§Å¡â€žÃ§â€°Â¹Ã¥Â¾ÂÃ¯Â¼Å’Ã¥â€ ÂÃ¤Â½Â¿Ã§â€Â¨Ã¦Å“â‚¬Ã¥Â°ÂÃ§Â»ÂÃ¥Â¯Â¹Ã¦â€Â¶Ã§Â¼Â©Ã¤Â¸Å½Ã©â‚¬â€°Ã¦â€¹Â©Ã§Â®â€”Ã¥Â­Â(least absolute shrinkage and selection operatorÃ¯Â¼Å’LASSO)Ã¦Â³â€¢Ã§Â­â€ºÃ©â‚¬â€°Ã¥â€¡ÂºÃ©Â¢â€žÃ¦Âµâ€¹Ã¤Â»Â·Ã¥â‚¬Â¼Ã¦Å“â‚¬Ã©Â«ËœÃ§Å¡â€žÃ§â€°Â¹Ã¥Â¾ÂÃ¯Â¼Å’Ã©â€¡â€¡Ã§â€Â¨Ã¥Â¤Å¡Ã¥â€ºÂ Ã§Â´Â logisticÃ¥â€ºÅ¾Ã¥Â½â€™Ã¦Å¾â€žÃ¥Â»ÂºÃ¥Â½Â±Ã¥Æ’ÂÃ§Â»â€žÃ¥Â­Â¦Ã¦Â¨Â¡Ã¥Å¾â€¹Ã£â‚¬â€šÃ¨Â®Â¡Ã§Â®â€”Ã¦Â¯ÂÃ¤Â¸ÂªÃ§â€”â€¦Ã¤Â¾â€¹Ã§Å¡â€žÃ¥Â½Â±Ã¥Æ’ÂÃ§Â»â€žÃ¥Â­Â¦Ã¥Ë†â€ Ã¥â‚¬Â¼(Radscore)Ã£â‚¬â€šÃ©â€¡â€¡Ã§â€Â¨WilcoxonÃ¦Â£â‚¬Ã©ÂªÅ’Ã¦Â¯â€Ã¨Â¾Æ’Ã¨Â®Â­Ã§Â»Æ’Ã§Â»â€žÃ¥â€™Å’Ã©ÂªÅ’Ã¨Â¯ÂÃ§Â»â€žÃ¨â€šÂ¾Ã¨â€°Â¯Ã£â‚¬ÂÃ¦ÂÂ¶Ã¦â‚¬Â§Ã¨â€šÂ¿Ã§ËœÂ¤Ã¤Â¹â€¹Ã©â€”Â´RadscoreÃ§Å¡â€žÃ¥Â·Â®Ã¥Â¼â€šÃ¯Â¼â€ºÃ¤Â½Â¿Ã§â€Â¨Ã¥Ââ€”Ã¨Â¯â€¢Ã¨â‚¬â€¦Ã¥Â·Â¥Ã¤Â½Å“Ã§â€°Â¹Ã¥Â¾Â(receiver operating characteristicÃ¯Â¼Å’ROC)Ã¦â€ºÂ²Ã§ÂºÂ¿Ã¥â€™Å’Ã§â€¢â„¢Ã§Â»â€žÃ¤ÂºÂ¤Ã¥Ââ€°Ã©ÂªÅ’Ã¨Â¯Â(leave group out cross validationÃ¯Â¼Å’LGOCV)Ã¦Â³â€¢Ã¥Ë†â€ Ã¦Å¾ÂÃ¥â€™Å’Ã¨Â¯â€žÃ¤Â¼Â°Ã¦Â¨Â¡Ã¥Å¾â€¹Ã©â€°Â´Ã¥Ë†Â«Ã¨â€šÂ¾Ã¨â€°Â¯Ã£â‚¬ÂÃ¦ÂÂ¶Ã¦â‚¬Â§Ã¨â€šÂ¿Ã§ËœÂ¤Ã§Å¡â€žÃ¨Â¯Å Ã¦â€“Â­Ã¦â€¢Ë†Ã¨Æ’Â½Ã¯Â¼â€ºÃ©â€¡â€¡Ã§â€Â¨Ã¥â€ Â³Ã§Â­â€“Ã¦â€ºÂ²Ã§ÂºÂ¿Ã¥Ë†â€ Ã¦Å¾ÂÃ¨Â¯â€žÃ¤Â¼Â°Ã¦Â¨Â¡Ã¥Å¾â€¹Ã§Å¡â€žÃ¤Â¸Â´Ã¥ÂºÅ Ã¥Âºâ€Ã§â€Â¨Ã¤Â»Â·Ã¥â‚¬Â¼Ã£â‚¬â€š<b>Ã§Â»â€œÃ¦Å¾Å“</b>: Ã¨â€°Â¯Ã£â‚¬ÂÃ¦ÂÂ¶Ã¦â‚¬Â§Ã¨â€šÂ¿Ã§ËœÂ¤Ã¤Â¸Â¤Ã§Â»â€žÃ¦â€šÂ£Ã¨â‚¬â€¦Ã¥Â¹Â´Ã©Â¾â€žÃ¥Â·Â®Ã¥Â¼â€šÃ¦Å“â€°Ã§Â»Å¸Ã¨Â®Â¡Ã¥Â­Â¦Ã¦â€žÂÃ¤Â¹â€°(<i>t</i>=4.383Ã¯Â¼Å’<i>P</i>&lt;0.001)Ã¯Â¼â€ºÃ¦â‚¬Â§Ã¥Ë†Â«Ã¦Å¾â€žÃ¦Ë†ÂÃ¥Â·Â®Ã¥Â¼â€šÃ¦â€”Â Ã§Â»Å¸Ã¨Â®Â¡Ã¥Â­Â¦Ã¦â€žÂÃ¤Â¹â€°(Ãâ€¡<sup>2</sup>=3.452Ã¯Â¼Å’<i>P</i>=0.063)Ã¯Â¼â€ºÃ¤Â¸Â¤Ã§Â»â€žÃ¨â€šÂ¿Ã§ËœÂ¤Ã¦Å“â‚¬Ã¥Â¤Â§Ã¥Â¾â€žÃ¥Â·Â®Ã¥Â¼â€šÃ¦â€”Â Ã§Â»Å¸Ã¨Â®Â¡Ã¥Â­Â¦Ã¦â€žÂÃ¤Â¹â€°(<i>t</i>=1.432Ã¯Â¼Å’<i>P</i>=0.154)Ã£â‚¬â€šÃ¥Å’Â»Ã¥Â¸Ë†AÃ¥â€™Å’Ã¥Å’Â»Ã¥Â¸Ë†BÃ¥Ââ€žÃ¨â€¡ÂªÃ§â€¹Â¬Ã§Â«â€¹Ã¦Âµâ€¹Ã©â€¡ÂÃ§Å¡â€žÃ§Â»â€žÃ©â€”Â´ICCÃ¥â‚¬Â¼Ã¤Â¸Âº0.71~0.87Ã¯Â¼Å’Ã¥Å’Â»Ã¥Â¸Ë†BÃ¤Â¸Â¤Ã¦Â¬Â¡Ã¦Âµâ€¹Ã©â€¡ÂÃ§Å¡â€žÃ§Â»â€žÃ¥â€ â€¦ICCÃ¤Â¸Âº0.76~0.91Ã£â‚¬â€šÃ©â€¡â€¡Ã§â€Â¨mRMRÃ§Â®â€”Ã¦Â³â€¢Ã§Â­â€ºÃ©â‚¬â€°Ã¥â€¡Âº30Ã¤Â¸ÂªÃ¥â€ â€”Ã¤Â½â„¢Ã¥ÂºÂ¦Ã¦Å“â‚¬Ã¤Â½Å½Ã§â€ºÂ¸Ã¥â€¦Â³Ã¦â‚¬Â§Ã¦Å“â‚¬Ã©Â«ËœÃ§Å¡â€žÃ§â€°Â¹Ã¥Â¾ÂÃ¯Â¼Å’Ã©â€¡â€¡Ã§â€Â¨LASSOÃ¦Â³â€¢Ã§Â­â€ºÃ©â‚¬â€°Ã¥â€¡Âº12Ã¤Â¸ÂªÃ©Â¢â€žÃ¦Âµâ€¹Ã¤Â»Â·Ã¥â‚¬Â¼Ã¦Å“â‚¬Ã©Â«ËœÃ§Å¡â€žÃ§â€°Â¹Ã¥Â¾ÂÃ£â‚¬â€šÃ¨Â®Â­Ã§Â»Æ’Ã§Â»â€žÃ¥â€™Å’Ã©ÂªÅ’Ã¨Â¯ÂÃ§Â»â€žÃ¦ÂÂ¶Ã¦â‚¬Â§Ã¨â€šÂ¿Ã§ËœÂ¤RadscoreÃ¥Ââ€¡Ã©Â«ËœÃ¤ÂºÅ½Ã¨â€°Â¯Ã¦â‚¬Â§Ã¨â€šÂ¿Ã§ËœÂ¤(Ã¥Ë†â€ Ã¥Ë†Â«<i>P</i>&lt;0.001Ã¥â€™Å’<i>P</i>=0.006)Ã£â‚¬â€šÃ¥Â½Â±Ã¥Æ’ÂÃ§Â»â€žÃ¥Â­Â¦Ã¦Â¨Â¡Ã¥Å¾â€¹Ã©â€°Â´Ã¥Ë†Â«Ã¨Â®Â­Ã§Â»Æ’Ã§Â»â€žÃ£â‚¬ÂÃ©ÂªÅ’Ã¨Â¯ÂÃ§Â»â€žÃ¨â€šÂ¾Ã¨â€°Â¯Ã£â‚¬ÂÃ¦ÂÂ¶Ã¦â‚¬Â§Ã¨â€šÂ¿Ã§ËœÂ¤Ã§Å¡â€žROCÃ¦â€ºÂ²Ã§ÂºÂ¿Ã¤Â¸â€¹Ã©ÂÂ¢Ã§Â§Â¯Ã¥Ë†â€ Ã¥Ë†Â«Ã¤Â¸Âº0.881Ã£â‚¬Â0.706Ã¯Â¼Å’Ã¥â€¡â€ Ã§Â¡Â®Ã¥ÂºÂ¦Ã¥Ë†â€ Ã¥Ë†Â«Ã¤Â¸Âº82.93%Ã£â‚¬Â79.00%Ã¯Â¼Å’Ã¦â€¢ÂÃ¦â€žÅ¸Ã¥ÂºÂ¦Ã¥Ë†â€ Ã¥Ë†Â«Ã¤Â¸Âº82.86%Ã£â‚¬Â77.11%Ã¯Â¼Å’Ã§â€°Â¹Ã¥Â¼â€šÃ¥ÂºÂ¦Ã¥Ë†â€ Ã¥Ë†Â«Ã¤Â¸Âº83.33%Ã£â‚¬Â88.24%Ã£â‚¬â€šÃ¥â€ Â³Ã§Â­â€“Ã¦â€ºÂ²Ã§ÂºÂ¿Ã¥Ë†â€ Ã¦Å¾ÂÃ§Â»â€œÃ¦Å¾Å“Ã¦ËœÂ¾Ã§Â¤ÂºÃ¥Â½â€œÃ©ËœË†Ã¥â‚¬Â¼Ã©Â«ËœÃ¤ÂºÅ½0.3Ã¦â€”Â¶Ã¯Â¼Å’Ã¥Â½Â±Ã¥Æ’ÂÃ§Â»â€žÃ¥Â­Â¦Ã¦Â¨Â¡Ã¥Å¾â€¹Ã§Å¡â€žÃ¥â€¡â‚¬Ã¦â€Â¶Ã§â€ºÅ Ã§Å½â€¡Ã©Â«ËœÃ¤ÂºÅ½Ã¨Â¢Â«Ã¨Â¯â€ Ã¥Ë†Â«Ã¤Â¸ÂºÃ¢â‚¬Å“Ã¥â€¦Â¨Ã©Æ’Â¨Ã¦ÂÂ¶Ã¦â‚¬Â§Ã¢â‚¬ÂÃ¦Ë†â€“Ã¢â‚¬Å“Ã¥â€¦Â¨Ã©Æ’Â¨Ã¨â€°Â¯Ã¦â‚¬Â§Ã¢â‚¬ÂÃ§Å¡â€žÃ¥â€¡â‚¬Ã¦â€Â¶Ã§â€ºÅ Ã§Å½â€¡Ã£â‚¬â€š<b>Ã§Â»â€œÃ¨Â®Âº</b>: Ã¥Å¸ÂºÃ¤ÂºÅ½BOLD-MRIÃ¥Â½Â±Ã¥Æ’ÂÃ§Â»â€žÃ¥Â­Â¦Ã¥ÂÂ¯Ã¤Â½Å“Ã¤Â¸ÂºÃ¤Â¸â‚¬Ã§Â§ÂÃ¦â€”Â Ã¥Ë†â€ºÃ©Â¢â€žÃ¦Âµâ€¹Ã¨â€šÂ¾Ã¨â€°Â¯Ã£â‚¬ÂÃ¦ÂÂ¶Ã¦â‚¬Â§Ã¨â€šÂ¿Ã§ËœÂ¤Ã§Å¡â€žÃ¥Â·Â¥Ã¥â€¦Â·Ã£â‚¬â€š.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20798,""
"Improving depression prediction using a novel feature selection algorithm coupled with context-aware analysis","Dai, Zhou, Ba, Zhou, Wang, Li","https://doi.org/10.1016/j.jad.2021.09.001","20211101","PubMed","Context-aware analysis; Depression prediction; Feature selection; Maximal information coefficient; Support vector machine; Algorithms; Databases, Factual; Depression; Machine Learning","Developing machine learning based depression prediction method with information from long-term recordings is important and challenging to clinical diagnosis of depression. We developed a novel two-stage feature selection algorithm conducted on the high-dimensional (over thirty thousand) features constructed by a context-aware analysis on the data set of DAIC-WOZ, including audio, video, and semantic features. The prediction performance was compared with seven reference models. The preferred topics and feature categories related to the retained features were also analyzed respectively. Parsimonious subsets (tens of features) were selected by the proposed method in each case of prediction. We obtained the best performance in depression classification with F1-score as 0.96 (0.67), Precision as 1.00 (0.63), and Recall as 0.92 (0.71) on the development set (test set). We also achieved promising results in depression severity estimation with RMSE as 4.43 (5.11) and MAE as 3.22 (3.98), having a marginal difference with the best reference model (random forest with 'Selected-Text' features). Five most important topics related to depression were revealed. The audio features were predominant to the other feature categories in depression classification while the contributions of the three feature categories to severity estimation were almost equal. More depression samples in the database we used should be further included. The second stage of feature selection is relatively time-consuming. This pipeline of depression recognition as well as the preferred topics and feature categories are expected to be useful in supporting the diagnosis of psychological distress conditions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20799,""
"Artificial intelligence in clinical and translational science: Successes, challenges and opportunities","Bernstam, Shireman, Meric-Bernstam, N Zozus, Jiang, Brimhall, Windham, Schmidt, Visweswaran, Ye, Goodrum, Ling, Berapatre, Becich","https://doi.org/10.1111/cts.13175","20211030","PubMed","artificial intelligence; machine learning; translational medical research","Artificial intelligence (AI) is transforming many domains, including finance, agriculture, defense, and biomedicine. In this paper, we focus on the role of AI in clinical and translational research (CTR), including preclinical research (T1), clinical research (T2), clinical implementation (T3), and public (or population) health (T4). Given the rapid evolution of AI in CTR, we present three complementary perspectives: (1) scoping literature review, (2) survey, and (3) analysis of federally funded projects. For each CTR phase, we addressed challenges, successes, failures, and opportunities for AI. We surveyed Clinical and Translational Science Award (CTSA) hubs regarding AI projects at their institutions. Nineteen of 63 CTSA hubs (30%) responded to the survey. The most common funding source (48.5%) was the federal government. The most common translational phase was T2 (clinical research, 40.2%). Clinicians were the intended users in 44.6% of projects and researchers in 32.3% of projects. The most common computational approaches were supervised machine learning (38.6%) and deep learning (34.2%). The number of projects steadily increased from 2012 to 2020. Finally, we analyzed 2604 AI projects at CTSA hubs using the National Institutes of Health Research Portfolio Online Reporting Tools (RePORTER) database for 2011-2019. We mapped available abstracts to medical subject headings and found that nervous system (16.3%) and mental disorders (16.2) were the most common topics addressed. From a computational perspective, big data (32.3%) and deep learning (30.0%) were most common. This work represents a snapshot in time of the role of AI in the CTSA program.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20800,""
"Understanding racial disparities in severe maternal morbidity using Bayesian network analysis","Rezaeiahari, Brown, Ali, Datta, Tilford","https://doi.org/10.1371/journal.pone.0259258","20211030","PubMed","","Previous studies have evaluated the marginal effect of various factors on the risk of severe maternal morbidity (SMM) using regression approaches. We add to this literature by utilizing a Bayesian network (BN) approach to understand the joint effects of clinical, demographic, and area-level factors. We conducted a retrospective observational study using linked birth certificate and insurance claims data from the Arkansas All-Payer Claims Database (APCD), for the years 2013 through 2017. We used various learning algorithms and measures of arc strength to choose the most robust network structure. We then performed various conditional probabilistic queries using Monte Carlo simulation to understand disparities in SMM. We found that anemia and hypertensive disorder of pregnancy may be important clinical comorbidities to target in order to reduce SMM overall as well as racial disparities in SMM.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20801,""
"Comparing Load-Sharing Miniplate and Load-Bearing Plate Fixation in Atrophic Edentulous Mandibular Fractures: A Systematic Review and Meta-Analysis","Seu, Jazayeri, Lopez, Khavanin, Lake, Phillips, Reategui, Shamliyan, Peacock, Dorafshar","https://doi.org/10.1097/SCS.0000000000007927","20211029","PubMed","Bone Plates; Fracture Fixation, Internal; Humans; Mandibular Fractures; Mouth, Edentulous; Weight-Bearing","To critically examine reported data to compare patient outcomes between load-sharing and load-bearing plate fixation for edentulous mandibular fractures. A systematic review and meta-analysis were designed to test the null hypothesis of no difference in postoperative outcomes between load-sharing and load-bearing plate fixation in atrophic, edentulous mandibular fractures. The PubMed, EMBASE, Cochrane Library, Elsevier text mining tool database, and clinicaltrials.gov trial registries were queried up until July 2016. The quality of evidence was determined using the Grading of Recommendations Assessment, Development, and Evaluation method. A total of 1212 studies were screened for inclusion of which we included 1 high-quality Cochrane review, 6 narrative reviews, and 21 publications of case reports and case series. Overall, the quality of evidence was low. No difference was found between load-bearing and load-sharing fixation in functional recovery, nonunion, or infection. An uncontrolled case series portrayed complete functional and morphological restoration in 96.9% of patients (83.2-99.5; 95% confidence interval) in load-bearing osteosynthesis while another demonstrated the same outcome in only 40.0% of patients (17.5-65.0; 95% confidence interval). The authors did not find a statistically significant difference between load-bearing and load-sharing plate fixation in edentulous atrophic mandibular fracture patients; although this finding may be influenced by type 2 statistical error. Surgeons should continue to use their best clinical judgment in deciding on treatment approach for these challenging fractures. Future studies with higher level evidence are necessary to guide optimal fracture management.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20802,""
"Pandemic tele-smart: a contactless tele-health system for efficient monitoring of remotely located COVID-19 quarantine wards in India using near-field communication and natural language processing system","Balasubramanian, Vivekanandhan, Mahadevan","https://doi.org/10.1007/s11517-021-02456-1","20211029","PubMed","Clinical decision support systems; Electronic medical records; Mobile health; Remote consultation; Telemedicine","Efficient remote monitoring of the patient infected with coronavirus without spread to healthcare workers is the need of the hour. An effectual and faster communication system must be established wherein the healthcare workers at the remote quarantine ward can communicate with healthcare professionals present in specialty hospitals. Incidentally, there is a need to establish a contactless smart cloud-based connection between a specialty hospital and quarantine wards during pandemic situation. This paper proposes an initial contactless web-based tele-health clinical decision support system that integrates near-field communication (NFC) tags and a smart cloud-based structuring tool that enables the quick diagnosis of patients with COVID-19 symptoms and monitors the remotely located quarantine wards during the recent pandemic. The proposed framework consists of three-stages: (i) contactless health parameter extraction from the patient using an NFC tag; (ii) converting medical report into digital text using optical character recognition algorithm and extracting values of relevant medical-parameters using natural language processing; and (iii) smart visualization of key medical parameters. The accuracy of the proposed system from NFC reader until analysis using a novel structuring algorithm deployed in the cloud is more than 94%. Several capabilities of the proposed web-based system were compared with similar systems and tested in an authentic mock clinical setup, and the physicians found that the system is reliable and user friendly.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20803,""
"White matter hyperintensities segmentation using an ensemble of neural networks","Li, Zhao, Jiang, Cheng, Zhu, Wu, Jing, Zhang, Wen, Sachdev, Wang, Liu, Li","https://doi.org/10.1002/hbm.25695","20211027","PubMed","CNN; ensemble models; segmentation; white matter hyperintensities","White matter hyperintensities (WMHs) represent the most common neuroimaging marker of cerebral small vessel disease (CSVD). The volume and location of WMHs are important clinical measures. We present a pipeline using deep fully convolutional network and ensemble models, combining U-Net, SE-Net, and multi-scale features, to automatically segment WMHs and estimate their volumes and locations. We evaluated our method in two datasets: a clinical routine dataset comprising 60 patients (selected from Chinese National Stroke Registry, CNSR) and a research dataset composed of 60 patients (selected from MICCAI WMH Challenge, MWC). The performance of our pipeline was compared with four freely available methods: LGA, LPA, UBO detector, and U-Net, in terms of a variety of metrics. Additionally, to access the model generalization ability, another research dataset comprising 40 patients (from Older Australian Twins Study and Sydney Memory and Aging Study, OSM), was selected and tested. The pipeline achieved the best performance in both research dataset and the clinical routine dataset with DSC being significantly higher than other methods (pÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°.001), reaching .833 and .783, respectively. The results of model generalization ability showed that the model trained on the research dataset (DSCÃ‚Â =Ã‚Â 0.736) performed higher than that trained on the clinical dataset (DSCÃ‚Â =Ã‚Â 0.622). Our method outperformed widely used pipelines in WMHs segmentation. This system could generate both image and text outputs for whole brain, lobar and anatomical automatic labeling WMHs. Additionally, software and models of our method are made publicly available at https://www.nitrc.org/projects/what_v1.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20804,""
"Radiomics in breast MRI: current progress toward clinical application in the era of artificial intelligence","Satake, Ishigaki, Ito, Naganawa","https://doi.org/10.1007/s11547-021-01423-y","20211027","PubMed","Artificial intelligence; Breast; Deep learning; MRI; Machine learning; Radiomics","Breast magnetic resonance imaging (MRI) is the most sensitive imaging modality for breast cancer diagnosis and is widely used clinically. Dynamic contrast-enhanced MRI is the basis for breast MRI, but ultrafast images, T2-weighted images, and diffusion-weighted images are also taken to improve the characteristics of the lesion. Such multiparametric MRI with numerous morphological and functional data poses new challenges to radiologists, and thus, new tools for reliable, reproducible, and high-volume quantitative assessments are warranted. In this context, radiomics, which is an emerging field of research involving the conversion of digital medical images into mineable data for clinical decision-making and outcome prediction, has been gaining ground in oncology. Recent development in artificial intelligence has promoted radiomics studies in various fields including breast cancer treatment and numerous studies have been conducted. However, radiomics has shown a translational gap in clinical practice, and many issues remain to be solved. In this review, we will outline the steps of radiomics workflow and investigate clinical application of radiomics focusing on breast MRI based on published literature, as well as current discussion about limitations and challenges in radiomics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20805,""
"Primary Bankart Repair Versus Arthroscopic Anatomic Glenoid Reconstruction in Patients with Subcritical Bone Loss: A Cost-Utility Analysis","Ali, Thavorn, Murphy, Sparavalo, Wong","https://doi.org/10.2106/JBJS.OA.21.00067","20211028","PubMed","","Anterior shoulder instability and its treatment is a quickly evolving field of interest in orthopaedics, both for patients and for health-care systems. In this study, we aimed to evaluate the cost-effectiveness of arthroscopic anatomic glenoid reconstruction (AAGR) compared with Bankart repair in the treatment of anterior shoulder instability in patients with subcritical glenoid bone loss. A cost-utility analysis was performed from the perspective of Canada's publicly funded health-care system. A decision-tree model was created to simulate the progression of patients undergoing either a primary Bankart repair or AAGR. Recently published data were used to determine the recurrence rate and level of glenoid bone loss for the AAGR procedure; the recurrence rate was 1.4% in a cohort with a mean glenoid bone loss of 25.3%. A literature review on the primary Bankart procedure in patients with at least subcritical levels of glenoid bone loss yielded a recurrence rate of 22.9% in patients with a mean glenoid bone loss of 17.5%. AAGR served as the revision surgery for both primary procedures. Health utility scores for anterior shoulder instability were obtained from published literature. Total procedure costs, including costs of operating-room consumables, anesthesia, diagnostic imaging, and rehabilitation, were sourced from a hospital database. A probabilistic sensitivity analysis using 5,000 Monte Carlo simulations was performed, and results were used to create a cost-effectiveness acceptability curve. The AAGR procedure was less costly and led to an improvement in quality-adjusted life years (QALYs) when compared with the arthroscopic Bankart repair in the treatment of patients with anterior shoulder instability with subcritical glenoid bone loss (AAGR, cost = $16,682.77 [Canadian dollars] and QALYs = 5.76; Bankart, cost = $16,720.29 and QALYs = 5.46), suggesting that the AAGR is dominant, i.e., lower costs with higher QALYs. Applying a commonly used willingness-to-pay threshold of $50,000 per QALY gained, the probability that the primary AAGR was more cost-effective was 85.8%. This study showed that, from the perspective of a publicly funded health-care system, AAGR was the economical treatment option when compared with Bankart repair in anterior shoulder instability with subcritical glenoid bone loss. Economic and Decision Analysis Level III. See Instructions for Authors for a complete description of levels of evidence.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20806,""
"Framework for Machine Learning of CT and PET Radiomics to Predict Local Failure after Radiotherapy in Locally Advanced Head and Neck Cancers","Devakumar, Sunny, Sasidharan, Bowen, Nadaraj, Jeyseelan, Mathew, Irodi, Isiah, Pavamani, John, T Thomas","https://doi.org/10.4103/jmp.JMP_6_21","20211028","PubMed","Computed tomography; head and neck cancer; local failure; machine learning; positron emission tomography; radiomics","Cancer Radiomics is an emerging field in medical imaging and refers to the process of converting routine radiological images that are typically qualitatively interpreted to quantifiable descriptions of the tumor phenotypes and when combined with statistical analytics can improve the accuracy of clinical outcome prediction models. However, to understand the radiomic features and their correlation to molecular changes in the tumor, first, there is a need for the development of robust image analysis methods, software tools and statistical prediction models which is often limited in low- and middle-income countries (LMIC). The aim is to build a framework for machine learning of radiomic features of planning computed tomography (CT) and positron emission tomography (PET) using open source radiomics and data analytics platforms to make it widely accessible to clinical groups. The framework is tested in a small cohort to predict local disease failure following radiation treatment for head-and-neck cancer (HNC). The predictors were also compared with the existing Aerts HNC radiomics signature. Retrospective analysis of patients with locally advanced HNC between 2017 and 2018 and 31 patients with both pre- and post-radiation CT and evaluation PET were selected. Tumor volumes were delineated on baseline PET using the semi-automatic adaptive-threshold algorithm and propagated to CT; PyRadiomics features (total of 110 under shape/intensity/texture classes) were extracted. Two feature-selection methods were tested for model stability. Models were built based on least absolute shrinkage and selection operator-logistic and Ridge regression of the top pretreatment radiomic features and compared to Aerts' HNC-signature. Average model performance across all internal validation test folds was summarized by the area under the receiver operator curve (ROC). Both feature selection methods selected CT features MCC (GLCM), SumEntropy (GLCM) and Sphericity (Shape) that could predict the binary failure status in the cross-validated group and achieved an AUC &gt;0.7. However, models using Aerts' signature features (Energy, Compactness, GLRLM-GrayLevelNonUniformity and GrayLevelNonUniformity-HLH wavelet) could not achieve a clear separation between outcomes (AUC = 0.51-0.54). Radiomics pipeline included open-source workflows which makes it adoptable in LMIC countries. Additional independent validation of data is crucial for the implementation of radiomic models for clinical risk stratification.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20807,""
"Development and validation of new screening tool for predicting dementia risk in community-dwelling older Japanese adults","Makino, Lee, Bae, Chiba, Harada, Katayama, Shinkai, Shimada","https://doi.org/10.1186/s12967-021-03121-9","20211102","PubMed","Decision-tree; Dementia prevention; Machine learning; Risk prediction; Aged; Dementia; Humans; Independent Living; Japan; Mass Screening; Surveys and Questionnaires","Established clinical assessments for detecting dementia risk often require time, cost, and face-to-face meetings. We aimed to develop a Simplified Telephone Assessment for Dementia risk (STAD) (a new screening tool utilizing telephonic interviews to predict dementia risk) and examine the predictive validity of the STAD for the incidence of dementia. We developed STAD based on a combination of literature review, statistical analysis, and expert opinion. We selected 12 binary questions on subjective cognitive complaints, depressive symptoms, and lifestyle activities. In the validation study, we used STAD for 4298 community-dwelling older adults and observed the incidence of dementia during the 24-month follow-up period. The total score of STAD ranging from 0 to 12 was calculated, and the cut-off point for dementia incidence was determined using the Youden index. The survival rate of dementia incidence according to the cut-off points was determined. Furthermore, we used a decision-tree model (classification and regression tree, CART) to enhance the predictive ability of STAD for dementia risk screening. The cut-off point of STAD was set at 4/5. Participants scoringÃ¢â‚¬â€°Ã¢â€°Â¥Ã¢â‚¬â€°5 points showed a significantly higher risk of dementia than those scoringÃ¢â‚¬â€°Ã¢â€°Â¤Ã¢â‚¬â€°4 points, even after adjusting for covariates (hazard ratio [95% confidence interval], 2.67 [1.40-5.08]). A decision tree model using the CART algorithm was constructed using 12 nodes with three STAD items. It showed better performance for dementia prediction in terms of accuracy and specificity as compared to the logistic regression model, although its sensitivity was worse than the logistic regression model. We developed a 12-item questionnaire, STAD, as a screening tool to predict dementia risk utilizing telephonic interviews and confirmed its predictive validity. Our findings might provide useful information for early screening of dementia risk and enable bridging between community and clinical settings. Additionally, STAD could be employed without face-to-face meetings in a short time; therefore, it may be a suitable screening tool for community-dwelling older adults who have negative attitudes toward clinical examination or are non-adherent to follow-up assessments in clinical trials.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20808,""
"Predictive performance and impact of algorithms in remote monitoring of chronic conditions: A systematic review and meta-analysis","Castelyn, Laranjo, Schreier, Gallego","https://doi.org/10.1016/j.ijmedinf.2021.104620","20211102","PubMed","Cardiovascular disease; Chronic disease; Machine learning; Respiratory disease; Telehealth; Telemonitoring","The use of telehealth interventions, such as the remote monitoring of patient clinical data (e.g. blood pressure, blood glucose, heart rate, medication use), has been proposed as a strategy to better manage chronic conditions and to reduce the impact on patients and healthcare systems. The use of algorithms for data acquisition, analysis, transmission, communication and visualisation are now common in remote patient monitoring. However, their use and impact on chronic disease management has not been systematically investigated. To investigate the use, impact, and performance of remote monitoring algorithms across various types of chronic conditions. A literature search of MEDLINE complete, CINHAL complete, and EMBASE was performed using search terms relating to the concepts of remote monitoring, chronic conditions, and data processing algorithms. Comparable outcomes from studies describing the impact on process measures and clinical and patient-reported outcomes were pooled for a summary effect and meta-analyses. A comparison of studies reporting the predictive performance of algorithms was also conducted using the Youden Index. A total of 89 articles were included in the review. There was no evidence of a positive impact on healthcare utilisation [OR 1.09 (0.90 to 1.31); PÃ‚Â =Ã‚Â .35] and mortality [OR 0.83 (0.63 to 1.10); PÃ‚Â =Ã‚Â .208], but there was a positive effect on generic health status [SDM 0.2912 (0.06 to 0.51); PÃ‚Â =Ã‚Â .010] and diabetes control [SDM -0.53 (-0.74 to -0.33); PÃ‚Â &lt;Ã‚Â .001; I<sup>2</sup>Ã‚Â =Ã‚Â 15.71] (with two of the three diabetes studies being identified as having a high risk of bias). While the majority of impact studies made use of heuristic threshold-based algorithms (nÃ‚Â =Ã‚Â 27,87%), most performance studies (nÃ‚Â =Ã‚Â 36, 62%) analysed non-sequential machine learning methods. There was considerable variance in the quality, sample size and performance amongst these studies. Overall, algorithms involved in diagnosis (nÃ‚Â =Ã‚Â 22, 47%) had superior performance to those involved in predicting a future event (nÃ‚Â =Ã‚Â 25, 53%). Detection of arrythmia and ischaemia utilising ECG data showed particularly promising results. The performance of data processing algorithms for the diagnosis of a current condition, particularly those related to the detection of arrythmia and ischaemia, is promising. However, there appears to exist minimal testing in experimental studies, with only two included impact studies citing a performance study as support for the intervention algorithm used. Because of the disconnect between performance and impact studies, there is currently limited evidence of the effect of integrating advanced inference algorithms in remote monitoring interventions. If the field of remote patient monitoring is to progress, future impact studies should address this disconnect by evaluating high performance validated algorithms in robust clinical trials.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20809,""
"Graph Signal Processing, Graph Neural Network and Graph Learning on Biological Data: A Systematic Review","Li, Yuan, Radfar, Marendy, Ni, O'Brien, Casillas-Espinosa","https://doi.org/10.1109/RBME.2021.3122522","20211026","PubMed","","Graph networks can model the data observed across different levels of biological systems that span from the population graph (with patients as network nodes) to the molecular graphs that involve omics data. Graph-based approaches have shed light on decoding biological processes modulated by complex interactions. This paper systematically reviews the graph-based analysis methods, including Graph Signal Processing (GSP), Graph Neural Network (GNN), and graph topology inference methods, and their applications to biological data. This work focuses on the algorithms of the graph-based approaches and the constructions of the graph-based frameworks that are adapted to the broad range of biological data. We cover the Graph Fourier Transform and the graph filter developed in GSP, which provides tools to investigate biological networks in the graph domain that can potentially benefit from the underlying graph structure. We also review the node, graph, and interaction oriented GNN architecture with inductive and transductive learning manners for various biological objectives. As the key component of graph analysis, we provide a review of the graph topology inference methods that incorporate assumptions for specific biological objectives. Finally, we discuss the biological application of graph analysis methods within the exhaustive literature collection, potentially providing insights for future research in the biological sciences.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20810,""
"R|S Atlas: Identifying existing cohort study data resources to accelerate epidemiological research on the influence of religion and spirituality on human health","Schachter, Argentieri, Seddighzadeh, Isehunwa, Kent, Trevvett, McDuffie, Mandel, Pargament, Underwood, McCray, Shields","https://doi.org/10.1136/bmjopen-2020-043830","20211102","PubMed","epidemiology; health informatics; public health; Cohort Studies; Humans; Prospective Studies; Religion; Research Personnel; Spirituality; Surveys and Questionnaires","Many studies have documented significant associations between religion and spirituality (R/S) and health, but relatively few prospective analyses exist that can support causal inferences. To date, there has been no systematic analysis of R/S survey items collected in US cohort studies. We conducted a systematic content analysis of all surveys ever fielded in 20 diverse US cohort studies funded by the National Institutes of Health (NIH) to identify all R/S-related items collected from each cohort's baseline survey through 2014. An R|S Ontology was developed from our systematic content analysis to categorise all R/S survey items identified into key conceptual categories. A systematic literature review was completed for each R/S item to identify any cohort publications involving these items through 2018. Our content analysis identified 319Ã¢â‚¬â€°R/S survey items, reflecting 213 unique R/S constructs and 50 R|S Ontology categories. 193 of the 319 extant R/S survey items had been analysed in at least one published paper. Using these data, we created the R|S Atlas (https://atlas.mgh.harvard.edu/), a publicly available, online relational database that allows investigators to identify R/S survey items that have been collected by US cohorts, and to further refine searches by other key data available in cohorts that may be necessary for a given study (eg, race/ethnicity, availability of DNA or geocoded data). R|S Atlas not only allows researchers to identify available sources of R/S data in cohort studies but will also assist in identifying novel research questions that have yet to be explored within the context of US cohort studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20811,""
"Detecting Fall Risk and Frailty in Elders with Inertial Motion Sensors: A Survey of Significant Gait Parameters","Ruiz-Ruiz, Jimenez, Garcia-Villamil, Seco","https://doi.org/10.3390/s21206918","20211027","PubMed","frailty; gait analysis; inertial sensor; Aged; Frailty; Gait; Geriatric Assessment; Humans; Walking; Walking Speed","In the elderly, geriatric problems such as the risk of fall or frailty are a challenge for society. Patients with frailty present difficulties in walking and higher fall risk. The use of sensors for gait analysis allows the detection of objective parameters related to these pathologies and to make an early diagnosis. Inertial Measurement Units (IMUs) are wearables that, due to their accuracy, portability, and low price, are an excellent option to analyze human gait parameters in health-monitoring applications. Many relevant gait parameters (e.g., step time, walking speed) are used to assess motor, or even cognitive, health problems in the elderly, but we perceived that there is not a full consensus on which parameters are the most significant to estimate the risk of fall and the frailty state. In this work, we analyzed the different IMU-based gait parameters proposed in the literature to assess frailty state (robust, prefrail, or frail) or fall risk. The aim was to collect the most significant gait parameters, measured from inertial sensors, able to discriminate between patient groups and to highlight those parameters that are not relevant or for which there is controversy among the examined works. For this purpose, a literature review of the studies published in recent years was carried out; apart from 10 previous relevant reviews using inertial and other sensing technologies, a total of 22 specific studies giving statistical significance values were analyzed. The results showed that the most significant parameters are double-support time, gait speed, stride time, step time, and the number of steps/day or walking percentage/day, for frailty diagnosis. In the case of fall risk detection, parameters related to trunk stability or movements are the most relevant. Although these results are important, the total number of works found was limited and most of them performed the significance statistics on subsets of all possible gait parameters; this fact highlights the need for new frailty studies using a more complete set of gait parameters.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20812,""
"A systematic review on artificial intelligence in robot-assisted surgery","Moglia, Georgiou, Georgiou, Satava, Cuschieri","https://doi.org/10.1016/j.ijsu.2021.106151","20211029","PubMed","Artificial intelligence robot-assisted surgery; Artificial intelligence robotic surgery; Computer vision robotic surgery; Deep learning robot-assisted surgery; General surgery robot surgery; Machine learning robot-assisted surgery; Urology robotic surgery","Despite the extensive published literature on the significant potential of artificial intelligence (AI) there are no reports on its efficacy in improving patient safety in robot-assisted surgery (RAS). The purposes of this work are to systematically review the published literature on AI in RAS, and to identify and discuss current limitations and challenges. A literature search was conducted on PubMed, Web of Science, Scopus, and IEEExplore according to PRISMA 2020 statement. Eligible articles were peer-review studies published in English language from January 1, 2016 to December 31, 2020. Amstar 2 was used for quality assessment. Risk of bias was evaluated with the Newcastle Ottawa Quality assessment tool. Data of the studies were visually presented in tables using SPIDER tool. Thirty-five publications, representing 3436 patients, met the search criteria and were included in the analysis. The selected reports concern: motion analysis (nÃ‚Â =Ã‚Â 17), urology (nÃ‚Â =Ã‚Â 12), gynecology (nÃ‚Â =Ã‚Â 1), other specialties (nÃ‚Â =Ã‚Â 1), training (nÃ‚Â =Ã‚Â 3), and tissue retraction (nÃ‚Â =Ã‚Â 1). Precision for surgical tools detection varied from 76.0% to 90.6%. Mean absolute error on prediction of urinary continence after robot-assisted radical prostatectomy (RARP) ranged from 85.9 to 134.7 days. Accuracy on prediction of length of stay after RARP was 88.5%. Accuracy on recognition of the next surgical task during robot-assisted partial nephrectomy (RAPN) achieved 75.7%. The reviewed studies were of low quality. The findings are limited by the small size of the datasets. Comparison between studies on the same topic was restricted due to algorithms and datasets heterogeneity. There is no proof that currently AI can identify the critical tasks of RAS operations, which determine patient outcome. There is an urgent need for studies on large datasets and external validation of the AI algorithms used. Furthermore, the results should be transparent and meaningful to surgeons, enabling them to inform patients in layman's words. Review Registry Unique Identifying Number: reviewregistry1225.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20813,""
"Estimating Redundancy in Clinical Text","Searle, Ibrahim, Teo, Dobson","https://doi.org/10.1016/j.jbi.2021.103938","20211025","PubMed","Deep transfer learning for language modelling of clinical text; Natural language processing methods to estimate redundancy of clinical text","The current mode of use of Electronic Health Records (EHR) elicits text redundancy. Clinicians often populate new documents by duplicating existing notes, then updating accordingly. Data duplication can lead to propagation of errors, inconsistencies and misreporting of care. Therefore, measures to quantify information redundancy play an essential role in evaluating innovations that operate on clinical narratives. This work is a quantitative examination of information redundancy in EHR notes. We present and evaluate two methods to measure redundancy: an information-theoretic approach and a lexicosyntactic and semantic model. Our first measure trains large Transformer-based language models using clinical text from a large openly available US-based ICU dataset and a large multi-site UK based Hospital. By comparing the information-theoretic efficient encoding of clinical text against open-domain corpora, we find that clinical text is Ã¢Ë†Â¼1.5x to Ã¢Ë†Â¼3x less efficient than open-domain corpora at conveying information. Our second measure, evaluates automated summarisation metrics Rouge and BERTScore to evaluate successive note pairs demonstrating lexicosyntactic and semantic redundancy, with averages from Ã¢Ë†Â¼43 to Ã¢Ë†Â¼65%.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20814,""
"Systematic Review and Meta-Analysis of 3 Treatment Arms for Vertebral Compression Fractures: A Comparison of Improvement in Pain, Adjacent-Level Fractures, and Quality of Life Between Vertebroplasty, Kyphoplasty, and Nonoperative Management","Halvachizadeh, Stalder, Bellut, Hoppe, Rossbach, Cianfoni, Schnake, Mica, Pfeifer, Sprengel, Pape","https://doi.org/10.2106/JBJS.RVW.21.00045","20211027","PubMed","","Osteoporotic vertebral fractures (OVFs) have become increasingly common, and previous nonrandomized and randomized controlled trials (RCTs) have compared the effects of cement augmentation versus nonoperative management on the clinical outcome. This meta-analysis focuses on RCTs and the calculated differences between cement augmentation techniques and nonsurgical management in outcome (e.g., pain reduction, adjacent-level fractures, and quality of life [QOL]). A systematic review was performed according to the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines, and the following scientific search engines were used: MEDLINE, Embase, Cochrane, Web of Science, and Scopus. The inclusion criteria included RCTs that addressed different treatment strategies for OVF. The primary outcome was pain, which was determined by a visual analog scale (VAS) score; the secondary outcomes were the risk of adjacent-level fractures and QOL (as determined by the EuroQol-5 Dimension [EQ-5D] questionnaire, the Oswestry Disability Index [ODI], the Quality of Life Questionnaire of the European Foundation for Osteoporosis [QUALEFFO], and the Roland-Morris Disability Questionnaire [RDQ]). Patients were assigned to 3 groups according to their treatment: vertebroplasty (VP), kyphoplasty (KP), and nonoperative management (NOM). The short-term (weeks), midterm (months), and long-term (&gt;1 year) effects were compared. A random effects model was used to summarize the treatment effect, including I2 for assessing heterogeneity and the revised Cochrane risk-of-bias 2 (RoB 2) tool for assessment of ROB. Funnel plots were used to assess risk of publication bias. The log of the odds ratio (OR) between treatments is reported. After screening of 1,861 references, 53 underwent full-text analysis and 16 trials (30.2%) were included. Eleven trials (68.8%) compared VP and NOM, 1 (6.3%) compared KP and NOM, and 4 (25.0%) compared KP and VP. Improvement of pain was better by 1.31 points (95% confidence interval [CI], 0.41 to 2.21; p &lt; 0.001) after VP when compared with NOM in short-term follow-up. Pain effects were similar after VP and KP (midterm difference of 0.0 points; 95% CI, -0.25 to 0.25). The risk of adjacent-level fractures was not increased after any treatment (log OR, -0.16; 95% CI, -0.83 to 0.5; NOM vs. VP or KP). QOL did not differ significantly between the VP or KP and NOM groups except in the short term when measured by the RDQ. This meta-analysis provides evidence in favor of the surgical treatment of OVFs. Surgery was associated with greater improvement of pain and was unrelated to the development of adjacent-level fractures or QOL. Although improvements in sagittal balance after surgery were poorly documented, surgical treatment may be warranted if pain is a relevant problem. Therapeutic Level I. See Instructions for Authors for a complete description of levels of evidence.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20815,""
"Evaluating the Clinical Feasibility of an Artificial Intelligence-Powered, Web-Based Clinical Decision Support System for the Treatment of Depression in Adults: Longitudinal Feasibility Study","Popescu, Golden, Benrimoh, Tanguay-Sela, Slowey, Lundrigan, Williams, Desormeau, Kardani, Perez, Rollins, Israel, Perlman, Armstrong, Baxter, Whitmore, Fradette, Felcarek-Hope, Soufi, Fratila, Mehltretter, Looper, Steiner, Rej, Karp, Heller, Parikh, McGuire-Snieckus, Ferrari, Margolese, Turecki","https://doi.org/10.2196/31862","20211027","PubMed","artificial intelligence; clinical decision support system; feasibility; major depressive disorder; mobile phone; usability","Approximately two-thirds of patients with major depressive disorder do not achieve remission during their first treatment. There has been increasing interest in the use of digital, artificial intelligence-powered clinical decision support systems (CDSSs) to assist physicians in their treatment selection and management, improving the personalization and use of best practices such as measurement-based care. Previous literature shows that for digital mental health tools to be successful, the tool must be easy for patients and physicians to use and feasible within existing clinical workflows. This study aims to examine the feasibility of an artificial intelligence-powered CDSS, which combines the operationalized 2016 Canadian Network for Mood and Anxiety Treatments guidelines with a neural network-based individualized treatment remission prediction. Owing to the COVID-19 pandemic, the study was adapted to be completed entirely remotely. A total of 7 physicians recruited outpatients diagnosed with major depressive disorder according to the Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition criteria. Patients completed a minimum of one visit without the CDSS (baseline) and 2 subsequent visits where the CDSS was used by the physician (visits 1 and 2). The primary outcome of interest was change in appointment length after the introduction of the CDSS as a proxy for feasibility. Feasibility and acceptability data were collected through self-report questionnaires and semistructured interviews. Data were collected between January and November 2020. A total of 17 patients were enrolled in the study; of the 17 patients, 14 (82%) completed the study. There was no significant difference in appointment length between visits (introduction of the tool did not increase appointment length; F<sub>2,24</sub>=0.805; mean squared error 58.08; P=.46). In total, 92% (12/13) of patients and 71% (5/7) of physicians felt that the tool was easy to use; 62% (8/13) of patients and 71% (5/7) of physicians rated that they trusted the CDSS. Of the 13 patients, 6 (46%) felt that the patient-clinician relationship significantly or somewhat improved, whereas 7 (54%) felt that it did not change. Our findings confirm that the integration of the tool does not significantly increase appointment length and suggest that the CDSS is easy to use and may have positive effects on the patient-physician relationship for some patients. The CDSS is feasible and ready for effectiveness studies. ClinicalTrials.gov NCT04061642; http://clinicaltrials.gov/ct2/show/NCT04061642.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20816,""
"Adverse Drug Event Prediction Using Noisy Literature-Derived Knowledge Graphs: Algorithm Development and Validation","Dasgupta, Jayagopal, Jun Hong, Mariappan, Rajan","https://doi.org/10.2196/32730","20211027","PubMed","Embedding of Semantic Predications; adverse drug event; biomedical literature; knowledge graph","Adverse drug events (ADEs) are unintended side effects of drugs that cause substantial clinical and economic burdens globally. Not all ADEs are discovered during clinical trials; therefore, postmarketing surveillance, called pharmacovigilance, is routinely conducted to find unknown ADEs. A wealth of information, which facilitates ADE discovery, lies in the growing body of biomedical literature. Knowledge graphs (KGs) encode information from the literature, where the vertices and the edges represent clinical concepts and their relations, respectively. The scale and unstructured form of the literature necessitates the use of natural language processing (NLP) to automatically create such KGs. Previous studies have demonstrated the utility of such literature-derived KGs in ADE prediction. Through unsupervised learning of the representations (features) of clinical concepts from the KG, which are used in machine learning models, state-of-the-art results for ADE prediction were obtained on benchmark data sets. Due to the use of NLP to infer literature-derived KGs, there is noise in the form of false positive (erroneous) and false negative (absent) nodes and edges. Previous representation learning methods do not account for such inaccuracies in the graph. NLP algorithms can quantify the confidence in their inference of extracted concepts and relations from the literature. Our hypothesis, which motivates this work, is that by using such confidence scores during representation learning, the learned embeddings would yield better features for ADE prediction models. We developed methods to use these confidence scores on two well-known representation learning methods-DeepWalk and Translating Embeddings for Modeling Multi-relational Data (TransE)-to develop their weighted versions: Weighted DeepWalk and Weighted TransE. These methods were used to learn representations from a large literature-derived KG, the Semantic MEDLINE Database, which contains more than 93 million clinical relations. They were compared with Embedding of Semantic Predications, which, to our knowledge, is the best reported representation learning method using the Semantic MEDLINE Database with state-of-the-art results for ADE prediction. Representations learned from different methods were used (separately) as features of drugs and diseases to build classification models for ADE prediction using benchmark data sets. The methods were compared rigorously over multiple cross-validation settings. The weighted versions we designed were able to learn representations that yielded more accurate predictive models than the corresponding unweighted versions of both DeepWalk and TransE, as well as Embedding of Semantic Predications, in our experiments. There were performance improvements of up to 5.75% in the F<sub>1</sub>-score and 8.4% in the area under the receiver operating characteristic curve value, thus advancing the state of the art in ADE prediction from literature-derived KGs. Our classification models can be used to aid pharmacovigilance teams in detecting potentially new ADEs. Our experiments demonstrate the importance of modeling inaccuracies in the inferred KGs for representation learning.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20817,""
"Knowledge, attitude, practice and barriers towards pharmacovigilance and adverse drug reactions reporting among healthcare professionals in Turkey: a systematic review","Khan, Karatas, Martins, Jamshed, Rahman","https://doi.org/10.1080/03007995.2021.1997287","20211025","PubMed","Pharmacovigilance; Turkey; adverse drug reactions; healthcare professionals; survey","Globally, pharmacovigilance (PV) is crucial for the patient's safety and proper use of drugs. Spontaneous reporting of adverse drug reaction (ADR) is a professional obligation of every healthcare professionals (HCPs). The purpose of this systematic review was to analyze the existing literature about the knowledge, attitude, and practices (KAP) level of HCPs regarding PV and ADRs reporting in Turkey. A systematic and comprehensive articles search strategy was carried out in different seven electronic databases (PubMed, PubMed Central, Goggle Scholar, Ovid-SP, MEDLINE, Wiley Online Library, DergiPark) from 2010 to 2020. We searched to identify existing literature about cross-sectional observational studies investigating the KAP of HCPs regarding PV and ADRs reporting in different geographical regions of Turkey. Quality assessment and risk of bias were assessed among included studies. Fifteen studies were chosen for full-text analysis. Finally, according to inclusion criteria, seven research articles were selected for systematic review. Overall, the KAP of HCPs varies across the studies. The lack of a standardized validated measuring tool to evaluate the KAP and differences in questionnaire items were the main limitations in included studies. Around, 69.1% (range: 54.6-100%) of HCPs were not aware of the national pharmacovigilance center in Turkey. About, 37.5% (range: 7.1-75.7%) of HCPs believed that reporting of ADRs is not important and 87.5% (range: 69.3-100%) stated that they never reported ADR previously during their practice. The most frequently highlighted barriers to PV were lack of time, uncertainty and did not know where to report. This systematic review revealed a major KAP gap in Turkey towards PV activities. Low ADR reporting practice of HCPs was a major identified issue. The creation of a mandatory unified PV education intervention for future HCPs to rationally report ADR of drugs are crucial for a better healthcare system.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20818,""
"Machine learning applications for therapeutic tasks with genomics data","Huang, Xiao, Glass, Critchlow, Gibson, Sun","https://doi.org/10.1016/j.patter.2021.100328","20211026","PubMed","genomics; machine learning; therapeutics discovery and development","Thanks to the increasing availability of genomics and other biomedical data, many machine learning algorithms have been proposed for a wide range of therapeutic discovery and development tasks. In this survey, we review the literature on machine learning applications for genomics through the lens of therapeutic development. We investigate the interplay among genomics, compounds, proteins, electronic health records, cellular images, and clinical texts. We identify 22 machine learning in genomics applications that span the whole therapeutics pipeline, from discovering novel targets, personalizing medicine, developing gene-editing tools, all the way to facilitating clinical trials and post-market studies. We also pinpoint seven key challenges in this field with potentials for expansion and impact. This survey examines recent research at the intersection of machine learning, genomics, and therapeutic development.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20819,""
"Change in Threads on Twitter Regarding Influenza, Vaccines, and Vaccination During the COVID-19 Pandemic: Artificial Intelligence-Based Infodemiology Study","Benis, Chatsubi, Levner, Ashkenazi","https://doi.org/10.2196/31983","20211026","PubMed","COVID-19; SARS-CoV-2; artificial intelligence; health communication; influenza; infodemiology; machine learning; social media; social networks; text mining; vaccination; vaccines","Discussions of health issues on social media are a crucial information source reflecting real-world responses regarding events and opinions. They are often important in public health care, since these are influencing pathways that affect vaccination decision-making by hesitant individuals. Artificial intelligence methodologies based on internet search engine queries have been suggested to detect disease outbreaks and population behavior. Among social media, Twitter is a common platform of choice to search and share opinions and (mis)information about health care issues, including vaccination and vaccines. Our primary objective was to support the design and implementation of future eHealth strategies and interventions on social media to increase the quality of targeted communication campaigns and therefore increase influenza vaccination rates. Our goal was to define an artificial intelligence-based approach to elucidate how threads in Twitter on influenza vaccination changed during the COVID-19 pandemic. Such findings may support adapted vaccination campaigns and could be generalized to other health-related mass communications. The study comprised the following 5 stages: (1) collecting tweets from Twitter related to influenza, vaccines, and vaccination in the United States; (2) data cleansing and storage using machine learning techniques; (3) identifying terms, hashtags, and topics related to influenza, vaccines, and vaccination; (4) building a dynamic folksonomy of the previously defined vocabulary (terms and topics) to support the understanding of its trends; and (5) labeling and evaluating the folksonomy. We collected and analyzed 2,782,720 tweets of 420,617 unique users between December 30, 2019, and April 30, 2021. These tweets were in English, were from the United States, and included at least one of the following terms: ""flu,"" ""influenza,"" ""vaccination,"" ""vaccine,"" and ""vaxx."" We noticed that the prevalence of the terms vaccine and vaccination increased over 2020, and that ""flu"" and ""covid"" occurrences were inversely correlated as ""flu"" disappeared over time from the tweets. By combining word embedding and clustering, we then identified a folksonomy built around the following 3 topics dominating the content of the collected tweets: ""health and medicine (biological and clinical aspects),"" ""protection and responsibility,"" and ""politics."" By analyzing terms frequently appearing together, we noticed that the tweets were related mainly to COVID-19 pandemic events. This study focused initially on vaccination against influenza and moved to vaccination against COVID-19. Infoveillance supported by machine learning on Twitter and other social media about topics related to vaccines and vaccination against communicable diseases and their trends can lead to the design of personalized messages encouraging targeted subpopulations' engagement in vaccination. A greater likelihood that a targeted population receives a personalized message is associated with higher response, engagement, and proactiveness of the target population for the vaccination process.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20820,""
"Barriers and facilitators to answering clinical questions in the Americas: a cross-sectional study of surgical trauma care providers","Noble, Vega Rivera, LaGrone","https://doi.org/10.1136/tsaco-2021-000774","20211026","PubMed","education; medical; practice guideline","We aimed to understand how surgical trauma providers in the Americas acquire answers to clinical questions and what barriers and facilitators they face in efforts to practice according to recommendations for common surgical cases. We hypothesized that increased English proficiency and country income improved providers' acquisition and application of clinical knowledge. A 23-question survey evaluated reported confidence in interpretation of evidence, perceived language fluency, and access to and application of recommendations on sepsis and appendicitis. Electronic surveys were distributed across the Americas to Pan American Trauma Society members. 108 participants from 21 countries completed this survey. 59% had Ã¢â€°Â¥21 years of provider experience. 38% reported their English reading comprehension as less than or equal to ""limited working proficiency."" 44% endorsed using Google Translate; 35% reported they did not need translation tools to evaluate medical literature. 59% felt uncertainty regarding clinical care at least weekly. 65% reported inability to answer their clinical questions at least once per month. 86% felt confident in their ability to interpret and apply evidence for their practice. To answer clinical questions, participants listed guidelines (76%), full-text peer-reviewed journal articles (61%), and meta-analyses (49%) as their most used resources. 25% answered all five clinical questions correctly, whereas 43% answered three or fewer correctly. 79% felt they had adequate access to resources to answer the five clinical questions. When controlling for individual demographic characteristics, decreased age (p&lt;0.01) and increased country income level (p=0.03) positively impacted correct answers to questions. Uncertainties in clinical care are unavoidable. Language, age, and country income level impacted provider acquisition and application of knowledge relevant to select clinical scenarios. These findings highlight disparities in access and training and add urgency to the movement for improved dissemination and implementation approaches for evidence-based practice in surgery. IV.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20821,""
"Respiratory Outcomes in Patients Following COVID-19-Related Hospitalization: A Meta-Analysis","Guo, Jiang, Liu, Zhao, Li, Wang","https://doi.org/10.3389/fmolb.2021.750558","20211026","PubMed","COVID-19; DLCO; FVC; follow-up; meta-analysis; pulmonary function test; synthesis review","<b>Background:</b> To determine the respiratory outcomes in patients following COVID-19-related hospitalization. <b>Methods:</b> Systematic review and meta-analysis of the literature. <b>Results:</b> Forced vital capacity (FVC, % of predicted): 0-3Ã‚Â months post discharge: 96.1, 95% CI [82.1-110.0]; 3-6Ã‚Â months post discharge: 99.9, 95% CI [84.8, 115.0]; &gt;6 months post discharge: 97.4, 95% CI [76.8-118.0]. Diffusing capacity of the lungs for carbon monoxide (DLCO, % of predicted): 0-3Ã‚Â months post discharge: 83.9, 95% CI [68.9-98.9]; 3-6Ã‚Â months post discharge: 91.2, 95% CI [74.8-107.7]; &gt;6Ã‚Â months post discharge: 97.3, 95% CI [76.7-117.9]. Percentage of patients with FVC less than 80% of predicted: 0-3Ã‚Â months post discharge: 10%, 95% CI [6-14%]; 3-6Ã‚Â months post discharge: 10%, 95% CI [2-18%]; &gt;6Ã‚Â months post discharge: 13%, 95% CI [8-18%]. Percentage of patients with DLCO less than 80% of predicted: 0-3Ã‚Â months post discharge: 48%, 95% CI [41-56%]; 3-6Ã‚Â months post discharge: 33%, 95% CI [23-44%]; &gt;6Ã‚Â months post discharge: 43%, 95% CI [22-65%]. <b>Conclusion:</b> The meta-analysis confirms a high prevalence of persistent lung diffusion impairment in patients following COVID-19-related hospitalization. Routine respiratory follow-up is thus strongly recommended.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20822,""
"Tiny noise, big mistakes: adversarial perturbations induce errors in brain-computer interface spellers","Zhang, Wu, Ding, Luo, Lin, Jung, Chavarriaga","https://doi.org/10.1093/nsr/nwaa233","20211026","PubMed","BCI spellers; adversarial examples; brain-computer interfaces; electroencephalogram","An electroencephalogram (EEG)-based brain-computer interface (BCI) speller allows a user to input text to a computer by thought. It is particularly useful to severely disabled individuals, e.g. amyotrophic lateral sclerosis patients, who have no other effective means of communication with another person or a computer. Most studies so far focused on making EEG-based BCI spellers faster and more reliable; however, few have considered their security. This study, for the first time, shows that P300 and steady-state visual evoked potential BCI spellers are very vulnerable, i.e. they can be severely attacked by adversarial perturbations, which are too tiny to be noticed when added to EEG signals, but can mislead the spellers to spell anything the attacker wants. The consequence could range from merely user frustration to severe misdiagnosis in clinical applications. We hope our research can attract more attention to the security of EEG-based BCI spellers, and more broadly, EEG-based BCIs, which has received little attention before.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20823,""
"Predicting Crime and Other Uses of Neural Networks in Police Decision Making","Walczak","https://doi.org/10.3389/fpsyg.2021.587943","20211026","PubMed","crime; geo-spatial reasoning; literature review; location; neural network; police; temporal reasoning","Neural networks are a machine learning method that excel in solving classification and forecasting problems. They have also been shown to be a useful tool for working with big data oriented environments such as law enforcement. This article reviews and examines existing research on the utilization of neural networks for forecasting crime and other police decision making problem solving. Neural network models to predict specific types of crime using location and time information and to predict a crime's location when given the crime and time of day are developed to demonstrate the application of neural networks to police decision making. The neural network crime prediction models utilize geo-spatiality to provide immediate information on crimes to enhance law enforcement decision making. The neural network models are able to predict the type of crime being committed 16.4% of the time for 27 different types of crime or 27.1% of the time when similar crimes are grouped into seven categories of crime. The location prediction neural networks are able to predict the zip code location or adjacent location 31.2% of the time.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20824,""
"The colors of our brain: an integrated approach for dimensionality reduction and explainability in fMRI through color coding (i-ECO)","Tarchi, Damiani, La Torraca Vittori, Marini, Nazzicari, Castellini, Pisano, Politi, Ricca","https://doi.org/10.1007/s11682-021-00584-8","20211024","PubMed","Eigenvector Centrality; Psychiatry; ReHo; fALFF; fMRI","Several systematic reviews have highlighted the role of multiple sources in the investigation of psychiatric illness. For what concerns fMRI, the focus of recent literature preferentially lies on three lines of research, namely: functional connectivity, network analysis and spectral analysis. Data was gathered from the UCLA Consortium for Neuropsychiatric Phenomics. The sample was composed by 130 neurotypicals, 50 participants diagnosed with Schizophrenia, 49 with Bipolar disorder and 43 with ADHD. Single fMRI scans were reduced in their dimensionality by a novel method (i-ECO) averaging results per Region of Interest and through an additive color method (RGB): local connectivity values (Regional Homogeneity), network centrality measures (Eigenvector Centrality), spectral dimensions (fractional Amplitude of Low-Frequency Fluctuations). Average images per diagnostic group were plotted and described. The discriminative power of this novel method for visualizing and analyzing fMRI results in an integrative manner was explored through the usage of convolutional neural networks. The new methodology of i-ECO showed between-groups differences that could be easily appreciated by the human eye. The precision-recall Area Under the Curve (PR-AUC) of our models wasÃ¢â‚¬â€°&gt;Ã¢â‚¬â€°84.5% for each diagnostic group as evaluated on the test-set - 80/20 split. In conclusion, this study provides evidence for an integrative and easy-to-understand approach in the analysis and visualization of fMRI results. A high discriminative power for psychiatric conditions was reached. This proof-of-work study may serve to investigate further developments over more extensive datasets covering a wider range of psychiatric diagnoses.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20825,""
"Subgroups of patients with young-onset type 2 diabetes in India reveal insulin deficiency as a major driver","Prasad, Asplund, Shukla, Wagh, Kunte, Bhat, Parikh, Shah, Phatak, KÃƒÂ¤rÃƒÂ¤jÃƒÂ¤mÃƒÂ¤ki, Datta, Kakati, Tuomi, Saboo, Ahlqvist, Groop, Yajnik","https://doi.org/10.1007/s00125-021-05543-y","20211024","PubMed","Europe; India; Insulin deficiency; Subgroups; Type 2 diabetes; Young-onset type 2 diabetes","Five subgroups were described in European diabetes patients using a data driven machine learning approach on commonly measured variables. We aimed to test the applicability of this phenotyping in Indian individuals with young-onset type 2 diabetes. We applied the European-derived centroids to Indian individuals with type 2 diabetes diagnosed before 45Ã‚Â years of age from the WellGen cohort (nÃ¢â‚¬â€°=Ã¢â‚¬â€°1612). We also applied de novo k-means clustering to the WellGen cohort to validate the subgroups. We then compared clinical and metabolic-endocrine characteristics and the complication rates between the subgroups. We also compared characteristics of the WellGen subgroups with those of two young European cohorts, ANDIS (nÃ¢â‚¬â€°=Ã¢â‚¬â€°962) and DIREVA (nÃ¢â‚¬â€°=Ã¢â‚¬â€°420). Subgroups were also assessed in two other Indian cohorts, Ahmedabad (nÃ¢â‚¬â€°=Ã¢â‚¬â€°187) and PHENOEINDY-2 (nÃ¢â‚¬â€°=Ã¢â‚¬â€°205). Both Indian and European young-onset type 2 diabetes patients were predominantly classified into severe insulin-deficient (SIDD) and mild obesity-related (MOD) subgroups, while the severe insulin-resistant (SIRD) and mild age-related (MARD) subgroups were rare. In WellGen, SIDD (53%) was more common than MOD (38%), contrary to findings in Europeans (Swedish 26% vs 68%, Finnish 24% vs 71%, respectively). A higher proportion of SIDD compared with MOD was also seen in Ahmedabad (57% vs 33%) and in PHENOEINDY-2 (67% vs 23%). Both in Indians and Europeans, the SIDD subgroup was characterised by insulin deficiency and hyperglycaemia, MOD by obesity, SIRD by severe insulin resistance and MARD by mild metabolic-endocrine disturbances. In WellGen, nephropathy and retinopathy were more prevalent in SIDD compared with MOD while the latter had higher prevalence of neuropathy. Our data identified insulin deficiency as the major driver of type 2 diabetes in young Indians, unlike in young European individuals in whom obesity and insulin resistance predominate. Our results provide useful clues to pathophysiological mechanisms and susceptibility to complications in type 2 diabetes in the young Indian population and suggest a need to review management strategies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20826,""
"Default-mode and fronto-parietal network connectivity during rest distinguishes asymptomatic patients with bipolar disorder and major depressive disorder","Rai, Griffiths, Breukelaar, Barreiros, Chen, Boyce, Hazell, Foster, Malhi, Harris, Korgaonkar","https://doi.org/10.1038/s41398-021-01660-9","20211024","PubMed","","Bipolar disorder (BD) is commonly misdiagnosed as major depressive disorder (MDD). This is understandable, as depression often precedes mania and is otherwise indistinguishable in both. It is therefore imperative to identify neural mechanisms that can differentiate the two disorders. Interrogating resting brain neural activity may reveal core distinguishing abnormalities. We adopted an a priori approach, examining three key networks documented in previous mood disorder literature subserving executive function, salience and rumination that may differentiate euthymic BD and MDD patients. Thirty-eight patients with BD, 39 patients with MDD matched for depression severity, and 39 age-gender matched healthy controls, completed resting-state fMRI scans. Seed-based and data-driven Independent Component analyses (ICA) were implemented to examine group differences in resting-state connectivity (pFDRÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.05). Seed analysis masks were target regions identified from the fronto-parietal (FPN), salience (SN) and default-mode (DMN) networks. Seed-based analyses identified significantly greater connectivity between the subgenual cingulate cortex (DMN) and right dorsolateral prefrontal cortex (FPN) in BD relative to MDD and controls. The ICA analyses also found greater connectivity between the DMN and inferior frontal gyrus, an FPN region in BD relative to MDD. There were also significant group differences across the three networks in both clinical groups relative to controls. Altered DMN-FPN functional connectivity is thought to underlie deficits in the processing, management and regulation of affective stimuli. Our results suggest that connectivity between these networks could potentially distinguish the two disorders and could be a possible trait mechanism in BD persisting even in the absence of symptoms.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20827,""
"Alterations in large-scale functional networks in adult posttraumatic stress disorder: A systematic review and meta-analysis of resting-state functional connectivity studies","Bao, Gao, Cao, Li, Liu, Liang, Hu, Zhang, Hu, Gong, Huang","https://doi.org/10.1016/j.neubiorev.2021.10.017","20211030","PubMed","Brain networks; Functional connectivity; Meta-analysis; Posttraumatic stress disorder; Resting-state; fMRI","Posttraumatic stress disorder (PTSD) is associated with dysfunction in large-scale brain functional networks, as revealed by resting-state functional connectivity studies. However, it remains unclear which networks have been most consistently affected and, more importantly, what role disease and trauma may play in the disrupted functional networks. We performed a systematic review of studies exploring network alterations using seed-based functional connectivity analysis, comparing individuals with PTSD to controls in general as well as trauma-exposed or nonexposed controls specifically, and quantitative meta-analysis was conducted when the number of studies was appropriately high. We found that hypoconnectivity within the default-mode network (DMN) as well as between the affective network (AN) and DMN were specifically associated with traumatic experience. Additionally, hyperconnectivity between the AN and somatomotor network (SMN) and between the DMN and SMN were specifically related to PTSD. Our results emphasize the effect of trauma itself on alterations in intrinsic brain networks and highlight disease-associated network alterations, which may help us better understand the neural mechanisms of trauma and PTSD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20828,""
"A muggles guide to deep learning wizardry","Currie","https://doi.org/10.1016/j.radi.2021.10.004","20211024","PubMed","Artificial intelligence; Convolutional neural network; Deep learning","Growing interest in the applications of artificial intelligence (AI) and, in particular, deep learning (DL) in nuclear medicine and radiology partitions the professional community. At one end of the spectrum are our expert DL wizards developing potion-like code and waving the DL capabilities like a wand across our professions. On the opposite side of the spectrum are our muggle colleagues who lack the wizardry of DL and may be largely oblivious to the entire magical realm. As crafted by Arthur C Clark, any sufficiently advanced technology is indistinguishable from magic. DL is not only an important technology in the future of medical imaging, but its application lives in the capabilities of medical imaging technologists. This may be incidental through application of techniques at the patient interface, through role expansion in data curation and management, or as active members of DL projects and development. Understanding the rudimentary principles of DL is emerging as requisite in medical imaging. AI and DL are valuable tools in advancing capabilities and outcomes in medical imaging. A working knowledge of the technology and techniques is important and achievable for the medical imaging technologist even when capability in application of DL to research and clinical practice is not within one's interests or scope of practice. While there is no requisite for all of the professional community to be tutored in the wizardry of DL, there are benefits for the profession and our patients for all to have a rudimentary understanding of the language and landscape. The breadth of DL literature assumes a level of understanding not evident for the bulk of our professions. This manuscript provides a simplified primer on DL with the aim of arming the muggles among us with sufficient insight to navigate the magical realm of DL without transferring any wizardry capability itself.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20829,""
"Current status and future perspectives on the Internet of Things in oncology","Muhsen, Rasheed, Habib, Alsaad, Maghrabi, Rahman, Sicker, Wood, Beg, Sung, Hashmi","https://doi.org/10.1016/j.hemonc.2021.09.003","20211023","PubMed","Cancer; Internet of medical things; Oncology; Wearables","The Internet of Things (IoT) has penetrated many aspects of everyday human life. The use of IoT in healthcare has been expanding over the past few years. In this review, we highlighted the current applications of IoT in the medical literature, along with the challenges and opportunities. IoT use mainly involves sensors and wearables, with potential applications in improving the quality of life, personal health monitoring, and diagnosis of diseases. Our literature review highlights that the current main application studied in the literature is physical activity tracking. In addition, we discuss the current technologies that would help IoT-enabled devices achieve safe, quick, and meaningful data transfer. These technologies include machine learning/artificial intelligence, 5G, and blockchain. Data on current IoT-enabled devices are still limited, and future research should address these devices' effect on patients' outcomes and the methods by which their integration in healthcare will avoid increasing costs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20830,""
"Augmenting BDI Agency with a Cognitive Service: Architecture and Validation in Healthcare Domain","Montagna, Mariani, Gamberini","https://doi.org/10.1007/s10916-021-01780-1","20211026","PubMed","BDI; Cognitive Services; Machine learning; Personal medical digital assistant; Trauma management; Cognition; Delivery of Health Care; Humans; Knowledge; Machine Learning; Triage","Autonomous intelligent systems are starting to influence clinical practice, as ways to both readily exploit experts' knowledge when contextual conditions demand so, and harness the overwhelming amount of patient related data currently at clinicians' disposal. However, these two approaches are rarely synergistically exploited, and tend to be used without integration. In this paper, we follow recent efforts reported in theÃ‚Â literature regarding integration of BDI agency with machine learning based Cognitive Services, by proposing an integration architecture, and by validating such architecture in the complex domain of trauma management. In particular, we show that augmentation of a BDI agent, endowed with predefined plans encoding experts' knowledge, with a Cognitive Service, trained on past observed data, can enhance trauma management by reducing over triage episodes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20831,""
"COVID-19 Mortality Risk Correlates Inversely with Vitamin D3 Status, and a Mortality Rate Close to Zero Could Theoretically Be Achieved at 50 ng/mL 25(OH)D3: Results of a Systematic Review and Meta-Analysis","Borsche, Glauner, von Mendel","https://doi.org/10.3390/nu13103596","20211026","PubMed","ACE2; ARDS; COVID-19; CRS; D3; SARS-CoV-2; angiotensin; calcidiol; calcitriol; cytokine release syndrome; immune status; immunodeficiency; inflammation; mortality; renin; virus infection; vitamin D","Much research shows that blood calcidiol (25(OH)D3) levels correlate strongly with SARS-CoV-2 infection severity. There is open discussion regarding whether low D3 is caused by the infection or if deficiency negatively affects immune defense. The aim of this study was to collect further evidence on this topic. Systematic literature search was performed to identify retrospective cohort as well as clinical studies on COVID-19 mortality rates versus D3 blood levels. Mortality rates from clinical studies were corrected for age, sex, and diabetes. Data were analyzed using correlation and linear regression. One population study and seven clinical studies were identified, which reported D3 blood levels preinfection or on the day of hospital admission. The two independent datasets showed a negative Pearson correlation of D3 levels and mortality risk (r(17) = -0.4154, <i>p</i> = 0.0770/r(13) = -0.4886, <i>p</i> = 0.0646). For the combined data, median (IQR) D3 levels were 23.2 ng/mL (17.4-26.8), and a significant Pearson correlation was observed (r(32) = -0.3989, <i>p</i> = 0.0194). Regression suggested a theoretical point of zero mortality at approximately 50 ng/mL D3. The datasets provide strong evidence that low D3 is a predictor rather than just a side effect of the infection. Despite ongoing vaccinations, we recommend raising serum 25(OH)D levels to above 50 ng/mL to prevent or mitigate new outbreaks due to escape mutations or decreasing antibody activity.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20832,""
"User Perception of Automated Dose Dispensed Medicine in Home Care: A Scoping Review","Mertz, Tornbjerg, NÃƒÂ¸hr","https://doi.org/10.3390/healthcare9101381","20211027","PubMed","automated dose dispensing; multi dose dispensing; primary healthcare; user experience","(1) Background: Automated dose dispensing (ADD) systems are today used around the world. The ADD robots are placed in patients' homes to increase medication safety as well as medication adherence; however, little is known about how ADD robots affect the patient's day-to-day lives, receiving the daily doses of medicine from a machine rather than from a human healthcare professional. The aim of this study is to review the available literature on users' perceptions of having an ADD robot and collect evidence on how they perceive having less human contact after implementing this technology in their homes. (2) Methods: References were searched for in Embase and PubMed. Literature investigating ADD robots in primary healthcare was included in this study and literature in a hospital setting was excluded. After screening processes, eleven publications were included in this review. (3) Results: The literature reported high medication adherence when using ADD robots and general satisfaction in terms of user experiences with the acceptability and functionality of ADD. (4) Conclusion: The review is the first focusing on user experience and perceptions regarding ADD robots. General satisfaction was shown towards ADD robots as an intervention, but the review indicates that research is missing on healthcare professionals and patient perceptions on how ADD affects their routines, both in relation to work and daily life.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20833,""
"The Development of Electronic Health and Artificial Intelligence in Surgery after the SARS-CoV-2 Pandemic-A Scoping Review","Taha-Mehlitz, Hendie, Taha","https://doi.org/10.3390/jcm10204789","20211026","PubMed","COVID-19; SARS-CoV-2; artificial intelligence; eHealth; pandemic; surgery","SARS-CoV-2 has significantly transformed the healthcare environment, and it has triggered the development of electronic health and artificial intelligence mechanisms, for instance. In this overview, we concentrated on enhancing the two concepts in surgery after the pandemic, and we examined the factors on a global scale. The primary goal of this scoping review is to elaborate on how surgeons have used eHealth and AI before; during; and after the current global pandemic. More specifically, this review focuses on the empowerment of the concepts of electronic health and artificial intelligence after the pandemic; which mainly depend on the efforts of countries to advance the notions of surgery. The use of an online search engine was the most applied method. The publication years of all the studies included in the study ranged from 2013 to 2021. Out of the reviewed studies; forty-four qualified for inclusion in the review. We evaluated the prevalence of the concepts in different continents such as the United States; Europe; Asia; the Middle East; and Africa. Our research reveals that the success of eHealth and artificial intelligence adoption primarily depends on the efforts of countries to advance the notions in surgery. The study's primary limitation is insufficient information on eHealth and artificial intelligence concepts; particularly in developing nations. Future research should focus on establishing methods of handling eHealth and AI challenges around confidentiality and data security.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20834,""
"Climate Change and Child Health Inequality: A Review of Reviews","Arpin, Gauffin, Kerr, Hjern, Mashford-Pringle, Barros, Rajmil, Choonara, Spencer","https://doi.org/10.3390/ijerph182010896","20211101","PubMed","children; climate change; global health; health inequality; scoping review; Adolescent; Child; Child Health; Climate Change; Health Status Disparities; Humans; Income; Poverty","There is growing evidence on the observed and expected consequences of climate change on population health worldwide. There is limited understanding of its consequences for child health inequalities, between and within countries. To examine these consequences and categorize the state of knowledge in this area, we conducted a review of reviews indexed in five databases (Medline, Embase, Web of Science, PsycInfo, Sociological Abstracts). Reviews that reported the effect of climate change on child health inequalities between low- and high-income children, within or between countries (high- vs low-middle-income countries; HICs and LMICs), were included. Twenty-three reviews, published between 2007 and January 2021, were included for full-text analyses. Using thematic synthesis, we identified strong descriptive, but limited quantitative, evidence that climate change exacerbates child health inequalities. Explanatory mechanisms relating climate change to child health inequalities were proposed in some reviews; for example, children in LMICs are more susceptible to the consequences of climate change than children in HICs due to limited structural and economic resources. Geographic and intergenerational inequalities emerged as additional themes from the review. Further research with an equity focus should address the effects of climate change on adolescents/youth, mental health and inequalities within countries.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20835,""
"Artificial Intelligence and Computer Vision in Low Back Pain: A Systematic Review","D'Antoni, Russo, Ambrosio, Vollero, VadalÃƒÂ , Merone, Papalia, Denaro","https://doi.org/10.3390/ijerph182010909","20211101","PubMed","artificial intelligence; computer aided diagnosis; computer vision; decision support systems; deep learning; digital image processing; low back pain; orthopaedics; Artificial Intelligence; Computers; Humans; Intervertebral Disc; Low Back Pain; Reproducibility of Results","Chronic Low Back Pain (LBP) is a symptom that may be caused by several diseases, and it is currently the leading cause of disability worldwide. The increased amount of digital images in orthopaedics has led to the development of methods related to artificial intelligence, and to computer vision in particular, which aim to improve diagnosis and treatment of LBP. In this manuscript, we have systematically reviewed the available literature on the use of computer vision in the diagnosis and treatment of LBP. A systematic research of PubMed electronic database was performed. The search strategy was set as the combinations of the following keywords: ""Artificial Intelligence"", ""Feature Extraction"", ""Segmentation"", ""Computer Vision"", ""Machine Learning"", ""Deep Learning"", ""Neural Network"", ""Low Back Pain"", ""Lumbar"". Results: The search returned a total of 558 articles. After careful evaluation of the abstracts, 358 were excluded, whereas 124 papers were excluded after full-text examination, taking the number of eligible articles to 76. The main applications of computer vision in LBP include feature extraction and segmentation, which are usually followed by further tasks. Most recent methods use deep learning models rather than digital image processing techniques. The best performing methods for segmentation of vertebrae, intervertebral discs, spinal canal and lumbar muscles achieve SÃƒÂ¸rensen-Dice scores greater than 90%, whereas studies focusing on localization and identification of structures collectively showed an accuracy greater than 80%. Future advances in artificial intelligence are expected to increase systems' autonomy and reliability, thus providing even more effective tools for the diagnosis and treatment of LBP.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20836,""
"Role of Digital Health and Artificial Intelligence in Inflammatory Bowel Disease: A Scoping Review","Majidova, Handfield, Kafi, Martin, Kubinski","https://doi.org/10.3390/genes12101465","20211026","PubMed","CrohnÃ¢â‚¬â„¢s disease (CD); artificial intelligence (AI); diagnosis; digital health (DH); inflammatory bowel disease (IBD); monitoring; prognosis; treatment; ulcerative colitis (UC)","Inflammatory bowel diseases (IBD), subdivided into Crohn's disease (CD) and ulcerative colitis (UC), are chronic diseases that are characterized by relapsing and remitting periods of inflammation in the gastrointestinal tract. In recent years, the amount of research surrounding digital health (DH) and artificial intelligence (AI) has increased. The purpose of this scoping review is to explore this growing field of research to summarize the role of DH and AI in the diagnosis, treatment, monitoring and prognosis of IBD. A review of 21 articles revealed the impact of both AI algorithms and DH technologies; AI algorithms can improve diagnostic accuracy, assess disease activity, and predict treatment response based on data modalities such as endoscopic imaging and genetic data. In terms of DH, patients utilizing DH platforms experienced improvements in quality of life, disease literacy, treatment adherence, and medication management. In addition, DH methods can reduce the need for in-person appointments, decreasing the use of healthcare resources without compromising the standard of care. These articles demonstrate preliminary evidence of the potential of DH and AI for improving the management of IBD. However, the majority of these studies were performed in a regulated clinical environment. Therefore, further validation of these results in a real-world environment is required to assess the efficacy of these methods in the general IBD population.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20837,""
"Are There Limits in Explainability of Prognostic Biomarkers? Scrutinizing Biological Utility of Established Signatures","Emmert-Streib, Manjang, Dehmer, Yli-Harja, Auvinen","https://doi.org/10.3390/cancers13205087","20211026","PubMed","biostatistics; causal model; computational biology; genomics; prognostic biomarker; survival analysis","Prognostic biomarkers can have an important role in the clinical practice because they allow stratification of patients in terms of predicting the outcome of a disorder. Obstacles for developing such markers include lack of robustness when using different data sets and limited concordance among similar signatures. In this paper, we highlight a new problem that relates to the biological meaning of already established prognostic gene expression signatures. Specifically, it is commonly assumed that prognostic markers provide sensible biological information and molecular explanations about the underlying disorder. However, recent studies on prognostic biomarkers investigating 80 established signatures of breast and prostate cancer demonstrated that this is not the case. We will show that this surprising result is related to the distinction between causal models and predictive models and the obfuscating usage of these models in the biomedical literature. Furthermore, we suggest a falsification procedure for studies aiming to establish a prognostic signature to safeguard against false expectations with respect to biological utility.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20838,""
"Features of Mobile Apps for People with Autism in a Post COVID-19 Scenario: Current Status and Recommendations for Apps Using AI","Rehman, Sobnath, Nasralla, Winnett, Anwar, Asif, Sherazi","https://doi.org/10.3390/diagnostics11101923","20211026","PubMed","COVID-19; applied behaviour analysis; artificial intelligence; augmentative and alternative communication; autism; mobile apps; special educational needs","The new 'normal' defined during the COVID-19 pandemic has forced us to re-assess how people with special needs thrive in these unprecedented conditions, such as those with Autism Spectrum Disorder (ASD). These changing/challenging conditions have instigated us to revisit the usage of telehealth services to improve the quality of life for people with ASD. This study aims to identify mobile applications that suit the needs of such individuals. This work focuses on identifying features of a number of highly-rated mobile applications (apps) that are designed to assist people with ASD, specifically those features that use Artificial Intelligence (AI) technologies. In this study, 250 mobile apps have been retrieved using keywords such as autism, autism AI, and autistic. Among 250 apps, 46 were identified after filtering out irrelevant apps based on defined elimination criteria such as ASD common users, medical staff, and non-medically trained people interacting with people with ASD. In order to review common functionalities and features, 25 apps were downloaded and analysed based on eye tracking, facial expression analysis, use of 3D cartoons, haptic feedback, engaging interface, text-to-speech, use of Applied Behaviour Analysis therapy, Augmentative and Alternative Communication techniques, among others were also deconstructed. As a result, software developers and healthcare professionals can consider the identified features in designing future support tools for autistic people. This study hypothesises that by studying these current features, further recommendations of how existing applications for ASD people could be enhanced using AI for (1) progress tracking, (2) personalised content delivery, (3) automated reasoning, (4) image recognition, and (5) Natural Language Processing (NLP). This paper follows the PRISMA methodology, which involves a set of recommendations for reporting systematic reviews and meta-analyses.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20839,""
"Mining Primary Care Electronic Health Records for Automatic Disease Phenotyping: A Transparent Machine Learning Framework","FernÃƒÂ¡ndez-GutiÃƒÂ©rrez, Kennedy, Cooksey, Atkinson, Choy, Brophy, Huo, Zhou","https://doi.org/10.3390/diagnostics11101908","20211026","PubMed","artificial intelligence; big data; cohort identification; electronic health records; feature selection; phenotyping; rheumatology; text mining; transparent machine learning","(1) Background: We aimed to develop a transparent machine-learning (ML) framework to automatically identify patients with a condition from electronic health records (EHRs) via a parsimonious set of features. (2) Methods: We linked multiple sources of EHRs, including 917,496,869 primary care records and 40,656,805 secondary care records and 694,954 records from specialist surgeries between 2002 and 2012, to generate a unique dataset. Then, we treated patient identification as a problem of text classification and proposed a transparent disease-phenotyping framework. This framework comprises a generation of patient representation, feature selection, and optimal phenotyping algorithm development to tackle the imbalanced nature of the data. This framework was extensively evaluated by identifying rheumatoid arthritis (RA) and ankylosing spondylitis (AS). (3) Results: Being applied to the linked dataset of 9657 patients with 1484 cases of rheumatoid arthritis (RA) and 204 cases of ankylosing spondylitis (AS), this framework achieved accuracy and positive predictive values of 86.19% and 88.46%, respectively, for RA and 99.23% and 97.75% for AS, comparable with expert knowledge-driven methods. (4) Conclusions: This framework could potentially be used as an efficient tool for identifying patients with a condition of interest from EHRs, helping clinicians in clinical decision-support process.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20840,""
"A Systematic Review of Neurofeedback for the Management of Motor Symptoms in Parkinson's Disease","Anil, Hall, Demain, Freeman, Ganis, Marsden","https://doi.org/10.3390/brainsci11101292","20211026","PubMed","ParkinsonÃ¢â‚¬â„¢s disease; electroencephalography; movement; neural network activity; neurofeedback; neuroimaging","Neurofeedback has been proposed as a treatment for Parkinson's disease (PD) motor symptoms by changing the neural network activity directly linked with movement. However, the effectiveness of neurofeedback as a treatment for PD motor symptoms is unclear. To systematically review the literature to identify the effects of neurofeedback in people with idiopathic PD; as defined by measurement of brain activity; motor function; and performance. A systematic review. Included Sources and Articles: PubMed; MEDLINE; Cinhal; PsychoInfo; Prospero; Cochrane; ClinicalTrials.gov; EMBASE; Web of Science; PEDro; OpenGrey; Conference Paper Index; Google Scholar; and eThos; searched using the Population-Intervention-Comparison-Outcome (PICO) framework. Primary studies with the following designs were included: randomized controlled trials (RCTs), non-RCTs; quasi-experimental; pre/post studies; and case studies. This review included 11 studies out of 6197 studies that were identified from the literature search. Neuroimaging methods used were fMRI; scalp EEG; surface brain EEG; and deep brain EEG; where 10-15 Hz and the supplementary motor area were the most commonly targeted signatures for EEG and fMRI, respectively. Success rates for changing one's brain activity ranged from 47% to 100%; however, both sample sizes and success criteria differed considerably between studies. While six studies included a clinical outcome; a lack of consistent assessments prevented a reliable conclusion on neurofeedback's effectiveness. Narratively, fMRI neurofeedback has the greatest potential to improve PD motor symptoms. Two main limitations were found in the studies that contributed to the lack of a confident conclusion: (1) insufficient clinical information and perspectives (e.g., no reporting of adverse events), and (2) limitations in numerical data reporting (e.g., lack of explicit statistics) that prevented a meta-analysis. While fMRI neurofeedback was narratively the most effective treatment; the omission of clinical outcome measures in studies using other neurofeedback approaches limits comparison. Therefore, no single neurofeedback type can currently be identified as an optimal treatment for PD motor symptoms. This systematic review highlights the need to improve the inclusion of clinical information and more robust reporting of numerical data in future work. Neurofeedback appears to hold great potential as a treatment for PD motor symptoms. However, this field is still in its infancy and needs high quality RCTs to establish its effectiveness. Review Registration: PROSPERO (ID: CRD42020191097).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20841,""
"Combined effects of acupuncture and auricular acupressure for relieving cancer-related fatigue in patients during lung cancer chemotherapy: A protocol for systematic review and meta-analysis","Li, Liu","https://doi.org/10.1097/MD.0000000000027502","20211027","PubMed","","Increasing attention has been paid to acupuncture and auricular acupressure as alternative strategies for cancer related fatigue (CRF) management. Therefore, we design this systematic review and meta-analysis to explore the efficacy and safety of acupuncture and auricular acupressure for relieving CRF in patients during lung cancer chemotherapy. From the inception to August 2021, the Web of Science, EMBASE, PubMed, and Cochrane Library electronic databases were searched using the key phrases ""acupuncture"", ""auricular acupressure"", and ""lung cancer"" for all relevant trials. Trials that compared acupuncture (including electroacupuncture) and auricular acupressure with acupuncture alone were included. The primary outcome was the measurement of the CRF symptoms. Secondary outcome measures were physical activity, quality of life, and adverse events. A P value of &lt;.05 was considered to be statistically significant. It will be the first such study and will obtain evidence for utilizing acupuncture and auricular acupressure for lung cancer patients. Combined acupuncture and auricular acupressure may be effective for relieving CRF in patients during lung cancer chemotherapy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20842,""
"Distribution of race and Fitzpatrick skin types in datasets for deep learning in dermatology: a systematic review","Kim, Kobic, Vidal","https://doi.org/10.1016/j.jaad.2021.10.010","20211022","PubMed","artificial intelligence education; deep learning; diversity; machine learning; neural networks","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20843,""
"Can machine learning-based analysis of multiparameter MRI and clinical parameters improve the performance of clinically significant prostate cancer diagnosis?","Peng, Xiao, Li, Pu, Niu, Zeng, Wang, Gao, Li, Chen, Yang","https://doi.org/10.1007/s11548-021-02507-w","20211022","PubMed","Classification; Machine learning; Magnetic resonance imaging; Prostate cancer; Radiomics; Texture analysis","ToÃ‚Â establish machine learning(ML) models for the diagnosis of clinically significant prostate cancer (csPC) using multiparameter magnetic resonance imaging (mpMRI), texture analysis (TA), dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) quantitative analysis and clinical parameters and to evaluate the stability of these models in internal and temporal validation. The dataset of 194 men was split into training (nÃ¢â‚¬â€°=Ã¢â‚¬â€°135) and internal validation (nÃ¢â‚¬â€°=Ã¢â‚¬â€°59) cohorts, and a temporal dataset (nÃ¢â‚¬â€°=Ã¢â‚¬â€°58) was used for evaluation. The lesions with Gleason scoreÃ¢â‚¬â€°Ã¢â€°Â¥Ã¢â‚¬â€°7 were defined as csPC. Logistic regression (LR), stepwise regression (SR), classical decision tree (cDT), conditional inference tree (CIT), random forest (RF) and support vector machine (SVM) models were established by combining mpMRI-TA, DCE-MRI and clinical parameters and validated by internal and temporal validation using the receiver operating characteristic (ROC) curve and Delong's method. Eight variables were determined as important predictors for csPC, with the first three related to texture features derived from the apparent diffusion coefficient (ADC) mapping. RF, LR and SR models yielded larger and more stable area under the ROC curve values (AUCs) than other models. In the temporal validation, the sensitivity was lower than that of the internal validation (pÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.05). There were no significant differences in specificity, accuracy, positive predictive value (PPV), negative predictive value (NPV) and AUC (pÃ¢â‚¬â€°&gt;Ã¢â‚¬â€°0.05). Each machine learning model in this study has good classification ability for csPC. Compared with internal validation, the sensitivity of each machine learning model in temporal validation was reduced, but the specificity, accuracy, PPV, NPV and AUCs remained stable at a good level. The RF, LR and SR models have better classification performance in the imaging-based diagnosis of csPC, and ADC texture-related parameters are of the highest importance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20844,""
"A Review of Modern Thermal Imaging Sensor Technology and Applications for Autonomous Aerial Navigation","Nguyen, Rosser, Chahl","https://doi.org/10.3390/jimaging7100217","20211029","PubMed","LWIR; SLAM; UAVs; navigation; neural network; optical flow; review; simultaneous localization and mapping; thermal imaging","Limited navigation capabilities of many current robots and UAVs restricts their applications in GPS denied areas. Large aircraft with complex navigation systems rely on a variety of sensors including radio frequency aids and high performance inertial systems rendering them somewhat resistant to GPS denial. The rapid development of computer vision has seen cameras incorporated into small drones. Vision-based systems, consisting of one or more cameras, could arguably satisfy both size and weight constraints faced by UAVs. A new generation of thermal sensors is available that are lighter, smaller and widely available. Thermal sensors are a solution to enable navigation in difficult environments, including in low-light, dust or smoke. The purpose of this paper is to present a comprehensive literature review of thermal sensors integrated into navigation systems. Furthermore, the physics and characteristics of thermal sensors will also be presented to provide insight into challenges when integrating thermal sensors in place of conventional visual spectrum sensors.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20845,""
"A Contemporary Evaluation on Posterior Direct Restoration Teaching among Undergraduates in Dental Schools in Malaysia","Alauddin, Mohammad, Jaafar, Abdul Fatah, Ahmad","https://doi.org/10.3390/dj9100123","20211026","PubMed","composite restoration; conservative dentistry; dental education; dentin bonding; operative dentistry; undergraduate dental student","There is a current trend to restore posterior teeth with composite resin due to increasing demands on natural tooth colour restoration and increased concern about the safety of amalgam restorations. The objective was to evaluate the current teaching of posterior direct restoration among restorative dental lecturers in Malaysia compared to available international literature. An online questionnaire, which sought information on the teaching of posterior restoration was developed and distributed to 13 dental schools in Malaysia. The response rate for the questionnaire was 53.8%. The most popular posterior restoration teaching methods among the respondents were lecture (95.7%), demonstration (87.0%) and problem-based learning (PBL) (73.9%), while continuous assessment and a practical competency test (82.6%) were the most popular assessment methods. Placing a hard setting calcium hydroxide and GIC base for deep cavity restored by composite restoration was taught in 79.2% of cases. The standard protocols for posterior composite restoration were incremental filling in deep cavity (87.5%), using circumferential metal bands with wooden wedge (91.7%), with a total etch system (95.8%), using a light emitting diode (LED) light curing unit (91.7%), finishing using water cooling (80%) and finishing with a disc (87.5%). Graduates from dental schools in Malaysia received similar theoretical, preclinical and clinical teaching on posterior restoration techniques, although there were variations in the delivery methods, techniques and assessments, pointing to a need for uniformity and consensus.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20846,""
"Use of Automated Thematic Annotations for Small Data Sets in a Psychotherapeutic Context: Systematic Review of Machine Learning Algorithms","Hudon, Beaudoin, Phraxayavong, Dellazizzo, Potvin, Dumais","https://doi.org/10.2196/22651","20211025","PubMed","artificial intelligence; automated text classification; machine learning; psychotherapy; systematic review","A growing body of literature has detailed the use of qualitative analyses to measure the therapeutic processes and intrinsic effectiveness of psychotherapies, which yield small databases. Nonetheless, these approaches have several limitations and machine learning algorithms are needed. The objective of this study is to conduct a systematic review of the use of machine learning for automated text classification for small data sets in the fields of psychiatry, psychology, and social sciences. This review will identify available algorithms and assess if automated classification of textual entities is comparable to the classification done by human evaluators. A systematic search was performed in the electronic databases of Medline, Web of Science, PsycNet (PsycINFO), and Google Scholar from their inception dates to 2021. The fields of psychiatry, psychology, and social sciences were selected as they include a vast array of textual entities in the domain of mental health that can be reviewed. Additional records identified through cross-referencing were used to find other studies. This literature search identified 5442 articles that were eligible for our study after the removal of duplicates. Following abstract screening, 114 full articles were assessed in their entirety, of which 107 were excluded. The remaining 7 studies were analyzed. Classification algorithms such as naive Bayes, decision tree, and support vector machine classifiers were identified. Support vector machine is the most used algorithm and best performing as per the identified articles. Prediction classification scores for the identified algorithms ranged from 53%-91% for the classification of textual entities in 4-7 categories. In addition, 3 of the 7 studies reported an interjudge agreement statistic; these were consistent with agreement statistics for text classification done by human evaluators. A systematic review of available machine learning algorithms for automated text classification for small data sets in several fields (psychiatry, psychology, and social sciences) was conducted. We compared automated classification with classification done by human evaluators. Our results show that it is possible to automatically classify textual entities of a transcript based solely on small databases. Future studies are nevertheless needed to assess whether such algorithms can be implemented in the context of psychotherapies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20847,""
"50th anniversary of computed tomography: past and future applications in clinical neuroscience","Dillon","https://doi.org/10.1117/1.JMI.8.5.052112","20211023","PubMed","brain; computed tomography; neuroradiology; spine; technology","<b>Purpose:</b> It has been 50Ã‚Â years since computed tomography was introduced to the worldwide neurologic medical and surgical community. In that time, tremendous advances in computer software and hardware, as well as creative changes in computerized tomographic (CT) hardware and tube technology, have dramatically improved the temporal and spatial resolution of CT. In this paper, I address what I feel are some of the most important impacts of CT in the field of clinical neuroscience over the last 50Ã‚Â years, as well as potential applications of CT that are on the horizon. <b>Approach:</b> I have recounted from literature, colleagues, and personal recollection the historical impact of CT on neuroradiology practice and what appear to be near-term future applications. <b>Conclusions:</b> Therapeutic applications beyond diagnosis, such as image-guided procedures, radiation, and surgical planning, and development of the field of theranostics have emerged and further increased the need for faster and more precise CT imaging. The integration of machine learning into the acquisition chain and radiologist tool kit has great implications for standardization, analysis, and diagnosis worldwide.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20848,""
"Remote Diabetic Foot Temperature Monitoring for Early Detection of Diabetic Foot Ulcers: A Cost-Effectiveness Analysis","Brooks, Burns, Ma, Scholten, Becker","https://doi.org/10.2147/CEOR.S322424","20211023","PubMed","biomedical; cost savings; cost-benefit analysis; decision trees; diabetes mellitus; diabetic foot; technology assessment","Foot temperature monitoring for the prevention and early detection of diabetic foot ulcers (DFU) is evidence-based and recommended in clinical practice. However, easy-to-use remote monitoring tools have been lacking, thereby preventing widespread adoption. To evaluate the cost-effectiveness of remote foot temperature monitoring (RFTM) (Siren's NeurofabricÃ¢â€žÂ¢ Diabetic socks) in addition to standard of care (SoC) versus SoC alone for early detection of DFU with diabetic neuropathy and a moderate to high risk of DFU. A payer perspective decision-tree analysis was conducted to compare expected DFU occurrence and subsequent amputation rates and costs between treatment strategies over one year. Inputs in the model were sourced from publicly available literature and relevant health technology assessments. One-way sensitivity analyses were performed for each model variable. In the base-case scenario, RFTM plus SoC was a dominant strategy compared to SoC alone. RFTM plus SoC was associated with cost savings of $38,593 per additional ulcer avoided versus SoC alone, and $8027 per patient per year on average compared to SoC alone. These results were highly robust to one-way sensitivity analysis; all scenarios remained dominant if compliance was Ã¢â€°Â¥13%. RFTM is a cost-effective addition to SoC in patients with diabetic neuropathy at a moderate-to-high risk of DFU and subsequent amputation. Further, reduction in DFU and associated complications may result in improvements in the patient's quality of life and mental health. Future studies are needed to evaluate the compliance and reduction of DFU occurrence in patients on RFTM.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20849,""
"The Prognostic Impact of Susceptibility-Weighted Imaging Prominent Veins in Acute Ischemic Stroke: A Systematic Review and Meta-Analysis","Lu, Cui, Zhao","https://doi.org/10.2147/NDT.S331874","20211023","PubMed","SWI; ischemic stroke; meta-analysis; prominent veins; stroke","We aimed to determine the prognostic impact of prominent veins (PVS) after an acute ischemic stroke identified on susceptibility-weighted imaging (PVS-SWI). We searched for studies published in PubMed, Embase, Cochrane Library and Chinese Biomedical Literature Database. Poor functional prognosis, early neurological deterioration, and hemorrhagic transformation were evaluated. Risk ratios (RR) were pooled implementing a random effect model. We performed a subgroup analysis by treatment, location (cortical/medullary) and a sensitivity analysis by follow-up time. Sixteen studies were included (a total of 1605 patients) in the quantitative meta-analysis. PVS-SWI were related with a poor functional outcome (RR 1.62, 95% CI 1.25 to 2.10), especially in the patients receiving thrombolysis (RR 2.19, 95% CI 1.53 to 3.15) and an augmented risk of early neurological damage (RR 2.85, 95% CI 2.31 to 3.51). Both cortical and medullary prominent veins were accompanied by a poor functional outcome (RR 1.82, 95% CI 1.30 to 2.56/RR 2.59, 95% CI 1.98 to 3.38). PVS-SWI were not associated with poor functional outcomes when patients were treated conservatively (RR 1.35, 95% CI 0.82 to 2.22), or with an increased risk of hemorrhagic transformation (RR 0.97, 95% CI 0.64 to 1.47). PVS-SWI were related to a poor functional prognosis and an increased risk of early neurological damage. In patients treated conservatively, PVS-SWI were not accompanied by a poor prognosis. PVS-SWI were not associated with an augmented risk of hemorrhagic transformation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20850,""
"A Systematic Review of Current Teleophthalmology Services in New Zealand Compared to the Four Comparable Countries of the United Kingdom, Australia, United States of America (USA) and Canada","Walsh, Hong, Chalakkal, Ogbuehi","https://doi.org/10.2147/OPTH.S294428","20211023","PubMed","age-related macular degeneration; diabetic retinopathy; telemedicine; teleophthalmology; triaging; videoconferencing","Over 700,000 New Zealanders (NZ), particularly elderly and MÃ„Âori, live without timely access to specialist ophthalmology services. Teleophthalmology is a widely recognised tool that can assist in overcoming resource and distance barriers. Teleophthalmology gained unprecedented traction in NZ during the COVID-19 pandemic and subsequent lockdown. However, its provision is still limited and there are equity issues. The aim of this study was to conduct a systematic review identifying, describing and contrasting teleophthalmology services in NZ with the comparable countries of Australia, USA, Canada and the United Kingdom. The electronic databases Embase, PubMed, Web of Science, Google Scholar and Google were systemically searched using the keywords: telemedicine, ophthalmology, tele-ophthalmology/teleophthalmology. The searches were filtered to the countries above, with no time constraints. An integrative approach was used to synthesise findings. One hundred and thirty-two studies were identified describing 90 discrete teleophthalmology services. Articles spanned from 1997 to 2020. Models were categorised into general eye care (n=21; 16%); emergency/trauma (n=6; 4.5%); school screening (n=25; 19%); artificial intelligence (AI) (n=23; 18%); and disease-specific models of care (MOC) (n=57; 43%). The most common diseases addressed were diabetic retinopathy (n=23; 17%); retinopathy of prematurity (n=9; 7%); and glaucoma (n=8; 6%). Programs were mainly centred in the US (n=72; 54.5%), followed by the UK (n=29; 22%), then Canada (n=16; 12%), Australia (n=13; 10%), with the fewest identified in NZ (n=3; 2%). Models generally involved an ophthalmologist consultative service, remote supervision and triaging. Most models involved local clinicians transmitting fed-forward or live images. Teleophthalmology will likely play a crucial role in the future of eye care. COVID-19 has offered a unique opportunity to observe the use of teleophthalmology services globally. Feed-forward and, increasingly, live-based teleophthalmology services have demonstrated feasibility and cost-effectiveness in similar countries internationally. New Zealand's teleophthalmology services, however, are currently limited. Investing in strategic partnerships and technology at a national level can advance health equities in ophthalmic care.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20851,""
"Restructuring of a Hospital Radiology Department: Subspecialization Between Man, Machine, and Multidisciplinary Board","Henkelmann, Ehrengut, Denecke","https://doi.org/10.1055/a-1545-4713","20211021","PubMed","","Ã¢â‚¬â€šRadiology, like almost no other discipline, is faced with a rapid increase in information and technology. This and the growing demands regarding referring medicine, quality requirements, and personnel efficiency increasingly require subspecialization in terms of content. There is already an established move towards radiological subspecialization in the Anglo-American region. In this review article, the content and possibilities of restructuring a hospital radiology department are presented in order to support acceptance in German-speaking countries. Ã¢â‚¬â€šBased on the current literature, the aspects of subspecialized radiology as well as its necessity, advantages, and disadvantages are discussed and the challenges to hospital management with respect to strategic implementation in the individual phases are presented based on the example of a university radiology department. The viewpoints also take into account the education regulations and integrate a modern learning concept. Ã¢â‚¬â€šModern restructuring of hospital radiology departments is faced with increasing demands on a traditionally technically organized radiology department with regard to the complexity of referring medicine, subspecialization pressure (including in certified boards), and staff efficiency. The restructuring of a radiology department must be aligned with the clinical requirements and discussed in the overall concept of radiology including its environment. Ã¢â‚¬â€š Ã‚Â· The tremendous expansion of knowledge requires a content-based subspecialization of modern radiology as a cross-sectional discipline.. Ã‚Â· Proactive radiology meets the increasing demands of its clinical partners and offers great potential for improving quality and efficiency.. Ã‚Â· The restructuring of a hospital radiology department requires well-planned strategic management taking into account all involved processes, resources, and personnel qualifications.. Ã‚Â· Henkelmann J, Ehrengut C, Denecke T. Restructuring of a Hospital Radiology Department: Subspecialization Between Man, Machine, and Multidisciplinary Board. Fortschr RÃƒÂ¶ntgenstr 2021; DOI: 10.1055/a-1545-4713. Ã¢â‚¬â€šDie Radiologie muss sich fast wie kein anderes Fach einem so rasanten Wissenszuwachs an Informationen und Technik stellen. Dies und wachsende AnsprÃƒÂ¼che der zuweisenden Medizin, QualitÃƒÂ¤tsforderungen und Personaleffizienz erfordern zunehmend eine inhaltliche Subspezialisierung. Bereits im angloamerikanischen Raum lÃƒÂ¤sst sich ein etablierter Umschwung zur radiologischen Subspezialisierung beobachten. Im Rahmen dieses ÃƒÅ“bersichtsartikels werden die Inhalte und MÃƒÂ¶glichkeiten einer Restrukturierung einer radiologischen Klinik dargestellt, um die Akzeptanz im deutschsprachigen Raum zu unterstÃƒÂ¼tzen. Ã¢â‚¬â€šAnhand der aktuellen Literatur werden die Aspekte zur subspezialisierten Radiologie sowie deren Notwendigkeit, Vor- und Nachteile erÃƒÂ¶rtert und die Herausforderungen an das Klinikmanagement zur strategischen Umsetzung in ihren einzelnen Phasen am Beispiel einer UniversitÃƒÂ¤tsradiologie dargelegt. Die Standpunkte berÃƒÂ¼cksichtigen zudem die Weiterbildungsordnung und integrieren ein modernes Lernkonzept. Ã¢â‚¬â€šDie moderne Restrukturierung der Krankenhausradiologie stellt sich den wachsenden Anforderungen an eine traditionell technisch organisierte Radiologie hinsichtlich der KomplexitÃƒÂ¤t der zuweisenden Medizin, dem Subspezialisierungsdruck (u.Ã¢â‚¬Å a. in zertifizierten Boards) und der Personaleffizienz. Die Restrukturierung einer Einrichtung ist an den klinischen Anforderungen auszurichten und im Gesamtkonzept der Radiologie mit dessen Umgebung zu diskutieren. Ã¢â‚¬â€š Ã‚Â· Der enorme Wissenszuwachs erfordert zunehmend eine inhaltliche Subspezialisierung der modernen Radiologie als Querschnittsfach.. Ã‚Â· Eine proaktive Radiologie kommt dem wachsenden Anspruch seiner klinischen Partner entgegen und bietet groÃƒÅ¸es Potenzial fÃƒÂ¼r eine QualitÃƒÂ¤ts- und Effizienzsteigerung.. Ã‚Â· Die Restrukturierung einer Klinikradiologie bedarf ein gut durchdachtes strategisches Management unter BerÃƒÂ¼cksichtigung aller beteiligten Prozesse, Ressourcen und personeller Qualifikationen.. Ã‚Â· Henkelmann J, Ehrengut C, Denecke T. Restructuring of aÃ‚Â Hospital Radiology Department: Subspecialization Between Man, Machine, and Multidisciplinary Board. Fortschr RÃƒÂ¶ntgenstr 2021; DOI: 10.1055/a-1545-4713.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20852,""
"Health Natural Language Processing: Methodology Development and Applications","Hao, Huang, Liang, Weng, Tang","https://doi.org/10.2196/23898","20211021","PubMed","application; health care; methodology; natural language processing; unstructured text","With the rapid growth of information technology, the necessity for processing substantial amounts of health data using advanced information technologies is increasing. A large amount of valuable data exists in natural text such as diagnosis text, discharge summaries, online health discussions, and eligibility criteria of clinical trials. Health natural language processing, as an interdisciplinary field of natural language processing and health care, plays a substantial role in a wide scope of both methodology development and applications. This editorial shares the most recent methodology innovations of health natural language processing and applications in the medical domain published in this JMIR Medical Informatics special theme issue entitled ""Health Natural Language Processing: Methodology Development and Applications"".","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20853,""
"Diagnostic and prognostic prediction models in ventilator-associated pneumonia: Systematic review and meta-analysis of prediction modelling studies","Frondelius, Atkova, Miettunen, Rello, Jansson","https://doi.org/10.1016/j.jcrc.2021.10.001","20211102","PubMed","Exhaled human breath; Machine learning; Mechanical ventilation; Predictive analytics; Prognostic model; Ventilator-associated pneumonia","Existing expert systems have not improved the diagnostic accuracy of ventilator-associated pneumonia (VAP). The aim of this systematic literature review was to review and summarize state-of-the-art prediction models detecting or predicting VAP from exhaled breath, patient reports and demographic and clinical characteristics. Both diagnostic and prognostic prediction models were searched from a representative list of multidisciplinary databases. An extensive list of validated search terms was added to the search to cover papers failing to mention predictive research in their title or abstract. Two authors independently selected studies, while three authors extracted data using predefined criteria and data extraction forms. The Prediction Model Risk of Bias Assessment Tool was used to assess both the risk of bias and the applicability of the prediction modelling studies. Technology readiness was also assessed. Out of 2052 identified studies, 20 were included. Fourteen (70%) studies reported the predictive performance of diagnostic models to detect VAP from exhaled human breath with a high degree of sensitivity and a moderate specificity. In addition, the majority of them were validated on a realistic dataset. The rest of the studies reported the predictive performance of diagnostic and prognostic prediction models to detect VAP from unstructured narratives [2 (10%)] as well as baseline demographics and clinical characteristics [4 (20%)]. All studies, however, had either a high or unclear risk of bias without significant improvements in applicability. The development and deployment of prediction modelling studies are limited in VAP and related outcomes. More computational, translational, and clinical research is needed to bring these tools from the bench to the bedside. PROSPERO CRD42020180218, registered on 05-07-2020.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20854,""
"Two data-driven approaches to identifying the spectrum of problematic opioid use: A pilot study within a chronic pain cohort","Schirle, Jeffery, Yaqoob, Sanchez-Roige, Samuels","https://doi.org/10.1016/j.ijmedinf.2021.104621","20211102","PubMed","Chronic pain; Electronic health records; Natural language processing; Opioid use disorder; Phenome-wide association study","Although electronic health records (EHR) have significant potential for the study of opioid use disorders (OUD), detecting OUD in clinical data is challenging. Models using EHR data to predict OUD often rely on case/control classifications focused on extreme opioid use. There is a need to expand this work to characterize the spectrum of problematic opioid use. Using a large academic medical center database, we developed 2 data-driven methods of OUD detection: (1) a Comorbidity Score developed from a Phenome-Wide Association Study of phenotypes associated with OUD and (2) a Text-based Score using natural language processing to identify OUD-related concepts in clinical notes. We evaluated the performance of both scores against a manual review with correlation coefficients, Wilcoxon rank sum tests, and area-under the receiver operating characteristic curves. Records with the highest Comorbidity and Text-based scores were re-evaluated by manual review to explore discrepancies. Both the Comorbidity and Text-based OUD risk scores were significantly elevated in the patients judged as High Evidence for OUD in the manual review compared to those with No Evidence (pÃ‚Â =Ã‚Â 1.3E-5 and 1.3E-6, respectively). The risk scores were positively correlated with each other (rhoÃ‚Â =Ã‚Â 0.52, pÃ‚Â &lt;Ã‚Â 0.001). AUCs for the Comorbidity and Text-based scores were high (0.79 and 0.76, respectively). Follow-up manual review of discrepant findings revealed strengths of data-driven methods over manual review, and opportunities for improvement in risk assessment. Risk scores comprising comorbidities and text offer differing but synergistic insights into characterizing problematic opioid use. This pilot project establishes a foundation for more robust work in the future.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20855,""
"Artificial intelligence to aid detection and diagnostic accuracy of mood disorders and predict suicide risk: A systematic review","Edavally, Miller, Youssef","https://doi.org/10.12788/acp.0041","20211021","PubMed","","Mood disorders often are diagnosed by clinical interview, yet many cases are missed or misdiagnosed. Mood disorders increase the risk of suicide, making it imperative to diagnose and treat these disorders quickly. Artificial intelligence (AI) has been investigated for diagnosing mood disorders, but the merits of the literature have not been evaluated. This systematic review aims to understand and explain AI methods and evaluate their use in augmenting clinical diagnosis of mood disorders as well as identifying individuals at increased suicide risk. We conducted a systematic literature review of all studies until August 1, 2020 examining the efficacy of different AI techniques for diagnosing mood disorders and identifying individuals at increased suicide risk because of a mood disorder. Our literature search generated 13 studies (10 of mood disorders and 3 describing suicide risk) where AI techniques were used. Machine learning and artificial neural networks were most commonly used; both showed merit in helping to diagnose mood disorders and assess suicide risk. The data shows that AI methods have merit in improving the diagnosis of mood disorders as well as identifying suicide risk. More research is needed for bipolar disorder because only 2 studies explored this condition, and it is often misdiagnosed. Although only a few AI techniques are discussed in detail in this review, there are many more that can be employed, and should be evaluated in future studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20856,""
"Risk of bias in studies on prediction models developed using supervised machine learning techniques: systematic review","Andaur Navarro, Damen, Takada, Nijman, Dhiman, Ma, Collins, Bajpai, Riley, Moons, Hooft","https://doi.org/10.1136/bmj.n2281","20211027","PubMed","Bias; Clinical Decision Rules; Data Interpretation, Statistical; Humans; Machine Learning; Models, Statistical; Multivariate Analysis; Risk","To assess the methodological quality of studies on prediction models developed using machine learning techniques across all medical specialties. Systematic review. PubMed from 1 January 2018 to 31 December 2019. Articles reporting on the development, with or without external validation, of a multivariable prediction model (diagnostic or prognostic) developed using supervised machine learning for individualised predictions. No restrictions applied for study design, data source, or predicted patient related health outcomes. Methodological quality of the studies was determined and risk of bias evaluated using the prediction risk of bias assessment tool (PROBAST). This tool contains 21 signalling questions tailored to identify potential biases in four domains. Risk of bias was measured for each domain (participants, predictors, outcome, and analysis) and each study (overall). 152 studies were included: 58 (38%) included a diagnostic prediction model and 94 (62%) a prognostic prediction model. PROBAST was applied to 152 developed models and 19 external validations. Of these 171 analyses, 148 (87%, 95% confidence interval 81% to 91%) were rated at high risk of bias. The analysis domain was most frequently rated at high risk of bias. Of the 152 models, 85 (56%, 48% to 64%) were developed with an inadequate number of events per candidate predictor, 62 handled missing data inadequately (41%, 33% to 49%), and 59 assessed overfitting improperly (39%, 31% to 47%). Most models used appropriate data sources to develop (73%, 66% to 79%) and externally validate the machine learning based prediction models (74%, 51% to 88%). Information about blinding of outcome and blinding of predictors was, however, absent in 60 (40%, 32% to 47%) and 79 (52%, 44% to 60%) of the developed models, respectively. Most studies on machine learning based prediction models show poor methodological quality and are at high risk of bias. Factors contributing to risk of bias include small study size, poor handling of missing data, and failure to deal with overfitting. Efforts to improve the design, conduct, reporting, and validation of such studies are necessary to boost the application of machine learning based prediction models in clinical practice. PROSPERO CRD42019161764.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20857,""
"Artificial intelligence as a diagnostic aid in cross-sectional radiological imaging of the abdominopelvic cavity: a protocol for a systematic review","Fowler, Macefield, Hardacre, Callaway, Smart, Blencowe","https://doi.org/10.1136/bmjopen-2021-054411","20211102","PubMed","computed tomography; diagnostic radiology; magnetic resonance imaging; surgery","The application of artificial intelligence (AI) technologies as a diagnostic aid in healthcare is increasing. Benefits include applications to improve health systems, such as rapid and accurate interpretation of medical images. This may improve the performance of diagnostic, prognostic and management decisions. While a large amount of work has been undertaken discussing the role of AI little is understood regarding the performance of such applications in the clinical setting. This systematic review aims to critically appraise the diagnostic performance of AI algorithms to identify disease from cross-sectional radiological images of the abdominopelvic cavity, to identify current limitations and inform future research. A systematic search will be conducted on Medline, EMBASE and the Cochrane Central Register of Controlled Trials to identify relevant studies. Primary studies where AI-based technologies have been used as a diagnostic aid in cross-sectional radiological images of the abdominopelvic cavity will be included. Diagnostic accuracy of AI models, including reported sensitivity, specificity, predictive values, likelihood ratios and the area under the receiver operating characteristic curve will be examined and compared with standard practice. Risk of bias of included studies will be assessed using the QUADAS-2 tool. Findings will be reported according to the Synthesis Without Meta-analysis guidelines. No ethical approval is required as primary data will not be collected. The results will inform further research studies in this field. Findings will be disseminated at relevant conferences, on social media and published in a peer-reviewed journal. CRD42021237249.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20858,""
"Factors Associated With the Development and Prevalence of Abnormal Behaviors in Horses: Systematic Review With Meta-Analysis","Seabra, Dittrich, Vale","https://doi.org/10.1016/j.jevs.2021.103750","20211021","PubMed","Data mining; Equine nutrition; Management techniques; Stable; Stereotypies","Researchers believe that the development and prevalence of abnormal behaviors in horses may be caused by several environmental and biological factors, and the literature offers numerous reports that discuss the causes and effects of stereotypies in these animals. In this light, this study aimed to conduct a systematic review and meta-analysis of the scientific literature, summarizing the main risk factors associated with the development of abnormal behaviors in horses. The searches were conducted over the course of four years in Portuguese, Spanish, and English. The publications reviewed were full text research thesis or articles that addressed issues within the following criteria: (1) presentation of epidemiological information on the studied population; (2) prevalence of abnormal behaviors in equine populations; (3) factors associated with the development or prevalence of stereotypies. Data were extracted from each study and inserted into an Excel spreadsheet to be analyzed through descriptive statistics. In addition, the Mann-Whitney U test was used to verify the existence of significant differences between the methodologies (direct observation/questionnaires). The dataset was also analyzed through data mining to identify the main factors that influence the prevalence of abnormal behaviors in the studied population. The results showed a great variation in the mean prevalence of abnormal behaviors, with no significant difference between research conducted through questionnaires or direct observation, and the data mining technique identified that incorrect nutritional management may be the main factor influencing the development and prevalence of abnormal behaviors in horses.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20859,""
"Predictive modeling for 14-day unplanned hospital readmission risk by using machine learning algorithms","Lo, Liao, Chen, Chang, Li","https://doi.org/10.1186/s12911-021-01639-y","20211101","PubMed","Discharge planning; Healthcare quality indicators; Machine learning; Risk prediction model; Unplanned readmission; Adult; Aged; Algorithms; Humans; Machine Learning; Middle Aged; Patient Readmission; Retrospective Studies; Risk Factors","Early unplanned hospital readmissions are associated with increased harm to patients, increased medical costs, and negative hospital reputation. With the identification of at-risk patients, a crucial step toward improving care, appropriate interventions can be adopted to prevent readmission. This study aimed to build machine learning models to predict 14-day unplanned readmissions. We conducted a retrospective cohort study on 37,091 consecutive hospitalized adult patients with 55,933 discharges between September 1, 2018, and August 31, 2019, in an 1193-bed university hospital. Patients who were agedÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°20Ã‚Â years, were admitted for cancer-related treatment, participated in clinical trial, were discharged against medical advice, died during admission, or lived abroad were excluded. Predictors for analysis included 7 categories of variables extracted from hospital's medical record dataset. In total, four machine learning algorithms, namely logistic regression, random forest, extreme gradient boosting, and categorical boosting, were used to build classifiers for prediction. The performance of prediction models for 14-day unplanned readmission risk was evaluated using precision, recall, F1-score, area under the receiver operating characteristic curve (AUROC), and area under the precision-recall curve (AUPRC). In total, 24,722 patients were included for the analysis. The mean age of the cohort was 57.34Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°18.13Ã‚Â years. The 14-day unplanned readmission rate was 1.22%. Among the 4 machine learning algorithms selected, Catboost had the best average performance in fivefold cross-validation (precision: 0.9377, recall: 0.5333, F1-score: 0.6780, AUROC: 0.9903, and AUPRC: 0.7515). After incorporating 21 most influential features in the Catboost model, its performance improved (precision: 0.9470, recall: 0.5600, F1-score: 0.7010, AUROC: 0.9909, and AUPRC: 0.7711). Our models reliably predicted 14-day unplanned readmissions and were explainable. They can be used to identify patients with a high risk of unplanned readmission based on influential features, particularly features related to diagnoses. The operation of the models with physiological indicators also corresponded to clinical experience and literature. Identifying patients at high risk with these models can enable early discharge planning and transitional care to prevent readmissions. Further studies should include additional features that may enable further sensitivity in identifying patients at a risk of early unplanned readmissions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20860,""
"Effects of aerobic physical exercise on neuroplasticity after stroke: systematic review","Penna, Pinheiro, Ramalho, Ribeiro","https://doi.org/10.1590/0004-282X-ANP-2020-0551","20211020","PubMed","","Stroke is among the leading causes of death and disability worldwide. Interventions for stroke rehabilitation aim to minimize sequelae, promote individuals' independence and potentially recover functional damage. The role of aerobic exercise as a facilitator of post-stroke neuroplasticity in humans is still questionable. To investigate the impact of aerobic exercise on neuroplasticity in patients with stroke sequelae. A systematic review of randomized clinical trials and crossover studies was performed, with searches for human studies in the following databases: PUBMED, EMBASE, LILACS and PeDRO, only in English, following the PRISMA protocol. The keywords used for selecting articles were defined based on the PICO strategy. This systematic review evaluated the impacts of aerobic exercise on neuroplasticity through assessment of neural networks and neuronal excitability, neurotrophic factors, or cognitive and functional assessment. Studies that evaluated the effects of aerobic exercise on neuroplasticity after stroke measured through functional resonance (fMRI) or cortical excitability have shown divergent results, but aerobic exercise potentially can modify the neural network, as measured through fMRI. Additionally, aerobic exercise combined with cognitive training improves certain cognitive domains linked to motor learning. Studies that involved analysis of neurotrophic factors to assess neuroplasticity had conflicting results. Physical exercise is a therapeutic intervention in rehabilitation programs that, beyond the known benefits relating to physical conditioning, functionality, mood and cardiovascular health, may also potentiate the neuroplasticity process. Neuroplasticity responses seem more robust in moderate to high-intensity exercise training programs, but dose-response heterogeneity and non-uniform neuroplasticity assessments limit generalizability.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20861,""
"An increasing number of convolutional neural networks for fracture recognition and classification in orthopaedics : are these externally validated and ready for clinical application?","Oliveira E Carmo, van den Merkhof, Olczak, Gordon, Jutte, Jaarsma, IJpma, Doornberg, Prijs, Algra, van den Bekerom, Bhandari, Bongers, Court-Brown, Bulstra, Buijze, Bzovsky, Colaris, Chen, Doornberg, Duckworth, Goslings, Gordon, Gravesteijn, Groot, Guyatt, Hendrickx, Hintermann, Hofstee, IJpma, Jaarsma, Janssen, Jeray, Jutte, Karhade, Keijser, Kerkhoffs, Langerhuizen, Lans, Mallee, Moran, McQueen, Mulders, Nelissen, Obdeijn, Oberai, Olczak, Oosterhoff, Petrisor, Poolman, Prijs, Ring, Tornetta III, Sanders, Schwab, Schemitsch, Schep, Schipper, Schoolmeesters, Schwab, Swiontkowski, Sprague, Steyerberg, Stirler, Tornetta, Walter, Walenkamp, Wijffels","https://doi.org/10.1302/2633-1462.210.BJO-2021-0133","20211027","PubMed","Artificial intelligence; CT scans; Convolutional neural networks; Deep learning; External validation; Machine learning; Prognosis; cadaveric studies; distal radius fractures; elbows; hip; orthopaedic surgeons; orthopaedic trauma; radiographs; variances","The number of convolutional neural networks (CNN) available for fracture detection and classification is rapidly increasing. External validation of a CNN on a temporally separate (separated by time) or geographically separate (separated by location) dataset is crucial to assess generalizability of the CNN before application to clinical practice in other institutions. We aimed to answer the following questions: are current CNNs for fracture recognition externally valid?; which methods are applied for external validation (EV)?; and, what are reported performances of the EV sets compared to the internal validation (IV) sets of these CNNs? The PubMed and Embase databases were systematically searched from January 2010 to October 2020 according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement. The type of EV, characteristics of the external dataset, and diagnostic performance characteristics on the IV and EV datasets were collected and compared. Quality assessment was conducted using a seven-item checklist based on a modified Methodologic Index for NOn-Randomized Studies instrument (MINORS). Out of 1,349 studies, 36 reported development of a CNN for fracture detection and/or classification. Of these, only four (11%) reported a form of EV. One study used temporal EV, one conducted both temporal and geographical EV, and two used geographical EV. When comparing the CNN's performance on the IV set versus the EV set, the following were found: AUCs of 0.967 (IV) versus 0.975 (EV), 0.976 (IV) versus 0.985 to 0.992 (EV), 0.93 to 0.96 (IV) versus 0.80 to 0.89 (EV), and F1-scores of 0.856 to 0.863 (IV) versus 0.757 to 0.840 (EV). The number of externally validated CNNs in orthopaedic trauma for fracture recognition is still scarce. This greatly limits the potential for transfer of these CNNs from the developing institute to another hospital to achieve similar diagnostic performance. We recommend the use of geographical EV and statements such as the Consolidated Standards of Reporting Trials-Artificial Intelligence (CONSORT-AI), the Standard Protocol Items: Recommendations for Interventional Trials-Artificial Intelligence (SPIRIT-AI) and the Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis-Machine Learning (TRIPOD-ML) to critically appraise performance of CNNs and improve methodological rigor, quality of future models, and facilitate eventual implementation in clinical practice. Cite this article: <i>Bone Jt Open</i>Ã‚Â 2021;2(10):879-885.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20862,""
"Advances of Artificial Intelligence Application in Medical Imaging of Ovarian Cancers","Chen, Huo, Wu, Lu","https://doi.org/10.24920/003963","20211020","PubMed","algorithm; artificial intelligence; machine learning; medical imaging; ovarian cancer; radiomics","Ovarian cancer is one of the three most common gynecological cancers in the world, and is regarded as a priority in terms of women's cancer. In the past few years, many researchers have attempted to develop and apply artificial intelligence (AI) techniques to multiple clinical scenarios of ovarian cancer, especially in the field of medical imaging. AI-assisted imaging studies have involved computer tomography (CT), ultrasonography (US), and magnetic resonance imaging (MRI). In this review, we perform a literature search on the published studies that using AI techniques in the medical care of ovarian cancer, and bring up the advances in terms of four clinical aspects, including medical diagnosis, pathological classification, targeted biopsy guidance, and prognosis prediction. Meanwhile, current status and existing issues of the researches on AI application in ovarian cancer are discussed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20863,""
"Prevalence and Temporal Trends Analysis of Instruments in Posttraumatic Stress Disorder Using Text Mining","Zong, Hu, Han, Li, Zhang","https://doi.org/10.2196/33599","20211019","PubMed","","Various instruments have been developed and applied in posttraumatic stress disorders (PTSD) for patients screening and diagnosis. The study comprehensively investigates prevalence and temporal trends of the majority instruments used in PTSD related studies. A total of 1345 clinical trials registered files from ClinicalTrials.gov and 9422 abstracts from PubMed database ranging from year 2005 to year 2020 were downloaded for this study. The instruments applied in clinical trials were manually annotated, and instruments in abstracts were recognized with exact string matching. The prevalence score of one instrument in a certain period is calculated as the number of studies divided by the number of appearance of the instrument. With the yearly prevalence index of each instrument calculated, we conducted a trends analysis and compared the index change trends between instruments. A total of 4178 instrument synonyms were annotated, which were mapped to 1423 unique instruments. In the 16 years from 2005 to 2020, only 10 instruments were used more than once per year, the top 4 most used instruments were PTSD Checklist (PCL), Clinician Administered PTSD Scale (CAPS), Patient Health Questionnaire (PHQ) and Beck Depression Inventory (BDI). There were 18 instruments whose yearly prevalence index score exceeded 0.1 at least once during the 16 years. The changes in trends and time points of partial instruments in clinical trials and PubMed abstracts are highly consistent. The average time duration of a PTSD related trial was 1495.5 days or approximately 4 years from submission to Clinicaltrial.gov to publishment on journal. The application of widely accepted and appropriate instruments can help improve the reliability of research results in PTSD clinical studies. With the broad text data from real clinical trials and published articles, we investigated and compared the usage of instruments in PTSD research community. We make the resource of this study available on http://bmtongji.cn:1236/scale/index.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20864,""
"The application of e-mental health in response to COVID-19: A scoping review and bibliometric analysis","Ellis, Meulenbroeks, Churruca, Pomare, Hatem, Harrison, Zurynski, Braithwaite","https://doi.org/10.2196/32948","20211019","PubMed","","The COVID-19 pandemic and its mitigation measures such as shelter-in-place orders, social isolation, restrictions on freedoms, unemployment, financial insecurity and disrupted routines, have led to declines in mental health worldwide and concomitant escalating demands for mental health services. Under the circumstances, e-mental health programs and services have rapidly become the ""new normal"". To assess key characteristics and evidence gaps in the e-mental health literature published in relation to the COVID-19 pandemic via a scoping review and bibliometric analysis. A search of four academic databases (MEDLINE, EMBASE, PsycINFO, CINAHL) published from 31st December 2019 to 31st March 2021 using keywords for e-mental health and COVID-19. Article information was extracted relevant to the review objective including journal, type of article, keywords, focus and corresponding author. Information was synthesised by coding these attributes, then summarised through descriptive statistics and narrative techniques. Article influence was examined from Altmetric and CiteScore data, and a network analysis was conducted on article keywords. A total of 356 publications were included in the review. Articles on e-mental health quickly thrived early in the pandemic, with most articles being non-empirical, chiefly commentaries or opinions (n = 225, 63.2%). Empirical publications emerged later and became more frequent as the pandemic progressed. The United States contributed the most articles (n = 160, 44.9%), though a notable number came from middle-income countries (n = 59, 16.6). Articles were spread across 165 journals, and were of above-average-influence (almost half of the articles were in the top 25% of outputs scores by Altmetric and the average CiteScore across articles was 4.22). The network analysis of author-supplied keywords identified key topic areas, including specific: mental disorders; e-health modalities; issues and challenges; and populations of interest. These were further explored via full-text analysis. Applications of e-mental health during the pandemic overcame, or were influenced by system, service, technology, provider and patient factors. COVID-19 has accelerated applications of e-mental health. Further research is needed to support the implementation of e-mental health across system and service infrastructure alongside evidence of the relative effectiveness of e-mental health in comparison to traditional modes of care.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20865,""
"Classification of drugs for evaluating drug interaction in drug development and clinical management","Maeda, Hisaka, Ito, Ohno, Ishiguro, Sato, Nagai","https://doi.org/10.1016/j.dmpk.2021.100414","20211101","PubMed","Clinical pharmacology; Decision tree; Drug development; Drug interaction; Index drug; Labeling; P450; Regulatory guideline; Transporter; Typical drug","During new drug development, clinical drug interaction studies are carried out in accordance with the mechanism of potential drug interactions evaluated by inÃ‚Â vitro studies. The obtained information should be provided efficiently to medical experts through package inserts and various information materials after the drug's launch. A recently updated Japanese guideline presents general procedures that are considered scientifically valid at the present moment. In this review, we aim to highlight the viewpoints of the Japanese guideline and enumerate drugs that were involved or are anticipated to be involved in evident pharmacokinetic drug interactions and classify them by their clearance pathway and potential intensity based on systematic reviews of the literature. The classification would be informative for designing clinical studies during the development stage, and the appropriate management of drug interactions in clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20866,""
"A New Sleep Staging System for Type III Sleep Studies Equipped with a Tracheal Sound Sensor","Vanbuis, Feuilloy, Baffet, Meslier, Gagnadoux, Girault","https://doi.org/10.1109/TBME.2021.3120927","20211019","PubMed","","Type III sleep studies record cardio-respiratory channels only. Compared with polysomnography, which also records electrophysiological channels, they present many advantages: they are less expensive, less time-consuming, and more likely to be performed at home. However, their accuracy is limited by missing sleep information. That is why many studies present specific cardio-respiratory parameters to assess the causal effects of sleep stages upon cardiac or respiratory activities. For this paper, we gathered many parameters proposed in literature, leading to 1,111 features. The pulse oximeter, the PneaVoX sensor (recording tracheal sounds), respiratory inductance plethysmography belts, the nasal cannula and the actimeter provided the 112 worthiest ones for automatic sleep scoring. Then, a 3-step model was implemented: classification with a multi-layer perceptron, sleep transition rules corrections (from the AASM guidelines), and sequence corrections using a Viterbi hidden Markov model. The whole process was trained and tested using 300 and 100 independent recordings provided from patients suspected of having sleep breathing disorders. Results indicated that the system achieves substantial agreement with manual scoring for classifications into 2 stages (wake vs. sleep: mean Cohen's Kappa of 0.63 and accuracy rate Acc of 87.8%) and 3 stages (wake vs. R stage vs. NREM stage: mean of 0.60 and Acc of 78.5%). It indicates that the method could provide information to help specialists while diagnosing sleep. The presented model had promising results and may enhance clinical diagnosis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20867,""
"Prediction of Readmission in Geriatric Patients From Clinical Notes: Retrospective Text Mining Study","Goh, Wang, Yeow, Ding, Au, Poh, Li, Yeow, Tan","https://doi.org/10.2196/26486","20211028","PubMed","artificial intelligence; geriatrics; psychosocial factors; readmission risk; text mining; Aged; Artificial Intelligence; Data Mining; Humans; Length of Stay; Patient Readmission; Retrospective Studies; Risk Factors","Prior literature suggests that psychosocial factors adversely impact health and health care utilization outcomes. However, psychosocial factors are typically not captured by the structured data in electronic medical records (EMRs) but are rather recorded as free text in different types of clinical notes. We here propose a text-mining approach to analyze EMRs to identify older adults with key psychosocial factors that predict adverse health care utilization outcomes, measured by 30-day readmission. The psychological factors were appended to the LACE (Length of stay, Acuity of the admission, Comorbidity of the patient, and Emergency department use) Index for Readmission to improve the prediction of readmission risk. We performed a retrospective analysis using EMR notes of 43,216 hospitalization encounters in a hospital from January 1, 2017 to February 28, 2019. The mean age of the cohort was 67.51 years (SD 15.87), the mean length of stay was 5.57 days (SD 10.41), and the mean intensive care unit stay was 5% (SD 22%). We employed text-mining techniques to extract psychosocial topics that are representative of these patients and tested the utility of these topics in predicting 30-day hospital readmission beyond the predictive value of the LACE Index for Readmission. The added text-mined factors improved the area under the receiver operating characteristic curve of the readmission prediction by 8.46% for geriatric patients, 6.99% for the general hospital population, and 6.64% for frequent admitters. Medical social workers and case managers captured more of the psychosocial text topics than physicians. The results of this study demonstrate the feasibility of extracting psychosocial factors from EMR clinical notes and the value of these notes in improving readmission risk prediction. Psychosocial profiles of patients can be curated and quantified from text mining clinical notes and these profiles can be successfully applied to artificial intelligence models to improve readmission risk prediction.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20868,""
"Learning About the Current State of Digital Mental Health Interventions for Canadian Youth to Inform Future Decision-Making: Mixed Methods Study","Kemp, Chorney, Kassam, MacDonald, MacDonald, Wozney, Strudwick","https://doi.org/10.2196/30491","20211028","PubMed","COVID-19; digital mental health; digital mental health interventions; e-mental health; youth mental health; Adolescent; Artificial Intelligence; COVID-19; Canada; Clinical Decision-Making; Humans; Mental Health; Pandemics; SARS-CoV-2","The COVID-19 pandemic has increased the demand for youth mental health services in Canada as disruptions to clinical care continue to persist due to the risk of transmission and exposure to the virus. Digital mental health interventions, including web-based resources and mobile apps, have provided opportunities to support youth mental health remotely across Canada. There is a need to better understand how these digital interventions are being selected, recommended, and used in various regions across Canada. A national jurisdictional scan was completed to (1) determine what web-based programs, apps, and websites are promoted and licensed in Canada for youth mental health; (2) identify criteria and decision-making processes that Canadian jurisdictions use to select web-based programs, apps, and websites for youth mental health; and (3) identify upcoming trends, innovations, and digital mental health possibilities that are emerging in the youth sector. The aims of the jurisdictional scan were addressed through a review of related academic and grey literature; stakeholder interviews, including individuals involved in various areas of the youth mental health sector; and a social media review of pertinent Twitter content. A total of 66 web-based resources and apps were identified for use by youth in Canada. 16 stakeholder interviews were completed and included discussions with researchers, clinicians, youth organizations, and others involved in digital interventions for youth mental health. These discussions identified a limited use of frameworks used to guide decision-making processes when selecting digital interventions. Many clinicians agreed on a similar set of eligibility requirements for youth mental health apps and digital resources, such as the evidence base and cultural relevance of the intervention. Stakeholders also identified upcoming trends and innovations in the youth digital mental health space, including artificial intelligence, digital phenotyping, and personalized therapy. Over 4 weeks, 2184 tweets were reviewed to identify and compare global and national trends and innovations involving digital mental health and youth. Key trends included the promotion of regional chat services as well as the effects of the COVID-19 pandemic on youth mental health and access to care. As organizations begin to plan for the delivery of mental health care following the pandemic, there are concerns about the sustainability of these digital mental health interventions as well as a need for services to be more informed by the experiences and preferences of youth.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20869,""
"Machine Learning for Workflow Applications in Screening Mammography: Systematic Review and Meta-Analysis","Hickman, Woitek, Le, Im, Mouritsen LuxhÃƒÂ¸j, Aviles-Rivero, Baxter, MacKay, Gilbert","https://doi.org/10.1148/radiol.2021210391","20211019","PubMed","","Background Advances in computer processing and improvements in data availability have led to the development of machine learning (ML) techniques for mammographic imaging. Purpose To evaluate the reported performance of stand-alone ML applications for screening mammography workflow. Materials and Methods Ovid Embase, Ovid Medline, Cochrane Central Register of Controlled Trials, Scopus, and Web of Science literature databases were searched for relevant studies published from January 2012 to September 2020. The study was registered with the PROSPERO International Prospective Register of Systematic Reviews (protocol no. CRD42019156016). Stand-alone technology was defined as a ML algorithm that can be used independently of a human reader. Studies were quality assessed using the Quality Assessment of Diagnostic Accuracy Studies 2 and the Prediction Model Risk of Bias Assessment Tool, and reporting was evaluated using the Checklist for Artificial Intelligence in Medical Imaging. A primary meta-analysis included the top-performing algorithm and corresponding reader performance from which pooled summary estimates for the area under the receiver operating characteristic curve (AUC) were calculated using a bivariate model. Results Fourteen articles were included, which detailed 15 studies for stand-alone detection (<i>n</i> = 8) and triage (<i>n</i> = 7). Triage studies reported that 17%-91% of normal mammograms identified could be read by adapted screening, while ""missing"" an estimated 0%-7% of cancers. In total, an estimated 185Ã¢â‚¬â€°252 cases from three countries with more than 39 readers were included in the primary meta-analysis. The pooled sensitivity, specificity, and AUC was 75.4% (95% CI: 65.6, 83.2; <i>P</i> = .11), 90.6% (95% CI: 82.9, 95.0; <i>P</i> = .40), and 0.89 (95% CI: 0.84, 0.98), respectively, for algorithms, and 73.0% (95% CI: 60.7, 82.6), 88.6% (95% CI: 72.4, 95.8), and 0.85 (95% CI: 0.78, 0.97), respectively, for readers. Conclusion Machine learning (ML) algorithms that demonstrate a stand-alone application in mammographic screening workflows achieve or even exceed human reader detection performance and improve efficiency. However, this evidence is from a small number of retrospective studies. Therefore, further rigorous independent external prospective testing of ML algorithms to assess performance at preassigned thresholds is required to support these claims. Ã‚Â©RSNA, 2021 <i>Online supplemental material is available for this article.</i> See also the editorial by Whitman and Moseley in this issue.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20870,""
"The augmented radiologist: artificial intelligence in the practice of radiology","Sorantin, Grasser, Hemmelmayr, Tschauner, Hrzic, Weiss, Lacekova, Holzinger","https://doi.org/10.1007/s00247-021-05177-7","20211019","PubMed","Artificial intelligence; Clinical decision-making; Deep learning; Pediatric radiology; Radiomics","In medicine, particularly in radiology, there are great expectations in artificial intelligence (AI), which can ""see"" more than human radiologists in regard to, for example, tumor size, shape, morphology, texture and kinetics - thus enabling better care by earlier detection or more precise reports. Another point is that AI can handle large data sets in high-dimensional spaces. But it should not be forgotten that AI is only as good as the training samples available, which should ideally be numerous enough to cover all variants. On the other hand, the main feature of human intelligence is content knowledge and the ability to find near-optimal solutions. The purpose of this paper is to review the current complexity of radiology working places, to describe their advantages and shortcomings. Further, we give an AI overview of the different types and features as used so far. We also touch on the differences between AI and human intelligence in problem-solving. We present a new AI type, labeled ""explainable AI,"" which should enable a balance/cooperation between AI and human intelligence - thus bringing both worlds in compliance with legal requirements. For support of (pediatric) radiologists, we propose the creation of an AI assistant that augments radiologists and keeps their brain free for generic tasks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20871,""
"SysInflam HuDB, a Web Resource for Mining Human Blood Cells Transcriptomic Data Associated with Systemic Inflammatory Responses to Sepsis","Toufiq, Huang, Boughorbel, Alfaki, Rinchai, Saraiva, Chaussabel, Garand","https://doi.org/10.4049/jimmunol.2100697","20211102","PubMed","","Sepsis develops after a dysregulated host inflammatory response to a systemic infection. Identification of sepsis biomarkers has been challenging because of the multifactorial causes of disease susceptibility and progression. Public transcriptomic data are a valuable resource for mechanistic discoveries and cross-studies concordance of heterogeneous diseases. Nonetheless, the approach requires structured methodologies and effective visualization tools for meaningful data interpretation. Currently, no such database exists for sepsis or systemic inflammatory diseases in human. Hence we curated SysInflam HuDB (http://sepsis.gxbsidra.org/dm3/geneBrowser/list), a unique collection of human blood transcriptomic datasets associated with systemic inflammatory responses to sepsis. The transcriptome collection and the associated clinical metadata are integrated onto a user-friendly and Web-based interface that allows the simultaneous exploration, visualization, and interpretation of multiple datasets stemming from different study designs. To date, the collection encompasses 62 datasets and 5719 individual profiles. Concordance of gene expression changes with the associated literature was assessed, and additional analyses are presented to showcase database utility. Combined with custom data visualization at the group and individual levels, SysInflam HuDB facilitates the identification of specific human blood gene signatures in response to infection (e.g., patients with sepsis versus healthy control subjects) and the delineation of major genetic drivers associated with inflammation onset and progression under various conditions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20872,""
"Mild Adverse Events of Sputnik V Vaccine in Russia: Social Media Content Analysis of Telegram via Deep Learning","Jarynowski, Semenov, KamiÃ…â€žski, Belik","https://doi.org/10.2196/30529","20211018","PubMed","","There is a limited amount of data on the COVID-19 vector vaccine Gam-COVID-Vac (Sputnik V) safety profile. Previous infodemiology studies showed that social media discourse could be analyzed to assess the most concerning adverse events (AE) caused by drugs. We aimed to investigate mild AEs of Sputnik V based on a participatory trial conducted on Telegram in the Russian language. We compared AEs extracted from Telegram with other limited databases on Sputnik V and other COVID-19 vaccines. We explored symptom co-occurrence patterns and determined how counts of administered doses, age, gender, and sequence of shots could confound the reporting of AEs. We collected a unique dataset consisting of 11,515 self-reported Sputnik V vaccine AEs posted on the Telegram group, and we utilized natural language processing methods to extract AEs. Specifically, we performed multi-label classifications using the deep neural language model BERT ""DeepPavlov"", which we pre-trained on a Russian language corpus and applied to the Telegram messages. The resulting AUC score was 0.991. We chose symptom classes that represented the following AEs: fever, pain, chills, fatigue, nausea/vomiting, headache, insomnia, lymph node enlargement, erythema, pruritus, swelling, and diarrhea. Telegram users complained mostly about pain (47%), fever (47%), fatigue (34%), and headache (25%). Females reported more AEs than males (1.2-fold, P&lt;.001). In addition, there were more AEs from the first dose than from the second dose (1.1-fold, P&lt;.001), and the number of AEs decreased with age (ÃŽÂ² = .05 per year, P&lt;.001). The results also showed that Sputnik V AEs were more similar to other vector vaccines (132 units) compared with mRNA ones (241 units) according to the average Euclidean distance between the vectors of AE frequencies. Elderly Telegram users reported significantly more (5.6-fold on average) systemic AEs than their peers, according to the results of the phase III clinical trials published in The Lancet. However, the AEs reported in Telegram posts were consistent (Pearson correlation r=.94, P=.02) with those reported in the Argentinian post-marketing AE registry. After the Sputnik V vaccination, Russian Telegram users reported mostly pain, fever, and fatigue. Sputnik V AE profile was comparable with other vector COVID-19 vaccines. Discussion on social media could provide meaningful information about the AE profile of novel vaccines.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20873,""
"Effects of Active Video Games on Health-Related Physical Fitness and Motor Competence in Children and Adolescents With Overweight or Obesity: Systematic Review and Meta-Analysis","Comeras-Chueca, Marin-Puyalto, Matute-Llorente, Vicente-Rodriguez, Casajus, Gonzalez-Aguero","https://doi.org/10.2196/29981","20211019","PubMed","BMI; active videogames; body fat; cardiorespiratory fitness; exergaming; motor skills; muscle","Childhood obesity is one of the most important public health problems. Active video games (AVGs) have been proposed as an attractive alternative to increase energy expenditure and are being investigated to determine their effectiveness against childhood obesity. The aim of this study is to summarize the existing research and draw conclusions about the effects of AVGs on health-related physical fitness and motor competence in children and adolescents with overweight and obesity. The search strategy was applied to PubMed, MEDLINE, Web of Science, and SPORTDiscus, including randomized and nonrandomized controlled trials investigating the effects of AVG programs on health-related physical fitness and motor competence in children and adolescents with overweight and obesity. To measure the risk of bias in randomized and nonrandomized controlled trials, 2 different quality assessment tools were used. In total, 15 articles met the inclusion criteria, and the variables of interest were BMI, body fat percentage, cardiorespiratory fitness (CRF), waist circumference, fat-free mass, muscular fitness, and motor competence. A meta-analysis was performed. Positive effects were found for BMI and body fat percentage, favoring the AVG group compared with a control group with no intervention (mean difference -0.209; 95% CI -0.388 to -0.031 vs mean difference -0.879; 95% CI -1.138 to -0.602). Positive effects seem to be observed for CRF. The effects of AVG interventions on muscular fitness, fat-free mass, waist circumference, and motor competence are unclear. AVG programs showed positive effects on BMI, body fat percentage, and CRF. AVG could be a good strategy to combat childhood obesity.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20874,""
"Machine Learning of Bone Marrow Histopathology Identifies Genetic and Clinical Determinants in Patients with MDS","BrÃƒÂ¼ck, Lallukka-BrÃƒÂ¼ck, Hohtari, Ianevski, Ebeling, Kovanen, KytÃƒÂ¶lÃƒÂ¤, Aittokallio, Ramos, Porkka, Mustjoki","https://doi.org/10.1158/2643-3230.BCD-20-0162","20211022","PubMed","","In myelodysplastic syndrome (MDS) and myeloproliferative neoplasm (MPN), bone marrow (BM) histopathology is assessed to identify dysplastic cellular morphology, cellularity, and blast excess. Yet, other morphologic findings may elude the human eye. We used convolutional neural networks to extract morphologic features from 236 MDS, 87 MDS/MPN, and 11 control BM biopsies. These features predicted genetic and cytogenetic aberrations, prognosis, age, and gender in multivariate regression models. Highest prediction accuracy was found for <i>TET2</i> [area under the receiver operating curve (AUROC) = 0.94] and spliceosome mutations (0.89) and chromosome 7 monosomy (0.89). Mutation prediction probability correlated with variant allele frequency and number of affected genes per pathway, demonstrating the algorithms' ability to identify relevant morphologic patterns. By converting regression models to texture and cellular composition, we reproduced the classical del(5q) MDS morphology consisting of hypolobulated megakaryocytes. In summary, this study highlights the potential of linking deep BM histopathology with genetics and clinical variables. Histopathology is elementary in the diagnostics of patients with MDS, but its high-dimensional data are underused. By elucidating the association of morphologic features with clinical variables and molecular genetics, this study highlights the vast potential of convolutional neural networks in understanding MDS pathology and how genetics is reflected in BM morphology. <i>See related commentary by Elemento, p. 195.</i>","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20875,""
"Application of machine learning in the prediction of COVID-19 daily new cases: A scoping review","Ghafouri-Fard, Mohammad-Rahimi, Motie, Minabi, Taheri, Nateghinia","https://doi.org/10.1016/j.heliyon.2021.e08143","20211022","PubMed","Artificial intelligence; COVID-19; Global pandemic; Machine learning; Spread","COVID-19 has produced a global pandemic affecting all over of the world. Prediction of the rate of COVID-19 spread and modeling of its course have critical impact on both health system and policy makers. Indeed, policy making depends on judgments formed by the prediction models to propose new strategies and to measure the efficiency of the imposed policies. Based on the nonlinear and complex nature of this disorder and difficulties in estimation of virus transmission features using traditional epidemic models, artificial intelligence methods have been applied for prediction of its spread. Based on the importance of machine and deep learning approaches in the estimation of COVID-19 spreading trend, in the present study, we review studies which used these strategies to predict the number of new cases of COVID-19. Adaptive neuro-fuzzy inference system, long short-term memory, recurrent neural network and multilayer perceptron are among the mostly used strategies in this regard. We compared the performance of several machine learning methods in prediction of COVID-19 spread. Root means squared error (RMSE), mean absolute error (MAE), R<sup>2</sup> coefficient of determination (R<sup>2</sup>), and mean absolute percentage error (MAPE) parameters were selected as performance measures for comparison of the accuracy of models. R<sup>2</sup> values have ranged from 0.64 to 1 for artificial neural network (ANN) and Bidirectional long short-term memory (LSTM), respectively. Adaptive neuro-fuzzy inference system (ANFIS), Autoregressive Integrated Moving Average (ARIMA) and Multilayer perceptron (MLP) have also have R<sup>2</sup> values near 1. ARIMA and LSTM had the highest MAPE values. Collectively, these models are capable of identification of learning parameters that affect dissimilarities in COVID-19 spread across various regions or populations, combining numerous intervention methods and implementing what-if scenarios by integrating data from diseases having analogous trends with COVID-19. Therefore, application of these methods would help in precise policy making to design the most appropriate interventions and avoid non-efficient restrictions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20876,""
"Artificial Intelligence for COVID-19: A Systematic Review","Wang, Zhang, Wang, Tong, Liu, Zhang, Huang, Zhang, Chen, Fan, Clarke","https://doi.org/10.3389/fmed.2021.704256","20211022","PubMed","COVID-19; artificial intelligence; diagnosis; drug discovery 2; epidemic prediction; prognosis evaluation","<b>Background:</b> Recently, Coronavirus Disease 2019 (COVID-19), caused by severe acute respiratory syndrome virus 2 (SARS-CoV-2), has affected more than 200 countries and lead to enormous losses. This study systematically reviews the application of Artificial Intelligence (AI) techniques in COVID-19, especially for diagnosis, estimation of epidemic trends, prognosis, and exploration of effective and safe drugs and vaccines; and discusses the potential limitations. <b>Methods:</b> We report this systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. We searched PubMed, Embase and the Cochrane Library from inception to 19 September 2020 for published studies of AI applications in COVID-19. We used PROBAST (prediction model risk of bias assessment tool) to assess the quality of literature related to the diagnosis and prognosis of COVID-19. We registered the protocol (PROSPERO CRD42020211555). <b>Results:</b> We included 78 studies: 46 articles discussed AI-assisted diagnosis for COVID-19 with total accuracy of 70.00 to 99.92%, sensitivity of 73.00 to 100.00%, specificity of 25 to 100.00%, and area under the curve of 0.732 to 1.000. Fourteen articles evaluated prognosis based on clinical characteristics at hospital admission, such as clinical, laboratory and radiological characteristics, reaching accuracy of 74.4 to 95.20%, sensitivity of 72.8 to 98.00%, specificity of 55 to 96.87% and AUC of 0.66 to 0.997 in predicting critical COVID-19. Nine articles used AI models to predict the epidemic of the COVID-19, such as epidemic peak, infection rate, number of infected cases, transmission laws, and development trend. Eight articles used AI to explore potential effective drugs, primarily through drug repurposing and drug development. Finally, 1 article predicted vaccine targets that have the potential to develop COVID-19 vaccines. <b>Conclusions:</b> In this review, we have shown that AI achieved high performance in diagnosis, prognosis evaluation, epidemic prediction and drug discovery for COVID-19. AI has the potential to enhance significantly existing medical and healthcare system efficiency during the COVID-19 pandemic.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20877,""
"Mitigating Burnout in an Oncological Unit: A Scoping Review","Alabi, Hietanen, Elmusrati, Youssef, Almangush, MÃƒÂ¤kitie","https://doi.org/10.3389/fpubh.2021.677915","20211025","PubMed","address; artificial intelligence; burnoutÃ¢â‚¬â€professional; compassion fatigue; job satisfaction; mitigate; oncology; stress; Artificial Intelligence; Burnout, Professional; Humans; Job Satisfaction; Medical Oncology; Oncologists","<b>Objectives:</b> The purpose of this study was to provide a scoping review on how to address and mitigate burnout in the profession of clinical oncology. Also, it examines how artificial intelligence (AI) can mitigate burnout in oncology. <b>Methods:</b> We searched Ovid Medline, PubMed, Scopus, and Web of Science, for articles that examine how to address burnout in oncology. <b>Results:</b> A total of 17 studies were found to examine how burnout in oncology can be mitigated. These interventions were either targeted at individuals (oncologists) or organizations where the oncologists work. The organizational interventions include educational (psychosocial and mindfulness-based course), art therapies and entertainment, team-based training, group meetings, motivational package and reward, effective leadership and policy change, and staff support. The individual interventions include equipping the oncologists with adequate training that include-communication skills, well-being and stress management, burnout education, financial independence, relaxation, self-efficacy, resilience, hobby adoption, and work-life balance for the oncologists. Similarly, AI is thought to be poised to offer the potential to mitigate burnout in oncology by enhancing the productivity and performance of the oncologists, reduce the workload and provide job satisfaction, and foster teamwork between the caregivers of patients with cancer. <b>Discussion:</b> Burnout is common among oncologists and can be elicited from different types of situations encountered in the process of caring for patients with cancer. Therefore, for these interventions to achieve the touted benefits, combinatorial strategies that combine other interventions may be viable for mitigating burnout in oncology. With the potential of AI to mitigate burnout, it is important for healthcare providers to facilitate its use in daily clinical practices. <b>Conclusion:</b> These combinatorial interventions can ensure job satisfaction, a supportive working environment, job retention for oncologists, and improved patient care. These interventions could be integrated systematically into routine cancer care for a positive impact on quality care, patient satisfaction, the overall success of the oncological ward, and the health organizations at large.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20878,""
"MRI-Based Grading of Clear Cell Renal Cell Carcinoma Using a Machine Learning Classifier","Chen, Zhang, Chen, Huang, Xia, Yan, Xu, Chen, Wang, Chen","https://doi.org/10.3389/fonc.2021.708655","20211022","PubMed","clear cell renal cell carcinoma; machine learning; magnetic resonance imaging; multi-layer perceptron algorithm; texture analysis","To develop a machine learning (ML)-based classifier for discriminating between low-grade (ISUP I-II) and high-grade (ISUP III-IV) clear cell renal cell carcinomas (ccRCCs) using MRI textures. We retrospectively evaluated a total of 99 patients (with 61 low-grade and 38 high-grade ccRCCs), who were randomly divided into a training set (<i>n</i> = 70) and a validation set (<i>n</i> = 29). Regions of interest (ROIs) of all tumors were manually drawn three times by a radiologist at the maximum lesion level of the cross-sectional CMP sequence images. The quantitative texture analysis software, MaZda, was used to extract texture features, including histograms, co-occurrence matrixes, run-length matrixes, gradient models, and autoregressive models. Reproducibility of the texture features was assessed with the intra-class correlation coefficient (ICC). Features were chosen based on their importance coefficients in a random forest model, while the multi-layer perceptron algorithm was used to build a classifier on the training set, which was later evaluated with the validation set. The ICCs of 257 texture features were equal to or higher than 0.80 (0.828-0.998. Six features, namely Kurtosis, 135dr_RLNonUni, Horzl_GLevNonU, 135dr_GLevNonU, S(4,4)Entropy, and S(0,5)SumEntrp, were chosen to develop the multi-layer perceptron classifier. A three-layer perceptron model, which has 229 nodes in the hidden layer, was trained on the training set. The accuracy of the model was 95.7% with the training set and 86.2% with the validation set. The areas under the receiver operating curves were 0.997 and 0.758 for the training and validation sets, respectively. A machine learning-based grading model was developed that can aid in the clinical diagnosis of clear cell renal cell carcinoma using MRI images.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20879,""
"Generative Adversarial Networks and Radiomics Supervision for Lung Lesion Synthesis","Pan, Flores, Lin, Stayman, Gang","https://doi.org/10.1117/12.2582151","20211022","PubMed","deep learning; generative adversarial network; lesion generation; virtual clinical trial","Realistic lesion generation is a useful tool for system evaluation and optimization. In this work, we investigate a data-driven approach for categorical lung lesion generation using public lung CT databases. We propose a generative adversarial network with a Wasserstein discrimination and gradient penalty to stabilize training. We further included conditional inputs such that the network can generate user-specified lesion categories. Novel to our network, we directly incorporated radiomic features in an intermediate supervision step to encourage similar textures between generated and real lesions. We evaluated the network using lung lesions from the Lung Image Database Consortium (LIDC) database. The lesions are divided into two categories: solid vs. non-solid. We performed quantitative evaluation of network performance base on four criteria: 1) overfitting in terms of structural and morphological similarity to the training data, 2) diversity of generated lesions in terms of similarity to other generated data, 3) similarity to real lesions in terms of distribution of example radiomics features, and 4) conditional consistency in terms of classification accuracy using a classifier trained on the training lesions. We imposed a quantitative threshold for similarity based on visual inspection. The percentage of non-solid and solid lesions that satisfy low overfitting and high diversity is 96.9% and 88.6% of non-solid and solid lesions respectively. The distribution of example radiomics features are similar in the generated and real lesions indicated by a low Kullback-Leibler divergence score. Classification accuracy for the generated lesions are comparable with that for the real lesions. The proposed network is a promising approach for data-driven generation of realistic lung lesions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20880,""
"Automated Text Messaging After Hip Arthroscopy: A randomized-controlled trial of ""Post-Op Buddy""","Scott, Anthony, O'Connor, Lynch, Westermann","https://doi.org/10.1016/j.arthro.2021.09.030","20211016","PubMed","electronic communication; hip arthroscopy; patient-reported outcomes; rehabilitation; telemedicine; text messaging","To assess an automated text messaging system for patients after hip arthroscopy and its impact at 90 days on the Hip Disability Osteoarthritis Outcome Score (HOOS-PS, HOOS-PAIN), compliance with rehabilitation guidelines and patient satisfaction. One hundred twenty-one participants (average age 29Ã‚Â±8.7 years, 52% female) undergoing hip arthroscopy at two academic institutions were prospectively enrolled and randomized to receive (1) standard perioperative communication or (2) additional automated mobile phone text messages. Inclusion criteria included ability to communicate in written English and access to a mobile phone with text messaging capability. Patients undergoing revision surgery or simultaneous femoral or acetabular osteotomy were excluded. HOOS-PS and HOOS-PAIN were collected pre-operatively, and after surgery an automated mobile phone robot sent participants in the therapeutic arm intermittent text messages for 90 days. At 90 days all participants again completed HOOS-PS, HOOS-PAIN, and additional survey questions on satisfaction with their experience (10-point scale), communication from the surgical team (10-point scale) and adherence to physical therapy exercises, weightbearing guidelines, and brace use, The primary outcome assessed was a statistically significant change in HOOS-PS and HOOS-PAIN; secondary outcomes included change in satisfaction, communication, and adherence to physical therapy exercises, weightbearing guidelines, or brace use. Wilcoxon rank sum was used to compare HOOS-PS and HOOS-PAIN scores at 0 and 90 days. Demographic characteristics and survey variables were compared using Students t-test for continuous variables and chi square or Fisher exact test for categorical variables as appropriate. There were statistically significant and clinically relevant improvements in HOOS-PS and HOOS-PAIN in both groups (p&lt;0.05). Subjective feedback was strongly positive, with 96% of text message participants reporting they would choose automated messages if it was offered to them again in the future. Ninety days of automated text messaging after hip arthroscopy failed to show a significant difference in HOOS-PS (p=0.09), HOOS-PAIN (p=0.13), patient reported compliance with post-operative guidelines, or satisfaction with support and communication from the surgical team. 1 - Randomized Control Trial (RCT).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20881,""
"A text-mining based analysis of 100,000 tumours affecting dogs and cats in the United Kingdom","RodrÃƒÂ­guez, Killick, Ressel, Espinosa de Los Monteros, Santana, Beck, Cian, McKay, Noble, Pinchbeck, Singleton, Radford","https://doi.org/10.1038/s41597-021-01039-x","20211030","PubMed","","Cancer is a major reason for veterinary consultation, especially in companion animals. Cancer surveillance plays a key role in prevention but opportunities for such surveillance in companion animals are limited by the lack of suitable veterinary population health infrastructures. In this paper we describe a pathology-based animal tumour registry (PTR) developed within the Small Animal Veterinary Surveillance Network (SAVSNET) built from electronic pathology records (EPR) submitted to this network. From an original collection of 180232 free text (non-structured) EPRs reported between April 2018 and June 2019, we used specific text-mining methodologies to identify 109895 neoplasias. These data were normalized to describe both the tumour (type and location) and the animal (breed, neutering status and veterinary practice postcode). The resulting PTR, the largest of its kind for companion animals to date, is an important research resource being able to facilitate a wide array of research in areas including surveillance, clinical decision making and comparative cancer biology.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20882,""
"Applying text mining to identify relevant literature in food science: Cold denaturation as a case study","Helmick, Nanda, Ettestad, Liceaga, Kokini","https://doi.org/10.1111/1750-3841.15940","20211015","PubMed","big data; cold denaturation; latent dirichlet allocation; python; systematic review; text mining; topic modeling","In a research environment characterized by the five V's of big data, volume, velocity, variety, value, and veracity, the need to develop tools that quickly screen a large number of publications into relevant work is an increasing area of concern, and the data-rich food industry is no exception. Here, a combination of latent Dirichlet allocation and food keyword searches were employed to analyze and filter a dataset of 6102 publications about cold denaturation. After using the Python toolkit generated in this work, the approach yielded 22 topics that provide background and insight on the direction of research in this field, as well as identified the publications in this dataset which are most pertinent to the food industry with precision and recall of 0.419 and 0.949, respectively. Precision is related to the relevance of a paper in the filtered dataset and the recall represents papers which were not identified in the screening method. Lastly, gaps in the literature based on keyword trends are identified to improve the knowledge base of cold denaturation as it relates to the food industry. This approach is generalizable to any similarly organized dataset, and the code is available upon request. Practical Application: A common problem in research is that when you are an expert in one field, learning about another field is difficult, because you may lack the vocabulary and background needed to read cutting edge literature from a new discipline. The Python toolkit developed in this research can be applied by any researcher that is new to a field to identify what the key literature is, what topics they should familiarize themselves with, and what the current trends are in the field. Using this structure, researchers can greatly speed up how they identify new areas to research and find new projects.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20883,""
"Text mining-based word representations for biomedical data analysis and protein-protein interaction networks in machine learning tasks","Alachram, Chereda, BeiÃƒÅ¸barth, Wingender, Stegmaier","https://doi.org/10.1371/journal.pone.0258623","20211022","PubMed","","Biomedical and life science literature is an essential way to publish experimental results. With the rapid growth of the number of new publications, the amount of scientific knowledge represented in free text is increasing remarkably. There has been much interest in developing techniques that can extract this knowledge and make it accessible to aid scientists in discovering new relationships between biological entities and answering biological questions. Making use of the word2vec approach, we generated word vector representations based on a corpus consisting of over 16 million PubMed abstracts. We developed a text mining pipeline to produce word2vec embeddings with different properties and performed validation experiments to assess their utility for biomedical analysis. An important pre-processing step consisted in the substitution of synonymous terms by their preferred terms in biomedical databases. Furthermore, we extracted gene-gene networks from two embedding versions and used them as prior knowledge to train Graph-Convolutional Neural Networks (CNNs) on large breast cancer gene expression data and on other cancer datasets. Performances of resulting models were compared to Graph-CNNs trained with protein-protein interaction (PPI) networks or with networks derived using other word embedding algorithms. We also assessed the effect of corpus size on the variability of word representations. Finally, we created a web service with a graphical and a RESTful interface to extract and explore relations between biomedical terms using annotated embeddings. Comparisons to biological databases showed that relations between entities such as known PPIs, signaling pathways and cellular functions, or narrower disease ontology groups correlated with higher cosine similarity. Graph-CNNs trained with word2vec-embedding-derived networks performed sufficiently good for the metastatic event prediction tasks compared to other networks. Such performance was good enough to validate the utility of our generated word embeddings in constructing biological networks. Word representations as produced by text mining algorithms like word2vec, therefore are able to capture biologically meaningful relations between entities. Our generated embeddings are publicly available at https://github.com/genexplain/Word2vec-based-Networks/blob/main/README.md.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20884,""
"New diagnostic and imaging technologies in dermatology","Jartarkar, Patil, Wollina, Gold, Stege, Grabbe, Goldust","https://doi.org/10.1111/jocd.14499","20211026","PubMed","dermatology; diagnosis; technology","Diagnosis of dermatological disorders is primarily based on clinical examination in combination with histopathology. However, clinical findings alone may not be sufficient for accurate diagnosis and cutaneous biopsies are being associated with morbidity. The objective of this article is to review the newer technologies along with their applications, limitation and future prospectus. Comprehensive literature search was performed using electronic online databases ""PubMed"" and ""Google Scholar"". Articles published in English language were considered for the review. In order to improve and/or widen the armamentarium in dermatologic disease diagnosis and therapy, newer emerging technologies are being made available which aid in diagnosis and management. New emerging technologies include confocal microscopy, digital photographic imaging, optical coherence tomography, high frequency ultrasonography, and artificial intelligence. There have been advancements in the dermoscopes. Significant progress is seen in the diagnostic methods and imaging technologies in dermatology, each having its advantages and limitations. Artificial intelligence/machine-based learning software may have a great scope to influence the dermatological practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20885,""
"Delineating the field of medical education: Bibliometric research approach(es)","Maggio, Ninkov, Frank, Costello, Artino","https://doi.org/10.1111/medu.14677","20211102","PubMed","","The field of medical education remains poorly delineated such that there is no broad consensus of articles or journals that comprise 'the field'. This lack of consensus indicates a missed opportunity for researchers to generate insights about the field that could facilitate conducting bibliometric studies and other research designs (e.g., systematic reviews) and also enable individuals to identify themselves as 'medical education researchers'. Other fields have utilised bibliometric field delineation, which is the assigning of articles or journals to a certain field in an effort to define that field. In this Research Approach, three bibliometric field delineation approaches-information retrieval, core journals, and journal co-citation-are introduced. For each approach, the authors describe attempts to apply it in medical education and identify related strengths and weaknesses. Based on co-citation, the authors propose the Medical Education Journal List 24 (MEJ-24), as a starting point for delineating medical education and invite the community to collaborate on improving and potentially expanding this list. As a research approach, field delineation is complicated, and there is no clear best way to delineate the field of medical education. However, recent advances in information science provide potentially fruitful approaches to deal with the field's complexity. When considering these approaches, researchers should consider collaborating with bibliometricians. Bibliometric approaches rely on available metadata for articles and journals, which necessitates that researchers examine the metadata prior to analysis to understand its strengths and weaknesses, and to assess how this might affect data interpretation. While using bibliometric approaches for field delineation is valuable, it is important to remember that these techniques are only as good as the research team's interpretation of the data, which suggests that an expanded approach is needed to better delineate medical education, an approach that includes active discussion within the medical education community.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20886,""
"Data Anonymization for Pervasive Health Care: Systematic Literature Mapping Study","Zuo, Watson, Budgen, Hall, Kennelly, Al Moubayed","https://doi.org/10.2196/29871","20211018","PubMed","DPA 2018; EHR; GDPR; SLM; anonymization; data science; healthcare; privacy-preserving; reidentification risk; usability","Data science offers an unparalleled opportunity to identify new insights into many aspects of human life with recent advances in health care. Using data science in digital health raises significant challenges regarding data privacy, transparency, and trustworthiness. Recent regulations enforce the need for a clear legal basis for collecting, processing, and sharing data, for example, the European Union's General Data Protection Regulation (2016) and the United Kingdom's Data Protection Act (2018). For health care providers, legal use of the electronic health record (EHR) is permitted only in clinical care cases. Any other use of the data requires thoughtful considerations of the legal context and direct patient consent. Identifiable personal and sensitive information must be sufficiently anonymized. Raw data are commonly anonymized to be used for research purposes, with risk assessment for reidentification and utility. Although health care organizations have internal policies defined for information governance, there is a significant lack of practical tools and intuitive guidance about the use of data for research and modeling. Off-the-shelf data anonymization tools are developed frequently, but privacy-related functionalities are often incomparable with regard to use in different problem domains. In addition, tools to support measuring the risk of the anonymized data with regard to reidentification against the usefulness of the data exist, but there are question marks over their efficacy. In this systematic literature mapping study, we aim to alleviate the aforementioned issues by reviewing the landscape of data anonymization for digital health care. We used Google Scholar, Web of Science, Elsevier Scopus, and PubMed to retrieve academic studies published in English up to June 2020. Noteworthy gray literature was also used to initialize the search. We focused on review questions covering 5 bottom-up aspects: basic anonymization operations, privacy models, reidentification risk and usability metrics, off-the-shelf anonymization tools, and the lawful basis for EHR data anonymization. We identified 239 eligible studies, of which 60 were chosen for general background information; 16 were selected for 7 basic anonymization operations; 104 covered 72 conventional and machine learning-based privacy models; four and 19 papers included seven and 15 metrics, respectively, for measuring the reidentification risk and degree of usability; and 36 explored 20 data anonymization software tools. In addition, we also evaluated the practical feasibility of performing anonymization on EHR data with reference to their usability in medical decision-making. Furthermore, we summarized the lawful basis for delivering guidance on practical EHR data anonymization. This systematic literature mapping study indicates that anonymization of EHR data is theoretically achievable; yet, it requires more research efforts in practical implementations to balance privacy preservation and usability to ensure more reliable health care applications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20887,""
"[Robot-assisted joint arthroplasty-An emerging technology of the present and the future]","Fu, Ni, Chen","https://doi.org/10.7507/1002-1892.202106086","20211018","PubMed","Robot-assisted surgery; artificial intelligence; joint replacement; precision surgery; Arthroplasty, Replacement, Knee; Artificial Limbs; Humans; Knee Joint; Operative Time; Robotics","To review and evaluate the research progress of the robot-assisted joint arthroplasty. The domestic and foreign related research literature on robot-assisted joint arthroplasty was extensively consulted. The advantages, disadvantages, effectiveness, and future prospects were mainly reviewed and summarized. The widely recognized advantages of robot-assisted joint arthroplasty are digital and intelligent preoperative planning, accurate intraoperative prosthesis implantation, and quantitative soft tissue balance, as well as good postoperative imaging prosthesis position and alignment. However, the advantages of effectiveness are still controversial. The main disadvantages of robot-assisted joint arthroplasty are the high price of the robot system, the prolonged operation time, and the increased radioactive damage of the imaging-dependent system. Compared to traditional arthroplasty, robot-assisted joint arthroplasty can improve the accuracy of the prosthesis position and assist in the quantitative assessment of soft tissue tension, and the repeatability rate is high. In the future, further research is needed to evaluate the clinical function and survival rate of the prosthesis, as well as to optimize the robot system. Ã¥Â¯Â¹Ã¦Å“ÂºÃ¥â„¢Â¨Ã¤ÂºÂºÃ¨Â¾â€¦Ã¥Å Â©Ã¥â€¦Â³Ã¨Å â€šÃ§Â½Â®Ã¦ÂÂ¢Ã¦â€°â€¹Ã¦Å“Â¯Ã§Å¡â€žÃ§Â â€Ã§Â©Â¶Ã¨Â¿â€ºÃ¥Â±â€¢Ã¨Â¿â€ºÃ¨Â¡Å’Ã§Â»Â¼Ã¨Â¿Â°Ã¥â€™Å’Ã¨Â¯â€žÃ¤Â»Â·Ã£â‚¬â€š. Ã¥Â¹Â¿Ã¦Â³â€ºÃ¦Å¸Â¥Ã©Ëœâ€¦Ã¥â€ºÂ½Ã¥â€ â€¦Ã¥Â¤â€“Ã¥â€¦Â³Ã¤ÂºÅ½Ã¦Å“ÂºÃ¥â„¢Â¨Ã¤ÂºÂºÃ¨Â¾â€¦Ã¥Å Â©Ã¥â€¦Â³Ã¨Å â€šÃ§Â½Â®Ã¦ÂÂ¢Ã¦â€°â€¹Ã¦Å“Â¯Ã§Å¡â€žÃ§â€ºÂ¸Ã¥â€¦Â³Ã§Â â€Ã§Â©Â¶Ã¦â€“â€¡Ã§Å’Â®Ã¯Â¼Å’Ã¥Â¯Â¹Ã¥â€¦Â¶Ã¤Â¼ËœÃ§Â¼ÂºÃ§â€šÂ¹Ã£â‚¬ÂÃ¤Â¸Â´Ã¥ÂºÅ Ã§â€“â€”Ã¦â€¢Ë†Ã¥â€™Å’Ã¦Å“ÂªÃ¦ÂÂ¥Ã¥Â±â€¢Ã¦Å“â€ºÃ§Â­â€°Ã¨Â¿â€ºÃ¨Â¡Å’Ã¦â‚¬Â»Ã§Â»â€œÃ£â‚¬â€š. Ã§â€ºÂ®Ã¥â€°ÂÃ¥Â¹Â¿Ã¦Â³â€ºÃ¨Â®Â¤Ã¥ÂÂ¯Ã§Å¡â€žÃ¦Å“ÂºÃ¥â„¢Â¨Ã¤ÂºÂºÃ¨Â¾â€¦Ã¥Å Â©Ã¥â€¦Â³Ã¨Å â€šÃ§Â½Â®Ã¦ÂÂ¢Ã¦â€°â€¹Ã¦Å“Â¯Ã¤Â¼ËœÃ¥Å Â¿Ã¥Å“Â¨Ã¤ÂºÅ½Ã¦â€¢Â°Ã¥Â­â€”Ã¥Å’â€“Ã£â‚¬ÂÃ¦â„¢ÂºÃ¨Æ’Â½Ã¥Å’â€“Ã§Å¡â€žÃ¦Å“Â¯Ã¥â€°ÂÃ¨Â§â€žÃ¥Ë†â€™Ã¯Â¼Å’Ã§Â²Â¾Ã¥â€¡â€ Ã¥Å’â€“Ã¥Ââ€¡Ã¤Â½â€œÃ¥Â®â€°Ã¨Â£â€¦Ã¥â€™Å’Ã©â€¡ÂÃ¥Å’â€“Ã§Å¡â€žÃ¦Å“Â¯Ã¤Â¸Â­Ã¨Â½Â¯Ã§Â»â€žÃ§Â»â€¡Ã¥Â¹Â³Ã¨Â¡Â¡Ã¯Â¼Å’Ã¤Â»Â¥Ã¥ÂÅ Ã¨â€°Â¯Ã¥Â¥Â½Ã§Å¡â€žÃ¦Å“Â¯Ã¥ÂÅ½Ã¥Â½Â±Ã¥Æ’ÂÃ¥Â­Â¦Ã¥Ââ€¡Ã¤Â½â€œÃ¥Â¯Â¹Ã¤Â½ÂÃ¥â€™Å’Ã¥Â¯Â¹Ã§ÂºÂ¿Ã¯Â¼Å’Ã¤Â½â€ Ã¤Â¸Â´Ã¥ÂºÅ Ã§â€“â€”Ã¦â€¢Ë†Ã¤Â¼ËœÃ¥Å Â¿Ã¤Â»ÂÃ¥Â­ËœÃ¥Å“Â¨Ã¤Âºâ€°Ã¨Â®Â®Ã£â‚¬â€šÃ¦Å“ÂºÃ¥â„¢Â¨Ã¤ÂºÂºÃ¨Â¾â€¦Ã¥Å Â©Ã¥â€¦Â³Ã¨Å â€šÃ§Â½Â®Ã¦ÂÂ¢Ã¦â€°â€¹Ã¦Å“Â¯Ã§Å¡â€žÃ§Â¼ÂºÃ§â€šÂ¹Ã¤Â¸Â»Ã¨Â¦ÂÃ¦Å“â€°Ã¦Å“ÂºÃ¥â„¢Â¨Ã¤ÂºÂºÃ§Â³Â»Ã§Â»Å¸Ã¤Â»Â·Ã¦Â Â¼Ã¦Ëœâ€šÃ¨Â´ÂµÃ£â‚¬ÂÃ¦â€°â€¹Ã¦Å“Â¯Ã¦â€”Â¶Ã©â€”Â´Ã¥Â»Â¶Ã©â€¢Â¿Ã£â‚¬ÂÃ¥Â½Â±Ã¥Æ’ÂÃ¥Â­Â¦Ã¤Â¾ÂÃ¨Âµâ€“Ã¦Å“ÂºÃ¥â„¢Â¨Ã¤ÂºÂºÃ§Â³Â»Ã§Â»Å¸Ã§Å¡â€žÃ¦â€Â¾Ã¥Â°â€žÃ¦â‚¬Â§Ã¦ÂÅ¸Ã¤Â¼Â¤Ã¥Â¢Å¾Ã¥Å Â Ã§Â­â€°Ã£â‚¬â€š. Ã§â€ºÂ¸Ã¨Â¾Æ’Ã¤ÂºÅ½Ã¤Â¼Â Ã§Â»Å¸Ã¦â€°â€¹Ã¦Å“Â¯Ã¯Â¼Å’Ã¦Å“ÂºÃ¥â„¢Â¨Ã¤ÂºÂºÃ¨Â¾â€¦Ã¥Å Â©Ã¥â€¦Â³Ã¨Å â€šÃ§Â½Â®Ã¦ÂÂ¢Ã¦â€°â€¹Ã¦Å“Â¯Ã¥ÂÂ¯Ã¦ÂÂÃ©Â«ËœÃ¥Ââ€¡Ã¤Â½â€œÃ¤Â½ÂÃ§Â½Â®Ã§Å¡â€žÃ§Â²Â¾Ã¥â€¡â€ Ã¥ÂºÂ¦Ã£â‚¬ÂÃ¨Â¾â€¦Ã¥Å Â©Ã©â€¡ÂÃ¥Å’â€“Ã¨Â¯â€žÃ¤Â¼Â°Ã¨Â½Â¯Ã§Â»â€žÃ§Â»â€¡Ã¥Â¼Â Ã¥Å â€ºÃ¯Â¼Å’Ã¤Â¸â€Ã¥ÂÂ¯Ã©â€¡ÂÃ¥Â¤ÂÃ¦â‚¬Â§Ã©Â«ËœÃ£â‚¬â€šÃ¦Å“ÂªÃ¦ÂÂ¥Ã¨Â¿ËœÃ©Å“â‚¬Ã¨Â¦ÂÃ¨Â¿â€ºÃ¤Â¸â‚¬Ã¦Â­Â¥Ã§Â â€Ã§Â©Â¶Ã¨Â¯â€žÃ¤Â¼Â°Ã¤Â¸Â´Ã¥ÂºÅ Ã¥Å Å¸Ã¨Æ’Â½Ã¥â€™Å’Ã¥Ââ€¡Ã¤Â½â€œÃ§â€Å¸Ã¥Â­ËœÃ§Å½â€¡Ã¯Â¼Å’Ã¤Â»Â¥Ã¥ÂÅ Ã¤Â¼ËœÃ¥Å’â€“Ã¦Å“ÂºÃ¥â„¢Â¨Ã¤ÂºÂºÃ§Â³Â»Ã§Â»Å¸Ã£â‚¬â€š.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20888,""
"Walking on common ground: a cross-disciplinary scoping review on the clinical utility of digital mobility outcomes","Polhemus, Ortiz, Brittain, Chynkiamis, Salis, GaÃƒÅ¸ner, Gross, Kirk, Rossanigo, Taraldsen, Balta, Breuls, Buttery, Cardenas, Endress, Gugenhan, Keogh, Kluge, Koch, MicÃƒÂ³-Amigo, Nerz, Sieber, Williams, Bergquist, de Basea, Buckley, Hansen, Mikolaizak, Schwickert, Scott, Stallforth, van Uem, Vereijken, Cereatti, Demeyer, Hopkinson, Maetzler, Troosters, Vogiatzis, Yarnall, Becker, Garcia-Aymerich, Leocani, MazzÃƒÂ , Rochester, Sharrack, Frei, Puhan","https://doi.org/10.1038/s41746-021-00513-5","20211030","PubMed","","Physical mobility is essential to health, and patients often rate it as a high-priority clinical outcome. Digital mobility outcomes (DMOs), such as real-world gait speed or step count, show promise as clinical measures in many medical conditions. However, current research is nascent and fragmented by discipline. This scoping review maps existing evidence on the clinical utility of DMOs, identifying commonalities across traditional disciplinary divides. In November 2019, 11 databases were searched for records investigating the validity and responsiveness of 34 DMOs in four diverse medical conditions (Parkinson's disease, multiple sclerosis, chronic obstructive pulmonary disease, hip fracture). Searches yielded 19,672 unique records. After screening, 855 records representing 775 studies were included and charted in systematic maps. Studies frequently investigated gait speed (70.4% of studies), step length (30.7%), cadence (21.4%), and daily step count (20.7%). They studied differences between healthy and pathological gait (36.4%), associations between DMOs and clinical measures (48.8%) or outcomes (4.3%), and responsiveness to interventions (26.8%). Gait speed, step length, cadence, step time and step count exhibited consistent evidence of validity and responsiveness in multiple conditions, although the evidence was inconsistent or lacking for other DMOs. If DMOs are to be adopted as mainstream tools, further work is needed to establish their predictive validity, responsiveness, and ecological validity. Cross-disciplinary efforts to align methodology and validate DMOs may facilitate their adoption into clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20889,""
"Diagnostic Test Accuracy of Deep Learning Detection of COVID-19: A Systematic Review and Meta-Analysis","Komolafe, Cao, Nguchu, Monkam, Olaniyi, Sun, Zheng, Yang","https://doi.org/10.1016/j.acra.2021.08.008","20211022","PubMed","COVID-19; Chest computed tomography; Deep learning; Diagnostic test accuracy; Meta-analysis","To perform a meta-analysis to compare the diagnostic test accuracy (DTA) of deep learning (DL) in detecting coronavirus disease 2019 (COVID-19), and to investigate how network architecture and type of datasets affect DL performance. We searched PubMed, Web of Science and Inspec from January 1, 2020, to December 3, 2020, for retrospective and prospective studies on deep learning detection with at least reported sensitivity and specificity. Pooled DTA was obtained using random-effect models. Sub-group analysis between studies was also carried out for data source and network architectures. The pooled sensitivity and specificity were 91% (95% confidence interval [CI]: 88%, 93%; I<sup>2</sup>Ã‚Â =Ã‚Â 69%) and 92% (95% CI: 88%, 94%; I<sup>2</sup>Ã‚Â =Ã‚Â 88%), respectively for 19 studies. The pooled AUC and diagnostic odds ratio (DOR) were 0.95 (95% CI: 0.88, 0.92) and 112.5 (95% CI: 57.7, 219.3; I<sup>2</sup>Ã‚Â =Ã‚Â 90%) respectively. The overall accuracy, recall, F1-score, LR<sup>+</sup> and LR<sup>-</sup> are 89.5%, 89.5%, 89.7%, 23.13 and 0.13. Sub-group analysis shows that the sensitivity and DOR significantly vary with the type of network architectures and sources of data with low heterogeneity are (I<sup>2</sup>Ã‚Â =Ã‚Â 0%) and (I<sup>2</sup>Ã‚Â =Ã‚Â 18%) for ResNet architecture and single-source datasets, respectively. The diagnosis of COVID-19 via deep learning has achieved incredible performance, and the source of datasets, as well as network architectures, strongly affect DL performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20890,""
"An ontology-based review of transgender literature: Revealing a history of medicalization and pathologization","Kronk, Dexheimer","https://doi.org/10.1016/j.ijmedinf.2021.104601","20211102","PubMed","Bibliography; Biological Ontologies; Natural Language Processing; Transgender Persons; Transsexualism","To evaluate the linguistic changes of transgender-related resources prior to 1999 to create a comprehensive dataset of resources using an ontology-derived search system, laying a framework for ontology-based reviews to be used in informatics. We analyzed 77 bibliographies and 11 databases for transgender resources published prior to 31 December 1999. We used 858 variants of the term ""transgender"" to identify resources. Individual sources were tagged by subject matter and major conceptual terminology usage. We evaluated the accuracy of a Gender, Sex, and Sexual Orientation (GSSO) ontology-based mechanism on tagging relevant literature searches. We identified 3,058 sources in 19 languages. Primary subjects covered included surgery, psychology, psychiatry, endocrinology, and sexology. The GSSO-based tagging mechanism correctly tagged 97.7% of MEDLINE resources as transgender-related. The GSSO-based tagging mechanism was more effective than keyword-specific elucidations of terminologically complex literature and was just as effective at manual identification of subjects discussed within resources. Diverse language relating to transgender persons can be identified using the GSSO, which can also be used for structured literature review based on subject matter thus improving research in the area.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20891,""
"Noise pollution and human cognition: An updated systematic review and meta-analysis of recent evidence","Thompson, Smith, Bou Karim, Shen, Drummond, Teng, Toledano","https://doi.org/10.1016/j.envint.2021.106905","20211102","PubMed","Cognition; Meta-analysis; Noise pollution; Systematic review","This systematic review provides a comprehensive synthesis of recent epidemiological evidence that environmental noise negatively impacts human cognition. We update a prior review with recent publications (PROSPERO CRD42019151923). The strength of evidence for associations was assessed using the GRADE (Grading of Recommendations, Assessment, Development and Evaluations) framework. We also conducted random-effects meta-analyses where suitable. 16 studies were identified and reviewed in tandem with 32 studies previously reviewed by Clark &amp; Paunovic (2018). A meta-analysis from 3 studies found that reading comprehension scores in quiet classrooms were 0.80 (95% confidence interval: 0.40; 1.20) points higher than children in noisier classrooms. Meta-analysis of the impact of 1Ã‚Â dB (dB) increase in environmental noise on reading and language abilities gave a pooled beta coefficient of -0.11(95% confidence interval: -0.32; 0.10). A meta-analysis of Odds Ratios (OR) from 3 studies found higher odds of cognitive impairment in people aged 45Ã‚Â +Ã‚Â with higher residential noise exposure (OR 1.40, 95% CI: 1.18;1.61). After qualitative synthesis of remaining studies, there was high quality evidence for an association between environmental noise and cognitive impairment in middle-to-older adults, moderate quality evidence for an association between aircraft noise and reading and language in children, and moderate quality evidence against an association between aircraft noise and executive functioning in children. Generally the literature was supportive for other cognitive outcomes, but with low or very low-quality evidence. The evidence so far suggests that noise exposure is associated with cognition, but more good quality research using standardised methodology is required to corroborate these results and to allow for precise risk estimation by larger meta-analyses. There is also a need for more research with older teenagers and young-to-middle aged adults, on the synergistic effects of noise and air pollution, and in Africa, Central and South America, South Asia and Australasia.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20892,""
"Artificial Intelligence Applications in Pediatric Brain Tumor Imaging: A Systematic Review","Huang, Shlobin, Lam, DeCuypere","https://doi.org/10.1016/j.wneu.2021.10.068","20211014","PubMed","artificial intelligence; brain tumors; imaging; pediatrics","Artificial intelligence (AI) has facilitated the analysis of medical imaging given increased computational capacity and medical data availability in recent years. Although many applications for AI in the imaging of brain tumors have been proposed, their potential clinical impact remains to be explored. A systematic review was performed to examine the role of AI in the analysis of pediatric brain tumor imaging. PubMed, Embase, and Scopus were searched for relevant articles up to January 27, 2021. Literature search identified 298 records, of which 22 studies were included. The most commonly studied tumors were posterior fossa tumors, including brainstem glioma, ependymoma, medulloblastoma, and pilocytic astrocytoma (15, 68%). Tumor diagnosis was the most frequently performed task (14, 64%), followed by tumor segmentation (3, 14%) and tumor detection (3, 14%). Of the 6 studies comparing AI to clinical experts, 5 demonstrated superiority of AI for tumor diagnosis. Other tasks, including tumor segmentation, attenuation correction of positron emission tomography scans, image registration for patient positioning, and dose calculation for radiotherapy, were performed with high accuracy comparable to clinical experts. No studies described use of the AI tool in routine clinical practice. AI methods for analysis of pediatric brain tumor imaging have increased exponentially in recent years. However, adoption of these methods in clinical practice requires further characterization of validity and utility. Implementation of these methods may streamline clinical workflows by improving diagnostic accuracy and automating basic imaging analysis tasks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20893,""
"Toxicological safety assessment of essential oils used as food supplements to establish safe oral recommended doses","Sartori Tamburlin, Roux, FeuillÃƒÂ©e, LabbÃƒÂ©, AussaguÃƒÂ¨s, El Fadle, Fraboul, Bouvier","https://doi.org/10.1016/j.fct.2021.112603","20211101","PubMed","Acceptable daily intake (ADI); Essential oil; Genotoxic carcinogens; Oral recommended dose; QSAR; Safety assessment","Essential oils (EOs) are increasingly consumed as food supplements. The few published recommended doses available generally lack details both on the methodology used and concentration limits for substances of concern, including genotoxic carcinogens. We propose a tiered approach based on the toxicological evaluation of maximized concentrations of each constituent present in the EO investigated. The genotoxic potential of each constituent is assessed using literature data or QSAR analyses. Genotoxic constituents are evaluated according to the methodology provided in the ICHM7 guideline. A Toxicological Reference Value (TRV) is associated to each non-genotoxic constituent, using one of the following methodologies (decision-tree successive steps): extraction from recognized databases or clinical studies, application of adequate safety factors to NOAELs established in animal studies, read-across analyses and when none was possible, TTC of Cramer classes. An EO recommended dose is considered safe when the safety margin (ratio between TRV and systemic exposure) for all constituents is all at least equal to 1. In conclusion, this methodology has proven to be robust to establish safe recommended doses for EOs used as food supplements, consistent with those publicly available, and avoiding unnecessary dedicated new animal testing.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20894,""
"Understanding the barriers to sustainable solid waste management in society 50 under uncertainties: a novelty of socials and technical perspectives on performance driving","Bui, Tseng","https://doi.org/10.1007/s11356-021-16962-0","20211014","PubMed","Choquet integral; Fuzzy Delphi method; Fuzzy decision-making trial and evaluation laboratory; Society 5.0 perspective; Sustainable solid waste management","This study contributes to identifying a valid and reliable set of barriers to sustainable solid waste management framework rooted in society 5.0 perspectives in Taiwan. The SSWM-related causal interrelationships within the proposed hierarchical structure, and critical barriers for the practical improvement and enhancement of SSWM performance are identified as preference enriching both literature and practices. In nature, the hierarchical structure is with the causal interrelationships under uncertainties. The perspective empowers the creation of a new biosphere based on technological progress, but in the sustainable solid waste management field, it is difficult to encounter and shape the systematized processes due to barriers and challenges. To address this shortcoming, this study evaluates the technical challenges faced in the field of sustainable solid waste management toward society 5.0. The valid attributes are usually described the qualitative information. The fuzzy Delphi method is applied to acquire the valid and reliable attributes. Fuzzy decision-making trial and evaluation laboratory experiment is to visualize the causal interrelationships among the attributes. Choquet integral with respect to the nonadditive attributes over the valid set provides an overall perspective function. The results establish an understanding of sustainable solid waste management barriers in the perspectives under uncertainties. Community uncertainty, policy and regulation problems, city architecture, and technology interaction are the factors that influence sustainable performance. In practices, (1) diverse disciplines and sectors in local, national, and global communities; (2) a lack of mobility and reliability; (3) mass production and mass consumption; (4) an insufficient level of artificial intelligence application; and (5) failures related to data management and security hinder the improvement of sustainable solid waste management toward society 5.0. The social and technical perspectives are indicated as the top priorities to improve SSWM performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20895,""
"Applications of Learning Analytics in High Schools: A Systematic Literature Review","de Sousa, Alexandre, Ferreira Mello, Pontual FalcÃƒÂ£o, Vesin, GaÃ…Â¡eviÃ„â€¡","https://doi.org/10.3389/frai.2021.737891","20211015","PubMed","high school; learning analytics; learning environments; machine learning; teaching and learning","Learning analytics aims to analyze data from students and learning environments to support learning at different levels. Although learning analytics is a recent field, it reached a high level of maturity, especially in its applications for higher education. However, little of the research in learning analytics targets other educational levels, such as high school. This paper reports the results of a systematic literature review (SLR) focused on the adoption of learning analytics in high schools. More specifically, the SLR followed four steps: the search, selection of relevant studies, critical assessment, and the extraction of the relevant field, which included the main goals, approaches, techniques, and challenges of adopting learning analytics in high school. The results show that, in this context, learning analytics applications are focused on small-scale initiatives rather than institutional adoption. Based on the findings of this study, in combination with the literature, this paper proposes future directions of research and development in order to scale up learning analytics applications in high schools.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20896,""
"Osteolysis: A Literature Review of Basic Science and Potential Computer-Based Image Processing Detection Methods","Saadi, Ranjbarzadeh, Ozeir Kazemi, Amirabadi, Ghoushchi, Kazemi, Azadikhah, Bendechache","https://doi.org/10.1155/2021/4196241","20211015","PubMed","Computers; Humans; Image Processing, Computer-Assisted; Osteolysis; Polyethylenes; Prosthesis Failure","Osteolysis is one of the most prominent reasons of revision surgeries in total joint arthroplasty. This biological phenomenon is induced by wear particles and corrosion products that stimulate inflammatory biological response of surrounding tissues. The eventual responses of osteolysis are the activation of macrophages leading to bone resorption and prosthesis failure. Various factors are involved in the initiation of osteolysis from biological issues, design, material specifications, and model of the prosthesis to the health condition of the patient. Nevertheless, the factors leading to osteolysis are sometimes preventable. Changes in implant design and polyethylene manufacturing are striving to improve overall wear. Osteolysis is clinically asymptomatic and can be diagnosed and analyzed during follow-up sessions through various imaging modalities and methods, such as serial radiographic, CT scan, MRI, and image processing-based methods, especially with the use of artificial neural network algorithms. Deep learning algorithms with a variety of neural network structures such as CNN, U-Net, and Seg-UNet have proved to be efficient algorithms for medical image processing specifically in the field of orthopedics for the detection and segmentation of tumors. These deep learning algorithms can effectively detect and analyze osteolytic lesions well in advance during follow-up sessions in order to administer proper treatments before reaching a critical point. Osteolysis can be treated surgically or nonsurgically with medications. However, revision surgeries are the only solution for the progressive osteolysis. In this literature review, the underlying causes, mechanisms, and treatments of osteolysis are discussed with the main focus on the possible computer-based methods and algorithms that can be effectively employed for the detection of osteolysis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20897,""
"The BrAID study protocol: integration of machine learning and transcriptomics for brugada syndrome recognition","Morales, Piacenti, Nesti, Solarino, Pieragnoli, Zucchelli, Del Ry, Cabiati, Vozzi","https://doi.org/10.1186/s12872-021-02280-3","20211022","PubMed","Brugada syndrome; Machine learning; RNA; Transcriptomic","Type 1 Brugada syndrome (BrS) is a hereditary arrhythmogenic disease showing peculiar electrocardiographic (ECG) patterns, characterized by ST-segment elevation in the right precordial leads, and risk of Sudden Cardiac Death (SCD). Furthermore, although various ECG patterns are described in the literature, different individual ECG may show high-grade variability, making the diagnosis problematic. The study aims to develop an innovative system for an accurate diagnosis of Type 1 BrS based on ECG pattern recognition by Machine Learning (ML) models and blood markers analysis trough transcriptomic techniques. The study is structured in 3 parts: (a) a retrospective study, with the first cohort of 300 anonymized ECG obtained in already diagnosed Type 1 BrS (75 spontaneous, 150 suspected) and 75 from control patients, which will be processed by ML analysis for pattern recognition; (b) a prospective study, with a cohort of 11 patients with spontaneous Type 1 BrS, 11 with drug-induced Type 1 BrS, 11 suspected BrS but negative to NaÃ¢â‚¬â€°+Ã¢â‚¬â€°channel blockers administration, and 11 controls, enrolled for ECG ML analysis and blood collection for transcriptomics and microvesicles analysis; (c) a validation study, with the third cohort of 100 patients (35 spontaneous and 35 drug-induced BrS, 30 controls) for ML algorithm and biomarkers testing. The BrAID system will help clinicians improve the diagnosis of Type 1 BrS by using multiple information, reducing the time between ECG recording and final diagnosis, integrating clinical, biochemical and ECG information thus favoring a more effective use of available resources. Trial registration Clinical Trial.gov, NCT04641585. Registered 17 November 2020, https://clinicaltrials.gov/ct2/show/NCT04641585.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20898,""
"Artificial intelligence forecasting mortality at an intensive care unit and comparison to a logistic regression system","Nistal-NuÃƒÂ±o","https://doi.org/10.31744/einstein_journal/2021AO6283","20211015","PubMed","Adult; Artificial Intelligence; Hospital Mortality; Humans; Intensive Care Units; Logistic Models; Machine Learning; ROC Curve","To explore an artificial intelligence approach based on gradient-boosted decision trees for prediction of all-cause mortality at an intensive care unit, comparing its performance to a recent logistic regression system in the literature, and a logistic regression model built on the same platform. A gradient-boosted decision trees model and a logistic regression model were trained and tested with the Medical Information Mart for Intensive Care database. The 1-hour resolution physiological measurements of adult patients, collected during 5 hours in the intensive care unit, consisted of eight routine clinical parameters. The study addressed how the models learn to categorize patients to predict intensive care unit mortality or survival within 12 hours. The performance was evaluated with accuracy statistics and the area under the Receiver Operating Characteristic curve. The gradient-boosted trees yielded an area under the Receiver Operating Characteristic curve of 0.89, compared to 0.806 for the logistic regression. The accuracy was 0.814 for the gradient-boosted trees, compared to 0.782 for the logistic regression. The diagnostic odds ratio was 17.823 for the gradient-boosted trees, compared to 9.254 for the logistic regression. The Cohen's kappa, F-measure, Matthews correlation coefficient, and markedness were higher for the gradient-boosted trees. The discriminatory power of the gradient-boosted trees was excellent. The gradient-boosted trees outperformed the logistic regression regarding intensive care unit mortality prediction. The high diagnostic odds ratio and markedness values for the gradient-boosted trees are important in the context of the studied unbalanced dataset.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20899,""
"Intelligent assistive technology devices for persons with dementia: A scoping review","Dada, Walt, May, Murray","https://doi.org/10.1080/10400435.2021.1992540","20211013","PubMed","Augmentative and alternative communication; assistive devices; assistive technology; communication; dementia; intelligent technology","Assistive technology (AT) with context-aware computing and artificial intelligence capabilities can be applied to address cognitive and communication impairments experienced by persons with dementia (PwD). This paper aims to provide an overview of current literature regarding some characteristics of intelligent assistive technology devices (IATDs) for cognitive and communicative impairments of PwD. It also aims to identify the areas of impairment addressed by these IATDs.A multi-faceted systematic search strategy yielded records. Predefined criteria were applied for inclusion and data extraction. Thereafter data was thematically analysed and synthesised. This review demonstrates that almost all of the research involving IATDs has focused on cognitive impairments of PwD and has not yet evolved past the conceptual or prototype stages of development. Summaries of commercially available IATDs for PwD and relevant prototypes are provided at the end of this review.This research concluded that IATDs for PwD targeting cognition and communication problems primarily focus on social robots, and that they address cognitive impairments of attention, affect, and social-pragmatic communicative impairments. Future research endeavours concerning AT for PwD should explore collaboration between computer engineering and health practitioners to address the identified gaps. This may contribute to the available information for evidence-based decision making for PwD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20900,""
"Pediatric Cranial Defects: What Size Warrants Repair?","Lane, Black","https://doi.org/10.1097/SCS.0000000000008284","20211015","PubMed","","Identifying which cranial defects among children warrant surgical repair is integral to providing adequate protection of the skull whereas minimizing exposure to surgical complications. This review examines the available evidence regarding the role of defect size in determining the appropriateness of nonsurgical versus surgical management. An electronic literature review was performed using PubMed and Google Scholar to identify publications that provided rationales for nonsurgical management of cranial defects in the pediatric population based on size. Titles and abstracts were reviewed by the authors to determine eligibility for full-text analysis. Ineligible studies were categorized and relevant data from fully analyzed texts were recorded. Of the 523 articles that were reviewed, 500 were ineligible for full-text analysis due to the following most common reasons: no cranial defect described (227, 45%), did not discuss management of cranial defects (68, 14%), or surgery was performed on all defects in evaluation of a technique or protocol (86, 17%). Ten publications provided relevant data. The suggested size below which surgery was not recommended varied widely between articles. Beyond the age of 1 to 2 years, no general agreement on recommended management in children was found. Craniofacial surgeons had divergent views on the minimum diameter for a ""critical"" defect and the size for which surgical repair is necessary. Little guidance or consensus exists regarding the indications for surgical correction of cranial defects based on the size of the defect. Objective data is needed to classify ""clinically critical defects"" in the pediatric population.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20901,""
"Building a Shared, Scalable, and Sustainable Source for the Problem-Oriented Medical Record: Developmental Study","Gaudet-Blavignac, Rudaz, Lovis","https://doi.org/10.2196/29174","20211014","PubMed","electronic health records; medical records; problem-oriented; semantics","Since the creation of the problem-oriented medical record, the building of problem lists has been the focus of many studies. To date, this issue is not well resolved, and building an appropriate contextualized problem list is still a challenge. This paper aims to present the process of building a shared multipurpose common problem list at the Geneva University Hospitals. This list aims to bridge the gap between clinicians' language expressed in free text and secondary uses requiring structured information. We focused on the needs of clinicians by building a list of uniquely identified expressions to support their daily activities. In the second stage, these expressions were connected to additional information to build a complex graph of information. A list of 45,946 expressions manually extracted from clinical documents was manually curated and encoded in multiple semantic dimensions, such as International Classification of Diseases, 10th revision; International Classification of Primary Care 2nd edition; Systematized Nomenclature of Medicine Clinical Terms; or dimensions dictated by specific usages, such as identifying expressions specific to a domain, a gender, or an intervention. The list was progressively deployed for clinicians with an iterative process of quality control, maintenance, and improvements, including the addition of new expressions or dimensions for specific needs. The problem management of the electronic health record allowed the measurement and correction of encoding based on real-world use. The list was deployed in production in January 2017 and was regularly updated and deployed in new divisions of the hospital. Over 4 years, 684,102 problems were created using the list. The proportion of free-text entries decreased progressively from 37.47% (8321/22,206) in December 2017 to 18.38% (4547/24,738) in December 2020. In the last version of the list, over 14 dimensions were mapped to expressions, among which 5 were international classifications and 8 were other classifications for specific uses. The list became a central axis in the electronic health record, being used for many different purposes linked to care, such as surgical planning or emergency wards, or in research, for various predictions using machine learning techniques. This study breaks with common approaches primarily by focusing on real clinicians' language when expressing patients' problems and secondarily by mapping whatever is required, including controlled vocabularies to answer specific needs. This approach improves the quality of the expression of patients' problems while allowing the building of as many structured dimensions as needed to convey semantics according to specific contexts. The method is shown to be scalable, sustainable, and efficient at hiding the complexity of semantics or the burden of constraint-structured problem list entry for clinicians. Ongoing work is analyzing the impact of this approach on how clinicians express patients' problems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20902,""
"Patient's perception of timing concepts in implant dentistry: A systematic review","Gotfredsen, Hosseini, Rimborg, Ãƒâ€“zhayat","https://doi.org/10.1111/clr.13861","20211014","PubMed","immediate loading; immediate placement; patient-reported outcome measures; Dental Implants; Dental Prosthesis, Implant-Supported; Esthetics, Dental; Humans; Immediate Dental Implant Loading; Perception; Prospective Studies","Protocols for implant dentistry, most frequently include periods until healing of the extraction sockets and osseointegration of the implant. Deductional thinking imply that patients would prefer if treatment time in implant dentistry were reduced. What is the patient perception of immediate or early implant placement or loading in comparison with traditional, delayed placement, and/or loading assessed by patient-reported outcome measures, as evidenced in randomized controlled clinical trials or prospective controlled studies? A systematic review was performed following the PRISMA guidelines with a literature search up to June 30. All hits were imported into Rayyan online software and analyzed by two authors for eligibility. Cochrane RoB2.0 and Newcastle-Ottawa Scale were used to evaluate risk of bias in the individual studies. Of the initially 1439 articles, 76 underwent full-text analysis and finally 40 articles, representing 35 cohort studies, were included. The quality evaluation demonstrated some concerns among most of the studies. a) There is no strong evidence to support that the time for implant placement or loading of implant-supported single or short-span reconstructions or overdentures influence patientsÃ‚Â´ discomfort, satisfaction with function or esthetics or overall satisfaction with the implant treatment. b) There is some evidence that studies including edentulous patients rehabilitated with implant-supported full-arch FDPs demonstrate more satisfied patients with immediate than for the early or delayed loaded implant reconstructions after short time, but the difference is not clear oneÃ‚Â year after treatment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20903,""
"Penetrance of male breast cancer susceptibility genes: a systematic review","Chamseddine, Wang, Yin, Wang, Singh, Zhou, Robson, Braun, Hughes","https://doi.org/10.1007/s10549-021-06413-2","20211013","PubMed","Cancer susceptibility gene; Genetics; Male breast cancer; Penetrance","Several male breast cancer (MBC) susceptibility genes have been identified, but the MBC risk for individuals with a pathogenic variant in each of these genes (i.e., penetrance) remains unclear. We conducted a systematic review of studies reporting the penetrance of MBC susceptibility genes to better summarize current estimates of penetrance. A search query was developed to identify MBC-related papers indexed in PubMed/MEDLINE. A validated natural language processing method was applied to identify papers reporting penetrance estimates. These penetrance studies' bibliographies were reviewed to ensure comprehensiveness. We accessed the potential ascertainment bias for each enrolled study. Fifteen penetrance studies were identified from 12,182 abstracts, covering five purported MBC susceptibility genes: ATM, BRCA1, BRCA2, CHEK2, and PALB2. Cohort (nÃ¢â‚¬â€°=Ã¢â‚¬â€°6, 40%) and case-control (nÃ¢â‚¬â€°=Ã¢â‚¬â€°5, 33%) studies were the two most common study designs, followed by family-based (nÃ¢â‚¬â€°=Ã¢â‚¬â€°3, 20%), and a kin-cohort study (nÃ¢â‚¬â€°=Ã¢â‚¬â€°1, 7%). Seven of the 15 studies (47%) adjusted for ascertainment adequately and therefore the MBC risks reported by these seven studies can be considered applicable to the general population. Based on these seven studies, we found pathogenic variants in ATM, BRCA2, CHEK2 c.1100delC, and PALB2 show an increased risk for MBC. The association between BRCA1 and MBC was not statistically significant. This work supports the conclusion that pathogenic variants in ATM, BRCA2, CHEK2 c.1100delC, and PALB2 increase the risk of MBC, whereas pathogenic variants in BRCA1 may not be associated with increased MBC risk.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20904,""
"Evaluation framework to guide implementation of AI systems into healthcare settings","Reddy, Rogers, Makinen, Coiera, Brown, Wenzel, Weicken, Ansari, Mathur, Casey, Kelly","https://doi.org/10.1136/bmjhci-2021-100444","20211028","PubMed","artificial intelligence; data science; health services research; informatics; machine learning","To date, many artificial intelligence (AI) systems have been developed in healthcare, but adoption has been limited. This may be due to inappropriate or incomplete evaluation and a lack of internationally recognised AI standards on evaluation. To have confidence in the generalisability of AI systems in healthcare and to enable their integration into workflows, there is a need for a practical yet comprehensive instrument to assess the translational aspects of the available AI systems. Currently available evaluation frameworks for AI in healthcare focus on the reporting and regulatory aspects but have little guidance regarding assessment of the translational aspects of the AI systems like the functional, utility and ethical components. To address this gap and create a framework that assesses real-world systems, an international team has developed a translationally focused evaluation framework termed 'Translational Evaluation of Healthcare AI (TEHAI)'. A critical review of literature assessed existing evaluation and reporting frameworks and gaps. Next, using health technology evaluation and translational principles, reporting components were identified for consideration. These were independently reviewed for consensus inclusion in a final framework by an international panel of eight expert. TEHAI includes three main components: capability, utility and adoption. The emphasis on translational and ethical features of the model development and deployment distinguishes TEHAI from other evaluation instruments. In specific, the evaluation components can be applied at any stage of the development and deployment of the AI system. One major limitation of existing reporting or evaluation frameworks is their narrow focus. TEHAI, because of its strong foundation in translation research models and an emphasis on safety, translational value and generalisability, not only has a theoretical basis but also practical application to assessing real-world systems. The translational research theoretic approach used to develop TEHAI should see it having application not just for evaluation of clinical AI in research settings, but more broadly to guide evaluation of working clinical systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20905,""
"In Vitro Degradation and Cytotoxicity of Eggshell-Based Hydroxyapatite: A Systematic Review and Meta-Analysis","Rohmadi, Harwijayanti, Ubaidillah, Triyono, Diharjo, Utomo","https://doi.org/10.3390/polym13193223","20211016","PubMed","cytotoxicity; degradation; eggshells; hydroxyapatite; meta-analysis","This review focuses on the in vitro degradation of eggshell-based hydroxyapatite for analyzing the weight loss of hydroxyapatite when applied in the human body. Cytotoxicity tests were used to observe cell growth and morphological effects. A systematic review and meta-analysis were conducted to observe the weight loss and viable cells of hydroxyapatite when used for implants. Based on the Population, Intervention, Comparison, and Outcome (PICO) strategy, the articles used for literature review were published in English on SCOPUS, PubMed, and Google Scholar from 1 January 2012 to 22 May 2021. Data regarding existing experiments in the literature articles the in vitro degradation and cytotoxicity testing of eggshell-based hydroxyapatite determined the biocompatibility of the materials. A meta-analysis was conducted to calculate the mean difference between the solutions and soaking times used for degradation and the stem cells used for cytotoxicity. From 231 relevant studies, 71 were chosen for full-text analysis, out of which 33 articles met the inclusion criteria for degradation and cytotoxicity analysis. A manual search of the field of study resulted in three additional articles. Thus, 36 articles were included in this systematic review. The aim of this study was to highlight the importance of the biocompatibility of eggshell-based hydroxyapatite. The weight loss and viability cells of eggshell-based hydroxyapatite showed optimum results for viable cells requirements above 70%, and there is a weight loss of eggshell-based hydroxyapatite for a material implant. The meta-analysis indicated significant differences in the weight loss of eggshell-based hydroxyapatite materials with different soaking times and solutions used. The various kinds of stem cells for incubation of cultured cells in contact with a device, either directly or through diffusions with various kinds of stem cells from animals and humans, yielded viability cells above 70%.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20906,""
"The Use and Performance of Artificial Intelligence in Prosthodontics: A Systematic Review","Bernauer, Zitzmann, Joda","https://doi.org/10.3390/s21196628","20211014","PubMed","artificial intelligence; deep learning; machine learning; neural networks; prosthetic treatment; reconstructive dentistry; Artificial Intelligence; Delivery of Health Care; Humans; Prosthodontics","(1) Background: The rapid pace of digital development in everyday life is also reflected in dentistry, including the emergence of the first systems based on artificial intelligence (AI). This systematic review focused on the recent scientific literature and provides an overview of the application of AI in the dental discipline of prosthodontics. (2) Method: According to a modified PICO-strategy, an electronic (MEDLINE, EMBASE, CENTRAL) and manual search up to 30 June 2021 was carried out for the literature published in the last five years reporting the use of AI in the field of prosthodontics. (3) Results: 560 titles were screened, of which 30 abstracts and 16 full texts were selected for further review. Seven studies met the inclusion criteria and were analyzed. Most of the identified studies reported the training and application of an AI system (<i>n</i> = 6) or explored the function of an intrinsic AI system in a CAD software (<i>n</i> = 1). (4) Conclusions: While the number of included studies reporting the use of AI was relatively low, the summary of the obtained findings by the included studies represents the latest AI developments in prosthodontics demonstrating its application for automated diagnostics, as a predictive measure, and as a classification or identification tool. In the future, AI technologies will likely be used for collecting, processing, and organizing patient-related datasets to provide patient-centered, individualized dental treatment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20907,""
"Recruitment in Health Services Research-A Study on Facilitators and Barriers for the Recruitment of Community-Based Healthcare Providers","Krebs, Lorenz, Nawabi, LÃƒÂ¼ck, Bau, Alayli, Stock","https://doi.org/10.3390/ijerph181910521","20211025","PubMed","community-based healthcare providers; health services research; recruitment; Community Health Services; Health Personnel; Health Services Research; Humans; Motivation; Qualitative Research","In health services research, the recruitment of patients is oftentimes conducted by community-based healthcare providers. Therefore, the recruitment of these healthcare providers is a crucial prerequisite for successful patient recruitment. However, recruiting community-based healthcare providers poses a major challenge and little is known about its influencing factors. This qualitative study is conducted alongside a health services research intervention trial. The aim of the study is to investigate facilitators and barriers for the recruitment of community-based healthcare providers. A qualitative text analysis of documents and semi-structured interviews with recruiting staff is performed. An inductive-deductive category-based approach is used. Our findings identify intrinsic motivation and interest in the trial's aims and goals as important facilitating factors in healthcare provider recruitment. Beyond that, extrinsic motivation generated through financial incentives or collegial obligation emerged as a conflicting strategy. While extrinsic motivation might aid in the initial enrollment of healthcare providers, it rarely resulted in active trial participation in the long run. Therefore, extrinsic motivational factors should be handled with care when recruiting healthcare providers for health services research intervention trials.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20908,""
"Etiologies of Melanoma Development and Prevention Measures: A Review of the Current Evidence","Djavid, Stonesifer, Fullerton, Wang, Tartaro, Kwinta, Grimes, Geskin, Saenger","https://doi.org/10.3390/cancers13194914","20211016","PubMed","UV; artificial intelligence; melanoma; prevention; screening; sun safety; sunscreen; tanning","(1) Melanoma is the most aggressive dermatologic malignancy, with an estimated 106,110 new cases to be diagnosed in 2021. The annual incidence rates continue to climb, which underscores the critical importance of improving the methods to prevent this disease. The interventions to assist with melanoma prevention vary and typically include measures such as UV avoidance and the use of protective clothing, sunscreen, and other chemopreventive agents. However, the evidence is mixed surrounding the use of these and other interventions. This review discusses the heritable etiologies underlying melanoma development before delving into the data surrounding the preventive methods highlighted above. (2) A comprehensive literature review was performed to identify the clinical trials, observational studies, and meta-analyses pertinent to melanoma prevention and incidence. Online resources were queried to identify epidemiologic and clinical trial information. (3) Evidence exists to support population-wide screening programs, the proper use of sunscreen, and community-targeted measures in the prevention of melanoma. Clinical evidence for the majority of the proposed preventive chemotherapeutics is presently minimal but continues to evolve. (4) Further study of these chemotherapeutics, as well as improvement of techniques in artificial intelligence and imaging techniques for melanoma screening, is warranted for continued improvement of melanoma prevention.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20909,""
"Improving classification of low-resource COVID-19 literature by using Named Entity Recognition","Lithgow-Serrano, Cornelius, Kanjirangat, MÃƒÂ©ndez-Cruz, Rinaldi","https://doi.org/10.5808/gi.21018","20211023","PubMed","COVID-19; NLP; Named Entity Recognition; classification","Automatic document classification for highly interrelated classes is a demanding task that becomes more challenging when there is little labeled data for training. Such is the case of the coronavirus disease 2019 (COVID-19) Clinical repository-a repository of classified and translated academic articles related to COVID-19 and relevant to the clinical practice-where a 3-way classification scheme is being applied to COVID-19 literature. During the 7th Biomedical Linked Annotation Hackathon (BLAH7) hackathon, we performed experiments to explore the use of named-entity-recognition (NER) to improve the classification. We processed the literature with OntoGene's Biomedical Entity Recogniser (OGER) and used the resulting identified Named Entities (NE) and their links to major biological databases as extra input features for the classifier. We compared the results with a baseline model without the OGER extracted features. In these proof-of-concept experiments, we observed a clear gain on COVID-19 literature classification. In particular, NE's origin was useful to classify document types and NE's type for clinical specialties. Due to the limitations of the small dataset, we can only conclude that our results suggests that NER would benefit this classification task. In order to accurately estimate this benefit, further experiments with a larger dataset would be needed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20910,""
"Acupoint stimulation for cancer-related fatigue: A quantitative synthesis of randomised controlled trials","Tan, Wang, Kirshbaum, Zhao, Eliseeva, Polotan, Yao, Huang, Zheng","https://doi.org/10.1016/j.ctcp.2021.101490","20211101","PubMed","Acupressure; Acupuncture; Cancer; Evidence synthesis; Fatigue; Randomised controlled trials; Acupuncture; Acupuncture Points; Acupuncture Therapy; Fatigue; Humans; Neoplasms; Randomized Controlled Trials as Topic","This study aimed to identify the research evidence on acupoint stimulation (AS) for cancer-related fatigue (CRF) management. Randomised controlled trials that utilised AS for CRF management were retrieved. The Cochrane Back Review Group Risk of Bias Tool was used for quality appraisal. RevMan 5.3 was used for meta-analysis. Fifteen studies were included. Both the overall (SMDÃ‚Â =Ã‚Â -0.95, pÃ‚Â =Ã‚Â 0.008) and sub-group (acupuncture: SMDÃ‚Â =Ã‚Â -1.25, pÃ‚Â =Ã‚Â 0.002; short-term AS: SMDÃ‚Â =Ã‚Â -0.95, pÃ‚Â =Ã‚Â 0.02; medium-term AS: SMDÃ‚Â =Ã‚Â -0.96, pÃ‚Â =Ã‚Â 0.003) analyses indicated that AS was more effective in alleviating CRF than standard treatment/care. A comparison between the true and sham AS interventions favoured the true AS for CRF management, although the difference did not reach statistical significance. This study identified a promising role of AS in improving CRF. However, the study findings should be interpreted prudently due to the limited quality and sample sizes of some of the included studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20911,""
"The psychometric properties of the Bidimensional Acculturation Scale for Marriage-Based Immigrant Women in Taiwan","Chen, Lai, Chien","https://doi.org/10.1371/journal.pone.0258323","20211015","PubMed","","Marriage-based immigrant women are increasing around the world. Although bi-dimensional acculturation is important for immigrant women's health, the existing scales have mainly been developed for immigrant women in Western countries and hence some items may not be suitable for Asian contexts. Thus, we developed and evaluated the Bidimensional Acculturation Scale for Marriage-Based Immigrant Women (BAS-MBIW) in Taiwan. The BAS-MBIW was developed based on a literature review and clinical observations. Bi-dimensional acculturation involves ""adaptation to host culture (acculturation)"" and ""maintenance of heritage culture (enculturation)."" The initial scale included two 24-item subscales. The validation samples were 310 marriage-based immigrant women who were pregnant for at least twelve weeks in Taiwan. The BAS-MBIW was assessed and modified by experts. Data analyses included factor analysis, Pearson's correlation, and Cronbach's alpha coefficient. Expert reviews and factor analysis indicated that the scale had acceptable content and construct validity. The validated scale includes two 19-item subscales, encompassing six domains: language, media, food preference, cultural heritage, social interaction, and shopping and merchandise preference, with good internal consistencies (Cronbach's alpha coefficient is 0.88 for acculturation and 0.83 for enculturation). Acculturation was positively related to local language ability and duration of immigration but negatively related to age at immigration, stress, and depression; whereas enculturation was positively related to age at immigration, stress, and depression but negatively related to duration of immigration, indicating convergent validity. The BAS-MBIW offers reliable and valid assessments of pregnant immigrant women's level of acculturation and enculturation in Taiwan. The BAS-MBIW could be used to assess bi-dimensional acculturation among marriage-based immigrant women.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20912,""
"Rolling Circle Amplification in Integrated Microsystems: An Uncut Gem toward Massively Multiplexed Pathogen Diagnostics and Genotyping","Soares, Madaboosi, Nilsson","https://doi.org/10.1021/acs.accounts.1c00438","20211102","PubMed","","ConspectusThe development of robust methods allowing the precise detection of specific nucleic acid sequences is of major societal relevance, paving the way for significant advances in biotechnology and biomedical engineering. These range from a better understanding of human disease at a molecular level, allowing the discovery and development of novel biopharmaceuticals and vaccines, to the improvement of biotechnological processes providing improved food quality and safety, efficient green fuels, and smart textiles. Among these applications, the significance of pathogen diagnostics as the main focus of this Account has become particularly clear during the recent SARS-CoV-2 pandemic. In this context, while RT-PCR is the gold standard method for unambiguous detection of genetic material from pathogens, other isothermal amplification alternatives circumventing rapid heating-cooling cycles up to Ã¢Ë†Â¼95 Ã‚Â°C are appealing to facilitate the translation of the assay into point-of-care (PoC) analytical platforms. Furthermore, the possibility of routinely multiplexing the detection of tens to hundreds of target sequences with single base pair specificity, currently not met by state-of-the-art methods available in clinical laboratories, would be instrumental along the path to tackle emergent viral variants and antimicrobial resistance genes. Here, we advocate that padlock probes (PLPs), first reported by Nilsson et al. in 1994, coupled with rolling circle amplification (RCA), termed here as PLP-RCA, is an underexploited technology in current arena of isothermal nucleic acid amplification tests (NAATs) providing an unprecedented degree of multiplexing, specificity, versatility, and amenability to integration in miniaturized PoC platforms. Furthermore, the intrinsically digital amplification of PLP-RCA retains spatial information and opens new avenues in the exploration of pathogenesis with spatial multiomics analysis of infected cells and tissue.The Account starts by introducing PLP-RCA in a nutshell focusing individually on the three main assay steps, namely, (1) PLP design and ligation mechanism, (2) RCA after probe ligation, and (3) detection of the RCA products. Each subject is touched upon succinctly but with sufficient detail for the reader to appreciate some assay intricacies and degree of versatility depending on the analytical challenge at hand. After familiarizing the reader with the method, we discuss specific examples of research in our group and others using PLP-RCA for viral, bacterial, and fungal diagnostics in a variety of clinical contexts, including the genotyping of antibiotic resistance genes and viral subtyping. Then, we dissect key developments in the miniaturization and integration of PLP-RCA to minimize user input, maximize analysis throughput, and expedite the time to results, ultimately aiming at PoC applications. These developments include molecular enrichment for maximum sensitivity, spatial arrays to maximize analytical throughput, automation of liquid handling to streamline the analytical workflow in miniaturized devices, and seamless integration of signal transduction to translate RCA product titers (and ideally spatial information) into a readable output. Finally, we position PLP-RCA in the current landscape of NAATs and furnish a systematic Strengths, Weaknesses, Opportunities and Threats analysis to shine light upon unpolished edges to uncover the gem with potential for ubiquitous, precise, and unbiased pathogen diagnostics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20913,""
"A Proposed Framework for Machine Learning-Aided Triage in Public Specialty Ophthalmology Clinics in Hong Kong","Li, Vardhanabhuti, Tsougenis, Lam, Shih","https://doi.org/10.1007/s40123-021-00405-7","20211015","PubMed","Machine learning; Ophthalmic specialty clinics; Public health care system; Triage","The public specialty ophthalmic clinics in Hong Kong, under the Hospital Authority, receive tens of thousands of referrals each year. Triaging these referrals incurs a significant workload for practitioners and the other clinical duties. It is well-established that Hong Kong is currently facing a shortage of healthcare workers. Thus a more efficient system in triaging willÃ‚Â not only free up resources for better use but also improve the satisfaction of both practitioners and patients. Machine learning (ML) has been shown to improve the efficiency of various medical workflows, including triaging, by both reducing the workload and increasing accuracy in some cases. Despite a myriad of studies on medical artificial intelligence, there is no specific framework for a triaging algorithm in ophthalmology clinics. This study proposes a general framework for developing, deploying and evaluating an ML-based triaging algorithm in a clinical setting. Through literature review, this study identifies good practices in various facets of developing such a network and protocols for maintenance and evaluation of the impact concerning clinical utility and external validity out of the laboratory. We hope this framework, albeit not exhaustive, can act as a foundation to accelerate future pilot studies and deployments.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20914,""
"Machine learning principles applied to CT radiomics to predict mucinous pancreatic cysts","Awe, Vanden Heuvel, Yuan, Rendell, Shen, Kampani, Liang, Morgan, Winslow, Lubner","https://doi.org/10.1007/s00261-021-03289-0","20211012","PubMed","Machine learning; Mucinous phenotype; Pancreatic cyst; Radiomics; Texture features","Current diagnostic and treatment modalities for pancreatic cysts (PCs) are invasive and are associated with patient morbidity. The purpose of this study is to develop and evaluate machine learning algorithms to delineate mucinous from non-mucinous PCs using non-invasive CT-based radiomics. A retrospective, single-institution analysis of patients with non-pseudocystic PCs, contrast-enhanced computed tomography scans within 1Ã‚Â year of resection, and available surgical pathology were included. A quantitative imaging software platform was used to extract radiomics. An extreme gradient boosting (XGBoost) machine learning algorithm was used to create mucinous classifiers using texture features only, or radiomic/radiologic and clinical combined models. Classifiers were compared using performance scoring metrics. Shapely additive explanation (SHAP) analyses were conducted to identify variables most important in model construction. Overall, 99 patients and 103 PCs were included in the analyses. Eighty (78%) patients had mucinous PCs on surgical pathology. Using multiple fivefold cross validations, the texture features only and combined XGBoost mucinous classifiers demonstrated an area under the curve of 0.72Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°0.14 and 0.73Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°0.14, respectively. By SHAP analysis, root mean square, mean attenuation, and kurtosis were the most predictive features in the texture features only model. Root mean square, cyst location, and mean attenuation were the most predictive features in the combined model. Machine learning principles can be applied to PC texture features to create a mucinous phenotype classifier. Model performance did not improve with the combined model. However, specific radiomic, radiologic, and clinical features most predictive in our models can be identified using SHAP analysis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20915,""
"An Automated Line-of-Therapy Algorithm for Adults With Metastatic Non-Small Cell Lung Cancer: Validation Study Using Blinded Manual Chart Review","Meng, Mosesso, Lane, Roberts, Griffith, Ou, Dexter","https://doi.org/10.2196/29017","20211013","PubMed","automated algorithm; line of therapy; longitudinal changes; manual chart review; nonÃ¢â‚¬â€œsmall cell lung cancer; systemic anticancer therapy","Extraction of line-of-therapy (LOT) information from electronic health record and claims data is essential for determining longitudinal changes in systemic anticancer therapy in real-world clinical settings. The aim of this retrospective cohort analysis is to validate and refine our previously described open-source LOT algorithm by comparing the output of the algorithm with results obtained through blinded manual chart review. We used structured electronic health record data and clinical documents to identify 500 adult patients treated for metastatic non-small cell lung cancer with systemic anticancer therapy from 2011 to mid-2018; we assigned patients to training (n=350) and test (n=150) cohorts, randomly divided proportional to the overall ratio of simple:complex cases (n=254:246). Simple cases were patients who received one LOT and no maintenance therapy; complex cases were patients who received more than one LOT and/or maintenance therapy. Algorithmic changes were performed using the training cohort data, after which the refined algorithm was evaluated against the test cohort. For simple cases, 16 instances of discordance between the LOT algorithm and chart review prerefinement were reduced to 8 instances postrefinement; in the test cohort, there was no discordance between algorithm and chart review. For complex cases, algorithm refinement reduced the discordance from 68 to 62 instances, with 37 instances in the test cohort. The percentage agreement between LOT algorithm output and chart review for patients who received one LOT was 89% prerefinement, 93% postrefinement, and 93% for the test cohort, whereas the likelihood of precise matching between algorithm output and chart review decreased with an increasing number of unique regimens. Several areas of discordance that arose from differing definitions of LOTs and maintenance therapy could not be objectively resolved because of a lack of precise definitions in the medical literature. Our findings identify common sources of discordance between the LOT algorithm and clinician documentation, providing the possibility of targeted algorithm refinement.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20916,""
"Comparison of one-phase and two-phase extraction methods for porcine tissue lipidomics applying a fast and reliable tentative annotation workflow","BÃƒÂ¶gl, Mlynek, Himmelsbach, Buchberger","https://doi.org/10.1016/j.talanta.2021.122849","20211013","PubMed","Ion mobility; Mass spectrometry; One-phase extraction; Tissue extraction; Two-phase extraction; Untargeted lipidomics; Animals; Lipidomics; Lipids; Mass Spectrometry; Solvents; Swine; Workflow","Lipidomics has great potential for the discovery of biomarkers, elucidation of metabolic processes and identifying dysregulations in complex biological systems. Concerning biofluids like plasma or cerebrospinal fluid, several studies for the comparison of lipid extraction solvents have already been conducted. With respect to tissues, which can differ significantly in terms of dry matter content and composition, only few studies are available. The proper selection of an extraction method that covers the complexity and individuality of different tissues is challenging. The goal of this work was to provide a systematic overview on the potential of different extraction methods for a broad applicability. This study covers six different extraction procedures and four different reconstitution solvents applied to ten different porcine tissues. To get an overview of the individual lipid profiles, a workflow was developed for a fast and reliable tentative lipid annotation. Therefore, several machine learning tools were utilized, like the prediction of collision cross sections to support the tentative lipid identification in case of untargeted lipidomics. In terms of data evaluation, unsupervised (e.g. principal component analysis) and supervised (e.g. partial least square - discriminant analysis) methods were applied to visualize and subsequently interpret all generated information. Furthermore, the influence of the tissue composition on the extraction performance was investigated. It could be shown that the ten porcine tissues can be distinguished based on their lipid profile with the applied workflow and that the methyl-tert-butyl ether (MTBE) based extraction method (two-phase) showed the best overall performance for the 16 examined lipid species. With this method the highest number of features (428 in lung tissue) could be annotated. Upcoming one-phase extractions also showed a high potential concerning total number of extracted lipids. Methanol/MTBE/chloroform (MMC) extracted slightly less lipids (393 in lung and liver) than MTBE but turned out to be the best one-phase extraction method. Additionally, the numbers of extracted lipids obtained by isopropanol/water 90:10 (IPA90) (399 in stomach) and by isopropanol/methanol/chloroform (IMC) (395 in stomach) were similar to those of the modified Folch method (402 in stomach). One-phase extractions can therefore clearly be seen as preferable when a high throughput is needed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20917,""
"Digital Strategies to Improve Food Assistance in Disasters: A Scoping Review","Martin, Sundermeir, Barnett, van Dongen, Rosman, Rosenblum, Gittelsohn","https://doi.org/10.1017/dmp.2021.281","20211011","PubMed","digital applications; digital technology; disasters; food assistance; food security","Modern digital strategies, including Internet of Things, machine learning, and mobile applications, have revolutionized situational awareness during disaster management. Despite their importance, no review of digital strategies to support emergency food security efforts has been conducted. This scoping review fills that gap. Keywords were defined within the concepts of food assistance, digital technology, and disasters. After the database searches, PRISMA guidelines were followed to perform a partnered, 2-round scoping literature review. The search identified 3201 articles, and 26 articles met criteria and were included in the analysis. The data types used to describe the tools were text/opinion (42.3%), qualitative (23.1%), system architecture (19.2%), quantitative and qualitative (11.5 %), and quantitative (3.8%). The tools' main functions were Resource Allocation (41.7%), Data Collection and Management (33%), Interagency Communications (15.4 %), Beneficiary Communications (11.5%), and Fundraising (7.7%). The platforms used to achieve these goals were Mobile Application (36%), Internet of Things (20%), Website (20%), and Mobile Survey (8%); 92% covered the disaster response phase. Digital tools for planning, situational awareness, client choice, and recovery are needed to support emergency food assistance, but there is a lack of these tools and research on their effectiveness across all disaster phases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20918,""
"OnTheFly<sup>20</sup>: a text-mining web application for automated biomedical entity recognition, document annotation, network and functional enrichment analysis","Baltoumas, Zafeiropoulou, Karatzas, Paragkamian, Thanati, Iliopoulos, Eliopoulos, Schneider, Jensen, Pafilis, Pavlopoulos","https://doi.org/10.1093/nargab/lqab090","20211012","PubMed","","Extracting and processing information from documents is of great importance as lots of experimental results and findings are stored in local files. Therefore, extracting and analyzing biomedical terms from such files in an automated way is absolutely necessary. In this article, we present OnTheFly<sup>2.0</sup>, a web application for extracting biomedical entities from individual files such as plain texts, office documents, PDF files or images. OnTheFly<sup>2.0</sup> can generate informative summaries in popup windows containing knowledge related to the identified terms along with links to various databases. It uses the EXTRACT tagging service to perform named entity recognition (NER) for genes/proteins, chemical compounds, organisms, tissues, environments, diseases, phenotypes and gene ontology terms. Multiple files can be analyzed, whereas identified terms such as proteins or genes can be explored through functional enrichment analysis or be associated with diseases and PubMed entries. Finally, protein-protein and protein-chemical networks can be generated with the use of STRING and STITCH services. To demonstrate its capacity for knowledge discovery, we interrogated published meta-analyses of clinical biomarkers of severe COVID-19 and uncovered inflammatory and senescence pathways that impact disease pathogenesis. OnTheFly<sup>2.0</sup> currently supports 197 species and is available at http://bib.fleming.gr:3838/OnTheFly/ and http://onthefly.pavlopouloslab.info.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20919,""
"New Imaging Signatures of Cardiac Alterations in Ischaemic Heart Disease and Cerebrovascular Disease Using CMR Radiomics","Rauseo, Izquierdo Morcillo, Raisi-Estabragh, Gkontra, Aung, Lekadir, Petersen","https://doi.org/10.3389/fcvm.2021.716577","20211012","PubMed","brain-heart axis; cardiovascular magnetic resonance; cerebrovascular disease; ischaemic heart disease; myocardial infarction; radiomics; stroke","<b>Background:</b> Ischaemic heart disease (IHD) and cerebrovascular disease are two closely inter-related clinical entities. Cardiovascular magnetic resonance (CMR) radiomics may capture subtle cardiac changes associated with these two diseases providing new insights into the brain-heart interactions. <b>Objective:</b> To define the CMR radiomics signatures for IHD and cerebrovascular disease and study their incremental value for disease discrimination over conventional CMR indices. <b>Methods:</b> We analysed CMR images of UK Biobank's subjects with pre-existing IHD, ischaemic cerebrovascular disease, myocardial infarction (MI), and ischaemic stroke (IS) (<i>n</i> = 779, 267, 525, and 107, respectively). Each disease group was compared with an equal number of healthy controls. We extracted 446 shape, first-order, and texture radiomics features from three regions of interest (right ventricle, left ventricle, and left ventricular myocardium) in end-diastole and end-systole defined from segmentation of short-axis cine images. Systematic feature selection combined with machine learning (ML) algorithms (support vector machine and random forest) and 10-fold cross-validation tests were used to build the radiomics signature for each condition. We compared the discriminatory power achieved by the radiomics signature with conventional indices for each disease group, using the area under the curve (AUC), receiver operating characteristic (ROC) analysis, and paired <i>t</i>-test for statistical significance. A third model combining both radiomics and conventional indices was also evaluated. <b>Results:</b> In all the study groups, radiomics signatures provided a significantly better disease discrimination than conventional indices, as suggested by AUC (IHD:0.82 vs. 0.75; cerebrovascular disease: 0.79 vs. 0.77; MI: 0.87 vs. 0.79, and IS: 0.81 vs. 0.72). Similar results were observed with the combined models. In IHD and MI, LV shape radiomics were dominant. However, in IS and cerebrovascular disease, the combination of shape and intensity-based features improved the disease discrimination. A notable overlap of the radiomics signatures of IHD and cerebrovascular disease was also found. <b>Conclusions:</b> This study demonstrates the potential value of CMR radiomics over conventional indices in detecting subtle cardiac changes associated with chronic ischaemic processes involving the brain and heart, even in the presence of more heterogeneous clinical pictures. Radiomics analysis might also improve our understanding of the complex mechanisms behind the brain-heart interactions during ischaemia.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20920,""
"Augmented Reality Meets Artificial Intelligence in Robotics: A Systematic Review","Bassyouni, Elhajj","https://doi.org/10.3389/frobt.2021.724798","20211012","PubMed","artificial intelligence; augmented realitiy; learning; perception; planning; robotics","Recently, advancements in computational machinery have facilitated the integration of artificial intelligence (AI) to almost every field and industry. This fast-paced development in AI and sensing technologies have stirred an evolution in the realm of robotics. Concurrently, augmented reality (AR) applications are providing solutions to a myriad of robotics applications, such as demystifying robot motion intent and supporting intuitive control and feedback. In this paper, research papers combining the potentials of AI and AR in robotics over the last decade are presented and systematically reviewed. Four sources for data collection were utilized: Google Scholar, Scopus database, the International Conference on Robotics and Automation 2020 proceedings, and the references and citations of all identified papers. A total of 29 papers were analyzed from two perspectives: a theme-based perspective showcasing the relation between AR and AI, and an application-based analysis highlighting how the robotics application was affected. These two sections are further categorized based on the type of robotics platform and the type of robotics application, respectively. We analyze the work done and highlight some of the prevailing limitations hindering the field. Results also explain how AR and AI can be combined to solve the model-mismatch paradigm by creating a closed feedback loop between the user and the robot. This forms a solid base for increasing the efficiency of the robotic application and enhancing the user's situational awareness, safety, and acceptance of AI robots. Our findings affirm the promising future for robust integration of AR and AI in numerous robotic applications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20921,""
"Comprehensive literature review on the radiographic findings, imaging modalities, and the role of radiology in the COVID-19 pandemic","Pal, Ali, Young, Oostenbrink, Prabhakar, Prabhakar, Deacon, Arnold, Eltayeb, Yap, Young, Tang, Lakshmanan, Lim, Pokarowski, Kakodkar","https://doi.org/10.4329/wjr.v13.i9.258","20211012","PubMed","Brixia score; COVID-19; Computed tomography; Coronavirus; MuLBSTA Scoring system; Radiological Assessment of Lung Edema classification; Ultrasound","Since the outbreak of the coronavirus disease 2019 (COVID-19) pandemic, over 103214008 cases have been reported, with more than 2231158 deaths as of January 31, 2021. Although the gold standard for diagnosis of this disease remains the reverse-transcription polymerase chain reaction of nasopharyngeal and oropharyngeal swabs, its false-negative rates have ignited the use of medical imaging as an important adjunct or alternative. Medical imaging assists in identifying the pathogenesis, the degree of pulmonary damage, and the characteristic features in each imaging modality. This literature review collates the characteristic radiographic findings of COVID-19 in various imaging modalities while keeping the preliminary focus on chest radiography, computed tomography (CT), and ultrasound scans. Given the higher sensitivity and greater proficiency in detecting characteristic findings during the early stages, CT scans are more reliable in diagnosis and serve as a practical method in following up the disease time course. As research rapidly expands, we have emphasized the CO-RADS classification system as a tool to aid in communicating the likelihood of COVID-19 suspicion among healthcare workers. Additionally, the utilization of other scoring systems such as MuLBSTA, Radiological Assessment of Lung Edema, and Brixia in this pandemic are reviewed as they integrate the radiographic findings into an objective scoring system to risk stratify the patients and predict the severity of disease. Furthermore, current progress in the utilization of artificial intelligence <i>via</i> radiomics is evaluated. Lastly, the lesson from the first wave and preparation for the second wave from the point of view of radiology are summarized.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20922,""
"Application of Magnetic Resonance Imaging in Liver Biomechanics: A Systematic Review","Seyedpour, Nabati, Lambers, Nafisi, Tautenhahn, Sack, Reichenbach, Ricken","https://doi.org/10.3389/fphys.2021.733393","20211012","PubMed","biomechanics; clinical application; constitutive model; elastography; liver; liver disease; magnetic resonance imaging (MRI); viscoelastic","MRI-based biomechanical studies can provide a deep understanding of the mechanisms governing liver function, its mechanical performance but also liver diseases. In addition, comprehensive modeling of the liver can help improve liver disease treatment. Furthermore, such studies demonstrate the beginning of an engineering-level approach to how the liver disease affects material properties and liver function. Aimed at researchers in the field of MRI-based liver simulation, research articles pertinent to MRI-based liver modeling were identified, reviewed, and summarized systematically. Various MRI applications for liver biomechanics are highlighted, and the limitations of different viscoelastic models used in magnetic resonance elastography are addressed. The clinical application of the simulations and the diseases studied are also discussed. Based on the developed questionnaire, the papers' quality was assessed, and of the 46 reviewed papers, 32 papers were determined to be of high-quality. Due to the lack of the suitable material models for different liver diseases studied by magnetic resonance elastography, researchers may consider the effect of liver diseases on constitutive models. In the future, research groups may incorporate various aspects of machine learning (ML) into constitutive models and MRI data extraction to further refine the study methodology. Moreover, researchers should strive for further reproducibility and rigorous model validation and verification.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20923,""
"A Systematic Review of Systematic Reviews on Blended Learning: Trends, Gaps and Future Directions","Ashraf, Yang, Zhang, Denden, Tlili, Liu, Huang, Burgos","https://doi.org/10.2147/PRBM.S331741","20211012","PubMed","blended learning; distance education; flipped learning; hybrid learning; literature review; research trend","Blended Learning (BL) is one of the most used methods in education to promote active learning and enhance students' learning outcomes. Although BL has existed for over a decade, there are still several challenges associated with it. For instance, the teachers' and students' individual differences, such as their behaviors and attitudes, might impact their adoption of BL. These challenges are further exacerbated by the COVID-19 pandemic, as schools and universities had to combine both online and offline courses to keep up with health regulations. This study conducts a systematic review of systematic reviews on BL, based on PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, to identify BL trends, gaps and future directions. The obtained findings highlight that BL was mostly investigated in higher education and targeted students in the first place. Additionally, most of the BL research is coming from developed countries, calling for cross-collaborations to facilitate BL adoption in developing countries in particular. Furthermore, a lack of ICT skills and infrastructure are the most encountered challenges by teachers, students and institutions. The findings of this study can create a roadmap to facilitate the adoption of BL. The findings of this study could facilitate the design and adoption of BL which is one of the possible solutions to face major health challenges, such as the COVID-19 pandemic.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20924,""
"Robotics and artificial intelligence in healthcare during COVID-19 pandemic: A systematic review","Sarker, Jamal, Ahmed, Irtisam","https://doi.org/10.1016/j.robot.2021.103902","20211015","PubMed","Artificial intelligence; Autonomous system; COVID-19; Healthcare; Robotics; SARS-coV-2","The outbreak of the COVID-19 pandemic is unarguably the biggest catastrophe of the 21st century, probably the most significant global crisis after the second world war. The rapid spreading capability of the virus has compelled the world population to maintain strict preventive measures. The outrage of the virus has rampaged through the healthcare sector tremendously. This pandemic created a huge demand for necessary healthcare equipment, medicines along with the requirement for advanced robotics and artificial intelligence-based applications. The intelligent robot systems have great potential to render service in diagnosis, risk assessment, monitoring, telehealthcare, disinfection, and several other operations during this pandemic which has helped reduce the workload of the frontline workers remarkably. The long-awaited vaccine discovery of this deadly virus has also been greatly accelerated with AI-empowered tools. In addition to that, many robotics and Robotics Process Automation platforms have substantially facilitated the distribution of the vaccine in many arrangements pertaining to it. These forefront technologies have also aided in giving comfort to the people dealing with less addressed mental health complicacies. This paper investigates the use of robotics and artificial intelligence-based technologies and their applications in healthcare to fight against the COVID-19 pandemic. A systematic search following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) method is conducted to accumulate such literature, and an extensive review on 147 selected records is performed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20925,""
"Substituting clinical features using synthetic medical phrases: Medical text data augmentation techniques","Abdollahi, Gao, Mei, Ghosh, Li, Narag","https://doi.org/10.1016/j.artmed.2021.102167","20211029","PubMed","Data augmentation; Machine learning; Medical document classification; Natural language processing; Unified Medical Language System; Machine Learning; Natural Language Processing","Biomedical natural language processing (NLP) has an important role in extracting consequential information in medical discharge notes. Detecting meaningful features from unstructured notes is a challenging task in medical document classification. The domain specific phrases and different synonyms within the medical documents make it hard to analyze them. Analyzing clinical notes becomes more challenging for short documents like abstract texts. All of these can result in poor classification performance, especially when there is a shortage of the clinical data in real life. Two new approaches (an ontology-guided approach and a combined ontology-based with dictionary-based approach) are suggested for augmenting medical data to enrich training data. Three different deep learning approaches are used to evaluate the classification performance of the proposed methods. The obtained results show that the proposed methods improved the classification accuracy in clinical notes classification.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20926,""
"Image quality assessment of pediatric chest and abdomen CT by deep learning reconstruction","Yoon, Kim, Lim, Lee","https://doi.org/10.1186/s12880-021-00677-2","20211022","PubMed","CT; Deep learning; Image quality; Iterative reconstruction; Pediatric","Efforts to reduce the radiation dose have continued steadily, with new reconstruction techniques. Recently, image denoising algorithms using artificial neural networks, termed deep learning reconstruction (DLR), have been applied to CT image reconstruction to overcome the drawbacks of iterative reconstruction (IR). The purpose of our study was to compare the objective and subjective image quality of DLR and IR on pediatric abdomen and chest CT images. This retrospective study included pediatric body CT images from February 2020 to October 2020, performed on 51 patients (34 boys and 17 girls; age 1-18Ã‚Â years). Non-contrast chest CT (nÃ¢â‚¬â€°=Ã¢â‚¬â€°16), contrast-enhanced chest CT (nÃ¢â‚¬â€°=Ã¢â‚¬â€°12), and contrast-enhanced abdomen CT (nÃ¢â‚¬â€°=Ã¢â‚¬â€°23) images were included. Standard 50% adaptive statistical iterative reconstruction V (ASIR-V) images were compared to images with 100% ASIR-V and DLR at medium and high strengths. Attenuation, noise, contrast to noise ratio (CNR), and signal to noise (SNR) measurements were performed. Overall image quality, artifacts, and noise were subjectively assessed by two radiologists using a four-point scale (superior, average, suboptimal, and unacceptable). A phantom scan was performed including the dose range of the clinical images used in our study, and the noise power spectrum (NPS) was calculated. Quantitative and qualitative parameters were compared using repeated-measures analysis of variance (ANOVA) with Bonferroni correction and Wilcoxon signed-rank tests. DLR had better CNR and SNR than 50% ASIR-V in both pediatric chest and abdomen CT images. When compared with 50% ASIR-V, high strength DLR was associated with noise reduction in non-contrast chest CT (33.0%), contrast-enhanced chest CT (39.6%), and contrast-enhanced abdomen CT (38.7%) with increases in CNR at 149.1%, 105.8%, and 53.1% respectively. The subjective assessment of overall image quality and the noise was also better on DLR images (pÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.001). However, there was no significant difference in artifacts between reconstruction methods. From NPS analysis, DLR methods showed a pattern of reducing the magnitude of noise while maintaining the texture. Compared with 50% ASIR-V, DLR improved pediatric body CT images with significant noise reduction. However, artifacts were not improved by DLR, regardless of strength.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20927,""
"Current Applications of Machine Learning in Spine: From Clinical View","Ren, Yu, Xie, Wang, Zhang, Huang, Wang, Wu","https://doi.org/10.1177/21925682211035363","20211011","PubMed","artificial intelligence; current applications; deep learning; machine learning; spine","Narrative review. This review aims to present current applications of machine learning (ML) in spine domain to clinicians. We conducted a comprehensive PubMed search of peer-reviewed articles that were published between 2006 and 2020 using terms (spine, spinal, lumbar, cervical, thoracic, machine learning) to examine ML in spine. Then exclude research of other domain, case report, review or meta-analysis, and which without available abstract or full text. Total 1738 articles were retrieved from database, and 292 studies were finally included. Key findings of current applications were compiled and summarized in this review. Main clinical applications of those techniques including image processing, diagnosis, decision supporting, operative assistance, rehabilitation, surgery outcomes, complications, hospitalization and cost. ML had achieved excellent performance and hold immense potential in spine. ML could help clinical staff to improve medical level, enhance work efficiency, and reduce adverse events. However more randomized controlled trials and improvement of interpretability are essential to clinicians accepting models' assistance in real work.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20928,""
"[Rule mining of acupoint and medication selection of acupoint application therapy for functional constipation]","Wang, Sun, Yin, Guo, Yang, Xiong, He, Zeng","https://doi.org/10.13703/j.0255-2930.20200823-k0003","20211012","PubMed","acupoint application therapy; acupoint selection rule; data mining; functional constipation (FC); medication selection rule; Acupuncture Points; Acupuncture Therapy; Constipation; Data Mining; Humans; Meridians","To analyze the rules of acupoint and medication selection of acupoint application therapy for functional constipation (FC) by data mining technology. The clinical research literature regarding acupoint application therapy for FC from published to February 26, 2020 was searched in CNKI, VIP, Wanfang, SinoMed and PubMed. The prescriptions were extracted, and by using SPSS24.0 and SPSS Modeler14.0 software, the use of high-frequency acupoints and medication was summarized. The association rule analysis, cluster analysis and core prescription analysis of acupoints and medication were analyzed. A total of 122 prescriptions of acupoint application therapy were included, involving 32 acupoints. The core prescription of acupoints was Tianshu (ST 25), Dachangshu (BL 25), Shenque (CV 8) and Guanyuan (CV 4). The high-frequency meridians mainly included conception vessel, <i>yangming</i> stomach meridian of foot and <i>taiyang</i> bladder meridian of foot. The core prescription of medication was rheum officinale, mirabilite, immature bitter orange, mangnolia officinalis, common aucklandia root and borneol. The use of local acupoint and regulating-<i>qi</i> and purgating medication is an important principle of acupoint application therapy for FC. <b>Ã§â€ºÂ®Ã§Å¡â€žÃ¯Â¼Å¡</b>Ã¨Â¿ÂÃ§â€Â¨Ã¦â€¢Â°Ã¦ÂÂ®Ã¦Å’â€“Ã¦Å½ËœÃ¦Å â‚¬Ã¦Å“Â¯Ã¥Ë†â€ Ã¦Å¾ÂÃ§Â©Â´Ã¤Â½ÂÃ¨Â´Â´Ã¦â€¢Â·Ã¦Â²Â»Ã§â€“â€”Ã¥Å Å¸Ã¨Æ’Â½Ã¦â‚¬Â§Ã¤Â¾Â¿Ã§Â§ËœÃ¯Â¼Ë†FCÃ¯Â¼â€°Ã§Å¡â€žÃ¥Ââ€“Ã§Â©Â´Ã§â€Â¨Ã¨ÂÂ¯Ã¨Â§â€žÃ¥Â¾â€¹Ã£â‚¬â€š<b>Ã¦â€“Â¹Ã¦Â³â€¢Ã¯Â¼Å¡</b>Ã¦Â£â‚¬Ã§Â´Â¢Ã¤Â¸Â­Ã¥â€ºÂ½Ã¦Å“Å¸Ã¥Ë†Å Ã¥â€¦Â¨Ã¦â€“â€¡Ã¦â€¢Â°Ã¦ÂÂ®Ã¥Âºâ€œÃ¯Â¼Ë†CNKIÃ¯Â¼â€°Ã£â‚¬ÂÃ§Â»Â´Ã¦â„¢Â®Ã¤Â¸Â­Ã¦â€“â€¡Ã§Â§â€˜Ã¦Å â‚¬Ã¦Å“Å¸Ã¥Ë†Å Ã¦â€¢Â°Ã¦ÂÂ®Ã¥Âºâ€œÃ¯Â¼Ë†VIPÃ¯Â¼â€°Ã£â‚¬ÂÃ¤Â¸â€¡Ã¦â€“Â¹Ã¥Â­Â¦Ã¦Å“Â¯Ã¦Å“Å¸Ã¥Ë†Å Ã¥â€¦Â¨Ã¦â€“â€¡Ã¦â€¢Â°Ã¦ÂÂ®Ã¥Âºâ€œÃ¯Â¼Ë†WanfangÃ¯Â¼â€°Ã£â‚¬ÂÃ¤Â¸Â­Ã¥â€ºÂ½Ã§â€Å¸Ã§â€°Â©Ã¥Å’Â»Ã¥Â­Â¦Ã¦â€“â€¡Ã§Å’Â®Ã¦â€¢Â°Ã¦ÂÂ®Ã¥Âºâ€œÃ¯Â¼Ë†SinoMedÃ¯Â¼â€°Ã£â‚¬ÂPubMedÃ¥Â»ÂºÃ¥Âºâ€œÃ¤Â»Â¥Ã¦ÂÂ¥Ã¨â€¡Â³2020Ã¥Â¹Â´2Ã¦Å“Ë†26Ã¦â€”Â¥Ã§Â©Â´Ã¤Â½ÂÃ¨Â´Â´Ã¦â€¢Â·Ã¦Â²Â»Ã§â€“â€”Ã¥Å Å¸Ã¨Æ’Â½Ã¦â‚¬Â§Ã¤Â¾Â¿Ã§Â§ËœÃ§Å¡â€žÃ¤Â¸Â´Ã¥ÂºÅ Ã§Â â€Ã§Â©Â¶Ã¦â€“â€¡Ã§Å’Â®Ã¯Â¼Å’Ã¦ÂÂÃ¥Ââ€“Ã¥Â¤â€žÃ¦â€“Â¹Ã¥Â¹Â¶Ã¤Â½Â¿Ã§â€Â¨SPSS24.0Ã£â‚¬ÂSPSS Modeler14.0Ã¨Â½Â¯Ã¤Â»Â¶Ã¯Â¼Å’Ã§Â»Å¸Ã¨Â®Â¡Ã©Â«ËœÃ©Â¢â€˜Ã¨â€¦Â§Ã§Â©Â´Ã£â‚¬ÂÃ¤Â¸Â­Ã¨ÂÂ¯Ã¯Â¼Å’Ã¥Â¹Â¶Ã¨Â¿â€ºÃ¨Â¡Å’Ã¨â€¦Â§Ã§Â©Â´Ã£â‚¬ÂÃ¤Â¸Â­Ã¨ÂÂ¯Ã¥â€¦Â³Ã¨Ââ€Ã¨Â§â€žÃ¥Ë†â„¢Ã¥Ë†â€ Ã¦Å¾ÂÃ£â‚¬ÂÃ¨ÂÅ¡Ã§Â±Â»Ã¥Ë†â€ Ã¦Å¾ÂÃ£â‚¬ÂÃ¦Â Â¸Ã¥Â¿Æ’Ã¥Â¤â€žÃ¦â€“Â¹Ã¥Ë†â€ Ã¦Å¾ÂÃ£â‚¬â€š<b>Ã§Â»â€œÃ¦Å¾Å“Ã¯Â¼Å¡</b>Ã¥â€¦Â±Ã§ÂºÂ³Ã¥â€¦Â¥Ã§Â©Â´Ã¤Â½ÂÃ¨Â´Â´Ã¦â€¢Â·Ã¥Â¤â€žÃ¦â€“Â¹122Ã©Â¦â€“Ã¯Â¼Å’Ã¦Â¶â€°Ã¥ÂÅ Ã¨â€¦Â§Ã§Â©Â´32Ã¤Â¸ÂªÃ¯Â¼Å’Ã¦Â Â¸Ã¥Â¿Æ’Ã¥Â¤â€žÃ¦â€“Â¹Ã¤Â¸ÂºÃ¥Â¤Â©Ã¦Å¾Â¢Ã£â‚¬ÂÃ¥Â¤Â§Ã¨â€šÂ Ã¤Â¿Å¾Ã£â‚¬ÂÃ§Â¥Å¾Ã©Ëœâ„¢Ã£â‚¬ÂÃ¥â€¦Â³Ã¥â€¦Æ’Ã¯Â¼Å’Ã¥Â¸Â¸Ã§â€Â¨Ã§Â»ÂÃ¨â€žâ€°Ã¤Â¸ÂºÃ¤Â»Â»Ã¨â€žâ€°Ã£â‚¬ÂÃ¨Â¶Â³Ã©ËœÂ³Ã¦ËœÅ½Ã¨Æ’Æ’Ã§Â»ÂÃ£â‚¬ÂÃ¨Â¶Â³Ã¥Â¤ÂªÃ©ËœÂ³Ã¨â€ â‚¬Ã¨Æ’Â±Ã§Â»ÂÃ£â‚¬â€šÃ¨Â´Â´Ã¦â€¢Â·Ã¨ÂÂ¯Ã§â€°Â©Ã¦Â Â¸Ã¥Â¿Æ’Ã¥Â¤â€žÃ¦â€“Â¹Ã¤Â¸ÂºÃ¥Â¤Â§Ã©Â»â€žÃ£â‚¬ÂÃ¨Å â€™Ã§Â¡ÂÃ£â‚¬ÂÃ¦Å¾Â³Ã¥Â®Å¾Ã£â‚¬ÂÃ¥Å½Å¡Ã¦Å“Â´Ã£â‚¬ÂÃ¦Å“Â¨Ã©Â¦â„¢Ã£â‚¬ÂÃ¥â€ Â°Ã§â€°â€¡Ã£â‚¬â€š<b>Ã§Â»â€œÃ¨Â®ÂºÃ¯Â¼Å¡</b>Ã¤Â»Â¥Ã¥Â±â‚¬Ã©Æ’Â¨Ã¥Ââ€“Ã§Â©Â´Ã¤Â¸ÂºÃ¤Â¸Â»Ã£â‚¬ÂÃ©â‚¬â€°Ã§â€Â¨Ã¨Â¡Å’Ã¦Â°â€Ã¦Â³Â»Ã¤Â¸â€¹Ã¨ÂÂ¯Ã§â€°Â©Ã¦ËœÂ¯Ã§Â©Â´Ã¤Â½ÂÃ¨Â´Â´Ã¦â€¢Â·Ã¦Â²Â»Ã§â€“â€”Ã¥Å Å¸Ã¨Æ’Â½Ã¦â‚¬Â§Ã¤Â¾Â¿Ã§Â§ËœÃ©â‚¬â€°Ã§Â©Â´Ã§â€Â¨Ã¨ÂÂ¯Ã§Å¡â€žÃ©â€¡ÂÃ¨Â¦ÂÃ¥Å½Å¸Ã¥Ë†â„¢Ã£â‚¬â€š.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20929,""
"A practical approach towards causality mining in clinical text using active transfer learning","Hussain, Satti, Hussain, Ali, Ali, Bilal, Park, Lee, Chung","https://doi.org/10.1016/j.jbi.2021.103932","20211028","PubMed","Active transfer learning; Causality mining; Clinical text mining; Machine learning","Causality mining is an active research area, which requires the application of state-of-the-art natural language processing techniques. In the healthcare domain, medical experts create clinical text to overcome the limitation of well-defined and schema driven information systems. The objective of this research work is to create a framework, which can convert clinical text into causal knowledge. A practical approach based on term expansion, phrase generation, BERT based phrase embedding and semantic matching, semantic enrichment, expert verification, and model evolution has been used to construct a comprehensive causality mining framework. This active transfer learning based framework along with its supplementary services, is able to extract and enrich, causal relationships and their corresponding entities from clinical text. The multi-model transfer learning technique when applied over multiple iterations, gains substantial performance improvements. We also present a comparative analysis of the presented techniques with their common alternatives, which demonstrate the correctness of our approach and its ability to capture most causal relationships. The presented framework has provided cutting-edge results in the healthcare domain. However, the framework can be tweaked to provide causality detection in other domains, as well. The presented framework is generic enough to be utilized in any domain, healthcare services can gain massive benefits due to the voluminous and various nature of its data. This causal knowledge extraction framework can be used to summarize clinical text, create personas, discover medical knowledge, and provide evidence to clinical decision making.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20930,""
"Cerebral Venous Sinus Thrombosis is not Significantly Linked to COVID-19 Vaccines or Non-COVID Vaccines in a Large Multi-State Health System","Pawlowski, RincÃƒÂ³n-Hekking, Awasthi, Pandey, Lenehan, Venkatakrishnan, Bade, O'Horo, Virk, Swift, Williams, Gores, Badley, Halamka, Soundararajan","https://doi.org/10.1016/j.jstrokecerebrovasdis.2021.105923","20211013","PubMed","COVID-19; COVID-19 Vaccines; Electronic Health Records; Humans; Incidence; Retrospective Studies; Risk Assessment; Risk Factors; Sinus Thrombosis, Intracranial; Time Factors; United States; Vaccination","To assess the association of COVID-19 vaccines and non-COVID-19 vaccines with cerebral venous sinus thrombosis (CVST). We retrospectively analyzed a cohort of 771,805 vaccination events across 266,094 patients in the Mayo Clinic Health System between 01/01/2017 and 03/15/2021. The primary outcome was a positive diagnosis of CVST, identified either by the presence of a corresponding ICD code or by an NLP algorithm which detected positive diagnosis of CVST within free-text clinical notes. For each vaccine we calculated the relative risk by dividing the incidence of CVST in the 30 days following vaccination to that in the 30 days preceding vaccination. We identified vaccination events for all FDA-approved COVID-19 vaccines including Pfizer-BioNTech (nÃ‚Â =Ã‚Â 94,818 doses), Moderna (nÃ‚Â =Ã‚Â 36,350 doses) and Johnson &amp; Johnson - J&amp;J (nÃ‚Â =Ã‚Â 1,745 doses). We also identified vaccinations events for 10 common FDA-approved non-COVID-19 vaccines (nÃ‚Â =Ã‚Â 771,805 doses). There was no statistically significant difference in the incidence rate of CVST in 30-days before and after vaccination for any vaccine in this population. We further found the baseline CVST incidence in the study population between 2017 and 2021 to be 45 to 98 per million patient years. This real-world evidence-based study finds that CVST is rare and is not significantly associated with COVID-19 vaccination in our patient cohort. Limitations include the rarity of CVST in our dataset, a relatively small number of J&amp;J COVID-19 vaccination events, and the use of a population drawn from recipients of a SARS-CoV-2 PCR test in a single health system.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20931,""
"A disease-specific language representation model for cerebrovascular disease research","Lin, Hsu, Liang, Lee, Liou, Lee, Peng, Shih, Fann","https://doi.org/10.1016/j.cmpb.2021.106446","20211028","PubMed","Cerebrovascular disease; Natural language processing; Specific language representation model; Cerebrovascular Disorders; Humans; Language; Natural Language Processing","Effectively utilizing disease-relevant text information from unstructured clinical notes for medical research presents many challenges. BERT (Bidirectional Encoder Representation from Transformers) related models such as BioBERT and ClinicalBERT, pre-trained on biomedical corpora and general clinical information, have shown promising performance in various biomedical language processing tasks. This study aims to explore whether a BERT-based model pre-trained on disease-related clinical information can be more effective for cerebrovascular disease-relevant research. This study proposed the StrokeBERT which was initialized from BioBERT and pre-trained on large-scale cerebrovascular disease related clinical text information. The pre-trained corpora contained 113,590 discharge notes, 105,743 radiology reports, and 38,199 neurological reports. Two real-world empirical clinical tasks were conducted to validate StrokeBERT's performance. The first task identified extracranial and intracranial artery stenosis from two independent sets of radiology angiography reports. The second task predicted the risk of recurrent ischemic stroke based on patients' first discharge information. In stenosis detection, StrokeBERT showed improved performance on targeted carotid arteries, with an average AUC compared to that of ClinicalBERT of 0.968 Ã‚Â± 0.021 and 0.956 Ã‚Â± 0.018, respectively. In recurrent ischemic stroke prediction, after 10-fold cross-validation on 1,700 discharge information, StrokeBERT presented better prediction ability (AUCÃ‚Â±SDÃ‚Â =Ã‚Â 0.838 Ã‚Â± 0.017) than ClinicalBERT (AUCÃ‚Â±SDÃ‚Â =Ã‚Â 0.808 Ã‚Â± 0.045). The attention scores of StrokeBERT showed better ability to detect and associate cerebrovascular disease related terms than current BERT based models. This study shows that a disease-specific BERT model improved the performance and accuracy of various disease-specific language processing tasks and can readily be fine-tuned to advance cerebrovascular disease research and further developed for clinical applications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20932,""
"The Ascent of Artificial Intelligence in Endourology: a Systematic Review Over the Last 2 Decades","Hameed, Shah, Naik, Rai, Karimi, Rice, Kronenberg, Somani","https://doi.org/10.1007/s11934-021-01069-3","20211012","PubMed","Artificial intelligence; ESWL; Endourology; Machine learning; PCNL; Ureteroscopy; Algorithms; Artificial Intelligence; Checklist; Humans; Kidney Calculi; Quality of Life","To highlight and review the application of artificial intelligence (AI) in kidney stone disease (KSD) for diagnostics, predicting procedural outcomes, stone passage, and recurrence rates. The systematic review was performed according to the Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) checklist. This review discusses the newer advancements in AI-driven management strategies, which holds great promise to provide an essential step for personalized patient care and improved decision making. AI has been used in all areas of KSD including diagnosis, for predicting treatment suitability and success, basic science, quality of life (QOL), and recurrence of stone disease. However, it is still a research-based tool and is not used universally in clinical practice. This could be due to a lack of data infrastructure needed to train the algorithms, wider applicability in all groups of patients, complexity of its use and cost involved with it. The constantly evolving literature and future research should focus more on QOL and the cost of KSD treatment and develop evidence-based AI algorithms that can be used universally, to guide urologists in the management of stone disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20933,""
"Indigenous knowledge around the ethics of human research from the Oceania region: A scoping literature review","Lovo, Woodward, Larkins, Preston, Baba","https://doi.org/10.1186/s13010-021-00108-8","20211022","PubMed","Ethics; Human research ethics committees; Indigenous research ethics principles; Oceania; Pacific; Values","Many indigenous people have died or been harmed because of inadequately monitored research. Strong regulations in Human Research Ethics (HRE) are required to address these injustices and to ensure that peoples' participation in health research is safe. Indigenous peoples advocate that research that respects indigenous principles can contribute to addressing their health inequities. This scoping literature review aims to analyze existing peer reviewed and grey literature to explore how indigenous values and principles from countries of Oceania are incorporated into HRE and the governance of research involving human participants. A scoping literature review framework was used for this study. A search for peer reviewed and grey literature from Google, bibliographies, and electronic databases such as SCOPUS, SPRINGER, Medline (Ovid) and JBI Database of Systematic Reviews was conducted, limited to the years 2002-2020. Sixty (60) documents that focused on indigenous knowledge from Oceania region and HRE were included, from which key findings and themes were synthesized. Charting the data showed that more than half the eligible documents were peer-reviewed journal articles (54%). Other sources included: International Declarations on Human Research (8%); book chapters (8%); government documents (8%); HRE Guidelines or protocols (13%); news articles (7%) and PhD thesis (2%). The literature was from Australia, Cook Islands, Guam, New Zealand, Fiji, Samoa, Tonga and Vanuatu, some of which focused specifically on HREs in the Pacific Region. Issues emerging from the literature were grouped into five themes (i) indigenous and cultural principles of HRE; (ii) informed consent in indigenous settings in Oceania; (iii) vulnerability and minority status of indigenous populations exploited for research; (iv) research ethics governance for Oceania indigenous peoples; and (v) research ethics committees in Oceania. Respect, relationship building, and trust were priority indigenous HRE principles that encompass the principles of partnership, capacity building, reciprocity, and equality. Relationship building and trust imply the equal distribution of benefits for indigenous population and researchers. Indigenous principles of HRE identified were interconnected and interdependent. Recommendations were to incorporate indigenous principles of research in HRE regulations and processes of all countries with indigenous populations. This is especially pertinent for emerging national research committees in LMIC countries, including Fiji and Tonga. Relationship building among researchers and indigenous populations is key to successful research with indigenous populations. HRE principles important for relationship building include respect that is reciprocal among researchers and indigenous people. Elements of the principle of respect highlighted are empathy, collaboration, sharing of benefits, reciprocity, appreciation, empowerment, protection, safety and awareness of culture and languages. Indigenous ontology from the Oceania region involves spirituality, connectedness to land, religious beliefs and a participatory approach to HRE and should be respected in research. An ethical governance mechanism of HRE is one that incorporates indigenous principles and applications for the purpose of maximizing the protection of the dignity and rights of indigenous peoples of Oceania.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20934,""
"The neural underpinnings of motor learning in people with neurodegenerative diseases: A scoping review","Aslan, Hernandez, Frechette, Gephart, Soloveychik, Sosnoff","https://doi.org/10.1016/j.neubiorev.2021.10.006","20211030","PubMed","Brain imaging; Motor learning; Neurodegenerative disorders","Chronic progressive neurodegenerative diseases (NDD) cause mobility and cognitive impairments that disrupt quality of life. The learning of new motor skills, motor learning, is a critical component of rehabilitation efforts to counteract these chronic progressive impairments. In people with NDD, there are impairments in motor learning which appear to scale with the severity of impairment. Compensatory cortical activity plays a role in counteracting motor learning impairments in NDD. Yet, the functional and structural brain alterations associated with motor learning have not been synthesized in people with NDD. The purpose of this scoping review is to explore the neural alterations of motor learning in NDD. Thirty-five peer-reviewed original articles met the inclusion criteria. Participant demographics, motor learning results, and brain imaging results were extracted. Distinct motor learning associated compensatory processes were identified across NDD populations. Evidence from this review suggests the success of motor learning in NDD populations depends on the neural alterations and their interaction with motor learning networks, as well as the progression of disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20935,""
"The Toxic Effect of Silver Nanoparticles on Nerve Cells: A Systematic Review and Meta-Analysis","Janzadeh, Hamblin, Janzadeh, Arzani, MahsaTashakori-Miyanroudi, Yousefifard, Ramezani","https://doi.org/10.1007/398_2021_67","20211008","PubMed","Apoptosis; MTT assay; Nerve cell; Neuron; Silver nanoparticle; Toxic","Despite the increasing use of silver nanoparticles in medical sciences, published studies on their interaction with nerve cells and evaluation of risks are dispersed. This systematic review and meta-analysis could be used to devise safety guidelines for the use of silver nanoparticles in industry and medicine to reduce adverse effects on the CNS.After extensive searches, the full text of 30 related studies was reviewed and data mining completed. Data were analyzed by calculating the mean of different ratios between treated and untreated groups. Linear regression between variables was evaluated by meta-regression. Subgroup analysis was also performed due to heterogeneity.Treatment with silver nanoparticles significantly reduced cell viability (SMDÃ‚Â =Ã‚Â -1.79%; 95% CI: -2.17 to -1.40; pÃ‚Â &lt;Ã‚Â 0.0001). ConcentrationÃ‚Â &gt;Ã‚Â 0.1Ã‚Â ÃŽÂ¼g/mL could kill neurons, while lower concentration would not (SMD -0.258; 95% CI: -0.821 to 0.305; pÃ‚Â =Ã‚Â 369). In addition to the concentration, the coating, size of the nanoparticles, and cell type are also factors that influence SNP nerve cell toxicity. Measurement of apoptosis (SMDÃ‚Â =Ã‚Â 2.21; 95% CI: 1.62 to 2.80; p=0.001) and lactate dehydrogenase release rate (SMDÃ‚Â =Ã‚Â 0.9; 95% CI: 0.33 to 1.47; pÃ‚Â &lt;Ã‚Â 0.0001) also confirmed the destructive effect of silver nanoparticles on nerve cells.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20936,""
"Deep learning convolutional neural network algorithms for the early detection and diagnosis of dental caries on periapical radiographs: A systematic review","Musri, Christie, Ichwan, Cahyanto","https://doi.org/10.5624/isd.20210074","20211009","PubMed","Deep Learning; Dental Caries; Neural Network Models; Radiography, Dental","The aim of this study was to analyse and review deep learning convolutional neural networks for detecting and diagnosing early-stage dental caries on periapical radiographs. In order to conduct this review, the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines were followed. Studies published from 2015 to 2021 under the keywords (deep convolutional neural network) AND (caries), (deep learning caries) AND (convolutional neural network) AND (caries) were systematically reviewed. When dental caries is improperly diagnosed, the lesion may eventually invade the enamel, dentin, and pulp tissue, leading to loss of tooth function. Rapid and precise detection and diagnosis are vital for implementing appropriate prevention and treatment of dental caries. Radiography and intraoral images are considered to play a vital role in detecting dental caries; nevertheless, studies have shown that 20% of suspicious areas are mistakenly diagnosed as dental caries using this technique; hence, diagnosis via radiography alone without an objective assessment is inaccurate. Identifying caries with a deep convolutional neural network-based detector enables the operator to distinguish changes in the location and morphological features of dental caries lesions. Deep learning algorithms have broader and more profound layers and are continually being developed, remarkably enhancing their precision in detecting and segmenting objects. Clinical applications of deep learning convolutional neural networks in the dental field have shown significant accuracy in detecting and diagnosing dental caries, and these models hold promise in supporting dental practitioners to improve patient outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20937,""
"Automated Identification of Surgical Candidates and Estimation of Postoperative Seizure Freedom in Children - A Focused Review","Samanta, Beal, Grinspan","https://doi.org/10.1016/j.spen.2021.100914","20211008","PubMed","","Surgery is an effective but underused treatment for drug-resistant epilepsy in children. Algorithms to identify surgical candidates and estimate the likelihood of postoperative clinical improvement may be valuable to improve access to epilepsy surgery. We provide a focused review of these approaches. For adults with epilepsy, tools to identify surgical candidates and predict seizure and cognitive outcomes (Ie, Cases for Epilepsy (toolsforepilepsy.com) and Epilepsy Surgery Grading Scale) have been validated and are in use. Analogous tools for children need development. A promising approach is to apply statistical learning tools to clinical datasets, such as electroencephalogram tracings, imaging studies, and the text of clinician notes. Demonstration projects suggest these techniques have the potential to be highly accurate, and await further validation and clinical application.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20938,""
"An overview of machine learning methods for monotherapy drug response prediction","Firoozbakht, Yousefi, Schwikowski","https://doi.org/10.1093/bib/bbab408","20211007","PubMed","","For an increasing number of preclinical samples, both detailed molecular profiles and their responses to various drugs are becoming available. Efforts to understand, and predict, drug responses in a data-driven manner have led to a proliferation of machine learning (ML) methods, with the longer term ambition of predicting clinical drug responses. Here, we provide a uniquely wide and deep systematic review of the rapidly evolving literature on monotherapy drug response prediction, with a systematic characterization and classification that comprises more than 70 ML methods in 13 subclasses, their input and output data types, modes of evaluation, and code and software availability. ML experts are provided with a fundamental understanding of the biological problem, and how ML methods are configured for it. Biologists and biomedical researchers are introduced to the basic principles of applicable ML methods, and their application to the problem of drug response prediction. We also provide systematic overviews of commonly used data sources used for training and evaluation methods.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20939,""
"Incorporating automated digital interventions into coach-delivered weight loss treatment: A meta-analysis","Berry, Sala, Abber, Forman","https://doi.org/10.1037/hea0001106","20211015","PubMed","Behavior Therapy; Humans; Weight Loss","Automated digital interventions (ADIs) represent a potentially promising approach to enhance the outcomes of human coach-delivered weight loss interventions. However, the extent to which ADIs provide additive benefit is unclear. This study represents the first systematic review and meta-analysis of the effectiveness of ADIs for improving the outcomes of human coach-delivered weight loss treatment. Electronic database searches were used to identify trials that compared differences in weight change between (a) weight loss interventions that were delivered exclusively by coaches and (b) interventions supplementing this same human coaching with an ADI. Subgroup and moderator analyses examined the influence of intervention duration, duration of human coach contact, presence of tailored coaching, modality of the ADI and demographic variables on ADI effectiveness outcomes. Thirteen studies met inclusion criteria (1,471 participants). Random-effects meta-analysis revealed a mean difference in weight change between conditions of 2.18 kg at postintervention, representing a medium effect size of .54 (95% CI [.13, .95]). Subgroup analyses suggested that lower duration of coach contact was associated with improved additive effectiveness of ADIs. No other subgroup differences were found. Publication bias appeared to be a potential concern, though high levels of heterogeneity and a small number of included studies likely limited the ability to infer its presence. Results support the use of ADIs to augment coach-delivered behavioral weight loss treatment, and also suggest that ADIs have the greatest impact when coaching is relatively low in frequency or duration. (PsycInfo Database Record (c) 2021 APA, all rights reserved).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20940,""
"Security, privacy, and healthcare-related conversational agents: a scoping review","May, Denecke","https://doi.org/10.1080/17538157.2021.1983578","20211007","PubMed","Healthcare; chatbots; conversational user interfaces; data privacy; data security","Health chatbots interview patients and collect health data. This process makes demands on data security and data privacy. To identify how and to what extent security and privacy are considered in current health chatbots. We conducted a scoping review by searching three bibliographic databases (PubMed, ACM Digital Library, IEEExplore) for papers reporting on chatbots in healthcare. We extracted which, how, and where data is stored by health chatbots and identified which external services have access to the data. Out of 1026 retrieved papers, we included 70 studies in the qualitative synthesis. Most papers report on chatbots that collect and process personal health data, usually in the context of mental health coaching applications. The majority did not provide any information regarding security or privacy aspects. We were able to determine limitations in literature and identified concrete challenges, including data access and usage of (third-party) services, data storage, data security methods, use case peculiarities and data privacy, as well as legal requirements. Data privacy and security in health chatbots are still underresearched and related information is underrepresented in scientific literature. By addressing the five key challenges in future, the transfer of theoretical solutions into practice can be facilitated.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20941,""
"Current status and limitations of artificial intelligence in colonoscopy","Hann, Troya, Fitting","https://doi.org/10.1002/ueg2.12108","20211027","PubMed","colonic polyps; colonoscopy; colorectal neoplasms; computer-assisted; deep learning; diagnosis; endoscopy; gastrointestinal","Artificial intelligence (AI) using deep learning methods for polyp detection (CADe) and characterization (CADx) is on the verge of clinical application. CADe already implied its potential use in randomized controlled trials. Further efforts are needed to take CADx to the next level of development. This work aims to give an overview of the current status of AI in colonoscopy, without going into too much technical detail. A literature search to identify important studies exploring the use of AI in colonoscopy was performed. This review focuses on AI performance in screening colonoscopy summarizing the first prospective trials for CADe, the state of research in CADx as well as current limitations of those systems and legal issues.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20942,""
"Deep learning identifies erroneous microarray-based, gene-level conclusions in literature","Qin, Yi, Chen, Guan","https://doi.org/10.1093/nargab/lqab089","20211008","PubMed","","More than 110Ã‚Â 000 publications have used microarrays to decipher phenotype-associated genes, clinical biomarkers and gene functions. Microarrays relyÃ‚Â on digital assaying the fluorescence signals of arrays. In this study, we retrospectively constructed raw images for 37Ã‚Â 724 published microarray data, and developed deep learning algorithms to automatically detect systematic defects. We report that an alarming amount of 26.73% of the microarray-based studies are affected by serious imaging defects. By literature mining, we found thatÃ‚Â publications associated with these affected microarrays have reported disproportionately more biological discoveries on the genes in the contaminated areas compared to other genes. 28.82% of the gene-level conclusions reported in these publications were based on measurements falling into the contaminated area, indicating severe, systematic problems caused by such contaminations. We provided the identified published, problematic datasets, affected genes and the imputed arrays as well as software tools for scanning such contamination that will become essential to future studies to scrutinize and critically analyze microarray data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20943,""
"Genetic variations analysis for complex brain disease diagnosis using machine learning techniques: opportunities and hurdles","Ahmed, Alarabi, El-Sappagh, Soliman, Elmogy","https://doi.org/10.7717/peerj-cs.697","20211008","PubMed","Brain disease; Deep learning; Genetic analysis; Machine learning; Microarrays; Single nucleotide polymorphism (SNP)","This paper presents an in-depth review of the state-of-the-art genetic variations analysis to discover complex genes associated with the brain's genetic disorders. We first introduce the genetic analysis of complex brain diseases, genetic variation, and DNA microarrays. Then, the review focuses on available machine learning methods used for complex brain disease classification. Therein, we discuss the various datasets, preprocessing, feature selection and extraction, and classification strategies. In particular, we concentrate on studying single nucleotide polymorphisms (SNP) that support the highest resolution for genomic fingerprinting for tracking disease genes. Subsequently, the study provides an overview of the applications for some specific diseases, including autism spectrum disorder, brain cancer, and Alzheimer's disease (AD). The study argues that despite the significant recent developments in the analysis and treatment of genetic disorders, there are considerable challenges to elucidate causative mutations, especially from the viewpoint of implementing genetic analysis in clinical practice. The review finally provides a critical discussion on the applicability of genetic variations analysis for complex brain disease identification highlighting the future challenges. We used a methodology for literature surveys to obtain data from academic databases. Criteria were defined for inclusion and exclusion. The selection of articles was followed by three stages. In addition, the principal methods for machine learning to classify the disease were presented in each stage in more detail. It was revealed that machine learning based on SNP was widely utilized to solve problems of genetic variation for complex diseases related to genes. Despite significant developments in genetic diseases in the past two decades of the diagnosis and treatment, there is still a large percentage in which the causative mutation cannot be determined, and a final genetic diagnosis remains elusive. So, we need to detect the variations of the genes related to brain disorders in the early disease stages.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20944,""
"Progress of MRI Radiomics in Hepatocellular Carcinoma","Gong, Tao, Wu, Liu, Yu, Wang, Zheng, Liu, Huang, Li, Yang, Wei, Yang, Zhang","https://doi.org/10.3389/fonc.2021.698373","20211008","PubMed","diagnosis; hepatocellular carcinoma; immune checkpoint inhibitors; intravoxel incoherent motion; magnetic resonance imaging; radiomics; target therapies; therapeutic response","Hepatocellular carcinoma (HCC) is the sixth most common cancer in the world and the third leading cause of cancer-related death. Although the diagnostic scheme of HCC is currently undergoing refinement, the prognosis of HCC is still not satisfactory. In addition to certain factors, such as tumor size and number and vascular invasion displayed on traditional imaging, some histopathological features and gene expression parameters are also important for the prognosis of HCC patients. However, most parameters are based on postoperative pathological examinations, which cannot help with preoperative decision-making. As a new field, radiomics extracts high-throughput imaging data from different types of images to build models and predict clinical outcomes noninvasively before surgery, rendering it a powerful aid for making personalized treatment decisions preoperatively. This study reviewed the workflow of radiomics and the research progress on magnetic resonance imaging (MRI) radiomics in the diagnosis and treatment of HCC. A literature review was conducted by searching PubMed for search of relevant peer-reviewed articles published from May 2017 to June 2021.The search keywords included HCC, MRI, radiomics, deep learning, artificial intelligence, machine learning, neural network, texture analysis, diagnosis, histopathology, microvascular invasion, surgical resection, radiofrequency, recurrence, relapse, transarterial chemoembolization, targeted therapy, immunotherapy, therapeutic response, and prognosis. Radiomics features on MRI can be used as biomarkers to determine the differential diagnosis, histological grade, microvascular invasion status, gene expression status, local and systemic therapeutic responses, and prognosis of HCC patients. Radiomics is a promising new imaging method. MRI radiomics has high application value in the diagnosis and treatment of HCC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20945,""
"Use of Machine Learning and Artificial Intelligence Methods in Geriatric Mental Health Research Involving Electronic Health Record or Administrative Claims Data: A Systematic Review","Chowdhury, Cervantes, Chan, Seitz","https://doi.org/10.3389/fpsyt.2021.738466","20211008","PubMed","administrative health data; artificial intelligence; electronic health records; geriatric; machine learning; mental health","<b>Introduction:</b> Electronic health records (EHR) and administrative healthcare data (AHD) are frequently used in geriatric mental health research to answer various health research questions. However, there is an increasing amount and complexity of data available that may lend itself to alternative analytic approaches using machine learning (ML) or artificial intelligence (AI) methods. We performed a systematic review of the current application of ML or AI approaches to the analysis of EHR and AHD in geriatric mental health. <b>Methods:</b> We searched MEDLINE, Embase, and PsycINFO to identify potential studies. We included all articles that used ML or AI methods on topics related to geriatric mental health utilizing EHR or AHD data. We assessed study quality either by Prediction model Risk OF Bias ASsessment Tool (PROBAST) or Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) checklist. <b>Results:</b> We initially identified 391 articles through an electronic database and reference search, and 21 articles met inclusion criteria. Among the selected studies, EHR was the most used data type, and the datasets were mainly structured. A variety of ML and AI methods were used, with prediction or classification being the main application of ML or AI with the random forest as the most common ML technique. Dementia was the most common mental health condition observed. The relative advantages of ML or AI techniques compared to biostatistical methods were generally not assessed. Only in three studies, low risk of bias (ROB) was observed according to all the PROBAST domains but in none according to QUADAS-2 domains. The quality of study reporting could be further improved. <b>Conclusion:</b> There are currently relatively few studies using ML and AI in geriatric mental health research using EHR and AHD methods, although this field is expanding. Aside from dementia, there are few studies of other geriatric mental health conditions. The lack of consistent information in the selected studies precludes precise comparisons between them. Improving the quality of reporting of ML and AI work in the future would help improve research in the field. Other courses of improvement include using common data models to collect/organize data, and common datasets for ML model validation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20946,""
"A Comprehensive Overview of Technologies for Species and Habitat Monitoring and Conservation","Lahoz-Monfort, Magrath","https://doi.org/10.1093/biosci/biab073","20211008","PubMed","biologging; computing; sensors; telemetry; wildlife monitoring","The range of technologies currently used in biodiversity conservation is staggering, with innovative uses often adopted from other disciplines and being trialed in the field. We provide the first comprehensive overview of the current (2020) landscape of conservation technology, encompassing technologies for monitoring wildlife and habitats, as well as for on-the-ground conservation management (e.g., fighting illegal activities). We cover both established technologies (routinely deployed in conservation, backed by substantial field experience and scientific literature) and novel technologies or technology applications (typically at trial stage, only recently used in conservation), providing examples of conservation applications for both types. We describe technologies that deploy sensors that are fixed or portable, attached to vehicles (terrestrial, aquatic, or airborne) or to animals (biologging), complemented with a section on wildlife tracking. The last two sections cover actuators and computing (including web platforms, algorithms, and artificial intelligence).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20947,""
"End-to-end multimodal clinical depression recognition using deep neural networks: A comparative analysis","Muzammel, Salam, Othmani","https://doi.org/10.1016/j.cmpb.2021.106433","20211028","PubMed","Biomedical informatics; Biomedical information processing; Deep learning; Features fusion; Multimodal depression recognition; Depression; Depressive Disorder, Major; Humans; Neural Networks, Computer","Major Depressive Disorder is a highly prevalent and disabling mental health condition. Numerous studies explored multimodal fusion systems combining visual, audio, and textual features via deep learning architectures for clinical depression recognition. Yet, no comparative analysis for multimodal depression analysis has been proposed in the literature. In this paper, an up-to-date literature overview of multimodal depression recognition is presented and an extensive comparative analysis of different deep learning architectures for depression recognition is performed. First, audio features based Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) are studied. Then, early-level and model-level fusion of deep audio features with visual and textual features through LSTM and CNN architectures are investigated. The performance of the proposed architectures using an hold-out strategy on the DAIC-WOZ dataset (80% training, 10% validation, 10% test split) for binary and severity levels of depression recognition is tested. Using this strategy, a set of experiments have been performed and they have demonstrated: (1) LSTM-based audio features perform slightly better than CNN ones with an accuracy of 66.25% versus 65.60% for binary depression classes. (2) the model level fusion of deep audio and visual features using LSTM network performed the best with an accuracy of 77.16%, a precision of 53% for the depressed class, and a precision of 83% for the non-depressed class. The given network obtained a normalized Root Mean Square Error (RMSE) of 0.15 for depression severity level prediction. Using a Leave-One-Subject-Out strategy, this network achieved an accuracy of 95.38% for binary depression detection, and a normalized RMSE of 0.1476 for depression severity level prediction. Our best-performing architecture outperforms all state-of-the-art approaches on DAIC-WOZ dataset. The obtained results show that the proposed LSTM-based surpass the proposed CNN-based architectures allowing to learn temporal dynamics representations of multimodal features. Furthermore, model-level fusion of audio and visual features using an LSTM network leads to the best performance. Our best-performing architecture successfully detects depression using a speech segment of less than 8 seconds, and an average prediction computation time of less than 6ms; making it suitable for real-world clinical applications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20948,""
"The messiness of the menstruator: assessing personas and functionalities of menstrual tracking apps","Pichon, Jackman, Winkler, Bobel, Elhadad","https://doi.org/10.1093/jamia/ocab212","20211013","PubMed","menstrual tracking; menstruation; mobile health; personal health informatics","The aim of this study was to examine trends in the intended users and functionalities advertised by menstrual tracking apps to identify gaps in personas and intended needs fulfilled by these technologies. Two types of materials were collected: a corpus of scientific articles related to the identities and needs of menstruators and a corpus of images and descriptions of menstrual tracking apps collected from the Google and Apple app stores. We conducted a scoping review of the literature to develop themes and then applied these as a framework to analyze the app corpus, looking for alignments and misalignments between the 2 corpora. A review of the literature showed a wide range of disciplines publishing work relevant to menstruators. We identified 2 broad themes: ""who are menstruators?"" and ""what are the needs of menstruators?"" Descriptions of menstrual trackers exhibited misalignments with these themes, with narrow characterizations of menstruators and design for limited needs. We synthesize gaps in the design of menstrual tracking apps and discuss implications for designing around: (1) an irregular menstrual cycle as the norm; (2) the embodied, leaky experience of menstruation; and (3) the varied biologies, identities, and goals of menstruators. An overarching gap suggests a need for a human-centered artificial intelligence approach for model and data provenance, transparency and explanations of uncertainties, and the prioritization of privacy in menstrual trackers. Comparing and contrasting literature about menstruators and descriptions of menstrual tracking apps provide a valuable guide to assess menstrual technology and their responsiveness to users and their needs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20949,""
"Coal and gangue identification method based on the intensity image of lidar and DenseNet","Xing, Zhao, Wang, Nie, Du","https://doi.org/10.1364/AO.422498","20211007","PubMed","","Coal and gangue (rock) identification is the essential process in a coal preparation plant. In an actual coal preparation plant, the existing classification methods have many disadvantages in safety and identification rate. We utilized the echo intensity image (EII) of lidar for coal and gangue identification for the first time, to the best of our knowledge, and achieved outstanding recognition results with a convolutional neural network. First, we acquire the information of the 3D point cloud, including the distance and the echo intensity, and decompose them into two channels. Then, we utilize the distance channel to remove the background noises and separate the object and the echo intensity channel to construct the 2D EII. Finally, we prune the dense convolutional network (DenseNet-121) to DenseNet-40 for the real-time identification and compare its F1 score with the other two traditional recognition algorithms. The experiment shows that the F1 score of the DenseNet-40 is up to 0.96, which indicates the DenseNet-40 is provably higher than other traditional algorithms in accuracy. Through trial and error, we find that the echo intensity of lidar can clearly show the texture information of coal and gangue. After combining with the DenseNet-40, it has more benefits than the existing classification methods in accuracy, efficiency, and robustness.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20950,""
"Accelerating the Appropriate Adoption of Artificial Intelligence in Health Care: Protocol for a Multistepped Approach","Wiljer, Salhia, Dolatabadi, Dhalla, Gillan, Al-Mouaswas, Jackson, Waldorf, Mattson, Clare, Lalani, Charow, Balakumar, Younus, Jeyakumar, Peteanu, Tavares","https://doi.org/10.2196/30940","20211007","PubMed","adoption; artificial intelligence; education; health care providers; learning; mHealth; patient care","Significant investments and advances in health care technologies and practices have created a need for digital and data-literate health care providers. Artificial intelligence (AI) algorithms transform the analysis, diagnosis, and treatment of medical conditions. Complex and massive data sets are informing significant health care decisions and clinical practices. The ability to read, manage, and interpret large data sets to provide data-driven care and to protect patient privacy are increasingly critical skills for today's health care providers. The aim of this study is to accelerate the appropriate adoption of data-driven and AI-enhanced care by focusing on the mindsets, skillsets, and toolsets of point-of-care health providers and their leaders in the health system. To accelerate the adoption of AI and the need for organizational change at a national level, our multistepped approach includes creating awareness and capacity building, learning through innovation and adoption, developing appropriate and strategic partnerships, and building effective knowledge exchange initiatives. Education interventions designed to adapt knowledge to the local context and address any challenges to knowledge use include engagement activities to increase awareness, educational curricula for health care providers and leaders, and the development of a coaching and practice-based innovation hub. Framed by the Knowledge-to-Action framework, we are currently in the knowledge creation stage to inform the curricula for each deliverable. An environmental scan and scoping review were conducted to understand the current state of AI education programs as reported in the academic literature. The environmental scan identified 24 AI-accredited programs specific to health providers, of which 11 were from the United States, 6 from Canada, 4 from the United Kingdom, and 3 from Asian countries. The most common curriculum topics across the environmental scan and scoping review included AI fundamentals, applications of AI, applied machine learning in health care, ethics, data science, and challenges to and opportunities for using AI. Technologies are advancing more rapidly than organizations, and professionals can adopt and adapt to them. To help shape AI practices, health care providers must have the skills and abilities to initiate change and shape the future of their discipline and practices for advancing high-quality care within the digital ecosystem. PRR1-10.2196/30940.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20951,""
"Radiology Implementation Considerations for Artificial Intelligence (AI) Applied to COVID-19, From the <i>AJR</i> Special Series on AI Applications","Li, Chang, Mei, Bernheim, Chung, Steinberger, Kalpathy-Cramer, Little","https://doi.org/10.2214/AJR.21.26717","20211006","PubMed","","Hundreds of imaging-based artificial intelligence (AI) models have been developed in response to the COVID-19 pandemic. AI systems that incorporate imaging have shown promise in primary detection, severity grading, and prognostication of outcomes in COVID-19, and have enabled integration of imaging with a broad range of additional clinical and epidemiologic data. However, systematic reviews of AI models applied to COVID-19 medical imaging have highlighted problems in the field, including methodologic issues and problems in real-world deployment. Clinical use of such models should be informed by both the promise and potential pitfalls of implementation. How does a practicing radiologist make sense of this complex topic, and what factors should be considered in the implementation of AI tools for imaging of COVID-19? This critical review aims to help the radiologist understand the nuances that impact the clinical deployment of AI for imaging of COVID-19. We review imaging use cases for AI models in COVID-19 (e.g., diagnosis, severity assessment, and prognostication) and explore considerations for AI model development and testing, deployment infrastructure, clinical user interfaces, quality control, and institutional review board and regulatory approvals, with a practical focus on what a radiologist should consider when implementing an AI tool for COVID-19.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20952,""
"Predicting Sarcopenia of Female Elderly from Physical Activity Performance Measurement Using Machine Learning Classifiers","Ko, Kim, Shin, Han, Han, Jung, Hong","https://doi.org/10.2147/CIA.S323761","20211008","PubMed","inertial measurement unit; machine learning; physical activity; sarcopenia","Sarcopenia is a symptom in which muscle mass decreases due to decreasing in the number of muscle fibers and muscle cross-sectional area as aging. This study aimed to develop a machine learning classification model for predicting sarcopenia through a inertial measurement unit (IMU)-based physical performance measurement data of female elderly. Seventy-eight female subjects from an elderly population (aged: 78.8Ã‚Â±5.7 years) volunteered to participate in this study. To evaluate the physical performance of the elderly, the experiment conducted timed-up-and-go test (TUG) and 6-minute walk test (6mWT) with worn a single IMU. Based on literature review, 132 features were extracted from collected data. Feature selection was performed through the Kruskal-Wallis test, and features datasets were constructed according to feature selection. Three major machine learning-based classification algorithms classified the sarcopenia group in each dataset, and the performance of classification models was compared. As a result of comparing the classification model performance for sarcopenia prediction, the k-nearest neighborhood algorithm (kNN) classification model using 40 major features of TUG and 6mWT showed the best performance at 88%. This study can be used as a basic research for the development of self-monitoring technology for sarcopenia.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20953,""
"Emerging Technologies in the Treatment of Adult Spinal Deformity","Patel, White, Schwartz, Pitaro, Shah, Singh, Arvind, Kim, Cho","https://doi.org/10.14245/ns.2142412.206","20211016","PubMed","Artificial intelligence; Machine learning; Robot; Rods; Spine surgery","Outcomes for adult spinal deformity continue to improve as new technologies become integrated into clinical practice. Machine learning, robot-guided spinal surgery, and patientspecific rods are tools that are being used to improve preoperative planning and patient satisfaction. Machine learning can be used to predict complications, readmissions, and generate postoperative radiographs which can be shown to patients to guide discussions about surgery. Robot-guided spinal surgery is a rapidly growing field showing signs of greater accuracy in screw placement during surgery. Patient-specific rods offer improved outcomes through higher correction rates and decreased rates of rod breakage while decreasing operative time. The objective of this review is to evaluate trends in the literature about machine learning, robot-guided spinal surgery, and patient-specific rods in the treatment of adult spinal deformity.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20954,""
"Computational simulations to dissect the cell immune response dynamics for severe and critical cases of SARS-CoV-2 infection","Blanco-RodrÃƒÂ­guez, Du, HernÃƒÂ¡ndez-Vargas","https://doi.org/10.1016/j.cmpb.2021.106412","20211028","PubMed","COVID-19; Disease severity; Immune response; Mathematical modeling; ODEs; SARS-CoV-2; CD8-Positive T-Lymphocytes; COVID-19; Humans; Immunity; Pandemics; SARS-CoV-2","COVID-19 is a global pandemic leading to high death tolls worldwide day by day. Clinical evidence suggests that COVID-19 patients can be classified as non-severe, severe, and critical cases. In particular, studies have highlighted the relationship between lymphopenia and the severity of the illness, where CD8<sup>+</sup> T cells have the lowest levels in critical cases. However, a quantitative understanding of the immune responses in COVID-19 patients is still missing. In this work, we aim to elucidate the key parameters that define the course of the disease deviating from severe to critical cases. The dynamics of different immune cells are taken into account in mechanistic models to elucidate those that contribute to the worsening of the disease. Several mathematical models based on ordinary differential equations are proposed to represent data sets of different immune response cells dynamics such as CD8<sup>+</sup> T cells, NK cells, and also CD4<sup>+</sup> T cells in patients with SARS-CoV-2 infection. Parameter fitting is performed using the differential evolution algorithm. Non-parametric bootstrap approach is introduced to abstract the stochastic environment of the infection. The mathematical model that represents the data more appropriately is considering CD8<sup>+</sup> T cell dynamics. This model had a good fit to reported experimental data, and in accordance with values found in the literature. The NK cells and CD4<sup>+</sup> T cells did not contribute enough to explain the dynamics of the immune responses. Our computational results highlight that a low viral clearance rate by CD8<sup>+</sup> T cells could lead to the severity of the disease. This deregulated clearance suggests that it is necessary immunomodulatory strategies during the course of the infection to avoid critical states in COVID-19 patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20955,""
"Machine learning in orthodontics: Challenges and perspectives","Liu, Chen, Li, Zhao, Wu","https://doi.org/10.17219/acem/138702","20211102","PubMed","artificial intelligence (AI); convolutional neural network (CNN); machine learning; neural network; orthodontics; Artificial Intelligence; Humans; Machine Learning; Orthodontics; Quality of Life; Reproducibility of Results","Artificial intelligence (AI) applications have significantly improved our everyday quality of life. The last decade has witnessed the emergence of up-and-coming applications in the field of dentistry. It is hopeful that AI, especially machine learning (ML), due to its powerful capacity for image processing and decision support systems, will find extensive application in orthodontics in the future. We performed a comprehensive literature review of the latest studies on the application of ML in orthodontic procedures, including diagnosis, decision-making and treatment. Machine learning models have been found to perform similar to or with even higher accuracy than humans in landmark identification, skeletal classification, bone age prediction, and tooth segmentation. Meanwhile, compared to human experts, ML algorithms allow for high agreement and stability in orthodontic decision-making procedures and treatment effect evaluation. However, current research on ML raises important questions regarding its interpretability and dataset sample reliability. Therefore, more collaboration between orthodontic professionals and technicians is urged to achieve a positive symbiosis between AI and the clinic.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20956,""
"Precise Modulation Strategies for Transcranial Magnetic Stimulation: Advances and Future Directions","Zhong, Yang, Jiang","https://doi.org/10.1007/s12264-021-00781-x","20211102","PubMed","Coil location; Individual treatment paradigm; Modulation strategies; Precise stimulation target; Transcranial magnetic stimulation","Transcranial magnetic stimulation (TMS) is a popular modulatory technique for the noninvasive diagnosis and therapy of neurological and psychiatric diseases. Unfortunately, current modulation strategies are only modestly effective. The literature provides strong evidence that the modulatory effects of TMS vary depending on device components and stimulation protocols. These differential effects are important when designing precise modulatory strategies for clinical or research applications. Developments in TMS have been accompanied by advances in combining TMS with neuroimaging techniques, including electroencephalography, functional near-infrared spectroscopy, functional magnetic resonance imaging, and positron emission tomography. Such studies appear particularly promising as they may not only allow us to probe affected brain areas during TMS but also seem to predict underlying research directions that may enable us to precisely target and remodel impaired cortices or circuits. However, few precise modulation strategies are available, and the long-term safety and efficacy of these strategies need to be confirmed. Here, we review the literature on possible technologies for precise modulation to highlight progress along with limitations with the goal of suggesting future directions for this field.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20957,""
"Association between human coronaviruses' epidemic and environmental factors on a global scale","Yan, Wang, Wang, Zhang, Wang, Lu, Jia","https://doi.org/10.1007/s11356-021-16500-y","20211008","PubMed","Environmental factor; Epidemic; Global health; Human coronavirus; Meteorological factor; One health; Vegetation coverage","Environmental factors could influence the epidemic of virus in human; however, the association remains intricate, and the evidence is still not clear in human coronaviruses (HCoVs). We aimed to explore and compare the associations between HCoVs' epidemic and environmental factors globally. Four common HCoVs' data were collected by a systematic literature review, and data of MERS, SARS, and COVID-19 were collected from the World Health Organization's reports. Monthly positive rates of common HCoVs and incidence rates of MERS, SARS, and COVID-19 were calculated. Geographical coordinates were used to link virus data and environmental data. Generalized additive models (GAMs) were used to quantitatively estimate the association of environmental factors with HCoVs' epidemic. We found that there are wide associations between HCoVs and environmental factors on a global scale, and some of the associations were nonlinear. In addition, COVID-19 has the most similarities in associations' direction with common HCoVs, especially for HCoV-HKU1 in four environmental factors including the significantly negative associations with average temperature, precipitation, vegetation coverage (p&lt;0.05), and the U-shaped association with temperature range. This study strengthened the relevant research evidences and provided significant insights into the epidemic rules of HCoVs in general. The similarities between COVID-19 and common HCoVs indicated that it is critically important to strengthen surveillance on common HCoVs and pay more attention to environmental factors' role in surveillance and early warning of HCoVs' epidemic.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20958,""
"Water treatment and artificial intelligence techniques: a systematic literature review research","Ismail, Niknejad, Bahari, Hendradi, Zaizi, Zulkifli","https://doi.org/10.1007/s11356-021-16471-0","20211005","PubMed","Artificial intelligence; Literature review; Water quality; Water treatment","As clean water can be considered among the essentials of human life, there is always a requirement to seek its foremost and high quality. Water primarily becomes polluted due to organic as well as inorganic pollutants, including nutrients, heavy metals, and constant contamination with organic materials. Predicting the quality of water accurately is essential for its better management along with controlling pollution. With stricter laws regarding water treatment to remove organic and biologic materials along with different pollutants, looking for novel technologic procedures will be necessary for improved control of the treatment processes by water utilities. Linear regression-based models with relative simplicity considering water prediction have been typically used as available statistical models. Nevertheless, in a majority of real problems, particularly those associated with modeling of water quality, non-linear patterns will be observed, requiring non-linear models to address them. Thus, artificial intelligence (AI) can be a good candidate in modeling and optimizing the elimination of pollutants from water in empirical settings with the ability to generate ideal operational variables, due to its recent considerable advancements. Management and operation of water treatment procedures are supported technically by these technologies, leading to higher efficiency compared to sole dependence on human operations. Thus, establishing predictive models for water quality and subsequently, more efficient management of water resources would be critically important, serving as a strong tool. A systematic review methodology has been employed in the present work to investigate the previous studies over the time interval of 2010-2020, while analyzing and synthesizing the literature, particularly regarding AI application in water treatment. A total number of 92 articles had addressed the topic under study using AI. Based on the conclusions, the application of AI can obviously facilitate operations, process automation, and management of water resources in significantly volatile contexts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20959,""
"Prediction of incident atrial fibrillation in community-based electronic health records: a systematic review with meta-analysis","Nadarajah, Alsaeed, Hurdus, Aktaa, Hogg, Bates, Cowan, Wu, Gale","https://doi.org/10.1136/heartjnl-2021-320036","20211005","PubMed","atrial fibrillation; electronic health records; meta-analysis; primary care","Atrial fibrillation (AF) is common and is associated with an increased risk of stroke. We aimed to systematically review and meta-analyse multivariable prediction models derived and/or validated in electronic health records (EHRs) and/or administrative claims databases for the prediction of incident AF in the community. Ovid Medline and Ovid Embase were searched for records from inception to 23 March 2021. Measures of discrimination were extracted and pooled by Bayesian meta-analysis, with heterogeneity assessed through a 95% prediction interval (PI). Risk of bias was assessed using Prediction model Risk Of Bias ASsessment Tool and certainty in effect estimates by Grading of Recommendations, Assessment, Development and Evaluation. Eleven studies met inclusion criteria, describing nine prediction models, with four eligible for meta-analysis including 9 289 959 patients. The CHADS (Congestive heart failure, Hypertension, Age&gt;75, Diabetes mellitus, prior Stroke or transient ischemic attack) (summary c-statistic 0.674; 95% CI 0.610 to 0.732; 95% PI 0.526-0.815), CHA<sub>2</sub>DS<sub>2</sub>-VASc (Congestive heart failure, Hypertension, Age&gt;75 (2 points), Stroke/transient ischemic attack/thromboembolism (2 points), Vascular disease, Age 65-74, Sex category) (summary c-statistic 0.679; 95% CI 0.620 to 0.736; 95% PI 0.531-0.811) and HATCH (Hypertension, Age, stroke or Transient ischemic attack, Chronic obstructive pulmonary disease, Heart failure) (summary c-statistic 0.669; 95% CI 0.600 to 0.732; 95% PI 0.513-0.803) models resulted in a c-statistic with a statistically significant 95% PI and moderate discriminative performance. No model met eligibility for inclusion in meta-analysis if studies at high risk of bias were excluded and certainty of effect estimates was 'low'. Models derived by machine learning demonstrated strong discriminative performance, but lacked rigorous external validation. Models externally validated for prediction of incident AF in community-based EHR demonstrate moderate predictive ability and high risk of bias. Novel methods may provide stronger discriminative performance. PROSPERO CRD42021245093.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20960,""
"Artificial Intelligence Applications and Cataract Management: A Systematic Review","Tognetto, Giglio, Vinciguerra, Milan, Rejdak, Rejdak, Zaluska-Ogryzek, Zweifel, Toro","https://doi.org/10.1016/j.survophthal.2021.09.004","20211004","PubMed","artificial intelligence; cataract management; complications; diagnosis; intraocular lens calculation; surgery","Artificial intelligence (AI)-based applications exhibit the potential to improve the quality and efficiency of patient care in different fields, including cataract management. A systematic review of the different applications of AI-based software on all aspects of a cataract patient's management, from diagnosis to follow-up, was carried out in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. All selected articles were analyzed to assess the level of evidence according to the Oxford Centre for Evidence-Based Medicine (OCEM) 2011 guidelines, and the quality of evidence according to the Grading of Recommendations Assessment, Development and Evaluation (GRADE) system. Of the articles analyzed, 49 met the inclusion criteria. No data synthesis was possible for the heterogeneity of available data and the design of the available studies. The AI-driven diagnosis seemed to be comparable and, in selected cases, to even exceed the accuracy of experienced clinicians in classifying disease, supporting the operating room scheduling, and intraoperative and postoperative management of complications. Considering the heterogeneity of data analyzed, however, further randomized controlled trials (RCTs) to assess the efficacy and safety of AI application in the management of cataract should be highly warranted.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20961,""
"The neurogenic dysphagia management via telemedicine: a systematic review","Reverberi, Gottardo, Battel, Castagnetti","https://doi.org/10.23736/S1973-9087.21.06921-5","20211004","PubMed","","Telerehabilitation is the provision of rehabilitation remotely through Information and Communication Technologies (ICT). Recently, there has been an increase of interest in its application thanks to increasing a new technology. The aim of this systematic review was to examine the evidence of the literature regarding the management of neurogenic dysphagia via telerehabilitation, compared to face-to-face rehabilitation treatment. The secondary aim was to create recommendations on telerehabilitation sessions for patients diagnosed with neurogenic dysphagia. The databases were: Medline, Embase, Cinahl, Scopus. A total of 235 records emerged from bibliographic research, manual search of full text and from gray literature, published until January 2021. Two blinded authors carried out titles and abstract screening and followed by full-text analysis. 16 articles were included in the systematic review and assessed through critical appraisal tools. The research shows that the majority of the studies on neurogenic dysphagia involved the Clinical Swallow Examination via telerehabilitation, compared with the inperson modality. Significant levels of agreement and high satisfaction from clinicians and patients are reported to support the use of telerehabilitation. Based on the results of this systematic review and qualitative analysis, the authors developed practical recommendations for the management of telerehabilitation sessions for patients with neurogenic dysphagia. Despite the presence of barriers, telerehabilitation allowed healthcare provision and increasing access to care and services with specialized professionals, remote rehabilitation can be a valid resource during the health emergency due to COVID-19.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20962,""
"Deep learning analysis of resting electrocardiograms for the detection of myocardial dysfunction, hypertrophy, and ischaemia: a systematic review","Al Hinai, Jammoul, Vajihi, Afilalo","https://doi.org/10.1093/ehjdh/ztab048","20211005","PubMed","Artificial intelligence; Coronary artery disease; Deep learning; Electrocardiogram; Heart failure; Left ventricular hypertrophy; Myocardial infarction","The aim of this review was to assess the evidence for deep learning (DL) analysis of resting electrocardiograms (ECGs) to predict structural cardiac pathologies such as left ventricular (LV) systolic dysfunction, myocardial hypertrophy, and ischaemic heart disease. A systematic literature search was conducted to identify published original articles on end-to-end DL analysis of resting ECG signals for the detection of structural cardiac pathologies. Studies were excluded if the ECG was acquired by ambulatory, stress, intracardiac, or implantable devices, and if the pathology of interest was arrhythmic in nature. After duplicate reviewers screened search results, 12 articles met the inclusion criteria and were included. Three articles used DL to detect LV systolic dysfunction, achieving an area under the curve (AUC) of 0.89-0.93 and an accuracy of 98%. One study used DL to detect LV hypertrophy, achieving an AUC of 0.87 and an accuracy of 87%. Six articles used DL to detect acute myocardial infarction, achieving an AUC of 0.88-1.00 and an accuracy of 83-99.9%. Two articles used DL to detect stable ischaemic heart disease, achieving an accuracy of 95-99.9%. Deep learning models, particularly those that used convolutional neural networks, outperformed rules-based models and other machine learning models. Deep learning is a promising technique to analyse resting ECG signals for the detection of structural cardiac pathologies, which has clinical applicability for more effective screening of asymptomatic populations and expedited diagnostic work-up of symptomatic patients at risk for cardiovascular disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20963,""
"A natural language processing pipeline to synthesize patient-generated notes toward improving remote care and chronic disease management: a cystic fibrosis case study","Hussain, Sezgin, Krivchenia, Luna, Rust, Huang","https://doi.org/10.1093/jamiaopen/ooab084","20211005","PubMed","artificial intelligence; chronic disease; cystic fibrosis; natural language processing; patient notes","Patient-generated health data (PGHD) are important for tracking and monitoring out of clinic health events and supporting shared clinical decisions. Unstructured text as PGHD (eg, medical diary notes and transcriptions) may encapsulate rich information through narratives which can be critical to better understand a patient's condition. We propose a natural language processing (NLP) supported data synthesis pipeline for unstructured PGHD, focusing on children with special healthcare needs (CSHCN), and demonstrate it with a case study on cystic fibrosis (CF). The proposed unstructured data synthesis and information extraction pipeline extract a broad range of health information by combining rule-based approaches with pretrained deep-learning models. Particularly, we build upon the scispaCy biomedical model suite, leveraging its named entity recognition capabilities to identify and link clinically relevant entities to established ontologies such as Systematized Nomenclature of Medicine (SNOMED) and RXNORM. We then use scispaCy's syntax (grammar) parsing tools to retrieve phrases associated with the entities in medication, dose, therapies, symptoms, bowel movements, and nutrition ontological categories. The pipeline is illustrated and tested with simulated CF patient notes. The proposed hybrid deep-learning rule-based approach can operate over a variety of natural language note types and allow customization for a given patient or cohort. Viable information was successfully extracted from simulated CF notes. This hybrid pipeline is robust to misspellings and varied word representations and can be tailored to accommodate the needs of a specific patient, cohort, or clinician. The NLP pipeline can extract predefined or ontology-based entities from free-text PGHD, aiming to facilitate remote care and improve chronic disease management. Our implementation makes use of open source models, allowing for this solution to be easily replicated and integrated in different health systems. Outside of the clinic, the use of the NLP pipeline may increase the amount of clinical data recorded by families of CSHCN and ease the process to identify health events from the notes. Similarly, care coordinators, nurses and clinicians would be able to track adherence with medications, identify symptoms, and effectively intervene to improve clinical care. Furthermore, visualization tools can be applied to digest the structured data produced by the pipeline in support of the decision-making process for a patient, caregiver, or provider. Our study demonstrated that an NLP pipeline can be used to create an automated analysis and reporting mechanism for unstructured PGHD. Further studies are suggested with real-world data to assess pipeline performance and further implications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20964,""
"Defining and measuring microservice granularity-a literature overview","Vera-Rivera, Gaona, Astudillo","https://doi.org/10.7717/peerj-cs.695","20211004","PubMed","Metrics; Micro service architecture; Micro-service granularity; Microservices decomposition; Monolith to microservices; Quality attributtes; Service computing; Sistematic literature review","Microservices are an architectural approach of growing use, and the optimal granularity of a microservice directly affects the application's quality attributes and usage of computational resources. Determining microservice granularity is an open research topic. We conducted a systematic literature review to analyze literature that addresses the definition of microservice granularity. We searched in IEEE Xplore, ACM Digital Library and Scopus. The research questions were: Which approaches have been proposed to define microservice granularity and determine the microservices' size? Which metrics are used to evaluate microservice granularity? Which quality attributes are addressed when researching microservice granularity? We found 326 papers and selected 29 after applying inclusion and exclusion criteria. The quality attributes most often addressed are runtime properties (<i>e.g.</i>, scalability and performance), not development properties (<i>e.g.</i>, maintainability). Most proposed metrics were about the product, both static (coupling, cohesion, complexity, source code) and runtime (performance, and usage of computational resources), and a few were about the development team and process. The most used techniques for defining microservices granularity were machine learning (clustering), semantic similarity, genetic programming, and domain engineering. Most papers were concerned with migration from monoliths to microservices; and a few addressed green-field development, but none address improvement of granularity in existing microservice-based systems. Methodologically speaking, microservice granularity research is at a Wild West stage: no standard definition, no clear development-operation trade-offs, and scarce conceptual reuse (<i>e.g</i>., few methods seem applicable or replicable in projects other than their initial proposal). These gaps in granularity research offer clear options to investigate on continuous improvement of the development and operation of microservice-based systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20965,""
"Artificial intelligence and abdominal adipose tissue analysis: a literature review","Greco, Mallio","https://doi.org/10.21037/qims-21-370","20211005","PubMed","Obesity; artificial intelligence (AI); deep learning; machine learning; visceral adiposity","Body composition imaging relies on assessment of tissues composition and distribution. Quantitative data provided by body composition imaging analysis have been linked to pathogenesis, risk, and clinical outcomes of a wide spectrum of diseases, including cardiovascular and oncologic. Manual segmentation of imaging data allows to obtain information on abdominal adipose tissue; however, this procedure can be cumbersome and time-consuming. On the other hand, quantitative imaging analysis based on artificial intelligence (AI) has been proposed as a fast and reliable automatic technique for segmentation of abdominal adipose tissue compartments, possibly improving the current standard of care. AI holds the potential to extract quantitative data from computed tomography (CT) and magnetic resonance (MR) images, which in most of the cases are acquired for other purposes. This information is of great importance for physicians dealing with a wide spectrum of diseases, including cardiovascular and oncologic, for the assessment of risk, pathogenesis, clinical outcomes, response to treatments, and complications. In this review we summarize the available evidence on AI algorithms aimed to the segmentation of visceral and subcutaneous adipose tissue compartments on CT and MR images.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20966,""
"Challenges Faced by Clinicians in the Personalized Treatment Planning: A Literature Review and the First Results of the Russian National Cancer Program","Shegai, Shatalov, Zabolotneva, Falaleeva, Ivanov, Kaprin","https://doi.org/10.1155/2021/6649771","20211005","PubMed","","Advances in cancer molecular profiling have enabled the development of more effective approaches to the diagnosis and personalized treatment of tumors. However, treatment planning has become more labor intensive, requiring hours or even days of clinician effort to optimize an individual patient case in a trial-and-error manner. Lessons learned from the world cancer programs provide insights into ways to develop approaches for the treatment strategy definition which can be introduced into clinical practice. This article highlights the variety of breakthroughs in patients' cancer treatment and some challenges that this field faces now in Russia. In this report, we consider the key characteristics for planning an optimal clinical treatment regimen and which should be included in the algorithm of clinical decision support systems. We discuss the perspectives of implementing artificial intelligence-based systems in cancer treatment planning in Russia.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20967,""
"A Method of CT Image Denoising Based on Residual Encoder-Decoder Network","Liu","https://doi.org/10.1155/2021/2384493","20211029","PubMed","","Low-dose computed tomography (CT) has proved effective in lowering radiation risk for the patients, but the resultant noise and bar artifacts in CT images can be a disturbance for medical diagnosis. The difficulty of modeling statistical features in the image domain makes it impossible for the existing methods that directly process reconstructed images to maintain the detailed texture structure of images while reducing noise, which accounts for the failure in CT diagnostic images in practical application. To overcome this defect, this paper proposes a CT image-denoising method based on an improved residual encoder-decoder network. Firstly, in our approach, the notion of recursion is integrated into the original residual encoder-decoder network to lower the algorithm complexity and boost efficiency in image denoising. The original CT images and the postrecursion result graph output after recursion are used as the input for the next recursion simultaneously, and the shallow encoder-decoder network is recycled. Secondly, the root-mean-square error loss function and perceptual loss function are introduced to ensure the texture of denoised CT images. On this basis, the tissue processing technology based on clustering segmentation is optimized considering that the images after improved RED-CNN training will still have certain artifacts. Finally, the experimental results of the TCGA-COAD clinical data set show that under the same experimental conditions, our method outperforms WGAN in average postdenoising PSNR and SSIM of CT images. Moreover, with a lower algorithm complexity and shorter execution time, our method is a significant improvement on RED-CNN and is applicable for actual scenarios.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20968,""
"Medical Text Classification Using Hybrid Deep Learning Models with Multihead Attention","Prabhakar, Won","https://doi.org/10.1155/2021/9425655","20211005","PubMed","Attention; Deep Learning; Humans; Machine Learning; Natural Language Processing; Neural Networks, Computer","To unlock information present in clinical description, automatic medical text classification is highly useful in the arena of natural language processing (NLP). For medical text classification tasks, machine learning techniques seem to be quite effective; however, it requires extensive effort from human side, so that the labeled training data can be created. For clinical and translational research, a huge quantity of detailed patient information, such as disease status, lab tests, medication history, side effects, and treatment outcomes, has been collected in an electronic format, and it serves as a valuable data source for further analysis. Therefore, a huge quantity of detailed patient information is present in the medical text, and it is quite a huge challenge to process it efficiently. In this work, a medical text classification paradigm, using two novel deep learning architectures, is proposed to mitigate the human efforts. The first approach is that a quad channel hybrid long short-term memory (QC-LSTM) deep learning model is implemented utilizing four channels, and the second approach is that a hybrid bidirectional gated recurrent unit (BiGRU) deep learning model with multihead attention is developed and implemented successfully. The proposed methodology is validated on two medical text datasets, and a comprehensive analysis is conducted. The best results in terms of classification accuracy of 96.72% is obtained with the proposed QC-LSTM deep learning model, and a classification accuracy of 95.76% is obtained with the proposed hybrid BiGRU deep learning model.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20969,""
"A Systematic Review of Artificial Intelligence Techniques in Cancer Prediction and Diagnosis","Kumar, Gupta, Singla, Hu","https://doi.org/10.1007/s11831-021-09648-w","20211005","PubMed","","Artificial intelligence has aided in the advancement of healthcare research. The availability of open-source healthcare statistics has prompted researchers to create applications that aid cancer detection and prognosis. Deep learning and machine learning models provide a reliable, rapid, and effective solution to deal with such challenging diseases in these circumstances. PRISMA guidelines had been used to select the articles published on the web of science, EBSCO, and EMBASE between 2009 and 2021. In this study, we performed an efficient search and included the research articles that employed AI-based learning approaches for cancer prediction. A total of 185 papers are considered impactful for cancer prediction using conventional machine and deep learning-based classifications. In addition, the survey also deliberated the work done by the different researchers and highlighted the limitations of the existing literature, and performed the comparison using various parameters such as prediction rate, accuracy, sensitivity, specificity, dice score, detection rate, area undercover, precision, recall, and F1-score. Five investigations have been designed, and solutions to those were explored. Although multiple techniques recommended in the literature have achieved great prediction results, still cancer mortality has not been reduced. Thus, more extensive research to deal with the challenges in the area of cancer prediction is required.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20970,""
"Wearable inertial sensors for human movement analysis: a five-year update","Picerno, Iosa, D'Souza, Benedetti, Paolucci, Morone","https://doi.org/10.1080/17434440.2021.1988849","20211012","PubMed","Accelerometry; activity monitoring; biomechanics; ergonomics; gait analysis; kinematics; mHealth; motion analysis; motor assessment; rehabilitation; remote monitoring; telerehabilitation","The aim of the present review is to track the evolution of wearable IMUs from their use in supervised laboratory- and ambulatory-based settings to their application for long-term monitoring of human movement in unsupervised naturalistic settings. Four main emerging areas of application were identified and synthesized, namely, mobile health solutions (specifically, for the assessment of frailty, risk of falls, chronic neurological diseases, and for the monitoring and promotion of active living), occupational ergonomics, rehabilitation and telerehabilitation, and cognitive assessment. Findings from recent scientific literature in each of these areas was synthesized from an applied and/or clinical perspective with the purpose of providing clinical researchers and practitioners with practical guidance on contemporary uses of inertial sensors in applied clinical settings. IMU-based wearable devices have undergone a rapid transition from use in laboratory-based clinical practice to unsupervised, applied settings. Successful use of wearable inertial sensing for assessing mobility, motor performance and movement disorders in applied settings will rely also on machine learning algorithms for managing the vast amounts of data generated by these sensors for extracting information that is both clinically relevant and interpretable by practitioners.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20971,""
"A scoping review of artificial intelligence applications in thoracic surgery","Seastedt, Moukheiber, Mahindre, Thammineni, Rosen, Watkins, Hashimoto, Hoang, Kpodonu, Celi","https://doi.org/10.1093/ejcts/ezab422","20211003","PubMed","Algorithm; Artificial intelligence; Complications; Machine learning; Prediction; Survival","Machine learning (ML) has great potential, but there are few examples of its implementation improving outcomes. The thoracic surgeon must be aware of pertinent ML literature and how to evaluate this field for the safe translation to patient care. This scoping review provides an introduction to ML applications specific to the thoracic surgeon. We review current applications, limitations and future directions. A search of the PubMed database was conducted with inclusion requirements being the use of an ML algorithm to analyse patient information relevant to a thoracic surgeon and contain sufficient details on the data used, ML methods and results. Twenty-two papers met the criteria and were reviewed using a methodological quality rubric. ML demonstrated enhanced preoperative test accuracy, earlier pathological diagnosis, therapies to maximize survival and predictions of adverse events and survival after surgery. However, only 4 performed external validation. One demonstrated improved patient outcomes, nearly all failed to perform model calibration and one addressed fairness and bias with most not generalizable to different populations. There was a considerable variation to allow for reproducibility. There is promise but also challenges for ML in thoracic surgery. The transparency of data and algorithm design and the systemic bias on which models are dependent remain issues to be addressed. Although there has yet to be widespread use in thoracic surgery, it is essential thoracic surgeons be at the forefront of the eventual safe introduction of ML to the clinic and operating room.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20972,""
"Bioinformatics and system biology approaches to identify pathophysiological impact of COVID-19 to the progression and severity of neurological diseases","Rahman, Rana, Peng, Kibria, Islam, Mahmud, Moni","https://doi.org/10.1016/j.compbiomed.2021.104859","20211102","PubMed","Bioinformatics; COVID-19; Neurological diseases; Ontology; Pathways; Proteins; Semantic similarity; Transcriptomic analysis","The Coronavirus Disease 2019 (COVID-19) still tends to propagate and increase the occurrence of COVID-19 across the globe. The clinical and epidemiological analyses indicate the link between COVID-19 and Neurological Diseases (NDs) that drive the progression and severity of NDs. Elucidating why some patients with COVID-19 influence the progression of NDs and patients with NDs who are diagnosed with COVID-19 are becoming increasingly sick, although others are not is unclear. In this research, we investigated how COVID-19 and ND interact and the impact of COVID-19 on the severity of NDs by performing transcriptomic analyses of COVID-19 and NDs samples by developing the pipeline of bioinformatics and network-based approaches. The transcriptomic study identified the contributing genes which are then filtered with cell signaling pathway, gene ontology, protein-protein interactions, transcription factor, and microRNA analysis. Identifying hub-proteins using protein-protein interactions leads to the identification of a therapeutic strategy. Additionally, the incorporation of comorbidity interactions score enhances the identification beyond simply detecting novel biological mechanisms involved in the pathophysiology of COVID-19 and its NDs comorbidities. By computing the semantic similarity between COVID-19 and each of the ND, we have found gene-based maximum semantic score between COVID-19 and Parkinson's disease, the minimum semantic score between COVID-19 and Multiple sclerosis. Similarly, we have found gene ontology-based maximum semantic score between COVID-19 and Huntington disease, minimum semantic score between COVID-19 and Epilepsy disease. Finally, we validated our findings using gold-standard databases and literature searches to determine which genes and pathways had previously been associated with COVID-19 and NDs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20973,""
"Retrospective Evaluation of Artificial Intelligence Leveraging Free-Text Imaging Order Entry to Facilitate Federally Required Clinical Decision Support","Gish, Ellenbogen, Patrie, Gaskin","https://doi.org/10.1016/j.jacr.2021.08.021","20211020","PubMed","Artificial intelligence; Protecting Access to Medicare Act; clinical decision support; order entry","The Protecting Access to Medicare Act mandates clinical decision support (CDS) at imaging order entry, necessitating the use of structured indications to map CDS scores. We evaluated the performance of a commercially available artificial intelligence (AI) tool leveraging free-text order entry to facilitate provider selection of the necessary structured indications. Our institution implemented an AI tool offering predicted structured indications based upon the ordering provider's entry of a free-text reason for examination. Providers remained able to order via the traditional direct search for structured indications. Alternatively, they could take the new free-text-AI approach allowing them to select from AI-predicted indications, perform additional direct searches, indicate no matching indication, or exit CDS workflow. We hypothesized the free-text-AI approach would be elected more often and the AI tool would be successful in facilitating selection of structured indications. We reviewed advanced imaging orders (nÃ‚Â = 40,053) for the first 3 months (February to May 2020) since implementation. Providers were more likely (P &lt; .001) to choose the free-text-AI approach (23,580; 58.9%) to order entry over direct search for structured indications (16,473; 41.1%). The AI tool yielded alerts with predicted indications in 91.7% (nÃ‚Â = 21,631) of orders with free text. Ultimately, providers chose AI-predicted indications in 57.7% (nÃ‚Â = 12,490) of cases in which they were offered by the tool. Providers significantly more often elected the new free-text-AI approach to order entry for CDS, suggesting provider preference over the traditional approach. The AI tool commonly predicted indications acceptable to ordering providers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20974,""
"Attention-based bidirectional long short-term memory networks for extracting temporal relationships from clinical discharge summaries","Alfattni, Peek, Nenadic","https://doi.org/10.1016/j.jbi.2021.103915","20211028","PubMed","Clinical text; Deep learning; Discharge summaries; NLP; TLINKs","Temporal relation extraction between health-related events is a widely studied task in clinical Natural Language Processing (NLP). The current state-of-the-art methods mostly rely on engineered features (i.e., rule-based modelling) and sequence modelling, which often encodes a source sentence into a single fixed-length context. An obvious disadvantage of this fixed-length context design is its incapability to model longer sentences, as important temporal information in the clinical text may appear at different positions. To address this issue, we propose an Attention-based Bidirectional Long Short-Term Memory (Att-BiLSTM) model to enable learning the important semantic information in long source text segments and to better determine which parts of the text are most important. We experimented with two embeddings and compared the performances to traditional state-of-the-art methods that require elaborate linguistic pre-processing and hand-engineered features. The experimental results on the i2b2 2012 temporal relation test corpus show that the proposed method achieves a significant improvement with an F-score of 0.811, which is at least 10% better than state-of-the-art in the field. We show that the model can be remarkably effective at classifying temporal relations when provided with word embeddings trained on corpora in a general domain. Finally, we perform an error analysis to gain insight into the common errors made by the model.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20975,""
"Albumin in the management of hepatic encephalopathy: A systematic review and meta-analysis","Is, Bombassaro, Tovo, de Mattos, Ahlert, Chiesa, de Mattos","https://doi.org/10.1016/j.aohep.2021.100541","20211022","PubMed","Albumin; Hepatic encephalopathy; Liver Cirrhosis; Meta-analysis; Systematic review","Introduction and objectives It has been suggested that albumin administration could alter the natural history of cirrhosis, and also, that long-term treatment with albumin might be associated with improvement in survival, control of ascites, reduction in the incidence bacterial infections, renal dysfunction, hepatic encephalopathy (HE) and hyponatremia, as well as reduction in length of hospitalization in patients with cirrhosis and ascites. The objective of the present study is to evaluate the role of albumin in the management of HE. Materiales and methods:: This is a systematic review of randomized controlled trials that evaluated the use of albumin in adult patients with cirrhosis and HE. The search for eligible studies was performed in MEDLINE, EMBASE, and Cochrane CENTRAL databases until June 2020. The outcomes of interest were the complete reversal of HE and mortality. Meta-analysis was performed using the random effects model, through the Mantel-Haenszel method. Results: This systematic review was registered at the PROSPERO platform (CRD42020194181). The search strategy retrieved 1,118 articles. After reviewing titles and abstracts, 24 studies were considered potentially eligible, but 22 were excluded after full-text analysis. Finally, 2 studies were included. In the meta-analysis, albumin was associated to significant lower risks of persistent HE (risk ratio - RRÃ‚Â =Ã‚Â 0.60; 95% confidence interval - CIÃ‚Â =Ã‚Â 0.38-0.95, pÃ‚Â =Ã‚Â 0.03) and mortality (RRÃ‚Â =Ã‚Â 0.54; 95% CIÃ‚Â =Ã‚Â 0.33-0.90, pÃ‚Â =Ã‚Â 0.02). Conclusion: Albumin administration improves HE and reduces mortality in patients with cirrhosis and HE.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20976,""
"Using Machine Learning to Capture Quality Metrics from Natural Language: A Case Study of Diabetic Eye Exams","Fong, Scoulios, Blumenthal, Anderson","https://doi.org/10.1055/s-0041-1736311","20211001","PubMed","","Ã¢â‚¬Æ’The prevalence of value-based payment models has led to an increased use of the electronic health record to capture quality measures, necessitating additional documentation requirements for providers. Ã¢â‚¬Æ’This case study uses text mining and natural language processing techniques to identify the timely completion of diabetic eye exams (DEEs) from 26,203 unique clinician notes for reporting as an electronic clinical quality measure (eCQM). Logistic regression and support vector machine (SVM) using unbalanced and balanced datasets, using the synthetic minority over-sampling technique (SMOTE) algorithm, were evaluated on precision, recall, sensitivity, and f1-score for classifying records positive for DEE. We then integrate a high precision DEE model to evaluate free-text clinical narratives from our clinical EHR system. Ã¢â‚¬Æ’Logistic regression and SVM models had comparable f1-score and specificity metrics with models trained and validated with no oversampling favoring precision over recall. SVM with and without oversampling resulted in the best precision, 0.96, and recall, 0.85, respectively. These two SVM models were applied to the unannotated 31,585 text segments representing 24,823 unique records and 13,714 unique patients. The number of records classified as positive for DEE using the SVM models ranged from 667 to 8,935 (2.7-36% out of 24,823, respectively). Unique patients classified as positive for DEE ranged from 3.5 to 41.8% highlighting the potential utility of these models. Ã¢â‚¬Æ’We believe the impact of oversampling on SVM model performance to be caused by the potential of overfitting of the SVM SMOTE model on the synthesized data and the data synthesis process. However, the specificities of SVM with and without SMOTE were comparable, suggesting both models were confident in their negative predictions. By prioritizing to implement the SVM model with higher precision over sensitivity or recall in the categorization of DEEs, we can provide a highly reliable pool of results that can be documented through automation, reducing the burden of secondary review. Although the focus of this work was on completed DEEs, this method could be applied to completing other necessary documentation by extracting information from natural language in clinician notes. Ã¢â‚¬Æ’By enabling the capture of data for eCQMs from documentation generated by usual clinical practice, this work represents a case study in how such techniques can be leveraged to drive quality without increasing clinician work.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20977,""
"Public Covid-19 X-ray datasets and their impact on model bias - A systematic review of a significant problem","Garcia Santa Cruz, Bossa, SÃƒÂ¶lter, Husch","https://doi.org/10.1016/j.media.2021.102225","20211102","PubMed","Bias; COVID-19; Confounding; Datasets; Imaging; Machine learning; Review; X-Ray","Computer-aided-diagnosis and stratification of COVID-19 based on chest X-ray suffers from weak bias assessment and limited quality-control. Undetected bias induced by inappropriate use of datasets, and improper consideration of confounders prevents the translation of prediction models into clinical practice. By adopting established tools for model evaluation to the task of evaluating datasets, this study provides a systematic appraisal of publicly available COVID-19 chest X-ray datasets, determining their potential use and evaluating potential sources of bias. Only 9 out of more than a hundred identified datasets met at least the criteria for proper assessment of risk of bias and could be analysed in detail. Remarkably most of the datasets utilised in 201 papers published in peer-reviewed journals, are not among these 9 datasets, thus leading to models with high risk of bias. This raises concerns about the suitability of such models for clinical use. This systematic review highlights the limited description of datasets employed for modelling and aids researchers to select the most suitable datasets for their task.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20978,""
"Seamless Integration of Artificial Intelligence Into the Clinical Environment: Our Experience With a Novel Pneumothorax Detection Artificial Intelligence Algorithm","Pierce, Rosipko, Youngblood, Gilkeson, Gupta, Bittencourt","https://doi.org/10.1016/j.jacr.2021.08.023","20211001","PubMed","Algorithm; artificial intelligence; clinical practice; imaging; radiology","Though interest in artificial intelligence (AI) has exploded in recent years and led to the development of numerous commercial and noncommercial algorithms, the process of implementing such tools into day-to-day clinical practice is rarely described in the burgeoning AI literature. In this report, we describe our experience with the successful integration of an AI-enabled mobile X-ray scanner with an FDA-approved algorithm for detecting pneumothoraces into an end-to-end solution capable of extracting, delivering, and prioritizing positive studies within our thoracic radiology clinical workflow. We also detail several sample cases from our AI algorithm and associated PACS workflow in action to highlight key insights from our experience. We hope this report can help inform other radiology enterprises seeking to evaluate and implement AI-related workflow solutions into daily clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20979,""
"[Improved Mental Health Clinical Practice Informed by Digital Phenotyping]","Bougeard, Guay Hottin, Houde, Jean, Piront, Potvin, Bernard, Tourjman, De Benedictis, Orban","https://www.google.com/search?q=[Improved+Mental+Health+Clinical+Practice+Informed+by+Digital+Phenotyping].","20211028","PubMed","Adolescent; Emotions; Humans; Machine Learning; Mental Disorders; Mental Health; Smartphone","Objectives This review is motivated by the observation that clinical decision-making in mental health is limited by the nature of the measures obtained in conventional clinical interviews and the difficulty for clinicians to make accurate predictions about their patients' future mental states. Our objective is to offer a representative overview of the potential of digital phenotyping coupled with machine learning to address this limitation, while highlighting its own current weaknesses. Methods Through a non-systematic narrative review of the literature, we identify the technological developments that make it possible to quantify, moment by moment and in ecologically valid settings, the human phenotype in various psychiatric populations using the smartphone. Relevant work is also selected in order to determine the usefulness and limitations of machine learning to guide predictions and clinical decision-making. Finally, the literature is explored to assess current barriers to the adoption of such tools. Results Although emerging from a recent field of research, a large body of work already highlights the value of measurements extracted from smartphone sensors in characterizing the human phenotype in behavioral, cognitive, emotional and social spheres that are all impacted by mental disorders. Machine learning permits useful and accurate clinical predictions based on such measures, but suffers from a lack of interpretability that will hamper its use in clinical practice in the near future. Moreover, several barriers identified both on the patient and clinician sides currently hamper the adoption of this type of monitoring and clinical decision support tools. Conclusion Digital phenotyping coupled with machine learning shows great promise for improving clinical practice in mental health. However, the youth of these new technological tools requires a necessary maturation process to be guided by the various concerned actors so that these promises can be fully realized.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20980,""
"[Basic, Clinical and Social Perspectives on the Use of Virtual Characters in Mental Health]","Marcoux, Tessier, Grondin, Reduron, Jackson","https://www.google.com/search?q=[Basic,+Clinical+and+Social+Perspectives+on+the+Use+of+Virtual+Characters+in+Mental+Health].","20211028","PubMed","Artificial Intelligence; Delivery of Health Care; Empathy; Humans; Mental Health; Mental Health Services","Along other breakthroughs in computer sciences, such as artificial intelligence, virtual characters (i.e. digitally represented characters featuring a human appearance or not) are foreseen as potential providers of mental healthcare services. However, their current use in clinical practice is marginal and limited to an assistive role to help clinicians in their practices. Safety and efficiency concerns, as well as a general lack of knowledge and experience, may explain this discrepancy between the expected (sometimes futuristic) and current use of virtual characters. An overview of recent evidence would help pinpoint the main concerns and challenges pertaining to their use in mental healthcare. Objective This paper aims to inform relevant actors, including clinicians, on the potential of virtual characters in mental healthcare practices and to raise awareness on societal challenges regarding their use. Method A narrative literature review was conducted to summarize basic and clinical research findings, and to outline an in-depth discussion on various societal caveats related to the inclusion of virtual characters. Results Basic studies highlight several characteristics of the virtual characters that seem to influence patient-clinician interactions. These characteristics can be classified into two categories: perceptual (e.g. realism) and social features (i.e. attribution of social categories such as gender). To this day, many interventions and/or assessments using virtual characters have shown various levels of efficiency in mental health, and certain elements of a therapeutic relationship (e.g. alliance and empathy) may even be triggered during an interaction with a virtual character. To develop and increase the use of virtual characters, numerous socioeconomic and ethical issues must be examined. Although the accessibility and the availability of virtual characters are an undeniable advantage for their use in mental healthcare, some inequities about their application remain. In addition, the accumulation of biometric data (e.g. heart rate) could provide valuable information to clinicians and could help develop autonomous virtual characters, which raises concerns over issues of security and privacy. This paper proposes some recommendations to avoid such undesirable outcomes. Conclusion Due to their promising features, the inclusion of virtual characters will no doubt be increasingly prevalent in mental healthcare services. All involved actors should thus be informed about specific challenges raised by such breakthroughs. They should also actively participate in discussions regarding the development of virtual characters in order to adopt unified recommendations for their safe and ethical use in mental healthcare.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20981,""
"Deep Learning-based Reconstruction for Lower-Dose Pediatric CT: Technical Principles, Image Characteristics, and Clinical Implementations","Nagayama, Sakabe, Goto, Emoto, Oda, Nakaura, Kidoh, Uetani, Funama, Hirai","https://doi.org/10.1148/rg.2021210105","20211102","PubMed","","Optimizing the CT acquisition parameters to obtain diagnostic image quality at the lowest possible radiation dose is crucial in the radiosensitive pediatric population. The image quality of low-dose CT can be severely degraded by increased image noise with filtered back projection (FBP) reconstruction. Iterative reconstruction (IR) techniques partially resolve the trade-off relationship between noise and radiation dose but still suffer from degraded noise texture and low-contrast detectability at considerably low-dose settings. Furthermore, sophisticated model-based IR usually requires a long reconstruction time, which restricts its clinical usability. With recent advances in artificial intelligence technology, deep learning-based reconstruction (DLR) has been introduced to overcome the limitations of the FBP and IR approaches and is currently available clinically. DLR incorporates convolutional neural networks-which comprise multiple layers of mathematical equations-into the image reconstruction process to reduce image noise, improve spatial resolution, and preserve preferable noise texture in the CT images. For DLR development, numerous network parameters are iteratively optimized through an extensive learning process to discriminate true attenuation from noise by using low-dose training and high-dose teaching image data. After rigorous validations of network generalizability, the DLR engine can be used to generate high-quality images from low-dose projection data in a short reconstruction time in a clinical environment. Application of the DLR technique allows substantial dose reduction in pediatric CT performed for various clinical indications while preserving the diagnostic image quality. The authors present an overview of the basic concept, technical principles, and image characteristics of DLR and its clinical feasibility for low-dose pediatric CT. <sup>Ã‚Â©</sup>RSNA, 2021.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20982,""
"Pediatric Chronic Critical Illness: Protocol for a Scoping Review","Zorko, McNally, Rochwerg, Pinto, Couban, O'Hearn, Choong","https://doi.org/10.2196/30582","20211004","PubMed","chronic critical illness; critical care; intensive care units; pediatrics; research design","Improvements in the delivery of intensive care have increased survival among even the most critically ill children, thereby leading to a growing number of children with chronic complex medical conditions in the pediatric intensive care unit (PICU). Some of these children are at a significant risk of recurrent and prolonged critical illness, with higher morbidity and mortality, making them a unique population described as having chronic critical illness (CCI). To date, pediatric CCI has been understudied and lacks an accepted consensus case definition. This study aims to describe the protocol and methodology used to perform a scoping review that will describe how pediatric CCI has been defined in the literature, including the concept of prolonged PICU admission and the methodologies used to develop any existing definitions. It also aims to describe patient characteristics and outcomes evaluated in the included studies. We will search four electronic databases for studies that evaluated children admitted to any PICU identified with CCI. We will also search for studies describing prolonged PICU admission, as this concept is related to pediatric CCI. Furthermore, we will develop a hybrid crowdsourcing and machine learning (ML) methodology to complete citation screening. Screening and data abstraction will be performed by 2 reviewers independently and in duplicate. Data abstraction will include the details of population definitions, demographic and clinical characteristics of children with CCI, and evaluated outcomes. The database search, crowd reviewer recruitment, and ML algorithm development began in March 2021. Citation screening and data abstraction were completed in April 2021. Final data verification is ongoing, with analysis and results anticipated to be completed by fall 2021. This scoping review will describe the existing or suggested definitions of pediatric CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review's results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. DERR1-10.2196/30582.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20983,""
"VBridge: Connecting the Dots Between Features and Data to Explain Healthcare Models","Cheng, Liu, Du, Lin, Zytek, Li, Qu, Veeramachaneni","https://doi.org/10.1109/TVCG.2021.3114836","20211001","PubMed","","Machine learning (ML) is increasingly applied to Electronic Health Records (EHRs) to solve clinical prediction tasks. Although many ML models perform promisingly, issues with model transparency and interpretability limit their adoption in clinical practice. Directly using existing explainable ML techniques in clinical settings can be challenging. Through literature surveys and collaborations with six clinicians with an average of 17 years of clinical experience, we identified three key challenges, including clinicians' unfamiliarity with ML features, lack of contextual information, and the need for cohort-level evidence. Following an iterative design process, we further designed and developed VBridge, a visual analytics tool that seamlessly incorporates ML explanations into clinicians' decision-making workflow. The system includes a novel hierarchical display of contribution-based feature explanations and enriched interactions that connect the dots between ML features, explanations, and data. We demonstrated the effectiveness of VBridge through two case studies and expert interviews with four clinicians, showing that visually associating model explanations with patients' situational records can help clinicians better interpret and use model predictions when making clinician decisions. We further derived a list of design implications for developing future explainable ML tools to support clinical decision-making.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20984,""
"A perspective on prognostic models in chronic lymphocytic leukemia in the era of targeted agents","Molica, Seymour, Polliack","https://doi.org/10.1002/hon.2929","20211001","PubMed","CLL; dynamic prognostic models; machine learning; post-treatment biomarkers; prognostic models; systematic review","Despite the increase in the number of prognostic models currently available for evaluating patients with chronic lymphocytic leukemia (CLL), their current application and utilization in clinical practice in the era of targeted agents is unclear. A critical reappraisal of recently developed prognostic models is presented in this review. The underlying CLL's genetic instability and changes in the host's health and comorbidities can all contribute to the acquisition of additional risk factors for adverse outcomes during the course of the disease. Therefore, available risk models solely based on pretreatment variables only partially predict patients' clinical outcome. A dynamic prognostic model that takes into account changes in the risk profile over time could indeed be useful in routine clinical practice. The next generation of risk assessment models should incorporate post-treatment and response biomarkers such as minimal residual disease. Finally, recent advances in the field of machine learning present novel opportunities to generate models capable of providing an individualized estimation of clinical outcomes in CLL. However, in the era of improved prognostic models, it is important to remember that these indices should supplement but not replace clinical expertise and medical decision-making.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20985,""
"Cost-effectiveness of gilteritinib for relapsed/refractory <i>FLT3</i><sup>mut+</sup> acute myeloid leukemia","Pandya, Qi, Garnham, Yang, Shah, Zeidan","https://doi.org/10.18553/jmcp.2021.27.10.1469","20211001","PubMed","","<b>BACKGROUND:</b> Patients with relapsed or refractory (R/R) acute myeloid leukemia (AML) and confirmed feline McDonough sarcoma (FMS)-like tyrosine kinase 3 gene mutations (<i>FLT3</i><sup>mut+</sup>) have a poor prognosis and limited effective treatment options. Gilteritinib is the first targeted therapy approved in the United States and Europe for R/R <i>FLT3</i><sup>mut+</sup> AML with significantly improved efficacy compared with existing treatments. <b>OBJECTIVE:</b> To evaluate gilteritinib against salvage chemotherapy (SC) and best supportive care (BSC) over a lifetime horizon among adult patients with R/R <i>FLT3</i><sup>mut+</sup> AML from a US third-party payer's perspective. <b>METHODS:</b> The model structure of this cost-effectiveness analysis included a decision tree to stratify patients based on their hematopoietic stem cell transplantation (HSCT) status, followed by 2 separate 3-state partitioned survival models to predict the long-term health status conditional on HSCT status. The ADMIRAL trial data and literature were used to predict probabilities of patients being in different health states until a conservative cure point at year 3. Afterwards, living patients followed the survival outcomes of long-term survivors with AML. Model inputs for utilities, medical resource use, and costs were based on the ADMIRAL trial, published literature, and public sources. All costs were inflated to 2019 US dollars (USD). Total incremental costs (in 2019 USD), life-years (LYs), quality-adjusted LYs (QALYs), and incremental cost-effectiveness ratios (ICERs) were calculated. Deterministic sensitivity analyses and probabilistic sensitivity analyses were performed. <b>RESULTS:</b> Over a lifetime horizon with a 3.0% annual discount rate, the base-case model estimated that gilteritinib led to an increase of 1.29 discounted QALYs at an additional cost of $148,106 vs SC, corresponding to an ICER of $115,192 per QALY; for BSC, results were an increase of 2.32 discounted QALYs, $249,674, and $107,435, respectively. The base-case findings were robust in sensitivity analyses. The estimated probabilities of gilteritinib being cost-effective vs SC and BSC were 90.5% and 99.8%, respectively, in the probabilistic sensitivity analyses, based on a willingness-to-pay threshold of $150,000 per QALY. <b>CONCLUSIONS:</b> Gilteritinib is a cost-effective novel treatment for patients with R/R <i>FLT3</i><sup>mut+</sup> AML in the United States. <b>DISCLOSURES:</b> This work was supported by Astellas Pharma, Inc., which was involved in all stages of the research and manuscript development. Garnham, Pandya, and Shah are employees of Astellas and hold stock/stock options. Zeidan consulted and received personal fees/honoraria and research funding from Astellas. Zeidan also has received research funding from Celgene/BMS, Abbvie, Astex, Pfizer, Medimmune/AstraZeneca, Boehringer-Ingelheim, Trovagene/Cardiff Oncology, Incyte, Takeda, Novartis, Amgen, Aprea, and ADC Therapeutics; has participated in advisory boards; has consulted with and/or received honoraria from AbbVie, Otsuka, Pfizer, Celgene/BMS, Jazz, Incyte, Agios, Boehringer-Ingelheim, Novartis, Acceleron, Daiichi Sankyo, Taiho, Seattle Genetics, BeyondSpring, Cardiff Oncology, Takeda, Ionis, Amgen, Janssen, Syndax, Gilead, Kura, Aprea, Lox Oncology, Genentech, Servier, Jasper, Tyme, and Epizyme; has served on clinical trial committees for Novartis, Abbvie, Geron, Gilead, Kura, Lox Oncology, BioCryst, and Celgene/BMS; and has received travel support for meetings from Pfizer, Novartis, and Cardiff Oncology. Qi and Yang are employees of Analysis Group, Inc., which received consulting fees from Astellas for work on this study. Part of this material was presented at the American Society of Hematology (ASH) Annual Meeting; December 7-10, 2019; Orlando, FL.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20986,""
"GENETEX-a GENomics Report TEXt mining R package and Shiny application designed to capture real-world clinico-genomic data","Miller, Shalhout","https://doi.org/10.1093/jamiaopen/ooab082","20211002","PubMed","REDCap; Shiny app; clinical informatics; clinico-genomics; data abstraction; electronic health records","Clinico-genomic data (CGD) acquired through routine clinical practice has the potential to improve our understanding of clinical oncology. However, these data often reside in heterogeneous and semistructured data, resulting in prolonged time-to-analyses. We created GENETEX: an R package and Shiny application for text mining genomic reports from electronic health record (EHR) and direct import into Research Electronic Data Capture (REDCap). GENETEX facilitates the abstraction of CGD from EHR and streamlines the capture of structured data into REDCap. Its functions include natural language processing of key genomic information, transformation of semistructured data into structured data, and importation into REDCap. When evaluated with manual abstraction, GENETEX had &gt;99% agreement and captured CGD in approximately one-fifth the time. GENETEX is freely available under the Massachusetts Institute of Technology license and can be obtained from GitHub (https://github.com/TheMillerLab/genetex). GENETEX is executed in R and deployed as a Shiny application for non-R users. It produces high-fidelity abstraction of CGD in a fraction of the time.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20987,""
"Cancer-related fatigue-pharmacological interventions: systematic review and network meta-analysis","Chow, Bruera, Sanatani, Chiu, Prsic, Boldt, Lock","https://doi.org/10.1136/bmjspcare-2021-003244","20211001","PubMed","fatigue; pharmacology","Cancer-related fatigue (CRF) is a very common symptom in patients with cancer, and one of the five areas of highest priority in cancer research. There is currently no consensus on pharmacologic interventions for treating CRF. The aim of this systematic review is to provide more clarity on which pharmacologic interventions may be most promising, for future clinical trials. The network meta-analysis provides the ability to compare multiple agents when no direct head-to-head trials of all agents have been performed. Medline (PubMed), EMBASE and Cochrane Central Register of Controlled Trials were searched up until 5 March 2021. Studies were included if they reported on a pharmacologic intervention for CRF. Standardised mean differences and corresponding 95% CIs were computed using a random-effects maximum-likelihood model. This review reports on 20 studies and 2688 patients, the most comprehensive review of pharmacologic interventions for CRF at the time of this publication. Methylphenidate, modafinil and paroxetine were superior to placebo. Methylphenidate and modafinil were equivalent to one another. Paroxetine was superior to both methylphenidate and modafinil. Paroxetine should be further studied in future trials. As well, more safety data are needed on pharmacologic interventions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20988,""
"Looking for consistency in an uncertain world: test-retest reliability of neurophysiological and behavioral readouts in autism","Beker, Foxe, Venticinque, Bates, Ridgeway, Schaaf, Molholm","https://doi.org/10.1186/s11689-021-09383-0","20211007","PubMed","ASD; Biomarkers; EEG; ERP; ICC; Inter-trial variability; Autism Spectrum Disorder; Autistic Disorder; Child; Evoked Potentials; Evoked Potentials, Visual; Humans; Infant; Reproducibility of Results","Autism spectrum disorders (ASD) are associated with altered sensory processing and perception. Scalp recordings of electrical brain activity time-locked to sensory events (event-related potentials; ERPs) provide precise information on the time-course of related altered neural activity, and can be used to model the cortical loci of the underlying neural networks. Establishing the test-retest reliability of these sensory brain responses in ASD is critical to their use as biomarkers of neural dysfunction in this population. EEG and behavioral data were acquired from 33 children diagnosed with ASD aged 6-9.4 years old, while they performed a child-friendly task at two different time-points, separated by an average of 5.2 months. In two blocked conditions, participants responded to the occurrence of an auditory target that was either preceded or not by repeating visual stimuli. Intraclass correlation coefficients (ICCs) were used to assess test-retest reliability of measures of sensory (auditory and visual) ERPs and performance, for the two experimental conditions. To assess the degree of reliability of the variability of responses within individuals, this analysis was performed on the variance of the measurements, in addition to their means. This yielded a total of 24 measures for which ICCs were calculated. The data yielded significant good ICC values for 10 of the 24 measurements. These spanned across behavioral and ERPs data, experimental conditions, and mean as well as variance measures. Measures of the visual evoked responses accounted for a disproportionately large number of the significant ICCs; follow-up analyses suggested that the contribution of a greater number of trials to the visual compared to the auditory ERP partially accounted for this. This analysis reveals that sensory ERPs and related behavior can be highly reliable across multiple measurement time-points in ASD. The data further suggest that the inter-trial and inter-participant variability reported in the ASD literature likely represents replicable individual participant neural processing differences. The stability of these neuronal readouts supports their use as biomarkers in clinical and translational studies on ASD. Given the minimum interval between test/retest sessions across our cohort, we also conclude that for the tested age-range of ~Ã¢â‚¬â€°6 to 9.4 years, these reliability measures are valid for at least a 3-month interval. Limitations related to EEG task demands and study length in the context of a clinical trial are considered.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20989,""
"Prevention of Suicidal Relapses in Adolescents With a Smartphone Application: Bayesian Network Analysis of a Preclinical Trial Using In Silico Patient Simulations","Mouchabac, Leray, Adrien, Gollier-Briant, Bonnot","https://doi.org/10.2196/24560","20211028","PubMed","artificial intelligence; bayesian network; digital psychiatry; smartphone application; suicide; Adolescent; Artificial Intelligence; Bayes Theorem; Computer Simulation; Humans; Patient Simulation; Recurrence; Smartphone; Suicidal Ideation","Recently, artificial intelligence technologies and machine learning methods have offered attractive prospects to design and manage crisis response processes, especially in suicide crisis management. In other domains, most algorithms are based on big data to help diagnose and suggest rational treatment options in medicine. But data in psychiatry are related to behavior and clinical evaluation. They are more heterogeneous, less objective, and incomplete compared to other fields of medicine. Consequently, the use of psychiatric clinical data may lead to less accurate and sometimes impossible-to-build algorithms and provide inefficient digital tools. In this case, the Bayesian network (BN) might be helpful and accurate when constructed from expert knowledge. Medical Companion is a government-funded smartphone application based on repeated questions posed to the subject and algorithm-matched advice to prevent relapse of suicide attempts within several months. Our paper aims to present our development of a BN algorithm as a medical device in accordance with the American Psychiatric Association digital healthcare guidelines and to provide results from a preclinical phase. The experts are psychiatrists working in university hospitals who are experienced and trained in managing suicidal crises. As recommended when building a BN, we divided the process into 2 tasks. Task 1 is structure determination, representing the qualitative part of the BN. The factors were chosen for their known and demonstrated link with suicidal risk in the literature (clinical, behavioral, and psychometrics) and therapeutic accuracy (advice). Task 2 is parameter elicitation, with the conditional probabilities corresponding to the quantitative part. The 4-step simulation (use case) process allowed us to ensure that the advice was adapted to the clinical states of patients and the context. For task 1, in this formative part, we defined clinical questions related to the mental state of the patients, and we proposed specific factors related to the questions. Subsequently, we suggested specific advice related to the patient's state. We obtained a structure for the BN with a graphical representation of causal relations between variables. For task 2, several runs of simulations confirmed the a priori model of experts regarding mental state, refining the precision of our model. Moreover, we noticed that the advice had the same distribution as the previous state and was clinically relevant. After 2 rounds of simulation, the experts found the exact match. BN is an efficient methodology to build an algorithm for a digital assistant dedicated to suicidal crisis management. Digital psychiatry is an emerging field, but it needs validation and testing before being used with patients. Similar to psychotropics, any medical device requires a phase II (preclinical) trial. With this method, we propose another step to respond to the American Psychiatric Association guidelines. ClinicalTrials.gov NCT03975881; https://clinicaltrials.gov/ct2/show/NCT03975881.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20990,""
"Cost-effectiveness analysis using lifetime attributable risk of proton beam therapy for pediatric medulloblastoma in Japan","Yoshimura, Tamori, Morii, Hashimoto, Shimizu, Ogasawara","https://doi.org/10.1093/jrr/rrab077","20210930","PubMed","cost-effectiveness; lifetime attribute risk; medulloblastoma; proton therapy; secondary cancer","Compared to conventional X-ray therapy, proton beam therapy (PBT) has more clinical and physical advantages such as irradiation dose reduction to normal tissues for pediatric medulloblastoma. However, PBT is expensive. We aimed to compare the cost-effectiveness of PBT for pediatric medulloblastoma with that of conventional X-ray therapy, while focusing on radiation-induced secondary cancers, which are rare, serious and negatively affect a patient's quality of life (QOL). Based on a systematic review, a decision tree model was used for the cost-effectiveness analysis. This analysis was performed from the perspective of health care payers; the cost was estimated from medical fees. The target population was pediatric patients with medulloblastoma below 14Ã‚Â years old. The time horizon was set at 7.7Ã‚Â years after medulloblastoma treatment. The primary outcome was the incremental cost-effectiveness ratio (ICER), which was defined as the ratio of the difference in cost and lifetime attributable risk (LAR) between conventional X-ray therapy and PBT. The discount rate was set at 2% annually. Sensitivity analyses were performed to model uncertainty. Cost and LAR in conventional X-ray therapy and PBT were Japanese yen (JPY) 1Ã¢â‚¬â€°067Ã¢â‚¬â€°608 and JPY 2436061 and 42% and 7%, respectively. The ICER was JPY 3856398/LAR. In conclusion, PBT is more cost-effective than conventional X-ray therapy in reducing the risk of radiation-induced secondary cancers in pediatric medulloblastoma. Thus, our constructed ICER using LAR is one of the valid indicators for cost-effectiveness analysis in radiation-induced secondary cancer.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20991,""
"Brain Computer Interfaces for Assisted Communication in Paralysis and Quality of Life","Chaudhary, Chander, Ohry, Jaramillo-Gonzalez, LulÃƒÂ©, Birbaumer","https://doi.org/10.1142/S0129065721300035","20210930","PubMed","Brain-computer-interfaces; amyotrophic lateral sclerosis; brain reorganization; locked-in state; quality of life","The rapid evolution of Brain-Computer Interface (BCI) technology and the exponential growth of BCI literature during the past 20 years is a consequence of increasing computational power and the achievements of statistical learning theory and machine learning since the 1960s. Despite this rapid scientific progress, the range of successful clinical and societal applications remained limited, with some notable exceptions in the rehabilitation of chronic stroke and first steps towards BCI-based assisted verbal communication in paralysis. In this contribution, we focus on the effects of noninvasive and invasive BCI-based verbal communication on the quality of life (QoL) of patients with amyotrophic lateral sclerosis (ALS) in the locked-in state (LIS) and the completely locked-in state (CLIS). Despite a substantial lack of replicated scientific data, this paper complements the existing methodological knowledge and focuses future investigators' attention on (1) Social determinants of QoL and (2) Brain reorganization and behavior. While it is not documented in controlled studies that the good QoL in these patients is a consequence of BCI-based neurorehabilitation, the proposed determinants of QoL might become the theoretical background needed to develop clinically more useful BCI systems and to evaluate the effects of BCI-based communication on QoL for advanced ALS patients and other forms of severe paralysis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20992,""
"The application of radiomics in laryngeal cancer","Rajgor, Patel, McCulloch, Obara, Bacardit, McQueen, Aboagye, Ali, O'Hara, Hamilton","https://doi.org/10.1259/bjr.20210499","20210929","PubMed","","Radiomics is the conversion of medical images into quantitative high-dimensional data. Laryngeal cancer, one of the most common head and neck cancers, has risen globally by 58.7%. CT, MRI and PET are acquired during the diagnostic process providing potential data for radiomic analysis and correlation with outcomes.This review aims to examine the applications of this technique to laryngeal cancer and the future considerations for translation into clinical practice. A comprehensive systematic review-informed search of the MEDLINE and EMBASE databases was undertaken. Keywords ""laryngeal cancer"" OR ""larynx"" OR ""larynx cancer"" OR ""head and neck cancer"" were combined with ""radiomic"" OR ""signature"" OR ""machine learning"" OR ""artificial intelligence"". Additional articles were obtained from bibliographies using the ""snowball method"". The included studies (<i>n</i> = 15) demonstrated that radiomic features are significantly associated with various clinical outcomes (including stage, overall survival, treatment response, progression-free survival) and that predictive models incorporating radiomic features are superior to those that do not. Two studies demonstrated radiomics could improve laryngeal cancer staging whilst 12 studies affirmed its predictive capability for clinical outcomes. Radiomics has potential for improving multiple aspects of laryngeal cancer care; however, the heterogeneous cohorts and lack of data on laryngeal cancer exclusively inhibits firm conclusions. Large prospective well-designed studies in laryngeal cancer are required to progress this field. Furthermore, to implement radiomics into clinical practice, a unified research effort is required to standardise radiomics practice. This review has highlighted the value of radiomics in enhancing laryngeal cancer care (including staging, prognosis and predicting treatment response).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20993,""
"Convolutional neural network optimizes the application of diffusion kurtosis imaging in Parkinson's disease","Sun, Chen, Tong, Ma, Gao, Fang, Zhang, Chan, He, Wu","https://doi.org/10.1186/s40708-021-00139-z","20211009","PubMed","Convolutional neural network; Diffusion kurtosis imaging; Kurtosis fractional anisotropy; Mean diffusivity; Mean kurtosis; ParkinsonÃ¢â‚¬â„¢s disease","The literature regarding the use of diffusion-tensor imaging-derived metrics in the evaluation of Parkinson's disease (PD) is controversial. This study attempted to assess the feasibility of a deep-learning-based method for detecting alterations in diffusion kurtosis measurements associated with PD. A total of 68 patients with PD and 77 healthy controls were scanned using scanner-A (3Ã‚Â T Skyra) (DATASET-1). Meanwhile, an additional five healthy volunteers were scanned with both scanner-A and an additional scanner-B (3Ã‚Â T Prisma) (DATASET-2). Diffusion kurtosis imaging (DKI) of DATASET-2 had an extra b shell compared to DATASET-1. In addition, a 3D-convolutional neural network (CNN) was trained from DATASET-2 to harmonize the quality of scalar measures of scanner-A to a similar level as scanner-B. Whole-brain unpaired t test and Tract-Based Spatial Statistics (TBSS) were performed to validate the differences between the PD and control groups using the model-fitting method and CNN-based method, respectively. We further clarified the correlation between clinical assessments and DKI results. An increase in mean diffusivity (MD) was found in the left substantia nigra (SN) in the PD group. In the right SN, fractional anisotropy (FA) and mean kurtosis (MK) values were negatively correlated with Hoehn and Yahr (H&amp;Y) scales. In the putamenÃ‚Â (Put), FA values were positively correlated with the H&amp;Y scales. It is worth noting that these findings were only observed with the deep learning method. There was neither a group difference nor a correlation with clinical assessments in the SN or striatum exceeding the significance level using the conventional model-fitting method. The CNN-based method improves the robustness of DKI and can help to explore PD-associated imaging features.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20994,""
"Cohort-Specific Optimization of Models Predicting Preclinical Alzheimer's Disease, to Enhance Screening Performance in the Middle of Preclinical Alzheimer's Disease Clinical Studies","Sato, Mano, Ihara, Suzuki, Niimi, Toda, Iwatsubo, Iwata","https://doi.org/10.14283/jpad.2021.39","20211101","PubMed","Amyloid beta; machine learning; preclinical AlzheimerÃ¢â‚¬â„¢s disease; predictive model; Aged; Alzheimer Disease; Brain; Female; Humans; Japan; Longitudinal Studies; Male; Mental Status and Dementia Tests; Middle Aged; Neuroimaging; Prodromal Symptoms; Retrospective Studies; United States","Models that can predict brain amyloid beta (AÃŽÂ²) status more accurately have been desired to identify participants for clinical trials of preclinical Alzheimer's disease (AD). However, potential heterogeneity between different cohorts and the limited cohort size have been the reasons preventing the development of reliable models applicable to the Asian population, including Japan. We aim to propose a novel approach to predict preclinical AD while overcoming these constraints, by building models specifically optimized for ADNI or for J-ADNI, based on the larger samples from A4 study data. This is a retrospective study including cognitive normal participants (CDR-global = 0) from A4 study, Alzheimer Disease Neuroimaging Initiative (ADNI), and Japanese-ADNI (J-ADNI) cohorts. The model is made up of age, sex, education years, history of AD, Clinical Dementia Rating-Sum of Boxes, Preclinical Alzheimer Cognitive Composite score, and APOE genotype, to predict the degree of amyloid accumulation in amyloid PET as Standardized Uptake Value ratio (SUVr). The model was at first built based on A4 data, and we can choose at which SUVr threshold configuration the A4-based model may achieve the best performance area under the curve (AUC) when applied to the random-split half ADNI or J-ADNI subset. We then evaluated whether the selected model may also achieve better performance in the remaining ADNI or J-ADNI subsets. When compared to the results without optimization, this procedure showed efficacy of AUC improvement of up to approximately 0.10 when applied to the models ""without APOE;"" the degree of AUC improvement was larger in the ADNI cohort than in the J-ADNI cohort. The obtained AUC had improved mildly when compared to the AUC in case of literature-based predetermined SUVr threshold configuration. This means our procedure allowed us to predict preclinical AD among ADNI or J-ADNI second-half samples with slightly better predictive performance. Our optimizing method may be practically useful in the middle of the ongoing clinical study of preclinical AD, as a screening to further increase the prior probability of preclinical AD before amyloid testing.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20995,""
"A UK-Wide Study Employing Natural Language Processing to Determine What Matters to People about Brain Health to Improve Drug Development: The Electronic Person-Specific Outcome Measure (ePSOM) Programme","Saunders, Muniz-Terrera, Sheehan, Ritchie, Luz","https://doi.org/10.14283/jpad.2021.30","20211101","PubMed","AlzheimerÃ¢â‚¬â„¢s disease; Clinically meaningful change; brain health; electronic patient reported outcome measures; outcome measures; Alzheimer Disease; Brain; Drug Development; Female; Humans; Male; Middle Aged; Natural Language Processing; Patient Reported Outcome Measures; Research Design; Self Report; Surveys and Questionnaires; United Kingdom","It is important to use outcome measures for novel interventions in Alzheimer's disease (AD) that capture the research participants' views of effectiveness. The electronic Person-Specific Outcome Measure (ePSOM) development programme is underpinned by the need to identify and detect change in early disease manifestations and the possibilities of incorporating artificial intelligence in outcome measures. The aim of the ePSOM programme is to better understand what outcomes matter to patients in the AD population with a focus on those at the pre-dementia stages of disease. Ultimately, we aim to develop an app with robust psychometric properties to be used as a patient reported outcome measure in AD clinical trials. We designed and ran a nationwide study (Aug 2019 - Nov 2019, UK), collecting primarily free text responses in five pre-defined domains. We collected self-reported clinical details and sociodemographic data to analyse responses by key variables whilst keeping the survey short (around 15 minutes). We used clustering and Natural Language Processing techniques to identify themes which matter most to individuals when developing new treatments for AD. The study was completed by 5,808 respondents, yielding over 80,000 free text answers. The analysis resulted in 184 themes of importance. An analysis focusing on key demographics to explore how priorities differed by age, gender and education revealed that there are significant differences in what groups consider important about their brain health. The ePSOM data has generated evidence on what matters to people when developing new treatments for AD that target secondary prevention and therein maintenance of brain health. These results will form the basis for an electronic outcome measure to be used in AD clinical research and clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20996,""
"Comparison of ANFIS and ANN modeling for predicting the water absorption behavior of polyurethane treated polyester fabric","Sarkar, Prottoy, Bari, Al Faruque","https://doi.org/10.1016/j.heliyon.2021.e08000","20210930","PubMed","ANFIS; ANN; Functional finishing; Modeling; Textile substrates","Nowadays, the polyurethane and its derivatives are highly applied as a surface modification material onto the textile substrates in different forms to enhance the functional properties of the textile materials. The primary purpose of this study is to develop prediction models to model the absorption property of the textile substrate using the Adaptive Neuro-Fuzzy Inference System (ANFIS) and Artificial Neural Network (ANN) methods. In this study, polyurethane (PU) along with acrylic binder was applied on the dyed polyester knitted fabric to develop and validate the prediction models. Through the morphological study, it was evident that the solution prepared with the polyurethane and the acrylic binder was effectively coated onto the fabric surface. The ANFIS model was constructed by considering binder (ml) and PU (%) as input parameters, whereas absorbency (%) was the only output parameter. On the other hand, the system was trained with 70% data for constructing the ANN model whereas testing and validation were done with 15% data, respectively. To train the network, feed-forward backpropagation with Levenberg-Marquardt learning algorithm was used. The coefficient of determination (R<sup>2</sup>) was found to be 0.98 and 0.93 for ANFIS and ANN model, respectively. Both prediction models exhibited an excellent mean absolute error percentage (0.76% for the ANFIS model and 1.18% for the ANN model). Furthermore, an outstanding root-mean-square error (RMSE) of 0.61% and 1.28% for ANFIS and ANN models was observed. These results suggested an excellent performance of the developed models to predict the absorption property of the polyurethane and acrylic binder treated fabric. Besides, these models can be taken as a basis to develop prediction models for specific types of functional applications of the textile materials to eliminate heaps of trial and error efforts of the textile industries, which eventually be helpful in the scalable production of functional textiles.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20997,""
"Preventing Alzheimer's disease within reach by 2025: Targeted-risk-AD-prevention (TRAP) strategy","Vitali, Branigan, Brinton","https://doi.org/10.1002/trc2.12190","20210930","PubMed","Alzheimer's; bioinformatics; prevention; risk factors","Alzheimer's disease (AD) is a progressive neurodegenerative disease that currently affects 6.2 million people in the United States and is projected to impact 12.7 million worldwide in 2050 with no effective disease-modifying therapeutic or cure. In 2011 as part of the National Alzheimer's Project Act, the National Plan to Address Alzheimer's Disease was signed into law which proposed to effectively prevent AD by 2025, which is rapidly approaching. The preclinical phase of AD can begin 20 years prior to diagnosis, which provides an extended window for preventive measures that would exert a transformative impact on incidence and prevalence of AD. A novel combination of text-mining and natural language processing strategies to identify (1) AD risk factors, (2) therapeutics that can target risk factor pathways, and (3) studies supporting therapeutics in the PubMed database was conducted. To classify the literature relevant to AD preventive strategies, a relevance score (RS) based on STRING (search tool for the retrieval of interacting genes/proteins) score for protein-protein interactions and a confidence score (CS) on Bayesian inference were developed. To address mechanism of action, network analysis of protein targets for effective drugs was conducted. Collectively, the analytic approach, referred to as a targeted-risk-AD-prevention (TRAP) strategy, led to a ranked list of candidate therapeutics to reduce AD risk. Based on TRAP mining of 9625 publications, 364 AD risk factors were identified. Based on risk factor indications, 629 Food and Drug Administration-approved drugs were identified. Computation of ranking scores enabled identification of 46 relevant high confidence (RS &amp; CSÃ‚Â &gt;Ã‚Â 0.7) drugs associated with reduced AD risk. Within these candidate therapeutics, 16 had more than one clinical study supporting AD risk reduction. Top-ranked therapeutics with high confidence emerged within lipid-lowering, anti-inflammatory, hormone, and metabolic-related drug classes. Outcomes of our novel bioinformatic strategy support therapeutic targeting of biological mechanisms and pathways underlying relevant AD risk factors with high confidence. Early interventions that target pathways associated with increased risk of AD have the potential to support the goal of effectively preventing AD by 2025.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20998,""
"An automated essay scoring systems: a systematic literature review","Ramesh, Sanampudi","https://doi.org/10.1007/s10462-021-10068-2","20210930","PubMed","Assessment; Deep learning; Essay grading; Natural language processing; Short answer scoring","Assessment in the Education system plays a significant role in judging student performance. The present evaluation system is through human assessment. As the number of teachers' student ratio is gradually increasing, the manual evaluation process becomes complicated. The drawback of manual evaluation is that it is time-consuming, lacks reliability, and many more. This connection online examination system evolved as an alternative tool for pen and paper-based methods. Present Computer-based evaluation system works only for multiple-choice questions, but there is no proper evaluation system for grading essays and short answers. Many researchers are working on automated essay grading and short answer scoring for the last few decades, but assessing an essay by considering all parameters like the relevance of the content to the prompt, development of ideas, Cohesion, and Coherence is a big challenge till now. Few researchers focused on Content-based evaluation, while many of them addressed style-based assessment. This paper provides a systematic literature review on automated essay scoring systems. We studied the Artificial Intelligence and Machine Learning techniques used to evaluate automatic essay scoring and analyzed the limitations of the current studies and research trends. We observed that the essay evaluation is not done based on the relevance of the content and coherence. The online version contains supplementary material available at 10.1007/s10462-021-10068-2.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",20999,""
"Machine learning methods for predicting progression from mild cognitive impairment to Alzheimer's disease dementia: a systematic review","Grueso, Viejo-Sobera","https://doi.org/10.1186/s13195-021-00900-w","20211014","PubMed","AlzheimerÃ¢â‚¬â„¢s disease; Conversion; Machine learning; Magnetic resonance; Mild cognitive impairment; PRISMA; Positron emission tomography; Prediction; Alzheimer Disease; Brain; Cognitive Dysfunction; Disease Progression; Humans; Machine Learning; Magnetic Resonance Imaging; Neuroimaging","An increase in lifespan in our society is a double-edged sword that entails a growing number of patients with neurocognitive disorders, Alzheimer's disease being the most prevalent. Advances in medical imaging and computational power enable new methods for the early detection of neurocognitive disorders with the goal of preventing or reducing cognitive decline. Computer-aided image analysis and early detection of changes in cognition is a promising approach for patients with mild cognitive impairment, sometimes a prodromal stage of Alzheimer's diseaseÃ‚Â dementia. We conducted a systematic review following PRISMA guidelines of studies where machine learning was applied to neuroimaging data in order to predict whether patients with mild cognitive impairment might develop Alzheimer's disease dementia or remain stable. After removing duplicates, we screened 452 studies and selected 116 for qualitative analysis. Most studies used magnetic resonance image (MRI) and positron emission tomography (PET) data but also magnetoencephalography. The datasets were mainly extracted from the Alzheimer's disease neuroimaging initiative (ADNI) database with some exceptions. Regarding the algorithms used, the most common was support vector machine with a mean accuracy of 75.4%, but convolutional neural networks achieved a higher mean accuracy of 78.5%. Studies combining MRI and PET achieved overall better classification accuracy than studies that only used one neuroimaging technique. In general, the more complex models such as those based on deep learning, combined with multimodal and multidimensional data (neuroimaging, clinical, cognitive, genetic, and behavioral) achieved the best performance. Although the performance of the different methods still has room for improvement, the results are promising and this methodology has a great potential as a support tool for clinicians and healthcare professionals.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21000,""
"Topic modelling online depression forums: beyond narratives of self-objectification and self-blaming","Sik, NÃƒÂ©meth, Katona","https://doi.org/10.1080/09638237.2021.1979493","20210928","PubMed","Depression; narrative identity; online forum; text mining; topic model","Depression raises a double challenge: besides the negative mood and the intrusive thoughts, the relation to the self also becomes difficult. Online forums are analysed as communicative platforms enabling the interactive reconstruction of the self. The discourses of online depression forums are explored. Firstly, narrative patterns are identified according to their thematic focus (e.g. dysfunctional body, challenges of intimacy) and discursive logic (e.g. information exchange, support). Secondly, narratives are analysed in order to describe various ways of grounding a depressed self. Ã¢Ë†Â¼70.000 depression-related posts from the biggest English-speaking online forums (e.g. www.reddit.com/r/depression, www.healthunlocked.com) were analysed. Quantitative (LDA topic modelling) and qualitative (deep reading) approaches were used simultaneously to determine the optimal number of topics and their interpretation. 13 topics were identified and interpreted according to their content and communicative function. Based on the inter-topic distances four clusters were identified (medicalized, intimacy-oriented, critical and uninhabitable self-narratives). The clusters of the 13 topics highlight various ways of narrating depression and the depressed self. Based on a comparison with a systematic review of mental illness recovery narratives, depression forums cover most narrative genres and emotional tones, thus create a unique opportunity for integrating the depressing experiences in the self.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21001,""
"The challenges and facilitators to successful translation and adaptation of written self-report psychological measures into sign languages: A systematic review","Chatzidamianos, Burns, Andriopoulou, Archer, du Feu","https://doi.org/10.1037/pas0001061","20211027","PubMed","Humans; Psychometrics; Self Report; Sign Language; Translating; Translations","Deaf people are known to have significantly poorer reading comprehension skills when compared to their hearing counterparts. This poses significant threats to text-based psychological assessments. The plethora of text-based self-report measures available provides ample opportunity to translate/adapt existing tools from text to sign language. This paper systematically reviewed the challenges and facilitators faced in previous translations/adaptations with the view to inform recommendations for future practice. This paper reports the results of a Preferred Reporting Items for Systematic Reviews and Meta-Analyses-informed systematic review of 30 studies that had translated or discussed the translation of a written self-report measure into sign language following screening against inclusion/exclusion criteria. A systematic search (powered by EbscoHost Research Database and using search terms and Boolean operators), was performed in The Allied and Complementary Medicine Database (AMED), Cinahl, Medline, APA PsycInfo, and APA PsycArticles. The Quality Assessment with Diverse Studies tool was used for quality appraisal of the included papers. Challenges/facilitators to effective translation/adaptation were grouped under linguistic, procedural, and cultural. Examples of specific linguistic, procedural, cultural challenges, and facilitators are discussed in the context of previous research and study limitations. Translating/adapting text-based self-report measures to sign language is a linguistically and procedurally demanding endeavor that requires a deep bicultural/bilingual understanding of both deaf and hearing communities. The present results and recommendations can help researchers develop suitably accessible translated/adapted self-report psychological measures and this can have significant implications on healthcare service planning and delivery. (PsycInfo Database Record (c) 2021 APA, all rights reserved).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21002,""
"Applications of Artificial Intelligence to Office Laryngoscopy: A Scoping Review","Yao, Usman, Chen, German, Andreadis, Mages, Rameau","https://doi.org/10.1002/lary.29886","20210928","PubMed","Laryngology; artificial intelligence; laryngoscopy; scoping review","This scoping review aims to provide a broad overview of the applications of artificial intelligence (AI) to office laryngoscopy to identify gaps in knowledge and guide future research. Scoping Review. Searches for studies on AI and office laryngoscopy were conducted in five databases. Title and abstract and then full-text screening were performed. Primary research studies published in English of any date were included. Studies were summarized by: AI applications, targeted conditions, imaging modalities, author affiliations, and dataset characteristics. Studies focused on vocal fold vibration analysis (43%), lesion recognition (24%), and vocal fold movement determination (19%). The most frequently automated tasks were recognition of vocal fold nodules (19%), polyp (14%), paralysis (11%), paresis (8%), and cyst (7%). Imaging modalities included high-speed laryngeal videos (45%), stroboscopy (29%), and narrow band imaging endoscopy (7%). The body of literature was primarily authored by science, technology, engineering, and math (STEM) specialists (76%) with only 30 studies (31%) involving co-authorship by STEM specialists and otolaryngologists. Datasets were mostly from single institution (84%) and most commonly originated from Germany (23%), USA (16%), Spain (9%), Italy (8%), and China (8%). Demographic information was only reported in 39 studies (40%), with age and sex being the most commonly reported, whereas race/ethnicity and gender were not reported in any studies. More interdisciplinary collaboration between STEM and otolaryngology research teams improved demographic reporting especially of race and ethnicity to ensure broad representation, and larger and more geographically diverse datasets will be crucial to future research on AI in office laryngoscopy. N/A Laryngoscope, 2021.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21003,""
"[Integration of structured reporting into the routine radiological workflow]","Kim, Mir-Bashiri, Matthies, Sommer, NÃƒÂ¶renberg","https://doi.org/10.1007/s00117-021-00917-0","20211101","PubMed","Artificial intelligence; Decision support; Report templates; Reporting systems; Structured data acquisition; Humans; Radiology; Radiology Information Systems; Software; Systems Integration; Workflow","Structured reporting has been one of the most discussed topics in radiology for years. Currently, there is aÃ‚Â lack of user-friendly software solutions that are integrated into the IT infrastructure of hospitals and practices to allow efficient data entry. Radiological reports are mostly generated as free text documents, either dictated via speech recognition systems or typed. In addition, text components are used to create reports of normal findings that can be further edited and complemented by free text. Software-based reporting systems can combine speech recognition systems with radiological reporting templates in the form of interactive decision trees. AÃ‚Â technical integration into RIS (""radiological information system""), PACS (""picture archiving and communication system""), and AV (""advanced visualization"") systems via application programming interfaces and interoperability standards can enable efficient processes and the generation of machine-readable report data. Structured and semantically annotated clinical data collected via the reporting system are immediately available for epidemiological data analysis and continuous AI training. The use of structured reporting in routine radiological diagnostics involves an initial transition phase. AÃ‚Â successful implementation further requires close integration of the technical infrastructure of several systems. By using aÃ‚Â hybrid reporting solution, radiological reports with different levels of structure can be generated. Clinical questions or procedural information can be semi-automatically transferred, thereby eliminating avoidable errors and increasing productivity. KLINISCHES/METHODISCHES PROBLEM: Strukturierte Befundung ist seit Jahren eines der meist diskutierten Themen in der Radiologie. Aktuell herrscht ein Mangel an nutzerfreundlichen SoftwarelÃƒÂ¶sungen, welche in die bestehende IT-Infrastruktur der Kliniken und Praxen integriert sind und effiziente Dateneingaben erlauben. Radiologische Befunde werden meist als Freitext ÃƒÂ¼ber Spracherkennungssysteme diktiert oder per Tastatur eingegeben. Zudem werden Textbausteine fÃƒÂ¼r die Erstellung von Normalbefunden verwendet und bei Bedarf durch Freitextinhalte ergÃƒÂ¤nzt. Softwarebasierte Befundungssysteme kÃƒÂ¶nnen Spracherkennungssysteme mit radiologischen Befundvorlagen in Form von interaktiven EntscheidungsbÃƒÂ¤umen vereinen. Eine technische Integration in RIS(Radiologieinformationssystem)-, PACS(Ã¢â‚¬Å¾picture archiving and communication systemÃ¢â‚¬Å“)- und AV(Ã¢â‚¬Å¾advanced visualizationÃ¢â‚¬Å“)-Systeme ÃƒÂ¼ber Programmierschnittstellen und InteroperabilitÃƒÂ¤tsstandards ermÃƒÂ¶glicht effiziente Prozesse und die Generierung maschinenlesbarer Befunddaten. LEISTUNGSFÃƒÂ¤HIGKEIT: Strukturierte, semantisch annotierte klinische Daten, die ÃƒÂ¼ber ein strukturiertes Befundungssystem erhoben werden, stehen unmittelbar fÃƒÂ¼r epidemiologische Datenauswertungen und kontinuierliches KI(KÃƒÂ¼nstliche Intelligenz)-Training zur VerfÃƒÂ¼gung. Der Einsatz der strukturierten Befundung in der radiologischen Routinediagnostik ist mit einer initialen Umstellungsphase verbunden. Eine erfolgreiche Implementierung setzt eine enge Verzahnung der technischen Infrastruktur mehrerer Systeme voraus. EMPFEHLUNG FÃƒÂ¼R DIE PRAXIS: Durch die Nutzung einer hybriden, softwarebasierten BefundungslÃƒÂ¶sung kÃƒÂ¶nnen radiologische Befunde mit unterschiedlichen Stufen der Struktur generiert werden. Klinische Fragestellungen oder Informationen kÃƒÂ¶nnen aus klinischen Subsystemen semiautomatisch ÃƒÂ¼bertragen werden, um vermeidbare Fehler zu eliminieren und die ProduktivitÃƒÂ¤t zu erhÃƒÂ¶hen.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21004,""
"Defining Patient-Oriented Natural Language Processing: A New Paradigm for Research and Development to Facilitate Adoption and Use by Medical Experts","Sarker, Al-Garadi, Yang, Choi, Quyyumi, Martin","https://doi.org/10.2196/18471","20210929","PubMed","evidence-based medicine; medical informatics; natural language processing; patient-centered care; text mining","The capabilities of natural language processing (NLP) methods have expanded significantly in recent years, and progress has been particularly driven by advances in data science and machine learning. However, NLP is still largely underused in patient-oriented clinical research and care (POCRC). A key reason behind this is that clinical NLP methods are typically developed, optimized, and evaluated with narrowly focused data sets and tasks (eg, those for the detection of specific symptoms in free texts). Such research and development (R&amp;D) approaches may be described as problem oriented, and the developed systems perform specialized tasks well. As standalone systems, however, they generally do not comprehensively meet the needs of POCRC. Thus, there is often a gap between the capabilities of clinical NLP methods and the needs of patient-facing medical experts. We believe that to increase the practical use of biomedical NLP, future R&amp;D efforts need to be broadened to a new research paradigm-one that explicitly incorporates characteristics that are crucial for POCRC. We present our viewpoint about 4 such interrelated characteristics that can increase NLP systems' suitability for POCRC (3 that represent NLP system properties and 1 associated with the R&amp;D process)-(1) interpretability (the ability to explain system decisions), (2) patient centeredness (the capability to characterize diverse patients), (3) customizability (the flexibility for adapting to distinct settings, problems, and cohorts), and (4) multitask evaluation (the validation of system performance based on multiple tasks involving heterogeneous data sets). By using the NLP task of clinical concept detection as an example, we detail these characteristics and discuss how they may result in the increased uptake of NLP systems for POCRC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21005,""
"CT Angiography Clot Burden Score from Data Mining of Structured Reports for Pulmonary Embolism","Fink, Mayer, Schneider, Seibold, Stiefelhagen, Kleesiek, Weber, Kauczor","https://doi.org/10.1148/radiol.2021211013","20210928","PubMed","","Background Many studies emphasize the role of structured reports (SRs) because they are readily accessible for further automated analyses. However, using SR data obtained in clinical routine for research purposes is not yet well represented in literature. Purpose To compare the performance of the Qanadli scoring system with a clot burden score mined from structured pulmonary embolism (PE) reports from CT angiography. Materials and Methods In this retrospective study, a rule-based text mining pipeline was developed to extract descriptors of PE and right heart strain from SR of patients with suspected PE between March 2017 and February 2020. From standardized PE reporting, a pulmonary artery obstruction index (PAOI) clot burden score (PAOI<sub>CBS</sub>) was derived and compared with the Qanadli score (PAOI<sub>Q</sub>). Scoring time and confidence from two independent readings were compared. Interobserver and interscore agreement was tested by using the intraclass correlation coefficient (ICC) and Bland-Altman analysis. To assess conformity and diagnostic performance of both scores, areas under the receiver operating characteristic curve (AUCs) were calculated to predict right heart strain incidence, as were optimal cutoff values for maximum sensitivity and specificity. Results SR content authored by 67 residents and signed off by 32 consultants from 1248 patients (mean age, 63 years Ã‚Â± 17 [standard deviation]; 639 men) was extracted accurately and allowed for PAOI<sub>CBS</sub> calculation in 304 of 357 (85.2%) PE-positive reports. The PAOI<sub>CBS</sub> strongly correlated with the PAOI<sub>Q</sub> (<i>r</i> = 0.94; <i>P</i> &lt; .001). Use of PAOI<sub>CBS</sub> yielded overall time savings (1.3 minutes Ã‚Â± 0.5 vs 3.0 minutes Ã‚Â± 1.7), higher confidence levels (4.2 Ã‚Â± 0.6 vs 3.6 Ã‚Â± 1.0), and a higher ICC (ICC, 0.99 vs 0.95), respectively, compared with PAOI<sub>Q</sub> (each, <i>P</i> &lt; .001). AUCs were similar for PAOI<sub>CBS</sub> (AUC, 0.75; 95% CI: 0.70, 0.81) and PAOI<sub>Q</sub> (AUC, 0.77; 95% CI: 0.72, 0.83; <i>P</i> = .68), with cutoff values of 27.5% for both scores. Conclusion Data mining of structured reports enabled the development of a CT angiography scoring system that simplified the Qanadli score as a semiquantitative estimate of thrombus burden in patients with pulmonary embolism. Ã‚Â© RSNA, 2021 <i>Online supplemental material is available for this article.</i> See also the editorial by Hunsaker in this issue.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21006,""
"[Mechanism of Magnoliae Officinalis Cortex in treatment of peptic ulcer based on network pharmacology and molecular docking]","Yang, Luo, Liu, Lin, Gao, Zhou","https://doi.org/10.19540/j.cnki.cjcmm.20210609.702","20210929","PubMed","Magnoliae Officinalis Cortex; PPAR-ÃŽÂ³ signaling pathway; molecular docking; network pharmacology; p53 signaling pathway; peptic ulcer disease; Drugs, Chinese Herbal; Humans; Molecular Docking Simulation; Peptic Ulcer; Protein Interaction Maps; Receptor, Muscarinic M1; Signal Transduction","Magnoliae Officinalis Cortex(Houpo) can treat peptic ulcer disease(PUD), the mechanism of which remains unclear. In this study, network pharmacology and molecular docking were employed to predict the mechanism of Houpo in the treatment of PUD. Through literature review and TCMSP screening, 15 main active ingredients were obtained. The SwissTargetPrediction database was used to predict the potential targets of the ingredients, and Therapeutic Target Database(TTD), DrugBank, and Human Phenotype Ontology(HPO) to screen the disease-related targets. A total of 49 potential targets were obtained by the intersection of active ingre-dients-related targets and disease-related targets. Cytoscape 3.6.1 was employed to construct the protein-protein interaction network for the targets with high confidence(score&amp;gt;0.700) screened out by STRING. The DAVID database was used for GO and KEGG pathway enrichment of potential targets. GO enrichment analysis showed that the treatment mechanism was mostly related to nuclear receptor activity, ligand-activated transcription factor activity, and G protein-coupled acetylcholine receptor activity. KEGG enrichment analysis found that Houpo could regulate material metabolism, endocrine system, p53 signaling pathway, and PPAR signaling pathway. Molecu-lar docking verified that all 15 ingredients had good binding activities with key targets(CHRM1, CHRM2, FABP1, mTOR, and STAT3). The results mean that Houpo can treat PUD by participating in cell metabolism, inhibiting inflammatory cytokines, and regulating cell proliferation and apoptosis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21007,""
"Detection of Baseline Emotion in Brow Lift Patients Using Artificial Intelligence","Boonipat, Lin, Bite","https://doi.org/10.1007/s00266-021-02430-0","20210928","PubMed","Artificial intelligence; Brow lift; Endoscopic browlift; FaceReader","The widespread popularity of browlifts and blepharoplasties speaks directly to the importance that patients place on the periorbital region of the face. In literature, most esthetic outcomes are based on instinctive analysis of the esthetic surgeon, rather than on patient assessments, public opinions, or other objective means. We employed an artificial intelligence system to objectively measure the impact of brow lifts and associated rejuvenation procedures on the appearance of emotion while the patient is in repose. We retrospectively identified all patients who underwent bilateral brow lift for visual field obstruction between 2006 and 2019. Images were analyzed using a commercially available facial expression recognition software package (FaceReaderÃ¢â€žÂ¢, Noldus Information Technology BV, Wageningen, Netherlands). The data generated reflected the proportion of each emotion expressed for any given facial movement and the action units associated. A total of 52 cases were identified after exclusion. Pre-operatively, the angry, happy, sad, scared, and surprised emotion were detected on average of 13.06%, 1.68%, 13.06%, 3.53%, and 0.97% among all the patients, respectively. Post-operatively, the angry emotion average decreased to 5.42% (p=0.009). The happy emotion increased to 9.35% (p=0.0013), while the sad emotion decreased to 5.42%. The scared emotion remained relatively the same at 3.4%, and the surprised emotion increased to 2.01%; however, these were not statistically significant. This study proposes a paradigm shift in the clinical evaluation of brow lift and other facial esthetic surgery, implementing an existing facial emotion recognition system to quantify changes in expression associated with facial surgery. This journal requires that authors assign a level of evidence to each article. For a full description of these Evidence-Based Medicine ratings, please refer to the Table of Contents or the online Instructions to Authors www.springer.com/00266 .","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21008,""
"A Systematic Review of Machine Learning Based Gait characteristics in Parkinson's disease","Sharma, Pahuja, Veer","https://doi.org/10.2174/1389557521666210927151553","20210928","PubMed","Classifiers Assessment; Gait; Machine Learning Tools; Parkinson's disease (PD)","Parkinson's disease is a pervasive neuro disorder that affects people's quality of life throughout the world. The unsatisfactory results of clinical rating scales open the door for more research. PD treatment using current biomarkers seems a difficult task. So automatic evaluation at an early stage may enhance the quality and time-period of life. Grading of Recommendations Assessment, Development, and Evaluation (GRADE) and Population, intervention, comparison, and outcome (PICO) search methodology schemes are followed to search the data and eligible studies for this survey. Approximate 1500 articles were extracted using related search strings. After the stepwise mapping and elimination of studies, 94 papers are found suitable for the present review. After the quality assessment of extracted studies, nine inhibitors are identified to analyze people's gait with Parkinson's disease, where four are critical. This review also differentiates the various machine learning classification techniques with their PD analysis characteristics in previous studies. The extracted research gaps are described as future perspectives. Results can help practitioners understand the PD gait as a valuable biomarker for detection, quantification, and classification. Due to less cost and easy recording of gait, gait-based techniques are becoming popular in PD detection. By encapsulating the gait-based studies, it gives an in-depth knowledge of PD, different measures that affect gait detection and classification.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21009,""
"A Comprehensive Review of Techniques for Processing and Analyzing Fetal Heart Rate Signals","Ponsiglione, Cosentino, Cesarelli, Amato, Romano","https://doi.org/10.3390/s21186136","20210929","PubMed","artificial neural networks; biomedical signal processing and analysis; fetal heart rate; fetal heart rate variability; linear FHRV indices; nonlinear FHRV indices; Algorithms; Artificial Intelligence; Cardiotocography; Female; Heart Rate; Heart Rate, Fetal; Humans; Neural Networks, Computer; Pregnancy","The availability of standardized guidelines regarding the use of electronic fetal monitoring (EFM) in clinical practice has not effectively helped to solve the main drawbacks of fetal heart rate (FHR) surveillance methodology, which still presents inter- and intra-observer variability as well as uncertainty in the classification of unreassuring or risky FHR recordings. Given the clinical relevance of the interpretation of FHR traces as well as the role of FHR as a marker of fetal wellbeing autonomous nervous system development, many different approaches for computerized processing and analysis of FHR patterns have been proposed in the literature. The objective of this review is to describe the techniques, methodologies, and algorithms proposed in this field so far, reporting their main achievements and discussing the value they brought to the scientific and clinical community. The review explores the following two main approaches to the processing and analysis of FHR signals: traditional (or linear) methodologies, namely, time and frequency domain analysis, and less conventional (or nonlinear) techniques. In this scenario, the emerging role and the opportunities offered by Artificial Intelligence tools, representing the future direction of EFM, are also discussed with a specific focus on the use of Artificial Neural Networks, whose application to the analysis of accelerations in FHR signals is also examined in a case study conducted by the authors.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21010,""
"A Systematic Review of the Application of Camera-Based Human Pose Estimation in the Field of Sport and Physical Exercise","Badiola-Bengoa, Mendez-Zorrilla","https://doi.org/10.3390/s21185996","20210929","PubMed","human joint estimation; human pose estimation; keypoint detection; physical exercise; sport; Adaptation, Physiological; Exercise; Humans; Sports","Human Pose Estimation (HPE) has received considerable attention during the past years, improving its performance thanks to the use of Deep Learning, and introducing new interesting uses, such as its application in Sport and Physical Exercise (SPE). The aim of this systematic review is to analyze the literature related to the application of HPE in SPE, the available data, methods, performance, opportunities, and challenges. One reviewer applied different inclusion and exclusion criteria, as well as quality metrics, to perform the paper filtering through the paper databases. The Association for Computing Machinery Digital Library, Web of Science, and dblp included more than 500 related papers after the initial filtering, finally resulting in 20. In addition, research was carried out regarding the publicly available data related to this topic. It can be concluded that even if related public data can be found, much more data is needed to be able to obtain good performance in different contexts. In relation with the methods of the authors, the use of general purpose systems as base, such as Openpose, combined with other methods and adaptations to the specific use case can be found. Finally, the limitations, opportunities, and challenges are presented.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21011,""
"Sample Preparation and Diagnostic Methods for a Variety of Settings: A Comprehensive Review","Nichols, Geddes","https://doi.org/10.3390/molecules26185666","20211001","PubMed","biosensors; extraction; high-throughput screening; medical diagnosis; microfluidics; point-of-care (POC); point-of-care testing (POCT); sample preparation; separations; Biosensing Techniques; COVID-19; Communicable Diseases; High-Throughput Screening Assays; Humans; Pandemics; Point-of-Care Systems; Point-of-Care Testing; SARS-CoV-2; Specimen Handling","Sample preparation is an essential step for nearly every type of biochemical analysis in use today. Among the most important of these analyses is the diagnosis of diseases, since their treatment may rely greatly on time and, in the case of infectious diseases, containing their spread within a population to prevent outbreaks. To address this, many different methods have been developed for use in the wide variety of settings for which they are needed. In this work, we have reviewed the literature and report on a broad range of methods that have been developed in recent years and their applications to point-of-care (POC), high-throughput screening, and low-resource and traditional clinical settings for diagnosis, including some of those that were developed in response to the coronavirus disease 2019 (COVID-19) pandemic. In addition to covering alternative approaches and improvements to traditional sample preparation techniques such as extractions and separations, techniques that have been developed with focuses on integration with smart devices, laboratory automation, and biosensors are also discussed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21012,""
"Prostate Cancer Radiogenomics-From Imaging to Molecular Characterization","Ferro, de Cobelli, Vartolomei, Lucarelli, Crocetto, Barone, Sciarra, Del Giudice, Muto, Maggi, Carrieri, Busetto, Falagario, Terracciano, Cormio, Musi, Tataru","https://doi.org/10.3390/ijms22189971","20211019","PubMed","MRI; PET-CT; genomics; molecular characterization; prostate cancer; radiogenomics; radiomics; Diagnostic Imaging; Genomics; Humans; Male; Molecular Imaging; Prostatic Neoplasms; Risk Factors","Radiomics and genomics represent two of the most promising fields of cancer research, designed to improve the risk stratification and disease management of patients with prostate cancer (PCa). Radiomics involves a conversion of imaging derivate quantitative features using manual or automated algorithms, enhancing existing data through mathematical analysis. This could increase the clinical value in PCa management. To extract features from imaging methods such as magnetic resonance imaging (MRI), the empiric nature of the analysis using machine learning and artificial intelligence could help make the best clinical decisions. Genomics information can be explained or decoded by radiomics. The development of methodologies can create more-efficient predictive models and can better characterize the molecular features of PCa. Additionally, the identification of new imaging biomarkers can overcome the known heterogeneity of PCa, by non-invasive radiological assessment of the whole specific organ. In the future, the validation of recent findings, in large, randomized cohorts of PCa patients, can establish the role of radiogenomics. Briefly, we aimed to review the current literature of highly quantitative and qualitative results from well-designed studies for the diagnoses, treatment, and follow-up of prostate cancer, based on radiomics, genomics and radiogenomics research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21013,""
"Personalised Medicine for Colorectal Cancer Using Mechanism-Based Machine Learning Models","Nwaokorie, Fey","https://doi.org/10.3390/ijms22189970","20211019","PubMed","WNT pathway; biomarkers; cancer; colorectal cancer; event-free survival; pathways; signal transduction networks; targeted therapy; Colorectal Neoplasms; Gene Expression Regulation, Neoplastic; Humans; Kaplan-Meier Estimate; Linear Models; Machine Learning; Models, Biological; Neoplasm Proteins; Precision Medicine; Progression-Free Survival; Proteomics; Wnt Signaling Pathway","Gaining insight into the mechanisms of signal transduction networks (STNs) by using critical features from patient-specific mathematical models can improve patient stratification and help to identify potential drug targets. To achieve this, these models should focus on the critical STNs for each cancer, include prognostic genes and proteins, and correctly predict patient-specific differences in STN activity. Focussing on colorectal cancer and the WNT STN, we used mechanism-based machine learning models to identify genes and proteins with significant associations to event-free patient survival and predictive power for explaining patient-specific differences of STN activity. First, we identified the WNT pathway as the most significant pathway associated with event-free survival. Second, we built linear-regression models that incorporated both genes and proteins from established mechanistic models in the literature and novel genes with significant associations to event-free patient survival. Data from The Cancer Genome Atlas and Clinical Proteomic Tumour Analysis Consortium were used, and patient-specific STN activity scores were computed using PROGENy. Three linear regression models were built, based on; (1) the gene-set of a state-of-the-art mechanistic model in the literature, (2) novel genes identified, and (3) novel proteins identified. The novel genes and proteins were genes and proteins of the extant WNT pathway whose expression was significantly associated with event-free survival. The results show that the predictive power of a model that incorporated novel event-free associated genes is better compared to a model focussing on the genes of a current state-of-the-art mechanistic model. Several significant genes that should be integrated into future mechanistic models of the WNT pathway are DVL3, FZD5, RAC1, ROCK2, GSK3B, CTB2, CBT1, and PRKCA. Thus, the study demonstrates that using mechanistic information in combination with machine learning can identify novel features (genes and proteins) that are important for explaining the STN heterogeneity between patients and their association to clinical outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21014,""
"A Human Pan-Cancer System Analysis of Procollagen-Lysine, 2-Oxoglutarate 5-Dioxygenase 3 (PLOD3)","Gong, Duan, Wu, Osterhoff, Schopow, Kallendrusch","https://doi.org/10.3390/ijms22189903","20211022","PubMed","PLOD3; big data; enrichment analysis; immune infiltration; immunotherapy; pan-cancer; prognosis; tumor; Gene Expression Regulation, Neoplastic; Gene Ontology; Gene Regulatory Networks; Humans; Lymphocytes, Tumor-Infiltrating; Microsatellite Instability; Mutation; Neoplasms; Procollagen-Lysine, 2-Oxoglutarate 5-Dioxygenase; Survival Analysis","The overexpression of the enzymes involved in the degradation of procollagen lysine is correlated with various tumor entities. Procollagen-lysine, 2-oxoglutarate 5-dioxygenase 3 (PLOD3) expression was found to be correlated to the progression and migration of cancer cells in gastric, lung and prostate cancer. Here, we analyzed the gene expression, protein expression, and the clinical parameters of survival across 33 cancers based on the Clinical Proteomic Tumor Analysis Consortium (CPTAC), function annotation of the mammalian genome 5 (FANTOM5), Gene Expression Omnibus (GEO), Genotype-Tissue Expression (GTEx), Human Protein Atlas (HPA) and The Cancer Genome Atlas (TCGA) databases. Genetic alteration, immune infiltration and relevant cellular pathways were analyzed in detail. PLOD3 expression negatively correlated with survival periods and the infiltration level of CD8<sup>+</sup> T cells, but positively correlated to the infiltration of cancer associated fibroblasts in diverse cancers. Immunohistochemistry in colon carcinomas, glioblastomas, and soft tissue sarcomas further confirm PLOD 3 expression in human cancer tissue. Moreover, amplification and mutation accounted for the largest proportion in esophageal adenocarcinoma and uterine corpus endometrial carcinoma, respectively; the copy number alteration of PLOD3 appeared in all cancers from TCGA; and molecular mechanisms further proved the effect of PLOD3 on tumorigenesis. In particular, PLOD3 expression appears to have a tumor immunological effect, and is related to multiple immune cells. Furthermore, it is also associated with tumor mutation burden and microsatellite instability in various tumors. PLOD3 acts as an inducer of various cancers, and it could be a potential biomarker for prognosis and targeted treatment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21015,""
"Feature Explanations in Recurrent Neural Networks for Predicting Risk of Mortality in Intensive Care Patients","Na Pattalung, Ingviya, Chaichulee","https://doi.org/10.3390/jpm11090934","20211001","PubMed","critical care; early warning scores; explainable artificial intelligence; machine learning; mortality; recurrent neural networks; time-series prediction","Critical care staff are presented with a large amount of data, which made it difficult to systematically evaluate. Early detection of patients whose condition is deteriorating could reduce mortality, improve treatment outcomes, and allow a better use of healthcare resources. In this study, we propose a data-driven framework for predicting the risk of mortality that combines high-accuracy recurrent neural networks with interpretable explanations. Our model processes time-series of vital signs and laboratory observations to predict the probability of a patient's mortality in the intensive care unit (ICU). We investigated our approach on three public critical care databases: Multiparameter Intelligent Monitoring in Intensive Care III (MIMIC-III), MIMIC-IV, and eICU. Our models achieved an area under the receiver operating characteristic curve (AUC) of 0.87-0.91. Our approach was not only able to provide the predicted mortality risk but also to recognize and explain the historical contributions of the associated factors to the prediction. The explanations provided by our model were consistent with the literature. Patients may benefit from early intervention if their clinical observations in the ICU are continuously monitored in real time.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21016,""
"A Systematic Review on the Contribution of Artificial Intelligence in the Development of Medicines for COVID-2019","Pires","https://doi.org/10.3390/jpm11090926","20211001","PubMed","COVID-2019; SARS-CoV-2; artificial intelligence; drug design; in silico methods; machine learning; medicines; molecular docking; molecular dynamics; repurposing of drugs","COVID-2019 pandemic lead to a raised interest on the development of new treatments through Artificial Intelligence (AI). to carry out a systematic review on the development of repurposed drugs against COVID-2019 through the application of AI. The Systematic Reviews and Meta-Analyses (PRISMA) checklist was applied. [""Artificial intelligence"" and (COVID or SARS) and (medicine or drug)]. Databases: PubMed<sup>Ã‚Â®</sup>, DOAJ and SciELO. Cochrane Library was additionally screened to identify previous published reviews on the same topic. From the 277 identified records [PubMed<sup>Ã‚Â®</sup> (n = 157); DOAJ (<i>n</i> = 119) and SciELO (<i>n</i> = 1)], 27 studies were included. Among other, the selected studies on new treatments against COVID-2019 were classified, as follows: studies with in-vitro and/or clinical data; association of known drugs; and other studies related to repurposing of drugs. Diverse potentially repurposed drugs against COVID-2019 were identified. The repurposed drugs were mainly from antivirals, antibiotics, anticancer, anti-inflammatory, and Angiotensin-converting enzyme 2 (ACE2) groups, although diverse other pharmacologic groups were covered. AI was a suitable tool to quickly analyze large amounts of data or to estimate drug repurposing against COVID-2019.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21017,""
"COVID Mortality Prediction with Machine Learning Methods: A Systematic Review and Critical Appraisal","Bottino, Tagliente, Pasquini, Napoli, Lucignani, FigÃƒÂ -Talamanca, Napolitano","https://doi.org/10.3390/jpm11090893","20211001","PubMed","COVID; computer Tomography (CT); deep learning; imaging; machine learning; mortality; prediction","More than a year has passed since the report of the first case of coronavirus disease 2019 (COVID), and increasing deaths continue to occur. Minimizing the time required for resource allocation and clinical decision making, such as triage, choice of ventilation modes and admission to the intensive care unit is important. Machine learning techniques are acquiring an increasingly sought-after role in predicting the outcome of COVID patients. Particularly, the use of baseline machine learning techniques is rapidly developing in COVID mortality prediction, since a mortality prediction model could rapidly and effectively help clinical decision-making for COVID patients at imminent risk of death. Recent studies reviewed predictive models for SARS-CoV-2 diagnosis, severity, length of hospital stay, intensive care unit admission or mechanical ventilation modes outcomes; however, systematic reviews focused on prediction of COVID mortality outcome with machine learning methods are lacking in the literature. The present review looked into the studies that implemented machine learning, including deep learning, methods in COVID mortality prediction thus trying to present the existing published literature and to provide possible explanations of the best results that the studies obtained. The study also discussed challenging aspects of current studies, providing suggestions for future developments.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21018,""
"Filtration-Histogram Based Magnetic Resonance Texture Analysis (MRTA) for the Distinction of Primary Central Nervous System Lymphoma and Glioblastoma","MacIver, Busaidi, Ganeshan, Maynard, Wastling, Hyare, Brandner, Markus, Lewis, Groves, Cwynarski, Thust","https://doi.org/10.3390/jpm11090876","20211001","PubMed","brain; computer-assisted; glioblastoma; lymphoma; magnetic resonance imaging","Primary central nervous system lymphoma (PCNSL) has variable imaging appearances, which overlap with those of glioblastoma (GBM), thereby necessitating invasive tissue diagnosis. We aimed to investigate whether a rapid filtration histogram analysis of clinical MRI data supports the distinction of PCNSL from GBM. Ninety tumours (PCNSL <i>n</i> = 48, GBM <i>n</i> = 42) were analysed using pre-treatment MRI sequences (T<sub>1</sub>-weighted contrast-enhanced (T<sub>1</sub>CE), T<sub>2</sub>-weighted (T<sub>2</sub>), and apparent diffusion coefficient maps (ADC)). The segmentations were completed with proprietary texture analysis software (TexRAD version 3.3). Filtered (five filter sizes SSF = 2-6 mm) and unfiltered (SSF = 0) histogram parameters were compared using Mann-Whitney U non-parametric testing, with receiver operating characteristic (ROC) derived area under the curve (AUC) analysis for significant results. Across all (<i>n</i> = 90) tumours, the optimal algorithm performance was achieved using an unfiltered ADC mean and the mean of positive pixels (MPP), with a sensitivity of 83.8%, specificity of 8.9%, and AUC of 0.88. For subgroup analysis with &gt;1/3 necrosis masses, ADC permitted the identification of PCNSL with a sensitivity of 96.9% and specificity of 100%. For T<sub>1</sub>CE-derived regions, the distinction was less accurate, with a sensitivity of 71.4%, specificity of 77.1%, and AUC of 0.779. A role may exist for cross-sectional texture analysis without complex machine learning models to differentiate PCNSL from GBM. ADC appears the most suitable sequence, especially for necrotic lesion distinction.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21019,""
"Leveraging Clinical Decision Support and Integrated Medical-Dental Electronic Health Records to Implementing Precision in Oral Cancer Risk Assessment and Preventive Intervention","Rindal, Mabry","https://doi.org/10.3390/jpm11090832","20211001","PubMed","SBIRT; artificial intelligence in health care; clinical practice; implementation; oral cancer risk; oropharyngeal cancer risk; precision medicine; prevention; screening","Precision medicine is focused on serving the unique needs of individuals. Oral and oropharyngeal cancer risk assessment identifies individual risk factors while providing support to reduce risk. The objective is to examine potential current and future strategies to broadly implement evidence-based oral and oropharyngeal cancer risk assessment and screening in dental practices throughout the United States. Feasible and effective oral cancer risk assessment and risk reduction strategies, ripe for implementation in dental practice, were identified in the published literature. The Screening, Brief Intervention, Referral for Treatment (SBIRT) model is a feasible approach to assessing individual oral cancer risk and providing risk reducing interventions in the dental setting. HPV is a more recently identified risk factor that dentistry is well positioned to address. Evidence supporting the utilization of specific risk assessment tools and risk reduction strategies is summarized and future opportunities discussed. Current knowledge of risk factors for oral and oropharyngeal cancers support the recommendation for dental providers to routinely assess all patients for risk factors, educate them about their personal level of cancer risk, and recommend actions to reduce relevant risk factors. Individuals ages 9-26 should be asked about their HPV vaccination status, educated about HPV and oropharyngeal cancer and receive a recommendation to get the HPV vaccination.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21020,""
"""Lessons Learned"" Preventing Recurrent Ischemic Strokes through Secondary Prevention Programs: A Systematic Review","Lambert, Olulana, Bailey-Davis, Abedi, Zand","https://doi.org/10.3390/jcm10184209","20211001","PubMed","cerebrovascular disease; recurrent stroke; secondary prevention","Recurrent ischemic strokes are a cause of significant healthcare burdens globally. Patients with uncontrolled vascular risk factors are more likely to develop recurrent ischemic strokes. This study aims to compile information gained from current secondary prevention programs. A pre-defined literature search strategy was applied to PubMed, SCOPUS, CINAHL, and Google Scholar databases, and studies from 1997 to 2020 were evaluated for quality, study aims, and outcomes. The search produced 1175 articles (1092 after duplicates were removed) and titles were screened; 55 titles were retained for the full-text analysis. Of the remaining studies, 31 were retained for assessment, five demonstrated long-term effectiveness, eight demonstrated short-term effectiveness, and 18 demonstrated no effectiveness. The successful studies utilized a variety of different techniques in the categories of physical fitness, education, and adherence to care plans to reduce the risk of recurrent strokes. The lessons we learned from the current prevention programs included (1) offer tailored care for underserved groups, (2) control blood pressure, (3) provide opportunities for medication dosage titration, (4) establish the care plan prior to discharge, (5) invest in supervised exercise programs, (6) remove barriers to accessing care in low resource settings, and (7) improve the transition of care.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21021,""
"Antimicrobial Resistance in Rural Settings in Latin America: A Scoping Review with a One Health Lens","Medina-Pizzali, Hartinger, Salmon-Mulanovich, Larson, Riveros, MÃƒÂ¤usezahl","https://doi.org/10.3390/ijerph18189837","20211029","PubMed","Latin America; anthropogenic activities; antimicrobial resistance; environment; livestock; one health; Animals; Anti-Bacterial Agents; Bacteria; Cattle; Drug Resistance, Bacterial; Humans; Latin America; One Health; Swine","Antimicrobial resistance (AMR) in rural Latin America is not fully understood. The transmission pathways are partially known since research predominantly focuses on the urban hospital setting. The contribution to AMR from environmental factors is usually only mentioned in large-scale animal production. To understand the state of the literature on AMR in rural LA, we carried out a scoping review using the One Health (OH) perspective. OH recognises the concomitant contributions and interconnectedness of humans, animal, and the environment, thus, we used the OH perspective to select those articles adopting a holistic view of the problem. We searched original articles in English, Spanish, and Portuguese in four peer-reviewed databases and included 21 publications in the analysis. We charted data on bibliometrics, design, data collection sources, and instruments. We identified the human, animal, and environmental contributions to AMR in rural locations, and information gaps on AMR transmission routes and AMR drivers. Intensive and non-intensive animal production systems and agricultural practices were the most frequently found human contributions to AMR. Poultry, swine, cattle, and fish were the most frequent livestock mentioned as sources of AMR bacteria. Animal carriage and/or transfer of AMR determinants or bacteria was recognised as the primary contribution of livestock to the problem, while water, soil, and farming were predominant environmental contributions. We found that only 1 article out of 21 considered the OH approach as a framework for their sampling scheme, whereas 5 out 21 discussed all the three OH components. There were hardly any descriptions of humans or human waste as reservoirs for AMR in rural locations, and rural health centres or hospitals and wildlife were not represented. No studies identified mining as an anthropogenic activity driving AMR. More OH-oriented studies, with emphasis on molecular approaches-for identification and comparison of AMR genes-are sorely needed to understand better the existence of a network of interconnected transmission routes in rural Latin America and provide efficient strategies to prevent further AMR emergence.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21022,""
"Preventing and Monitoring Work-Related Diseases in Firefighters: A Literature Review on Sensor-Based Systems and Future Perspectives in Robotic Devices","Taborri, Pasinetti, Cardinali, Perroni, Rossi","https://doi.org/10.3390/ijerph18189723","20211029","PubMed","firefighters; physiological and physical parameters; robotic devices; wearable sensors; work-related disease; Exoskeleton Device; Firefighters; Humans; Monitoring, Physiologic; Movement; Robotics","In recent years, the necessity to prevent work-related diseases has led to the use of sensor-based systems to measure important features during working activities. This topic achieved great popularity especially in hazardous and demanding activities such as those required of firefighters. Among feasible sensor systems, wearable sensors revealed their advantages in terms of possibility to conduct measures in real conditions and without influencing the movements of workers. In addition, the advent of robotics can be also exploited in order to reduce work-related disorders. The present literature review aims at providing an overview of sensor-based systems used to monitor physiological and physical parameters in firefighters during real activities, as well as to offer ideas for understanding the potentialities of exoskeletons and assistive devices.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21023,""
"The Influence of Academic Emotions on Learning Effects: A Systematic Review","Tan, Mao, Jiang, Gao","https://doi.org/10.3390/ijerph18189678","20211029","PubMed","academic emotions; cognitive; facial expressions; learning effects; systematic review; Academic Performance; Emotions; Humans; Schools; Students; Universities","Academic emotions can have different influences on learning effects, but these have not been systematically studied. In this paper, we objectively evaluate the influence of various academic emotions on learning effects and studied the relationship between positive and negative academic emotions and learning effects by using five electronic databases, including WOS, EMBASE, PubMed, PsycINFO, and Google Scholar. According to established standards, a total of 14 articles from 506 articles were included in the analysis. We divided the 14 studies into nine intervention studies and five observational studies; five of the nine intervention studies found that students who used active learning materials performed better and had higher mental loads than those who used neutral learning materials. Positive academic emotions promoted the learning effect. Four of the five observational studies with high school, college, and postgraduate participants reported that regulating academic emotions can improve learning effects. In conclusion, this paper holds that positive academic emotions are better than negative academic emotions at improving academic performance. In future research, a new method combining multichannel video observation, physiological data, and facial expression data is proposed to capture learners' learning behavior in various learning environments.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21024,""
"Artificial Intelligence Is Reshaping Healthcare amid COVID-19: A Review in the Context of Diagnosis &amp; Prognosis","Saha, Aich, Tripathy, Kim","https://doi.org/10.3390/diagnostics11091604","20211001","PubMed","AI; COVID-19; diagnosis; healthcare; interpretive structural modeling","Preventing respiratory failure is crucial in a large proportion of COVID-19 patients infected with SARS-CoV-2 virus pneumonia termed as Novel Coronavirus Pneumonia (NCP). Rapid diagnosis and detection of high-risk patients for effective interventions have been shown to be troublesome. Using a large, computed tomography (CT) database, we developed an artificial intelligence (AI) parameter to diagnose NCP and distinguish it from other kinds of pneumonia and traditional controls. The literature was studied and analyzed from diverse assets which include Scopus, Nature medicine, IEEE, Google scholar, Wiley Library, and PubMed. The search terms used were 'COVID-19', 'AI', 'diagnosis', and 'prognosis'. To strengthen the overall performance of AI in COVID-19 diagnosis and prognosis, we segregated several components to perceive threats and opportunities, as well as their inter-dependencies that affect the healthcare sector. This paper seeks to pick out the crucial fulfillment of factors for AI with inside the healthcare sector in the Indian context. Using critical literature review and experts' opinion, a total of 11 factors affecting COVID-19 diagnosis and prognosis were detected, and we eventually used an interpretive structural model (ISM) to build a framework of interrelationships among the identified factors. Finally, the matrice d'impacts croisÃƒÂ©s multiplication appliquÃƒÂ©e ÃƒÂ¡ un classment (MICMAC) analysis resulted the driving and dependence powers of these identified factors. Our analysis will help healthcare stakeholders to realize the requirements for successful implementation of AI.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21025,""
"Recent Advances in Intelligent Source Code Generation: A Survey on Natural Language Based Studies","Yang, Liu, Yin","https://doi.org/10.3390/e23091174","20210930","PubMed","machine learning application; natural language-based source code generation; systematic literature review","Source Code Generation (SCG) is a prevalent research field in the automation software engineering sector that maps specific descriptions to various sorts of executable code. Along with the numerous intensive studies, diverse SCG types that integrate different scenarios and contexts continue to emerge. As the ultimate purpose of SCG, Natural Language-based Source Code Generation (NLSCG) is growing into an attractive and challenging field, as the expressibility and extremely high abstraction of the input end. The booming large-scale dataset generated by open-source code repositories and Q&amp;A resources, the innovation of machine learning algorithms, and the development of computing capacity make the NLSCG field promising and give more opportunities to the model implementation and perfection. Besides, we observed an increasing interest stream of NLSCG relevant studies recently, presenting quite various technical schools. However, many studies are bound to specific datasets with customization issues, producing occasional successful solutions with tentative technical methods. There is no systematic study to explore and promote the further development of this field. We carried out a systematic literature survey and tool research to find potential improvement directions. First, we position the role of NLSCG among various SCG genres, and specify the generation context empirically via software development domain knowledge and programming experiences; second, we explore the selected studies collected by a thoughtfully designed snowballing process, clarify the NLSCG field and understand the NLSCG problem, which lays a foundation for our subsequent investigation. Third, we model the research problems from technical focus and adaptive challenges, and elaborate insights gained from the NLSCG research backlog. Finally, we summarize the latest technology landscape over the transformation model and depict the critical tactics used in the essential components and their correlations. This research addresses the challenges of bridging the gap between natural language processing and source code analytics, outlines different dimensions of NLSCG research concerns and technical utilities, and shows a bounded technical context of NLSCG to facilitate more future studies in this promising area.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21026,""
"Role of Artificial Intelligence in the Early Diagnosis of Oral Cancer A Scoping Review","GarcÃƒÂ­a-Pola, Pons-Fuster, SuÃƒÂ¡rez-FernÃƒÂ¡ndez, Seoane-Romero, Romero-MÃƒÂ©ndez, LÃƒÂ³pez-Jornet","https://doi.org/10.3390/cancers13184600","20211001","PubMed","artificial intelligence; deep learning; early diagnosis; machine learning; oral cancer; screening","The early diagnosis of cancer can facilitate subsequent clinical patient management. Artificial intelligence (AI) has been found to be promising for improving the diagnostic process. The aim of the present study is to increase the evidence on the application of AI to the early diagnosis of oral cancer through a scoping review. A search was performed in the PubMed, Web of Science, Embase and Google Scholar databases during the period from January 2000 to December 2020, referring to the early non-invasive diagnosis of oral cancer based on AI applied to screening. Only accessible full-text articles were considered. Thirty-six studies were included on the early detection of oral cancer based on images (photographs (optical imaging and enhancement technology) and cytology) with the application of AI models. These studies were characterized by their heterogeneous nature. Each publication involved a different algorithm with potential training data bias and few comparative data for AI interpretation. Artificial intelligence may play an important role in precisely predicting the development of oral cancer, though several methodological issues need to be addressed in parallel to the advances in AI techniques, in order to allow large-scale transfer of the latter to population-based detection protocols.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21027,""
"Seeing the Forest for the Trees: Evaluating Population Data in Allergy-Immunology","McGowan, Robinson, Chen, Rider","https://doi.org/10.1016/j.jaip.2021.09.018","20211004","PubMed","Biostatistics; Epidemiology; Machine learning; Population-health","A population-level study is essential for understanding treatment effects, epidemiologic phenomena, and health care best practices. Evaluating large populations and associated data requires an analytic framework, which is commonly used by statisticians, epidemiologists, and data scientists. This document will serve to provide an overview of these commonly employed methods in allergy and immunology research. We will draw upon recent examples from the allergy-immunology literature to contextualize discrete principles of relevance to population-level analysis that include statistical features of a study population, elements of statistical inference, regression analysis, and an overview of machine learning practices. Our intent is to guide the reader through a practical description of this important quantitative discipline and facilitate greater understanding about data and result display in the medical literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21028,""
"A KG-enhanced Multi-Graph Neural Network for Attentive Herb Recommendation","Jin, Ji, Zhang, He, Wang, Wang","https://doi.org/10.1109/TCBB.2021.3115489","20210927","PubMed","","Traditional Chinese Medicine (TCM) has the longest clinical history in Asia and contributes a lot to health maintenance worldwide. An essential step during the TCM diagnostic process is syndrome induction, which comprehensively analyzes the symptoms and generates an overall summary of the symptoms. Given a set of symptoms, the existing herb recommenders aim to generate the corresponding herbs as a treatment by inducing the implicit syndrome representations based on TCM prescriptions. As different symptoms have various importance during the comprehensive consideration, we argue that treating the co-occurred symptoms equally to do syndrome induction in the previous studies will lead to the coarse-grained syndrome representation. In this paper, we bring the attention mechanism to model the syndrome induction process. Given a set of symptoms, we leverage an attention network to discriminate the symptom importance and adaptively fuse the symptom embeddings. Besides, we introduce a TCM knowledge graph to enrich the input corpus and improve the quality of representation learning. Further, we build a KG-enhanced Multi-Graph Neural Network architecture, which performs the attentive propagation to combine node feature and graph structural information. Extensive experimental results on two TCM data sets show that our proposed model has the outstanding performance over the state-of-the-arts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21029,""
"Trends, Limits, and Challenges of Computer Technologies in Attention Deficit Hyperactivity Disorder Diagnosis and Treatment","MontaleÃƒÂ£o Brum Alves, Ferreira da Silva, Assis Schmitz, Juarez Alencar","https://doi.org/10.1089/cyber.2020.0867","20210927","PubMed","ADHD; computing; diagnosis; technology; treatment","Attention deficit hyperactivity disorder (ADHD) is a neurobiological condition that appears during an individual's childhood and may follow her/him for life. The research objective was to understand better how and which computer technologies have been applied to support ADHD diagnosis and treatment. The research used the systematic literature review method: a rigorous, verifiable, and repeatable approach that follows well-defined steps. Six well-known academic data sources have been consulted, including search engines and bibliographic databases, from technology and health care areas. After a rigorous research protocol, 1,239 articles were analyzed. For the diagnosis, the use of machine learning techniques was verified in 61 percent of the articles. Neurofeedback was ranked second with 9.3 percent participation, followed by serious games and eye tracking with 5.6 percent each. For the treatment, neurofeedback was present in 50 percent of the articles, whereas some studies combined both approaches, accounting for 31 percent of the total. Nine percent of the articles reported remote assistance technology, whereas another 9 percent have used virtual reality. By highlighting the leading computer technologies used, their applications, results, and challenges, this literature review breaks ground for further investigations. Moreover, the study highlighted the lack of consensus on ADHD biomarkers. The approaches using machine learning call attention to the probable occurrence of overfitting in several studies, thus demonstrating limitations of this technology on small-sized bases. This research also presented the convergence of evidence from different studies on the persistence of long-term effects of using neurofeedback in treating ADHD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21030,""
"Machine Learning in Pain Medicine: An Up-To-Date Systematic Review","Matsangidou, Liampas, Pittara, Pattichi, Zis","https://doi.org/10.1007/s40122-021-00324-2","20210927","PubMed","Algorithms; Machine learning; Pain; Pain classification; Pain diagnosis; Pain management; Pain manifestation; Supervised learning; Unsupervised learning","Pain is the unpleasant sensation and emotional experience that leads to poor quality of life for millions of people worldwide. Considering the complexity in understanding the principles of pain and its significant impact on individuals and society, research focuses to deliver innovative pain relief methods and techniques. This review explores the clinical uses of machine learning (ML) for the diagnosis, classification, and management of pain. A systematic review of the current literature was conducted using the PubMed database library. Twenty-six papers related to pain and ML research were included. Most of the studies used ML for effectively classifying the patients' level of pain, followed by use of ML for the prediction of manifestation of pain and for pain management. A less common reason for performing ML analysis was for the diagnosis of pain. The different approaches are thoroughly discussed. ML is increasingly used in pain medicine and appears to be more effective compared to traditional statistical approaches in the diagnosis, classification, and management of pain.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21031,""
"MRI Patterns Distinguish AQP4 Antibody Positive Neuromyelitis Optica Spectrum Disorder From Multiple Sclerosis","Clarke, Arnett, Bukhari, Khalilidehkordi, Jimenez Sanchez, O'Gorman, Sun, Prain, Woodhall, Silvestrini, Bundell, Abernethy, Bhuta, Blum, Boggild, Boundy, Brew, Brownlee, Butzkueven, Carroll, Chen, Coulthard, Dale, Das, Fabis-Pedrini, Gillis, Hawke, Heard, Henderson, Heshmat, Hodgkinson, Kilpatrick, King, Kneebone, Kornberg, Lechner-Scott, Lin, Lynch, Macdonell, Mason, McCombe, Pereira, Pollard, Ramanathan, Reddel, Shaw, Spies, Stankovich, Sutton, Vucic, Walsh, Wong, Yiu, Barnett, Kermode, Marriott, Parratt, Slee, Taylor, Willoughby, Brilot, Vincent, Waters, Broadley","https://doi.org/10.3389/fneur.2021.722237","20210929","PubMed","NMOSD; diagnosis; magnetic resonance imaging; multiple sclerosis; neuromyelitis optica","Neuromyelitis optica spectrum disorder (NMOSD) and multiple sclerosis (MS) are inflammatory diseases of the CNS. Overlap in the clinical and MRI features of NMOSD and MS means that distinguishing these conditions can be difficult. With the aim of evaluating the diagnostic utility of MRI features in distinguishing NMOSD from MS, we have conducted a cross-sectional analysis of imaging data and developed predictive models to distinguish the two conditions. NMOSD and MS MRI lesions were identified and defined through a literature search. Aquaporin-4 (AQP4) antibody positive NMOSD cases and age- and sex-matched MS cases were collected. MRI of orbits, brain and spine were reported by at least two blinded reviewers. MRI brain or spine was available for 166/168 (99%) of cases. Longitudinally extensive (OR = 203), ""bright spotty"" (OR = 93.8), whole (axial; OR = 57.8) or gadolinium (Gd) enhancing (OR = 28.6) spinal cord lesions, bilateral (OR = 31.3) or Gd-enhancing (OR = 15.4) optic nerve lesions, and nucleus tractus solitarius (OR = 19.2), periaqueductal (OR = 16.8) or hypothalamic (OR = 7.2) brain lesions were associated with NMOSD. Ovoid (OR = 0.029), Dawson's fingers (OR = 0.031), pyramidal corpus callosum (OR = 0.058), periventricular (OR = 0.136), temporal lobe (OR = 0.137) and T1 black holes (OR = 0.154) brain lesions were associated with MS. A score-based algorithm and a decision tree determined by machine learning accurately predicted more than 85% of both diagnoses using first available imaging alone. We have confirmed NMOSD and MS specific MRI features and combined these in predictive models that can accurately identify more than 85% of cases as either AQP4 seropositive NMOSD or MS.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21032,""
"The Symphony of Team Flow in Virtual Teams Using Artificial Intelligence for Its Recognition and Promotion","Peifer, Pollak, Flak, Pyszka, Nisar, Irshad, Grzegorzek, Kordyaka, KoÃ…Â¼usznik","https://doi.org/10.3389/fpsyg.2021.697093","20210929","PubMed","collective communication; machine learning; team effectiveness; team flow; virtual teams","More and more teams are collaborating virtually across the globe, and the COVID-19 pandemic has further encouraged the dissemination of virtual teamwork. However, there are challenges for virtual teams - such as reduced informal communication - with implications for team effectiveness. Team flow is a concept with high potential for promoting team effectiveness, however its measurement and promotion are challenging. Traditional team flow measurements rely on self-report questionnaires that require interrupting the team process. Approaches in artificial intelligence, i.e., machine learning, offer methods to identify an algorithm based on behavioral and sensor data that is able to identify team flow and its dynamics over time without interrupting the process. Thus, in this article we present an approach to identify team flow in virtual teams, using machine learning methods. First of all, based on a literature review, we provide a model of team flow characteristics, composed of characteristics that are shared with individual flow and characteristics that are unique for team flow. It is argued that those characteristics that are unique for team flow are represented by the concept of collective communication. Based on that, we present physiological and behavioral correlates of team flow which are suitable - but not limited to - being assessed in virtual teams and which can be used as input data for a machine learning system to assess team flow in real time. Finally, we suggest interventions to support team flow that can be implemented in real time, in virtual environments and controlled by artificial intelligence. This article thus contributes to finding indicators and dynamics of team flow in virtual teams, to stimulate future research and to promote team effectiveness.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21033,""
"WSES project on decision support systems based on artificial neural networks in emergency surgery","Litvin, Korenev, Rumovskaya, Sartelli, Baiocchi, Biffl, Coccolini, Di Saverio, Kelly, Kluger, LeppÃƒÂ¤niemi, Sugrue, Catena","https://doi.org/10.1186/s13017-021-00394-9","20210930","PubMed","Acute appendicitis; Acute cholecystitis; Acute pancreatitis; Artificial neural networks; Bowel obstruction; Decision support system; Emergency surgery; Peptic ulcer bleeding; Perforated gastroduodenal ulcers; Strangulated hernias","The article is a scoping review of the literature on the use of decision support systems based on artificial neural networks in emergency surgery. The authors present modern literature data on the effectiveness of artificial neural networks for predicting, diagnosing and treating abdominal emergency conditions: acute appendicitis, acute pancreatitis, acute cholecystitis, perforated gastric or duodenal ulcer, acute intestinal obstruction, and strangulated hernia. The intelligent systems developed at present allow a surgeon in an emergency setting, not only to check his own diagnostic and prognostic assumptions, but also to use artificial intelligence in complex urgent clinical cases. The authors summarize the main limitations for the implementation of artificial neural networks in surgery and medicine in general. These limitations are the lack of transparency in the decision-making process; insufficient quality educational medical data; lack of qualified personnel; high cost of projects; and the complexity of secure storage of medical information data. The development and implementation of decision support systems based on artificial neural networks is a promising direction for improving the forecasting, diagnosis and treatment of emergency surgical diseases and their complications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21034,""
"Artificial intelligence for pre-operative lymph node staging in colorectal cancer: a systematic review and meta-analysis","Bedrikovetski, Dudi-Venkata, Kroon, Seow, Vather, Carneiro, Moore, Sammour","https://doi.org/10.1186/s12885-021-08773-w","20211018","PubMed","Artificial intelligence; Colorectal cancer; Deep learning; Lymph node metastasis; Machine learning; Radiomics; meta-analysis; Artificial Intelligence; Bias; Colorectal Neoplasms; Deep Learning; Humans; Lymph Nodes; Lymphatic Metastasis; Magnetic Resonance Imaging; Preoperative Care; Publication Bias; ROC Curve; Radiologists; Rectal Neoplasms; Sensitivity and Specificity; Tomography, X-Ray Computed","Artificial intelligence (AI) is increasingly being used in medical imaging analysis. We aimed to evaluate the diagnostic accuracy of AI models used for detection of lymph node metastasis on pre-operative staging imaging for colorectal cancer. A systematic review was conducted according to PRISMA guidelines using a literature search of PubMed (MEDLINE), EMBASE, IEEE Xplore and the Cochrane Library for studies published from January 2010 to October 2020. Studies reporting on the accuracy of radiomics models and/or deep learning for the detection of lymph node metastasis in colorectal cancer by CT/MRI were included. Conference abstracts and studies reporting accuracy of image segmentation rather than nodal classification were excluded. The quality of the studies was assessed using a modified questionnaire of the QUADAS-2 criteria. Characteristics and diagnostic measures from each study were extracted. Pooling of area under the receiver operating characteristic curve (AUROC) was calculated in a meta-analysis. Seventeen eligible studies were identified for inclusion in the systematic review, of which 12 used radiomics models and five used deep learning models. High risk of bias was found in two studies and there was significant heterogeneity among radiomics papers (73.0%). In rectal cancer, there was a per-patient AUROC of 0.808 (0.739-0.876) and 0.917 (0.882-0.952) for radiomics and deep learning models, respectively. Both models performed better than the radiologists who had an AUROC of 0.688 (0.603 to 0.772). Similarly in colorectal cancer, radiomics models with a per-patient AUROC of 0.727 (0.633-0.821) outperformed the radiologist who had an AUROC of 0.676 (0.627-0.725). AI models have the potential to predict lymph node metastasis more accurately in rectal and colorectal cancer, however, radiomics studies are heterogeneous and deep learning studies are scarce. PROSPERO CRD42020218004 .","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21035,""
"Stretching for Recovery from Groin Pain or Injury in Athletes: A Critical and Systematic Review","Afonso, Claudino, Fonseca, Moreira-GonÃƒÂ§alves, Ferreira, Almeida, Clemente, Ramirez-Campillo","https://doi.org/10.3390/jfmk6030073","20211002","PubMed","exercise training; flexibility; musculoskeletal pain; pubalgia; rehabilitation; return to sport","Stretching is usually used as part of rehabilitation protocols for groin pain or injury, but its specific contribution to and within multimodal recovery protocols is unclear. Our goal was to systematically review the effects of stretching for the recovery from groin pain or injury. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines were followed, with eligibility criteria defined according to PICOS: (Participants) athletes with groin pain or injuries; (Interventions) interventions with stretching as the differentiating factor; (Comparators) comparators not applying stretching; (Outcomes) symptom remission or improvement and/or time to return to sport and/or return to play; (Study design) randomized controlled trials. Searches were performed on 26 March 2021, in CINAHL, Cochrane Library, EBSCO, EMBASE, PEDro, PubMed, Scielo, Scopus, SPORTDiscus, and Web of Science, with no limitations regarding language or date, and no filters. Of 117 retrieved results, 65 were duplicates and 49 were excluded at the screening stage. The three articles eligible for full-text analysis failed to comply with one or more inclusion criteria (participants, intervention and/or comparators). We then went beyond the protocol and searched for non-randomized trials and case series, but no intervention was found where stretching was the differentiating factor. We found no trials specifically assessing the effects of stretching on recovery or improvement of groin pain or injury in athletes. Currently, the efficacy of these interventions is unknown, and more research is warranted.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21036,""
"A review of water pollution arising from agriculture and mining activities in Central Asia: Facts, causes and effects","Liu, Wang, Gojenko, Yu, Wei, Luo, Xiao","https://doi.org/10.1016/j.envpol.2021.118209","20211001","PubMed","Agriculture; Central Asia; Mining activities; Water pollution","Central Asia is one of many regions worldwide that face severe water shortages; nevertheless, water pollution in this region exacerbates the existing water stress and increases the risk of regional water conflicts. In this study, we perform an extensive literature review, and the data show that water pollution in Central Asia is closely linked to human activities. Within the Asian Gold Belt, water pollution is influenced mainly by mining, and the predominant pollutants are heavy metals and radionuclides. However, in the irrigated areas along the middle and lower reaches of inland rivers (e.g., the Amu Darya and Syr Darya), water pollution is strongly associated with agriculture. Hence, irrigated areas are characterized by high concentrations of ammonia, nitrogen, and phosphorus. In addition, the salinities of rivers and groundwater in the middle and lower reaches of inland rivers generally increase along the flow path due to high rates of evaporation. Soil salinization and frequent salt dust storms in the Aral Sea basin further increase the pollution of surface water bodies. Ultimately, the pollution of surface water and groundwater poses risks to human health and deteriorates the ecological environment. To prevent further water pollution, joint monitoring of the surface water and groundwater quantity and quality throughout Central Asia must be implemented immediately.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21037,""
"Effect of Light Therapy on Cancer-Related Fatigue: A Systematic Review and Meta-Analysis","Xiao, Ding, Duan, Li, Zhou, Luo, Xie, Cheng","https://doi.org/10.1016/j.jpainsymman.2021.09.010","20211024","PubMed","Light treatment; cancer; cancer-related fatigue; fatigue; meta-analysis; phototherapy; quality of life","Light therapy is a non-pharmacological therapy that is currently being studied in cancer-related symptoms and is certificated as a low-risk intervention by FDA. Cancer-related fatigue (CRF) is the most common symptom reported by cancer patients. To examine the effectiveness of light therapy for CRF in cancer patients through a systematic review and meta-analysis. We conducted a systematic review of four electronic databases targeted randomized clinical trials evaluating light therapy for CRF (CRD42020215446), from inception to May 2021. The primary outcome was changes of CRF scores; secondary outcomes included depression, sleep, and quality of life (QoL). We quantitatively pooled outcomes using meta-analysis with random-effects models and assessed methodological bias. We identified thirteen RCTs representing 551 cancer patients, encompassing breast (nÃ‚Â =Ã‚Â 5), ovarian or endometrial (nÃ‚Â =Ã‚Â 1), multiple myeloma (nÃ‚Â =Ã‚Â 1), lung (nÃ‚Â =Ã‚Â 1), or combined (nÃ‚Â =Ã‚Â 5) cancers. The comparison groups included dim light (nÃ‚Â =Ã‚Â 12) and waiting list (nÃ‚Â =Ã‚Â 1). Duration of intervention ranged from 1 to 12 weeks. Light intensities ranged from 417.9 to 12,000 lux. Light therapy was associated with a significant improvement in CRF (SMDÃ‚Â =Ã‚Â 0.45, PÃ‚Â =Ã‚Â 0.007), depression (SMDÃ‚Â =Ã‚Â -0.26, PÃ‚Â =Ã‚Â 0.03) and sleep difficulty (SMDÃ‚Â =Ã‚Â -2.46, PÃ‚Â =Ã‚Â 0.0006); a statistically non-significant trend was observed for QoL (SMDÃ‚Â =Ã‚Â 0.33, PÃ‚Â =Ã‚Â 0.09). Funnel plots for CRF suggest not significant publication bias. Light therapy could be a feasible and effective option for improving CRF in cancer patients. Larger sample, rigor trials design and a standard protocol of intervention are needed to draw more conclusive conclusions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21038,""
"A systematic review and meta-analysis of robotic-assisted transabdominal total mesorectal excision and transanal total mesorectal excision: which approach offers optimal short-term outcomes for mid-to-low rectal adenocarcinoma?","Butterworth, Butterworth, Meyer, Giacobino, Buchs, Ris, Scarpinata","https://doi.org/10.1007/s10151-021-02515-7","20211022","PubMed","Rectal cancer; Robotic; Total mesorectal excision; Transabdominal; Transanal; Adenocarcinoma; Humans; Laparoscopy; Male; Postoperative Complications; Prospective Studies; Rectal Neoplasms; Rectum; Retrospective Studies; Robotic Surgical Procedures; Transanal Endoscopic Surgery; Treatment Outcome","Resection of low rectal adenocarcinoma can be challenging in the narrow pelvis of male patients. Transanal total mesorectal excision (TaTME) appears to offer technical advantages for distal rectal tumours, and robotic-assisted transabdominal TME (rTME) was introduced in effort to improve operative precision and ergonomics. However, no study has comprehensively compared these approaches. The aim of the present study was to perform a systematic review of the literature to compare postoperative short-term outcomes in rTME and TaTME. A systematic online search (1974-July 2020) of MEDLINE, Embase, web of science and google scholar was conducted for trials, prospective or retrospective studies involving rTME, or TaTME for rectal cancer. Outcome variables included: hospital stay; operation duration, blood loss; resection margins; proportion of histologically complete resected specimens; lymph nodes; overall complications; anastomotic leak, and 30-day mortality. Sixty-two articles met the inclusion criteria, including 37 studies (3835 patients) assessing rTME resection, 23 studies (1326 patients) involving TaTME and 2 comparing both (165 patients). Operating time was longer in rTME (309.2Ã‚Â min, 95% CI 285.5-332.8) than in TaTME studies (256.2Ã‚Â min, 95% CI 231.5-280.9) (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.002). rTME resected specimens had a larger distal resection margin (2.62Ã‚Â cm, 95% CI 2.35-2.88) than in TaTME studies (2.10Ã‚Â cm, 95% CI 1.83-2.36) (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.007). Other outcome variables did not significantly differ between the two techniques. rTME provides similar pathological and short-term outcomes to TaTME and both are reasonable surgical approaches for patients with mid-to-low rectal cancer. To definitively answer the question of the optimal TME technique, we suggest a prospective trial comparing both techniques assessing long-term survival as a primary outcome.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21039,""
"Making the case for librarian expertise to support evidence synthesis for the sustainable development goals","Ghezzi-Kopel, Ault, Chimwaza, Diekmann, Eldermire, Gathoni, Kelly, Kinengyere, Kocher, Lwoga, Page, Young, Porciello","https://doi.org/10.1002/jrsm.1528","20211022","PubMed","evidence synthesis; information retrieval; information specialists; librarians; protocols; sustainable development goals","Evidence syntheses that engage librarians as co-authors produce higher-quality results than those that do not. Trained as teachers, researchers, and information managers, librarians possess expert knowledge on research methodologies and information retrieval approaches that are critical for evidence synthesis. Researchers are under increasing pressure to produce evidence syntheses to inform practice and policymaking. Many fields outside of health science and medicine, however, do not have established guidelines, processes, or methodologies. This article describes how librarians led the creation of an interdisciplinary toolkit for researchers new to evidence synthesis. The implementation of the tools, including a protocol, supported eight evidence syntheses focused on effective agricultural interventions published in a special collection in Nature Research in October 2020. This article is a step-by-step overview of the tools and process. We advocate that librarian collaboration in evidence synthesis must become the norm, not the exception. Evidence synthesis project leads without access to a qualified librarian may use this toolkit as a point of entry for production of transparent, reproducible reviews.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21040,""
"Correction to: Technical and clinical validation of commercial automated volumetric MRI tools for dementia diagnosis-a systematic review","Pemberton, Zaki, Goodkin, Das, Steketee, Barkhof, Vernooij","https://doi.org/10.1007/s00234-021-02818-4","20211021","PubMed","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21041,""
"TGSA: Protein-Protein Association-Based Twin Graph Neural Networks for Drug Response Prediction with Similarity Augmentation","Zhu, Ouyang, Chen, Feng, Chen, Cao, Wu","https://doi.org/10.1093/bioinformatics/btab650","20210924","PubMed","","Drug response prediction (DRP) plays an important role in precision medicine (e.g., for cancer analysis and treatment). Recent advances in deep learning algorithms make it possible to predict drug responses accurately based on genetic profiles. However, existing methods ignore the potential relationships among genes. In addition, similarity among cell lines/drugs was rarely considered explicitly. We propose a novel DRP framework, called TGSA, to make better use of prior domain knowledge. TGSA consists of Twin Graph neural networks for Drug Response Prediction (TGDRP) and a Similarity Augmentation (SA) module to fuse fine-grained and coarse-grained information. Specifically, TGDRP abstracts cell lines as graphs based on STRING protein-protein association networks and employs Graph Neural Networks (GNNs) for representation learning. SA views DRP as an edge regression problem on a heterogeneous graph and utilizes GNNs to smooth the representations of similar cell lines/drugs. Besides, we introduce an auxiliary pre-training strategy to remedy the identified limitations of scarce data and poor out-of-distribution generalization. Extensive experiments on the GDSC2 dataset demonstrate that our TGSA consistently outperforms all the state-of-the-art baselines under various experimental settings. We further evaluate the effectiveness and contributions of each component of TGSA via ablation experiments. The promising performance of TGSA shows enormous potential for clinical applications in precision medicine. The source code is available at https://github.com/violet-sto/TGSA. Supplementary data are available at Bioinformatics online.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21042,""
"Comparison of accuracy and safety between robot-assisted and conventional fluoroscope assisted placement of pedicle screws in thoracolumbar spine: A meta-analysis","Li, Li, Gao, Cao, Li, He, Ma, Li","https://doi.org/10.1097/MD.0000000000027282","20211001","PubMed","Fluoroscopy; Humans; Lumbar Vertebrae; Pedicle Screws; Randomized Controlled Trials as Topic; Reoperation; Robotic Surgical Procedures; Thoracic Vertebrae","The purpose of this systematic review and meta-analysis is to explore the screw positioning accuracy, complications related to pedicle screw implantation, revision rate and radiation exposure between robot screw placement and traditional fluoroscopic screw placement. We searched several databases, including CNKI, Wanfang database, cqvip datebase, PubMed, Cochrane library and EMBASE, to identify articles that might meet the criteria. Meta-analysis was performed using Revman 5.3 software. A total of 13 randomized controlled trial were included. The results showed that the pedicle screw accuracy of the robot assisted group was significantly better than that of the conventional freehand (FH) group (ORÃ¢â‚¬Å =Ã¢â‚¬Å 3.5, 95% confidence interval [CI] [2.75,4.45], PÃ¢â‚¬Å &lt;Ã¢â‚¬Å .0001). There was no significant difference in the complications caused by pedicle screw implantation between the robot-assisted group and the conventional FH group [ORÃ¢â‚¬Å =Ã¢â‚¬Å 0.39, 95%CI (0.10,1.48), PÃ¢â‚¬Å =Ã¢â‚¬Å .17]. The rate of facet joint invasion in the robot-assisted group was significantly lower than that in the conventional FH group (ORÃ¢â‚¬Å =Ã¢â‚¬Å 0.06, 95%CI [0.01,0.29], PÃ¢â‚¬Å =Ã¢â‚¬Å .0006). The revision rate in the robot-assisted group was significantly lower than that in the conventional FH group (ORÃ¢â‚¬Å =Ã¢â‚¬Å 0.19, 95%CI [0.05,0.71], PÃ¢â‚¬Å =Ã¢â‚¬Å 0.0.01). There was no significant difference in the average radiation of pedicle screws implantation between the robot-assisted group and the conventional FH (mean differenceÃ¢â‚¬Å =Ã¢â‚¬Å -7.94, 95%CI [-20.18,4.30], PÃ¢â‚¬Å =Ã¢â‚¬Å .20). The robot-assisted group was significantly better than the conventional FH in the accuracy of pedicle screw placement and facet joint invasion rate and revision rate. There was no significant difference in the complication and fluoroscopy time between the two groups.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21043,""
"Application of Artificial Intelligence to Clinical Practice in Inflammatory Bowel Disease - What the Clinician Needs to Know","Chen, Fulmer, Gordon, Syed, Stidham, Vande Casteele, Qin, Falloon, Cohen, Wyllie, Rieder","https://doi.org/10.1093/ecco-jcc/jjab169","20210924","PubMed","Inflammatory bowel disease; artificial intelligence; machine learning; neural networks","Artificial intelligence (AI) techniques are quickly spreading across medicine as an analytical method to tackle challenging clinical questions. What were previously thought of as highly complex data sources, such as images or free text, are now becoming manageable. Novel analytical methods merge the latest developments in information technology infrastructure with advances in computer science. Once primarily associated with Silicon Valley, AI techniques are now making their way into medicine, including in the field of inflammatory bowel diseases (IBD). Understanding potential applications and limitations of these techniques can be difficult, in particular for busy clinicians. In this article, we explain the basic terminologies and provide particular focus on the foundations behind state-of-the-art AI methodologies in both imaging and text. We explore the growing applications of AI in medicine, with a specific focus on IBD to inform the practicing gastroenterologist and IBD specialist. Finally, we outline possible future uses of these technologies in daily clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21044,""
"Artificial Intelligence and Mapping a New Direction in Laboratory Medicine: A Review","Herman, Rhoads, Schulz, Durant","https://doi.org/10.1093/clinchem/hvab165","20211102","PubMed","artificial intelligence; laboratory medicine; machine learning; supervised machine learning","Modern artificial intelligence (AI) and machine learning (ML) methods are now capable of completing tasks with performance characteristics that are comparable to those of expert human operators. As a result, many areas throughout healthcare are incorporating these technologies, including in vitro diagnostics and, more broadly, laboratory medicine. However, there are limited literature reviews of the landscape, likely future, and challenges of the application of AI/ML in laboratory medicine. In this review, we begin with a brief introduction to AI and its subfield of ML. The ensuing sections describe ML systems that are currently in clinical laboratory practice or are being proposed for such use in recent literature, ML systems that use laboratory data outside the clinical laboratory, challenges to the adoption of ML, and future opportunities for ML in laboratory medicine. AI and ML have and will continue to influence the practice and scope of laboratory medicine dramatically. This has been made possible by advancements in modern computing and the widespread digitization of health information. These technologies are being rapidly developed and described, but in comparison, their implementation thus far has been modest. To spur the implementation of reliable and sophisticated ML-based technologies, we need to establish best practices further and improve our information system and communication infrastructure. The participation of the clinical laboratory community is essential to ensure that laboratory data are sufficiently available and incorporated conscientiously into robust, safe, and clinically effective ML-supported clinical diagnostics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21045,""
"A Systematic Literature Review on Particle Swarm Optimization Techniques for Medical Diseases Detection","Pervaiz, Ul-Qayyum, Bangyal, Gao, Ahmad","https://doi.org/10.1155/2021/5990999","20210925","PubMed","","Artificial Intelligence (AI) is the domain of computer science that focuses on the development of machines that operate like humans. In the field of AI, medical disease detection is an instantly growing domain of research. In the past years, numerous endeavours have been made for the improvements of medical disease detection, because the errors and problems in medical disease detection cause serious wrong medical treatment. Meta-heuristic techniques have been frequently utilized for the detection of medical diseases and promise better accuracy of perception and prediction of diseases in the domain of biomedical. Particle Swarm Optimization (PSO) is a swarm-based intelligent stochastic search technique encouraged from the intrinsic manner of bee swarm during the searching of their food source. Consequently, for the versatility of numerical experimentation, PSO has been mostly applied to address the diverse kinds of optimization problems. However, the PSO techniques are frequently adopted for the detection of diseases but there is still a gap in the comparative survey. This paper presents an insight into the diagnosis of medical diseases in health care using various PSO approaches. This study presents to deliver a systematic literature review of current PSO approaches for knowledge discovery in the field of disease detection. The systematic analysis discloses the potential research areas of PSO strategies as well as the research gaps, although, the main goal is to provide the directions for future enhancement and development in this area. This paper gives a systematic survey of this conceptual model for the advanced research, which has been explored in the specified literature to date. This review comprehends the fundamental concepts, theoretical foundations, and conventional application fields. It is predicted that our study will be beneficial for the researchers to review the PSO algorithms in-depth for disease detection. Several challenges that can be undertaken to move the field forward are discussed according to the current state of the PSO strategies in health care.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21046,""
"Literature Mining and Mechanistic Graphical Modelling to Improve mRNA Vaccine Platforms","Leonardelli, Lofano, Selvaggio, Parolo, Giampiccolo, Tomasoni, Domenici, Priami, Song, Medini, Marchetti, Siena","https://doi.org/10.3389/fimmu.2021.738388","20210925","PubMed","graphical modeling; mRNA vaccines; mechanisms of action; natural language processing; scientific literature mining","RNA vaccines represent a milestone in the history of vaccinology. They provide several advantages over more traditional approaches to vaccine development, showing strong immunogenicity and an overall favorable safety profile. While preclinical testing has provided some key insights on how RNA vaccines interact with the innate immune system, their mechanism of action appears to be fragmented amid the literature, making it difficult to formulate new hypotheses to be tested in clinical settings and ultimately improve this technology platform. Here, we propose a systems biology approach, based on the combination of literature mining and mechanistic graphical modeling, to consolidate existing knowledge around mRNA vaccines mode of action and enhance the translatability of preclinical hypotheses into clinical evidence. A Natural Language Processing (NLP) pipeline for automated knowledge extraction retrieved key biological evidences that were joined into an interactive mechanistic graphical model representing the chain of immune events induced by mRNA vaccines administration. The achieved mechanistic graphical model will help the design of future experiments, foster the generation of new hypotheses and set the basis for the development of mathematical models capable of simulating and predicting the immune response to mRNA vaccines.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21047,""
"A 2D-3D hybrid convolutional neural network for lung lobe auto-segmentation on standard slice thickness computed tomography of patients receiving radiotherapy","Gu, Gan, Zhang, Feng, Wang, Huang, Chen, Shao, Duan, Xu","https://doi.org/10.1186/s12938-021-00932-1","20210927","PubMed","Artificial intelligence; Automatic segmentation; Computed tomography; Convolutional neural network; Lung lobe","Accurate segmentation of lung lobe on routine computed tomography (CT) images of locally advanced stage lung cancer patients undergoing radiotherapy can help radiation oncologists to implement lobar-level treatment planning, dose assessment and efficacy prediction. We aim to establish a novel 2D-3D hybrid convolutional neural network (CNN) to provide reliable lung lobe auto-segmentation results in the clinical setting. We retrospectively collected and evaluated thorax CT scans of 105 locally advanced non-small-cell lung cancer (NSCLC) patients treated at our institution from June 2019 to August 2020. The CT images were acquired with 5Ã‚Â mm slice thickness. Two CNNs were used for lung lobe segmentation, a 3D CNN for extracting 3D contextual information and a 2D CNN for extracting texture information. Contouring quality was evaluated using six quantitative metrics and visual evaluation was performed to assess the clinical acceptability. For the 35 cases in the test group, Dice Similarity Coefficient (DSC) of all lung lobes contours exceeded 0.75, which met the pass criteria of the segmentation result. Our model achieved high performances with DSC as high as 0.9579, 0.9479, 0.9507, 0.9484, and 0.9003 for left upper lobe (LUL), left lower lobe (LLL), right upper lobe (RUL), right lower lobe (RLL), and right middle lobe (RML), respectively. The proposed model resulted in accuracy, sensitivity, and specificity of 99.57, 98.23, 99.65 for LUL; 99.6, 96.14, 99.76 for LLL; 99.67, 96.13, 99.81 for RUL; 99.72, 92.38, 99.83 for RML; 99.58, 96.03, 99.78 for RLL, respectively. Clinician's visual assessment showed that 164/175 lobe contours met the requirements for clinical use, only 11 contours need manual correction. Our 2D-3D hybrid CNN model achieved accurate automatic segmentation of lung lobes on conventional slice-thickness CT of locally advanced lung cancer patients, and has good clinical practicability.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21048,""
"Oral cancer awareness in patients attending university dental clinics: A scoping review of Australian studies","Ramamurthy, Sharma, Thomson","https://doi.org/10.1111/adj.12877","20211004","PubMed","Attitude; awareness; health education; knowledge; oral cancer","This scoping review was carried out to evaluate the important role Australian university-based dental teaching clinics and dental students might have in promoting oral cancer awareness in their patients. Four Online database (PubMed, OVID, Scopus and Emcare) were searched for studies that assessed oral cancer awareness amongst patients attending Australian university-associated (teaching) clinics. A total of five articles were retrieved for full-text analysis. All studies showed significant variation in patient awareness and understanding regarding the principal risk factors associated with oral cancer development. Smoking was predominantly identified as a significant risk factor, but alcohol consumption was less frequently recognized as relevant. Non-healing ulceration was most commonly identified as a symptom of concern, whilst red and/or white mucosal patches were infrequently recognized as potentially malignant conditions. Our review confirms that a significant lack of patient awareness regarding oral cancer risk and the signs /symptoms of early malignancy or potentially malignant disease exist in patients attending dental teaching clinics. Important opportunities exist to involve dental students proactively in raising oral cancer awareness, delivering smoking cessation interventions and safe alcohol consumption advice to their patients. Incorporation of established health educational models might deliver effective support for such student-delivered patient education.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21049,""
"My Cancer Genome: Coevolution of Precision Oncology and a Molecular Oncology Knowledgebase","Holt, Mittendorf, LeNoue-Newton, Jain, Anderson, Lovly, Osterman, Micheel, Levy","https://doi.org/10.1200/CCI.21.00084","20211101","PubMed","Biomarkers, Tumor; Humans; Knowledge Bases; Medical Oncology; Neoplasms; Precision Medicine","The My Cancer Genome (MCG) knowledgebase and resulting website were launched in 2011 with the purpose of guiding clinicians in the application of genomic testing results for treatment of patients with cancer. Both knowledgebase and website were originally developed using a wiki-style approach that relied on manual evidence curation and synthesis of that evidence into cancer-related biomarker, disease, and pathway pages on the website that summarized the literature for a clinical audience. This approach required significant time investment for each page, which limited website scalability as the field advanced. To address this challenge, we designed and used an assertion-based data model that allows the knowledgebase and website to expand with the field of precision oncology. Assertions, or computationally accessible cause and effect statements, are both manually curated from primary sources and imported from external databases and stored in a knowledge management system. To generate pages for the MCG website, reusable templates transform assertions into reconfigurable text and visualizations that form the building blocks for automatically updating disease, biomarker, drug, and clinical trial pages. Combining text and graph templates with assertions in our knowledgebase allows generation of web pages that automatically update with our knowledgebase. Automated page generation empowers rapid scaling of the website as assertions with new biomarkers and drugs are added to the knowledgebase. This process has generated more than 9,100 clinical trial pages, 18,100 gene and alteration pages, 900 disease pages, and 2,700 drug pages to date. Leveraging both computational and manual curation processes in combination with reusable templates empowers automation and scalability for both the MCG knowledgebase and MCG website.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21050,""
"Intelligent quantitative assessment of skeletal maturation based on multi-stage model: a retrospective cone-beam CT study of cervical vertebrae","Xie, Tang, Izadikhah, Chen, Zhao, Zhao, Li, Yan","https://doi.org/10.1007/s11282-021-00566-y","20210923","PubMed","Cervical vertebral maturation index; Cone-beam computed tomography; Machine learning; Multi-stage model; Skeletal maturation","To develop new logistic regression estimative models of the cervical vertebral maturation index (CVMI) based on cone-beam CT (CBCT)-derived parameters for intelligent evaluating skeletal maturation. From 231 CBCT volumes (age range 7-17, mean age 11.09Ã‚Â years), 154 were randomly selected to produce 2D sagittal projections of the second to fourth cervical vertebrae (C2-C4). From 19 quantitative parameters, significant predictors were deduced to formulate logistic models. Using the CVMI and significant predictors of 77 other subjects, performance of the models was externally examined by direct comparison and the area under the receiver operating characteristic curve (AUC). Models were modified if required, to improve their accuracy. Chronological age, C3 height ([Formula: see text], and ratio of posterior height to lower width of C4 [Formula: see text] were entered as significant predictors. Accuracy of the models was acceptable (total AUCÃ¢â‚¬â€°=Ã¢â‚¬â€°0.91) except for 4th and 5th stage (AUC of 0.82 and 0.83, respectively), which were mis-predicted inversely. Adjusted models were generated by bivariate logistic regression analysis and adding significant parameters ([Formula: see text] and [Formula: see text], with odds ratios of 3.308 and 3.38, respectively) from 58 subjects in 4th and 5th stages of CVMI in the model establishment group. The total AUC increased to 0.94, along with an increase in the accuracy of the latter optimized models to 77.9 and 87%, respectively. The new intelligent models reliably estimated skeletal maturation and can be utilized in the clinical field or machine learning-based skeletal maturation assessment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21051,""
"Analysis of Population Differences in Digital Conversations About Cancer Clinical Trials: Advanced Data Mining and Extraction Study","Perez, Jaffee, Whyte, Boyce, Carpten, Lozano, Williams, Winkfield, Bernstein, Poblete","https://doi.org/10.2196/25621","20211102","PubMed","cancer; clinical trials; data mining; health care disparities; health communication; natural language processing; race and ethnicity; social media; text extraction","Racial and ethnic diversity in clinical trials for cancer treatment is essential for the development of treatments that are effective for all patients and for identifying potential differences in toxicity between different demographics. Mining of social media discussions about clinical trials has been used previously to identify patient barriers to enrollment in clinical trials; however, a comprehensive breakdown of sentiments and barriers by various racial and ethnic groups is lacking. The aim of this study is to use an innovative methodology to analyze web-based conversations about cancer clinical trials and to identify and compare conversation topics, barriers, and sentiments between different racial and ethnic populations. We analyzed 372,283 web-based conversations about cancer clinical trials, of which 179,339 (48.17%) of the discussions had identifiable race information about the individual posting the conversations. Using sophisticated machine learning software and analyses, we were able to identify key sentiments and feelings, topics of interest, and barriers to clinical trials across racial groups. The stage of treatment could also be identified in many of the discussions, allowing for a unique insight into how the sentiments and challenges of patients change throughout the treatment process for each racial group. We observed that only 4.01% (372,283/9,284,284) of cancer-related discussions referenced clinical trials. Within these discussions, topics of interest and identified clinical trial barriers discussed by all racial and ethnic groups throughout the treatment process included health care professional interactions, cost of care, fear, anxiety and lack of awareness, risks, treatment experiences, and the clinical trial enrollment process. Health care professional interactions, cost of care, and enrollment processes were notably discussed more frequently in minority populations. Other minor variations in the frequency of discussion topics between ethnic and racial groups throughout the treatment process were identified. This study demonstrates the power of digital search technology in health care research. The results are also valuable for identifying the ideal content and timing for the delivery of clinical trial information and resources for different racial and ethnic groups.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21052,""
"Success stories of AI in drug discovery - where do things stand?","Mak, Balijepalli, Pichika","https://doi.org/10.1080/17460441.2022.1985108","20211013","PubMed","Artificial intelligence; clinical trials; collaborations; deep learning; drug discovery &amp; development; machine learning; partnerships; scientometric analysis","Artificial intelligence (AI) in drug discovery and development (DDD) has gained more traction in the past few years. Many scientific reviews have already been made available in this area. Thus, in this review, the authors have focused on the success stories of AI-driven drug candidates and the scientometric analysis of the literature in this field. The authors explore the literature to compile the success stories of AI-driven drug candidates that are currently being assessed in clinical trials or have investigational new drug (IND) status. The authors also provide the reader with their expert perspectives for future developments and their opinions on the field. Partnerships between AI companies and the pharma industry are booming. The early signs of the impact of AI on DDD are encouraging, and the pharma industry is hoping for breakthroughs. AI can be a promising technology to unveil the greatest successes, but it has yet to be proven as AI is still at the embryonic stage.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21053,""
"Demographic Disparities in Clinical Outcomes of COVID-19: Data From a Statewide Cohort in South Carolina","Yang, Zhang, Chen, Olatosi, Bruner, Diedhiou, Scott, Mansaray, Weissman, Li","https://doi.org/10.1093/ofid/ofab428","20210925","PubMed","COVID-19; South Carolina; disease severity; hospitalization; mortality","Current literature examining the clinical characteristics of coronavirus disease 2019 (COVID-19) patients under-represent COVID-19 cases who were either asymptomatic or had mild symptoms. We analyzed statewide data from 280 177 COVID-19 cases from various health care facilities during March 4-December 31, 2020. Each COVID-19 case was reported using the standardized Case Report Form (CRF), which collected information on demographic characteristics, symptoms, hospitalization, and death. We used multivariable logistic regression to analyze the associations between sociodemographics and disease severity, hospitalization, and mortality. Among a total of 280 177 COVID-19 cases, 5.2% (14 451) were hospitalized and 1.9% (5308) died. Older adults, males, and Black individuals had higher odds of hospitalization and death from COVID-19 (all <i>P</i> &lt; 0.0001). In particular, individuals residing in rural areas experienced a high risk of death (odds ratio [OR], 1.16; 95% CI, 1.08-1.25). Regarding disease severity, older adults (OR, 1.06; 95% CI, 1.03-1.10) and Hispanic or Latino patients (OR, 2.06; 95% CI, 1.95-2.18) had higher odds of experiencing moderate/severe symptoms, while male and Asian patients, compared with White patients, had lower odds of experiencing moderate/severe symptoms. As the first statewide population-based study using data from multiple health care systems with a long follow-up period in the United States, we provide a more generalizable picture of COVID-19 symptoms and clinical outcomes. The findings from this study reinforce the fact that rural residence and racial/ethnic social determinants of health, unfortunately, remain predictors of adverse health outcomes for COVID-19 patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21054,""
"Novel methods to enhance surgical sperm retrieval: a systematic review","Kresch, Efimenko, Gonzalez, Rizk, Ramasamy","https://doi.org/10.1080/2090598X.2021.1926752","20210925","PubMed","Azoospermia; ORBEYE; artificial intelligence; infertility; micro-TESE; ultrasonography","<b>Objectives</b>: To explore the use of novel technologies in sperm retrieval in men with azoospermia due to a production defect. <b>Methods</b>: We performed a Preferred Reporting Items for Systemic Reviews and Meta-Analysis (PRISMA)-compliant systemic literature review for manuscripts focussed on novel sperm-retrieval methods. We identified 30 studies suitable for qualitative analysis. <b>Results and Conclusions</b>: We identified multiple new promising technologies, each with its own distinct set of benefits and limitations, to enhance chances of sperm retrieval; these include the use of multiphoton microscopy, Raman spectroscopy, and full-field optical coherence tomography during a microdissection-testicular sperm extraction procedure. ORBEYE and ultrasonography technologies can also serve to better visualise areas of sperm production. Finally, artificial intelligence technology can play a role in the identification of sperm and, perhaps, better-quality sperm for use with assisted reproduction. <b>Abbreviations:</b> AI: artificial intelligence; ANN: artificial neural network; ART: assisted reproductive technology; 3D: three-dimensional; DNN: deep neural networks; FFOCT: full-field optical coherence tomography; H&amp;E: haematoxylin and eosin; ICSI: intracytoplasmic sperm injection; IVF: <i>in vitro</i> fertilisation; MESA: micro-epididymal sperm aspiration; MeSH: Medical Subject Heading; MPM: multiphoton microscopy; (N)OA: (non-)obstructive azoospermia; SCO: Sertoli cell-only syndrome; SRR: sperm retrieval rates; TESA: testicular sperm aspiration; (micro-)TESE: (microdissection-) testicular sperm extraction; (CE)US: (contrast-enhanced) ultrasonography.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21055,""
"InNetGAN: Inception Network-Based Generative Adversarial Network for Denoising Low-Dose Computed Tomography","Kulathilake, Abdullah, Bandara, Lai","https://doi.org/10.1155/2021/9975762","20210925","PubMed","","Low-dose Computed Tomography (LDCT) has gained a great deal of attention in clinical procedures due to its ability to reduce the patient's risk of exposure to the X-ray radiation. However, reducing the X-ray dose increases the quantum noise and artifacts in the acquired LDCT images. As a result, it produces visually low-quality LDCT images that adversely affect the disease diagnosing and treatment planning in clinical procedures. Deep Learning (DL) has recently become the cutting-edge technology of LDCT denoising due to its high performance and data-driven execution compared to conventional denoising approaches. Although the DL-based models perform fairly well in LDCT noise reduction, some noise components are still retained in denoised LDCT images. One reason for this noise retention is the direct transmission of feature maps through the skip connections of contraction and extraction path-based DL modes. Therefore, in this study, we propose a Generative Adversarial Network with Inception network modules (InNetGAN) as a solution for filtering the noise transmission through skip connections and preserving the texture and fine structure of LDCT images. The proposed Generator is modeled based on the U-net architecture. The skip connections in the U-net architecture are modified with three different inception network modules to filter out the noise in the feature maps passing over them. The quantitative and qualitative experimental results have shown the performance of the InNetGAN model in reducing noise and preserving the subtle structures and texture details in LDCT images compared to the other state-of-the-art denoising algorithms.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21056,""
"Natural Language Processing as an Emerging Tool to Detect Late-Life Depression","DeSouza, Robin, Gumus, Yeung","https://doi.org/10.3389/fpsyt.2021.719125","20210925","PubMed","artificial intelligence; depression; digital health; geriatric mental health; late-life depression; natural language processing; speech","Late-life depression (LLD) is a major public health concern. Despite the availability of effective treatments for depression, barriers to screening and diagnosis still exist. The use of current standardized depression assessments can lead to underdiagnosis or misdiagnosis due to subjective symptom reporting and the distinct cognitive, psychomotor, and somatic features of LLD. To overcome these limitations, there has been a growing interest in the development of objective measures of depression using artificial intelligence (AI) technologies such as natural language processing (NLP). NLP approaches focus on the analysis of acoustic and linguistic aspects of human language derived from text and speech and can be integrated with machine learning approaches to classify depression and its severity. In this review, we will provide rationale for the use of NLP methods to study depression using speech, summarize previous research using NLP in LLD, compare findings to younger adults with depression and older adults with other clinical conditions, and discuss future directions including the use of complementary AI strategies to fully capture the spectrum of LLD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21057,""
"Teaching Neuroimmunology to Undergraduate Students: Resource for Full Course or Modular Implementation","Watanabe","https://www.google.com/search?q=Teaching+Neuroimmunology+to+Undergraduate+Students:+Resource+for+Full+Course+or+Modular+Implementation.","20210925","PubMed","critical thinking; neuroimmunology; oral and written communication; primary literature","This paper describes a course I designed to teach neuroimmunology to undergraduate students. In this course I incorporated many active learning strategies to help make it a student-centered class, where they developed communication skills, while reading and analyzing primary literature articles. As the field of neuroimmunology is relatively new, most textbooks in the field approached the subject from the perspective of neurology and autoimmune diseases. Therefore, I used reading, analysis, and student-led presentation of primary papers in the classroom to not only develop critical thinking and application of the scientific method, but also oral communication skills. Other activities such as writing <i>New York Times</i>-style articles and literature review papers were employed to develop written communications skills. The goal of this article is to provide a reference tool for instructors trained in neuroscience to deploy an entire course on neuroimmunology or select a module or a single paper to incorporate into their existing course to offer students a taste for neuroimmunology.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21058,""
"SARS-CoV-2 in Solid Organ Transplant Recipients: A Structured Review of 2020","Quante, Brake, Tolios, Della Penna, Steidle, Gruendl, Grishina, Haeberle, Guthoff, Tullius, KÃƒÂ¶nigsrainer, Nadalin, LÃƒÂ¶ffler","https://doi.org/10.1016/j.transproceed.2021.08.019","20211028","PubMed","COVID-19; Cross-Sectional Studies; Humans; Organ Transplantation; Pandemics; SARS-CoV-2; Transplant Recipients","The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic is challenging health systems all over the world. Particularly high-risk groups show considerable mortality rates after infection. In 2020, a huge number of case reports, case series, and consecutively various systematic reviews have been published reporting on morbidity and mortality risk connected with SARS-CoV-2 in solid organ transplant (SOT) recipients. However, this vast array of publications resulted in an increasing complexity of the field, overwhelming even for the expert reader. We performed a structured literature review comprising electronic databases, transplant journals, and literature from previous systematic reviews covering the entire year 2020. From 164 included articles, we identified 3451 cases of SARS-CoV-2-infected SOT recipients. Infections resulted in a hospitalization rate of 84% and 24% intensive care unit admissions in the included patients. Whereas 53.6% of patients were reported to have recovered, cross-sectional overall mortality reported after coronavirus disease 2019 (COVID-19) was at 21.1%. Synoptic data concerning immunosuppressive medication attested to the reduction or withdrawal of antimetabolites (81.9%) and calcineurin inhibitors (48.9%) as a frequent adjustment. In contrast, steroids were reported to be increased in 46.8% of SOT recipients. COVID-19 in SOT recipients is associated with high morbidity and mortality worldwide. Conforming with current guidelines, modifications of immunosuppressive therapies mostly comprised a reduction or withdrawal of antimetabolites and calcineurin inhibitors, while frequently maintaining or even increasing steroids. Here, we provide an accessible overview to the topic and synoptic estimates of expectable outcomes regarding in-hospital mortality of SOT recipients with COVID-19.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21059,""
"The State of Mind of Health Care Professionals in Light of the COVID-19 Pandemic: Text Analysis Study of Twitter Discourses","Elyashar, Plochotnikov, Cohen, Puzis, Cohen","https://doi.org/10.2196/30217","20211028","PubMed","COVID-19; Twitter; active learning; emotion analysis; health care professionals; machine learning; sentiment analysis; social media; topic analysis; COVID-19; Health Personnel; Humans; Pandemics; SARS-CoV-2; Social Media","The COVID-19 pandemic has affected populations worldwide, with extreme health, economic, social, and political implications. Health care professionals (HCPs) are at the core of pandemic response and are among the most crucial factors in maintaining coping capacities. Yet, they are also vulnerable to mental health effects caused by managing a long-lasting emergency with a lack of resources and under complicated personal concerns. However, there are a lack of longitudinal studies that investigate the HCP population. The aim of this study was to analyze the state of mind of HCPs as expressed in online discussions published on Twitter in light of the COVID-19 pandemic, from the onset of the pandemic until the end of 2020. The population for this study was selected from followers of a few hundred Twitter accounts of health care organizations and common HCP points of interest. We used active learning, a process that iteratively uses machine learning and manual data labeling, to select the large-scale population of Twitter accounts maintained by English-speaking HCPs, focusing on individuals rather than official organizations. We analyzed the topics and emotions in their discourses during 2020. The topic distributions were obtained using the latent Dirichlet allocation algorithm. We defined a measure of topic cohesion and described the most cohesive topics. The emotions expressed in tweets during 2020 were compared to those in 2019. Finally, the emotion intensities were cross-correlated with the pandemic waves to explore possible associations between the pandemic development and emotional response. We analyzed the timelines of 53,063 Twitter profiles, 90% of which were maintained by individual HCPs. Professional topics accounted for 44.5% of tweets by HCPs from January 1, 2019, to December 6, 2020. Events such as the pandemic waves, US elections, or the George Floyd case affected the HCPs' discourse. The levels of joy and sadness exceeded their minimal and maximal values from 2019, respectively, 80% of the time (P=.001). Most interestingly, fear preceded the pandemic waves, in terms of the differences in confirmed cases, by 2 weeks with a Spearman correlation coefficient of ÃÂ(47 pairs)=0.340 (P=.03). Analyses of longitudinal data over the year 2020 revealed that a large fraction of HCP discourse is directly related to professional content, including the increase in the volume of discussions following the pandemic waves. The changes in emotional patterns (ie, decrease in joy and increase in sadness, fear, and disgust) during the year 2020 may indicate the utmost importance in providing emotional support for HCPs to prevent fatigue, burnout, and mental health disorders during the postpandemic period. The increase in fear 2 weeks in advance of pandemic waves indicates that HCPs are in a position, and with adequate qualifications, to anticipate pandemic development, and could serve as a bottom-up pathway for expressing morbidity and clinical situations to health agencies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21060,""
"Semi-automated Tools for Systematic Searches","Adam, Wallace, Trikalinos","https://doi.org/10.1007/978-1-0716-1566-9_2","20210923","PubMed","Information science; Literature identification; Machine learning; Systematic review methods; Text mining","Traditionally, literature identification for systematic reviews has relied on a two-step process: first, searching databases to identify potentially relevant citations, and then manually screening those citations. A number of tools have been developed to streamline and semi-automate this process, including tools to generate terms; to visualize and evaluate search queries; to trace citation linkages; to deduplicate, limit, or translate searches across databases;Ã‚Â and to prioritize relevant abstracts for screening. Research is ongoing into tools that can unify searching and screening into a single step, and several protype tools have been developed. As this field grows, it is becoming increasingly important to develop and codify methods for evaluating the extent to which these tools fulfill their purpose.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21061,""
"Assessing the Prognostic Significance of Tumor-Infiltrating Lymphocytes in Patients With Melanoma Using Pathologic Features Identified by Natural Language Processing","Yang, Lian, Chin, Wang, Lian, Murphy, Zhou","https://doi.org/10.1001/jamanetworkopen.2021.26337","20211008","PubMed","","Although tumor-infiltrating lymphocytes (TILs) are an important histopathologic characteristic reflecting host immune response in patients with melanoma, their prognostic value remains controversial. Because manual review of medical records is labor intensive, a survival analysis using a large patient cohort with comprehensive clinical and histopathologic characteristics is lacking. To assess the prognostic significance of TILs among patients with cutaneous melanoma using a large cohort established through natural language processing (NLP) algorithms. This retrospective cohort study analyzed the medical records of 14Ã¢â‚¬Â¯436 patients with cutaneous melanoma at Brigham and Women's Hospital between June 1, 2004, and December 31, 2019. Patients were followed up to death or censored at their last clinical visit. The primary outcome was overall survival (OS). Survival analysis was conducted using Kaplan-Meier curves, the log-rank test, and Cox proportional hazards regression analysis. A total of 14Ã¢â‚¬Â¯436 patients with cutaneous melanoma were identified in the institution's pathology information system. Using NLP, we established a study cohort of 2624 patients (1462 men [55.7%]; median age, 61 years [interquartile range, 50-72 years]) who had vertical growth phase melanoma with TIL status scored. Absent TILs were identified in 434 patients (16.5%), nonbrisk TILs in 1916 patients (73.0%), and brisk TILs in 274 patients (10.4%). The 5-year survival rate was 71.0% (95% CI, 65.5%-76.9%) among patients with an absence of TILs, 73.8% (95% CI, 71.1%-76.5%) among patients with nonbrisk TILs, and 85.2% (95% CI, 80.0%-90.7%) among patients with brisk TILs. Brisk TILs were significantly associated with improved OS (adjusted hazard ratio, 0.63; 95% CI, 0.42-0.95; PÃ¢â‚¬â€°=Ã¢â‚¬â€°.03; 14.2% OS advantage at 5 years), and nonbrisk TILs were not associated with improved OS (adjusted hazard ratio, 0.87; 95% CI, 0.68-1.11; PÃ¢â‚¬â€°=Ã¢â‚¬â€°.25), compared with the absence of TILs. This study provides evidence based on a large patient cohort from a single institution that suggests that brisk TILs represent an independent prognostic factor for OS among patients with primary cutaneous melanoma. The study also suggests that NLP is a highly efficient tool to facilitate large-scale analyses that involve free-text clinical data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21062,""
"Evaluating the Cost-effectiveness of Prehospital Plasma Transfusion in Unstable Trauma Patients: A Secondary Analysis of the PAMPer Trial","Hrebinko, Sperry, Guyette, Brown, Daley, Miller, Harbrecht, Claridge, Phelan, Neal, Zuckerbraun, Yazer, Nicholson","https://doi.org/10.1001/jamasurg.2021.4529","20211008","PubMed","","Prehospital plasma transfusion is lifesaving for trauma patients in hemorrhagic shock but is not commonly used owing to cost and feasibility concerns. To evaluate the cost-effectiveness of prehospital thawed plasma transfusion in trauma patients with hemorrhagic shock during air medical transport. A decision tree and Markov model were created to compare standard care and prehospital thawed plasma transfusion using published and unpublished patient-level data from the Prehospital Plasma in Air Medical Transport in Trauma Patients at Risk for Hemorrhagic Shock (PAMPer) trial conducted from May 2014 to October 2017, health care and trauma-specific databases, and the published literature. Prehospital transfusion, short-term inpatient care, and lifetime health care costs and quality of life outcomes were included. One-way, 2-way, and Monte Carlo probabilistic sensitivity analyses were performed across clinically plausible ranges. Data were analyzed in December 2019. Relative costs and health-related quality of life were evaluated by an incremental cost-effectiveness ratio at a standard willingness-to-pay threshold of $100Ã¢â‚¬Â¯000 per quality-adjusted life-year (QALY). The trial included 501 patients in the modified intention-to-treat cohort. Median (interquartile range) age for patients in the thawed plasma and standard care cohorts were 44 (31-59) and 46 (28-60) years, respectively. Overall, 364 patients (72.7%) were male. Thawed plasma transfusion was cost-effective with an incremental cost-effectiveness ratio of $50Ã¢â‚¬Â¯467.44 per QALY compared with standard care. The preference for thawed plasma was robust across all 1- and 2-way sensitivity analyses. When considering only patients injured by a blunt mechanism, the incremental cost-effectiveness ratio decreased to $37Ã¢â‚¬Â¯735.19 per QALY. Thawed plasma was preferred in 8140 of 10Ã¢â‚¬Â¯000 iterations (81.4%) on probabilistic sensitivity analysis. A detailed analysis of incremental costs between strategies revealed most were attributable to the in-hospital and postdischarge lifetime care of critically ill patients surviving severe trauma. In this study, prehospital thawed plasma transfusion during air medical transport for trauma patients in hemorrhagic shock was lifesaving and cost-effective compared with standard care and should become commonplace.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21063,""
"Lack of Transparency and Potential Bias in Artificial Intelligence Data Sets and Algorithms: A Scoping Review","Daneshjou, Smith, Sun, Rotemberg, Zou","https://doi.org/10.1001/jamadermatol.2021.3129","20210922","PubMed","","Clinical artificial intelligence (AI) algorithms have the potential to improve clinical care, but fair, generalizable algorithms depend on the clinical data on which they are trained and tested. To assess whether data sets used for training diagnostic AI algorithms addressing skin disease are adequately described and to identify potential sources of bias in these data sets. In this scoping review, PubMed was used to search for peer-reviewed research articles published between January 1, 2015, and November 1, 2020, with the following paired search terms: deep learning and dermatology, artificial intelligence and dermatology, deep learning and dermatologist, and artificial intelligence and dermatologist. Studies that developed or tested an existing deep learning algorithm for triage, diagnosis, or monitoring using clinical or dermoscopic images of skin disease were selected, and the articles were independently reviewed by 2 investigators to verify that they met selection criteria. Data set audit criteria were determined by consensus of all authors after reviewing existing literature to highlight data set transparency and sources of bias. A total of 70 unique studies were included. Among these studies, 1Ã¢â‚¬Â¯065Ã¢â‚¬Â¯291 images were used to develop or test AI algorithms, of which only 257Ã¢â‚¬Â¯372 (24.2%) were publicly available. Only 14 studies (20.0%) included descriptions of patient ethnicity or race in at least 1 data set used. Only 7 studies (10.0%) included any information about skin tone in at least 1 data set used. Thirty-six of the 56 studies developing new AI algorithms for cutaneous malignant neoplasms (64.3%) met the gold standard criteria for disease labeling. Public data sets were cited more often than private data sets, suggesting that public data sets contribute more to new development and benchmarks. This scoping review identified 3 issues in data sets that are used to develop and test clinical AI algorithms for skin disease that should be addressed before clinical translation: (1) sparsity of data set characterization and lack of transparency, (2) nonstandard and unverified disease labels, and (3) inability to fully assess patient diversity used for algorithm development and testing.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21064,""
"[The relationship between physical exercise and gut microbiota in the human being: a systematic review]","Clemente, Bravini, Corna, Colombo, Sartorio, Rinaldi, Vercelli","https://doi.org/10.19191/EP21.4.P245.080","20210923","PubMed","Bacterial taxa; Cardiorespiratory fitness; Exercise; Gut microbiota; Physiotherapy; Cardiorespiratory Fitness; Exercise; Gastrointestinal Microbiome; Humans; Italy","the relationship between physical exercise and gut microbiota has opened new therapeutic frontiers for many inflammatory diseases. However, there is still a lot of uncertainty about how to administer exercise. to review the literature to bridge this gap and examine the relationship between cardiorespiratory fitness (CRF) and microbiota. systematic review. studies involving humans who undergoing exercise programmes of any lengths, intensities, and types were included. The research was carried out through PubMed, Scopus, and Web of Science. the primary outcome was change in gut microbiota composition (ÃŽÂ± and ÃŽÂ²-diversity), while the secondary outcome was the CRF level. the 15 studies included (all with PEDro scale &lt;=5) used aerobic training alone or combined with resistance exercises. In general, exercise has shown positive effects on the microbiota, influencing the faecal count of some bacterial phyla (in particular Bacteroidetes, Firmicutes, and Proteobacteria), with a weak tendency towards proportionality in relation to training duration and intensity. However, the evidence supporting the exercise effects on the gut microbiota and the relationship with CRF are of low quality. despite the weak evidence in favour of the effects of the practice of physical exercise on the intestinal microbiota, there are still many aspects that need to be explored. In particular, future studies shall have higher quality and methodological rigour, standardize the methods for outcome assessment, and determine type and thresholds of interventions intensity and duration.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21065,""
"Overview of featurization techniques used in traditional versus emerging deep learning-based algorithms for automated interpretation of the 12-lead ECG","Finlay, Bond, Jennings, McCausland, Guldenring, Kennedy, Biglarbeigi, Al-Zaiti, Brisk, McLaughlin","https://doi.org/10.1016/j.jelectrocard.2021.08.010","20210922","PubMed","Artificial intelligence; Automated electrocardiogram interpretation; Deep learning; ECG","Automated interpretation of the 12-lead ECG has remained an underpinning interest in decades of research that has seen a diversity of computing applications in cardiology. The application of computers in cardiology began in the 1960s with early research focusing on the conversion of analogue ECG signals (voltages) to digital samples. Alongside this, software techniques that automated the extraction of wave measurements and provided basic diagnostic statements, began to emerge. In the years since then there have been many significant milestones which include the widespread commercialisation of 12-lead ECG interpretation software, associated clinical utility and the development of the related regulatory frameworks to promote standardised development. In the past few years, the research community has seen a significant rejuvenation in the development of ECG interpretation programs. This is evident in the research literature where a large number of studies have emerged tackling a variety of automated ECG interpretation problems. This is largely due to two factors. Specifically, the technical advances, both software and hardware, that have facilitated the broad adoption of modern artificial intelligence (AI) techniques, and, the increasing availability of large datasets that support modern AI approaches. In this article we provide a very high-level overview of the operation of and approach to the development of early 12-lead ECG interpretation programs and we contrast this to the approaches that are now seen in emerging AI approaches. Our overview is mainly focused on highlighting differences in how input data are handled prior to generation of the diagnostic statement.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21066,""
"Artificial intelligence approach towards assessment of condition of COVID-19 patients - Identification of predictive biomarkers associated with severity of clinical condition and disease progression","BlagojeviÃ„â€¡, Ã…Â uÃ…Â¡terÃ…Â¡iÃ„Â, Lorencin, Ã…Â egota, AnÃ„â€˜eliÃ„â€¡, MilovanoviÃ„â€¡, BaskiÃ„â€¡, BaskiÃ„â€¡, PetroviÃ„â€¡, SazdanoviÃ„â€¡, Car, FilipoviÃ„â€¡","https://doi.org/10.1016/j.compbiomed.2021.104869","20211102","PubMed","COVID-19; Clinical condition assessment; Personalized model; Predictive blood biomarkers; Rule-based machine learning","Although ML has been studied for different epidemiological and clinical issues as well as for survival prediction of COVID-19, there is a noticeable shortage of literature dealing with ML usage in prediction of disease severity changes through the course of the disease. In that way, predicting disease progression from mild towards moderate, severe and critical condition, would help not only to respond in a timely manner to prevent lethal results, but also to minimize the number of patients in hospitals where this is not necessary. We present a methodology for the classification of patients into 4 distinct categories of the clinical condition of COVID-19 disease. Classification of patients is based on the values of blood biomarkers that were assessed by Gradient boosting regressor and which were selected as biomarkers that have the greatest influence in the classification of patients with COVID-19. The results show that among several tested algorithms, XGBoost classifier achieved best results with an average accuracy of 94% and an average F1-score of 94.3%. We have also extracted 10 best features from blood analysis that are strongly associated with patient condition and based on those features we can predict the severity of the clinical condition. The main advantage of our system is that it is a decision tree-based algorithm which is easier to interpret, instead of the use of black box models, which are not appealing in medical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21067,""
"The role of machine learning in the primary prevention of work-related musculoskeletal disorders: A scoping review","Chan, Ross, Clouthier, Fischer, Graham","https://doi.org/10.1016/j.apergo.2021.103574","20211026","PubMed","Artificial intelligence; Classification; Cluster analysis; Occupational injury; Prediction","To determine the applications of machine learning (ML) techniques used for the primary prevention of work-related musculoskeletal disorders (WMSDs), a scoping review was conducted using seven literature databases. Of the 4,639 initial results, 130 primary research studies were deemed relevant for inclusion. Studies were reviewed and classified as a contribution to one of six steps within the primary WMSD prevention research framework by van der Beek et al. (2017). ML techniques provided the greatest contributions to the development of interventions (48 studies), followed by risk factor identification (33 studies), underlying mechanisms (29 studies), incidence of WMSDs (14 studies), evaluation of interventions (6 studies), and implementation of effective interventions (0 studies). Nearly a quarter (23.8%) of all included studies were published in 2020. These findings provide insight into the breadth of ML techniques used for primary WMSD prevention and can help identify areas for future research and development.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21068,""
"Technology-Enabled and Artificial Intelligence Support for Pre-Visit Planning in Ambulatory Care: Findings From an Environmental Scan","Holdsworth, Park, Asch, Lin","https://doi.org/10.1370/afm.2716","20210930","PubMed","ambulatory care; artificial intelligence; qualitative methods; Ambulatory Care; Artificial Intelligence; COVID-19; Humans; SARS-CoV-2; Technology","Pre-visit planning (PVP) is believed to improve effectiveness, efficiency, and experience of care, yet numerous implementation barriers exist. There are opportunities for technology-enabled and artificial intelligence (AI) support to augment existing human-driven PVP processes-from appointment reminders and pre-visit questionnaires to pre-visit order sets and care gap closures. This study aimed to explore the current state of PVP, barriers to implementation, evidence of impact, and potential use of non-AI and AI tools to support PVP. We used an environmental scan approach involving: (1) literature review; (2) key informant interviews with PVP experts in ambulatory care; and (3) a search of the public domain for technology-enabled and AI solutions that support PVP. We then synthesized the findings using a qualitative matrix analysis. We found 26 unique PVP implementations in the literature and conducted 16 key informant interviews. Demonstration of impact is typically limited to process outcomes, with improved patient outcomes remaining elusive. Our key informants reported that many PVP barriers are human effort-related and see potential for non-AI and AI technologies to support certain aspects of PVP. We identified 8 examples of commercially available technology-enabled tools that support PVP, some with AI capabilities; however, few of these have been independently evaluated. As health systems transition toward value-based payment models in a world where the coronavirus disease 2019 pandemic has shifted patient care into the virtual space, PVP activities-driven by humans and supported by technology-may become more important and powerful and should be rigorously evaluated.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21069,""
"Cost-effectiveness analysis of vaborem for the treatment of carbapenem-resistant Enterobacteriaceae-Klebsiella pneumoniae carbapenemase (CRE-KPC) infections in the UK","Vlachaki, Zinzi, Falla, Mantopoulos, Guy, Jandu, Dodgson","https://doi.org/10.1007/s10198-021-01375-0","20210923","PubMed","Best available treatment; Carbapenem-resistant EnterobacteriaceaeÃ¢â‚¬â€Klebsiella pneumoniae carbapenemase; Cost-effectiveness; Meropenem-vaborbactam","The study objective of this analysis was to determine the cost-effectiveness of vaborem (meropenem-vaborbactam) compared to the best available therapy (BAT) in adult patients with carbapenem-resistant Enterobacteriaceae-Klebsiella pneumoniae carbapenemase (CRE-KPC) infections from the perspective of the UK National Health Service (NHS) and Personal Social Services (PSS). A decision tree model was developed to conduct a cost-effectiveness analysis for Vaborem compared to BAT in CRE-KPC patients over a 5Ã‚Â year time horizon. The model structure for Vaborem simulated the clinical pathway of patients with a confirmed CRE-KPC infection. Model inputs for clinical effectiveness were sourced from the TANGO II trial, and published literature. Costs, resource use and utility values associated with CRE-KPC infections in the UK were sourced from the British National Formulary, NHS reference costs and published sources. Over a 5Ã‚Â year time horizon, Vaborem use increased total costs by Ã‚Â£5165 and increased quality-adjusted life years (QALYs) by 0.366, resulting in an incremental cost-effectiveness ratio (ICER) of Ã‚Â£14,113 per QALY gained. The ICER was most sensitive to the probability of discharge to long-term care (LTC), the annual cost of LTC and the utility of discharge to home. At thresholds of Ã‚Â£20,000/QALY and Ã‚Â£30,000/QALY, the probability of Vaborem being cost-effective compared to BAT was 79.85% and 94.93%, respectively. Due to a limited cost impact and increase in patient quality of life, vaborem can be considered as a cost-effective treatment option compared to BAT for adult patients with CRE-KPC infections in the UK.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21070,""
"Automatic Classification of Thyroid Findings Using Static and Contextualized Ensemble Natural Language Processing Systems: Development Study","Shin, Kam, Jeon, Kim","https://doi.org/10.2196/30223","20210922","PubMed","convolution neural network; deep learning; electronic medical records; ensemble; long short-term memory; natural language processing; thyroid; transformer; word embedding","In the case of Korean institutions and enterprises that collect nonstandardized and nonunified formats of electronic medical examination results from multiple medical institutions, a group of experienced nurses who can understand the results and related contexts initially classified the reports manually. The classification guidelines were established by years of workers' clinical experiences and there were attempts to automate the classification work. However, there have been problems in which rule-based algorithms or human labor-intensive efforts can be time-consuming or limited owing to high potential errors. We investigated natural language processing (NLP) architectures and proposed ensemble models to create automated classifiers. This study aimed to develop practical deep learning models with electronic medical records from 284 health care institutions and open-source corpus data sets for automatically classifying 3 thyroid conditions: healthy, caution required, and critical. The primary goal is to increase the overall accuracy of the classification, yet there are practical and industrial needs to correctly predict healthy (negative) thyroid condition data, which are mostly medical examination results, and minimize false-negative rates under the prediction of healthy thyroid conditions. The data sets included thyroid and comprehensive medical examination reports. The textual data are not only documented in fully complete sentences but also written in lists of words or phrases. Therefore, we propose static and contextualized ensemble NLP network (SCENT) systems to successfully reflect static and contextual information and handle incomplete sentences. We prepared each convolution neural network (CNN)-, long short-term memory (LSTM)-, and efficiently learning an encoder that classifies token replacements accurately (ELECTRA)-based ensemble model by training or fine-tuning them multiple times. Through comprehensive experiments, we propose 2 versions of ensemble models, SCENT-v1 and SCENT-v2, with the single-architecture-based CNN, LSTM, and ELECTRA ensemble models for the best classification performance and practical use, respectively. SCENT-v1 is an ensemble of CNN and ELECTRA ensemble models, and SCENT-v2 is a hierarchical ensemble of CNN, LSTM, and ELECTRA ensemble models. SCENT-v2 first classifies the 3 labels using an ELECTRA ensemble model and then reclassifies them using an ensemble model of CNN and LSTM if the ELECTRA ensemble model predicted them as ""healthy"" labels. SCENT-v1 outperformed all the suggested models, with the highest F1 score (92.56%). SCENT-v2 had the second-highest recall value (94.44%) and the fewest misclassifications for caution-required thyroid condition while maintaining 0 classification error for the critical thyroid condition under the prediction of the healthy thyroid condition. The proposed SCENT demonstrates good classification performance despite the unique characteristics of the Korean language and problems of data lack and imbalance, especially for the extremely low amount of critical condition data. The result of SCENT-v1 indicates that different perspectives of static and contextual input token representations can enhance classification performance. SCENT-v2 has a strong impact on the prediction of healthy thyroid conditions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21071,""
"Non-Operative Management of Appendicitis: Evolution, not Revolution","Barie","https://doi.org/10.1089/sur.2021.059","20210921","PubMed","acute appendicitis; antibiotics; appendix; history of surgery; non-operative management","<b><i>Background:</i></b> The medical fascination with the appendix vermiformis dates from the clandestine prosectors of the fifteenth century. The surgical management of appendiceal inflammation dates from 1735, but acceptance that acute appendicitis (AA) should be treated primarily by resection with or without drainage would not follow for 150 years. Recent publication of several randomized clinical trials (RCTs) of non-operative management (NOM) of AA affords the opportunity to review the historical record, describe the evolution of AA management toward NOM, and assess what is in the best interest of the patient. <b><i>Methods:</i></b> Review and synthesis of historical and contemporary English, French, German, and Italian literature with expert opinion. <b><i>Results:</i></b> Modern understanding of AA dates to the landmark 1886 clinico-pathologic correlative study by Reginald Fitz, which coined the term appendicitis and coincided with recognition by surgeons that AA could be diagnosed pre-operatively and managed surgically, with mortality rates of approximately 10%. Not until 1901 did Albert Ochsner advocate NOM, paradoxically for severe cases unlikely to survive operation. Markedly decreased mortality coincided with the introduction of sulfanilamide in 1935 and penicillin and curare in 1942. The first large series of patients with AA treated primarily with NOM was published in 1956 by Eric Coldrey. Modern management evolved rapidly in the late twentieth century, including effective anti-anaerobic antibiotic agents (1970s), laparoscopic appendectomy (LA; 1980), and pelvis computed tomography with rectal contrast (1998) all representing important contributions. Randomized controlled trials of NOM of AA date to 1995, with one large trial (2015) showing that open appendectomy was not non-inferior to NOM, and another (2020) demonstrating non-inferiority between (mostly) LA and NOM. However, one-year failure rates are high (Ã¢Ë†Â¼30%) and appear to increase further with longer follow-up. <b><i>Conclusions:</i></b> Laparoscopic appendectomy is curative and cost-effective management for AA, with low morbidity. Results of recent RCTs of NOM of AA indicate that LA remains the treatment of choice, particularly if a fecalith is present. However, patient preferences must be taken into account; some may prefer NOM for the 60%-70% chance that surgery may be avoided, which should be considered when providing informed consent. Non-operative management should be undertaken in the outpatient setting if possible. Antibiotic management-whether or not for NOM-should adhere to the principles of stewardship.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21072,""
"Artificial intelligence-enhanced intraoperative neurosurgical workflow: state of the art and future perspectives","Tariciotti, Palmisciano, Giordano, Remoli, Lacorte, Bertani, Locatelli, Dimeco, Caccavella, Prada","https://doi.org/10.23736/S0390-5616.21.05483-7","20210921","PubMed","","Artificial Intelligence (AI) and Machine Learning (ML) augment decision-making processes and productivity by supporting surgeons over a range of clinical activities: from diagnosis and preoperative planning to intraoperative surgical assistance. We reviewed the literature to identify current AI platforms applied to neurosurgical perioperative and intraoperative settings and describe their role in multiple subspecialties. A systematic review of the literature was conducted following the PRISMA guidelines. PubMed, EMBASE, and Scopus databases were searched from inception to December 31, 2020. Original articles were included if they: presented AI platforms implemented in perioperative, intraoperative settings and reported ML models' performance metrics. Due to the heterogeneity in neurosurgical applications, a qualitative synthesis was deemed appropriate. The risk of bias and applicability of predicted outcomes were assessed using the PROBAST tool. 41 articles were included. All studies evaluated a supervised learning algorithm. A total of 10 ML models were described; the most frequent were neural networks (n = 15) and tree-based models (n = 13). Overall, the risk of bias was medium-high, but applicability was considered positive for all studies. Articles were grouped into 4 categories according to the subspecialty of interest: neuro-oncology, spine, functional and other. For each category, different prediction tasks were identified. In this review, we summarize the state-of-art applications of AI for the intraoperative augmentation of neurosurgical workflows across multiple subspecialties. ML models may boost surgical team performances by reducing human errors and providing patient-tailored surgical plans, but further and higher-quality studies need to be conducted.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21073,""
"Machine Learning in the Differentiation of Soft Tissue Neoplasms: Comparison of Fat-Suppressed T2WI and Apparent Diffusion Coefficient (ADC) Features-Based Models","Hu, Chen, Zhou","https://doi.org/10.1007/s10278-021-00513-7","20211028","PubMed","Apparent diffusion coefficient (ADC); Diffusion MR weighted imaging; Least absolute shrinkage and selection operator (LASSO); Soft tissue neoplasms (STN); Texture analysis (TA)","Machine learning has been widely used in the characterization of tumors recently. This article aims to explore the feasibility of the whole tumor fat-suppressed (FS) T2WI and ADC features-based least absolute shrinkage and selection operator (LASSO)-logistic predictive models in the differentiation of soft tissue neoplasms (STN). The clinical and MR findings of 160 cases with 161 histologically proven STN were reviewed, retrospectively, 75 with diffusion-weighted imaging (DWI with b values of 50, 400, and 800Ã‚Â s/mm<sup>2</sup>). They were divided into benign and malignant groups and further divided into training (70%) and validation (30%) cohorts. The MR FS T2WI and ADC features-based LASSO-logistic models were built and compared. The AUC of the FS T2WI features-based LASSO-logistic regression model for benign and malignant prediction was 0.65 and 0.75 for the training and validation cohorts. The model's sensitivity, specificity, and accuracy of the validation cohort were 55%, 96%, and 76.6%. While the AUC of the ADC features-based model was 0.932 and 0.955 for the training and validation cohorts. The model's sensitivity, specificity, and accuracy were 83.3%, 100%, and 91.7%. The performances of these models were also validated by decision curve analysis (DCA). The AUC of the whole tumor ADC features-based LASSO-logistic regression predictive model was larger than that of FS T2WI features (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.017). The whole tumor fat-suppressed T2WI and ADC features-based LASSO-logistic predictive models both can serve as useful tools in the differentiation of STN. ADC features-based LASSO-logistic regression predictive model did better than that of FS T2WI features.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21074,""
"Stakeholders' perspectives on the future of artificial intelligence in radiology: a scoping review","Yang, Ene, Arabi Belaghi, Koff, Stein, Santaguida","https://doi.org/10.1007/s00330-021-08214-z","20210921","PubMed","Artificial intelligence; Attitude; Education; Ethics; Radiology","Artificial intelligence (AI) has the potential to impact clinical practice and healthcare delivery. AI is of particular significance in radiology due to its use in automatic analysis of image characteristics. This scoping review examines stakeholder perspectives on AI use in radiology, the benefits, risks, and challenges to its integration. A search was conducted from 1960 to November 2019 in EMBASE, PubMed/MEDLINE, Web of Science, Cochrane Library, CINAHL, and grey literature. Publications reflecting stakeholder attitudes toward AI were included with no restrictions. Commentaries (n = 32), surveys (n = 13), presentation abstracts (n = 8), narrative reviews (n = 8), and a social media study (n = 1) were included from 62 eligible publications. These represent the views of radiologists, surgeons, medical students, patients, computer scientists, and the general public. Seven themes were identified (predicted impact, potential replacement, trust in AI, knowledge of AI, education, economic considerations, and medicolegal implications). Stakeholders anticipate a significant impact on radiology, though replacement of radiologists is unlikely in the near future. Knowledge of AI is limited for non-computer scientists and further education is desired. Many expressed the need for collaboration between radiologists and AI specialists to successfully improve patient care. Stakeholder views generally suggest that AI can improve the practice of radiology and consider the replacement of radiologists unlikely. Most stakeholders identified the need for education and training on AI, as well as collaborative efforts to improve AI implementation. Further research is needed to gain perspectives from non-Western countries, non-radiologist stakeholders, on economic considerations, and medicolegal implications. Stakeholders generally expressed that AI alone cannot be used to replace radiologists. The scope of practice is expected to shift with AI use affecting areas from image interpretation to patient care. Patients and the general public do not know how to address potential errors made by AI systems while radiologists believe that they should be ""in-the-loop"" in terms of responsibility. Ethical accountability strategies must be developed across governance levels. Students, residents, and radiologists believe that there is a lack in AI education during medical school and residency. The radiology community should work with IT specialists to ensure that AI technology benefits their work and centres patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21075,""
"Computer-Based Decision Tools for Shared Therapeutic Decision-making in Oncology: Systematic Review","Yung, Kay, Beale, Gibson, Shaw","https://doi.org/10.2196/31616","20211027","PubMed","artificial intelligence; cancer; computer-based; decision support; decision-making; machine learning; oncology; shared decision-making; system; tool; uncertainty","Therapeutic decision-making in oncology is a complex process because physicians must consider many forms of medical data and protocols. Another challenge for physicians is to clearly communicate their decision-making process to patients to ensure informed consent. Computer-based decision tools have the potential to play a valuable role in supporting this process. This systematic review aims to investigate the extent to which computer-based decision tools have been successfully adopted in oncology consultations to improve patient-physician joint therapeutic decision-making. This review was conducted in accordance with the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 checklist and guidelines. A literature search was conducted on February 4, 2021, across the Cochrane Database of Systematic Reviews (from 2005 to January 28, 2021), the Cochrane Central Register of Controlled Trials (December 2020), MEDLINE (from 1946 to February 4, 2021), Embase (from 1947 to February 4, 2021), Web of Science (from 1900 to 2021), Scopus (from 1969 to 2021), and PubMed (from 1991 to 2021). We used a snowball approach to identify additional studies by searching the reference lists of the studies included for full-text review. Additional supplementary searches of relevant journals and gray literature websites were conducted. The reviewers screened the articles eligible for review for quality and inclusion before data extraction. There are relatively few studies looking at the use of computer-based decision tools in oncology consultations. Of the 4431 unique articles obtained from the searches, only 10 (0.22%) satisfied the selection criteria. From the 10 selected studies, 8 computer-based decision tools were identified. Of the 10 studies, 6 (60%) were conducted in the United States. Communication and information-sharing were improved between physicians and patients. However, physicians did not change their habits to take advantage of computer-assisted decision-making tools or the information they provide. On average, the use of these computer-based decision tools added approximately 5 minutes to the total length of consultations. In addition, some physicians felt that the technology increased patients' anxiety. Of the 10 selected studies, 6 (60%) demonstrated positive outcomes, 1 (10%) showed negative results, and 3 (30%) were neutral. Adoption of computer-based decision tools during oncology consultations continues to be low. This review shows that information-sharing and communication between physicians and patients can be improved with the assistance of technology. However, the lack of integration with electronic health records is a barrier. This review provides key requirements for enhancing the chance of success of future computer-based decision tools. However, it does not show the effects of health care policies, regulations, or business administration on physicians' propensity to adopt the technology. Nevertheless, it is important that future research address the influence of these higher-level factors as well. PROSPERO International Prospective Register of Systematic Reviews CRD42021226087; https://www.crd.york.ac.uk/prospero/display_record.php?ID=CRD42021226087.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21076,""
"Social Determinants in Machine Learning Cardiovascular Disease Prediction Models: A Systematic Review","Zhao, Wood, Mirin, Cook, Chunara","https://doi.org/10.1016/j.amepre.2021.04.016","20211008","PubMed","Cardiovascular Diseases; China; Europe; Humans; Machine Learning; Social Determinants of Health","Cardiovascular disease is the leading cause of death worldwide, and cardiovascular disease burden is increasing in low-resource settings and for lower socioeconomic groups. Machine learning algorithms are being developed rapidly and incorporated into clinical practice for cardiovascular disease prediction and treatment decisions. Significant opportunities for reducing death and disability from cardiovascular disease worldwide lie with accounting for the social determinants of cardiovascular outcomes. This study reviews how social determinants of health are being included in machine learning algorithms to inform best practices for the development of algorithms that account for social determinants. A systematic review using 5 databases was conducted in 2020. English language articles from any location published from inception to April 10, 2020, which reported on the use of machine learning for cardiovascular disease prediction that incorporated social determinants of health, were included. Most studies that compared machine learning algorithms and regression showed increased performance of machine learning, and most studies that compared performance with or without social determinants of health showed increased performance with them. The most frequently included social determinants of health variables were gender, race/ethnicity, marital status, occupation, and income. Studies were largely from North America, Europe, and China, limiting the diversity of the included populations and variance in social determinants of health. Given their flexibility, machine learning approaches may provide an opportunity to incorporate the complex nature of social determinants of health. The limited variety of sources and data in the reviewed studies emphasize that there is an opportunity to include more social determinants of health variables, especially environmental ones, that are known to impact cardiovascular disease risk and that recording such data in electronic databases will enable their use.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21077,""
"Image-Based Artificial Intelligence in Wound Assessment: A Systematic Review","Anisuzzaman, Wang, Rostami, Gopalakrishnan, Niezgoda, Yu","https://doi.org/10.1089/wound.2021.0091","20210921","PubMed","","Accurately predicting wound healing trajectories is difficult for wound care clinicians due to the complex and dynamic processes involved in wound healing. Wound care teams capture images of wounds during clinical visits generating big data sets over time. Developing novel artificial intelligence (AI) systems can help clinicians diagnose, assess the effectiveness of therapy, and predict healing outcomes. Recent Advances: Rapid developments in computer processing have enabled the development of AI-based systems that can improve the diagnosis and effectiveness of therapy in various clinical specializations. In the past decade, we have witnessed AI revolutionizing all types of medical imaging like X-ray, ultrasound, CT, MRI, etc., but AI-based systems remain to be developed clinically and computationally for high-quality wound care that can result in better patient outcomes. In the current standard of care, collecting wound images on every clinical visit, interpreting and archiving the data are cumbersome and time-consuming. Commercial platforms are developed to capture images, perform wound measurements, and provide clinicians with a workflow for diagnosis, but AI-based systems are still in their infancy. This systematic review summarizes the breadth and depth of the most recent and relevant work in intelligent image-based data analysis and system developments for wound assessment. With increasing availabilities of massive data (wound images, wound-specific electronic health records, etc.) as well as powerful computing resources, AI-based digital platforms will play a significant role in delivering data-driven care to people suffering from debilitating chronic wounds.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21078,""
"Ethics, Integrity, and Retributions of Digital Detection Surveillance Systems for Infectious Diseases: Systematic Literature Review","Zhao, Ma, Yu, Liu, Dong, Pang, Lu, Molassiotis, Holroyd, Wong","https://doi.org/10.2196/32328","20211028","PubMed","artificial intelligence; electronic medical records; ethics; infectious diseases; machine learning; Artificial Intelligence; COVID-19; Communicable Diseases; Humans; Pandemics; SARS-CoV-2","The COVID-19 pandemic has increased the importance of the deployment of digital detection surveillance systems to support early warning and monitoring of infectious diseases. These opportunities create a ""double-edge sword,"" as the ethical governance of such approaches often lags behind technological achievements. The aim was to investigate ethical issues identified from utilizing artificial intelligence-augmented surveillance or early warning systems to monitor and detect common or novel infectious disease outbreaks. In a number of databases, we searched relevant articles that addressed ethical issues of using artificial intelligence, digital surveillance systems, early warning systems, and/or big data analytics technology for detecting, monitoring, or tracing infectious diseases according to PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, and further identified and analyzed them with a theoretical framework. This systematic review identified 29 articles presented in 6 major themes clustered under individual, organizational, and societal levels, including awareness of implementing digital surveillance, digital integrity, trust, privacy and confidentiality, civil rights, and governance. While these measures were understandable during a pandemic, the public had concerns about receiving inadequate information; unclear governance frameworks; and lack of privacy protection, data integrity, and autonomy when utilizing infectious disease digital surveillance. The barriers to engagement could widen existing health care disparities or digital divides by underrepresenting vulnerable and at-risk populations, and patients' highly sensitive data, such as their movements and contacts, could be exposed to outside sources, impinging significantly upon basic human and civil rights. Our findings inform ethical considerations for service delivery models for medical practitioners and policymakers involved in the use of digital surveillance for infectious disease spread, and provide a basis for a global governance structure. PROSPERO CRD42021259180; https://www.crd.york.ac.uk/prospero/display_record.php?RecordID=259180.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21079,""
"Diagnostic test accuracy of artificial intelligence analysis of cross-sectional imaging in pulmonary hypertension: a systematic literature review","Hardacre, Robertshaw, Barratt, Adams, MacKenzie Ross, Robinson, Suntharalingam, Pauling, Rodrigues","https://doi.org/10.1259/bjr.20210332","20210929","PubMed","","To undertake the first systematic review examining the performance of artificial intelligence (AI) applied to cross-sectional imaging for the diagnosis of acquired pulmonary arterial hypertension (PAH). Searches of Medline, Embase and Web of Science were undertaken on 1 July 2020. Original publications studying AI applied to cross-sectional imaging for the diagnosis of acquired PAH in adults were identified through two-staged double-blinded review. Study quality was assessed using the Quality Assessment of Diagnostic Accuracy Studies and Checklist for Artificial Intelligence in Medicine frameworks. Narrative synthesis was undertaken following Synthesis Without Meta-Analysis guidelines. This review received no funding and was registered in the International Prospective Register of Systematic Reviews (ID:CRD42020196295). Searches returned 476 citations. Three retrospective observational studies, published between 2016 and 2020, were selected for data-extraction. Two methods applied to cardiac-MRI demonstrated high diagnostic accuracy, with the best model achieving AUC=0.90 (95% CI: 0.85-0.93), 89% sensitivity and 81% specificity. Stronger results were achieved using cardiac-MRI for classification of idiopathic PAH, achieving AUC=0.97 (95% CI: 0.89-1.0), 96% sensitivity and 87% specificity. One study reporting CT-based AI demonstrated lower accuracy, with 64.6% sensitivity and 97.0% specificity. Automated methods for identifying PAH on cardiac-MRI are emerging with high diagnostic accuracy. AI applied to cross-sectional imaging may provide non-invasive support to reduce diagnostic delay in PAH. This would be helped by stronger solutions in other modalities. There is a significant shortage of research in this important area. Early detection of PAH would be supported by further research advances on the promising emerging technologies identified.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21080,""
"Advanced brain ageing in Parkinson's disease is related to disease duration and individual impairment","Eickhoff, Hoffstaedter, Caspers, Reetz, Mathys, Dogan, Amunts, Schnitzler, Eickhoff","https://doi.org/10.1093/braincomms/fcab191","20210921","PubMed","ParkinsonÃ¢â‚¬â„¢s; age; atrophy; machine learning; prediction","Machine learning can reliably predict individual age from MRI data, revealing that patients with neurodegenerative disorders show an elevated biological age. A surprising gap in the literature, however, pertains to Parkinson's disease. Here, we evaluate brain age in two cohorts of Parkinson's patients and investigated the relationship between individual brain age and clinical characteristics. We assessed 372 patients with idiopathic Parkinson's disease, newly diagnosed cases from the Parkinson's Progression Marker Initiative database and a more chronic local sample, as well as age- and sex-matched healthy controls. Following morphometric preprocessing and atlas-based compression, individual brain age was predicted using a multivariate machine learning model trained on an independent, multi-site reference sample. Across cohorts, healthy controls were well predicted with a mean error of 4.4 years. In turn, Parkinson's patients showed a significant (controlling for age, gender and site) increase in brain age of Ã¢Ë†Â¼3 years. While this effect was already present in the newly diagnosed sample, advanced biological age was significantly related to disease duration as well as worse cognitive and motor impairment. While biological age is increased in patients with Parkinson's disease, the effect is at the lower end of what is found for other neurological and psychiatric disorders. We argue that this may reflect a heterochronicity between forebrain atrophy and small but behaviourally salient midbrain pathology. Finally, we point to the need to disentangle physiological ageing trajectories, lifestyle effects and core pathological changes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21081,""
"Scope and challenges of machine learning-based diagnosis and prognosis in clinical dentistry: A literature review","Reyes, Knorst, Ortiz, Ardenghi","https://www.google.com/search?q=Scope+and+challenges+of+machine+learning-based+diagnosis+and+prognosis+in+clinical+dentistry:+A+literature+review.","20210921","PubMed","artificial intelligence; dentistry; diagnosis; machine learning; oral health; prognosis","Machine learning (ML) has emerged as a branch of artificial intelligence dealing with the analysis of large amounts of data. The applications of ML algorithms have also expanded to health care, including dentistry. Recent advances in this field point to future improvements in diagnostic techniques and the prognosis of various diseases of the teeth and other maxillofacial structures. The aim of this literature review is to describe the basis for ML being applied to different dental sub-fields in recent years, to identify typical algorithms used in the studies, and to summarize the scope and challenges of using these techniques in dental clinical practice. The proficiency of emerging technologies that have begun to show encouraging results in the diagnosis and prognosis of oral diseases can improve the precision in the selection of treatment for patients. It is necessary to understand the challenges associated with using these tools to effectively use them in dental services and ensure a higher quality of care for patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21082,""
"Knowledge and attitudes towards artificial intelligence in imaging: a look at the quantitative survey literature","Bhandari, Purchuri, Sharma, Ibrahim, Prior","https://doi.org/10.1016/j.clinimag.2021.08.004","20210928","PubMed","Artificial intelligence; Attitudes; Knowledge; Opinion; Survey","There exists many single sample perspectives on artificial intelligence (AI). The aim of this review was to collate the current data on attitudes/knowledge towards AI in three unique populations: medical students, clinicians and patients. A literature search was performed on PubMed, Scopus and Web of Science pertaining to survey data on AI in radiology. Quality assessment was performed by an adapted version of the assessment tool from the National Heart, Lung and Blood Institute for Observational Studies. Fourteen studies were found on attitudes/knowledge towards AI in radiology. Four studies examined medical students, seven on clinicians and three on patient populations. Deficiencies in the literature mainly related to sampling bias. Students had anxiety relating to future job prospects. Clinicians were optimistic and viewed AI as an aid to the diagnosis and wanted to further their knowledge. Patients were concerned about the lack of human interaction and accountability during error. Attitudes and knowledge regarding AI in radiology remains a topic that needs to be researched further and education given pertaining to its use in a clinical setting.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21083,""
"Cost utility analysis of Remdesivir and Dexamethasone treatment for hospitalised COVID-19 patients - a hypothetical study","Carta, Conversano","https://doi.org/10.1186/s12913-021-06998-w","20210921","PubMed","Cost Effectiveness; Cost Utility; Covid-19; Decision tree; Dexamethasone; Remdesivir; Sars-Cov-2; pharmacoeconomics; Adenosine Monophosphate; Alanine; COVID-19; Cost-Benefit Analysis; Dexamethasone; Humans; SARS-CoV-2","Sars-Cov-2 is a novel corona virus associated with significant morbidity and mortality. Remdesivir and Dexamethasone are two treatments that have shown to be effective against the Sars-Cov-2 associated disease. However, a cost-effectiveness analysis of the two treatments is still lacking. The cost-utility of Remdesivir, Dexamethasone and a simultaneous use of the two drugs with respect to standard of care for treatment Covid-19 hospitalized patients is evaluated, together with the effect of Remdesivir compared to the base model but based on alernative assumptions. A decision tree for an hypothetical cohort of Covid-19 hospitalized patients, from an health care perspective and a one year horizon is specified. Efficacy data are retrieved from a literature review of clinical trials, whilst costs and utility are obtained from other published studies. Remdesivir, if health care costs are related to the days of hospitalization, is a cost saving strategy. Dexamethasone is cost effective with an ICER of &lt;DOLLAR/&gt;5208/QALY, and the concurrent use of Remdesivir and Dexamethasone is the most favorable strategy for higher level of willingness to pay thresholds. Moreover, if Remdesivir has a positive effect on mortality the utility is three times higher respect to base case. Whereas, if health care costs are not related to the length of patient hospitalization Remdesivir has an ICER respect to standard of care of &lt;DOLLAR/&gt;384412.8/QALY gained, which is not cost effective. We also find that Dexaamethasone is cost effective respect to standard care if we compute the cost for live saved with an ICER of &lt;DOLLAR/&gt;313.79 for life saved. The uncertainty of the model parameters is also tested through both a one-way deterministic sensitivity analysis and a probabilistic sensitivity analysis. We find that the use of Remdesivir and/or Dexamethasone is effective from an economic standpoint.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21084,""
"The emergence of machine learning in auditory neural impairment: A systematic review","Abu Bakar, Lai, Hamzaid","https://doi.org/10.1016/j.neulet.2021.136250","20211022","PubMed","Auditory Evoked Potential (AEP); Auditory assessment; Classification; Electroencephalography (EEG); Machine learning","Hearing loss is a common neurodegenerative disease that can start at any stage of life. Misalignment of the auditory neural impairment may impose challenges in processing incoming auditory stimulus that can be measured using electroencephalography (EEG). The electrophysiological behaviour response emanated from EEG auditory evoked potential (AEP) requires highly trained professionals for analysis and interpretation. Reliable automated methods using techniques of machine learning would assist the auditory assessment process for informed treatment and practice. It is thus highly required to develop models that are more efficient and precise by considering the characteristics of brain signals. This study aims to provide a comprehensive review of several state-of-the-art techniques of machine learning that adopt EEG evoked response for the auditory assessment within the last 13Ã‚Â years. Out of 161 initially screened articles, 11 were retained for synthesis. The outcome of the review presented that the Support Vector Machine (SVM) classifier outperformed with over 80% accuracy metric and was recognized as the best suited model within the field of auditory research. This paper discussed the comprehensive iterative properties of the proposed computed algorithms and the feasible future direction in hearing impaired rehabilitation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21085,""
"Design of a multifaceted strategy based on automated text messaging in patients with recent heart failure admission","Rohde, Hoffmann Filho, Rover, Rabelo-Silva, Lopez, Passos, Silvestre, Martins, de Figueiredo Neto, Silveira, Canesin, SimÃƒÂµes, Akio Nishijuka, Bertoldi, Danzmann, Mourilhe-Rocha, Magedanz, Esteves, de Castilho, Fernandes-Silva, Ritt, Blacher, Soares, Cavalcanti, Ramirez","https://doi.org/10.1002/ehf2.13516","20210918","PubMed","Heart failure; Natriuretic peptide; Telemonitoring","To evaluate a telemonitoring strategy based on automated text messaging and telephone support after heart failure (HF) hospitalization. The MESSAGE-HF study is a prospective multicentre, randomized, nationwide trial enrolling patients from 30 clinics in all regions of Brazil. HF patients with reduced left ventricular ejection fraction (&lt;40%) and access to mobile phones are eligible after an acute decompensated HF hospitalization. Patients meeting eligibility criteria undergo an initial feasibility text messaging assessment and are randomized to usual care or telemonitoring intervention. All patients receive a HF booklet with basic information and recommendations about self-care. Patients in the intervention group receive four daily short text messages (educational and feedback) during the first 30Ã‚Â days of the protocol to optimize self-care; the feedback text messages from patients could trigger diuretic adjustments or a telephone call from the healthcare team. After 30Ã‚Â days, the frequency of text messages can be adjusted. Patients are followed up after 30, 90, and 180Ã‚Â days, with final status ascertained at 365Ã‚Â days by telephone. Our primary endpoint is the change in N-terminal pro-brain natriuretic peptide (NT-proBNP) levels after 180Ã‚Â days. Secondary endpoints include changes in NT-proBNP after 30Ã‚Â days; health-related quality of life, HF self-care, and knowledge scales after 30 and 180Ã‚Â days; and a composite outcome of HF hospitalization and cardiovascular death, adjudicated by a blinded and independent committee. The MESSAGE-HF trial is evaluating an educational and self-care promotion strategy involving a simple, intensive, and tailored telemonitoring system. If proven effective, it could be applied to a broader population worldwide.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21086,""
"Palliative medicine education-Bed Race, The End of Life Board Game in undergraduates","Harris, Atkinson","https://doi.org/10.1136/bmjspcare-2021-003015","20210918","PubMed","communication; education and training; symptoms and symptom management; terminal care","Educational board games facilitate active learning to conceptualise knowledge, and, promote collaborative learning and team work. Despite increasing interest in them, use in palliative and end of life care has been very limited to date. In 'Bed race, The End of Life Game', participants are divided into four teams who move a model hospital bed around a board to collect items (syringe driver; Do Not Attempt Resuscitation form; oral hydration gel; a 'heart'; Just In Case medicines). To obtain items at themed 'checkpoints', each team needs to answer quiz questions, which require application of clinical knowledge and/or communication skills. Pregame and postgame quiz scores and feedback were collected from 12 game sessions involving 251 year 5 medical students. 169 (67%) of students completed pregame and postgame anonymous quiz questions and free-text feedback. Postgame quiz scores were higher for each topic, and the difference in the paired pregame and postgame questionnaires was statistically significant (p&lt;0.05). Themes from the free-text feedback included 'engaging and fun'; 'relevant learning'; 'peer learning and team work'. Educational board games are not a new panacea for education, but the concept can be successfully applied in palliative care.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21087,""
"Facilitators and barriers to using telepresence robots in aged care settings: a scoping review protocol","Smith, Gregorio, Hung","https://doi.org/10.1136/bmjopen-2021-051769","20211102","PubMed","geriatric medicine; mental health; telemedicine; Aged; Humans; Loneliness; Long-Term Care; Quality of Life; Research Design; Review Literature as Topic; Robotics; Social Isolation","Social isolation is a significant issue in aged care settings (eg, long-term care (LTC) and hospital) and is associated with adverse outcomes such as reduced well-being and loneliness. Loneliness is linked with depression, anxiety, cognitive decline, weakened immune system, poor physical health, poor quality of life and mortality. The use of robotic assistance may help mitigate social isolation and loneliness. Although telepresence robots have been used in healthcare settings, a comprehensive review of studies focusing on their use in aged care for reducing social isolation requires further investigation. This scoping review will focus on the use of telepresence robots to support social connection of older people in care settings. This scoping review will follow Joanna Briggs Institute scoping review methodology. The review team consists of patient partners and family partners, a nurse researcher and a group of students. In the scoping review, we will search the following databases: MEDLINE (Ovid), CINAHL, PsycINFO (EBSCO), Web of Science and ProQuest Dissertations &amp; Theses Global. Google and Google Scholar will be used to search for additional literature. A handsearch will be conducted using the reference lists of included studies to identify additional relevant articles. The scoping review will consider studies of using a telepresence robotic technology with older adults in care settings (ie, LTC and hospital), published in English. Since the methodology of the study consists of collecting data from publicly available articles, it does not require ethics approval. By examining the current state of using telepresence to support older people in care settings, this scoping review can offer useful insight into users' needs (eg, patients' and care providers' needs) and inform future research and practice. We will share the scoping review results through conference presentations and an open access publication in a peer-reviewed journal.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21088,""
"Applications of Blockchain in the Medical Field: Narrative Review","Xie, Zhang, Wang, Liu, Liu, Huo, Duan, Dong, Lu, Ye","https://doi.org/10.2196/28613","20211102","PubMed","COVID-19; blockchain; electronic health records; health care; health data; review; smart health care; Blockchain; COVID-19; Confidentiality; Data Management; Electronic Health Records; Humans; SARS-CoV-2","As a distributed technology, blockchain has attracted increasing attention from stakeholders in the medical industry. Although previous studies have analyzed blockchain applications from the perspectives of technology, business, or patient care, few studies have focused on actual use-case scenarios of blockchain in health care. In particular, the outbreak of COVID-19 has led to some new ideas for the application of blockchain in medical practice. This paper aims to provide a systematic review of the current and projected uses of blockchain technology in health care, as well as directions for future research. In addition to the framework structure of blockchain and application scenarios, its integration with other emerging technologies in health care is discussed. We searched databases such as PubMed, EMBASE, Scopus, IEEE, and Springer using a combination of terms related to blockchain and health care. Potentially relevant papers were then compared to determine their relevance and reviewed independently for inclusion. Through a literature review, we summarize the key medical scenarios using blockchain technology. We found a total of 1647 relevant studies, 60 of which were unique studies that were included in this review. These studies report a variety of uses for blockchain and their emphasis differs. According to the different technical characteristics and application scenarios of blockchain, we summarize some medical scenarios closely related to blockchain from the perspective of technical classification. Moreover, potential challenges are mentioned, including the confidentiality of privacy, the efficiency of the system, security issues, and regulatory policy. Blockchain technology can improve health care services in a decentralized, tamper-proof, transparent, and secure manner. With the development of this technology and its integration with other emerging technologies, blockchain has the potential to offer long-term benefits. Not only can it be a mechanism to secure electronic health records, but blockchain also provides a powerful tool that can empower users to control their own health data, enabling a foolproof health data history and establishing medical responsibility.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21089,""
"Using Acoustic Speech Patterns From Smartphones to Investigate Mood Disorders: Scoping Review","Flanagan, Chan, Roop, Sundram","https://doi.org/10.2196/24352","20211101","PubMed","data science; diagnosis; monitoring; mood disorders; smartphone; speech patterns; Acoustics; Humans; Monitoring, Physiologic; Mood Disorders; Smartphone; Speech","Mood disorders are commonly underrecognized and undertreated, as diagnosis is reliant on self-reporting and clinical assessments that are often not timely. Speech characteristics of those with mood disorders differs from healthy individuals. With the wide use of smartphones, and the emergence of machine learning approaches, smartphones can be used to monitor speech patterns to help the diagnosis and monitoring of mood disorders. The aim of this review is to synthesize research on using speech patterns from smartphones to diagnose and monitor mood disorders. Literature searches of major databases, Medline, PsycInfo, EMBASE, and CINAHL, initially identified 832 relevant articles using the search terms ""mood disorders"", ""smartphone"", ""voice analysis"", and their variants. Only 13 studies met inclusion criteria: use of a smartphone for capturing voice data, focus on diagnosing or monitoring a mood disorder(s), clinical populations recruited prospectively, and in the English language only. Articles were assessed by 2 reviewers, and data extracted included data type, classifiers used, methods of capture, and study results. Studies were analyzed using a narrative synthesis approach. Studies showed that voice data alone had reasonable accuracy in predicting mood states and mood fluctuations based on objectively monitored speech patterns. While a fusion of different sensor modalities revealed the highest accuracy (97.4%), nearly 80% of included studies were pilot trials or feasibility studies without control groups and had small sample sizes ranging from 1 to 73 participants. Studies were also carried out over short or varying timeframes and had significant heterogeneity of methods in terms of the types of audio data captured, environmental contexts, classifiers, and measures to control for privacy and ambient noise. Approaches that allow smartphone-based monitoring of speech patterns in mood disorders are rapidly growing. The current body of evidence supports the value of speech patterns to monitor, classify, and predict mood states in real time. However, many challenges remain around the robustness, cost-effectiveness, and acceptability of such an approach and further work is required to build on current research and reduce heterogeneity of methodologies as well as clinical evaluation of the benefits and risks of such approaches.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21090,""
"Conversational Agents for Health and Well-being Across the Life Course: Protocol for an Evidence Map","Guerreiro, Angelini, Rafael Henriques, El Kamali, Baixinho, Balsa, FÃƒÂ©lix, Khaled, Carmo, ClÃƒÂ¡udio, Caon, Daher, Alexandre, Padinha, Mugellini","https://doi.org/10.2196/26680","20211022","PubMed","artificial intelligence; chatbot; conversational agent; e-coach; health; intervention; relational agent; virtual assistant; virtual humans; well-being","Conversational agents, which we defined as computer programs that are designed to simulate two-way human conversation by using language and are potentially supplemented with nonlanguage modalities, offer promising avenues for health interventions for different populations across the life course. There is a lack of open-access and user-friendly resources for identifying research trends and gaps and pinpointing expertise across international centers. Our aim is to provide an overview of all relevant evidence on conversational agents for health and well-being across the life course. Specifically, our objectives are to identify, categorize, and synthesize-through visual formats and a searchable database-primary studies and reviews in this research field. An evidence map was selected as the type of literature review to be conducted, as it optimally corresponded to our aim. We systematically searched 8 databases (MEDLINE; CINAHL; Web of Science; Scopus; the Cochrane, ACM, IEEE, and Joanna Briggs Institute databases; and Google Scholar). We will perform backward citation searching on all included studies. The first stage of a double-stage screening procedure, which was based on abstracts and titles only, was conducted by using predetermined eligibility criteria for primary studies and reviews. An operational screening procedure was developed for streamlined and consistent screening across the team. Double data extraction will be performed with previously piloted data collection forms. We will appraise systematic reviews by using A Measurement Tool to Assess Systematic Reviews (AMSTAR) 2. Primary studies and reviews will be assessed separately in the analysis. Data will be synthesized through descriptive statistics, bivariate statistics, and subgroup analysis (if appropriate) and through high-level maps such as scatter and bubble charts. The development of the searchable database will be informed by the research questions and data extraction forms. As of April 2021, the literature search in the eight databases was concluded, yielding a total of 16,351 records. The first stage of screening, which was based on abstracts and titles only, resulted in the selection of 1282 records of primary studies and 151 records of reviews. These will be subjected to second-stage screening. A glossary with operational definitions for supporting the study selection and data extraction stages was drafted. The anticipated completion date is October 2021. Our wider definition of a conversational agent and the broad scope of our evidence map will explicate trends and gaps in this field of research. Additionally, our evidence map and searchable database of studies will help researchers to avoid fragmented research efforts and wasteful redundancies. Finally, as part of the Harnessing the Power of Conversational e-Coaches for Health and Well-being Through Swiss-Portuguese Collaboration project, our work will also inform the development of an international taxonomy on conversational agents for health and well-being, thereby contributing to terminology standardization and categorization. DERR1-10.2196/26680.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21091,""
"Health Equity in Artificial Intelligence and Primary Care Research: Protocol for a Scoping Review","Wang, Somani, Chen, Murray, Sarkar","https://doi.org/10.2196/27799","20211022","PubMed","artificial intelligence; big data; data mining; decision support; diagnosis; electronic health records; family medicine; health disparity; health equity; health informatics; health information technology; primary care; scoping review; treatment","Though artificial intelligence (AI) has the potential to augment the patient-physician relationship in primary care, bias in intelligent health care systems has the potential to differentially impact vulnerable patient populations. The purpose of this scoping review is to summarize the extent to which AI systems in primary care examine the inherent bias toward or against vulnerable populations and appraise how these systems have mitigated the impact of such biases during their development. We will conduct a search update from an existing scoping review to identify studies on AI and primary care in the following databases: Medline-OVID, Embase, CINAHL, Cochrane Library, Web of Science, Scopus, IEEE Xplore, ACM Digital Library, MathSciNet, AAAI, and arXiv. Two screeners will independently review all abstracts, titles, and full-text articles. The team will extract data using a structured data extraction form and synthesize the results in accordance with PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines. This review will provide an assessment of the current state of health care equity within AI for primary care. Specifically, we will identify the degree to which vulnerable patients have been included, assess how bias is interpreted and documented, and understand the extent to which harmful biases are addressed. As of October 2020, the scoping review is in the title- and abstract-screening stage. The results are expected to be submitted for publication in fall 2021. AI applications in primary care are becoming an increasingly common tool in health care delivery and in preventative care efforts for underserved populations. This scoping review would potentially show the extent to which studies on AI in primary care employ a health equity lens and take steps to mitigate bias. PRR1-10.2196/27799.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21092,""
"Network pharmacology study on the mechanism of Qiangzhifang in the treatment of panic disorder","Zhao, Liu, Song, Liu, Chu, Liu, Jiang, Dong, Shi, Yan","https://doi.org/10.21037/atm-21-4090","20210918","PubMed","Qiangzhifang (QZF); molecular docking; network pharmacology; panic disorder (PD)","Panic disorder (PD) is a kind of mental illness characterized by the symptom of recurring panic attacks. Qiangzhifang (QZF) is a novel decoction developed by Professor Zhaojun Yan based on a unique system of syndrome differentiation and clinical experience. It has achieved remarkable results after long-term clinical practice, but its mechanism of action is still unclear. This study aims to use network pharmacology and molecular docking to explore the mechanism of QZF in the treatment of PD. We used the Traditional Chinese Medicine Systems Pharmacology Database and Analysis Platform (TCMSP), a literature search, and Encyclopedia of Traditional Chinese Medicine (ETCM) to find active ingredients and targets of QZF. We searched for PD targets in GeneCards, Online Mendelian Inheritance in Man (OMIM), the Comparative Toxicogenomics Database (CTD), and DrugBank. We established a PD target database, constructed a protein-protein interaction (PPI) network, and performed Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analysis in order to screen possible pathways of action and analyze the mechanism. This study identified 84 effective components of QZF, 691 potential targets, 357 PD targets, and 97 intersectional targets. Enrichment analysis using the Database for Annotation, Visualization, and Integrated Discovery (DAVID) showed that QZF was associated with 118 biological processes (BPs), 18 cellular components (CCs), 35 molecular functions (MFs) [false discovery rate (FDR) &lt;0.01], and 62 pathways (FDR &lt;0.01). QZF mainly acts on its targets <i>AKT1, FOS</i>, and <i>APP</i> through active ingredients such as quercetin, ÃŽÂ²-sitosterol, 4-(4'-hydroxybenzyloxy)benzyl methyl ether, harmine, 1,7-dimethoxyxanthone, and 1-hydroxy-3,7-dimethoxyxanthone to regulate serotonin, gamma-aminobutyric acid (GABA), cyclic adenosine monophosphate (cAMP), and other signal pathways to treat PD. Through network pharmacology and molecular docking technology, we predicted the possible mechanism of QZF in the treatment of PD, revealed the interaction targets and potential value of QZF, and provided a basis for its clinical application.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21093,""
"Detection of hypomimia in patients with Parkinson's disease via smile videos","Su, Lin, Yin, Luo, Xu, Xu, Dong","https://doi.org/10.21037/atm-21-3457","20210918","PubMed","ParkinsonÃ¢â‚¬â„¢s hypomimia (PD); detection system; facial expressions; geometric features; texture features","Parkinson's disease (PD) is a neurodegenerative disease characterized by the impairment of facial expression, known as hypomimia. Hypomimia has serious impacts on patients' ability to communicate, and it is difficult to detect at early stages of the disease. Furthermore, due to bradykinesia or other reasons, it is inconvenient for PD patients to visit the hospital. Therefore, it is appealing to develop an auxiliary diagnostic method that remotely detects hypomimia. We proposed an automatic detection system for Parkinson's hypomimia based on facial expressions (DSPH-FE). DSPH-FE provides a convenient remote service for those who potentially suffer from hypomimia and only requires patients to input their facial videos. Specifically, patients can detect hypomimia through two aspects: geometric features and texture features. Geometric features focus on visually representing structures of facial muscles. Facial expression factors (FEFs) are used as the first metric to quantify the current activation state of the facial muscles. Facial expression change factors (FECFs) are subsequently used as the second metric to calculate the moving trajectories of the activation states in the videos. Geometric features primarily concentrate on spatial information, with little involvement of temporal information. Thus, the extended histogram of oriented gradients (HOG) algorithm is introduced. This algorithm can extract texture features within multiple continuous frames and incorporate the temporal information into the features. Finally, these features are applied to four machine learning algorithms to model the relationship between these features and hypomimia. The DSPH-FE detection system achieved the best performance when concatenating geometric features and texture features, resulting in a F1 score of 0.9997. The best F1 scores achieved with geometric features and texture features were 0.8286 and 0.9446, respectively. This indicated that both geometric features and texture features have an ability to predict hypomimia, and demonstrated that temporal information can boost the model performance. Thus, DSPH-FE is an effective supportive tool in the medical management of PD patients. Comprehensive experiments demonstrated that proposed features fit well with real-world videos and are beneficial in the clinical diagnosis of hypomimia. In particular, hypomimia had a greater impact on eyes and mouths when patients are smiling.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21094,""
"Early outcome detection for COVID-19 patients","SÃƒÂ®rbu, Barbieri, Faita, Ferragina, Gargani, Ghiadoni, Priami","https://doi.org/10.1038/s41598-021-97990-1","20210927","PubMed","Algorithms; COVID-19; Cohort Studies; Decision Support Systems, Clinical; Humans; Machine Learning; Models, Theoretical; Mortality","With the outbreak of COVID-19 exerting a strong pressure on hospitals and health facilities, clinical decision support systems based on predictive models can help to effectively improve the management of the pandemic. We present a method for predicting mortality for COVID-19 patients. Starting from a large number of clinical variables, we select six of them with largest predictive power, using a feature selection method based on genetic algorithms and starting from a set of COVID-19 patients from the first wave. The algorithm is designed to reduce the impact of missing values in the set of variables measured, and consider only variables that show good accuracy on validation data. The final predictive model provides accuracy larger than 85% on test data, including a new patient cohort from the second COVID-19 wave, and on patients with imputed missing values. The selected clinical variables are confirmed to be relevant by recent literature on COVID-19.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21095,""
"A Combined Radiomics and Machine Learning Approach to Overcome the Clinicoradiologic Paradox in Multiple Sclerosis","Pontillo, Tommasin, Cuocolo, Petracca, Petsas, Ugga, Carotenuto, Pozzilli, Iodice, Lanzillo, Quarantelli, Brescia Morra, Tedeschi, Pantano, Cocozza","https://doi.org/10.3174/ajnr.A7274","20210917","PubMed","","Conventional MR imaging explains only a fraction of the clinical outcome variance in multiple sclerosis. We aimed to evaluate machine learning models for disability prediction on the basis of radiomic, volumetric, and connectivity features derived from routine brain MR images. In this retrospective cross-sectional study, 3T brain MR imaging studies of patients with multiple sclerosis, including 3D T1-weighted and T2-weighted FLAIR sequences, were selected from 2 institutions. T1-weighted images were processed to obtain volume, connectivity score (inferred from the T2 lesion location), and texture features for an atlas-based set of GM regions. The site 1 cohort was randomly split into training (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°400) and test (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°100) sets, while the site 2 cohort (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°104) constituted the external test set. After feature selection of clinicodemographic and MR imaging-derived variables, different machine learning algorithms predicting disability as measured with the Expanded Disability Status Scale were trained and cross-validated on the training cohort and evaluated on the test sets. The effect of different algorithms on model performance was tested using the 1-way repeated-measures ANOVA. The selection procedure identified the 9 most informative variables, including age and secondary-progressive course and a subset of radiomic features extracted from the prefrontal cortex, subcortical GM, and cerebellum. The machine learning models predicted disability with high accuracy (<i>r</i> approaching 0.80) and excellent intra- and intersite generalizability (<i>rÃ¢â‚¬â€°</i>Ã¢â€°Â¥<i>Ã¢â‚¬â€°</i>0.73). The machine learning algorithm had no relevant effect on the performance. The multidimensional analysis of brain MR images, including radiomic features and clinicodemographic data, is highly informative of the clinical status of patients with multiple sclerosis, representing a promising approach to bridge the gap between conventional imaging and disability.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21096,""
"Neural network-based left ventricle geometry prediction from CMR images with application in biomechanics","Romaszko, Borowska, Lazarus, Dalton, Berry, Luo, Husmeier, Gao","https://doi.org/10.1016/j.artmed.2021.102140","20211029","PubMed","3D reconstruction; Cardiac Magnetic Resonance Imaging; Cardiac Mechanics; Convolutional neural network; Deep learning; Myocardium; Biomechanical Phenomena; Heart Ventricles; Humans; Magnetic Resonance Imaging; Magnetic Resonance Imaging, Cine; Neural Networks, Computer; Ventricular Function, Left","Combining biomechanical modelling of left ventricular (LV) function and dysfunction with cardiac magnetic resonance (CMR) imaging has the potential to improve the prognosis of patient-specific cardiovascular disease risks. Biomechanical studies of LV function in three dimensions usually rely on a computerized representation of the LV geometry based on finite element discretization, which is essential for numerically simulating in vivo cardiac dynamics. Detailed knowledge of the LV geometry is also relevant for various other clinical applications, such as assessing the LV cavity volume and wall thickness. Accurately and automatically reconstructing personalized LV geometries from conventional CMR images with minimal manual intervention is still a challenging task, which is a pre-requisite for any subsequent automated biomechanical analysis. We propose a deep learning-based automatic pipeline for predicting the three-dimensional LV geometry directly from routinely-available CMR cine images, without the need to manually annotate the ventricular wall. Our framework takes advantage of a low-dimensional representation of the high-dimensional LV geometry based on principal component analysis. We analyze how the inference of myocardial passive stiffness is affected by using our automatically generated LV geometries instead of manually generated ones. These insights will inform the development of statistical emulators of LV dynamics to avoid computationally expensive biomechanical simulations. Our proposed framework enables accurate LV geometry reconstruction, outperforming previous approaches by delivering a reconstruction error 50% lower than reported in the literature. We further demonstrate that for a nonlinear cardiac mechanics model, using our reconstructed LV geometries instead of manually extracted ones only moderately affects the inference of passive myocardial stiffness described by an anisotropic hyperelastic constitutive law. The developed methodological framework has the potential to make an important step towards personalized medicine by eliminating the need for time consuming and costly manual operations. In addition, our method automatically maps the CMR scan into a low-dimensional representation of the LV geometry, which constitutes an important stepping stone towards the development of an LV geometry-heterogeneous emulator.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21097,""
"Identifying digenic disease genes via machine learning in the Undiagnosed Diseases Network","Mukherjee, Cogan, Newman, Phillips, Hamid, Meiler, Capra","https://doi.org/10.1016/j.ajhg.2021.08.010","20211102","PubMed","UDN; Undiagnosed Diseases Network; clinical prediction; digenic disease; machine learning; oligogenic disease; rare disease","Rare diseases affect millions of people worldwide, and discovering their genetic causes is challenging. More than half of the individuals analyzed by the Undiagnosed Diseases Network (UDN) remain undiagnosed. The central hypothesis of this work is that many of these rare genetic disorders are caused by multiple variants in more than one gene. However, given the large number of variants in each individual genome, experimentally evaluating combinations of variants for potential to cause disease is currently infeasible. To address this challenge, we developed the digenic predictor (DiGePred), a random forest classifier for identifying candidate digenic disease gene pairs by features derived from biological networks, genomics, evolutionary history, and functional annotations. We trained the DiGePred classifier by using DIDA, the largest available database of known digenic-disease-causing gene pairs, and several sets of non-digenic gene pairs, including variant pairs derived from unaffected relatives of UDN individuals. DiGePred achieved high precision and recall in cross-validation and on a held-out test set (PR area under the curve &gt; 77%), and we further demonstrate its utility by using digenic pairs from the recent literature. In contrast to other approaches, DiGePred also appropriately controls the number of false positives when applied in realistic clinical settings. Finally, to enable the rapid screening of variant gene pairs for digenic disease potential, we freely provide the predictions of DiGePred on all human gene pairs. Our work enables the discovery of genetic causes for rare non-monogenic diseases by providing a means to rapidly evaluate variant gene pairs for the potential to cause digenic disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21098,""
"Systematic reviews: current perspectives and future directions","Misra, Ravindran","https://doi.org/10.4997/JRCPE.2021.303","20211021","PubMed","PICO; PRISMA; PROSPERO; artificial intelligence; crowd sourcing; meta-analysis; review protocol; Forecasting; Humans; Systematic Reviews as Topic","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21099,""
"Application of Artificial Intelligence in Acute Coronary Syndrome: A Brief Literature Review","Wang, Zu, Chen, Yang, Ahmed","https://doi.org/10.1007/s12325-021-01908-2","20211011","PubMed","Acute coronary syndrome; Artificial intelligence; Machine learning; Major adverse cardiac events; Mortality; Myocardial infarction; Percutaneous coronary intervention; Acute Coronary Syndrome; Algorithms; Artificial Intelligence; Delivery of Health Care; Humans; Machine Learning","Artificial intelligence (AI) is defined as a set of algorithms and intelligence to try to imitate human intelligence. Machine learning is one of them, and deep learning is one of those machine learning techniques. The application of AI in healthcare systems including hospitals and clinics has many possible advantages and future prospects. Applications of AI in cardiovascular medicine are machine learning techniques for diagnostic procedures including imaging modalities and biomarkers and predictive analytics for personalized therapies and improved outcomes. In cardiovascular medicine, AI-based systems have found new applications in risk prediction for cardiovascular diseases, in cardiovascular imaging, in predicting outcomes after revascularization procedures, and in newer drug targets. AI such as machine learning has partially resolved and provided possible solutions to unmet requirements in interventional cardiology. Predicting economically vital endpoints, predictive models with a wide range of health factors including comorbidities, socioeconomic factors, and angiographic factors comprising of the size of stents, the volume of contrast agent which was infused during angiography, stent malposition, and so on have been possible owing to machine learning and AI. Nowadays, machine learning techniques might possibly help in the identification of patients at risk, with higher morbidity and mortality following acute coronary syndrome (ACS). AI through machine learning has shown several potential benefits in patients with ACS. From diagnosis to treatment effects to predicting adverse events and mortality in patients with ACS, machine learning should find an essential place in clinical medicine and in interventional cardiology for the treatment and management of patients with ACS. This paper is a review of the literature which will focus on the application of AI in ACS.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21100,""
"Case Report and Literature Review: Primary Pulmonary NUT-Midline Carcinoma","Zhang, Han, Dong, Hou, Li, Li, Zhou, Liu, Zhao, Li","https://doi.org/10.3389/fonc.2021.700781","20210917","PubMed","NUT-midline carcinoma (NMC); bromodomain-containing protein 4 (BRAD4); genomic analysis; lung; nuclear protein of the testis (NUT)","Nuclear protein of the testis (NUT) carcinoma is a very rare and aggressive carcinoma characterized by chromosomal rearrangement. NUT-midline carcinoma (NMC) can occur anywhere in the body, but most of the tumors are found in the midline anatomic structure or mediastinum. Pulmonary-originated NMC is extremely rare and often difficult to be distinguished from other poorly differentiated tumors, making the diagnosis awfully challenged in clinical practice. There are less than 100 cases of NUT carcinoma reported so far. In this study, the diagnosis and molecular mechanisms of reported NUT carcinoma cases were reviewed. Furthermore, a case of primary pulmonary NUT-midline carcinoma and its pathological features was reported. The process of pathological identification and genomic analysis for establishing the diagnosis was discussed. We found that NUT carcinoma could be identified by combining CT, H&amp;E staining, immunohistochemistry (IHC), and molecular tests. The development of NUT carcinoma might be associated with mutation of <i>MYC</i>, <i>p63</i>, and <i>MED24</i> genes and the Wnt, MAPK, and PI3K signaling pathways. Our study provided a detailed molecular mechanistic review on NMC and established a procedure to identify pulmonary NMC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21101,""
"A systematic review and meta-analysis of diagnostic performance and physicians' perceptions of artificial intelligence (AI)-assisted CT diagnostic technology for the classification of pulmonary nodules","Huang, Wei, Tang, Bai, Lin, Xue","https://doi.org/10.21037/jtd-21-810","20210917","PubMed","CT image; Diagnostic performance; artificial intelligence (AI); lung cancer; pulmonary nodules","Lung cancer was the second most commonly diagnosed cancer and the leading cause of cancer death in 2020. Although artificial intelligence (AI)-assisted diagnostic technologies have shown promise and has been used in clinical practice in recent years, no products related to AI-assisted CT diagnostic technologies for the classification of pulmonary nodules have been approved by the National Medical Products Administration in China. The objective of this article was to systematically review the diagnostic performance of AI-assisted CT diagnostic technology for the classification of pulmonary nodules as benign or malignant and to analyze physicians' perceptions of this technology in China. All relevant studies from 6 literature databases were searched and screened according to the inclusion and exclusion criteria. Data were extracted and the study quality was assessed by two reviewers. The study heterogeneity and publication bias were estimated. A questionnaire survey on the perceptions of physicians was conducted in 9 public tertiary hospitals in China. A meta-analysis, meta-regression and univariate logistic model were used in the systematic review and to explore the association of physicians' perceptions with their rate of support for the clinical application of the technology. Twenty-seven studies with 5,727 pulmonary nodules were finally included in the meta-analysis. We found that the quality of the included studies was generally acceptable and that the pooled sensitivity and specificity of AI-assisted CT diagnostic technology for the classification of pulmonary nodules as benign or malignant were 0.90 and 0.89, respectively. The pooled diagnostic odds ratio (DOR) was 70.33. The majority of the surveyed physicians in China perceived ""reduced workload for radiologists"" and ""improved diagnostic efficiency"" as the important benefits of this technology. In addition, diagnostic accuracy (including misdiagnosis) and practical experience were significantly associated with whether physicians supported its clinical application. In the context of lung cancer diagnosis, AI-assisted CT diagnostic technology for the classification of pulmonary nodules as benign or malignant has good diagnostic performance, but its specificity needs to be improved.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21102,""
"A deep transfer learning approach for wearable sleep stage classification with photoplethysmography","Radha, Fonseca, Moreau, Ross, Cerny, Anderer, Long, Aarts","https://doi.org/10.1038/s41746-021-00510-8","20211005","PubMed","","Unobtrusive home sleep monitoring using wrist-worn wearable photoplethysmography (PPG) could open the way for better sleep disorder screening and health monitoring. However, PPG is rarely included in large sleep studies with gold-standard sleep annotation from polysomnography. Therefore, training data-intensive state-of-the-art deep neural networks is challenging. In this work a deep recurrent neural network is first trained using a large sleep data set with electrocardiogram (ECG) data (292 participants, 584 recordings) to perform 4-class sleep stage classification (wake, rapid-eye-movement, N1/N2, and N3). A small part of its weights is adapted to a smaller, newer PPG data set (60 healthy participants, 101 recordings) through three variations of transfer learning. Best results (Cohen's kappa of 0.65Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°0.11, accuracy of 76.36Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°7.57%) were achieved with the domain and decision combined transfer learning strategy, significantly outperforming the PPG-trained and ECG-trained baselines. This performance for PPG-based 4-class sleep stage classification is unprecedented in literature, bringing home sleep stage monitoring closer to clinical use. The work demonstrates the merit of transfer learning in developing reliable methods for new sensor technologies by reusing similar, older non-wearable data sets. Further study should evaluate our approach in patients with sleep disorders such as insomnia and sleep apnoea.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21103,""
"Data mining and knowledge discovery in databases for urban solid waste management: A scientific literature review","Dias, Sott, FerrÃƒÂ£o, Furtado, Moraes","https://doi.org/10.1177/0734242X211042276","20211014","PubMed","Data mining; digital transformation; knowledge discovery; solid waste management; sustainability; Data Mining; Databases, Factual; Knowledge Discovery; Solid Waste; Waste Management","The processes related to solid waste management (SWM) are being revised as new technologies emerge and are applied in the area to achieve greater environmental, social and economic sustainability for society. To achieve our goal, two robust review protocols (Population, Intervention, Comparison, Outcome, and Context (PICOC) and Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA)) were used to systematically analyze 62 documents extracted from the Web of Science database to identify the main techniques and tools for Knowledge Discovery in Databases (KDD) and Data Mining (DM) as applied to SWM and explore the technological potential to optimize the stages of collecting and transporting waste. Moreover, it was possible to analyze the main challenges and opportunities of KDD and DM for SWM. The results show that the most used tools for SWM are MATLAB (29.7%) and GIS (13.5%), whereas the most used techniques are Artificial Neural Networks (35.8%), Linear Regression (16.0%) and Support Vector Machine (12.3%). In addition, 15.3% of the studies were conducted with data from China, 11.1% from India and 9.7% of the studies analyzed and compared data from several other countries. Furthermore, the research showed that the main challenges in the field of study are related to the collection and treatment of data, whereas the opportunities appear to be linked mainly to the impact on the pillars of sustainable development. Thus, this study portrays important issues associated with the use of KDD and DM for optimal SWM and has the potential to assist and direct researchers and field professionals in future studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21104,""
"A deep learning approach for synthetic MRI based on two routine sequences and training with synthetic data","Moya-SÃƒÂ¡ez, PeÃƒÂ±a-Nogales, Luis-GarcÃƒÂ­a, Alberola-LÃƒÂ³pez","https://doi.org/10.1016/j.cmpb.2021.106371","20210928","PubMed","Deep learning; Parametric Maps; Quantitative MRI; Synthetic MRI; Brain; Deep Learning; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer","Synthetic magnetic resonance imaging (MRI) is a low cost procedure that serves as a bridge between qualitative and quantitative MRI. However, the proposed methods require very specific sequences or private protocols which have scarcely found integration in clinical scanners. We propose a learning-based approach to compute T1, T2, and PD parametric maps from only a pair of T1- and T2-weighted images customarily acquired in the clinical routine. Our approach is based on a convolutional neural network (CNN) trained with synthetic data; specifically, a synthetic dataset with 120 volumes was constructed from the anatomical brain model of the BrainWeb tool and served as the training set. The CNN learns an end-to-end mapping function to transform the input T1- and T2-weighted images to their underlying T1, T2, and PD parametric maps. Then, conventional weighted images unseen by the network are analytically synthesized from the parametric maps. The network can be fine tuned with a small database of actual weighted images and maps for better performance. This approach is able to accurately compute parametric maps from synthetic brain data achieving normalized squared error values predominantly below 1%. It also yields realistic parametric maps from actual MR brain acquisitions with T1, T2, and PD values in the range of the literature and with correlation values above 0.95 compared to the T1 and T2 maps obtained from relaxometry sequences. Further, the synthesized weighted images are visually realistic; the mean square error values are always below 9% and the structural similarity index is usually above 0.90. Network fine tuning with actual maps improves performance, while training exclusively with a small database of actual maps shows a performance degradation. These results show that our approach is able to provide realistic parametric maps and weighted images out of a CNN that (a) is trained with a synthetic dataset and (b) needs only two inputs, which are in turn obtained from a common full-brain acquisition that takes less than 8Ã‚Â min of scan time. Although a fine tuning with actual maps improves performance, synthetic data is crucial to reach acceptable performance levels. Hence, we show the utility of our approach for both quantitative MRI in clinical viable times and for the synthesis of additional weighted images to those actually acquired.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21105,""
"Artificial Intelligence in the Assessment of Female Reproductive Function Using Ultrasound: A Review","Chen, Wang, Du, Liu","https://doi.org/10.1002/jum.15827","20210915","PubMed","artificial intelligence; endometrial receptivity; infertility; ovarian response; ultrasound","The incidence of infertility is continuously increasing nearly all over the world in recent years, and novel methods for accurate assessment are of great need. Artificial Intelligence (AI) has gradually become an effective supplementary method for the assessment of female reproductive function. It has been used in clinical follicular monitoring, optimum timing for transplantation, and prediction of pregnancy outcome. Some literatures summarize the use of AI in this field, but few of them focus on the assessment of female reproductive function by AI-aided ultrasound. In this review, we mainly discussed the applicability, feasibility, and value of clinical application of AI in ultrasound to monitor follicles, assess endometrial receptivity, and predict the pregnancy outcome of in vitro fertilization and embryo transfer (IVF-ET). The limitations, challenges, and future trends of ultrasound combined with AI in providing efficient and individualized evaluation of female reproductive function had also been mentioned.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21106,""
"Distantly supervised biomedical relation extraction using piecewise attentive convolutional neural network and reinforcement learning","Zhu, Qin, Xiang, Hu, Chen, Peng","https://doi.org/10.1093/jamia/ocab176","20210915","PubMed","biomedical relation extraction; deep learning; distant supervision; neural networks; reinforcement learning","There have been various methods to deal with the erroneous training data in distantly supervised relation extraction (RE), however, their performance is still far from satisfaction. We aimed to deal with the insufficient modeling problem on instance-label correlations for predicting biomedical relations using deep learning and reinforcement learning. In this study, a new computational model called piecewise attentive convolutional neural network and reinforcement learning (PACNN+RL) was proposed to perform RE on distantly supervised data generated from Unified Medical Language System with MEDLINE abstracts and benchmark datasets. In PACNN+RL, PACNN was introduced to encode semantic information of biomedical text, and the RL method with memory backtracking mechanism was leveraged to alleviate the erroneous data issue. Extensive experiments were conducted on 4 biomedical RE tasks. The proposed PACNN+RL model achieved competitive performance on 8 biomedical corpora, outperforming most baseline systems. Specifically, PACNN+RL outperformed all baseline methods with the F1-score of 0.5592 on the may-prevent dataset, 0.6666 on the may-treat dataset, and 0.3838 on the DDI corpus, 2011. For the protein-protein interaction RE task, we obtained new state-of-the-art performance on 4 out of 5 benchmark datasets. The performance on many distantly supervised biomedical RE tasks was substantially improved, primarily owing to the denoising effect of the proposed model. It is anticipated that PACNN+RL will become a useful tool for large-scale RE and other downstream tasks to facilitate biomedical knowledge acquisition. We also made the demonstration program and source code publicly available at http://112.74.48.115:9000/.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21107,""
"Automated Monitoring of Suicidal Adolescents' Digital Media Use: Qualitative Study Exploring Acceptability Within Clinical Care","Biernesser, Zelazny, Brent, Bear, Mair, Trauth","https://doi.org/10.2196/26031","20210916","PubMed","adolescents; digital media; implementation in clinical care; monitoring; natural language processing; parents; qualitative; social media; suicide prevention; technology","Monitoring linguistic cues from adolescents' digital media use (DMU; ie, digital content transmitted on the web, such as through text messages or social media) that could denote suicidal risk offers a unique opportunity to protect adolescents vulnerable to suicide, the second leading cause of death among youth. Adolescents communicate through digital media in high volumes and frequently express emotionality. In fact, web-based disclosures of suicidality are more common than in-person disclosures. The use of automated methods of digital media monitoring triggered by a natural language processing algorithm offers the potential to detect suicidal risk from subtle linguistic units (eg, negatively valanced words, phrases, or emoticons known to be associated with suicidality) present within adolescents' digital media content and to use this information to respond to alerts of suicidal risk. Critical to the implementation of such an approach is the consideration of its acceptability in the clinical care of adolescents at high risk of suicide. Through data collection among recently suicidal adolescents, parents, and clinicians, this study examines the current context of digital media monitoring for suicidal adolescents seeking clinical care to inform the need for automated monitoring and the factors that influence the acceptance of automated monitoring of suicidal adolescents' DMU within clinical care. A total of 15 recently suicidal adolescents (aged 13-17 years), 12 parents, and 10 clinicians participated in focus groups, qualitative interviews, and a group discussion, respectively. Data were recorded, transcribed, and analyzed using thematic analysis. Participants described important challenges to the current strategies for monitoring the DMU of suicidal youth. They felt that automated monitoring would have advantages over current monitoring approaches, namely, by protecting web-based environments and aiding adolescent disclosure and support seeking about web-based suicidal risk communication, which may otherwise go unnoticed. However, they identified barriers that could impede implementation within clinical care, namely, adolescents' and parents' concerns about unintended consequences of automated monitoring, that is, the potential for loss of privacy or false alerts, and clinicians' concerns about liability to respond to alerts of suicidal risk. On the basis of the needs and preferences of adolescents, parents, and clinicians, a model for automated digital media monitoring is presented that aims to optimize acceptability within clinical care for suicidal youth. Automated digital media monitoring offers a promising means to augment detection and response to suicidal risk within the clinical care of suicidal youth when strategies that address the preferences of adolescents, parents, and clinicians are in place.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21108,""
"Artificial Learning and Machine Learning Decision Guidance Applications in Total Hip and Knee Arthroplasty: A Systematic Review","Lopez, Gazgalis, Boddapati, Shah, Cooper, Geller","https://doi.org/10.1016/j.artd.2021.07.012","20210916","PubMed","Artificial intelligence; Artificial neural networks; Deep learning; Hip and knee arthroplasty; Machine learning; Orthopedic surgery","Artificial intelligence (AI) and machine learning (ML) modeling in hip and knee arthroplasty (total joint arthroplasty [TJA]) is becoming more commonplace. This systematic review aims to quantify the accuracy of current AI- and ML-based application for cognitive support and decision-making in TJA. A comprehensive search of publications was conducted through the EMBASE, Medline, and PubMed databases using relevant keywords to maximize the sensitivity of the search. No limits were placed on level of evidence or timing of the study. Findings were reported according to the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Analysis of variance testing with post-hoc Tukey test was applied to compare the area under the curve (AUC) of the models. After application of inclusion and exclusion criteria, 49 studies were included in this review. The application of AI/ML-based models and average AUC is as follows: cost prediction-0.77, LOS and discharges-0.78, readmissions and reoperations-0.66, preoperative patient selection/planning-0.79, adverse events and other postoperative complications-0.84, postoperative pain-0.83, postoperative patient-reported outcomes measures and functional outcome-0.81. Significant variability in model AUC across the different decision support applications was found (<i>P</i> &lt; .001) with the AUC for readmission and reoperation models being significantly lower than that of the other decision support categories. AI/ML-based applications in TJA continue to expand and have the potential to optimize patient selection and accurately predict postoperative outcomes, complications, and associated costs. On average, the AI/ML models performed best in predicting postoperative complications, pain, and patient-reported outcomes and were less accurate in predicting hospital readmissions and reoperations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21109,""
"Artificial intelligence to diagnose ear disease using otoscopic image analysis: a review","Canares, Wang, Unberath, Clark","https://doi.org/10.1136/jim-2021-001870","20210915","PubMed","diagnostic tests; ear; external; routine","AI relates broadly to the science of developing computer systems to imitate human intelligence, thus allowing for the automation of tasks that would otherwise necessitate human cognition. Such technology has increasingly demonstrated capacity to outperform humans for functions relating to image recognition. Given the current lack of cost-effective confirmatory testing, accurate diagnosis and subsequent management depend on visual detection of characteristic findings during otoscope examination. The aim of this manuscript is to perform a comprehensive literature review and evaluate the potential application of artificial intelligence for the diagnosis of ear disease from otoscopic image analysis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21110,""
"Predicting the risk of cancer in adults using supervised machine learning: a scoping review","Abdullah Alfayez, Kunz, Grace Lai","https://doi.org/10.1136/bmjopen-2020-047755","20211020","PubMed","health informatics; information technology; oncology; Adult; Calibration; Humans; Machine Learning; Neoplasms; Risk Factors; Supervised Machine Learning","The purpose of this scoping review is to: (1) identify existing supervised machine learning (ML) approaches on the prediction of cancer in asymptomatic adults; (2) to compare the performance of ML models with each other and (3) to identify potential gaps in research. Scoping review using the population, concept and context approach. PubMed search engine was used from inception to 10 November 2020 to identify literature meeting following inclusion criteria: (1) a general adult (Ã¢â€°Â¥18 years) population, either sex, asymptomatic (population); (2) any study using ML techniques to derive predictive models for future cancer risk using clinical and/or demographic and/or basic laboratory data (concept) and (3) original research articles conducted in all settings in any region of the world (context). The search returned 627 unique articles, of which 580 articles were excluded because they did not meet the inclusion criteria, were duplicates or were related to benign neoplasm. Full-text reviews were conducted for 47 articles and a final set of 10 articles were included in this scoping review. These 10 very heterogeneous studies used ML to predict future cancer risk in asymptomatic individuals. All studies reported area under the receiver operating characteristics curve (AUC) values as metrics of model performance, but no study reported measures of model calibration. Research gaps that must be addressed in order to deliver validated ML-based models to assist clinical decision-making include: (1) establishing model generalisability through validation in independent cohorts, including those from low-income and middle-income countries; (2) establishing models for all cancer types; (3) thorough comparisons of ML models with best available clinical tools to ensure transparency of their potential clinical utility; (4) reporting of model calibration performance and (5) comparisons of different methods on the same cohort to reveal important information about model generalisability and performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21111,""
"Exploiting ICD Hierarchy for Classification of EHRs in Spanish through multi-task Transformers","Blanco, Perez, Casillas","https://doi.org/10.1109/JBHI.2021.3112130","20210914","PubMed","","Electronic Health Records (EHRs) convey valuable information. Experts in clinical documentation read the report, understand the antecedents, procedures, tests carried out, and encode the EHRs according to the International Classification of Diseases (ICD). Assigning these codes to the EHRs helps to share information, and extract statistics. In this paper, we explore computer-aided multi-label classification approaches. While Natural Language Understanding has evolved for clinical text mining, there is still a gap for languages other than English. Language-modeling aware Transformers has demonstrated state of the art approaches through exploiting contextual dependencies. Here we focus on EHRs written in Spanish, and try to benefit from the Language Model itself, with unannotated corpus with less data but in-house, in-domain and closely-related EHRs to that of the downstream task. The International Classification of Diseases coding scheme is hierarchical, but its synergies among hierarchical levels are rarely exploited. In this work, we implement and release a hierarchical head for multi-label classification, which benefits from the hierarchy of the ICD via multi-task classification.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21112,""
"Predicting clinical outcomes in COVID-19 using radiomics on chest radiographs","Varghese, Shin, Desai, Gholamrezanezhad, Lei, Perkins, Oberai, Nanda, Cen, Duddalwar","https://doi.org/10.1259/bjr.20210221","20210923","PubMed","Adult; Aged; COVID-19; Critical Care; Early Diagnosis; Female; Health Services Needs and Demand; Humans; Machine Learning; Male; Middle Aged; Pneumonia, Viral; Predictive Value of Tests; Prognosis; Radiography, Thoracic; Respiration, Artificial; Retrospective Studies; SARS-CoV-2","For optimal utilization of healthcare resources, there is a critical need for early identification of COVID-19 patients at risk of poor prognosis as defined by the need for intensive unit care and mechanical ventilation. We tested the feasibility of chest X-ray (CXR)-based radiomics metrics to develop machine-learning algorithms for predicting patients with poor outcomes. In this Institutional Review Board (IRB) approved, Health Insurance Portability and Accountability Act (HIPAA) compliant, retrospective study, we evaluated CXRs performed around the time of admission from 167 COVID-19 patients. Of the 167 patients, 68 (40.72%) required intensive care during their stay, 45 (26.95%) required intubation, and 25 (14.97%) died. Lung opacities were manually segmented using ITK-SNAP (open-source software). CaPTk (open-source software) was used to perform 2D radiomics analysis. Of all the algorithms considered, the AdaBoost classifier performed the best with AUC = 0.72Ã¢â‚¬â€°to predict the need for intubation, AUC = 0.71Ã¢â‚¬â€°to predict death, and AUC = 0.61Ã¢â‚¬â€°to predict the need for admission to the intensive care unit (ICU). AdaBoost had similar performance with ElasticNet in predicting the need for admission to ICU. Analysis of the key radiomic metrics that drive model prediction and performance showed the importance of first-order texture metrics compared to other radiomics panel metrics. Using a Venn-diagram analysis, two first-order texture metrics and one second-order texture metric that consistently played an important role in driving model performance in all three outcome predictions were identified. Considering the quantitative nature and reliability of radiomic metrics, they can be used prospectively as prognostic markers to individualize treatment plans for COVID-19 patients and also assist with healthcare resource management. We report on the performance of CXR-based imaging metrics extracted from RT-PCR positive COVID-19 patients at admission to develop machine-learning algorithms for predicting the need for ICU, the need for intubation, and mortality, respectively.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21113,""
"Promoting Physical Activity Through Conversational Agents: Mixed Methods Systematic Review","Luo, Aguilera, Lyles, Figueroa","https://doi.org/10.2196/25486","20211028","PubMed","behavior change; chatbot; conversational agent; digital health; eHealth; health behavior; mHealth; mobile health; mobile phone; physical activity; virtual agent; Communication; Computers, Handheld; Delivery of Health Care; Exercise; Humans; Natural Language Processing","Regular physical activity (PA) is crucial for well-being; however, healthy habits are difficult to create and maintain. Interventions delivered via conversational agents (eg, chatbots or virtual agents) are a novel and potentially accessible way to promote PA. Thus, it is important to understand the evolving landscape of research that uses conversational agents. This mixed methods systematic review aims to summarize the usability and effectiveness of conversational agents in promoting PA, describe common theories and intervention components used, and identify areas for further development. We conducted a mixed methods systematic review. We searched seven electronic databases (PsycINFO, PubMed, Embase, CINAHL, ACM Digital Library, Scopus, and Web of Science) for quantitative, qualitative, and mixed methods studies that conveyed primary research on automated conversational agents designed to increase PA. The studies were independently screened, and their methodological quality was assessed using the Mixed Methods Appraisal Tool by 2 reviewers. Data on intervention impact and effectiveness, treatment characteristics, and challenges were extracted and analyzed using parallel-results convergent synthesis and narrative summary. In total, 255 studies were identified, 7.8% (20) of which met our inclusion criteria. The methodological quality of the studies was varied. Overall, conversational agents had moderate usability and feasibility. Those that were evaluated through randomized controlled trials were found to be effective in promoting PA. Common challenges facing interventions were repetitive program content, high attrition, technical issues, and safety and privacy concerns. Conversational agents hold promise for PA interventions. However, there is a lack of rigorous research on long-term intervention effectiveness and patient safety. Future interventions should be based on evidence-informed theories and treatment approaches and should address users' desires for program variety, natural language processing, delivery via mobile devices, and safety and privacy concerns.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21114,""
"Automatic detection of depression symptoms in twitter using multimodal analysis","Safa, Bayat, Moghtader","https://doi.org/10.1007/s11227-021-04040-8","20210915","PubMed","Depression detection; Mental health; Multimodal framework; Social media; Text mining","Depression is the most prevalent mental disorder that can lead to suicide. Due to the tendency of people to share their thoughts on social platforms, social data contain valuable information that can be used to identify user's psychological states. In this paper, we provide an automated approach to collect and evaluate tweets based on self-reported statements and present a novel multimodal framework to predict depression symptoms from user profiles. We used n-gram language models, LIWC dictionaries, automatic image tagging, and bag-of-visual-words. We consider the correlation-based feature selection and nine different classifiers with standard evaluation metrics to assess the effectiveness of the method. Based on the analysis, the tweets and bio-text alone showed 91% and 83% accuracy in predicting depressive symptoms, respectively, which seems to be an acceptable result. We also believe performance improvements can be achieved by limiting the user domain or presence of clinical information.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21115,""
"Clinical prediction models for hospital falls: a scoping review protocol","Parsons, Cramb, McPhail","https://doi.org/10.1136/bmjopen-2021-051047","20211102","PubMed","geriatric medicine; health &amp; safety; health informatics; quality in health care; risk management; Hospitals; Humans; Models, Statistical; Peer Review; Prognosis; Research Design; Review Literature as Topic; Systematic Reviews as Topic","Falls remain one of the most prevalent adverse events in hospitals and are associated with substantial negative health impacts and costs. Approaches to assess patients' fall risk have been implemented in hospitals internationally, ranging from brief screening questions to multifactorial risk assessments and complex prediction models, despite a lack of clear evidence of effect in reducing falls in acute hospital environments. The increasing digitisation of hospital systems provides new opportunities to understand and predict falls using routinely recorded data, with potential to integrate fall prediction models into real-time or near-real-time computerised decision support for clinical teams seeking to mitigate fall risk. However, the use of non-traditional approaches to fall risk prediction, including machine learning using integrated electronic medical records, has not yet been reviewed relative to more traditional fall prediction models. This scoping review will summarise methodologies used to develop existing hospital fall prediction models, including reporting quality assessment. This scoping review will follow the Arksey and O'Malley framework and its recent advances, and will be reported using Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews recommendations. Four electronic databases (CINAHL via EBSCOhost, PubMed, IEEE Xplore and Embase) will be initially searched for studies up to 12 November 2020, and searches may be updated prior to final reporting. Additional studies will be identified by reference list review and citation analysis of included studies. No restriction will be placed on the date or language of identified studies. Screening of search results and extraction of data will be performed by two independent reviewers. Reporting quality will be assessed by the adherence to the Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis. Ethical approval is not required for this study. Findings will be disseminated through peer-reviewed publication and scientific conferences.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21116,""
"Optical Properties and Color Stability of Denture Teeth-A Systematic Review","Tieh, Waddell, Choi","https://doi.org/10.1111/jopr.13429","20210925","PubMed","Color change; color stability; denture teeth; optical properties; systematic review","To systematically review past studies to determine the effect of various solutions on the color of denture teeth, thus answering the question in regards to which type of denture teeth has the best optical properties after exposure to various solutions. The method of measuring the color of artificial teeth was also evaluated as a secondary outcome. A search of studies that quantitatively investigated the influence of immersion solutions on the color change of denture teeth was conducted. Ovid MEDLINE, PubMed and Scopus databases were searched from 1997 to April 2021. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines were used during article selection. Data regarding the effect of immersion solutions, accelerated aging and surface treatments on color change were gathered. Methodologies used to assess optical properties were also summarized and compared. The modified CONSORT checklist was used to determine the risk of bias of past studied included in this review. One hundred thirty-three studies were identified after removing duplicates. Forty-one studies were selected for full-text analysis, and 35 remaining papers met the inclusion criteria and were therefore included in this systematic review. Thirty-two in vitro studies and 3 in vivo studies were included in the review. All studies reported that immersion in various solutions has a significant influence on the change in color and optical properties of denture teeth. However, the discoloration of denture teeth is still clinically acceptable in most studies. Exposure to various solutions also affected the translucency parameter of denture teeth. Most studies also investigated the surface roughness and hardness along with the optical properties, and reported that immersion cycles did not cause changes in surface roughness of denture teeth, while hardness was affected. The optical properties of PMMA denture teeth have been studied extensively, whereas that of CAD/CAM and 3D printed denture teeth is limited. Color stability of CAD/CAM milled denture teeth is comparable to conventional PMMA denture teeth. There are contradictory findings in terms of color stability of 3D printed denture teeth as compared to conventional PMMA denture teeth. Staining by coffee is worst among the common beverages and solutions investigated. Denture teeth can show color changes after immersion in staining beverages as early as one week. The degree of discoloration of denture teeth after immersion is time dependent, with the larger extent in the initial phase.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21117,""
"Predicting the Mortality and Readmission of In-Hospital Cardiac Arrest Patients With Electronic Health Records: A Machine Learning Approach","Chi, Ao, Winkler, Fu, Xu, Ho, Huang, Soltani","https://doi.org/10.2196/27798","20211028","PubMed","30-day mortality; 30-day readmission; imbalanced dataset; in-hospital cardiac arrest; machine learning; Electronic Health Records; Heart Arrest; Hospitals; Humans; Machine Learning; Patient Readmission","In-hospital cardiac arrest (IHCA) is associated with high mortality and health care costs in the recovery phase. Predicting adverse outcome events, including readmission, improves the chance for appropriate interventions and reduces health care costs. However, studies related to the early prediction of adverse events of IHCA survivors are rare. Therefore, we used a deep learning model for prediction in this study. This study aimed to demonstrate that with the proper data set and learning strategies, we can predict the 30-day mortality and readmission of IHCA survivors based on their historical claims. National Health Insurance Research Database claims data, including 168,693 patients who had experienced IHCA at least once and 1,569,478 clinical records, were obtained to generate a data set for outcome prediction. We predicted the 30-day mortality/readmission after each current record (ALL-mortality/ALL-readmission) and 30-day mortality/readmission after IHCA (cardiac arrest [CA]-mortality/CA-readmission). We developed a hierarchical vectorizer (HVec) deep learning model to extract patients' information and predict mortality and readmission. To embed the textual medical concepts of the clinical records into our deep learning model, we used Text2Node to compute the distributed representations of all medical concept codes as a 128-dimensional vector. Along with the patient's demographic information, our novel HVec model generated embedding vectors to hierarchically describe the health status at the record-level and patient-level. Multitask learning involving two main tasks and auxiliary tasks was proposed. As CA-mortality and CA-readmission were rare, person upsampling of patients with CA and weighting of CA records were used to improve prediction performance. With the multitask learning setting in the model learning process, we achieved an area under the receiver operating characteristic of 0.752 for CA-mortality, 0.711 for ALL-mortality, 0.852 for CA-readmission, and 0.889 for ALL-readmission. The area under the receiver operating characteristic was improved to 0.808 for CA-mortality and 0.862 for CA-readmission after solving the extremely imbalanced issue for CA-mortality/CA-readmission by upsampling and weighting. This study demonstrated the potential of predicting future outcomes for IHCA survivors by machine learning. The results showed that our proposed approach could effectively alleviate data imbalance problems and train a better model for outcome prediction.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21118,""
"Computer Vision for Continuous Bedside Pharmacological Data Extraction: A Novel Application of Artificial Intelligence for Clinical Data Recording and Biomedical Research","Froese, Dian, Batson, Gomez, Sainbhi, Unger, Zeiler","https://doi.org/10.3389/fdata.2021.689358","20210914","PubMed","computer vision; data integration; image modification; opitcal character recognition; system integration","<b>Introduction:</b> As real time data processing is integrated with medical care for traumatic brain injury (TBI) patients, there is a requirement for devices to have digital output. However, there are still many devices that fail to have the required hardware to export real time data into an acceptable digital format or in a continuously updating manner. This is particularly the case for many intravenous pumps and older technological systems. Such accurate and digital real time data integration within TBI care and other fields is critical as we move towards digitizing healthcare information and integrating clinical data streams to improve bedside care. We propose to address this gap in technology by building a system that employs Optical Character Recognition through computer vision, using real time images from a pump monitor to extract the desired real time information. <b>Methods:</b> Using freely available software and readily available technology, we built a script that extracts real time images from a medication pump and then processes them using Optical Character Recognition to create digital text from the image. This text was then transferred to an ICM + real-time monitoring software in parallel with other retrieved physiological data. <b>Results:</b> The prototype that was built works effectively for our device, with source code openly available to interested end-users. However, future work is required for a more universal application of such a system. <b>Conclusion:</b> Advances here can improve medical information collection in the clinical environment, eliminating human error with bedside charting, and aid in data integration for biomedical research where many complex data sets can be seamlessly integrated digitally. Our design demonstrates a simple adaptation of current technology to help with this integration.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21119,""
"Identification of social determinants of health using multi-label classification of electronic health record clinical notes","Stemerman, Arguello, Brice, Krishnamurthy, Houston, Kitzmiller","https://doi.org/10.1093/jamiaopen/ooaa069","20210914","PubMed","electronic health records; machine learning; natural language processing; social determinants of health","Social determinants of health (SDH), key contributors to health, are rarely systematically measured and collected in the electronic health record (EHR). We investigate how to leverage clinical notes using novel applications of multi-label learning (MLL) to classify SDH in mental health and substance use disorder patients who frequent the emergency department. We labeled a gold-standard corpus of EHR clinical note sentences (<i>N</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°4063) with 6 identified SDH-related domains recommended by the Institute of Medicine for inclusion in the EHR. We then trained 5 classification models: linear-Support Vector Machine, K-Nearest Neighbors, Random Forest, XGBoost, and bidirectional Long Short-Term Memory (BI-LSTM). We adopted 5 common evaluation measures: accuracy, average precision-recall (AP), area under the curve receiver operating characteristic (AUC-ROC), Hamming loss, and log loss to compare the performance of different methods for MLL classification using the F1 score as the primary evaluation metric. Our results suggested that, overall, BI-LSTM outperformed the other classification models in terms of AUC-ROC (93.9), AP (0.76), and Hamming loss (0.12). The AUC-ROC values of MLL models of SDH related domains varied between (0.59-1.0). We found that 44.6% of our study population (<i>N</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°1119) had at least one positive documentation of SDH. The proposed approach of training an MLL model on an SDH rich data source can produce a high performing classifier using only unstructured clinical notes. We also provide evidence that model performance is associated with lexical diversity by health professionals and the auto-generation of clinical note sentences to document SDH.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21120,""
"Clinical Risk Factors for Mortality Among Critically Ill Mexican Patients With COVID-19","HernÃƒÂ¡ndez-CÃƒÂ¡rdenas, ChoreÃƒÂ±o-Parra, Torruco-Sotelo, Jurado, Serna-Secundino, Aguilar, GarcÃƒÂ­a-OlazarÃƒÂ¡n, HernÃƒÂ¡ndez-GarcÃƒÂ­a, ChoreÃƒÂ±o-Parra, ZÃƒÂºÃƒÂ±iga, Lugo-Goytia","https://doi.org/10.3389/fmed.2021.699607","20210914","PubMed","ARDS; COVID-19; SARS-CoV-2; mortality; risk factors","Little literature exists about critically ill patients with coronavirus disease 2019 (COVID-19) from Latin America. Here, we aimed to describe the clinical characteristics and mortality risk factors in mechanically ventilated COVID-19 patients from Mexico. For this purpose, we recruited 67 consecutive mechanically ventilated COVID-19 patients which were grouped according to their clinical outcome (survival vs. death). Clinical risk factors for mortality were identified by machine-learning and logistic regression models. The median age of participants was 42 years and 65% were men. The most common comorbidity observed was obesity (49.2%). Fever was the most frequent symptom of illness (88%), followed by dyspnea (84%). Multilobe ground-glass opacities were observed in 76% of patients by thoracic computed tomography (CT) scan. Fifty-two percent of study participants were ventilated in prone position, and 59% required cardiovascular support with norepinephrine. Furthermore, 49% of participants were coinfected with a second pathogen. Two-thirds of COVID-19 patients developed acute kidney injury (AKIN). The mortality of our cohort was 44.7%. AKIN, uric acid, lactate dehydrogenase (LDH), and a longitudinal increase in the ventilatory ratio were associated with mortality. Baseline PaO2/FiO2 values and a longitudinal recovery of lymphocytes were protective factors against mortality. Our study provides reference data about the clinical phenotype and risk factors for mortality in mechanically ventilated Mexican patients with COVID-19.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21121,""
"Measuring the Value of a Practical Text Mining Approach to Identify Patients With Housing Issues in the Free-Text Notes in Electronic Health Record: Findings of a Retrospective Cohort Study","Hatef, Singh Deol, Rouhizadeh, Li, Eibensteiner, Monsen, Bratslaver, Senese, Kharrazi","https://doi.org/10.3389/fpubh.2021.697501","20211025","PubMed","clinical notes; electronic health record; free-text; housing; natural language processing; social determinants of health; Data Mining; Electronic Health Records; Female; Housing; Humans; Retrospective Studies; Social Determinants of Health; United States","<b>Introduction:</b> Despite the growing efforts to standardize coding for social determinants of health (SDOH), they are infrequently captured in electronic health records (EHRs). Most SDOH variables are still captured in the unstructured fields (i.e., free-text) of EHRs. In this study we attempt to evaluate a practical text mining approach (i.e., advanced pattern matching techniques) in identifying phrases referring to housing issues, an important SDOH domain affecting value-based healthcare providers, using EHR of a large multispecialty medical group in the New England region, United States. To present how this approach would help the health systems to address the SDOH challenges of their patients we assess the demographic and clinical characteristics of patients with and without housing issues and briefly look into the patterns of healthcare utilization among the study population and for those with and without housing challenges. <b>Methods:</b> We identified five categories of housing issues [i.e., homelessness current (HC), homelessness history (HH), homelessness addressed (HA), housing instability (HI), and building quality (BQ)] and developed several phrases addressing each one through collaboration with SDOH experts, consulting the literature, and reviewing existing coding standards. We developed pattern-matching algorithms (i.e., advanced regular expressions), and then applied them in the selected EHR. We assessed the text mining approach for recall (sensitivity) and precision (positive predictive value) after comparing the identified phrases with manually annotated free-text for different housing issues. <b>Results:</b> The study dataset included EHR structured data for a total of 20,342 patients and 2,564,344 free-text clinical notes. The mean (SD) age in the study population was 75.96 (7.51). Additionally, 58.78% of the cohort were female. BQ and HI were the most frequent housing issues documented in EHR free-text notes and HH was the least frequent one. The regular expression methodology, when compared to manual annotation, had a high level of precision (positive predictive value) at phrase, note, and patient levels (96.36, 95.00, and 94.44%, respectively) across different categories of housing issues, but the recall (sensitivity) rate was relatively low (30.11, 32.20, and 41.46%, respectively). <b>Conclusion:</b> Results of this study can be used to advance the research in this domain, to assess the potential value of EHR's free-text in identifying patients with a high risk of housing issues, to improve patient care and outcomes, and to eventually mitigate socioeconomic disparities across individuals and communities.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21122,""
"Predicting in-hospital mortality in adult non-traumatic emergency department patients: a retrospective comparison of the Modified Early Warning Score (MEWS) and machine learning approach","Wu, Cheng, Tai, Wang, Huang, Su, Chang","https://doi.org/10.7717/peerj.11988","20210914","PubMed","MEWS; Machine learning; Mortality prediction","A feasible and accurate risk prediction systems for emergency department (ED) patients is urgently required. The Modified Early Warning Score (MEWS) is a wide-used tool to predict clinical outcomes in ED. Literatures showed that machine learning (ML) had better predictability in specific patient population than traditional scoring system. By analyzing a large multicenter dataset, we aim to develop a ML model to predict in-hospital morality of the adult non traumatic ED patients for different time stages, and comparing performance with other ML models and MEWS. A retrospective observational cohort study was conducted in five Taiwan EDs including two tertiary medical centers and three regional hospitals. All consecutively adult (&gt;17 years old) non-traumatic patients admit to ED during a 9-year period (January first, 2008 to December 31th, 2016) were included. Exclusion criteria including patients with (1) out-of-hospital cardiac arrest and (2) discharge against medical advice and transferred to other hospital (3) missing collect variables. The primary outcome was in-hospital mortality and were categorized into 6, 24, 72, 168 hours mortality. MEWS was calculated by systolic blood pressure, pulse rate, respiratory rate, body temperature, and level of consciousness. An ensemble supervised stacking ML model was developed and compared to sensitive and unsensitive Xgboost, Random Forest, and Adaboost. We conducted a performance test and examine both the area under the receiver operating characteristic (AUROC) and the area under the precision and recall curve (AUPRC) as the comparative measures. After excluding 182,001 visits (7.46%), study group was consisted of 24,37,326 ED visits. The dataset was split into 67% training data and 33% test data for ML model development. There was no statistically difference found in the characteristics between two groups. For the prediction of 6, 24, 72, 168 hours in-hospital mortality, the AUROC of MEW and ML mode was 0.897, 0.865, 0.841, 0.816 and 0.939, 0.928, 0.913, 0.902 respectively. The stacking ML model outperform other ML model as well. For the prediction of in-hospital mortality over 48-hours, AUPRC performance of MEWS drop below 0.1, while the AUPRC of ML mode was 0.317 in 6 hours and 0.2150 in 168 hours. For each time frame, ML model achieved statistically significant higher AUROC and AUPRC than MEWS (all <i>P</i>Ã‚Â &lt;Ã‚Â 0.001). Both models showed decreasing prediction ability as time elapse, but there was a trend that the gap of AUROC values between two model increases gradually (<i>P</i>Ã‚Â &lt;Ã‚Â 0.001). Three MEWS thresholds (score &gt;3, &gt;4, and &gt;5) were determined as baselines for comparison, ML mode consistently showed improved or equally performance in sensitivity, PPV, NPV, but not in specific. Stacking ML methods improve predicted in-hospital mortality than MEWS in adult non-traumatic ED patients, especially in the prediction of delayed mortality.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21123,""
"Quantification of scar collagen texture and prediction of scar development via second harmonic generation images and a generative adversarial network","Wang, Liu, Chen, Wang, Chen, Zhu","https://doi.org/10.1364/BOE.431096","20210914","PubMed","","Widely used for medical analysis, the texture of the human scar tissue is characterized by irregular and extensive types. The quantitative detection and analysis of the scar texture as enabled by image analysis technology is of great significance to clinical practice. However, the existing methods remain disadvantaged by various shortcomings, such as the inability to fully extract the features of texture. Hence, the integration of second harmonic generation (SHG) imaging and deep learning algorithm is proposed in this study. Through combination with Tamura texture features, a regression model of the scar texture can be constructed to develop a novel method of computer-aided diagnosis, which can assist clinical diagnosis. Based on wavelet packet transform (WPT) and generative adversarial network (GAN), the model is trained with scar texture images of different ages. Generalized Boosted Regression Trees (GBRT) is also adopted to perform regression analysis. Then, the extracted features are further used to predict the age of scar. The experimental results obtained by our proposed model are better compared to the previously published methods. It thus contributes to the better understanding of the mechanism behind scar development and possibly the further development of SHG for skin analysis and clinic practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21124,""
"A Multistakeholder Approach to the Airport Gate Assignment Problem: Application of Fuzzy Theory for Optimal Performance Indicator Selection","Li, Wu, Liang, Zhang","https://doi.org/10.1155/2021/2675052","20210914","PubMed","Airports; Algorithms; Cluster Analysis; Fuzzy Logic","Airport gate assignment performance indicator selection is a complicated decision-making problem with strong subjectivity and difficulty in measuring the importance of each indicator. A better selection of performance indicators (PIs) can greatly increase the airport overall benefit. We adopt a multicriteria decision-making approach to quantify qualitative PIs and conduct subsequent selection using the fuzzy clustering method. First, we identify 21 commonly used PIs through literature review and survey. Subsequently, the fuzzy analytic hierarchy process technique was employed to obtain the selection criteria weights based on the relative importance of significance, availability, and generalisability. Further, we aggregated the selection criteria weights and experts' score to evaluate each PI for the clustering process. The fuzzy-possibilistic product partition <i>c</i>-means algorithm was applied to divide the PIs into different groups based on the three selection criteria as partitioning features. The cluster with highest weights of the centre was identified as the very high-influence cluster, and 10 PIs were identified as a result. This study revealed that the passenger-oriented objective is the most important performance criterion; however, the relevance of the airport/airline-oriented and robustness-oriented performance objectives was highlighted as well. It also offers a scientific approach to determine the objective functions for future gate assignment research. And, we believe, through slight modifications, this model can be used in other airports, other indicator selection problems, or other scenarios at the same airport to facilitate policy making and real situation practice, hence facilitate the management system for the airport.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21125,""
"Automatic detection of actionable radiology reports using bidirectional encoder representations from transformers","Nakamura, Hanaoka, Nomura, Nakao, Miki, Watadani, Yoshikawa, Hayashi, Abe","https://doi.org/10.1186/s12911-021-01623-6","20210927","PubMed","Actionable finding; Bidirectional encoder representations from transformers (BERT); Deep learning; Natural language processing (NLP); Radiology reports; Humans; Logistic Models; Machine Learning; Natural Language Processing; Radiography; Radiology","It is essential for radiologists to communicate actionable findings to the referring clinicians reliably. Natural language processing (NLP) has been shown to help identify free-text radiology reports including actionable findings. However, the application of recent deep learning techniques to radiology reports, which can improve the detection performance, has not been thoroughly examined. Moreover, free-text that clinicians input in the ordering form (order information) has seldom been used to identify actionable reports. This study aims to evaluate the benefits of two new approaches: (1) bidirectional encoder representations from transformers (BERT), a recent deep learning architecture in NLP, and (2) using order information in addition to radiology reports. We performed a binary classification to distinguish actionable reports (i.e., radiology reports tagged as actionable in actual radiological practice) from non-actionable ones (those without an actionable tag). 90,923 Japanese radiology reports in ourÃ‚Â hospital were used, of which 788 (0.87%) were actionable. We evaluated four methods, statistical machine learning with logistic regression (LR) and with gradient boosting decision tree (GBDT), and deep learning with a bidirectional long short-term memory (LSTM) model and a publicly available Japanese BERT model. Each method was used with two different inputs, radiology reports alone and pairs of order information and radiology reports. Thus, eight experiments were conducted to examine the performance. Without order information, BERT achieved the highest area under the precision-recall curve (AUPRC) of 0.5138, which showed a statistically significant improvement over LR, GBDT, and LSTM, and the highest area under the receiver operating characteristic curve (AUROC) of 0.9516. Simply coupling the order information with the radiology reports slightly increased the AUPRC of BERT but did not lead to a statistically significant improvement. This may be due to the complexity of clinical decisions made by radiologists. BERT was assumed to be useful to detect actionable reports. More sophisticated methods are required to use order information effectively.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21126,""
"Multi-auxiliary domain transfer learning for diagnosis of MCI conversion","Cheng, Zhu, Pu","https://doi.org/10.1007/s10072-021-05568-6","20210912","PubMed","AlzheimerÃ¢â‚¬â„¢s disease; Feature selection; Mild cognitive impairment; Multi-auxiliary domain; Transfer learning","In the early stage of Alzheimer's disease (AD), mild cognitive impairment (MCI) has a higher risk of progression to AD, so the prediction of whether an MCI subject will progress to AD (known as progressive MCI, PMCI) or not (known as stable MCI, SMCI) within a certain period is particularly important in practice. It is known that such a task could benefit from jointly learning-related auxiliary tasks such as differentiating AD from PMCI or PMCI from normal control (NC) in order to take full advantage of their shared commonality. However, few existing methods along this line fully consider the correlations between the target and auxiliary tasks according to the clinical practice of AD pathology for diagnosis. To deal with this problem, in this paper, treating each task domain as a different one, we borrow the idea from transfer learning and propose a novel multi-auxiliary domain transfer learning (MaDTL) method, which explicitly utilizes the correlations between the target domain (task) and multi-auxiliary domains (tasks) according to the clinical practice. Specifically, the proposed MaDTL method incorporates two key modules. The first one is a multi-auxiliary domain transfer-based feature selection (MaDTFS) model, which can select a discriminative feature subset shared by the target domain and the multi-auxiliary domains. In the MaDTFS model, to combine more training data from multi-auxiliary domains and simultaneously suppress the negative effects resulting from the irrelevant parts of multi-auxiliary domains, we proposed a sparse group correlation Lasso that includes a proposed group correlation Lasso penalty (i.e., [Formula: see text]) and a proposed correlation Lasso penalty (i.e., [Formula: see text]). The second module in MaDTL is a multi-auxiliary domain transfer-based classification (MaDTC) model that improves the voting with linear weighting-based ensemble learning. This model extends the constraints of the linear weighting method so that it can simultaneously combine training data from multi-auxiliary domains and achieve a robust classifier by minimizing negative effects from the irrelevant part of multi-auxiliary domains. Experimental results on 409 subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database with the baseline magnetic resonance imaging (MRI) and cerebrospinal fluid (CSF) data validate the effectiveness of the proposed method by significantly improving the classification accuracy to 80.37% for the identification of MCI-to-AD conversion, outperforming the state-of-the-art methods.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21127,""
"The Effect of Supervision in Vestibular Rehabilitation in Patients with Acute or Chronic Unilateral Vestibular Dysfunction: A Systematic Review","Lilios, Chimona, Nikitas, Papadakis, Chatziioannou, Skoulakis","https://doi.org/10.1097/MAO.0000000000003354","20210914","PubMed","","The investigation of supervised vestibular rehabilitation treatment role for individuals with dizziness and imbalance due to peripheral, unilateral vestibular disorders. Cochrane, PubMed, and Physiotherapy Evidence Database (PEDro) were utilized to identify relevant studies. The key search terms used were ""Vestibular Rehabilitation and Unilateral Vestibular Hypofunction,"" ""Vestibular Rehabilitation and Unilateral Vestibular Loss,"" and ""Vestibular Rehabilitation and Supervision."" A manual search was performed by exploring the references of included articles to identify studies not captured through the computer-based searches. The quality of the studies was assessed according to the PEDro scale. Inclusion criteria were: 1) studies with patients, aged from 18 to 80Ã¢â‚¬Å years, with acute or chronic dizziness and disequilibrium due to unilateral vestibular dysfunction, 2) randomized control trials (RCTs), 3) studies comparing supervised vestibular rehabilitation program with an unsupervised vestibular rehabilitation program or home-based training or standard care or placebo, and 4) articles written in the English language. Studies reporting cases of vertigo and imbalance due to possible recurrent pathologies, acute benign paroxysmal positional vertigo, or central neurological/orthopedic deficits, were excluded. A total of 448 articles were retrieved from the systematic database search strategy. Five of them were included in the systematic review after full-text analysis, plus one more after manual searching of their references. All studies involved supervised vestibular rehabilitation treatment programs compared with unsupervised home training, the performance of daily activities and, standard care. Based on PEDro's scoring system, one study rated as high-quality RCT, three studies were considered of fair quality and one scored as low-quality RCT. Although most RCTs report better outcomes with a supervised vestibular rehabilitation treatment program regarding the emotional status, dizziness, and balance improvement, this systematic review failed to provide a strong evidence that supervision is superior to unsupervised protocols in patients with UNH. The self-reported subjective measures used by the included RCTs represent a serious limitation of their results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21128,""
"The acute and non-acute effects of cannabis on reward processing: A systematic review","Skumlien, Langley, Lawn, Voon, Curran, Roiser, Sahakian","https://doi.org/10.1016/j.neubiorev.2021.09.008","20211020","PubMed","Anhedonia; Apathy; Cannabis use; MID task; Motivation; Reward processing; THC; Adolescent; Anhedonia; Cannabis; Cross-Sectional Studies; Humans; Motivation; Reward; Young Adult","Cannabis use has historically been thought to cause amotivation, but the relationship between cannabis and apathy, anhedonia, and reward processing remains poorly characterised. In this systematic review, we evaluated whether cannabis exposure acutely and/or non-acutely was associated with altered reward processing using questionnaire, behavioural, or functional neuroimaging measures. Questionnaire studies demonstrated greater anhedonia in adolescent cannabis users, and some indication of greater apathy in young adult cannabis users. Behavioural studies yielded some evidence of reduced reward learning in adolescent cannabis users, though there were too few studies in this category for reliable conclusions. Finally, longitudinal and acute functional neuroimaging studies showed an association between cannabis and blunted neural responses to reward, which did not emerge consistently in cross-sectional studies. The current results suggest that cannabis use is associated with specific impairments in reward and motivation. Future large-scale, longitudinal studies which use multiple behavioural and neuroimaging measures of reward processing may further clarify the impact of cannabis use on motivational and reward processes, and neural networks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21129,""
"Skin cancer classification via convolutional neural networks: systematic review of studies involving human experts","HaggenmÃƒÂ¼ller, Maron, Hekler, Utikal, Barata, Barnhill, Beltraminelli, Berking, Betz-Stablein, Blum, Braun, Carr, Combalia, Fernandez-Figueras, Ferrara, Fraitag, French, Gellrich, Ghoreschi, Goebeler, Guitera, Haenssle, Haferkamp, Heinzerling, Heppt, Hilke, Hobelsberger, Krahl, Kutzner, Lallas, Liopyris, Llamas-Velasco, Malvehy, Meier, MÃƒÂ¼ller, Navarini, Navarrete-Dechent, Perasole, Poch, Podlipnik, Requena, Rotemberg, Saggini, Sangueza, Santonja, Schadendorf, Schilling, Schlaak, Schlager, Sergon, Sondermann, Soyer, Starz, Stolz, Vale, Weyers, Zink, Krieghoff-Henning, Kather, von Kalle, Lipka, FrÃƒÂ¶hling, Hauschild, Kittler, Brinker","https://doi.org/10.1016/j.ejca.2021.06.049","20210924","PubMed","Artificial intelligence; Convolutional neural network(s); Deep learning; Dermatology; Digital biomarkers; Machine learning; Malignant melanoma; Skin cancer classification","Multiple studies have compared the performance of artificial intelligence (AI)-based models for automated skin cancer classification to human experts, thus setting the cornerstone for a successful translation of AI-based tools into clinicopathological practice. The objective of the study was to systematically analyse the current state of research on reader studies involving melanoma and to assess their potential clinical relevance by evaluating three main aspects: test set characteristics (holdout/out-of-distribution data set, composition), test setting (experimental/clinical, inclusion of metadata) and representativeness of participating clinicians. PubMed, Medline and ScienceDirect were screened for peer-reviewed studies published between 2017 and 2021 and dealing with AI-based skin cancer classification involving melanoma. The search terms skin cancer classification, deep learning, convolutional neural network (CNN), melanoma (detection), digital biomarkers, histopathology and whole slide imaging were combined. Based on the search results, only studies that considered direct comparison of AI results with clinicians and had a diagnostic classification as their main objective were included. A total of 19 reader studies fulfilled the inclusion criteria. Of these, 11 CNN-based approaches addressed the classification of dermoscopic images; 6 concentrated on the classification of clinical images, whereas 2 dermatopathological studies utilised digitised histopathological whole slide images. All 19 included studies demonstrated superior or at least equivalent performance of CNN-based classifiers compared with clinicians. However, almost all studies were conducted in highly artificial settings based exclusively on single images of the suspicious lesions. Moreover, test sets mainly consisted of holdout images and did not represent the full range of patient populations and melanoma subtypes encountered in clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21130,""
"Incorporating clinical knowledge with constrained classifier chain into a multimodal deep network for melanoma detection","Wang, Cai, Louie, Wang, Lee","https://doi.org/10.1016/j.compbiomed.2021.104812","20211011","PubMed","7-Point checklist; Constrained classifier chain; Melanoma detection; Multi-modality; Dermoscopy; Diagnosis, Computer-Assisted; Humans; Melanoma; Skin Diseases; Skin Neoplasms","In recent years, vast developments in Computer-Aided Diagnosis (CAD) for skin diseases have generated much interest from clinicians and other eventual end-users of this technology. Introducing clinical domain knowledge to these machine learning strategies can help dispel the black box nature of these tools, strengthening clinician trust. Clinical domain knowledge also provides new information channels which can improve CAD diagnostic performance. In this paper, we propose a novel framework for malignant melanoma (MM) detection by fusing clinical images and dermoscopic images. The proposed method combines a multi-labeled deep feature extractor and clinically constrained classifier chain (CC). This allows the 7-point checklist, a clinician diagnostic algorithm, to be included in the decision level while maintaining the clinical importance of the major and minor criteria in the checklist. Our proposed framework achieved an average accuracy of 81.3% for detecting all criteria and melanoma when testing on a publicly available 7-point checklist dataset. This is the highest reported results, outperforming state-of-the-art methods in the literature by 6.4% or more. Analyses also show that the proposed system surpasses the single modality system of using either clinical images or dermoscopic images alone and the systems without adopting the approach of multi-label and clinically constrained classifier chain. Our carefully designed system demonstrates a substantial improvement over melanoma detection. By keeping the familiar major and minor criteria of the 7-point checklist and their corresponding weights, the proposed system may be more accepted by physicians as a human-interpretable CAD tool for automated melanoma detection.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21131,""
"A randomized controlled trial of a therapeutic relational agent for reducing substance misuse during the COVID-19 pandemic","Prochaska, Vogel, Chieng, Baiocchi, Maglalang, Pajarito, Weingardt, Darcy, Robinson","https://doi.org/10.1016/j.drugalcdep.2021.108986","20210929","PubMed","Artificial intelligence; COVID-19 pandemic; Randomized controlled trial; Relational conversational agent; Substance-related disorders; Adult; COVID-19; Female; Humans; Male; Mental Health; Pandemics; SARS-CoV-2; Substance-Related Disorders","The COVID-19 pandemic disrupted access to treatment for substance use disorders (SUDs), while alcohol and cannabis retail sales increased. During the pandemic, we tested a tailored digital health solution, Woebot-SUDs (W-SUDs), for reducing substance misuse. In a randomized controlled trial, we compared W-SUDs for 8 weeks to a waitlist control. U.S. adults (N = 180) who screened positive for substance misuse (CAGE-AID&gt;1) were enrolled June-August 2020. The primary outcome was the change in past-month substance use occasions from baseline to end-of-treatment (EOT). Study retention was 84%. General linear models tested group differences in baseline-to-EOT change scores, adjusting for baseline differences and attrition. At baseline, the sample (age M = 40, SD = 12, 65% female, 68% non-Hispanic white) averaged 30.2 (SD = 18.6) substance occasions in the past month. Most (77%) reported alcohol problems, 28% cannabis, and 45% multiple substances; 46% reported moderate-to-severe depressive symptoms. Treatment participants averaged 920 in-app text messages (SD = 892, Median = 701); 96% of completed lessons were rated positively; and 88% would recommend W-SUDs. Relative to waitlist, W-SUDs participants significantly reduced past-month substance use occasions (M = -9.1, SE = 2.0 vs. M = -3.3, SE = 1.8; p = .039). Secondary substance use and mood outcomes did not change significantly by group; however, reductions in substance use occasions correlated significantly with increased confidence and fewer substance use problems, cravings, depression and anxiety symptoms, and pandemic-related mental health effects (p-value&lt;.05). W-SUDs was associated with significant reductions in substance use occasions. Reduction in substance use occasions was associated with better outcomes, including improved mental health. W-SUDs satisfaction was high.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21132,""
"Current uses, emerging applications, and clinical integration of artificial intelligence in neuroradiology","Fiani, Pasko, Sarhadi, Covarrubias","https://doi.org/10.1515/revneuro-2021-0101","20210910","PubMed","artificial intelligence; computational intelligence; computer aided diagnosis; imaging optimization; neuroradiology","Artificial intelligence (AI) is a branch of computer science with a variety of subfields and techniques, exploited to serve as a deductive tool that performs tasks originally requiring human cognition. AI tools and its subdomains are being incorporated into healthcare delivery for the improvement of medical data interpretation encompassing clinical management, diagnostics, and prognostic outcomes. In the field of neuroradiology, AI manifested through deep machine learning and connected neural networks (CNNs) has demonstrated incredible accuracy in identifying pathology and aiding in diagnosis and prognostication in several areas of neurology and neurosurgery. In this literature review, we survey the available clinical data highlighting the utilization of AI in the field of neuroradiology across multiple neurological and neurosurgical subspecialties. In addition, we discuss the emerging role of AI in neuroradiology, its strengths and limitations, as well as future needs in strengthening its role in clinical practice. Our review evaluated data across several subspecialties of neurology and neurosurgery including vascular neurology, spinal pathology, traumatic brain injury (TBI), neuro-oncology, multiple sclerosis, Alzheimer's disease, and epilepsy. AI has established a strong presence within the realm of neuroradiology as a successful and largely supportive technology aiding in the interpretation, diagnosis, and even prognostication of various pathologies. More research is warranted to establish its full scientific validity and determine its maximum potential to aid in optimizing and providing the most accurate imaging interpretation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21133,""
"Deep learning versus ophthalmologists for screening for glaucoma on fundus examination: A systematic review and meta-analysis","Buisson, Navel, LabbÃƒÂ©, Watson, Baker, Murtagh, Chiambaretta, Dutheil","https://doi.org/10.1111/ceo.14000","20210923","PubMed","artificial intelligence; deep learning; glaucoma; machine learning; screening","In this systematic review and meta-analysis, we aimed to compare deep learning versus ophthalmologists in glaucoma diagnosis on fundus examinations. PubMed, Cochrane, Embase, ClinicalTrials.gov and ScienceDirect databases were searched for studies reporting a comparison between the glaucoma diagnosis performance of deep learning and ophthalmologists on fundus examinations on the same datasets, until 10 December 2020. Studies had to report an area under the receiver operating characteristics (AUC) with SD or enough data to generate one. We included six studies in our meta-analysis. There was no difference in AUC between ophthalmologists (AUCÃ‚Â =Ã‚Â 82.0, 95% confidence intervals [CI] 65.4-98.6) and deep learning (97.0, 89.4-104.5). There was also no difference using several pessimistic and optimistic variants of our meta-analysis: the best (82.2, 60.0-104.3) or worst (77.7, 53.1-102.3) ophthalmologists versus the best (97.1, 89.5-104.7) or worst (97.1, 88.5-105.6) deep learning of each study. We did not retrieve any factors influencing those results. Deep learning had similar performance compared to ophthalmologists in glaucoma diagnosis from fundus examinations. Further studies should evaluate deep learning in clinical situations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21134,""
"Telehealth Behavioral Intervention for Diabetes Management in Adults With Physical Disabilities: Intervention Fidelity Protocol for a Randomized Controlled Trial","Zengul, Evans, Hall, Qu, Willig, Cherrington, Thirumalai","https://doi.org/10.2196/31695","20211022","PubMed","artificial intelligence; diabetes mellitus; health coaching; intervention fidelity; mobile phone; telehealth","Diabetes mellitus is a major health problem among people with physical disabilities. Health coaching has been proven to be an effective approach in terms of behavioral changes, patient self-efficacy, adherence to treatment, health service use, and health outcomes. Telehealth systems combined with health coaching have the potential to improve the quality of health care by increasing access to services. Treatment fidelity is particularly important for behavior change studies; however, fidelity protocols are inadequately administered and reported in the literature. The aim of this study is to outline all the intervention fidelity strategies and procedures of a telecoaching intervention-artificial intelligence for diabetes management (AI4DM)-which is a randomized controlled trial to evaluate the feasibility, acceptability, and preliminary efficacy of a telehealth platform in adults with type 2 diabetes and permanent impaired mobility. AI4DM aims to create a web-based disability-inclusive diabetes self-management program. We selected the National Institutes of Health Behavior Change Consortium (NIH BCC) fidelity framework to describe strategies to ensure intervention fidelity in our research. We have developed fidelity strategies based on the five fidelity domains outlined by the NIH BCC-focusing on study design, provider training, treatment delivery, treatment receipt, and enactment of treatment skills. The design of the study is grounded in the social cognitive theory and is intended to ensure that both arms would receive the same amount of attention from the intervention. All providers will receive standardized training to deliver consistent health coaching to the participants. The intervention will be delivered through various controlling and monitoring strategies to reduce differences within and between treatment groups. The content and structure of the study are delivered to ensure comprehension and participation among individuals with low health literacy. By constantly reviewing and monitoring participant progress and protocol adherence, we intend to ensure that participants use cognitive and behavioral skills in real-world settings to engage in health behavior. Enrollment for AI4DM will begin in October 2021 and end in October 2022. The results of this study will be reported in late 2022. Developing and using fidelity protocols in behavior change studies is essential to ensure the internal and external validity of interventions. This study incorporates NIH BCC recommendations into an artificial intelligence embedded telecoaching platform for diabetes management designed for people with physical disabilities. The developed fidelity protocol can provide guidance for other researchers conducting telehealth interventions within behavioral health settings to present more consistent and reproducible research. ClinicalTrials.gov NCT04927377; http://clinicaltrials.gov/ct2/show/NCT04927377. PRR1-10.2196/31695.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21135,""
"A One-Health evaluation of the burden of cystic echinococcosis and its prevention costs: Case study from a hypo-endemic area in Italy","Cassini, Canali, Tamarozzi, Angheben, Capelli, Gobbi, Legnardi, Brichese, Napoletano, Cestaro, Casulli, Drigo, Aragrande","https://doi.org/10.1016/j.onehlt.2021.100320","20210911","PubMed","Cystic echinococcosis; Economic evaluation; Epidemiology; Italy; One Health","An integrated model, based on a One Health approach, was implemented to estimate the epidemiological and economic outcomes of cystic echinococcosis (CE) in Veneto region, an hypo-endemic area of Northern Italy, and the costs for its prevention. Data and information needed to populate the model were retrieved from published literature, official statistics, expert opinions, or actively searched through data mining (i.e., Hospital and slaughterhouse data), when fundamental data were not available. Human-health and animal-health costs, both public and private, were considered. The overall impact of CE in the study area was estimated in an yearly cost of about 0.5 million Ã¢â€šÂ¬, due to an average of 19.5 human hospitalized cases and about 200 infected animals among cattle and sheep, per year. The human:animal costs ratio was about 8:1. Most of the infected animals were autochthonous, while the identification of an autochthonous source of the infection for the human cases was extremely difficult, and unlikely in most cases. No specific action resulted to be in place for human surveillance, while veterinary surveillance accounted for a yearly cost of about 22,000 Ã¢â€šÂ¬. Sheepherders were found to pay privately an overall amount of around 2000 Ã¢â€šÂ¬ for the preventive treatment of their dogs every year, but the applied protocol proved to be sub-optimal. The source of most of the human cases was likely external to the study area, and their economic impact accounts for a cost that is far exceeding that of surveillance and preventive actions in place in the veterinary sector. Although autochthonous human cases appeared to be very rare, the strengthening of preventive actions and surveillance systems can reduce the risk of their increment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21136,""
"Advanced deep learning algorithms for infectious disease modeling using clinical data- A Case Study on CoVID-19","Kumar, Kolnure, Abhishek, Fadi-Al-Turjman, Nerurkar, Ghalib, Shankar","https://doi.org/10.2174/1573405617666210908125911","20210910","PubMed","Big data analysis; COVID-19; Deep learning; Time series forecasting Infectious disease modeling","Infectious disease happens when an individual is defiled by a micro-organism/virus from another person or an animal. It is troublesome that causes hurt at both individual and huge scope scales. The ongoing episode of COVID-19 ailment brought about by the new coronavirus first distinguished in Wuhan China, and its quick spread far and wide, revived the consideration of the world towards the impacts of such plagues on individual's regular daily existence. We attempt to exploit this effectiveness of Advanced deep learning algorithms to predict the Growth of Infectious disease based on time series data and classification based on (symptoms) text data and X-ray image data. Goal is identifying the nature of the phenomenon represented by the sequence of observations and forecasting.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21137,""
"A Clinical Update on the Prognostic Effect of microRNA Biomarkers for Survival Outcome in Nasopharyngeal Carcinoma: A Systematic Review and Meta-Analysis","Shaw, Senthilnathan, Krishnan, Suresh, Shetty, Muthukaliannan, Mani, Sivanandy, Chandramoorthy, Gupta, Baxi, Jayaraj","https://doi.org/10.3390/cancers13174369","20210913","PubMed","biomarkers; meta-analysis; miRNAs; nasopharyngeal carcinoma; prognosis; survival; systematic review","<i>Background</i>: Nasopharyngeal carcinoma (NPC), a relatively uncommon malignancy in the Western world, is highly prevalent in Southeast Asia where the treatment outcomes are poor. Despite recent improvements in diagnosis and treatment locoregional control, distant metastasis and chemoresistance continue to be a significant cause of mortality. Identification of a reliable and comprehensive prognostic biomarker is highly desirable. The potential relevance of microRNAs (miRNAs) as prognostic markers in NPC is assessed in this systematic review and meta-analysis. <i>Methods</i>: A systematic review was performed using the PubMed and Science Direct databases. The search was limited to search results between 2018 and 2020 with the keywords and search strings developed as per the Preferred Reporting Items for Systematic Review and Meta-analysis (PRISMA) guidelines. The recovered articles were carefully screened based on the selection criteria. In the meta-analysis study, high and low expression levels of miRNAs were measured using the hazard ratio (HR) and 95 percent confidence interval (CI) for patients' survival outcomes. Egger's bias indicator test and funnel plot symmetry were used to assess the risk of bias. <i>Results</i>: Amongst the 25 studies, 13 fulfilled the conditions of inclusion in this meta-analysis. The researchers further delved into the 21 miRNA expression levels from 3015 NPC patients to ascertain a link between miRNA's predictive role and survival outcomes. The majority of the articles retrieved during this study were from China, with two studies from Canada and Malaysia. The overall pooled effect size estimation (HR) for dysregulated miRNAs was 1.590 (95% CI: 1.253-2.017), displaying that miRNA marker expression increased the risk of mortality in NPC patients by 59%. <i>Conclusions</i>: This meta-analysis is novel and looks at the prognostic significance of miRNAs as biomarkers in NPC patients using a continuous version pooled meta-analysis. Although our findings are ambiguous, they do show that greater miRNA expression in NPC may be associated with a lower overall survival rate. To acquire clear conclusions, more prospective studies with large cohorts are required to determine the clinical utility of miRNAs as prognostic biomarkers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21138,""
"An Extensive Literature Review on Underwater Image Colour Correction","Vlachos, Skarlatos","https://doi.org/10.3390/s21175690","20210913","PubMed","UW; artificial intelligence; colour correction; image restoration; Color; Water","The topic of underwater (UW) image colour correction and restoration has gained significant scientific interest in the last couple of decades. There are a vast number of disciplines, from marine biology to archaeology, that can and need to utilise the true information of the UW environment. Based on that, a significant number of scientists have contributed to the topic of UW image colour correction and restoration. In this paper, we try to make an unbiased and extensive review of some of the most significant contributions from the last 15 years. After considering the optical properties of water, as well as light propagation and haze that is caused by it, the focus is on the different methods that exist in the literature. The criteria for which most of them were designed, as well as the quality evaluation used to measure their effectiveness, are underlined.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21139,""
"Proverbs and Aphorisms in Neurorehabilitation: A Literature Review","Cano-de-la-Cuerda","https://doi.org/10.3390/ijerph18179240","20211027","PubMed","aphorisms; brain; neurological disorders; neuroplasticity; neurorehabilitation; neurosciences; proverbs; Adolescent; Adult; Brain; Child; Humans; Language; Neurological Rehabilitation; Neurosciences; Systematic Reviews as Topic","Brain plasticity is not limited to childhood or adolescence, as originally assumed, but continues into adulthood. Understanding this conceptual evolution about the nervous system, neuroscience and neurorehabilitation, researchers have left different proverbs and aphorisms derived of their investigations that are still used in university and postgraduate training. A proverb is defined as a phrase of popular origin traditionally repeated invariably, in which a moral thought, advice or teaching is expressed. On the other hand, an aphorism is understood as a brief and doctrinal phrase or sentence that is proposed as a rule in some science or art. The aim of this paper is to present a compilation of proverbs and aphorisms related to neuroscience and neurorehabilitation, classified chronologically, to illustrate the conceptual evolution about the brain and to improve our understanding about the management of neurological patients through the methods and techniques developed during the 19th, 20th and 21st centuries, as many therapies are based on them. A literature review was conducted based on the recommendations for Systematic Reviews guidelines for scoping reviews. A computerized search was conducted in the following electronic databases: CINAHL Medical Science, Medline through EBSCO, PubMed, Physiotherapy Evidence Database (PEDro) and Scopus, limiting the search to papers published until April 2021 in English and Spanish. Inverse searches were also carried out based on papers found in the databases. The following data were extracted: technique or approach; author; date of birth and death; proverbs and aphorisms; clinical interpretation. Proverbs and aphorisms linked to authors such as Charles Edward Beevor (1854-1908), Heinrich Sebastian Frenkel (1860-1931), Rudolf Magnus (1873-1927), Nikolai Bernstein (1896-1966), Donald O. Hebb (1904-1985), Elwood Henneman (1915-1996), Wilder Graves Penfield (1891-1976), Humberto Augusto Maturana RomesÃƒÂ­n (1928), Edward Taub (1931), Janet Howard Carr (1933-2014), Roberta Barkworth Shepherd (1934), Brown &amp; Hardman (1987), Jeffrey A. Kleim and Theresa A. Jones (2008) were compiled. Different authors have developed throughout history a series of proverbs and aphorisms related to neurosciences and neurorehabilitation that have helped to better our understanding of the nervous system and, therefore, in the management of the neurological patient through the methods and techniques developed throughout the 19th, 20th and 21st centuries.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21140,""
"Big Data for Biomedical Education with a Focus on the COVID-19 Era: An Integrative Review of the Literature","Khamisy-Farah, Gilbey, Furstenau, Sott, Farah, Viviani, Bisogni, Kong, Ciliberti, Bragazzi","https://doi.org/10.3390/ijerph18178989","20210914","PubMed","COVID-19; big data; curriculum; integrative review; medical education; Big Data; COVID-19; Curriculum; Humans; Learning; SARS-CoV-2","Medical education refers to education and training delivered to medical students in order to become a practitioner. In recent decades, medicine has been radically transformed by scientific and computational/digital advances-including the introduction of new information and communication technologies, the discovery of DNA, and the birth of genomics and post-genomics super-specialties (transcriptomics, proteomics, interactomics, and metabolomics/metabonomics, among others)-which contribute to the generation of an unprecedented amount of data, so-called 'big data'. While these are well-studied in fields such as medical research and methodology, translational medicine, and clinical practice, they remain overlooked and understudied in the field of medical education. For this purpose, we carried out an integrative review of the literature. Twenty-nine studies were retrieved and synthesized in the present review. Included studies were published between 2012 and 2021. Eleven studies were performed in North America: specifically, nine were conducted in the USA and two studies in Canada. Six studies were carried out in Europe: two in France, two in Germany, one in Italy, and one in several European countries. One additional study was conducted in China. Eight papers were commentaries/theoretical or perspective articles, while five were designed as a case study. Five investigations exploited large databases and datasets, while five additional studies were surveys. Two papers employed visual data analytical/data mining techniques. Finally, other two papers were technical papers, describing the development of software, computational tools and/or learning environments/platforms, while two additional studies were literature reviews (one of which being systematic and bibliometric).The following nine sub-topics could be identified: (I) knowledge and awareness of big data among medical students; (II) difficulties and challenges in integrating and implementing big data teaching into the medical syllabus; (III) exploiting big data to review, improve and enhance medical school curriculum; (IV) exploiting big data to monitor the effectiveness of web-based learning environments among medical students; (V) exploiting big data to capture the determinants and signatures of successful academic performance and counteract/prevent drop-out; (VI) exploiting big data to promote equity, inclusion, and diversity; (VII) exploiting big data to enhance integrity and ethics, avoiding plagiarism and duplication rate; (VIII) empowering medical students, improving and enhancing medical practice; and, (IX) exploiting big data in continuous medical education and learning. These sub-themes were subsequently grouped in the following four major themes/topics: namely, (I) big data and medical curricula; (II) big data and medical academic performance; (III) big data and societal/bioethical issues in biomedical education; and (IV) big data and medical career. Despite the increasing importance of big data in biomedicine, current medical curricula and syllabuses appear inadequate to prepare future medical professionals and practitioners that can leverage on big data in their daily clinical practice. Challenges in integrating, incorporating, and implementing big data teaching into medical school need to be overcome to facilitate the training of the next generation of medical professionals. Finally, in the present integrative review, state-of-art and future potential uses of big data in the field of biomedical discussion are envisaged, with a focus on the still ongoing ""Coronavirus Disease 2019"" (COVID-19) pandemic, which has been acting as a catalyst for innovation and digitalization.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21141,""
"Extraperitoneal Single-Port Robot-Assisted Radical Prostatectomy","Khalil, Joseph","https://doi.org/10.1089/end.2021.0440","20211026","PubMed","extraperitoneal; robotic radical prostatectomy; single port; Humans; Male; Prostatectomy; Prostatic Neoplasms; Robotic Surgical Procedures; Robotics","Robot-assisted radical prostatectomy (RARP) is currently the standard minimally invasive procedure for the surgical management of localized prostate cancer. It has been shown that the minimally invasive robotic approach offers comparable oncologic and functional outcomes with potential advantages, including decreased blood loss, shorter hospital stay, and recovery period when compared with open surgery. Generally, the transperitoneal RARP approach is the most commonly performed among robotic surgeons, owing to its wider space and early adoption. However, similar oncologic outcomes have been reported with the extraperitoneal approach. Owing to its perceived technical difficulty, extraperitoneal RARP is less adopted nowadays. This approach, however, has its merits particularly in cases where intraperitoneal access can be problematic with extensive adhesions from previous surgeries. Also, extraperitoneal approach allows for minimal bowel manipulation, less steep Trendelenburg positioning, and less pneumoperitoneum, which reflect on early recovery of bowel function after RARP. Both transperitoneal and extraperitoneal approaches can be performed using either the conventional multiport robotic system or the more recent single-port (SP) robotic system. With respect to extraperitoneal RARP, there has been an increased adoption of the SP system, with purported advantages such as better cosmesis, less postoperative analgesic and opioid requirements, and shorter duration of hospital stay. Herein, we describe the technical steps relevant to extraperitoneal single-port robot-assisted radical prostatectomy, and elaborate on the clinical outcomes reported in the literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21142,""
"Machine Learning Approaches to Retrieve High-Quality, Clinically Relevant Evidence From the Biomedical Literature: Systematic Review","Abdelkader, Navarro, Parrish, Cotoi, Germini, Iorio, Haynes, Lokker","https://doi.org/10.2196/30401","20211022","PubMed","accuracy; bioinformatics; clinical care; clinical support; evidence-based medicine; information retrieval; literature databases; machine learning; medical literature; systematic review","The rapid growth of the biomedical literature makes identifying strong evidence a time-consuming task. Applying machine learning to the process could be a viable solution that limits effort while maintaining accuracy. The goal of the research was to summarize the nature and comparative performance of machine learning approaches that have been applied to retrieve high-quality evidence for clinical consideration from the biomedical literature. We conducted a systematic review of studies that applied machine learning techniques to identify high-quality clinical articles in the biomedical literature. Multiple databases were searched to July 2020. Extracted data focused on the applied machine learning model, steps in the development of the models, and model performance. From 3918 retrieved studies, 10 met our inclusion criteria. All followed a supervised machine learning approach and applied, from a limited range of options, a high-quality standard for the training of their model. The results show that machine learning can achieve a sensitivity of 95% while maintaining a high precision of 86%. Machine learning approaches perform well in retrieving high-quality clinical studies. Performance may improve by applying more sophisticated approaches such as active learning and unsupervised machine learning approaches.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21143,""
"Influenza virus genotype to phenotype predictions through machine learning: a systematic review","Borkenhagen, Allen, Runstadler","https://doi.org/10.1080/22221751.2021.1978824","20210929","PubMed","Influenza virus; classification; machine learning; phenotype; prediction","There is great interest in understanding the viral genomic predictors of phenotypic traits that allow influenza A viruses to adapt to or become more virulent in different hosts. Machine learning techniques have demonstrated promise in addressing this critical need for other pathogens because the underlying algorithms are especially well equipped to uncover complex patterns in large datasets and produce generalizable predictions for new data. As the body of research where these techniques are applied for influenza A virus phenotype prediction continues to grow, it is useful to consider the strengths and weaknesses of these approaches to understand what has prevented these models from seeing widespread use by surveillance laboratories and to identify gaps that are underexplored with this technology. We present a systematic review of English literature published through 15 April 2021 of studies employing machine learning methods to generate predictions of influenza A virus phenotypes from genomic or proteomic input. Forty-nine studies were included in this review, spanning the topics of host discrimination, human adaptability, subtype and clade assignment, pandemic lineage assignment, characteristics of infection, and antiviral drug resistance. Our findings suggest that biases in model design and a dearth of wet laboratory follow-up may explain why these models often go underused. We, therefore, offer guidance to overcome these limitations, aid in improving predictive models of previously studied influenza A virus phenotypes, and extend those models to unexplored phenotypes in the ultimate pursuit of tools to enable the characterization of virus isolates across surveillance laboratories.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21144,""
"Verbal autopsy models in determining causes of death","Tunga, Lungo, Chambua, Kateule","https://doi.org/10.1111/tmi.13678","20210930","PubMed","InSilicoVA; InterVA; King and Lu; Naive Bayes; VA Algorithm; VA Models; causes of death; tariff; verbal autopsy; verbal autopsy algorithm; verbal autopsy model","To systematically review current practices, strengths and limitations of existing VA approaches to increase understanding of health system stakeholders and researchers. The review was conducted and reported based on the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) guidelines, in which articles were systematically obtained from the PubMed and SCOPUS online databases. The search was limited to English language journal articles published between 2010 and 2020. The review identified 5602 articles and after thorough scrutiny, 25 articles related to VA approaches were included. (1) InterVA and Tariff are widely used VA models; (2) Bayes rule is the most common and successful algorithm; (3) the lack of standardised datasets and metrics to evaluate models creates bias in determining VA model performance; (4) performance of the models trained using in-hospital data cannot be replicated in community death; (5) the performance of models among physicians and computer-coded algorithms differs with variation in settings. The physician-certified verbal autopsy (PCVA) approaches are more effective in determining community CoD while computerised coding of verbal autopsy (CCVA) models perform well when the underlying CoD are reliably established using hospital data where data are trained in a similar environment to the target population. Our study recommends the use of hybrid models that combine strengths from various models and using an open standards dataset that includes death from different settings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21145,""
"Automation in nursing decision support systems: A systematic review of effects on decision making, care delivery, and patient outcomes","Akbar, Lyell, Magrabi","https://doi.org/10.1093/jamia/ocab123","20211015","PubMed","automation; clinical decision support systems; nursing informatics; patient safety","The study sought to summarize research literature on nursing decision support systems (DSSs ); understand which steps of the nursing care process (NCP) are supported by DSSs, and analyze effects of automated information processing on decision making, care delivery, and patient outcomes. We conducted a systematic review in accordance with the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) statement. PubMed, CINAHL, Cochrane, Embase, Scopus, and Web of Science were searched from January 2014 to April 2020 for studies focusing on DSSs used exclusively by nurses and their effects. Information about the stages of automation (information acquisition, information analysis, decision and action selection, and action implementation), NCP, and effects was assessed. Of 1019 articles retrieved, 28 met the inclusion criteria, each studying a unique DSS. Most DSSs were concerned with two NCP steps: assessment (82%) and intervention (86%). In terms of automation, all included DSSs automated information analysis and decision selection. Five DSSs automated information acquisition and only one automated action implementation. Effects on decision making, care delivery, and patient outcome were mixed. DSSs improved compliance with recommendations and reduced decision time, but impacts were not always sustainable. There were improvements in evidence-based practice, but impact on patient outcomes was mixed. Current nursing DSSs do not adequately support the NCP and have limited automation. There remain many opportunities to enhance automation, especially at the stage of information acquisition. Further research is needed to understand how automation within the NCP can improve nurses' decision making, care delivery, and patient outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21146,""
"Mining genetic and transcriptomic data using machine learning approaches in Parkinson's disease","Su, Tong, Wang","https://doi.org/10.1038/s41531-020-00127-w","20211011","PubMed","","High-throughput techniques have generated abundant genetic and transcriptomic data of Parkinson's disease (PD) patients but data analysis approaches such as traditional statistical methods have not provided much in the way of insightful integrated analysis or interpretation of the data. As an advanced computational approach, machine learning, which enables people to identify complex patterns and insight from data, has consequently been harnessed to analyze and interpret large, highly complex genetic and transcriptomic data toward a better understanding of PD. In particular, machine learning models have been developed to integrate patient genotype data alone or combined with demographic, clinical, neuroimaging, and other information, for PD outcome study. They have also been used to identify biomarkers of PD based on transcriptomic data, e.g., gene expression profiles from microarrays. This study overviews the relevant literature on using machine learning models for genetic and transcriptomic data analysis in PD, points out remaining challenges, and suggests future directions accordingly. Undoubtedly, the use of machine learning is amplifying PD genetic and transcriptomic achievements for accelerating the study of PD. Existing studies have demonstrated the great potential of machine learning in discovering hidden patterns within genetic or transcriptomic information and thus revealing clues underpinning pathology and pathogenesis. Moving forward, by addressing the remaining challenges, machine learning may advance our ability to precisely diagnose, prognose, and treat PD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21147,""
"Forecasting the length-of-stay of pediatric patients in hospitals: a scoping review","Medeiros, Fogliatto, Rocha, Tortorella","https://doi.org/10.1186/s12913-021-06912-4","20210910","PubMed","Forecasting models; Hospital length-of-stay; Neonatal patients; Pediatric patients; Scoping review; Child; Hospitals; Humans; Length of Stay; Reproducibility of Results; Research Design","Healthcare management faces complex challenges in allocating hospital resources, and predicting patients' length-of-stay (LOS) is critical in effectively managing those resources. This work aims to map approaches used to forecast the LOS of Pediatric Patients in Hospitals (LOS-P) and patients' populations and environments used to develop the models. Using the Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) methodology, we performed a scoping review that identified 28 studies and analyzed them. The search was conducted on four databases (Science Direct, Scopus, Web of Science, and Medline). The identification of relevant studies was structured around three axes related to the research questions: (i) forecast models, (ii) hospital length-of-stay, and (iii) pediatric patients. Two authors carried out all stages to ensure the reliability of the review process. Articles that passed the initial screening had their data charted on a spreadsheet. Methods reported in the literature were classified according to the stage in which they are used in the modeling process: (i) pre-processing of data, (ii) variable selection, and (iii) cross-validation. Forecasting models are most often applied to newborn patients and, consequently, in neonatal intensive care units. Regression analysis is the most widely used modeling approach; techniques associated with Machine Learning are still incipient and primarily used in emergency departments to model patients in specific situations. The studies' main benefits include informing family members about the patient's expected discharge date and enabling hospital resources' allocation and planning. Main research gaps are associated with the lack of generalization of forecasting models and limited reported applicability in hospital management. This study also provides a practical guide to LOS-P forecasting methods and a future research agenda.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21148,""
"Machine Learning for Detection of Correct Peripherally Inserted Central Catheter Tip Position from Radiology Reports in Infants","Shah, Shu, Prasath, Ni, Schapiro, Dufendach","https://doi.org/10.1055/s-0041-1735178","20210911","PubMed","","Ã¢â‚¬Æ’In critically ill infants, the position of a peripherally inserted central catheter (PICC) must be confirmed frequently, as the tip may move from its original position and run the risk of hyperosmolar vascular damage or extravasation into surrounding spaces. Automated detection of PICC tip position holds great promise for alerting bedside clinicians to noncentral PICCs. Ã¢â‚¬Æ’This research seeks to use natural language processing (NLP) and supervised machine learning (ML) techniques to predict PICC tip position based primarily on text analysis of radiograph reports from infants with an upper extremity PICC. Ã¢â‚¬Æ’Radiographs, containing a PICC line in infants under 6 months of age, were manually classified into 12 anatomical locations based on the radiologist's textual report of the PICC line's tip. After categorization, we performed a 70/30 train/test split and benchmarked the performance of seven different (neural network, support vector machine, the naÃƒÂ¯ve Bayes, decision tree, random forest, AdaBoost, and K-nearest neighbors) supervised ML algorithms. After optimization, we calculated accuracy, precision, and recall of each algorithm's ability to correctly categorize the stated location of the PICC tip. Ã¢â‚¬Æ’A total of 17,337 radiographs met criteria for inclusion and were labeled manually. Interrater agreement was 99.1%. Support vector machines and neural networks yielded accuracies as high as 98% in identifying PICC tips in central versus noncentral position (binary outcome) and accuracies as high as 95% when attempting to categorize the individual anatomical location (12-category outcome). Ã¢â‚¬Æ’Our study shows that ML classifiers can automatically extract the anatomical location of PICC tips from radiology reports. Two ML classifiers, support vector machine (SVM) and a neural network, obtained top accuracies in both binary and multiple category predictions. Implementing these algorithms in a neonatal intensive care unit as a clinical decision support system may help clinicians address PICC line position.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21149,""
"Contrastive Cross-Modal Pre-Training: A General Strategy for Small Sample Medical Imaging","Liang, Greenwell, Zhang, Xing, Wang, Kavuluru, Jacobs","https://doi.org/10.1109/JBHI.2021.3110805","20210908","PubMed","","A key challenge in training neural networks for a given medical imaging task is often the difficulty of obtaining a sufficient number of manually labeled examples. In contrast, textual imaging reports, which are often readily available in medical records, contain rich but unstructured interpretations written by experts as part of standard clinical practice. We propose using these textual reports as a form of weak supervision to improve the image interpretation performance of a neural network without requiring additional manually labeled examples. We use an image-text matching task to train a feature extractor and then fine-tune it in a transfer learning setting for a supervised task using a small labeled dataset. The end result is a neural network that automatically interprets imagery without requiring textual reports during inference. This approach can be applied to any task for which text-image pairs are readily available. We evaluate our method on three classification tasks and find consistent performance improvements, reducing the need for labeled data by 67%--98%.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21150,""
"Facial Anatomical Landmark Detection using Regularized Transfer Learning with Application to Fetal Alcohol Syndrome Recognition","Fu, Jiao, Suttie, Noble","https://doi.org/10.1109/JBHI.2021.3110680","20210908","PubMed","","Fetal alcohol syndrome (FAS) caused by prenatal alcohol exposure can result in a series of cranio-facial anomalies, and behavioral and neurocognitive problems. Current diagnosis of FAS is typically done by identifying a set of facial characteristics, which are often obtained by manual examination. Anatomical landmark detection, which provides rich geometric information, is important to detect the presence of FAS associated facial anomalies. This imaging application is characterized by large variations in data appearance and limited availability of labeled data. Current deep learning-based heatmap regression methods designed for facial landmark detection in natural images assume availability of large datasets and are therefore not wellsuited for this application. To address this restriction, we develop a new regularized transfer learning approach that exploits the knowledge of a network learned on large facial recognition datasets. In contrast to standard transfer learning which focuses on adjusting the pre-trained weights, the proposed learning approach regularizes the model behavior. It explicitly reuses the rich visual semantics of a domain-similar source model on the target task data as an additional supervisory signal for regularizing landmark detection optimization. Specifically, we develop four regularization constraints for the proposed transfer learning, including constraining the feature outputs from classification and intermediate layers, as well as matching activation attention maps in both spatial and channel levels. Experimental evaluation on a collected clinical imaging dataset demonstrate that the proposed approach can effectively improve model generalizability under limited training samples, and is advantageous to other approaches in the literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21151,""
"[Prenatal care for normal-risk pregnant women by obstetric nurses and midwives: cost-effectiveness from the perspective of the Supplementary Health System in Brazil]","Menezes, Knobel, Andreucci, MagalhÃƒÂ£es, Amorim, Katz, Takemoto","https://doi.org/10.1590/0102-311X00076320","20210920","PubMed","Brazil; Cost-Benefit Analysis; Female; Humans; Midwifery; Nurses; Pregnancy; Pregnant Women; Prenatal Care","In several countries, primary care for pregnant women is performed by obstetric nurses and/or midwives. In Brazil's Supplementary Health System (private health insurance and out-of-pocket care), coverage of prenatal care is mandatory and is performed by medical obstetricians. The objective of this study is to conduct a cost-effectiveness analysis, comparing clinical outcomes and costs associated with the incorporation of prenatal care by obstetric nurses and midwives in the Supplementary Health System, from the perspective of the operator of health plans as the payment source. A decision tree was built, based on data from a Cochrane Collaboration meta-analysis that showed a reduction in the risk of premature birth in the group of normal-risk pregnant women accompanied by obstetric nurses and midwives. The analysis only considered the direct medical costs covered by health plan operators for essential appointments and tests, according to the prevailing Ministry of Health protocol. The study assumed equal unit costs of consultations by medical professionals and applied an increase in the overall cost of prenatal tests associated with medical follow-up, based on data from the literature. Incremental cost-effective ratio was estimated at -BRL 10,038.43 (savings of BRL 10,038.43) per premature birth avoided. This result was consistent with the sensitivity analyses, with savings associated with the substitution ranging from -BRL 2,544.60 to -BRL 31,807.46 per premature death avoided. In conclusion, prenatal care provided by obstetric nurses and midwives was superior to that provided by medical obstetricians for the prevention of premature birth, besides resulting in cost savings. Em diversos paÃƒÂ­ses, a atenÃƒÂ§ÃƒÂ£o primÃƒÂ¡ria ÃƒÂ s gestantes ÃƒÂ© conduzida por enfermeiras obstetras e/ou obstetrizes. No Sistema Suplementar de SaÃƒÂºde no Brasil, a cobertura da assistÃƒÂªncia prÃƒÂ©-natal ÃƒÂ© obrigatÃƒÂ³ria e realizada por mÃƒÂ©dicos obstetras. O objetivo deste estudo ÃƒÂ© conduzir anÃƒÂ¡lise de custo-efetividade, comparando desfechos clÃƒÂ­nicos e custos associados Ãƒ incorporaÃƒÂ§ÃƒÂ£o do prÃƒÂ©-natal por enfermeiras obstetras e obstetrizes no ÃƒÂ¢mbito do Sistema de SaÃƒÂºde Suplementar, sob a perspectiva da operadora de planos de saÃƒÂºde como fonte pagadora. Foi construÃƒÂ­da uma ÃƒÂ¡rvore de decisÃƒÂ£o, baseada nos dados de metanÃƒÂ¡lise da ColaboraÃƒÂ§ÃƒÂ£o Cochrane que mostrou reduÃƒÂ§ÃƒÂ£o do risco de parto prematuro no grupo de gestantes de risco habitual acompanhado por enfermeiras obstetras e obstetrizes. Foram considerados apenas os custos mÃƒÂ©dicos diretos cobertos pelas operadoras de planos de saÃƒÂºde para a realizaÃƒÂ§ÃƒÂ£o de consultas e exames essenciais, conforme protocolo do MinistÃƒÂ©rio da SaÃƒÂºde vigente. Assumiu-se custo unitÃƒÂ¡rio de consulta com cada profissional como iguais e aplicou-se um aumento do custo global com exames prÃƒÂ©-natais associado ao acompanhamento mÃƒÂ©dico, conforme dado obtido na literatura. Estimou-se a razÃƒÂ£o de custo-efetividade incremental de -R$ 10.038,43 (economia de R$ 10.038,43) por parto prematuro evitado. Esse resultado mostrou-se consistente nas anÃƒÂ¡lises de sensibilidade, com economias associadas Ãƒ substituiÃƒÂ§ÃƒÂ£o variando de -R$ 2.544,60 atÃƒÂ© -R$ 31.807,46 por parto prematuro evitado. Como conclusÃƒÂ£o, observou-se que o cuidado prÃƒÂ©-natal por enfermeiras obstetras e obstetrizes ÃƒÂ© superior ao prestado por mÃƒÂ©dicos obstetras para o desfecho prevenÃƒÂ§ÃƒÂ£o de parto prematuro, resultando ainda em economia de recursos. En diversos paÃƒÂ­ses, la atenciÃƒÂ³n primaria a las gestantes se realiza con enfermeras obstetras y/o parteras. En el Sistema Suplementario de Salud en Brasil, la cobertura de la asistencia prenatal es obligatoria y la realizan mÃƒÂ©dicos obstetras. El objetivo de este estudio es realizar un anÃƒÂ¡lisis de costo-efectividad, comparando resultados clÃƒÂ­nicos y costes asociados a la incorporaciÃƒÂ³n en el perÃƒÂ­odo prenatal de enfermeras obstetras y parteras, en el ÃƒÂ¡mbito del Sistema de Salud Suplementaria, desde la perspectiva de una operadora de planes de salud como fuente pagadora. Se construyÃƒÂ³ un ÃƒÂ¡rbol de decisiÃƒÂ³n, basado en datos de metaanÃƒÂ¡lisis de la ColaboraciÃƒÂ³n Cochrane, que mostrÃƒÂ³ una reducciÃƒÂ³n del riesgo de parto prematuro en el grupo de gestantes de riesgo habitual, con un seguimiento de enfermeras obstetras y parteras. Se consideraron solo los costes mÃƒÂ©dicos directos, cubiertos por las operadoras de planes de salud para la realizaciÃƒÂ³n de consultas y exÃƒÂ¡menes esenciales, conforme el protocolo vigente del Ministerio de Salud. Se asumiÃƒÂ³ el coste unitario de consulta con cada profesional como iguales, y se aplicÃƒÂ³ un aumento del coste global con exÃƒÂ¡menes prenatales asociado al seguimiento mÃƒÂ©dico, conforme los datos obtenidos en la literatura. Se estimÃƒÂ³ la razÃƒÂ³n de costo-efectividad incremental de -BRL 10.038,43 (economÃƒÂ­a de BRL 10.038,43) por parto prematuro evitado. Este resultado se mostrÃƒÂ³ consistente en los anÃƒÂ¡lisis de sensibilidad, con ahorros asociados a la sustituciÃƒÂ³n, variando de -BRL 2.544,60 hasta -BRL 31.807,46 por parto prematuro evitado. Como conclusiÃƒÂ³n, se observÃƒÂ³ que el cuidado prenatal por parte de enfermeras obstetras y parteras es superior al prestado por mÃƒÂ©dicos obstetras para el desenlace de prevenciÃƒÂ³n de parto prematuro, resultando incluso en un ahorro de recursos.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21152,""
"Identifying evidence for five realist reviews in primary health care: A comparison of search methods","Duddy, Roberts","https://doi.org/10.1002/jrsm.1523","20210921","PubMed","grey literature; information retrieval; literature searching; primary health care; realist review; realist synthesis","The approach to identifying evidence for inclusion in realist reviews differs from that used in 'traditional' systematic reviews. Guidance suggests that realist reviews should be inclusive of diverse data from a range of sources, gathered in iterative searching cycles. Saturation is prioritised over exhaustiveness. Supplementary techniques such as citation snowballing are emphasised as potentially important sources of evidence. This paper describes the processes used to identify evidence in a selection of realist reviews focused on primary health care settings and examines the origin and type of evidence selected for inclusion. Data from five realist reviews were extracted from (a) reviewers' reference management libraries and (b) records kept by review teams. Although all reviews focused on primary health care, they used data from a wide range of document types and research designs, drawing on learning from multiple perspectives and settings, and sourced the documents containing this data in a variety of ways. Systematic searching of academic databases played an important role, supplementary search techniques such as snowballing were used to identify a significant proportion of documents included in the reviews. Our analysis demonstrates the diverse data sources used within realist reviews and the need for flexible, responsive efforts to identify relevant documents. Reviewers and information specialists should devise approaches to data gathering that reflect the individual needs of realist review projects and report these transparently.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21153,""
"The Increasing Centrality of Robotic Technology in the Context of Nursing Care: Bioethical Implications Analyzed through a Scoping Review Approach","Gibelli, Ricci, Sirignano, Turrina, De Leo","https://doi.org/10.1155/2021/1478025","20211011","PubMed","Artificial Intelligence; COVID-19; Humans; Male; Nursing Care; Pandemics; Robotics; SARS-CoV-2","At the dawn of the fourth industrial revolution, the healthcare industry is experiencing a momentous shift in the direction of increasingly pervasive technologization of care. If, up until the 2000s, imagining healthcare provided by robots was a purely futuristic fantasy, today, such a scenario is in fact a concrete reality, especially in some countries, such as Japan, where nursing care is largely delivered by assistive and social robots in both public and private healthcare settings, as well as in home care. This revolution in the context of care, already underway in many countries and destined to take place soon on a global scale, raises obvious ethical issues, related primarily to the progressive dehumanization of healthcare, a process which, moreover, has undergone an important acceleration following the outbreak of the COVID-19 pandemic, which has made it necessary to devise new systems to deliver healthcare services while minimizing interhuman contact. According to leading industry experts, nurses will be the primary users of healthcare robots in the short term. The aim of this study is to provide a general overview, through a scoping review approach, of the most relevant ethical issues that have emerged in the nursing care field in relation to the increasingly decisive role that service robots play in the provision of care. Specifically, through the adoption of the population-concept-context framework, we formulated this broad question: what are the most relevant ethical issues directly impacting clinical practice that arise in nursing care delivered by assistive and social robots? We conducted the review according to the five-step methodology outlined by Arksey and O'Malley. The first two steps, formulating the main research question and carrying out the literature search, were performed based on the population-context-concept (PCC) framework suggested by the Joanna Briggs Institute. Starting from an initial quota of 2,328 scientific papers, we performed an initial screening through a computer system by eliminating duplicated and non-English language articles. The next step consisted of selection based on a reading of the titles and abstracts, adopting four precise exclusion criteria: articles related to a nonnursing environment, articles dealing with bioethical aspects in a marginal way, articles related to technological devices other than robots, and articles that did not treat the dynamics of human-robot relationships in depth. Of the 2,328 titles and abstracts screened, we included 14. The results of the 14 papers revealed the existence of nonnegligible difficulties in the integration of robotic systems within nursing, leading to a lively search for new theoretical ethical frameworks, in which robots can find a place; concurrent with this exploration are the frantic attempts to identify the best ethical design system applicable to robots who work alongside nurses in hospital wards. In the final part of the paper, we also proposed considerations about the Italian nursing context and the legal implications of nursing care provided by robots in light of the Italian legislative panorama. Regarding future perspectives, this paper offers insights regarding robot engagement strategies within nursing.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21154,""
"Comparison of two deep learning image reconstruction algorithms in chest CT images: A task-based image quality assessment on phantom data","Greffier, Frandon, Si-Mohamed, Dabli, Hamard, Belaouni, Akessoul, Besse, Guiu, Beregi","https://doi.org/10.1016/j.diii.2021.08.001","20210908","PubMed","Deep learning image reconstruction; Multidetector computed tomography; Task-based image quality assessment","The purpose of this study was to compare the effect of two deep learning image reconstruction (DLR) algorithms in chest computed tomography (CT) with different clinical indications. Acquisitions on image quality and anthropomorphic phantoms were performed at six dose levels (CTDI<sub>vol</sub>: 10/7.5/5/2.5/1/0.5mGy) on two CT scanners equipped with two different DLR algorithms (TrueFidelity<sup>TM</sup> and AiCE). Raw data were reconstructed using the filtered back-projection (FBP) and the lowest/intermediate/highest DLR levels (L-DLR/M-DLR/H-DLR) of each algorithm. Noise power spectrum, task-based transfer function (TTF) and detectability index (d') were computed: d' modelled detection of a soft tissue mediastinal nodule, ground-glass opacity, or high-contrast pulmonary lesion. Subjective image quality of anthropomorphic phantom images was analyzed by two radiologists. For the L-DLR/M-DLR levels, the noise magnitude was lower with TrueFidelity<sup>TM</sup> than with AiCE from 2.5 to 10 mGy. For H-DLR, noise magnitude was lower with AiCE . For L-DLR and M-DLR, the average NPS spatial frequency (f<sub>av</sub>) values were greater for AiCE except for 0.5 mGy. For H-DLR levels, f<sub>av</sub> was greater for TrueFidelity<sup>TM</sup> than for AiCE. TTF<sub>50%</sub> values were greater with AiCE for the air insert, and lower than TrueFidelity<sup>TM</sup> for the polyethylene insert. From 2.5 to10 mGy, d' was greater for AiCE than for TrueFidelity<sup>TM</sup> for H-DLR for all lesions, but similar for L-DLR and M-DLR. Image quality was rated clinically appropriate for all levels of both algorithms, for dose from 2.5 to 10 mGy, except for L-DLR of AiCE. DLR algorithms reduce the image-noise and improve lesion detectability. Their operations and properties impacted both noise-texture and spatial resolution.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21155,""
"Comments on ""Artificial intelligence applications in restorative dentistry: A systematic review""","Habib, Umer","https://doi.org/10.1016/j.prosdent.2021.08.003","20210908","PubMed","","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21156,""
"Machine Learning-based Prediction Models for Diagnosis and Prognosis in Inflammatory Bowel Diseases: A Systematic Review","Nguyen, Picetti, Dulai, Jairath, Sandborn, Ohno-Machado, Chen, Singh","https://doi.org/10.1093/ecco-jcc/jjab155","20210914","PubMed","CrohnÃ¢â‚¬â„¢s disease; Machine learning; big data; prediction; ulcerative colitis","There is increasing interest in machine learning-based prediction models in inflammatory bowel diseases (IBD). We synthesized and critically appraised studies comparing machine learning vs. traditional statistical models, using routinely available clinical data for risk prediction in IBD. Through a systematic review till January 1, 2021, we identified cohort studies that derived and/or validated machine learning models, based on routinely collected clinical data in patients with IBD, to predict the risk of harboring or developing adverse clinical outcomes, and reported its predictive performance against a traditional statistical model for the same outcome. We appraised the risk of bias in these studies using the Prediction model Risk of Bias ASsessment (PROBAST) tool. We included 13 studies on machine learning-based prediction models in IBD encompassing themes of predicting treatment response to biologics and thiopurines, predicting longitudinal disease activity and complications and outcomes in patients with acute severe ulcerative colitis. The most common machine learnings models used were tree-based algorithms, which are classification approaches achieved through supervised learning. Machine learning models outperformed traditional statistical models in risk prediction. However, most models were at high risk of bias, and only one was externally validated. Machine learning-based prediction models based on routinely collected data generally perform better than traditional statistical models in risk prediction in IBD, though frequently have high risk of bias. Future studies examining these approaches are warranted, with special focus on external validation and clinical applicability.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21157,""
"Experiences With Hearing Health Care Services: What Can We Learn From Online Consumer Reviews?","Manchaiah, Bennett, Ratinaud, Swanepoel","https://doi.org/10.1044/2021_AJA-21-00041","20210913","PubMed","","Objective The aim of this study was to examine experiences of hearing health care services as described in online consumer reviews. Design This study used a cross-sectional design. Online consumer reviews about hearing health care services generated from Google.com to an open-ended question ""Share details of your own experience at this place"" and perceived overall experience (indicated on a 5-point rating scale: ""very good"" to ""very poor"") were extracted from 40 different cities across the United States. The open text contributed a text corpus of 9,622 unique consumer reviews. These responses were analyzed with the cluster analysis approach using an open-source automated text analysis software program, IRaMuTeQ, to identify key themes. Association between clusters and consumer experience ratings as well as consumer metadata (percentage of older adults in the city, region) were examined using the chi-square analysis. Results The majority of consumers appeared satisfied with their hearing health care services, with nearly 95% of consumers reporting ""very good"" and ""good"" on the global experience scale. The analysis of text responses resulted in seven clusters within two domains. Domain 1 (Clinical Processes) included the three clusters: <i>administration processes, perceived benefits,</i> and <i>device acquisition.</i> Domain 2 (Staff and Service Interactions) included the four clusters: <i>clinician communications, staff professionalism</i>, <i>customer service,</i> and <i>provider satisfaction</i>. Content relating to <i>administration processes</i> was associated with overall rating regarding the hearing health care service experience. Consumer's reviews relating to <i>administration processes</i> mostly described negative experiences, and these participants were more inclined to provide poorer overall experience ratings. In addition, city characteristics (i.e., percentage of older adults, region) had bearing toward what elements of hearing health care services are highlighted more in the consumer reviews. Conclusions Consumers comment on a variety of elements when describing their experiences with hearing health care services. Experiences reported in most clusters were generally positive, although some concerns in the ""clinical process"" are associated with lower satisfaction. Employing patient-centered strategies and ensuring patients have good experiences in the areas of concern may help improve both patient experience and their satisfaction. Supplemental Material https://doi.org/10.23641/asha.16455924.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21158,""
"Cognitive Function Assessment and Prediction for Subjective Cognitive Decline and Mild Cognitive Impairment","Li, Yue, Xiao, Liu","https://doi.org/10.1007/s11682-021-00545-1","20210907","PubMed","Alzheimer's disease; MR brain images; Random Forest; Subjective Cognitive Decline","Alzheimer's disease (AD) is a progressive and irreversible neurodegenerative dementia. Recent studies found that subjective cognitive decline (SCD) may be the early clinical precursor that precedes mild cognitive impairment (MCI) for AD. SCD subjects with normal cognition may already have some medial temporal lobe atrophy. Although brain changes by AD have been widely studied in the literature, it is still challenging to investigate the anatomical subtle changes in SCD. This paper proposes a machine learning framework by combination of sparse coding and random forest (RF) to identify the informative imaging biomarkers for assessment and prediction of cognitive functions and their changes in individuals with MCI, SCD and normal control (NC) using magnetic resonance imaging (MRI). First, we compute the volumes from both the regions of interest from whole brain and the subregions of hippocampus and amygdala as the features of structural MRIs. Then, sparse coding is applied to identify the relevant features. Finally, the proximity-based RF is used to combine three sets of volumetric features and establish a regression model for predicting clinical scores. Our method has double feature selections to better explore the relevant features for prediction and is evaluated with the T1-weighted structural MR images from 36 MCI, 112 SCD, 78 NC subjects. The results demonstrate the effectiveness of proposed method. In addition to hippocampus and amygdala, we also found that the fimbria, basal nucleus and cortical nucleus subregions are more important than other regions for prediction of Mini-Mental State Examination (MMSE) and Montreal Cognitive Assessment (MoCA) scores and their changes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21159,""
"Achieving Expert-Level Interpretation of Serum Protein Electrophoresis through Deep Learning Driven by Human Reasoning","Chabrun, Dieu, Ferre, Gaillard, Mery, Chao de la Barca, Taisne, Urbanski, Reynier, Mirebeau-Prunier","https://doi.org/10.1093/clinchem/hvab133","20211004","PubMed","artificial intelligence; deep learning; monoclonal gammopathy; myeloma; neural network; serum protein electrophoresis","Serum protein electrophoresis (SPE) is a common clinical laboratory test, mainly indicated for the diagnosis and follow-up of monoclonal gammopathies. A time-consuming and potentially subjective human expertise is required for SPE analysis to detect possible pitfalls and to provide a clinically relevant interpretation. An expert-annotated SPE dataset of 159Ã¢â‚¬â€°969 entries was used to develop SPECTR (serum protein electrophoresis computer-assisted recognition), a deep learning-based artificial intelligence, which analyzes and interprets raw SPE curves produced by an analytical system into text comments that can be used by practitioners. It was designed following academic recommendations for SPE interpretation, using a transparent architecture avoiding the ""black box"" effect. SPECTR was validated on an external, independent cohort of 70Ã¢â‚¬â€°362 SPEs and challenged by a panel of 9 independent experts from other hospital centers. SPECTR was able to identify accurately both quantitative abnormalities (rÃ¢â‚¬â€°Ã¢â€°Â¥Ã¢â‚¬â€°0.98 for fractions quantification) and qualitative abnormalities [receiver operating characteristic-area under curve (ROC-AUC)Ã¢â‚¬â€°Ã¢â€°Â¥Ã¢â‚¬â€°0.90 for M-spikes, restricted heterogeneity of immunoglobulins, and beta-gamma bridging]. Furthermore, it showed highly accurate at both detecting (ROC-AUCÃ¢â‚¬â€°Ã¢â€°Â¥Ã¢â‚¬â€°0.99) and quantifying (rÃ¢â‚¬â€°=Ã¢â‚¬â€°0.99) M-spikes. It proved highly reproducible and resilient to minor variations and its agreement with human experts was higher (ÃŽÂºÃ¢â‚¬â€°=Ã¢â‚¬â€°0.632) than experts between each other (ÃŽÂºÃ¢â‚¬â€°=Ã¢â‚¬â€°0.624). SPECTR is an algorithm based on artificial intelligence suitable to high-throughput SPEs analyses and interpretation. It aims at improving SPE reproducibility and reliability. It is freely available in open access through an online tool providing fully editable validation assistance for SPE.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21160,""
"Deep Learning Predicts Interval and Screening-detected Cancer from Screening Mammograms: A Case-Case-Control Study in 6369 Women","Zhu, Wolfgruber, Leong, Jensen, Scott, Winham, Sadowski, Vachon, Kerlikowske, Shepherd","https://doi.org/10.1148/radiol.2021203758","20210907","PubMed","","Background The ability of deep learning (DL) models to classify women as at risk for either screening mammography-detected or interval cancer (not detected at mammography) has not yet been explored in the literature. Purpose To examine the ability of DL models to estimate the risk of interval and screening-detected breast cancers with and without clinical risk factors. Materials and Methods This study was performed on 25Ã¢â‚¬â€°096 digital screening mammograms obtained from January 2006 to December 2013. The mammograms were obtained in 6369 women without breast cancer, 1609 of whom developed screening-detected breast cancer and 351 of whom developed interval invasive breast cancer. A DL model was trained on the negative mammograms to classify women into those who did not develop cancer and those who developed screening-detected cancer or interval invasive cancer. Model effectiveness was evaluated as a matched concordance statistic (C statistic) in a held-out 26% (1669 of 6369) test set of the mammograms. Results The C statistics and odds ratios for comparing patients with screening-detected cancer versus matched controls were 0.66 (95% CI: 0.63, 0.69) and 1.25 (95% CI: 1.17, 1.33), respectively, for the DL model, 0.62 (95% CI: 0.59, 0.65) and 2.14 (95% CI: 1.32, 3.45) for the clinical risk factors with the Breast Imaging Reporting and Data System (BI-RADS) density model, and 0.66 (95% CI: 0.63, 0.69) and 1.21 (95% CI: 1.13, 1.30) for the combined DL and clinical risk factors model. For comparing patients with interval cancer versus controls, the C statistics and odds ratios were 0.64 (95% CI: 0.58, 0.71) and 1.26 (95% CI: 1.10, 1.45), respectively, for the DL model, 0.71 (95% CI: 0.65, 0.77) and 7.25 (95% CI: 2.94, 17.9) for the risk factors with BI-RADS density (b rated vs non-b rated) model, and 0.72 (95% CI: 0.66, 0.78) and 1.10 (95% CI: 0.94, 1.29) for the combined DL and clinical risk factors model. The <i>P</i> values between the DL, BI-RADS, and combined model's ability to detect screen and interval cancer were .99, .002, and .03, respectively. Conclusion The deep learning model outperformed in determining screening-detected cancer risk but underperformed for interval cancer risk when compared with clinical risk factors including breast density. Ã‚Â© RSNA, 2021 See also the editorial by Bae and Kim in this issue.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21161,""
"Improved diagnosis of thyroid cancer aided with deep learning applied to sonographic text reports: a retrospective, multi-cohort, diagnostic study","Zhang, Zhang, Li, Pan, Zhao, Feng, Zhao, Wang, Zheng, Yang, Liu, Qin, Zhao, Liu, Li, Zhang, Yang, Zhuo, Zhang, Liu, Gao, Di, Meng, Ji, Yang, Xin, Wei, Jin, Zhang, Wang, Song, Zheng, Gao, Chen, Li","https://doi.org/10.20892/j.issn.2095-3941.2020.0509","20210907","PubMed","Thyroid cancer; deep learning; natural language process; sonographic text report","Large volume radiological text data have been accumulated since the incorporation of electronic health record (EHR) systems in clinical practice. We aimed to determine whether deep natural language processing algorithms could aid radiologists in improving thyroid cancer diagnosis. Sonographic EHR data were obtained from the EHR database. Pathological reports were used as the gold standard for diagnosing thyroid cancer. We developed thyroid cancer diagnosis based on natural language processing (THCaDxNLP) to interpret unstructured sonographic text reports for thyroid cancer diagnosis. We used the area under the receiver operating characteristic curve (AUROC) as the primary metric to measure the performance of the THCaDxNLP. We compared the performance of thyroid ultrasound radiologists aided with THCaDxNLP <i>vs.</i> those without THCaDxNLP using 5 independent test sets. We obtained a total number of 788,129 sonographic radiological reports. The number of thyroid sonographic data points was 132,277, 18,400 of which were thyroid cancer patients. Among the 5 test sets, the numbers of patients per set were 439, 186, 82, 343, and 171. THCaDxNLP achieved high performance in identifying thyroid cancer patients (the AUROC ranged from 0.857-0.932). Thyroid ultrasound radiologists aided with THCaDxNLP achieved significantly higher performances than those without THCaDxNLP in terms of accuracy (93.8% <i>vs.</i> 87.2%; one-sided <i>t</i>-test, adjusted <i>P</i> = 0.003), precision (92.5% <i>vs.</i> 86.0%; <i>P</i> = 0.018), and F1 metric (94.2% <i>vs.</i> 86.4%; <i>P</i> = 0.007). THCaDxNLP achieved a high AUROC for the identification of thyroid cancer, and improved the accuracy, sensitivity, and precision of thyroid ultrasound radiologists. This warrants further investigation of THCaDxNLP in prospective clinical trials.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21162,""
"Utility of machine learning algorithms in degenerative cervical and lumbar spine disease: a systematic review","Stephens, O'Neal, Westrup, Muhammad, McKenzie, Fagg, Smith","https://doi.org/10.1007/s10143-021-01624-z","20210907","PubMed","Artificial intelligence; Cervical spondylotic myelopathy; Degenerative spine disease; Machine learning; Predictive modeling; Systematic review","Machine learning is a rapidly evolving field that offers physicians an innovative and comprehensive mechanism to examine various aspects of patient data. Cervical and lumbar degenerative spine disorders are commonly age-related disease processes that can utilize machine learning to improve patient outcomes with careful patient selection and intervention. The aim of this study is to examine the current applications of machine learning in cervical and lumbar degenerative spine disease. A systematic review was conducted using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. A search of PubMed, Embase, Medline, and Cochrane was conducted through May 31st, 2020, using the following terms: ""artificial intelligence"" OR ""machine learning"" AND ""neurosurgery"" AND ""spine."" Studies were included if original research on machine learning was utilized in patient care for degenerative spine disease, including radiographic machine learning applications. Studies focusing on robotic applications in neurosurgery, navigation, or stereotactic radiosurgery were excluded. The literature search identified 296 papers, with 35 articles meeting inclusion criteria. There were nine studies involving cervical degenerative spine disease and 26 studies on lumbar degenerative spine disease. The majority of studies for both cervical and lumbar spines utilized machine learning for the prediction of postoperative outcomes, with 5 (55.6%) and 15 (61.5%) studies, respectively. Machine learning applications focusing on degenerative lumbar spine greatly outnumber the current volume of cervical spine studies. The current research in lumbar spine also demonstrates more advanced clinical applications of radiographic, diagnostic, and predictive machine learning models.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21163,""
"Reconstruction of the Cytokine Signaling in Lysosomal Storage Diseases by Literature Mining and Network Analysis","Parolo, Tomasoni, Bora, Ramponi, Kaddi, Azer, Domenici, Neves-Zaph, Lombardo","https://doi.org/10.3389/fcell.2021.703489","20210908","PubMed","ASMD; Fabry; Gaucher; cytokine; lysosomal storage diseases; natural language processing; systems biology; text-mining","Lysosomal storage diseases (LSDs) are characterized by the abnormal accumulation of substrates in tissues due to the deficiency of lysosomal proteins. Among the numerous clinical manifestations, chronic inflammation has been consistently reported for several LSDs. However, the molecular mechanisms involved in the inflammatory response are still not completely understood. In this study, we performed text-mining and systems biology analyses to investigate the inflammatory signals in three LSDs characterized by sphingolipid accumulation: Gaucher disease, Acid Sphingomyelinase Deficiency (ASMD), and Fabry Disease. We first identified the cytokines linked to the LSDs, and then built on the extracted knowledge to investigate the inflammatory signals. We found numerous transcription factors that are putative regulators of cytokine expression in a cell-specific context, such as the signaling axes controlled by STAT2, JUN, and NR4A2 as candidate regulators of the monocyte Gaucher disease cytokine network. Overall, our results suggest the presence of a complex inflammatory signaling in LSDs involving many cellular and molecular players that could be further investigated as putative targets of anti-inflammatory therapies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21164,""
"Cost-Effectiveness Analysis of Vedolizumab Compared With Infliximab in Anti-TNF-ÃŽÂ±-NaÃƒÂ¯ve Patients With Moderate-to-Severe Ulcerative Colitis in China","Zhou, Sheng, Guan, Meng, Wang","https://doi.org/10.3389/fpubh.2021.704889","20211026","PubMed","China; cost-effectiveness analysis; infliximab; ulcerative colitis; vedolizumab; Adult; Antibodies, Monoclonal, Humanized; China; Colitis, Ulcerative; Cost-Benefit Analysis; Humans; Infliximab; Tumor Necrosis Factor Inhibitors; Tumor Necrosis Factor-alpha","<b>Objective:</b> To evaluate the cost effectiveness of vedolizumab vs. infliximab in the treatment of anti-tumor necrosis factor-alpha (TNF-ÃŽÂ±)-naÃƒÂ¯ve patients with moderate-to-severe active ulcerative colitis (UC) in China. <b>Methods:</b> The costs and effectiveness of vedolizumab and infliximab in the treatment of anti-TNF-ÃŽÂ± naÃƒÂ¯ve patients with moderate-to-severe active UC were compared using a hybrid decision tree model and a Markov model. From the perspective of the Chinese healthcare system, this study simulated the lifetime health benefits [quality-adjusted life-years (QALYs)] and costs (USD) for patients with UC from the induction phase to the maintenance phase, with an annual discount rate of 5%. The clinical efficacy and transition probability data were based on a previously published network meta-analysis. The health utility, surgical risk, biologic drug discontinuation rate, and mortality were derived from previous literature and the Chinese statistical yearbook. The cost data were based on China's drug purchase and biding platform and the results of a survey sent to clinicians in 18 tertiary hospitals. One-way and probabilistic sensitivity analyses (PSAs) were performed to validate the robustness of the models' assumptions and specific parameter estimates. <b>Results:</b> The results of the base-case analyses showed that compared with infliximab, vedolizumab led to a gain of 0.25 QALYs (9.56 vs. 9.31 QALYs) and was less expensive by $7,349 ($180,138 vs. 187,487), indicating that the use of vedolizumab was a dominant strategy. The results of one-way sensitivity analyses suggested that the annual discount rate and health-state costs had the greatest impact, but the results were otherwise consistent with those of the base-case analyses. The PSAs suggested that vedolizumab had a 98.6% probability of being effective at a threshold of 3 times the gross domestic product (GDP) per capita in China in 2020. <b>Conclusion:</b> Compared with infliximab, vedolizumab appears to be a more cost-effective option in the treatment of anti-TNF-ÃŽÂ± naÃƒÂ¯ve adult patients with moderate-to-severe, active UC in China.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21165,""
"Overall Survival Prediction for Gliomas Using a Novel Compound Approach","Huang, Zhang, Fang, Hong, Su, Lai","https://doi.org/10.3389/fonc.2021.724191","20210908","PubMed","automatic segmentation; deep learning; gliomas; magnetic resonance imaging; overall survival prediction","As a highly malignant tumor, the incidence and mortality of glioma are not optimistic. Predicting the survival time of patients with glioma by extracting the feature information from gliomas is beneficial for doctors to develop more targeted treatments. Magnetic resonance imaging (MRI) is a way to quickly and clearly capture the details of brain tissue. However, manually segmenting brain tumors from MRI will cost doctors a lot of energy, and doctors can only vaguely estimate the survival time of glioma patients, which are not conducive to the formulation of treatment plans. Therefore, automatically segmenting brain tumors and accurately predicting survival time has important significance. In this article, we first propose the NLSE-VNet model, which integrates the Non-Local module and the Squeeze-and-Excitation module into V-Net to segment three brain tumor sub-regions in multimodal MRI. Then extract the intensity, texture, wavelet, shape and other radiological features from the tumor area, and use the CNN network to extract the deep features. The factor analysis method is used to reduce the dimensionality of features, and finally the dimensionality-reduced features and clinical features such as age and tumor grade are combined into the random forest regression model to predict survival. We evaluate the effect on the BraTS 2019 and BraTS 2020 datasets. The average Dice of brain tumor segmentation tasks up to 79% and the average RMSE of the survival predictive task is as low as 311.5. The results indicate that the method in this paper has great advantages in segmentation and survival prediction of gliomas.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21166,""
"Magnetic Resonance Imaging Studies on Acupuncture Therapy in Depression: A Systematic Review","Zhang, Wu, Nie, Zhuo, Li, Hu, Xu, Yu","https://doi.org/10.3389/fpsyt.2021.670739","20210908","PubMed","acupuncture; depression; magnetic resonance imaging; systematic review; treatment","Accumulating studies had been performed using magnetic resonance imaging (MRI) to understand the neural mechanism of acupuncture therapy for depression. However, inconsistencies remain due to differences in research designs and MRI analytical methods. Therefore, we aim to summarize the current MRI research and provide useful information for further research by identifying papers published in English and Chinese about MRI studies on acupuncture for depression up to November 2020. A total of 22 studies met the inclusion criteria, including 810 depression patients and 416 health controls (HCs). The applied designs of these studies are mainly random control trial and pre-post designs. The MRI analytical methods are mainly (fractional) amplitude of low-frequency fluctuation (fALFF/ALFF) and functional connectivity (FC), whereas a small subset of studies used voxel-based morphometry (VBM) and diffusion tensor imaging (DTI). The most consistent functional MRI (fMRI) results showed increased <i>N</i>-acetylaspartate/creatine (NAA/Cr) ratios, increased ALFF in the right precuneus, decreased ALFF in the inferior frontal gyrus (IFG), and increased FC of the anterior cingulate cortex (ACC). In contrast, no significant neurological changes were identified in any of the DTI or VBM studies. However, clear, reliable conclusions cannot be drawn due to the use of different designs, analytical methods, seed points selected, types of depression, acupuncture points, and so on. Improved report specifications, well-designed studies, consistent analytical methods, and larger sample sizes will enable the field to better elucidate the underlying mechanisms of acupuncture in depressed patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21167,""
"Predicting the Emergence of Major Neurocognitive Disorder Within Three Months After a Stroke","Aamodt, Schellhorn, Stage, Sanjay, Logan, Svaldi, Apostolova, Saltvedt, Beyer","https://doi.org/10.3389/fnagi.2021.705889","20210908","PubMed","MRI; dementia; neurocognitive disorders; prediction; rapid onset; stroke","<b>Background:</b> Neurocognitive disorder (NCD) is common after stroke, with major NCD appearing in about 10% of survivors of a first-ever stroke. We aimed to classify clinical- and imaging factors related to rapid development of major NCD 3 months after a stroke, so as to examine the optimal composition of factors for predicting rapid development of the disorder. We hypothesized that the prediction would mainly be driven by neurodegenerative as opposed to vascular brain changes. <b>Methods:</b> Stroke survivors from five Norwegian hospitals were included from the ""Norwegian COgnitive Impairment After STroke"" (Nor-COAST) study. A support vector machine (SVM) classifier was trained to distinguish between patients who developed major NCD 3 months after the stroke and those who did not. Potential predictor factors were based on previous literature and included both vascular and neurodegenerative factors from clinical and structural magnetic resonance imaging findings. Cortical thickness was obtained via FreeSurfer segmentations, and volumes of white matter hyperintensities (WMH) and stroke lesions were semi-automatically gathered using FSL BIANCA and ITK-SNAP, respectively. The predictive value of the classifier was measured, compared between classifier models and cross-validated. <b>Results:</b> Findings from 227 stroke survivors [age = 71.7 (11.3), males = (56.4%), stroke severity NIHSS = 3.8 (4.8)] were included. The best predictive accuracy (AUC = 0.876) was achieved by an SVM classifier with 19 features. The model with the fewest number of features that achieved statistically comparable accuracy (AUC = 0.850) was the 8-feature model. These features ranked by their weighting were; stroke lesion volume, WMH volume, left occipital and temporal cortical thickness, right cingulate cortical thickness, stroke severity (NIHSS), antiplatelet medication intake, and education. <b>Conclusion:</b> The rapid (&lt;3 months) development of major NCD after stroke is possible to predict with an 87.6% accuracy and seems dependent on both neurodegenerative and vascular factors, as well as aspects of the stroke itself. In contrast to previous literature, we also found that vascular changes are more important than neurodegenerative ones. Although possible to predict with relatively high accuracy, our findings indicate that the development of rapid onset post-stroke NCD may be more complex than earlier suggested.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21168,""
"Progress of Acupuncture Therapy in Diseases Based on Magnetic Resonance Image Studies: A Literature Review","Zhang, Li, Li, Li, Hu, Xu, Yu","https://doi.org/10.3389/fnhum.2021.694919","20210908","PubMed","MRI; acupuncture; diseases; mechanism; review","The neural mechanisms of acupuncture are not well-understood. Over the past decades, an increasing number of studies have used MRI to investigate the response of the brain to acupuncture. The current review aims to provide an update on acupuncture therapy in disease. The PubMed, Embase, Web of Science, and Cochrane Library databases were searched from inception to January 31, 2021. Article selection and data extraction were conducted by two review authors. A total of 107 publications about MRI in acupuncture were included, the collective findings of which were as follows: (1) stroke and GB34 (Yanglingquan) are the most studied disease and acupoint. Related studies suggested that the mechanism of acupuncture treatment for stroke may associate with structural and functional plasticity, left and right hemispheres balance, and activation of brain areas related to movement and cognition. GB34 is mainly used in stroke and Parkinson's disease, which mainly activates brain response in the premotor cortex, the supplementary motor area, and the supramarginal gyrus; (2) resting-state functional MRI (rs-fMRI) and functional connectivity (FC) analysis are the most frequently used approaches; (3) estimates of efficacy and brain response to acupuncture depend on the type of sham acupuncture (SA) used for comparison. Brain processing after acupuncture differs between patients and health controls (HC) and occurs mainly in disorder-related areas. Factors that influence the effect of acupuncture include depth of needling, number and locations of acupoints, and <i>deqi</i> and expectation effect, each contributing to the brain response. While studies using MRI have increased understanding of the mechanism underlying the effects of acupuncture, there is scope for development in this field. Due to the small sample sizes, heterogeneous study designs, and analytical methods, the results were inconsistent. Further studies with larger sample sizes, careful experimental design, multimodal neuroimaging techniques, and standardized methods should be conducted to better explain the efficacy and specificity of acupuncture, and to prepare for accurate efficacy prediction in the future.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21169,""
"Applying a novel approach to scoping review incorporating artificial intelligence: mapping the natural history of gonorrhoea","Whelan, Ghoniem, MÃƒÂ©doc, Apicella, Beck","https://doi.org/10.1186/s12874-021-01367-x","20210929","PubMed","Artificial intelligence; Clinical outcomes; Co-clustering; Gonorrhoea; Health problems; N. gonorrhoeae; Natural history; Natural language processing; Scoping review; Visual text mining; Artificial Intelligence; Gonorrhea; Humans; Infant, Newborn; MEDLINE; Mass Screening","Systematic and scoping literature searches are increasingly resource intensive. We present the results of a scoping review which combines the use of a novel artificial-intelligence-(AI)-assisted Medline search tool with two other 'traditional' literature search methods. We illustrate this novel approach with a case study to identify and map the range of conditions (clinical presentations, complications, coinfections and health problems) associated with gonorrhoea infection. To fully characterize the range of health outcomes associated with gonorrhoea, we combined a high yield preliminary search with a traditional systematic search, then supplemented with the output of a novel AI-assisted Medline search tool based on natural language processing methods to identify eligible literature. We identified 189 health conditions associated with gonorrhoea infection of which: 53 were identified through the initial 'high yield' search; 99 through the systematic search; and 124 through the AI-assisted search. These were extracted from 107 unique references and 21 International Statistical Classification of Diseases and Related Health Problems Ninth and Tenth Revision (ICD 9/10) or Read codes. Health conditions were mapped to the urogenital tract (nÃ‚Â =Ã¢â‚¬â€°86), anorectal tract (nÃ‚Â =Ã¢â‚¬â€°6) oropharyngeal tract (nÃ‚Â =Ã¢â‚¬â€°5) and the eye (nÃ‚Â =Ã¢â‚¬â€°14); and other conditions such as systemic (nÃ‚Â =Ã¢â‚¬â€°61) and neonatal conditions (nÃ‚Â =Ã¢â‚¬â€°7), psychosocial associations (nÃ‚Â =Ã¢â‚¬â€°3), and co-infections (nÃ¢â‚¬â€°=Ã¢â‚¬â€°7). The 107 unique references attained a Scottish Intercollegiate Guidelines Network (SIGN) score of Ã¢â€°Â¥2++ (nÃ‚Â =Ã¢â‚¬â€°2), 2+ (14 [13%]), 2- (30 [28%]) and 3 (45 [42%]), respectively. The remaining papers (nÃ‚Â =Ã¢â‚¬â€°16) were reviews. Through AI screening of Medline, we captured - titles, abstracts, case reports and case series related to rare but serious health conditions related to gonorrhoea infection. These outcomes might otherwise have been missed during a systematic search. The AI-assisted search provided a useful addition to traditional/manual literature searches especially when rapid results are required in an exploratory setting.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21170,""
"Clinical Score and Machine Learning-Based Model to Predict Diagnosis of Primary Aldosteronism in Arterial Hypertension","Buffolo, Burrello, Burrello, Heinrich, Adolf, MÃƒÂ¼ller, Chen, Forestiero, Sconfienza, Tetti, Veglio, Williams, Mulatero, Monticone","https://doi.org/10.1161/HYPERTENSIONAHA.121.17444","20211014","PubMed","aldosterone; hypertension; kidney; machine learning; prevalence","[Figure: see text].","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21171,""
"Portable technologies for digital phenotyping of bipolar disorder: A systematic review","Saccaro, Amatori, Cappelli, Mazziotti, Dell'Osso, Rutigliano","https://doi.org/10.1016/j.jad.2021.08.052","20211101","PubMed","Audiovisual recordings; Bipolar disorder; Machine learning; Smartphone apps; Wearable sensors; Artificial Intelligence; Bipolar Disorder; Humans; Self-Assessment; Wearable Electronic Devices","Bias-prone psychiatric interviews remain the mainstay of bipolar disorder (BD) assessment. The development of digital phenotyping promises to improve BD management. We present a systematic review of the evidence about the use of portable digital devices for the identification of BD, BD types and BD mood states and for symptom assessment. We searched Web of Knowledge<sup>SM</sup>, Scopus Ã‚Â®, IEEE Xplore, and ACM Digital Library databases (until 5/1/2021) for articles evaluating the use of portable/wearable digital devices, such as smartphone apps, wearable sensors, audio and/or visual recordings, and multimodal tools. The protocol is registered in PROSPERO (CRD42020200086). We included 62 studies (2325 BD; 724 healthy controls, HC): 27 using smartphone apps, either for recording self-assessments (nÃ‚Â =Ã‚Â 10) or for passively gathering metadata (nÃ‚Â =Ã‚Â 7) or both (nÃ‚Â =Ã‚Â 10); 15 using wearable sensors for physiological parameters; 17 analysing audio and/or video recordings; 3 using multiple technologies. Two thirds of the included studies applied artificial intelligence (AI)-based approaches. They achieved fair to excellent classification performances. The included studies had small sample sizes and marked heterogeneity. Evidence of overfitting emerged, limiting generalizability. The absence of clear guidelines about reporting classification performances, with no shared standard metrics, makes results hardly interpretable and comparable. New technologies offer a noteworthy opportunity to BD digital phenotyping with objectivity and high granularity. AI-based models could deliver important support in clinical decision-making. Further research and cooperation between different stakeholders are needed for addressing methodological, ethical and socio-economic considerations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21172,""
"Acceptability, usefulness, and satisfaction with a web-based video-tailored physical activity intervention: The TaylorActive randomized controlled trial","Schoeppe, Duncan, Plotnikoff, Mummery, Rebar, Alley, To, Short, Vandelanotte","https://doi.org/10.1016/j.jshs.2021.09.001","20211030","PubMed","Online; Physical activity; Process evaluation; Program; Video-based","This study examined the usage, acceptability, usability, perceived usefulness, and satisfaction of a web-based video-tailored physical activity (PA) intervention (TaylorActive) in adults. In 2013-2014, 501 Australian adults aged 18+ years were randomized into a video-tailored intervention, text-tailored intervention, or control group. Over 3 months, the intervention groups received access to 8 sessions of personally tailored PA advice delivered via the TaylorActive website. Only the delivery method differed between the intervention groups: video-tailored vs. text-tailored. Google Analytics and telephone surveys conducted at post intervention (3 months) were used to assess intervention usage, acceptability, usability, perceived usefulness, and satisfaction. Quantitative and qualitative process data were analyzed using descriptive statistics and thematic content analysis. Of 501 recruited adults, 259 completed the 3-month post-intervention survey (52% retention). Overall, usage of the TaylorActive website with respect to number of website visits, intervention sessions, and action plans completed was modest in both the video-tailored (7.6 Ã‚Â± 7.2 visits, mean Ã‚Â± SD) and text-tailored (7.3 Ã‚Â± 5.4 visits) groups with no significant between-group differences. The majority of participants in all groups used the TaylorActive website less than once in 2 weeks (66.7% video-tailored, 62.7% text-tailored, 87.5% control; p &lt; 0.001). Acceptability was rated mostly high in all groups and, in some instances, significantly higher in the intervention groups compared to the control group (p &lt; 0.01). Usability was also rated high; mean Systems Usability Scores were 77.3 (video-tailored), 75.7 (text-tailored), and 74.1 (control) with no significant between-group differences. Perceived usefulness of the TaylorActive intervention was low, though mostly rated higher in the intervention groups compared to the control group (p &lt; 0.01). Satisfaction with the TaylorActive website was mixed. Participants in both intervention groups liked its ease of use, personalized feedback, and tracking of progress, but also found completing action plans and survey questions for each session repetitive and tedious. Providing personally tailored PA advice on its own (through either video or text) is likely insufficient to ensure good retention, usage, perceived usefulness, and satisfaction with a web-based PA intervention. Strategies to address this may include the incorporation of additional intervention components such as activity trackers, social interactions, gamification, as well as the use of advanced artificial intelligence and machine learning technologies to allow more personalized dialogue with participants.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21173,""
"Enhancing adversarial defense for medical image analysis systems with pruning and attention mechanism","Chen, Zhao, Chen","https://doi.org/10.1002/mp.15208","20210914","PubMed","adversarial examples; attention mechanism; defense; medical image model; prune","Deep learning has achieved impressive performance across a variety of tasks, including medical image processing. However, recent research has shown that deep neural networks (DNNs) are susceptible to small adversarial perturbations in the image, which raise safety concerns about the deployment of these systems in clinical settings. To improve the defense of the medical imaging system against adversarial examples, we propose a new model-based defense framework for medical image DNNs model equipped with pruning and attention mechanism module based on the analysis of the reason why existing medical image DNNs models are vulnerable to attacks from adversarial examples is that complex biological texture of medical imaging and overparameterized medical image DNNs model. Three benchmark medical image datasets have verified the effectiveness of our method in improving the robustness of medical image DNNs models. In the chest X-ray datasets, our defending method can even achieve up 77.18% defense rate for projected gradient descent attack and 69.49% defense rate for DeepFool attack. And through ablation experiments on the pruning module and the attention mechanism module, it is verified that the use of pruning and attention mechanism can effectively improve the robustness of the medical image DNNs model. Compared with the existing model-based defense methods proposed for natural images, our defense method is more suitable for medical images. Our method can be a general strategy to approach the design of more explainable and secure medical deep learning systems, and can be widely used in various medical image tasks to improve the robustness of medical models.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21174,""
"Risk, Mechanisms and Implications of Asthma-Associated Infectious and Inflammatory Multimorbidities (AIMs) among Individuals With Asthma: a Systematic Review and a Case Study","Kwon, Wi, Seol, Park, King, Ryu, Sohn, Liu, Juhn","https://doi.org/10.4168/aair.2021.13.5.697","20210916","PubMed","Asthma; autoimmunity; comorbidity; disease; epidemiology; infection; inflammation; multimorbidity; risk","Our prior work and the work of others have demonstrated that asthma increases the risk of a broad range of both respiratory (<i>e.g.</i>, pneumonia and pertussis) and non-respiratory (<i>e.g.</i>, zoster and appendicitis) infectious diseases as well as inflammatory diseases (<i>e.g.</i>, celiac disease and myocardial infarction [MI]), suggesting the systemic disease nature of asthma and its impact beyond the airways. We call these conditions asthma-associated infectious and inflammatory multimorbidities (AIMs). At present, little is known about why some people with asthma are at high-risk of AIMs, and others are not, to the extent to which controlling asthma reduces the risk of AIMs and which specific therapies mitigate the risk of AIMs. These questions represent a significant knowledge gap in asthma research and unmet needs in asthma care, because there are no guidelines addressing the identification and management of AIMs. This is a systematic review on the association of asthma with the risk of AIMs and a case study to highlight that 1) AIMs are relatively under-recognized conditions, but pose major health threats to people with asthma; 2) AIMs provide insights into immunological and clinical features of asthma as a systemic inflammatory disease beyond a solely chronic airway disease; and 3) it is time to recognize AIMs as a distinctive asthma phenotype in order to advance asthma research and improve asthma care. An improved understanding of AIMs and their underlying mechanisms will bring valuable and new perspectives improving the practice, research, and public health related to asthma.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21175,""
"Mining Employees Safety and the Application of Information Technology in Coal Mining: Review","Yang, Birhane, Zhu, Geng","https://doi.org/10.3389/fpubh.2021.709987","20211026","PubMed","coal mining accidents; coal mining safety; human behavior; human error; intelligent mining; internet of things; mining environmental impact; mining injuries; Accidents, Occupational; Coal; Coal Mining; Humans; Information Technology; Safety Management","<b>Background:</b> Though the introduction of modern safer underground coal mining methods and automation, mine accidents still cause loss of lives, time, and money. This paper aims to analyze in detail the causes of safety and environmental issues in the coal mining industry, as well as the impact of IoT on coal mining. <b>Method:</b> A systematic review was conducted. A comprehensive search involving Web of Science, Google Scholar, Scopus, and Science direct databases was conducted using a combination of the following keywords: mining accidents, coal mining injuries, human error in mining, intelligent mining, etc. The inclusion criteria: (1) the study was published between January 2000 and June 2020; (2) the participants were coal mining employees/coal mining accidents and accidents were work-related; (3) the study focused on identifying causes of coal mining safety issues or accidents, factors that influence unsafe behaviors and accidents in coal mining, coal mining rescue management, coal mining rescue plan, coal mining environmental impact, mining information technology, intelligent mining; (4) the study was published in a refereed journal; (5) the study was written in English. In this paper, articles were retained if they were original studies. <b>Results:</b> A total of 59 papers were reviewed in detail. Safety issues in coal mining and the impact of IoT were identified and categorized into three main factors: general safety issues, environmental factors, and mining information technology. Recently, the coal mines had become mechanized and automated leading to improved safety, productivity, and cost. However, Human factors such as lack of appropriate skill, lack of experience, perceptual error, and unsafe behaviors, as well as lack of detailed emergency rescue plan were the leading causes of coal mining injuries. Furthermore, abandoned mining sites' carbon emission is greater than active sites. <b>Conclusion:</b> The study recommends further research to be conducted using different psychological models to understand human factors and design effective safety management systems. And the environmental impact of abandoned mining sites should be given due attention.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21176,""
"Characterization of Postanoxic Tonic Eyelid Opening: A Poorly Recognized Prognostic Sign","Alsallom, Shaker, Newey, Hantus, Punia","https://doi.org/10.1212/CPJ.0000000000000990","20210907","PubMed","","Postanoxic myoclonus is a known poor prognostic sign, and other postanoxic spontaneous movements have been reported but poorly described. We aim to describe the electroclinical phenomenon of postanoxic eyelid openings in context of its possible prognostic value. We collected clinical data on postcardiac arrest patients with suspicious eyelid movements noted on continuous EEG monitoring. The eyelid movements captured on the video were correlated with the EEG findings and final clinical outcome. Neuroimaging data were reviewed when available. We also conducted a thorough literature review on this topic. A total of 10 patients (5 females) with average age of 56.1 (Ã‚Â±14.4) years were included. The mean cardiopulmonary resuscitation duration was 18.9 (Ã‚Â±11.3) minutes. Postanoxic eyelid-opening movements occurred at variable intervals (0.5-570 seconds) in each individual. Close examination of eyelid opening (available in 6 patients) revealed them to be tonic movements, lasting an average of 3 (Ã‚Â±0.8) seconds and always succeeded the onset of burst of EEG activity in a burst-suppression background. This is a transient phenomenon, lasting a median duration of 30 (interquartile range 7.75-36) hours. MRI findings in 3 patients demonstrated diffuse cortical ischemic injury with relative sparing of the brainstem. All patients died within 2-7 days following cardiac arrest. Contrary to previous descriptions, the postanoxic tonic eyelid openings (PATEO) are repetitive but nonperiodic, nonmyoclonic movements. Their close and specific temporal correlation with the burst of EEG activity suggests that this could be considered an ictal phenomenon requiring an intact midbrain based on MRI findings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21177,""
"Models of Student Engagement in Music Education Classroom in Higher Education","Wang","https://doi.org/10.3389/fpsyg.2021.738207","20210907","PubMed","higher education; learning; models of student; music education; student engagement","Higher education is undergoing a paradigm move from passive learning toward active learning. Student engagement is assumed to be a significant criterion and gauge for the quality of the student skill for higher education; however, in the literature, the term engagement remains to be vague to delineate, and it is construed in different ways. Since institutions accentuate preparing alumnae for life further than their education, student engagement has turned out to be a priority for music education, and within the last 5 years, the attention was drawn to ""Students as Partners"" as a response to ""students as consumers"" construct manipulating higher education theory. Concerning the literature review, the meaning of student engagement, determinants influencing it, and its merits are brought together. In conclusion, the implications of student engagement are presented, and new guidelines for future research are depicted.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21178,""
"Using Interpersonal Dimensions of Personality and Personality Pathology to Examine Momentary and Idiographic Patterns of Alliance Rupture","Luo, Hopwood, Good, Turchan, Thomas, Levendosky","https://doi.org/10.3389/fpsyg.2021.711109","20210907","PubMed","Alternative Model of Personality Disorders (AMPD); alliance rupture; idiographic analysis; interpersonal circumplex model; momentary processes; psychotherapy process","The Alternative Model of Personality Disorders (AMPD) integrates several theoretical models of personality functioning, including interpersonal theory. The interpersonal circumplex dimensions of warmth and dominance can be conceptualized as traits similar to those in AMPD Criterion B, but interpersonal theory also offers dynamic hypotheses about how these variables that change from moment to moment, which help to operationalize some of the processes alluded to in AMPD Criterion A. In the psychotherapy literature, dynamic interpersonal behaviors are thought to be critical for identifying therapeutic alliance ruptures, yet few studies have examined moment-to-moment interpersonal behaviors that are associated with alliance ruptures at an idiographic level. The current study examined the concurrent and cross-lagged relationships between interpersonal behaviors and alliance ruptures within each session in the famous Gloria films (""Three Approaches to Psychotherapy""). Interpersonal behaviors (warmth and dominance) as well as alliance ruptures (i.e., withdrawal and confrontation) were calculated at half minute intervals for each dyad. We identified distinct interpersonal patterns associated with alliance ruptures for each session: Gloria (patient)'s warmth was positively related with withdrawal ruptures concurrently in the session with Carl Rogers; Gloria's dominance and coldness were related with increased confrontation ruptures in the session with Fritz Perls concurrently, while her coldness was also predicted by confrontation ruptures at previous moments; lastly, both Gloria's dominance and Albert Ellis's submissiveness were positively related with withdrawal ruptures. These interpersonal patterns demonstrated the promise of using AMPD dimensions to conceptualize momentary interpersonal processes related to therapy ruptures, as well as the clinical importance of attuning to repetitive, dyad-specific interpersonal cues of ruptures within each session.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21179,""
"Relationship Between Interpersonal Depressive Symptoms and Reduced Amygdala Volume in People with Multiple Sclerosis: Considerations for Clinical Practice","Haines, Butler, Stuckey, Hester, Grech","https://doi.org/10.7224/1537-2073.2020-015","20210907","PubMed","Amygdala; Clinical practice; Depression; Interpersonal; Multiple sclerosis (MS)","The lifetime prevalence of depression in people with multiple sclerosis (MS) is approximately 50% compared with around 15% in the general population. There is a relationship between depression and quality of life in people with MS and evidence that depression may contribute to disease progression. This cross-sectional pilot study assessed the association between depression and regional brain atrophy, including amygdala and hippocampal volume. Forty-nine participants with MS recruited through a hospital MS clinic were administered the Center for Epidemiological Studies Depression Scale Revised (CESD-R) to investigate whether higher endorsements on the items depressive affect and interpersonal symptoms were associated with volumetric magnetic resonance imaging measurements of hippocampal and amygdala atrophy. Regression analysis revealed an association between depression-related interpersonal symptoms and right amygdala volume. No association was found between depression and hippocampal volume. These results provide preliminary support for a unilateral, biologically based relationship between the right amygdala and characteristic interpersonal depressive symptoms expressed by people with MS and add to the growing body of literature implicating regional brain atrophy in MS-associated depression. Given that the interpersonal subcomponent of the CESD-R measures social functioning, and the neural networks in the amygdala are known to be implicated in processing social stimuli, this research suggests that targeted diagnosis and treatments for depression in people with MS may be particularly beneficial. Further confirmatory research of this relationship is required.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21180,""
"Machine Learning and Deep Learning Based Computational Approaches in Automatic Microorganisms Image Recognition: Methodologies, Challenges, and Developments","Rani, Kotwal, Manhas, Sharma, Sharma","https://doi.org/10.1007/s11831-021-09639-x","20210907","PubMed","","Microorganisms or microbes comprise majority of the diversity on earth and are extremely important to human life. They are also integral to processes in the ecosystem. The process of their recognition is highly tedious, but very much essential in microbiology to carry out different experimentation. To overcome certain challenges, machine learning techniques assist microbiologists in automating the entire process. This paper presents a systematic review of research done using machine learning (ML) and deep leaning techniques in image recognition of different microorganisms. This review investigates certain research questions to analyze the studies concerning image pre-processing, feature extraction, classification techniques, evaluation measures, methodological limitations and technical development over a period of time. In addition to this, this paper also addresses the certain challenges faced by researchers in this field. Total of 100 research publications in the chronological order of their appearance have been considered for the time period 1995-2021. This review will be extremely beneficial to the researchers due to the detailed analysis of different methodologies and comprehensive overview of effectiveness of different ML techniques being applied in microorganism image recognition field.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21181,""
"Obstacles and features of health information systems: A systematic literature review","Tummers, Tekinerdogan, Tobi, Catal, Schalk","https://doi.org/10.1016/j.compbiomed.2021.104785","20211011","PubMed","Electronic health record; Features of HIS; Health information system; Obstacles to HIS; State-of-the-art; Systematic literature review; Delivery of Health Care; Health Information Systems","Currently many healthcare systems are supported by an increasing set of Health Information Sys-tems (HISs), which assist the activities for multiple stakeholders. The literature on HISs is, however, fragmented and a solid overview of the current state of HISs is missing. This impedes the understanding and characterization of the required HISs for the healthcare domain. In this article, we present the results of a Systematic Literature Review (SLR) that identifies the HISs, their domains, stakeholders, features, and obstacles. In the SLR, we identified 1340 papers from which we selected 136 studies, on which we performed a full-text analysis. After the synthesis of the data, we were able to report on 33 different domains, 41 stakeholders, 73 features, and 69 obstacles. We discussed how these domains, features, and obstacles interact with each other and presented suggestions to overcome the identified obstacles. We recognized five groups of obstacles: technical problems, operational functionality, maintenance &amp; support, usage problems, and quality problems. Obstacles from all groups require to be solved to pave the way for further research and application of HISs. This study shows that there is a plentitude of HISs with unique features and that there is no consensus on the requirements and types of HISs in the literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21182,""
"Magnetic Resonance Imaging Phenotypes of Breast Cancer Molecular Subtypes: A Systematic Review","Ab Mumin, Ramli Hamid, Wong, Rahmat, Ng","https://doi.org/10.1016/j.acra.2021.07.017","20210905","PubMed","Dynamic contrast-enhanced; Invasive breast cancer; Magnetic resonance imaging; Molecular subtypes","Magnetic resonance imaging (MRI) is the most sensitive imaging modality in detecting breast cancer. The purpose of this systematic review is to investigate the role of human extracted MRI phenotypes in classifying molecular subtypes of breast cancer. We performed a literature search of published articles on the application of MRI phenotypic features in invasive breast cancer molecular subtype classifications by radiologists' interpretation on Medline Complete, Pubmed, and Google scholar from 1st January 2000 to 31st March 2021. Of the 1403 literature identified, 42 fulfilled the inclusion criteria. All studies were case-controlled, retrospective study and research-based. The majority of the studies assessed the MRI features using American College of Radiology- Breast Imaging Reporting and Data System (ACR-BIRADS) classification and using dynamic contrast-enhanced (DCE) kinetic features, Apparent Diffusion Coefficient (ADC) values, and T2 sequence. Most studies divided invasive breast cancer into 4 main subtypes, luminal A, luminal B, HER2, and triple-negative (TN) cancers, and used 2 readers. We present a summary of the radiologists' extracted breast MRI phenotypical features and their correlating breast cancer subtypes classifications. The characteristic features are morphology, enhancement kinetics, and T2 signal intensity. We found that the TN subtype has the most distinctive MRI features compared to the other subtypes and luminal A and B have many similar features. The MRI features which are predictive of each subtype are the morphology, internal enhancement features, and T2 signal intensity, predominantly between TN and the rest. Radiologists' visual interpretation of some of MRI features may offer insight into the respective invasive breast cancer molecular subtype. However, current evidence are still limited to ""suggestive"" features instead of a diagnostic standard.Ã‚ Further research is recommended to explore this potential application, for example, by augmentation of radiologists' visual interpretation by artificial intelligence.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21183,""
"Enhancing Biomedical Relation Extraction with Transformer Models using Shortest Dependency Path Features and Triplet Information","Kanjirangat, Rinaldi","https://doi.org/10.1016/j.jbi.2021.103893","20211020","PubMed","BioBERT; Inter-sentential; Intra-sentential; Relation extraction; Shortest dependency paths; Triplets; Language; Natural Language Processing; Research Design","Entity relation extraction plays an important role in the biomedical, healthcare, and clinical research areas. Recently, pre-trained models based on transformer architectures and their variants have shown remarkable performances in various natural language processing tasks. Most of these variants were based on slight modifications in the architectural components, representation schemes and augmenting data using distant supervision methods. In distantly supervised methods, one of the main challenges is pruning out noisy samples. A similar situation can arise when the training samples are not directly available but need to be constructed from the given dataset. The BioCreative V Chemical Disease Relation (CDR) task provides a dataset that does not explicitly offer mention-level gold annotations and hence replicates the above scenario. Selecting the representative sentences from the given abstract or document text that could convey a potential entity relationship becomes essential. Most of the existing methods in literature propose to either consider the entire text or all the sentences which contain the entity mentions. This could be a computationally expensive and time consuming approach. This paper presents a novel approach to handle such scenarios, specifically in biomedical relation extraction. We propose utilizing the Shortest Dependency Path (SDP) features for constructing data samples by pruning out noisy information and selecting the most representative samples for model learning. We also utilize triplet information in model learning using the biomedical variant of BERT, viz., BioBERT. The problem is represented as a sentence pair classification task using the sentence and the entity-relation pair as input. We analyze the approach on both intra-sentential and inter-sentential relations in the CDR dataset. The proposed approach that utilizes the SDP and triplet features presents promising results, specifically on the inter-sentential relation extraction task. We make the code used for this work publicly available on Github.<sup>1</sup>.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21184,""
"Relation extraction from DailyMed structured product labels by optimally combining crowd, experts and machines","Shingjergji, Celebi, Scholtes, Dumontier","https://doi.org/10.1016/j.jbi.2021.103902","20211020","PubMed","Crowdsourcing; Drug data quality; Drug indications; Drug repositioning; Drug-disease relation classification; Human-in-the-loop; Machine learning; Programmatic labeling; Weak supervision; Crowdsourcing; Drug Repositioning; Machine Learning","The effectiveness of machine learning models to provide accurate and consistent results in drug discovery and clinical decision support is strongly dependent on the quality of the data used. However, substantive amounts of open data that drive drug discovery suffer from a number of issues including inconsistent representation, inaccurate reporting, and incomplete context. For example, databases of FDA-approved drug indications used in computational drug repositioning studies do not distinguish between treatments that simply offer symptomatic relief from those that target the underlying pathology. Moreover, drug indication sources often lack proper provenance and have little overlap. Consequently, new predictions can be of poor quality as they offer little in the way of new insights. Hence, work remains to be done to establish higher quality databases of drug indications that are suitable for use in drug discovery and repositioning studies. Here, we report on the combination of weak supervision (i.e., programmatic labeling and crowdsourcing) and deep learning methods for relation extraction from DailyMed text to create a higher quality drug-disease relation dataset. The generated drug-disease relation data shows a high overlap with DrugCentral, a manually curated dataset. Using this dataset, we constructed a machine learning model to classify relations between drugs and diseases from text into four categories; treatment, symptomatic relief, contradiction, and effect, exhibiting an improvement of 15.5% with Bi-LSTM (F1 score of 71.8%) over the best performing discrete method. Access to high quality data is crucial to building accurate and reliable drug repurposing prediction models. Our work suggests how the combination of crowds, experts, and machine learning methods can go hand-in-hand to improve datasets and predictive models.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21185,""
"Artificial intelligence and diabetes technology: A review","Gautier, Ziegler, Gerber, Campos-NÃƒÂ¡ÃƒÂ±ez, Patek","https://doi.org/10.1016/j.metabol.2021.154872","20211019","PubMed","Artificial intelligence; Automation; Diabetes; Diagnosis; Machine learning; Prognosis","Artificial intelligence (AI) is widely discussed in the popular literature and is portrayed as impacting many aspects of human life, both in and out of the workplace. The potential for revolutionizing healthcare is significant because of the availability of increasingly powerful computational platforms and methods, along with increasingly informative sources of patient data, both in and out of clinical settings. This review aims to provide a realistic assessment of the potential for AI in understanding and managing diabetes, accounting for the state of the art in the methodology and medical devices that collect data, process data, and act accordingly. Acknowledging that many conflicting definitions of AI have been put forth, this article attempts to characterize the main elements of the field as they relate to diabetes, identifying the main perspectives and methods that can (i) affect basic understanding of the disease, (ii) affect understanding of risk factors (genetic, clinical, and behavioral) of diabetes development, (iii) improve diagnosis, (iv) improve understanding of the arc of disease (progression and personal/societal impact), and finally (v) improve treatment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21186,""
"The evolution of image guidance in robotic-assisted laparoscopic prostatectomy (RALP): a glimpse into the future","Makary, van Diepen, Arianayagam, McClintock, Fallot, Leslie, Thanigasalam","https://doi.org/10.1007/s11701-021-01305-5","20210904","PubMed","Artificial intelligence; Augmented reality; Intraoperative imaging; Robotic-assisted laparoscopic surgery (RALP)","To describe the innovative intraoperative technologies emerging to aid surgeons during minimally invasive robotic-assisted laparoscopic prostatectomy. We searched multiple electronic databases reporting on intraoperative imaging and navigation technologies, robotic surgery in combination with 3D modeling and 3D printing used during laparoscopic or robotic-assisted laparoscopic prostatectomy. Additional searches were conducted for articles that considered the role of artificial intelligence and machine learning and their application to robotic surgery. We excluded studies using intraoperative navigation technologies during open radical prostatectomy and studies considering technology to visualize lymph nodes. Intraoperative imaging using either transrectal ultrasonography or augmented reality was associated with a potential decrease in positive surgical margins rates. Improvements in detecting capsular involvement may be seen with augmented reality. The benefit, feasibility and applications of other imaging modalities such as 3D-printed models and optical imaging are discussed. The application of image-guided surgery and robotics has led to the development of promising new intraoperative imaging technologies such as augmented reality, fluorescence imaging, optical coherence tomography, confocal laser endomicroscopy and 3D printing. Currently challenges regarding tissue deformation and automatic tracking of prostate movements remain and there is a paucity in the literature supporting the use of these technologies. Urologic surgeons are encouraged to improve and test these advanced technologies in the clinical arena, preferably with comparative, randomized, trials.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21187,""
"Intra-aortic balloon pump versus percutaneous Impella<sup>Ã‚Â©</sup> in emergency revascularisation for myocardial infarction and cardiogenic shock: systematic review","Frain, Rees","https://doi.org/10.1177/02676591211037026","20210904","PubMed","Impella; cardiogenic shock; coronary artery bypass graft; intra-aortic balloon pump; mechanical circulatory support; mortality; myocardial infarction; percutaneous coronary intervention","Mortality rates in patients with acute myocardial infarction and cardiogenic shock (AMI-CS) remain persistently high despite advances over the past decade in percutaneous mechanical circulatory support. This systematic review aims to analyse the existing literature to compare mortality outcomes in patients mechanically supported by intra-aortic balloon pump or percutaneous Impella 2.5/CP<sup>Ã‚Â©</sup> for AMI-CS undergoing emergency revascularisation. The following MeSH terms were applied to the databases Ovid Medline, Ovid Embase, Cochrane and Web of Science: 'Intra-aortic balloon pump', 'Impella', 'Cardiogenic shock', 'Myocardial Infarction' and 'Mortality'. This yielded 2643 studies. Using predefined inclusion and exclusion criteria, the studies were initially screened by title and abstract before full text analysis. Fourteen studies met eligibility criteria: two randomised controlled trials (RCTs) and 12 observational studies. Data from a total of 21,006 patients were included across the studies. Notably, one study claimed reduced mortality with IABP versus control, and one study concluded that Impella<sup>Ã‚Â©</sup> improved survival rates over the IABP. The average 30-day all-cause mortality in patients supported by IABP was 38.1%, 54.3% in Impella<sup>Ã‚Â©</sup> groups and 39.4% in control groups. AMI-CS presents an important cohort of patients in whom conducting RCTs is difficult. As a result, the literature is limited. Analysis of the available literature suggests that there is insufficient evidence to support superior survival in those supported by IABP or Impella<sup>Ã‚Â©</sup> when compared to control despite suggestions that the Impella<sup>Ã‚Â©</sup> offers superior haemodynamic support. Limitations of the studies have been discussed to outline suggestions for future research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21188,""
"Year 2020 (with COVID): Observation of Scientific Literature on Clinical Natural Language Processing","Grabar, Grouin","https://doi.org/10.1055/s-0041-1726528","20211001","PubMed","COVID-19; Clinical Trials as Topic; Humans; Medical Records; Mental Disorders; Natural Language Processing; Social Networking","To analyze the content of publications within the medical NLP domain in 2020. Automatic and manual preselection of publications to be reviewed, and selection of the best NLP papers of the year. Analysis of the important issues. Three best papers have been selected in 2020. We also propose an analysis of the content of the NLP publications in 2020, all topics included. The two main issues addressed in 2020 are related to the investigation of COVID-related questions and to the further adaptation and use of transformer models. Besides, the trends from the past years continue, such as diversification of languages processed and use of information from social networks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21189,""
"A Review of Recent Work in Transfer Learning and Domain Adaptation for Natural Language Processing of Electronic Health Records","Laparra, Mascio, Velupillai, Miller","https://doi.org/10.1055/s-0041-1726522","20211001","PubMed","Datasets as Topic; Electronic Health Records; Language; Machine Learning; Natural Language Processing","We survey recent work in biomedical NLP on building more adaptable or generalizable models, with a focus on work dealing with electronic health record (EHR) texts, to better understand recent trends in this area and identify opportunities for future research. We searched PubMed, the Institute of Electrical and Electronics Engineers (IEEE), the Association for Computational Linguistics (ACL) anthology, the Association for the Advancement of Artificial Intelligence (AAAI) proceedings, and Google Scholar for the years 2018-2020. We reviewed abstracts to identify the most relevant and impactful work, and manually extracted data points from each of these papers to characterize the types of methods and tasks that were studied, in which clinical domains, and current state-of-the-art results. The ubiquity of pre-trained transformers in clinical NLP research has contributed to an increase in domain adaptation and generalization-focused work that uses these models as the key component. Most recently, work has started to train biomedical transformers and to extend the fine-tuning process with additional domain adaptation techniques. We also highlight recent research in cross-lingual adaptation, as a special case of adaptation. While pre-trained transformer models have led to some large performance improvements, general domain pre-training does not always transfer adequately to the clinical domain due to its highly specialized language. There is also much work to be done in showing that the gains obtained by pre-trained transformers are beneficial in real world use cases. The amount of work in domain adaptation and transfer learning is limited by dataset availability and creating datasets for new domains is challenging. The growing body of research in languages other than English is encouraging, and more collaboration between researchers across the language divide would likely accelerate progress in non-English clinical NLP.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21190,""
"Key Contributions in Clinical Research Informatics","Daniel, Bellamine, Kalra","https://doi.org/10.1055/s-0041-1726514","20210917","PubMed","Biomedical Research; Computer Security; Data Mining; Electronic Health Records; Humans; Machine Learning; Medical Informatics; Pharmacovigilance; Phenotype","To summarize key contributions to current research in the field of Clinical Research Informatics (CRI) and to select best papers published in 2020. A bibliographic search using a combination of Medical Subject Headings (MeSH) descriptors and free-text terms on CRI was performed using PubMed, followed by a double-blind review in order to select a list of candidate best papers to be then peer-reviewed by external reviewers. After peer-review ranking, a consensus meeting between two section editors and the editorial team was organized to finally conclude on the selected four best papers. Among the 877 papers published in 2020 and returned by the search, there were four best papers selected. The first best paper describes a method for mining temporal sequences from clinical documents to infer disease trajectories and enhancing high-throughput phenotyping. The authors of the second best paper demonstrate that the generation of synthetic Electronic Health Record (EHR) data through Generative Adversarial Networks (GANs) could be substantially improved by more appropriate training and evaluation criteria. The third best paper offers an efficient advance on methods to detect adverse drug events by computer-assisting expert reviewers with annotated candidate mentions in clinical documents. The large-scale data quality assessment study reported by the fourth best paper has clinical research informatics implications, in terms of the trustworthiness of inferences made from analysing electronic health records. The most significant research efforts in the CRI field are currently focusing on data science with active research in the development and evaluation of Artificial Intelligence/Machine Learning (AI/ML) algorithms based on ever more intensive use of real-world data and especially EHR real or synthetic data. A major lesson that the coronavirus disease 2019 (COVID-19) pandemic has already taught the scientific CRI community is that timely international high-quality data-sharing and collaborative data analysis is absolutely vital to inform policy decisions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21191,""
"Mapping the Role of Digital Health Technologies in Prevention and Control of COVID-19 Pandemic: Review of the Literature","Tilahun, Gashu, Mekonnen, Endehabtu, Angaw","https://doi.org/10.1055/s-0041-1726505","20210917","PubMed","Artificial Intelligence; Biomedical Technology; COVID-19; Information Management; Medical Informatics Applications; Telemedicine","Coronavirus Disease (COVID-19) is currently spreading exponentially around the globe. Various digital health technologies are currently being used as weapons in the fight against the pandemic in different ways by countries. The main objective of this review is to explore the role of digital health technologies in the fight against the COVID-19 pandemic and address the gaps in the use of these technologies for tackling the pandemic. We conducted a scoping review guided by the Joanna Briggs Institute guidelines. The articles were searched using electronic databases including MEDLINE (PubMed), Cochrane Library, and Hinari. In addition, Google and Google scholar were searched. Studies that focused on the application of digital health technologies on COVID-19 prevention and control were included in the review. We characterized the distribution of technological applications based on geographical locations, approaches to apply digital health technologies and main findings. The study findings from the existing literature were presented using thematic content analysis. A total of 2,601 potentially relevant studies were generated from the initial search and 22 studies were included in the final review. The review found that telemedicine was used most frequently, followed by electronic health records and other digital technologies such as artificial intelligence, big data, and the internet of things (IoT). Digital health technologies were used in multiple ways in response to the COVID-19 pandemic, including screening and management of patients, methods to minimize exposure, modelling of disease spread, and supporting overworked providers. Digital health technologies like telehealth, mHealth, electronic medical records, artificial intelligence, the internet of things, and big data/internet were used in different ways for the prevention and control of the COVID-19 pandemic in different settings using multiple approaches. For more effective deployment of digital health tools in times of pandemics, development of a guiding policy and standard on the development, deployment, and use of digital health tools in response to a pandemic is recommended.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21192,""
"Application of Artificial Intelligence in Community-Based Primary Health Care: Systematic Scoping Review and Critical Appraisal","Abbasgholizadeh Rahimi, LÃƒÂ©garÃƒÂ©, Sharma, Archambault, Zomahoun, Chandavong, Rheault, T Wong, Langlois, Couturier, Salmeron, Gagnon, LÃƒÂ©garÃƒÂ©","https://doi.org/10.2196/29839","20211028","PubMed","artificial intelligence; community-based primary health care; machine learning; systematic scoping review; Artificial Intelligence; Community Health Services; Delivery of Health Care; Health Personnel; Humans; Primary Health Care","Research on the integration of artificial intelligence (AI) into community-based primary health care (CBPHC) has highlighted several advantages and disadvantages in practice regarding, for example, facilitating diagnosis and disease management, as well as doubts concerning the unintended harmful effects of this integration. However, there is a lack of evidence about a comprehensive knowledge synthesis that could shed light on AI systems tested or implemented in CBPHC. We intended to identify and evaluate published studies that have tested or implemented AI in CBPHC settings. We conducted a systematic scoping review informed by an earlier study and the Joanna Briggs Institute (JBI) scoping review framework and reported the findings according to PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analysis-Scoping Reviews) reporting guidelines. An information specialist performed a comprehensive search from the date of inception until February 2020, in seven bibliographic databases: Cochrane Library, MEDLINE, EMBASE, Web of Science, Cumulative Index to Nursing and Allied Health Literature (CINAHL), ScienceDirect, and IEEE Xplore. The selected studies considered all populations who provide and receive care in CBPHC settings, AI interventions that had been implemented, tested, or both, and assessed outcomes related to patients, health care providers, or CBPHC systems. Risk of bias was assessed using the Prediction Model Risk of Bias Assessment Tool (PROBAST). Two authors independently screened the titles and abstracts of the identified records, read the selected full texts, and extracted data from the included studies using a validated extraction form. Disagreements were resolved by consensus, and if this was not possible, the opinion of a third reviewer was sought. A third reviewer also validated all the extracted data. We retrieved 22,113 documents. After the removal of duplicates, 16,870 documents were screened, and 90 peer-reviewed publications met our inclusion criteria. Machine learning (ML) (41/90, 45%), natural language processing (NLP) (24/90, 27%), and expert systems (17/90, 19%) were the most commonly studied AI interventions. These were primarily implemented for diagnosis, detection, or surveillance purposes. Neural networks (ie, convolutional neural networks and abductive networks) demonstrated the highest accuracy, considering the given database for the given clinical task. The risk of bias in diagnosis or prognosis studies was the lowest in the participant category (4/49, 4%) and the highest in the outcome category (22/49, 45%). We observed variabilities in reporting the participants, types of AI methods, analyses, and outcomes, and highlighted the large gap in the effective development and implementation of AI in CBPHC. Further studies are needed to efficiently guide the development and implementation of AI interventions in CBPHC settings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21193,""
"Technical and clinical validation of commercial automated volumetric MRI tools for dementia diagnosis-a systematic review","Pemberton, Zaki, Goodkin, Das, Steketee, Barkhof, Vernooij","https://doi.org/10.1007/s00234-021-02746-3","20211022","PubMed","AI; Atrophy; Dementia diagnosis; Neuroradiology; Quantitative MRI; Volumetric; Dementia; Humans; Magnetic Resonance Imaging","Developments in neuroradiological MRI analysis offer promise in enhancing objectivity and consistency in dementia diagnosis through the use of quantitative volumetric reporting tools (QReports). Translation into clinical settings should follow a structured framework of development, including technical and clinical validation steps. However, published technical and clinical validation of the available commercial/proprietary tools is not always easy to find and pathways for successful integration into the clinical workflow are varied. The quantitative neuroradiology initiative (QNI) framework highlights six necessary steps for the development, validation and integration of quantitative tools in the clinic. In this paper, we reviewed the published evidence regarding regulatory-approved QReports for use in the memory clinic and to what extent this evidence fulfils the steps of the QNI framework. We summarize unbiased technical details of available products in order to increase the transparency of evidence and present the range of reporting tools on the market. Our intention is to assist neuroradiologists in making informed decisions regarding the adoption of these methods in the clinic. For the 17 products identified, 11 companies have published some form of technical validation on their methods, but only 4 have published clinical validation of their QReports in a dementia population. Upon systematically reviewing the published evidence for regulatory-approved QReports in dementia, we concluded that there is a significant evidence gap in the literature regarding clinical validation, workflow integration and in-use evaluation of these tools in dementia MRI diagnosis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21194,""
"A convolutional neural network combined with positional and textural attention for the fully automatic delineation of primary nasopharyngeal carcinoma on non-contrast-enhanced MRI","Wong, Ai, Poon, Tong, Ma, Hui, Shi, King","https://doi.org/10.21037/qims-21-196","20210904","PubMed","Texture; convolutional neural network (CNN); head and neck; magnetic resonance imaging (MRI); nasopharyngeal carcinomas (NPCs)","Convolutional neural networks (CNNs) have the potential to automatically delineate primary nasopharyngeal carcinoma (NPC) on magnetic resonance imaging (MRI), but currently, the literature lacks a module to introduce valuable pre-computed features into a CNN. In addition, most CNNs for primary NPC delineation have focused on contrast-enhanced MRI. To enable the use of CNNs in clinical applications where it would be desirable to avoid contrast agents, such as cancer screening or intra-treatment monitoring, we aim to develop a CNN algorithm with a positional-textural fully-connected attention (FCA) module that can automatically delineate primary NPCs on contrast-free MRI. This retrospective study was performed in 404 patients with NPC who had undergone staging MRI. A proposed CNN algorithm incorporated with our positional-textural FCA module (<i>A<sub>proposed</sub></i> ) was trained on manually delineated tumours (<i>M<sub>1st</sub></i> ) to automatically delineate primary NPCs on non-contrast-enhanced T2-weighted fat-suppressed (NE-T2W-FS) images. The performance of <i>A<sub>proposed</sub></i> , three well-established CNNs, Unet (<i>A<sub>unet</sub></i> ), Attention-Unet (<i>A<sub>att</sub></i> ) and Dense-Unet (<i>A<sub>dense</sub></i> ), and a second manual delineation repeated to evaluate human variability (<i>M</i> <sub>2</sub> <i><sub>nd</sub></i> ) were measured by comparing to the reference standard <i>M</i> <sub>1</sub> <i><sub>st</sub></i> to obtain the Dice similarity coefficient (DSC) and average surface distance (ASD). The Wilcoxon rank test was used to compare the performance of <i>A<sub>proposed</sub></i> against <i>A<sub>unet</sub></i> , <i>A<sub>att</sub></i> , <i>A<sub>dense</sub></i> and <i>M</i> <sub>2</sub> <i><sub>nd</sub></i> . <i>A<sub>proposed</sub></i> showed a median DSC of 0.79 (0.10) and ASD of 0.66 (0.84) mm. It performed better than the well-established networks <i>A<sub>unet</sub></i> [DSC =0.75 (0.12) and ASD =1.22 (1.73) mm], <i>A<sub>att</sub></i> [DSC =0.75 (0.10) and ASD =0.96 (1.16) mm] and <i>A<sub>dense</sub></i> [DSC =0.71 (0.14) and ASD =1.67 (1.92) mm] (all P&lt;0.01), but slightly worse when compared to <i>M</i> <sub>2</sub> <i><sub>nd</sub></i> [DSC =0.81 (0.07) and ASD =0.56 (0.80) mm] (P&lt;0.001). The proposed CNN algorithm has potential to accurately delineate primary NPCs on non-contrast-enhanced MRI.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21195,""
"Deep learning methods to generate synthetic CT from MRI in radiotherapy: A literature review","Boulanger, Nunes, Chourak, Largent, Tahri, Acosta, De Crevoisier, Lafond, Barateau","https://doi.org/10.1016/j.ejmp.2021.07.027","20211013","PubMed","Deep learning; Dose calculation; MRI; Radiation therapy; Synthetic-CT; Deep Learning; Magnetic Resonance Imaging; Multicenter Studies as Topic; Radiotherapy Dosage; Radiotherapy Planning, Computer-Assisted; Tomography, X-Ray Computed","In radiotherapy, MRI is used for target volume and organs-at-risk delineation for its superior soft-tissue contrast as compared to CT imaging. However, MRI does not provide the electron density of tissue necessary for dose calculation. Several methods of synthetic-CT (sCT) generation from MRI data have been developed for radiotherapy dose calculation. This work reviewed deep learning (DL) sCT generation methods and their associated image and dose evaluation, in the context of MRI-based dose calculation. We searched the PubMed and ScienceDirect electronic databases from January 2010 to March 2021. For each paper, several items were screened and compiled in figures and tables. This review included 57 studies. The DL methods were either generator-only based (45% of the reviewed studies), or generative adversarial network (GAN) architecture and its variants (55% of the reviewed studies). The brain and pelvis were the most commonly investigated anatomical localizations (39% and 28% of the reviewed studies, respectively), and more rarely, the head-and-neck (H&amp;N) (15%), abdomen (10%), liver (5%) or breast (3%). All the studies performed an image evaluation of sCTs with a diversity of metrics, with only 36 studies performing dosimetric evaluations of sCT. The median mean absolute errors were around 76 HU for the brain and H&amp;N sCTs and 40 HU for the pelvis sCTs. For the brain, the mean dose difference between the sCT and the reference CT was &lt;2%. For the H&amp;N and pelvis, the mean dose difference was below 1% in most of the studies. Recent GAN architectures have advantages compared to generator-only, but no superiority was found in term of image or dose sCT uncertainties. Key challenges of DL-based sCT generation methods from MRI in radiotherapy is the management of movement for abdominal and thoracic localizations, the standardization of sCT evaluation, and the investigation of multicenter impacts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21196,""
"ReHouSED: A novel measurement of Veteran housing stability using natural language processing","Chapman, Jones, Kelley, Jones, Gawron, Montgomery, Byrne, Suo, Cook, Pettey, Peterson, Jones, Nelson","https://doi.org/10.1016/j.jbi.2021.103903","20211020","PubMed","Homelessness; Information extraction; Natural language processing; Social determinants of health; Veterans affairs; Documentation; Electronics; Homeless Persons; Housing; Humans; Natural Language Processing; United States; United States Department of Veterans Affairs; Veterans","Housing stability is an important determinant of health. The US Department of Veterans Affairs (VA) administers several programs to assist Veterans experiencing unstable housing. Measuring long-term housing stability of Veterans who receive assistance from VA is difficult due to a lack of standardized structured documentation in the Electronic Health Record (EHR). However, the text of clinical notes often contains detailed information about Veterans' housing situations that may be extracted using natural language processing (NLP). We present a novel NLP-based measurement of Veteran housing stability: Relative Housing Stability in Electronic Documentation (ReHouSED). We first develop and evaluate a system for classifying documents containing information about Veterans' housing situations. Next, we aggregate information from multiple documents to derive a patient-level measurement of housing stability. Finally, we demonstrate this method's ability to differentiate between Veterans who are stably and unstably housed. Thus, ReHouSED provides an important methodological framework for the study of long-term housing stability among Veterans receiving housing assistance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21197,""
"Redefining ÃŽÂ²-blocker response in heart failure patients with sinus rhythm and atrial fibrillation: a machine learning cluster analysis","Karwath, Bunting, Gill, Tica, Pendleton, Aziz, Barsky, Chernbumroong, Duan, Mobley, Cardoso, Slater, Williams, Bruce, Wang, Flather, Coats, Gkoutos, Kotecha","https://doi.org/10.1016/S0140-6736(21)01638-X","20211030","PubMed","","Mortality remains unacceptably high in patients with heart failure and reduced left ventricular ejection fraction (LVEF) despite advances in therapeutics. We hypothesised that a novel artificial intelligence approach could better assess multiple and higher-dimension interactions of comorbidities, and define clusters of ÃŽÂ²-blocker efficacy in patients with sinus rhythm and atrial fibrillation. Neural network-based variational autoencoders and hierarchical clustering were applied to pooled individual patient data from nine double-blind, randomised, placebo-controlled trials of ÃŽÂ² blockers. All-cause mortality during median 1Ã‚Â·3 years of follow-up was assessed by intention to treat, stratified by electrocardiographic heart rhythm. The number of clusters and dimensions was determined objectively, with results validated using a leave-one-trial-out approach. This study was prospectively registered with ClinicalTrials.gov (NCT00832442) and the PROSPERO database of systematic reviews (CRD42014010012). 15Ã¢â‚¬Ë†659 patients with heart failure and LVEF of less than 50% were included, with median age 65 years (IQR 56-72) and LVEF 27% (IQR 21-33). 3708 (24%) patients were women. In sinus rhythm (n=12Ã¢â‚¬Ë†822), most clusters demonstrated a consistent overall mortality benefit from ÃŽÂ² blockers, with odds ratios (ORs) ranging from 0Ã‚Â·54 to 0Ã‚Â·74. One cluster in sinus rhythm of older patients with less severe symptoms showed no significant efficacy (OR 0Ã‚Â·86, 95% CI 0Ã‚Â·67-1Ã‚Â·10; p=0Ã‚Â·22). In atrial fibrillation (n=2837), four of five clusters were consistent with the overall neutral effect of ÃŽÂ² blockers versus placebo (OR 0Ã‚Â·92, 0Ã‚Â·77-1Ã‚Â·10; p=0Ã‚Â·37). One cluster of younger atrial fibrillation patients at lower mortality risk but similar LVEF to average had a statistically significant reduction in mortality with ÃŽÂ² blockers (OR 0Ã‚Â·57, 0Ã‚Â·35-0Ã‚Â·93; p=0Ã‚Â·023). The robustness and consistency of clustering was confirmed for all models (p&lt;0Ã‚Â·0001 vs random), and cluster membership was externally validated across the nine independent trials. An artificial intelligence-based clustering approach was able to distinguish prognostic response from ÃŽÂ² blockers in patients with heart failure and reduced LVEF. This included patients in sinus rhythm with suboptimal efficacy, as well as a cluster of patients with atrial fibrillation where ÃŽÂ² blockers did reduce mortality. Medical Research Council, UK, and EU/EFPIA Innovative Medicines Initiative BigData@Heart.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21198,""
"COVID-19 Imaging-based AI Research - A Literature Review","Ge, Zhang, Xie, Kong, Zhang, Chang","https://doi.org/10.2174/1573405617666210902103729","20210902","PubMed","AI-assisted ; Artificial intelligence; COVID-19; Medical diagnosis; Medical imaging; Segmentation","The new coronavirus disease 2019 (COVID-19) is spreading rapidly around the world. Artificial intelligence (AI) assisted identification and detection of diseases is an ef-fective method of medical diagnosis. To present recent advances in AI-assisted diagnosis of COVID-19, we introduce major aspects of AI in the process of diagnosing COVID-19. In this paper, we firstly cover the latest collection and processing methods of da-tasets of COVID-19. The processing methods mainly include building public datasets, transfer learning, unsupervised learning and weakly supervised learning, semi-supervised learning methods and so on. Secondly, we introduce the algorithm application and evaluation metrics of AI in medical imaging segmentation and automatic screening. Then, we introduce the quantifi-cation and severity assessment of infection in COVID-19 patients based on image segmenta-tion and automatic screening. Finally, we analyze and point out the current AI-assisted diagno-sis of COVID-19 problems, which may provide useful clues for future work. AI is critical for COVID-19 diagnosis. Combining chest imaging with AI can not only save time and effort, but also provide more accurate and efficient medical diagnosis results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21199,""
"A comparison of deep learning-based pre-processing and clustering approaches for single-cell RNA sequencing data","Wang, Zou, Lin","https://doi.org/10.1093/bib/bbab345","20210902","PubMed","clustering analysis; deep learning; pre-processing steps; single-cell RNA-seq","The emergence of single cell RNA sequencing has facilitated the studied of genomes, transcriptomes and proteomes. As available single-cell RNA-seq datasets are released continuously, one of the major challenges facing traditional RNA analysis tools is the high-dimensional, high-sparsity, high-noise and large-scale characteristics of single-cell RNA-seq data. Deep learning technologies match the characteristics of single-cell RNA-seq data perfectly and offer unprecedented promise. Here, we give a systematic review for most popular single-cell RNA-seq analysis methods and tools based on deep learning models, involving the procedures of data preprocessing (quality control, normalization, data correction, dimensionality reduction and data visualization) and clustering task for downstream analysis. We further evaluate the deep model-based analysis methods of data correction and clustering quantitatively on 11 gold standard datasets. Moreover, we discuss the data preferences of these methods and their limitations, and give some suggestions and guidance for users to select appropriate methods and tools.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21200,""
"Towards a comprehensive understanding of p75 neurotrophin receptor functions and interactions in the brain","Ritala, Lyne, Sajanti, Girard, KoskimÃƒÂ¤ki","https://doi.org/10.4103/1673-5374.314291","20210902","PubMed","bioinformatics; brain injury; data mining; neuron; neurotrophins; p75NTR; plasticity; regeneration","The role of neurotrophins in neuronal plasticity has recently become a strong focus in neuroregeneration research field to elucidate the biological mechanisms by which these molecules modulate synapses, modify the response to injury, and alter the adaptation response. Intriguingly, the prior studies highlight the role of p75 neurotrophin receptor (p75<sup>NTR</sup>) in various injuries and diseases such as central nervous system injuries, Alzheimer's disease and amyotrophic lateral sclerosis. More comprehensive elucidation of the mechanisms, and therapies targeting these molecular signaling networks may allow for neuronal tissue regeneration following an injury. Due to a diverse role of the p75<sup>NTR</sup> in biology, the body of evidence comprising its biological role is diffusely spread out over numerous fields. This review condenses the main evidence of p75<sup>NTR</sup> for clinical applications and presents new findings from published literature how data mining approach combined with bioinformatic analyses can be utilized to gain new hypotheses in a molecular and network level.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21201,""
"Automated processing of thermal imaging to detect COVID-19","Brzezinski, Rabin, Lewis, Peled, Kerpel, Tsur, Gendelman, Naftali-Shani, Gringauz, Amital, Leibowitz, Mayan, Ben-Zvi, Heller, Shechtman, Rogowski, Shenhar-Tsarfaty, Konen, Marom, Ironi, Rahav, Zimmer, Grossman, Ovadia-Blechman, Leor, Hoffer","https://doi.org/10.1038/s41598-021-96900-9","20210913","PubMed","Adult; Aged; Algorithms; Area Under Curve; COVID-19; Disease Progression; Female; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Point-of-Care Systems; Sensitivity and Specificity; Smartphone","Rapid and sensitive screening tools for SARS-CoV-2 infection are essential to limit the spread of COVID-19 and to properly allocate national resources. Here, we developed a new point-of-care, non-contact thermal imaging tool to detect COVID-19, based on advanced image processing algorithms. We captured thermal images of the backs of individuals with and without COVID-19 using a portable thermal camera that connects directly to smartphones. Our novel image processing algorithms automatically extracted multiple texture and shape features of the thermal images and achieved an area under the curve (AUC) of 0.85 in COVID-19 detection with up to 92% sensitivity. Thermal imaging scores were inversely correlated with clinical variables associated with COVID-19 disease progression. In summary, we show, for the first time, that a hand-held thermal imaging device can be used to detect COVID-19. Non-invasive thermal imaging could be used to screen for COVID-19 in out-of-hospital settings, especially in low-income regions with limited imaging resources.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21202,""
"Use of artificial intelligence for image analysis in breast cancer screening programmes: systematic review of test accuracy","Freeman, Geppert, Stinton, Todkill, Johnson, Clarke, Taylor-Phillips","https://doi.org/10.1136/bmj.n1872","20210910","PubMed","Artificial Intelligence; Breast Neoplasms; Early Detection of Cancer; Female; Humans; Mammography; Mass Screening","To examine the accuracy of artificial intelligence (AI) for the detection of breast cancer in mammography screening practice. Systematic review of test accuracy studies. Medline, Embase, Web of Science, and Cochrane Database of Systematic Reviews from 1 January 2010 to 17 May 2021. Studies reporting test accuracy of AI algorithms, alone or in combination with radiologists, to detect cancer in women's digital mammograms in screening practice, or in test sets. Reference standard was biopsy with histology or follow-up (for screen negative women). Outcomes included test accuracy and cancer type detected. Two reviewers independently assessed articles for inclusion and assessed the methodological quality of included studies using the QUality Assessment of Diagnostic Accuracy Studies-2 (QUADAS-2) tool. A single reviewer extracted data, which were checked by a second reviewer. Narrative data synthesis was performed. Twelve studies totalling 131 822 screened women were included. No prospective studies measuring test accuracy of AI in screening practice were found. Studies were of poor methodological quality. Three retrospective studies compared AI systems with the clinical decisions of the original radiologist, including 79Ã¢â‚¬â€°910 women, of whom 1878 had screen detected cancer or interval cancer within 12 months of screening. Thirty four (94%) of 36 AI systems evaluated in these studies were less accurate than a single radiologist, and all were less accurate than consensus of two or more radiologists. Five smaller studies (1086 women, 520 cancers) at high risk of bias and low generalisability to the clinical context reported that all five evaluated AI systems (as standalone to replace radiologist or as a reader aid) were more accurate than a single radiologist reading a test set in the laboratory. In three studies, AI used for triage screened out 53%, 45%, and 50% of women at low risk but also 10%, 4%, and 0% of cancers detected by radiologists. Current evidence for AI does not yet allow judgement of its accuracy in breast cancer screening programmes, and it is unclear where on the clinical pathway AI might be of most benefit. AI systems are not sufficiently specific to replace radiologist double reading in screening programmes. Promising results in smaller studies are not replicated in larger studies. Prospective studies are required to measure the effect of AI in clinical practice. Such studies will require clear stopping rules to ensure that AI does not reduce programme specificity. Protocol registered as PROSPERO CRD42020213590.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21203,""
"In-silico strategies to combat COVID-19: A comprehensive review","Basu, Ramaiah, Anbarasu","https://doi.org/10.1080/02648725.2021.1966920","20211011","PubMed","Coronavirus disease (COVID)-19; Severe acute respiratory syndrome coronavirus (SARS-CoV)-2; bioinformatics; computational biology; Antiviral Agents; Artificial Intelligence; COVID-19; COVID-19 Vaccines; China; Computational Biology; Computer Simulation; Drug Design; Epitopes; Humans; Ligands; Machine Learning; Molecular Dynamics Simulation; Pandemics","The novel coronavirus SARS-CoV-2 since its emergence at Wuhan, China in December 2019 has been creating global health turmoil despite extensive containment measures and has resulted in the present pandemic COVID-19. Although the virus and its interaction with the host have been thoroughly characterized, effective treatment regimens beyond symptom-based care and repurposed therapeutics could not be identified. Various countries have successfully developed vaccines to curb the disease-transmission and prevent future outbreaks. Vaccination-drives are being conducted on a war-footing, but the process is time-consuming, especially in the densely populated regions of the world. Bioinformaticians and computational biologists have been playing an efficient role in this state of emergency to escalate clinical research and therapeutic development. However, there are not many reviews available in the literature concerning COVID-19 and its management. Hence, we have focused on designing a comprehensive review on <i>in-silico</i> approaches concerning COVID-19 to discuss the relevant bioinformatics and computational resources, tools, patterns of research, outcomes generated so far and their future implications to efficiently model data based on epidemiology; identify drug targets to design new drugs; predict epitopes for vaccine design and conceptualize diagnostic models. Artificial intelligence/machine learning can be employed to accelerate the research programs encompassing all the above urgent needs to counter COVID-19 and similar outbreaks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21204,""
"Systematic Review of Approaches to Preserve Machine Learning Performance in the Presence of Temporal Dataset Shift in Clinical Medicine","Guo, Pfohl, Fries, Posada, Fleming, Aftandilian, Shah, Sung","https://doi.org/10.1055/s-0041-1735184","20210908","PubMed","","The change in performance of machine learning models over time as a result of temporal dataset shift is a barrier to machine learning-derived models facilitating decision-making in clinical practice. Our aim was to describe technical procedures used to preserve the performance of machine learning models in the presence of temporal dataset shifts. Studies were included if they were fully published articles that used machine learning and implemented a procedure to mitigate the effects of temporal dataset shift in a clinical setting. We described how dataset shift was measured, the procedures used to preserve model performance, and their effects. Of 4,457 potentially relevant publications identified, 15 were included. The impact of temporal dataset shift was primarily quantified using changes, usually deterioration, in calibration or discrimination. Calibration deterioration was more common (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°11) than discrimination deterioration (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°3). Mitigation strategies were categorized as model level or feature level. Model-level approaches (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°15) were more common than feature-level approaches (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°2), with the most common approaches being model refitting (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°12), probability calibration (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°7), model updating (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°6), and model selection (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°6). In general, all mitigation strategies were successful at preserving calibration but not uniformly successful in preserving discrimination. There was limited research in preserving the performance of machine learning models in the presence of temporal dataset shift in clinical medicine. Future research could focus on the impact of dataset shift on clinical decision making, benchmark the mitigation strategies on a wider range of datasets and tasks, and identify optimal strategies for specific settings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21205,""
"FABNet: Fusion Attention Block and Transfer Learning for Laryngeal cancer Tumor Grading in P63 IHC Histopathology Images","Huang, Tan, Zhou, Liu, Mercaldo, Santone","https://doi.org/10.1109/JBHI.2021.3108999","20210901","PubMed","","Laryngeal cancer tumor (LCT) grading is a challenging task in P63 Immunohistochemical (IHC) histopathology images due to small differences between LCT levels in pathology images, the lack of precision in lesion regions of interest (LROIs) and the paucity of LCT pathology image samples. The key to solving the LCT grading problem is to transfer knowledge from other images and to identify more accurate LROIs, but the following problems occur: 1) transferring knowledge without a priori experience often causes negative transfer and creates a heavy workload due to the abundance of image types, and 2) convolutional neural networks (CNNs) constructing deep models by stacking cannot sufficiently identify LROIs, often deviate significantly from the LROIs focused on by experienced pathologists, and are prone to providing misleading second opinions. So we propose a novel fusion attention block network (FABNet) to address these problems. First, we propose a model transfer method based on clinical a priori experience and sample analysis (CPESA) that analyzes the transfer ability by integrating clinical a priori experience using indicators such as the relationship between the cancer onset location and morphology and the texture and staining degree of cell nuclei in histopathology images; our method further validates these indicators by the probability distribution of cancer image samples. Then, we propose a fusion attention block (FAB) structure, which can both provide an advanced non-uniform sparse representation of images and extract spatial relationship information between nuclei; consequently, the LROI can be more accurate and more relevant to pathologists. We conducted extensive experiments, compared with the best Baseline model, the classification accuracy is improved 25%, and It is demonstrated that FABNet performs better on different cancer pathology image datasets and outperforms other state of the art (SOTA) models.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21206,""
"Practical Guide to Natural Language Processing for Radiology","Mozayan, Fabbri, Maneevese, Tocino, Chheang","https://doi.org/10.1148/rg.2021200113","20210907","PubMed","","Natural language processing (NLP) is the subset of artificial intelligence focused on the computer interpretation of human language. It is an invaluable tool in the analysis, aggregation, and simplification of free text. It has already demonstrated significant potential in the analysis of radiology reports. There are abundant open-source libraries and tools available that facilitate its application to the benefit of radiology. Radiologists who understand its limitations and potential will be better positioned to evaluate NLP models, understand how they can improve clinical workflow, and facilitate research endeavors involving large amounts of human language. The advent of increasingly affordable and powerful computer processing, the large quantities of medical and radiologic data, and advances in machine learning algorithms have contributed to the large potential of NLP. In turn, radiology has significant potential to benefit from the ability of NLP to convert relatively standardized radiology reports to machine-readable data. NLP benefits from standardized reporting, but because of its ability to interpret free text by using context clues, NLP does not necessarily depend on it. An overview and practical approach to NLP is featured, with specific emphasis on its applications to radiology. A brief history of NLP, the strengths and challenges inherent to its use, and freely available resources and tools are covered to guide further exploration and study within the field. Particular attention is devoted to the recent development of the Word2Vec and BERT (Bidirectional Encoder Representations from Transformers) language models, which have exponentially increased the power and utility of NLP for a variety of applications. <i>Online supplemental material is available for this article.</i> <sup>Ã‚Â©</sup>RSNA, 2021.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21207,""
"CT Noise-Reduction Methods for Lower-Dose Scanning: Strengths and Weaknesses of Iterative Reconstruction Algorithms and New Techniques","Mohammadinejad, Mileto, Yu, Leng, Guimaraes, Missert, Jensen, Gong, McCollough, Fletcher","https://doi.org/10.1148/rg.2021200196","20210907","PubMed","","Iterative reconstruction (IR) algorithms are the most widely used CT noise-reduction method to improve image quality and have greatly facilitated radiation dose reduction within the radiology community. Various IR methods have different strengths and limitations. Because IR algorithms are typically nonlinear, they can modify spatial resolution and image noise texture in different regions of the CT image; hence traditional image-quality metrics are not appropriate to assess the ability of IR to preserve diagnostic accuracy, especially for low-contrast diagnostic tasks. In this review, the authors highlight emerging IR algorithms and CT noise-reduction techniques and summarize how these techniques can be evaluated to help determine the appropriate radiation dose levels for different diagnostic tasks in CT. In addition to advanced IR techniques, we describe novel CT noise-reduction methods based on convolutional neural networks (CNNs). CNN-based noise-reduction techniques may offer the ability to reduce image noise while maintaining high levels of image detail but may have unique drawbacks. Other novel CT noise-reduction methods are being developed to leverage spatial and/or spectral redundancy in multiphase or multienergy CT. Radiologists and medical physicists should be familiar with these different alternatives to adapt available CT technology for different diagnostic tasks. The scope of this article is <i>(a</i>) to review the clinical applications of IR algorithms as well as their strengths, weaknesses, and methods of assessment and <i>(b</i>) to explore new CT image reconstruction and noise-reduction techniques that promise to facilitate radiation dose reduction. <sup>Ã‚Â©</sup>RSNA, 2021.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21208,""
"Identifying adverse drug reactions from free-text electronic hospital health record notes","Wasylewicz, van de Burgt, Weterings, Jessurun, Korsten, Egberts, Bouwman, Kerskes, Grouls, van der Linden","https://doi.org/10.1111/bcp.15068","20211014","PubMed","adverse drug event; adverse drug reaction; clinical decision support; clinical decision support system; drug allergy; free-text; natural language processing; text-mining","Adverse drug reactions (ADRs) are estimated to be the fifth cause of hospital death. Up to 50% are potentially preventable and a significant number are recurrent (reADRs). Clinical decision support systems have been used to prevent reADRs using structured reporting concerning the patient's ADR experience, which in current clinical practice is poorly performed. Identifying ADRs directly from free text in electronic health records (EHRs) could circumvent this. To develop strategies to identify ADRs from free-text notes in electronic hospital health records. In stage I, the EHRs of 10 patients were reviewed to establish strategies for identifying ADRs. In stage II, complete EHR histories of 45 patients were reviewed for ADRs and compared to the strategies programmed into a rule-based model. ADRs were classified using MedDRA and included in the study if the Naranjo causality score was Ã¢â€°Â¥1. Seriousness was assessed using the European Medicine Agency's important medical event list. In stage I, two main search strategies were identified: keywords indicating an ADR and specific prepositions followed by medication names. In stage II, the EHRs contained a median of 7.4 (range 0.01-18) years of medical history covering over 35Ã¢â‚¬â€°000 notes. A total of 318 unique ADRs were identified of which 63 were potentially serious and 179 (sensitivity 57%) were identified by the rule. The method falsely identified 377 ADRs (positive predictive value 32%). However, it also identified an additional eight ADRs. Two key strategies were developed to identify ADRs from hospital EHRs using free-text notes. The results appear promising and warrant further study.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21209,""
"Health-Related Criterion-Referenced Cut-Points for Cardiorespiratory Fitness Among Youth: A Systematic Review","Rollo, Fraser, Seguin, Sampson, Lang, Tomkinson, Tremblay","https://doi.org/10.1007/s40279-021-01537-3","20210901","PubMed","","Cardiorespiratory fitness (CRF), which reflects the overall aerobic capacity of the cardiovascular, respiratory, and muscular systems, is significantly related to health among youth. The aim of this systematic review was to identify health-related criterion-referenced cut-points for CRF among youth aged 5-17Ã‚Â years. A systematic search of two electronic databases (MEDLINE and SPORTDiscus) was conducted in September 2020. Only peer-reviewed studies that developed health-related criterion-referenced cut-points for CRF among youth were eligible provided they included (1) youth aged 5-17Ã‚Â years from the general population; (2) at least one quantitative assessment of CRF (e.g., peak oxygen uptake [[Formula: see text]O<sub>2peak</sub>]); (3) at least one quantitative assessment of health (e.g., cardiometabolic risk); (4) a criterion for health; and (5) a quantitative analysis (e.g., receiver operating characteristic [ROC] curve) of at least one health-related cut-point for CRF. A narrative synthesis was used to describe the results of the included studies. Collectively, 29 included studies developed health-related criterion-referenced cut-points for CRF among 193,311 youth from 23 countries. CRF cut-points, expressed as [Formula: see text]O<sub>2peak</sub>, estimated using the 20-m shuttle run test, demonstrated high discriminatory ability (median area under the curve [AUC]Ã¢â‚¬â€°Ã¢â€°Â¥Ã¢â‚¬â€°0.71) for both cardiometabolic and obesity risk. Cut-points derived from maximal cycle-ergometer tests demonstrated moderate discriminatory ability (median AUC 0.64-0.70) for cardiometabolic risk, and low discriminatory ability for early subclinical atherosclerosis (median AUC 0.56-0.63). Cut-points for CRF using submaximal treadmill exercise testing demonstrated high discriminatory ability for cardiometabolic risk, but only moderate discriminatory ability for obesity risk. CRF cut-points estimated using submaximal step testing demonstrated high discriminatory ability for cardiometabolic risk and moderate discriminatory ability for high blood pressure, while those for the 9-min walk/run test demonstrated moderate-to-high discriminatory ability for obesity risk. Collectively, CRF cut-points, expressed as [Formula: see text]O<sub>2peak</sub>, demonstrated moderate-to-high discriminatory ability (median AUCÃ¢â‚¬â€°Ã¢â€°Â¥Ã¢â‚¬â€°0.64) for cardiometabolic risk, obesity risk, and high blood pressure. Currently, there is too wide a range of health-related criterion-referenced cut-points for CRF among youth to suggest universal age- and sex-specific thresholds. To further inform the development of universal cut-points, there is a need for additional research, using standardized testing protocols and health-risk definitions, that examines health-related criterion-referenced cut-points for CRF that are age, sex, and culturally diverse. PROSPERO registration number: CRD42020207458.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21210,""
"Percutaneous puncture during PCNL: new perspective for the future with virtual imaging guidance","Checcucci, Amparore, Volpi, Piramide, De Cillis, Piana, Alessio, Verri, Piscitello, Carbonaro, Meziere, Zamengo, Tsaturyan, Cacciamani, Rivas, De Luca, Manfredi, Fiori, Liatsikos, Porpiglia","https://doi.org/10.1007/s00345-021-03820-4","20210901","PubMed","3D; Artificial intelligence; Augmented reality; Kidney stones; PCNL; Virtual imaging","Large and complex renal stones are usually treated with percutaneous nephrolithotomy (PCNL). One of the crucial steps in this procedure is the access to the collecting system with the percutaneous puncture and this maneuver leads to a risk of vascular and neighboring organs' injury. In the last years, the application of virtual image-guided surgery has gained wide diffusion even in this specific field. To provide a short overview of the most recent evidence on current applications of virtual imaging guidance for PCNL. A non-systematic review of the literature was performed. Medline, PubMed, the Cochrane Database and Embase were screened for studies regarding the use virtual imaging guidance for PCNL. 3D virtual navigation technology for PCNL was first used in urology with the purpose of surgical training and surgical planning; subsequently, the field of surgical navigation with different modalities (from cognitive to augmented reality or mixed reality) had been explored. Finally, anecdotal preliminary experiences explored the potential application of artificial intelligence guidance for percutaneous puncture. Nowadays, many experiences proved the potential benefit of virtual guidance for surgical simulation and training. Focusing on surgery, this tool revealed to be useful both for surgical planning, allowed to achieve a better surgical performance, and for surgical navigation by using augmented reality and mixed reality systems aimed to assist the surgeon in real time during the intervention.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21211,""
"Revisiting performance metrics for prediction with rare outcomes","Adhikari, Normand, Bloom, Shahian, Rose","https://doi.org/10.1177/09622802211038754","20211013","PubMed","Prediction; classification; ensembles; machine learning; mortality","Machine learning algorithms are increasingly used in the clinical literature, claiming advantages over logistic regression. However, they are generally designed to maximize the area under the receiver operating characteristic curve. While area under the receiver operating characteristic curve and other measures of accuracy are commonly reported for evaluating binary prediction problems, these metrics can be misleading. We aim to give clinical and machine learning researchers a realistic medical example of the dangers of relying on a single measure of discriminatory performance to evaluate binary prediction questions. Prediction of medical complications after surgery is a frequent but challenging task because many post-surgery outcomes are rare. We predicted post-surgery mortality among patients in a clinical registry who received at least one aortic valve replacement. Estimation incorporated multiple evaluation metrics and algorithms typically regarded as performing well with rare outcomes, as well as an ensemble and a new extension of the lasso for multiple unordered treatments. Results demonstrated high accuracy for all algorithms with moderate measures of cross-validated area under the receiver operating characteristic curve. False positive rates were <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mo>&lt;</mml:mo></mml:math>1%, however, true positive rates were <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mo>&lt;</mml:mo></mml:math>7%, even when paired with a 100% positive predictive value, and graphical representations of calibration were poor. Similar results were seen in simulations, with the addition of high area under the receiver operating characteristic curve (<mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mo>&gt;</mml:mo></mml:math>90%) accompanying low true positive rates. Clinical studies should not primarily report only area under the receiver operating characteristic curve or accuracy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21212,""
"Functional MRI findings in personality disorders: A review","Zarnowski, Ziton, Holmberg, Musto, Riegle, Van Antwerp, Santos-Nunez","https://doi.org/10.1111/jon.12924","20210901","PubMed","fMRI; functional connectivity; neuroimaging; neuropathology; personality disorder","Personality disorders (PDs) have a prevalence of approximately 10% in the United States, translating to over 30 million people affected in just one country. The true prevalence of these disorders may be even higher, as the paucity of objective diagnostic criteria could be leading to underdiagnosis. Because little is known about the underlying neuropathologies of these disorders, patients are diagnosed using subjective criteria and treated nonspecifically. To better understand the neural aberrancies responsible for these patients' symptoms, a review of functional MRI literature was performed. The findings reveal that each PD is characterized by a unique set of activation changes corresponding to individual structures or specific neural networks. While unique patterns of neural activity are distinguishable within each PD, aberrations of the limbic/paralimbic structures and default mode network are noted across several of them. In addition to identifying valuable activation patterns, this review reveals a void in research pertaining to paranoid, schizoid, histrionic, narcissistic, and dependent PDs. By delineating patterns in PD neuropathology, we can more effectively direct future research efforts toward enhancing objective diagnostic techniques and developing targeted treatment modalities. Furthermore, understanding why patients are manifesting certain symptoms can advance clinical awareness and improve patient outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21213,""
"Artificial intelligence for MRI diagnosis of joints: a scoping review of the current state-of-the-art of deep learning-based approaches","Fritz, Fritz","https://doi.org/10.1007/s00256-021-03830-8","20210901","PubMed","Artificial intelligence; Computer; Deep learning; Joints; Magnetic resonance imaging; Musculoskeletal system; Neural networks","Deep learning-based MRI diagnosis of internal joint derangement is an emerging field of artificial intelligence, which offers many exciting possibilities for musculoskeletal radiology. A variety of investigational deep learning algorithms have been developed to detect anterior cruciate ligament tears, meniscus tears, and rotator cuff disorders. Additional deep learning-based MRI algorithms have been investigated to detect Achilles tendon tears, recurrence prediction of musculoskeletal neoplasms, and complex segmentation of nerves, bones, and muscles. Proof-of-concept studies suggest that deep learning algorithms may achieve similar diagnostic performances when compared to human readers in meta-analyses; however, musculoskeletal radiologists outperformed most deep learning algorithms in studies including a direct comparison. Earlier investigations and developments of deep learning algorithms focused on the binary classification of the presence or absence of an abnormality, whereas more advanced deep learning algorithms start to include features for characterization and severity grading. While many studies have focused on comparing deep learning algorithms against human readers, there is a paucity of data on the performance differences of radiologists interpreting musculoskeletal MRI studies without and with artificial intelligence support. Similarly, studies demonstrating the generalizability and clinical applicability of deep learning algorithms using realistic clinical settings with workflow-integrated deep learning algorithms are sparse. Contingent upon future studies showing the clinical utility of deep learning algorithms, artificial intelligence may eventually translate into clinical practice to assist detection and characterization of various conditions on musculoskeletal MRI exams.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21214,""
"A deep learning framework for autonomous detection and classification of Crohn's disease lesions in the small bowel and colon with capsule endoscopy","Majtner, Brodersen, Herp, Kjeldsen, Halling, Jensen","https://doi.org/10.1055/a-1507-4980","20210903","PubMed","","<b>Background and study aimsÃ¢â‚¬â€š</b> Small bowel ulcerations are efficiently detected with deep learning techniques, whereas the ability to diagnose Crohn's disease (CD) in the colon with it is unknown. This study examined the ability of a deep learning framework to detect CD lesions with pan-enteric capsule endoscopy (CE) and classify lesions of different severity. <b>Patients and methodsÃ¢â‚¬â€š</b> CEs from patients with suspected or known CD were included in the analysis. Two experienced gastroenterologists classified anonymized images into normal mucosa, non-ulcerated inflammation, aphthous ulceration, ulcer, or fissure/extensive ulceration. An automated framework incorporating multiple ResNet-50 architectures was trained. To improve its robustness and ability to characterize lesions, image processing methods focused on texture enhancement were employed. <b>ResultsÃ¢â‚¬â€š</b> A total of 7744 images from 38 patients with CD were collected (small bowel 4972, colon 2772) of which 2748 contained at least one ulceration (small bowel 1857, colon 891). With a patient-dependent split of images for training, validation, and testing, ulcerations were diagnosed with a sensitivity, specificity, and diagnostic accuracy of 95.7Ã¢â‚¬Å % (CI 93.4-97.4), 99.8Ã¢â‚¬Å % (CI 99.2-100), and 98.4Ã¢â‚¬Å % (CI 97.6-99.0), respectively. The diagnostic accuracy was 98.5Ã¢â‚¬Å % (CI 97.5-99.2) for the small bowel and 98.1Ã¢â‚¬Å % (CI 96.3-99.2) for the colon. Ulcerations of different severities were classified with substantial agreement (ÃŽÂºÃ¢â‚¬Å =Ã¢â‚¬Å 0.72). <b>ConclusionsÃ¢â‚¬â€š</b> Our proposed framework is in excellent agreement with the clinical standard, and diagnostic accuracies are equally high for the small bowel and colon. Deep learning approaches have a great potential to help clinicians detect, localize, and determine the severity of CD with pan-enteric CE.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21215,""
"A well-trained artificial neural network for predicting the rheological behavior of MWCNT-Al<sub>2</sub>O<sub>3</sub> (30-70%)/oil SAE40 hybrid nanofluid","Esfe, Eftekhari, Hekmatifar, Toghraie","https://doi.org/10.1038/s41598-021-96808-4","20211018","PubMed","","In this study, the influence of different volume fractions ([Formula: see text]) of nanoparticles and temperatures on the dynamic viscosity ([Formula: see text]) of MWCNT-Al<sub>2</sub>O<sub>3</sub> (30-70%)/oil SAE40 hybrid nanofluid was examined by ANN. For this reason, the [Formula: see text] was derived for 203 various experiments through a series of experimental tests, including a combination of 7 different [Formula: see text], 6 various temperatures, and 5 shear rates. These data were then used to train an artificial neural network (ANN) to generalize results in the predefined ranges for two input parameters. For this reason, a feed-forward perceptron ANN with two inputs (T and [Formula: see text]) and one output ([Formula: see text]) was used. The best topology of the ANN was determined by trial and error, and a two-layer with 10 neurons in the hidden layer with the tansig function had the best performance. A well-trained ANN is created using the trainbr algorithm and showed an MSE value of 4.3e-3 along 0.999 as a correlation coefficient for predicting [Formula: see text]. The results show that an increase [Formula: see text] has a significant effect on [Formula: see text] value. As [Formula: see text] increases, the viscosity of this nanofluid increases at all temperatures. On the other hand, with increasing temperature, the viscosity of this nanofluid decreases. Based on all of the diagrams presented for the trained ANNs, we can conclude that a well-trained ANN can be used as an approximating function for predicting the [Formula: see text].","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21216,""
"Patients' and professionals' views related to ethical issues in precision medicine: a mixed research synthesis","Erdmann, Rehmann-Sutter, Bozzaro","https://doi.org/10.1186/s12910-021-00682-8","20210927","PubMed","Access; Benefits; Data security; Discrimination; Genomic medicine; Informed consent; Knowledge; Personalized medicine; Precision medicine; Stigmatization; Artificial Intelligence; Humans; Informed Consent; Physician-Patient Relations; Precision Medicine; Quality of Life","Precision medicine development is driven by the possibilities of next generation sequencing, information technology and artificial intelligence and thus, raises a number of ethical questions. Empirical studies have investigated such issues from the perspectives of health care professionals, researchers and patients. We synthesize the results from these studies in this review. We used a systematic strategy to search, screen and assess the literature for eligibility related to our research question. The initial search for empirical studies in five data bases provided 665 different records and we selected 92 of these publications for inclusion in this review. Data were extracted in a spreadsheet and categorized into different topics representing the views on ethical issues in precision medicine. Many patients and professionals expect high benefits from precision medicine and have a positive attitude towards it. However, patients and professionals also perceive some risks. Commonly perceived risks include: lack of evidence for accuracy of tests and efficacy of treatments; limited knowledge of patients, which makes informed consent more difficult; possible unavailability of access to precision medicine for underprivileged people and ethnic minorities; misuse of data by insurance companies and employers, potential of racial stigmatization due to genetic information; unwanted communication of incidental findings; changes in doctor-patient-relationship through focusing on data; and the problem that patients could feel under pressure to optimize their health. National legislation and guidelines already minimize many risks associated with precision medicine. However, from our perspective some problems require more attention. Should hopes for precision medicine's benefits be fulfilled, then the ethical principle of justice would require an unlimited access to precision medicine for all people. The potential for autonomous patients' decisions must be greatly enhanced by improvements in patient education. Harm from test results must be avoided in any case by the highest possible data security level and communication guidelines. Changes in the doctor-patient relationship and the impact of precision medicine on the quality of life should be further investigated. Additionally, the cost-effectiveness of precision medicine should be further examined, in order to avoid malinvestment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21217,""
"Exploring the diagnostic effectiveness for myocardial ischaemia based on CCTA myocardial texture features","Zhao, Yuan, Chen, Liao, Lin","https://doi.org/10.1186/s12872-021-02206-z","20210913","PubMed","Coronary CT angiography; Coronary atherosclerosis; Myocardial ischaemia; Texture features","To explore the characteristics of myocardial textures on coronary computed tomography angiography (CCTA) images in patients with coronary atherosclerotic heart disease, a classification model was established, and the diagnostic effectiveness of CCTA for myocardial ischaemia patients was explored. This was a retrospective analysis of the CCTA images of 155 patients with clinically diagnosed coronary heart disease from September 2019 to January 2020, 79 of whom were considered positive (myocardial ischaemia) and 76 negative (normal myocardial blood supply) according to their clinical diagnoses. By using the deep learning model-based CQK software, the myocardium was automatically segmented from the CCTA images and used to extract texture features. All patients were randomly divided into a training cohort and a test cohort at a 7:3 ratio. The Spearman correlation and least absolute shrinkage and selection operator (LASSO) method were used for feature selection. Based on the selected features of the training cohort, a multivariable logistic regression model was established. Finally, the test cohort was used to verify the regression model. A total of 387 features were extracted from the CCTA images of the 155 coronary heart disease patients. After performing dimensionality reduction with the Spearman correlation and LASSO, three texture features were selected. The accuracy, area under the curve, specificity, sensitivity, positive predictive value and negative predictive value of the constructed multivariable logistic regression model with the test cohort were 0.783, 0.875, 0.733, 0.875, 0.650 and 0.769, respectively. CCTA imaging texture features of the myocardium have potential as biomarkers for diagnosing myocardial ischaemia.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21218,""
"Modern Clinical Text Mining: A Guide and Review","Percha","https://doi.org/10.1146/annurev-biodatasci-030421-030931","20211025","PubMed","clinical text; electronic health record; machine learning; natural language processing; text mining; Data Mining; Electronic Health Records; Humans; Machine Learning; Physicians; Time","Electronic health records (EHRs) are becoming a vital source of data for healthcare quality improvement, research, and operations. However, much of the most valuable information contained in EHRs remains buried in unstructured text. The field of clinical text mining has advanced rapidly in recent years, transitioning from rule-based approaches to machine learning and, more recently, deep learning. With new methods come new challenges, however, especially for those new to the field. This review provides an overview of clinical text mining for those who are encountering it for the first time (e.g., physician researchers, operational analytics teams, machine learning scientists from other domains). While not a comprehensive survey, this review describes the state of the art, with a particular focus on new tasks and methods developed over the past few years. It also identifies key barriers between these remarkable technical advances and the practical realities of implementation in health systems and in industry.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21219,""
"Design and implementation of a standard care programme of therapeutic exercise and education for breast cancer survivors","RoldÃƒÂ¡n-JimÃƒÂ©nez, Pajares, Ruiz-Medina, Trinidad-FernÃƒÂ¡ndez, GonzÃƒÂ¡lez-SÃƒÂ¡nchez, Ribelles, GarcÃƒÂ­a-Almeida, RÃƒÂ­os-LÃƒÂ³pez, Alba, Cuesta-Vargas","https://doi.org/10.1007/s00520-021-06470-9","20210903","PubMed","Breast cancer; Breast cancer survivors; Community; Exercise therapy; Nutrition therapy","Breast cancer survivors (BCS) face several symptoms and are at higher risk of weight gain following diagnosis. Current literature shows that both exercise and diet play a key role in recovery of BCS. However, there is a gap between current guidelines and the real-world context. The aim of this article is to describe the process behind a free, not-for-profit community-based therapeutic exercise and education programme (TEEP) for BCS in the clinical setting. The ""Onco-Health Club"" (OHC) consists of therapeutic exercise (TE) intervention aimed at ameliorating cancer-related fatigue (CRF) and improving QoL and physical function. TE is supplemented with nutritional education, providing information about the Mediterranean diet. To this end, patients are recruited from an oncologist and are referred to a physiotherapist and a nutritionist for baseline assessment. TEEP consists of a 3-month intervention, delivered twice a week in a group format with 1Ã‚Â h of TE and 30Ã‚Â min of nutritional education. BCS then have a final assessment and are advised to continue with a healthy lifestyle. Data about referral, compliance and assessment were collected. From May 2017 to February of 2020, a total of 158 patients were recruited from 8 cohorts and 142 initially started the OHC. From 119 that joined the program, 96 patients were considered to have finished it with good adherence (assistanceÃ¢â‚¬â€°&gt;Ã¢â‚¬â€°80%). BCS significantly improved their QoL, as well as upper and lower limb's function, and increased their level of physical activity. CRF tended to decrease (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.005). This study obtained data on recruitment, compliance, and possible limitations of these kinds of programmes in a real-world context. Further research is needed in order to optimize patient engagement and compliance, as well as to determine the transferability of these programmes in the clinical setting. NCT03879096, Registered 18th March 2019. Retrospectively registered.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21220,""
"Automatic ICD-10 Coding and Training System: Deep Neural Network Based on Supervised Learning","Chen, Wang, Liao, Kuo, Chen, Lin, Yang, Chiu, Chang, Lai","https://doi.org/10.2196/23230","20210929","PubMed","International Classification of Diseases; Recurrent Neural Network; deep learning; natural language processing; text classification","The International Classification of Diseases (ICD) code is widely used as the reference in medical system and billing purposes. However, classifying diseases into ICD codes still mainly relies on humans reading a large amount of written material as the basis for coding. Coding is both laborious and time-consuming. Since the conversion of ICD-9 to ICD-10, the coding task became much more complicated, and deep learning- and natural language processing-related approaches have been studied to assist disease coders. This paper aims at constructing a deep learning model for ICD-10 coding, where the model is meant to automatically determine the corresponding diagnosis and procedure codes based solely on free-text medical notes to improve accuracy and reduce human effort. We used diagnosis records of the National Taiwan University Hospital as resources and apply natural language processing techniques, including global vectors, word to vectors, embeddings from language models, bidirectional encoder representations from transformers, and single head attention recurrent neural network, on the deep neural network architecture to implement ICD-10 auto-coding. Besides, we introduced the attention mechanism into the classification model to extract the keywords from diagnoses and visualize the coding reference for training freshmen in ICD-10. Sixty discharge notes were randomly selected to examine the change in the F<sub>1</sub>-score and the coding time by coders before and after using our model. In experiments on the medical data set of National Taiwan University Hospital, our prediction results revealed F<sub>1</sub>-scores of 0.715 and 0.618 for the ICD-10 Clinical Modification code and Procedure Coding System code, respectively, with a bidirectional encoder representations from transformers embedding approach in the Gated Recurrent Unit classification model. The well-trained models were applied on the ICD-10 web service for coding and training to ICD-10 users. With this service, coders can code with the F<sub>1</sub>-score significantly increased from a median of 0.832 to 0.922 (P&lt;.05), but not in a reduced interval. The proposed model significantly improved the F<sub>1</sub>-score but did not decrease the time consumed in coding by disease coders.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21221,""
"Cardiogenic shock and machine learning: A systematic review on prediction through clinical decision support softwares","Aleman, Patel, Sleiman, Navia, Sheffield, Brozzi","https://doi.org/10.1111/jocs.15934","20211004","PubMed","area under the curve; cardiogenic shock; early detection; machine learning; receiving operating characteristics; systematic review; Decision Support Systems, Clinical; Female; Humans; Machine Learning; Sensitivity and Specificity; Shock, Cardiogenic; Software","Cardiogenic shock (CS) withholds a significantly high mortality rate between 40% and 60% despite advances in diagnosis and medical/surgical intervention. To date, machine learning (ML) is being implemented to integrate numerous data to optimize early diagnostic predictions and suggest clinical courses. This systematic review summarizes the area under the curve (AUC) receiver operating characteristics (ROCs) accuracy for the early prediction of CS. A systematic review was conducted within databases of PubMed, ScienceDirect, Clinical Key/MEDLINE, Embase, GoogleScholar, and Cochrane. Cohort studies that assessed the accuracy of early detection of CS using ML software were included. Data extraction was focused on AUC-ROC values directed towards the early detection of CS. A total of 943 studies were included for systematic review. From the reviewed studies, 2.2% (NÃ¢â‚¬â€°=Ã¢â‚¬â€°21) evaluated patient outcomes, of which 14.3% (NÃ¢â‚¬â€°=Ã¢â‚¬â€°3) were assessed. The collective patient cohort (NÃ¢â‚¬â€°=Ã¢â‚¬â€°698) consisted of 314 (45.0%) females, with an average age and body mass index of 64.1 years and 28.1Ã¢â‚¬â€°kg/m<sup>2</sup> , respectively. Collectively, 159 (22.8%) mortalities were reported following early CS detection. Altogether, the AUC-ROC value was 0.82 (ÃŽÂ±Ã¢â‚¬â€°=Ã¢â‚¬â€°.05), deeming it of superb sensitivity and specificity. From the present comprehensively gathered data, this study accounts the use of ML software for the early detection of CS in a clinical setting as a valid tool to predict patients at risk of CS. The complexity of ML and its parallel lack of clinical evidence implies that further prospective randomized control trials are needed to draw definitive conclusions before standardizing the use of these technologies. The catastrophic risk of developing CS continues to be a concern in the management of critical cardiac care. The use of ML predictive models have the potential to provide the accurate and necessary feedback for the early detection and proper management of CS. This systematic review summarizes the AUC-ROCs accuracy for the early prediction of CS.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21222,""
"Automated Detection and Diagnosis of Diabetic Retinopathy: A Comprehensive Survey","Lakshminarayanan, Kheradfallah, Sarkar, Jothi Balaji","https://doi.org/10.3390/jimaging7090165","20211029","PubMed","artificial intelligence; datasets; deep learning; diabetic retinopathy; fundus image; machine-learning; ophthalmology; optical coherence tomography","Diabetic Retinopathy (DR) is a leading cause of vision loss in the world. In the past few years, artificial intelligence (AI) based approaches have been used to detect and grade DR. Early detection enables appropriate treatment and thus prevents vision loss. For this purpose, both fundus and optical coherence tomography (OCT) images are used to image the retina. Next, Deep-learning (DL)-/machine-learning (ML)-based approaches make it possible to extract features from the images and to detect the presence of DR, grade its severity and segment associated lesions. This review covers the literature dealing with AI approaches to DR such as ML and DL in classification and segmentation that have been published in the open literature within six years (2016-2021). In addition, a comprehensive list of available DR datasets is reported. This list was constructed using both the PICO (P-Patient, I-Intervention, C-Control, O-Outcome) and Preferred Reporting Items for Systematic Review and Meta-analysis (PRISMA) 2009 search strategies. We summarize a total of 114 published articles which conformed to the scope of the review. In addition, a list of 43 major datasets is presented.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21223,""
"Unsupervised Approaches for the Segmentation of Dry ARMD Lesions in Eye Fundus cSLO Images","Royer, Sublime, Rossant, Paques","https://doi.org/10.3390/jimaging7080143","20211029","PubMed","W-net; automatic segmentation; clustering; dry ARMD; unsupervised learning","Age-related macular degeneration (ARMD), a major cause of sight impairment for elderly people, is still not well understood despite intensive research. Measuring the size of the lesions in the fundus is the main biomarker of the severity of the disease and as such is widely used in clinical trials yet only relies on manual segmentation. Artificial intelligence, in particular automatic image analysis based on neural networks, has a major role to play in better understanding the disease, by analyzing the intrinsic optical properties of dry ARMD lesions from patient images. In this paper, we propose a comparison of automatic segmentation methods (classical computer vision method, machine learning method and deep learning method) in an unsupervised context applied on cSLO IR images. Among the methods compared, we propose an adaptation of a fully convolutional network, called W-net, as an efficient method for the segmentation of ARMD lesions. Unlike supervised segmentation methods, our algorithm does not require annotated data which are very difficult to obtain in this application. Our method was tested on a dataset of 328 images and has shown to reach higher quality results than other compared unsupervised methods with a F1 score of 0.87, while having a more stable model, even though in some specific cases, texture/edges-based methods can produce relevant results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21224,""
"A Green Prospective for Learned Post-Processing in Sparse-View Tomographic Reconstruction","Morotti, Evangelista, Loli Piccolomini","https://doi.org/10.3390/jimaging7080139","20211029","PubMed","CNN; UNet; green AI; learned post-processing; sparse-views tomography; tomographic reconstruction","Deep Learning is developing interesting tools that are of great interest for inverse imaging applications. In this work, we consider a medical imaging reconstruction task from subsampled measurements, which is an active research field where Convolutional Neural Networks have already revealed their great potential. However, the commonly used architectures are very deep and, hence, prone to overfitting and unfeasible for clinical usages. Inspired by the ideas of the green AI literature, we propose a shallow neural network to perform efficient Learned Post-Processing on images roughly reconstructed by the filtered backprojection algorithm. The results show that the proposed inexpensive network computes images of comparable (or even higher) quality in about one-fourth of time and is more robust than the widely used and very deep ResUNet for tomographic reconstructions from sparse-view protocols.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21225,""
"Transfer Learning in Magnetic Resonance Brain Imaging: A Systematic Review","Valverde, Imani, Abdollahzadeh, De Feo, Prakash, Ciszek, Tohka","https://doi.org/10.3390/jimaging7040066","20210903","PubMed","artificial intelligence; brain; convolutional neural networks; machine learning; magnetic resonance imaging; survey; systematic review; transfer learning","(1) Background: Transfer learning refers to machine learning techniques that focus on acquiring knowledge from related tasks to improve generalization in the tasks of interest. In magnetic resonance imaging (MRI), transfer learning is important for developing strategies that address the variation in MR images from different imaging protocols or scanners. Additionally, transfer learning is beneficial for reutilizing machine learning models that were trained to solve different (but related) tasks to the task of interest. The aim of this review is to identify research directions, gaps in knowledge, applications, and widely used strategies among the transfer learning approaches applied in MR brain imaging; (2) Methods: We performed a systematic literature search for articles that applied transfer learning to MR brain imaging tasks. We screened 433 studies for their relevance, and we categorized and extracted relevant information, including task type, application, availability of labels, and machine learning methods. Furthermore, we closely examined brain MRI-specific transfer learning approaches and other methods that tackled issues relevant to medical imaging, including privacy, unseen target domains, and unlabeled data; (3) Results: We found 129 articles that applied transfer learning to MR brain imaging tasks. The most frequent applications were dementia-related classification tasks and brain tumor segmentation. The majority of articles utilized transfer learning techniques based on convolutional neural networks (CNNs). Only a few approaches utilized clearly brain MRI-specific methodology, and considered privacy issues, unseen target domains, or unlabeled data. We proposed a new categorization to group specific, widely-used approaches such as pretraining and fine-tuning CNNs; (4) Discussion: There is increasing interest in transfer learning for brain MRI. Well-known public datasets have clearly contributed to the popularity of Alzheimer's diagnostics/prognostics and tumor segmentation as applications. Likewise, the availability of pretrained CNNs has promoted their utilization. Finally, the majority of the surveyed studies did not examine in detail the interpretation of their strategies after applying transfer learning, and did not compare their approach with other transfer learning approaches.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21226,""
"Emerging artificial intelligence applications in otological imaging","Chawdhary, Shoman","https://doi.org/10.1097/MOO.0000000000000754","20211025","PubMed","Algorithms; Artificial Intelligence; Endolymphatic Hydrops; Humans; Magnetic Resonance Imaging; Meniere Disease","To highlight the recent literature on artificial intelligence (AI) pertaining to otological imaging and to discuss future directions, obstacles and opportunities. The main themes in the recent literature centre around automated otoscopic image diagnosis and automated image segmentation for application in virtual reality surgical simulation and planning. Other applications that have been studied include identification of tinnitus MRI biomarkers, facial palsy analysis, intraoperative augmented reality systems, vertigo diagnosis and endolymphatic hydrops ratio calculation in Meniere's disease. Studies are presently at a preclinical, proof-of-concept stage. The recent literature on AI in otological imaging is promising and demonstrates the future potential of this technology in automating certain imaging tasks in a healthcare environment of ever-increasing demand and workload. Some studies have shown equivalence or superiority of the algorithm over physicians, albeit in narrowly defined realms. Future challenges in developing this technology include the compilation of large high quality annotated datasets, fostering strong collaborations between the health and technology sectors, testing the technology within real-world clinical pathways and bolstering trust among patients and physicians in this new method of delivering healthcare.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21227,""
"The Role of Debriefing in a Community Health Study Abroad","Steppe, White, Keen, Blake, Thompson","https://doi.org/10.1177/10436596211042411","20210830","PubMed","InternatÃ¢â‚¬â„¢l educational experiences; baccalaureate programs; nursing practice","Study abroad experiences offer nursing students the opportunity to develop cultural competence and sensitivity while providing care within the context of a different culture. Debriefing is a strategy that engages students in conversation and active reflection to process emotions, examine personal values, and synthesize knowledge gained from active learning experiences. While debriefing can enhance learning outcomes in study abroad programs, there is currently a paucity of literature that explores its use within the context of study abroad. In this article, we describe a structured debriefing approach we use in an international community health clinical experience. We conclude with a discussion of the lessons we have learned to improve the effectiveness of our debriefing sessions and recommendations for future research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21228,""
"X-Ray Equipped with Artificial Intelligence: Changing the COVID-19 Diagnostic Paradigm during the Pandemic","Ghaderzadeh, Aria, Asadi","https://doi.org/10.1155/2021/9942873","20210908","PubMed","Algorithms; Artificial Intelligence; COVID-19; COVID-19 Testing; Humans; ROC Curve; SARS-CoV-2; Tomography, X-Ray Computed","Due to the excessive use of raw materials in diagnostic tools and equipment during the COVID-19 pandemic, there is a dire need for cheaper and more effective methods in the healthcare system. With the development of artificial intelligence (AI) methods in medical sciences as low-cost and safer diagnostic methods, researchers have turned their attention to the use of imaging tools with AI that have fewer complications for patients and reduce the consumption of healthcare resources. Despite its limitations, X-ray is suggested as the first-line diagnostic modality for detecting and screening COVID-19 cases. This systematic review assessed the current state of AI applications and the performance of algorithms in X-ray image analysis. The search strategy yielded 322 results from four databases and google scholar, 60 of which met the inclusion criteria. The performance statistics included the area under the receiver operating characteristics (AUC) curve, accuracy, sensitivity, and specificity. The average sensitivity and specificity of CXR equipped with AI algorithms for COVID-19 diagnosis were &gt;96% (83%-100%) and 92% (80%-100%), respectively. For common X-ray methods in COVID-19 detection, these values were 0.56 (95% CI 0.51-0.60) and 0.60 (95% CI 0.54-0.65), respectively. AI has substantially improved the diagnostic performance of X-rays in COVID-19. X-rays equipped with AI can serve as a tool to screen the cases requiring CT scans. The use of this tool does not waste time or impose extra costs, has minimal complications, and can thus decrease or remove unnecessary CT slices and other healthcare resources.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21229,""
"An Examination of the Statistical Laws of Semantic Change in Clinical Notes","Peterson, Liu","https://www.google.com/search?q=An+Examination+of+the+Statistical+Laws+of+Semantic+Change+in+Clinical+Notes.","20210910","PubMed","Humans; Language; Natural Language Processing; Semantics; Unified Medical Language System","Natural language is continually changing. Given the prevalence of unstructured, free-text clinical notes in the healthcare domain, understanding the aspects of this change is of critical importance to clinical Natural Language Processing (NLP) systems. In this study, we examine two previously described semantic change laws based on word frequency and polysemy, and analyze how they apply to the clinical domain. We also explore a new facet of change: whether domain-specific clinical terms exhibit different change patterns compared to general-purpose English. Using a corpus spanning eighteen years of clinical notes, we find that the previously described laws of semantic change hold for our data set. We also find that domain-specific biomedical terms change faster compared to general English words.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21230,""
"Understanding Clinical Trial Reports: Extracting Medical Entities and Their Relations","Nye, DeYoung, Lehman, Nenkova, Marshall, Wallace","https://www.google.com/search?q=Understanding+Clinical+Trial+Reports:+Extracting+Medical+Entities+and+Their+Relations.","20210910","PubMed","Humans; Natural Language Processing","The best evidence concerning comparative treatment effectiveness comes from clinical trials, the results of which are reported in unstructured articles. Medical experts must manually extract information from articles to inform decision-making, which is time-consuming and expensive. Here we consider the <i>end-to-end</i> task of both (a) extracting treatments and outcomes from full-text articles describing clinical trials (entity identification) and, (b) inferring the reported results for the former with respect to the latter (relation extraction). We introduce new data for this task, and evaluate models that have recently achieved state-of-the-art results on similar tasks in Natural Language Processing. We then propose a new method motivated by how trial results are typically presented that outperforms these purely data-driven baselines. Finally, we run a fielded evaluation of the model with a non-profit seeking to identify existing drugs that might be re-purposed for cancer, showing the potential utility of end-to-end evidence extraction systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21231,""
"Deep EHR Spotlight: a Framework and Mechanism to Highlight Events in Electronic Health Records for Explainable Predictions","Nguyen-Duc, Mulligan, Mannu, Bettencourt-Silva","https://www.google.com/search?q=Deep+EHR+Spotlight:+a+Framework+and+Mechanism+to+Highlight+Events+in+Electronic+Health+Records+for+Explainable+Predictions.","20210910","PubMed","Deep Learning; Electronic Health Records; Humans","The wide adoption of Electronic Health Records (EHR) has resulted in large amounts of clinical data becoming available, which promises to support service delivery and advance clinical and informatics research. Deep learning techniques have demonstrated performance in predictive analytic tasks using EHRs yet they typically lack model result transparency or explainability functionalities and require cumbersome pre-processing tasks. Moreover, EHRs contain heterogeneous and multi-modal data points such as text, numbers and time series which further hinder visualisation and interpretability. This paper proposes a deep learning framework to: 1) encode patient pathways from EHRs into images, 2) highlight important events within pathway images, and 3) enable more complex predictions with additional intelligibility. The proposed method relies on a deep attention mechanism for visualisation of the predictions and allows predicting multiple sequential outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21232,""
"Empirical Findings on the Role of Structured Data, Unstructured Data, and their Combination for Automatic Clinical Phenotyping","Moldwin, Demner-Fushman, Goodwin","https://www.google.com/search?q=Empirical+Findings+on+the+Role+of+Structured+Data,+Unstructured+Data,+and+their+Combination+for+Automatic+Clinical+Phenotyping.","20210910","PubMed","Critical Care; Databases, Factual; Electronic Health Records; Humans; Phenotype","The objective of this study is to explore the role of structured and unstructured data for clinical phenotyping by determining which types of clinical phenotypes are best identified using unstructured data (e.g., clinical notes), structured data (e.g., laboratory values, vital signs), or their combination across 172 clinical phenotypes. Specifically, we used laboratory and chart measurements as well as clinical notes from the MIMIC-III critical care database and trained an LSTM using features extracted from each type of data to determine which categories of phenotypes were best identified by structured data, unstructured data, or both. We observed that textual features on their own outperformed structured features for 145 (84%) of phenotypes, and that Doc2Vec was the most effective representation of unstructured data for all phenotypes. When evaluating the impact of adding textual features to systems previously relying only on structured features, we found a statistically significant (p &lt; 0.05) increase in phenotyping performance for 51 phenotypes (primarily involving the circulatory system, injury, and poisoning), one phenotype for which textual features degraded performance (diabetes without complications), and no statistically significant change in performance with the remaining 120 phenotypes. We provide analysis on which phenotypes are best identified by each type of data and guidance on which data sources to consider for future research on phenotype identification.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21233,""
"Integration of NLP2FHIR Representation with Deep Learning Models for EHR Phenotyping: A Pilot Study on Obesity Datasets","Liu, Luo, Stone, Zong, Wen, Yu, Rasmussen, Wang, Pathak, Liu, Jiang","https://www.google.com/search?q=Integration+of+NLP2FHIR+Representation+with+Deep+Learning+Models+for+EHR+Phenotyping:+A+Pilot+Study+on+Obesity+Datasets.","20210910","PubMed","Algorithms; Deep Learning; Electronic Health Records; Humans; Obesity; Pilot Projects","HL7 Fast Healthcare Interoperability Resources (FHIR) is one of the current data standards for enabling electronic healthcare information exchange. Previous studies have shown that FHIR is capable of modeling both structured and unstructured data from electronic health records (EHRs). However, the capability of FHIR in enabling clinical data analytics has not been well investigated. The objective of the study is to demonstrate how FHIR-based representation of unstructured EHR data can be ported to deep learning models for text classification in clinical phenotyping. We leverage and extend the NLP2FHIR clinical data normalization pipeline and conduct a case study with two obesity datasets. We tested several deep learning-based text classifiers such as convolutional neural networks, gated recurrent unit, and text graph convolutional networks on both raw text and NLP2FHIR inputs. We found that the combination of NLP2FHIR input and text graph convolutional networks has the highest F1 score. Therefore, FHIR-based deep learning methods has the potential to be leveraged in supporting EHR phenotyping, making the phenotyping algorithms more portable across EHR systems and institutions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21234,""
"A Comparison between Human and NLP-based Annotation of Clinical Trial Eligibility Criteria Text Using The OMOP Common Data Model","Li, Liu, Kury, Yuan, Butler, Sun, Ostropolets, Xu, Weng","https://www.google.com/search?q=A+Comparison+between+Human+and+NLP-based+Annotation+of+Clinical+Trial+Eligibility+Criteria+Text+Using+The+OMOP+Common+Data+Model.","20210910","PubMed","Humans; Natural Language Processing","Human annotations are the established gold standard for evaluating natural language processing (NLP) methods. The goals of this study are to quantify and qualify the disagreement between human and NLP. We developed an NLP system for annotating clinical trial eligibility criteria text and constructed a manually annotated corpus, both following the OMOP Common Data Model (CDM). We analyzed the discrepancies between the human and NLP annotations and their causes (e.g., ambiguities in concept categorization and tacit decisions on inclusion of qualifiers and temporal attributes during concept annotation). This study initially reported complexities in clinical trial eligibility criteria text that complicate NLP and the limitations of the OMOP CDM. The disagreement between and human and NLP annotations may be generalizable. We discuss implications for NLP evaluation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21235,""
"Retention and Transfer of Cognitive Bias Mitigation Interventions: A Systematic Literature Study","Korteling, Gerritsma, Toet","https://doi.org/10.3389/fpsyg.2021.629354","20210831","PubMed","bias mitigation; cognitive biases; neural networks; retention; systematic literature study; training interventions; transfer of training","Cognitive biases can adversely affect human judgment and decision making and should therefore preferably be mitigated, so that we can achieve our goals as effectively as possible. Hence, numerous bias mitigation interventions have been developed and evaluated. However, to be effective in practical situations beyond laboratory conditions, the bias mitigation effects of these interventions should be retained over time and should transfer across contexts. This systematic review provides an overview of the literature on retention and transfer of bias mitigation interventions. A systematic search yielded 52 studies that were eligible for screening. At the end of the selection process, only 12 peer-reviewed studies remained that adequately studied retention over a period of at least 14 days (all 12 studies) or transfer to different tasks and contexts (one study). Eleven of the relevant studies investigated the effects of bias mitigation training using game- or video-based interventions. These 11 studies showed considerable overlap regarding the biases studied, kinds of interventions, and decision-making domains. Most of them indicated that gaming interventions were effective after the retention interval and that games were more effective than video interventions. The study that investigated transfer of bias mitigation training (next to retention) found indications of transfer across contexts. To be effective in practical circumstances, achieved effects of cognitive training should lead to enduring changes in the decision maker's behavior and should generalize toward other task domains or training contexts. Given the small number of overlapping studies, our main conclusion is that there is currently insufficient evidence that bias mitigation interventions will substantially help people to make better decisions in real life conditions. This is in line with recent theoretical insights about the ""hard-wired"" neural and evolutionary origin of cognitive biases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21236,""
"Is the presence of 10-MDP associated to higher bonding performance for self-etching adhesive systems? A meta-analysis of in vitro studies","Fehrenbach, Isolan, MÃƒÂ¼nchow","https://doi.org/10.1016/j.dental.2021.08.014","20211018","PubMed","Dental bonding; Dentin; Enamel; Functional acidic monomer; Universal adhesives; Bayes Theorem; Dental Bonding; Dental Cements; Dentin; Dentin-Bonding Agents; Materials Testing; Methacrylates; Resin Cements; Tensile Strength","The purpose of this systematic review and meta-analysis was to analyze the literature on the bond strength of self-etching (SE) adhesives containing 10-MDP or other acidic functional monomers, comparing the bonding performance of both compositions. This study is registered in PROSPERO (CRD42020175715) and it followed the PRISMA Statement. The literature search was performed in PubMed, Web of Science, SciELO, Scopus, LILACS, IBECS, and BBO from the starting coverage date through 30 June 2021. Study eligibility criteria consisted of in vitro studies that evaluated the bond strength (microtensile, microshear, tensile or shear testing) to sound dentin/enamel of a minimum of two distinct SE systems, with at least one material containing 10-MDP and one other being comprised of a distinct acidic composition. Statistical analyses were carried out with RevMan 5.3.5 and using random-effects models with the significance level at p &lt; 0.05. Also, Bayesian network meta-analysis (NMA) was conducted using MetaInsight V3 tool. From 740 relevant studies evaluated in full-text analysis, 210 were incorporated to the systematic review and 206 in meta-analysis. The majority of studies was classified as having medium risk of bias (56.7%), followed by low (35.2%) and high (8.1%) risk of bias. Data from a total of 64 adhesive systems were collected, which favored the 10-MDP-based group at both dentin (overall effect: 6.98; 95% CI: 5.61, 8.36; p &lt; 0.00001) and enamel (overall effect: 2.79; 95% CI: 1.62, 3.96; p &lt; 0.00001) substrates. Microtensile testing was more frequently used (73.4%) in the included studies. Adhesives based on 10-MDP showed greater bonding performance than adhesives comprised of monomers such as PENTA, 6-MHP, 4-META, 4-MET, pyrophosphate esters, mixed composition or monomers derived from sulfonic acid (p Ã¢â€°Â¤ 0.01); whereas similar bond strength values were verified between 10-MDP-based materials and those containing PEM-F, acrylamide phosphates, 4-AET, MAC-10, or monomers derived from polyacrylic and phosphonic acids (p Ã¢â€°Â¥ 0.05). Adhesives based on GPDM were the only ones that resulted in greater bonding potential than the 10-MDP-based group (p = 0.03). Dental bonds in dentin were favored with the application of 2-step 10-MDP-based adhesives; whereas in enamel the dental bonds were favored for both 2-steps versions of adhesives, regardless of the presence of 10-MDP. Indirect evidence from NMA revealed that 1-step 10-MDP-free and universal 10-MDP-free adhesives seemed to perform worst in dentin and enamel, respectively. Adhesives containing 10-MDP showed higher bonding performance than materials formulated with other acidic ingredients, although this result relied on the type of mechanical testing, type of the substrate, acidic composition of the adhesive, and the application category of the SE system. This review summarized the effects of the foregoing factors on the adhesion to dental substrates.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21237,""
"A deep CNN model for anomaly detection and localization in wireless capsule endoscopy images","Jain, Seal, Ojha, Yazidi, Bures, Tacheci, Krejcar","https://doi.org/10.1016/j.compbiomed.2021.104789","20211011","PubMed","Anomaly detection; Attention mechanism; Deep convolutional neural network; Localization; Wireless capsule endoscopy; Algorithms; Capsule Endoscopy; Image Processing, Computer-Assisted; Machine Learning; Neural Networks, Computer; ROC Curve","Wireless capsule endoscopy (WCE) is one of the most efficient methods for the examination of gastrointestinal tracts. Computer-aided intelligent diagnostic tools alleviate the challenges faced during manual inspection of long WCE videos. Several approaches have been proposed in the literature for the automatic detection and localization of anomalies in WCE images. Some of them focus on specific anomalies such as bleeding, polyp, lesion, etc. However, relatively fewer generic methods have been proposed to detect all those common anomalies simultaneously. In this paper, a deep convolutional neural network (CNN) based model 'WCENet' is proposed for anomaly detection and localization in WCE images. The model works in two phases. In the first phase, a simple and efficient attention-based CNN classifies an image into one of the four categories: polyp, vascular, inflammatory, or normal. If the image is classified in one of the abnormal categories, it is processed in the second phase for the anomaly localization. Fusion of Grad-CAM++ and a custom SegNet is used for anomalous region segmentation in the abnormal image. WCENet classifier attains accuracy and area under receiver operating characteristic of 98% and 99%. The WCENet segmentation model obtains a frequency weighted intersection over union of 81%, and an average dice score of 56% on the KID dataset. WCENet outperforms nine different state-of-the-art conventional machine learning and deep learning models on the KID dataset. The proposed model demonstrates potential for clinical applications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21238,""
"Intelligent localization and quantitative evaluation of anterior talofibular ligament injury using magnetic resonance imaging of ankle","Yan, Meng, Sun, Yu, Wang","https://doi.org/10.1186/s12880-021-00660-x","20211011","PubMed","Anterior talofibular ligament; DRLSE; Intelligent localization of ATFL; Magnetic resonance imaging; Quantitative evaluation of ATFL injury","There is a high incidence of injury to the lateral ligament of the ankle in daily living and sports activities. The anterior talofibular ligament (ATFL) is the most frequent types of ankle injuries. It is of great clinical significance to achieve intelligent localization and injury evaluation of ATFL due to its vulnerability. According to the specific characteristics of bones in different slices, the key slice was extracted by image segmentation and characteristic analysis. Then, the talus and fibula in the key slice were segmented by distance regularized level set evolution (DRLSE), and the curvature of their contour pixels was calculated to find useful feature points including the neck of talus, the inner edge of fibula, and the outer edge of fibula. ATFL area can be located using these feature points so as to quantify its first-order gray features and second-order texture features. Support vector machine (SVM) was performed for evaluation of ATFL injury. Data were collected retrospectively from 158 patients who underwent MRI, and were divided into normal (68) and tear (90) group. The positioning accuracy and Dice coefficient were used to measure the performance of ATFL localization, and the mean values are 87.7% and 77.1%, respectively, which is helpful for the following feature extraction. SVM gave a good prediction ability with accuracy of 93.8%, sensitivity of 88.9%, specificity of 100%, precision of 100%, and F1 score of 94.2% in the test set. Experimental results indicate that the proposed method is reliable in diagnosing ATFL injury. This study may provide a potentially viable method for aided clinical diagnoses of some ligament injury.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21239,""
"Systematic review of automatic assessment systems for resistance-training movement performance: A data science perspective","Hart, Smith, Zhang","https://doi.org/10.1016/j.compbiomed.2021.104779","20211011","PubMed","Machine learning; Movement assessment; Movement classification; Rehabilitation; Resistance training; Data Science; Humans; Machine Learning; Movement; Resistance Training","The technical performance of resistance-training (RT) movement is commonly monitored through visual assessment and feedback by trained practitioners or by individual self-evaluation. However, both approaches are limited due to their subjectivity, inability to monitor multiple joints simultaneously, and dependency on the assessor's or exerciser's experience and skill. Portable data collection devices and machine learning (ML) have been combined to overcome these limitations by providing objective assessments for RT movement performance. This systematic review evaluates systems developed for providing objective, automatic assessment for RT movements used to improve physical performance and/or rehabilitation in otherwise healthy individuals. Databases searched included Scopus, PubMed and Engineering Village. From 363 papers initially identified, 13 met the inclusion and exclusion criteria. Information extracted from the collated papers included the experimental protocols, data processing, ML model development methodology and movement classification performance. Identified movement assessment systems ranged in classification performance (accuracy of 70%-90% for most classifiers). However, several methodological errors in the development of the ML models were identified, and additional aspects such as model interpretability or generalisability were often neglected. Future ML models should adopt the correct developmental methodology and provide interpretable and generalisable models for application in the RT environment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21240,""
"Machine learning applications in tobacco research: a scoping review","Fu, Kundu, Mitsakakis, Elton-Marshall, Wang, Hill, Bondy, Hamilton, Selby, Schwartz, Chaiton","https://doi.org/10.1136/tobaccocontrol-2020-056438","20210828","PubMed","health services; public policy; surveillance and monitoring","Identify and review the body of tobacco research literature that self-identified as using machine learning (ML) in the analysis. MEDLINE, EMABSE, PubMed, CINAHL Plus, APA PsycINFO and IEEE Xplore databases were searched up to September 2020. Studies were restricted to peer-reviewed, English-language journal articles, dissertations and conference papers comprising an empirical analysis where ML was identified to be the method used to examine human experience of tobacco. Studies of genomics and diagnostic imaging were excluded. Two reviewers independently screened the titles and abstracts. The reference list of articles was also searched. In an iterative process, eligible studies were classified into domains based on their objectives and types of data used in the analysis. Using data charting forms, two reviewers independently extracted data from all studies. A narrative synthesis method was used to describe findings from each domain such as study design, objective, ML classes/algorithms, knowledge users and the presence of a data sharing statement. Trends of publication were visually depicted. 74 studies were grouped into four domains: ML-powered technology to assist smoking cessation (n=22); content analysis of tobacco on social media (n=32); smoker status classification from narrative clinical texts (n=6) and tobacco-related outcome prediction using administrative, survey or clinical trial data (n=14). Implications of these studies and future directions for ML researchers in tobacco control were discussed. ML represents a powerful tool that could advance the research and policy decision-making of tobacco control. Further opportunities should be explored.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21241,""
"A systematic review and meta-analysis of the effects of aerobic exercise interventions on cardiorespiratory fitness in adults with intellectual disability","Obrusnikova, Firkin, Farquhar","https://doi.org/10.1016/j.dhjo.2021.101185","20210828","PubMed","Aerobic exercise; Cardiorespiratory fitness; Intellectual disability; Meta-analysis; Oxygen consumption","Adults with an intellectual disability (ID) have low cardiorespiratory fitness (CRF). Low CRF has been associated with a high risk of cardiovascular disease and all-cause mortality. Participation in regular exercise can help adults with ID increase their CRF. To perform a systematic review and meta-analysis of published, peer-reviewed clinical trials that evaluated the effects of aerobic exercise (AE) interventions on CRF in adults with ID, ages 18-65 years. English-language articles were searched up to June 2021 from 11 electronic databases. Data were extracted using an author-developed form. Two independent authors assessed the risk of bias using the Tool for the Assessment of Study Quality and reporting in Exercise (TESTEX). Meta-analysis was performed using the RevMan 5.3. Of the 1870 article titles and abstracts screened, 16 articles were included. The average TESTEX score (out of 15) was 8.1 (SDÃ‚Â =Ã‚Â 3.5, range 2-14). The pooled effect was statistically significant (SMDÃ‚Â =Ã‚Â 0.41, 95% CI: 0.19 to 0.63, zÃ‚Â =Ã‚Â 3.59; pÃ‚Â =Ã‚Â .000) with moderate heterogeneity (I<sup>2</sup>Ã‚Â =Ã‚Â 35%, pÃ‚Â =Ã‚Â .000). Both types of intervention produced statistically significant CRF gains, with interventions that combined AE with resistance, balance, and/or flexibility exercises being slightly more effective (SMDÃ‚Â =Ã‚Â 0.40, 95% CI: 0.11 to 0.70, pÃ‚Â =Ã‚Â .007) than non-combined interventions (SMDÃ‚Â =Ã‚Â 0.42, 95% CI: 0.05 to 0.79, pÃ‚Â =Ã‚Â .02). Heterogeneity was moderate but non-significant for both types of intervention. The review supports the use of AE interventions in promoting CRF in adults with ID. The interpretation is limited by the quality of evidence and by poorly described and/or executed familiarization and measurement protocols.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21242,""
"Computer Vision-Based Construction Process Sensing for Cyber-Physical Systems: A Review","Zhang, Yang, Wang, Wang, Liu, Fang","https://doi.org/10.3390/s21165468","20210831","PubMed","computer vision; cyberÃ¢â‚¬â€œphysical systems; review; sensing system; Automation; Computers; Engineering","Cyber-physical systems (CPSs) are generally considered to be the next generation of engineered systems. However, the actual application of CPSs in the Architecture, Engineering and Construction (AEC) industry is still at a low level. The sensing method in the construction process plays a very important role in the establishment of CPSs. Therefore, the purpose of this paper is to discuss the application potential of computer vision-based sensing methods and provide practical suggestions through a literature review. This paper provides a review of the current application of CPSs in the AEC industry, summarizes the current knowledge gaps, and discusses the problems with the current construction site sensing approach. Considering the unique advantages of the computer vision (CV) method at the construction site, the application of CV for different construction entities was reviewed and summarized to achieve a CV-based construction site sensing approach for construction process CPSs. The potential of CPS can be further stimulated by providing rich information from on-site sensing using CV methods. According to the review, this approach has unique advantages in the specific environment of the construction site. Based on the current knowledge gap identified in the literature review, this paper proposes a novel concept of visual-based construction site sensing method for CPS application, and an architecture for CV-based CPS is proposed as an implementation of this concept. The main contribution of this paper is to propose a CPS architecture using computer vision as the main information acquisition method based on the literature review. This architecture innovatively introduces computer vision as a sensing method of construction sites, and realizes low-cost and non-invasive information acquisition in complex construction scenarios. This method can be used as an important supplement to on-site sensing to further promote the automation and intelligence of the construction process.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21243,""
"Designing a Simple Fiducial Marker for Localization in Spatial Scenes Using Neural Networks","KoÃ…Â¡Ã…Â¥ÃƒÂ¡k, SlabÃƒÂ½","https://doi.org/10.3390/s21165407","20210831","PubMed","augmented reality; computer vision; deep learning; fiducial marker; neural network; Augmented Reality; Fiducial Markers; Neural Networks, Computer; Space Perception","The paper describes the process of designing a simple fiducial marker. The marker is meant for use in augmented reality applications. Unlike other systems, it does not encode any information, but it can be used for obtaining the position, rotation, relative size, and projective transformation. Also, the system works well with motion blur and is resistant to the marker's imperfections, which could theoretically be drawn only by hand. Previous systems put constraints on colors that need to be used to form the marker. The proposed system works with any saturated color, leading to better blending with the surrounding environment. The marker's final shape is a rectangular area of a solid color with three lines of a different color going from the center to three corners of the rectangle. Precise detection can be achieved using neural networks, given that the training set is very varied and well designed. A detailed literature review was performed, and no such system was found. Therefore, the proposed design is novel for localization in the spatial scene. The testing proved that the system works well both indoor and outdoor, and the detections are precise.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21244,""
"Automated Bowel Sound Analysis: An Overview","Nowak, Nowak, Radzikowski, Grulkowski, Walkowiak","https://doi.org/10.3390/s21165294","20210831","PubMed","automated analysis; bowel sound; intestine; motility; recording; Artificial Intelligence; Automation; Gastrointestinal Diseases; Humans; Neural Networks, Computer; Sound","Despite technological progress, we lack a consensus on the method of conducting automated bowel sound (BS) analysis and, consequently, BS tools have not become available to doctors. We aimed to briefly review the literature on BS recording and analysis, with an emphasis on the broad range of analytical approaches. Scientific journals and conference materials were researched with a specific set of terms (Scopus, MEDLINE, IEEE) to find reports on BS. The research articles identified were analyzed in the context of main research directions at a number of centers globally. Automated BS analysis methods were already well developed by the early 2000s. Accuracy of 90% and higher had been achieved with various analytical approaches, including wavelet transformations, multi-layer perceptrons, independent component analysis and autoregressive-moving-average models. Clinical research on BS has exposed their important potential in the non-invasive diagnosis of irritable bowel syndrome, in surgery, and for the investigation of gastrointestinal motility. The most recent advances are linked to the application of artificial intelligence and the development of dedicated BS devices. BS research is technologically mature, but lacks uniform methodology, an international forum for discussion and an open platform for data exchange. A common ground is needed as a starting point. The next key development will be the release of freely available benchmark datasets with labels confirmed by human experts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21245,""
"Artificial intelligence applications in different imaging modalities for corneal topography","Shanthi, Aruljyothi, Balasundaram, Janakiraman, Nirmaladevi, Pyingkodi","https://doi.org/10.1016/j.survophthal.2021.08.004","20210920","PubMed","Artificial Intelligence; Deep Learning; Imaging modalities; Keratoconus; Machine Learning; Ophthalmology","Interpretation of topographical maps used to detect corneal ectasias requires a high level of expertise. Several artificial intelligence (AI) technologies have attempted to interpret topographic maps. The purpose of this study is to provide a review of AI algorithms in corneal topography from the perspectives of an eye care professional, a biomedical engineer, and a data scientist. A systematic literature review using Web of Science, Pubmed, and Google Scholar was performed from 2010 to 2020 on themes regarding imaging modalities, their parameters, purpose, and conclusions and their samples and performance related to AI in corneal topography. We provide a comprehensive summary of advances in corneal imaging and its applications in AI. Combined metrics from the Dual Scheimpflug and Placido device could be a good starting point to try AI models in corneal imaging systems. The range of area under the receiving operating curve for AI in keratoconus detection and classification was from 0.87 to 1, sensitivity was from 0.89 to 1, and specificity was from 0.82 to 1. A combination of different types of AI applications to corneal ectasia diagnosis is recommended.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21246,""
"COVID-19 Mortality Prediction From Deep Learning in a Large Multistate Electronic Health Record and Laboratory Information System Data Set: Algorithm Development and Validation","Sankaranarayanan, Balan, Walsh, Wu, Minnich, Piazza, Osborne, Oliver, Lesko, Bates, Khezeli, Block, DiGuardo, Kreuter, O'Horo, Kalantari, Klee, Salama, Kipp, Morice, Jenkinson","https://doi.org/10.2196/30157","20211001","PubMed","COVID-19; EHR; algorithm; deep learning; development; electronic health record; machine learning; missing data; mortality; neural network; prediction; recurrent neural networks; time series; validation; Algorithms; COVID-19; Clinical Laboratory Information Systems; Deep Learning; Electronic Health Records; Humans; Retrospective Studies; SARS-CoV-2","COVID-19 is caused by the SARS-CoV-2 virus and has strikingly heterogeneous clinical manifestations, with most individuals contracting mild disease but a substantial minority experiencing fulminant cardiopulmonary symptoms or death. The clinical covariates and the laboratory tests performed on a patient provide robust statistics to guide clinical treatment. Deep learning approaches on a data set of this nature enable patient stratification and provide methods to guide clinical treatment. Here, we report on the development and prospective validation of a state-of-the-art machine learning model to provide mortality prediction shortly after confirmation of SARS-CoV-2 infection in the Mayo Clinic patient population. We retrospectively constructed one of the largest reported and most geographically diverse laboratory information system and electronic health record of COVID-19 data sets in the published literature, which included 11,807 patients residing in 41 states of the United States of America and treated at medical sites across 5 states in 3 time zones. Traditional machine learning models were evaluated independently as well as in a stacked learner approach by using AutoGluon, and various recurrent neural network architectures were considered. The traditional machine learning models were implemented using the AutoGluon-Tabular framework, whereas the recurrent neural networks utilized the TensorFlow Keras framework. We trained these models to operate solely using routine laboratory measurements and clinical covariates available within 72 hours of a patient's first positive COVID-19 nucleic acid test result. The GRU-D recurrent neural network achieved peak cross-validation performance with 0.938 (SE 0.004) as the area under the receiver operating characteristic (AUROC) curve. This model retained strong performance by reducing the follow-up time to 12 hours (0.916 [SE 0.005] AUROC), and the leave-one-out feature importance analysis indicated that the most independently valuable features were age, Charlson comorbidity index, minimum oxygen saturation, fibrinogen level, and serum iron level. In the prospective testing cohort, this model provided an AUROC of 0.901 and a statistically significant difference in survival (P&lt;.001, hazard ratio for those predicted to survive, 95% CI 0.043-0.106). Our deep learning approach using GRU-D provides an alert system to flag mortality for COVID-19-positive patients by using clinical covariates and laboratory values within a 72-hour window after the first positive nucleic acid test result.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21247,""
"Use of flowable resin composite as an intermediate layer in class II restorations: a systematic review and meta-analysis","Cavalheiro, Scherer, Imparato, Collares, Lenzi","https://doi.org/10.1007/s00784-021-04090-5","20210917","PubMed","Class II restoration; Dental restoration; Direct restoration; Flowable resin composite; Resin composite; Systematic review; Composite Resins; Dental Caries; Dental Restoration, Permanent; Humans","To investigate the influence of an intermediate layer of a flowable resin composite in class II resin composite restorations. The authors searched MEDLINE via PubMed, Scopus, LILACS, Embase, and Web of Science electronic databases, and the ClinicalTrials.gov website to identify laboratory and clinical studies that evaluated class II cavities with resin composite restorations with or without an intermediate layer of flowable resin composite. Two authors independently selected the studies, extracted the data, and assessed the risk of bias and the quality of the evidence. Meta-analyses were performed using RevMan5.3 with fixed-effects model comparing bond strength (MPa), fracture strength (Newton), and clinical (number of failures) outcomes between restorative techniques (with or without flowable resin composite as an intermediate layer). From 1707 potentially eligible studies, 140 in vitro studies and 14 clinical studies were selected for full-text analysis, and 11 were included in the systematic review, being 7 in vitro and 4 clinical studies. There was no statistically significant difference between the restorative techniques considering the outcomes evaluated. The heterogeneity found was null. The risk of bias was classified as medium for in vitro studies and unclear in most clinical studies. The quality of the evidence of the clinical studies was low. The use of flowable resin composite as an intermediate layer does not improve the effectiveness of the class II restorations based on laboratory and clinical outcomes. Flowable resin composite as an intermediate layer may be used for class II restorations; however, this technique does not improve the effectiveness of the class II restorations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21248,""
"Predicting Kidney Graft Survival Using Machine Learning Methods: Prediction Model Development and Feature Significance Analysis Study","Naqvi, Tennankore, Vinson, Roy, Abidi","https://doi.org/10.2196/26843","20211026","PubMed","dimensionality reduction; feature sensitivity analysis; kidney transplantation; machine learning; predictive modeling; survival prediction; Graft Survival; Humans; Kidney; Kidney Transplantation; Machine Learning; Tissue Donors","Kidney transplantation is the optimal treatment for patients with end-stage renal disease. Short- and long-term kidney graft survival is influenced by a number of donor and recipient factors. Predicting the success of kidney transplantation is important for optimizing kidney allocation. The aim of this study was to predict the risk of kidney graft failure across three temporal cohorts (within 1 year, within 5 years, and after 5 years following a transplant) based on donor and recipient characteristics. We analyzed a large data set comprising over 50,000 kidney transplants covering an approximate 20-year period. We applied machine learning-based classification algorithms to develop prediction models for the risk of graft failure for three different temporal cohorts. Deep learning-based autoencoders were applied for data dimensionality reduction, which improved the prediction performance. The influence of features on graft survival for each cohort was studied by investigating a new nonoverlapping patient stratification approach. Our models predicted graft survival with area under the curve scores of 82% within 1 year, 69% within 5 years, and 81% within 17 years. The feature importance analysis elucidated the varying influence of clinical features on graft survival across the three different temporal cohorts. In this study, we applied machine learning to develop risk prediction models for graft failure that demonstrated a high level of prediction performance. Acknowledging that these models performed better than those reported in the literature for existing risk prediction tools, future studies will focus on how best to incorporate these prediction models into clinical care algorithms to optimize the long-term health of kidney recipients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21249,""
"Toward Personalized Medicine in Radiotherapy of Hepatocellular Carcinoma: Emerging Radiomic Biomarker Candidates of Response and Toxicity","De la Pinta","https://doi.org/10.1089/omi.2021.0065","20210915","PubMed","biomarkers; liver cancer; personalized medicine; radiogenomics; radiomics; radiotherapy","Radiology and radiotherapy are currently undergoing radical transformation with use of biomarkers and digital technologies such as artificial intelligence. These current and upcoming changes in radiology speak of an overarching new vision for personalized medicine. This is particularly evident in the case of radiotherapy of cancers, and of liver cancer in particular. The development of modern radiotherapy with stereotactic body radiotherapy allows targeted treatments to be delivered to the tumor site, limiting the dose to surrounding healthy organs, thus becoming a new therapeutic alternative for hepatocellular carcinoma and other liver tumors. However, not all patients have the same response to radiotherapy or display the same side-effect profile. Biomarkers of response and toxicity in liver radiotherapy would facilitate the vision and practice of personalized medicine. This expert review examines the available molecular, radiomic, and radiogenomic biomarker candidates for acute liver toxicity with potential use for prediction of radiotherapy-induced liver toxicity. To this end, I highlight for oncologists and life scientists that radiomics allows diagnostic images to be analyzed using computer algorithms to extract information imperceptible to the human eye and of relevance to forecasting clinical outcomes. This article underscores particularly (1) the microRNA-based biomarker candidates as among the most promising predictors of radiation-induced liver toxicity and (2) the texture features in radiomic analyses for response prediction. Radiotherapy of hepatocellular carcinoma is edging toward personalized medicine with emerging radiomic biomarker candidates. Future large-scale biomarker studies are called for to enable personalized medicine in liver cancers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21250,""
"Machine learning model development for quantitative analysis of CT heterogeneity in canine hepatic masses may predict histologic malignancy","Shaker, Wilke, Ober, Lawrence","https://doi.org/10.1111/vru.13012","20210827","PubMed","cancer; computed tomography; liver","Tumor heterogeneity is a well-established marker of biologically aggressive neoplastic processes and is associated with local recurrence and distant metastasis. Quantitative analysis of CT textural features is an indirect measure of tumor heterogeneity and therefore may help predict malignant disease. The purpose of this retrospective, secondary analysis study was to quantitatively evaluate CT heterogeneity in dogs with histologically confirmed liver masses to build a predictive model for malignancy. Forty dogs with liver tumors and corresponding histopathologic evaluation from a previous prospective study were included. Triphasic image acquisition was standardized across dogs and whole liver and liver mass were contoured on each precontrast and delayed postcontrast dataset. First-order and second-order indices were extracted from contoured regions. Univariate analysis identified potentially significant indices that were subsequently used for top-down model construction. Multiple quadratic discriminatory models were constructed and tested, including individual models using both postcontrast and precontrast whole liver or liver mass volumes. The best performing model utilized the CT features voxel volume and uniformity from postcontrast mass contours; this model had an accuracy of 0.90, sensitivity of 0.67, specificity of 1.0, positive predictive value of 1.0, negative predictive value of 0.88, and precision of 1.0. Heterogeneity indices extracted from delayed postcontrast CT hepatic mass contours were more informative about tumor type compared to indices from whole liver contours, or from precontrast hepatic mass and whole liver contours. Results demonstrate that CT radiomic feature analysis may hold clinical utility as a noninvasive method of predicting hepatic malignancy and may influence diagnostic or therapeutic approaches.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21251,""
"Ontology Engineering for Gastric Dystemperament in Persian Medicine","Shojaee-Mend, Ayatollahi, Abdolahadi","https://doi.org/10.1055/s-0041-1735168","20210827","PubMed","","Ã¢â‚¬Æ’Developing an ontology can help collecting and sharing information in traditional medicine including Persian medicine in a well-defined format. The present study aimed to develop an ontology for gastric dystemperament in the Persian medicine. Ã¢â‚¬Æ’This was a mixed-methods study conducted in 2019. The first stage was related to providing an ontology requirements specification document. In the second stage, important terms, concepts, and their relationships were identified via literature review and expert panels. Then, the results derived from the second stage were refined and validated using the Delphi method in three rounds. Finally, in the fourth stage, the ontology was evaluated in terms of consistency and coherence. Ã¢â‚¬Æ’In this study, 241 concepts related to different types of gastric dystemperament, diagnostic criteria, and treatments in the Persian medicine were identified through literature review and expert panels, and 12 new concepts were suggested during the Delphi study. In total, after performing three rounds of the Delphi study, 233 concepts were identified. Finally, an ontology was developed with 71 classes, and the results of the evaluation study revealed that the ontology was consistent and coherent. Ã¢â‚¬Æ’In this study, an ontology was created for gastric dystemperament in the Persian medicine. This ontology can be used for designing future systems, such as case-based reasoning and expert systems. Moreover, the use of other evaluation methods is suggested to construct a more complete and precise ontology.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21252,""
"Efficacy and Safety of Intranasal Esketamine in Treatment-Resistant Depression in Adults: A Systematic Review","Sapkota, Khurshid, Qureshi, Jahan, Went, Sultan, Alfonso","https://doi.org/10.7759/cureus.17352","20210828","PubMed","adverse event; esketamine; intranasal; ketamine; treatment-resistant depression","Intranasal form of esketamine, the S-enantiomer of racemic ketamine, was approved by the US FDAÃ‚Â in 2019 for treatment-resistant depression (TRD) in adults. Since intranasal esketamine is a newly approved drug with a novel mechanism of action, much still remains unknown in regard to its use in TRD. The objective of this study is to systematically review the latest existing evidence on intranasal esketamine, and provide a better insight into its safety and efficacy in TRD in adults. PubMed, MEDLINE (through PubMed), and Google Scholar were systematically searched from 2016 to 2021, using automation tools. After removal of duplicates and screening on the basis of title/abstract, eligibility criteria were applied and quality appraisal was done independently by two reviewers. A total of 10 studies were selected for the final review which included five clinical trials (three short-term trials, one withdrawal design relapse prevention study, and one long-term study), three post hoc studies, one case/non-case study, and one review article. Out of three short-term clinical trials, only one demonstrated a statistically significant difference between treatment with esketamine plus oral antidepressant (OAD) vs placebo plus OAD. The result of the relapse prevention study showed significantly delayed relapse of depressive symptoms in esketamine plus OAD arm when compared to placebo plus OAD arm. Similarly, the result of the long-term clinical trial showed that the improvement in depressive symptoms was found to be sustained in those using esketamine. The most common adverse effects of esketamine included nausea, dizziness, dissociation, headache, vertigo, somnolence, and dysgeusia (altered sense of taste); most were mild-moderate in severity. One case/non-case study reportedÃ‚Â rare adverse effects including panic attacks, mania, ataxia, akathisia, self-harm ideation, increased loquacity (talkativeness), and autoscopy. Intranasal esketamine has shown efficacy in reducing depressive symptoms in clinical trials, but the clinical meaningfulness of the treatment effect in the real-world population still needs to be explored. Although the safety profile of esketamine appears to be favorable in most clinical trials, some serious side effects are being reported to the FDA Adverse Event Reporting System, and therefore requires further investigation. More robust clinical trials, especially long-term randomized controlled trials are needed which can help provide a better assessment on the efficacy and safety of intranasal esketamine in the treatment of TRD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21253,""
"Digital health interventions for COVID-19 in China: a retrospective analysis","Chen, Xu, Husain, Galea","https://doi.org/10.1016/j.imed.2021.03.001","20210910","PubMed","Artificial intelligence; Big data; Coronavirus disease 2019; Digital health; Telemedicine","The use of digital health technologies was an integral part to China's early response to coronavirus disease 2019 (COVID-19). Existing literatures have analyzed and discussed implemented digital health innovations from the perspective of technologies, whereas how policy mechanisms contributed to the formulation of the digital health landscape for COVID-19 was overlooked. This study aimed to examine the contexts and key mechanisms in China's rapid mobilization of digital health interventions in response to COVID-19, and to document and share lessons learned. Policy documents were identified and retrieved from government portals and recognized media outlets. Data on digital health interventions were collected through three consecutive surveys administered between 23 January 2020 and 31 March 2020 by China Academy of Information and Communication Technology (CAICT) affiliated to the Ministry of Industry and Information Technology (MIIT). Participants were member companies of the Internet Health alliance established by MIIT and the National Health Commission (NHC) in June 2016. Self-report digital interventions focusing on social and economic recovery were excluded. Two hundred and sixty-six unique digital health interventions meeting our criteria were extracted from 175 narratives on digital health interventions submitted by 116 participating companies. Thematic analysis was conducted to describe the scope and priority of policies advocating for the use of digital health technologies and the implementation pattern of digital health interventions. Data limitations precluded an evaluation of the impact of digital health interventions over a longer time frame. Between January and March 2020, national policy directives promoting the use of digital technologies for the containment of COVID-19 collectively advocated for use cases in emergency planning and preparedness, public health response, and clinical services. Interventions to strengthen clinical services were mentioned more than the other two themes (<i>n</i>Ã‚Â =Ã‚Â 15, 62.5% (15/24)). Using digital technologies for public health response was mentioned much less than clinical services (<i>n</i>Ã‚Â =Ã‚Â 5, 20.8% (5/24)). Emergency planning and preparedness was least mentioned (<i>n</i>Ã‚Â =Ã‚Â 4, 16.7% (4/24)). Interventions in support of clinical services disproportionately favored healthcare facilities in less resource-constraint settings. Digital health interventions shared the same pattern of distribution. More digital health technologies were implemented in clinical services (<i>n</i>Ã‚Â =Ã‚Â 103, 38.7% (103/266)) than that in public health response (<i>n</i>Ã‚Â =Ã‚Â 91, 34.2% (91/266)). Emergency planning and preparedness had the least self-reported digital health interventions (<i>n</i>Ã‚Â =Ã‚Â 72, 27.1% (72/266)). We further identified case studies under each theme in which the wide use of digital health technologies highlighted contextual factors and key enabling mechanisms. The contextual factors and key enabling mechanisms through the use of policy instruments to promote digital health interventions for COVID-19 in China include pathway of policy directives influencing the private sector using a decentralized system, the booming digital health landscape before COVID-19, agility of the public sector in introducing regulatory flexibilities and incentives to mobilize the private sector.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21254,""
"Patient and general public attitudes towards clinical artificial intelligence: a mixed methods systematic review","Young, Amara, Bhattacharya, Wei","https://doi.org/10.1016/S2589-7500(21)00132-1","20210910","PubMed","Artificial Intelligence; Attitude to Computers; Attitude to Health; Humans; Patients; Public Opinion","Artificial intelligence (AI) promises to change health care, with some studies showing proof of concept of a provider-level performance in various medical specialties. However, there are many barriers to implementing AI, including patient acceptance and understanding of AI. Patients' attitudes toward AI are not well understood. We systematically reviewed the literature on patient and general public attitudes toward clinical AI (either hypothetical or realised), including quantitative, qualitative, and mixed methods original research articles. We searched biomedical and computational databases from Jan 1, 2000, to Sept 28, 2020, and screened 2590 articles, 23 of which met our inclusion criteria. Studies were heterogeneous regarding the study population, study design, and the field and type of AI under study. Six (26%) studies assessed currently available or soon-to-be available AI tools, whereas 17 (74%) assessed hypothetical or broadly defined AI. The quality of the methods of these studies was mixed, with a frequent issue of selection bias. Overall, patients and the general public conveyed positive attitudes toward AI but had many reservations and preferred human supervision. We summarise our findings in six themes: AI concept, AI acceptability, AI relationship with humans, AI development and implementation, AI strengths and benefits, and AI weaknesses and risks. We suggest guidance for future studies, with the goal of supporting the safe, equitable, and patient-centred implementation of clinical AI.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21255,""
"Process Improvement Approaches for Increasing the Response of Emergency Departments against the COVID-19 Pandemic: A Systematic Review","OrtÃƒÂ­z-Barrios, Coba-Blanco, Alfaro-SaÃƒÂ­z, Stand-GonzÃƒÂ¡lez","https://doi.org/10.3390/ijerph18168814","20210831","PubMed","COVID-19; emergency department; healthcare; process improvement; systematic review; Artificial Intelligence; COVID-19; Emergency Service, Hospital; Humans; Pandemics; SARS-CoV-2","The COVID-19 pandemic has strongly affected the dynamics of Emergency Departments (EDs) worldwide and has accentuated the need for tackling different operational inefficiencies that decrease the quality of care provided to infected patients. The EDs continue to struggle against this outbreak by implementing strategies maximizing their performance within an uncertain healthcare environment. The efforts, however, have remained insufficient in view of the growing number of admissions and increased severity of the coronavirus disease. Therefore, the primary aim of this paper is to review the literature on process improvement interventions focused on increasing the ED response to the current COVID-19 outbreak to delineate future research lines based on the gaps detected in the practical scenario. Therefore, we applied the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines to perform a review containing the research papers published between December 2019 and April 2021 using ISI Web of Science, Scopus, PubMed, IEEE, Google Scholar, and Science Direct databases. The articles were further classified taking into account the research domain, primary aim, journal, and publication year. A total of 65 papers disseminated in 51 journals were concluded to satisfy the inclusion criteria. Our review found that most applications have been directed towards predicting the health outcomes in COVID-19 patients through machine learning and data analytics techniques. In the overarching pandemic, healthcare decision makers are strongly recommended to integrate artificial intelligence techniques with approaches from the operations research (OR) and quality management domains to upgrade the ED performance under social-economic restrictions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21256,""
"Psychiatry in the Digital Age: A Blessing or a Curse?","Roth, Papassotiropoulos, BrÃƒÂ¼hl, Lang, Huber","https://doi.org/10.3390/ijerph18168302","20210906","PubMed","app-based cognitive behavioral therapy; computer-based cognitive behavioral therapy; digitalization; electronic health records; machine learning; omics; precision psychiatry; psychiatry; telemedicine; virtual reality; COVID-19; Humans; Pandemics; Psychiatry; Telemedicine","Social distancing and the shortage of healthcare professionals during the COVID-19 pandemic, the impact of population aging on the healthcare system, as well as the rapid pace of digital innovation are catalyzing the development and implementation of new technologies and digital services in psychiatry. Is this transformation a blessing or a curse for psychiatry? To answer this question, we conducted a literature review covering a broad range of new technologies and eHealth services, including telepsychiatry; computer-, internet-, and app-based cognitive behavioral therapy; virtual reality; digital applied games; a digital medicine system; omics; neuroimaging; machine learning; precision psychiatry; clinical decision support; electronic health records; physician charting; digital language translators; and online mental health resources for patients. We found that eHealth services provide effective, scalable, and cost-efficient options for the treatment of people with limited or no access to mental health care. This review highlights innovative technologies spearheading the way to more effective and safer treatments. We identified artificially intelligent tools that relieve physicians from routine tasks, allowing them to focus on collaborative doctor-patient relationships. The transformation of traditional clinics into digital ones is outlined, and the challenges associated with the successful deployment of digitalization in psychiatry are highlighted.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21257,""
"Meta-Analysis and Machine Learning Models to Optimize the Efficiency of Self-Healing Capacity of Cementitious Material","Gupta, Al-Obaidi, Ferrara","https://doi.org/10.3390/ma14164437","20210831","PubMed","artificial neural network; meta-analysis; self-healing concrete; systematic review","Concrete and cement-based materials inherently possess an autogenous self-healing capacity. Despite the huge amount of literature on the topic, self-healing concepts still fail to consistently enter design strategies able to effectively quantify their benefits on structural performance. This study aims to develop quantitative relationships through statistical models and artificial neural network (ANN) by establishing a correlation between the mix proportions, exposure type and time, and width of the initial crack against suitably defined self-healing indices (SHI), quantifying the recovery of material performance. Furthermore, it is intended to pave the way towards consistent incorporation of self-healing concepts into durability-based design approaches for reinforced concrete structures, aimed at quantifying, with reliable confidence, the benefits in terms of slower degradation of the structural performance and extension of the service lifespan. It has been observed that the exposure type, crack width and presence of healing stimulators such as crystalline admixtures has the most significant effect on enhancing SHI and hence self-healing efficiency. However, other parameters, such as the amount of fibers and Supplementary Cementitious Materials have less impact on the autogenous self-healing. The study proposes, through suitably built design charts and ANN analysis, a straightforward input-output model to quickly predict and evaluate, and hence ""design"", the self-healing efficiency of cement-based materials.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21258,""
"Recent Trends in Sedentary Time: A Systematic Literature Review","Fang, Jing, Chen, Wu, Wan","https://doi.org/10.3390/healthcare9080969","20210830","PubMed","COVID-19; bibliometric; children; physical activity; sedentary time","This paper systematically reviews and synthesizes the relevant literature on sedentary time research. A bibliometric analysis was conducted to evaluate the publications from 2010 to 2020 in the Web of Science (WoS) core collection database. Derwent Data Analyzer software was used for the cleaning, mining, and visualization of the data. Historical trends of the topics, main contributors, leading countries, leading institutions, leading research areas, and journals were explored. A total of 3020 publications were studied. The United States, the United Kingdom, and Australia are the three most productive countries. The Australian institution Baker Heart and Diabetes Institute led the list of productive institutions, and Ekelund U published the most papers. Sedentary time raised the concerns of scholars from 106 research areas, and public health was the dominant field. Physical activity, accelerometer, children, and obesity were the most frequently used keywords. The findings suggest that sedentary time is rapidly emerging as a global issue that has detrimental effects on public health. The hotspots shifted in the past 10 years, and COVID-19 was the most popular topic of sedentary time research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21259,""
"Signal and Texture Features from T2 Maps for the Prediction of Mild Cognitive Impairment to Alzheimer's Disease Progression","Trejo-Castro, Caballero-Luna, Garnica-LÃƒÂ³pez, Vega-Lara, Martinez-Torteya","https://doi.org/10.3390/healthcare9080941","20210830","PubMed","ADNI; AlzheimerÃ¢â‚¬â„¢s disease; MRI biomarkers; T2 maps; mild cognitive impairment; signal; texture","Early detection of Alzheimer's disease (AD) is crucial to preserve cognitive functions and provide the opportunity for patients to enter clinical trials. In recent years, some studies have reported that features related to the signal and texture of MRI images can be an effective biomarker of AD. To test these claims, a study was conducted using T2 maps, a sequence not previously studied, of 40 patients with mild cognitive impairment (MCI) from the Alzheimer's Disease Neuroimaging Initiative database, who either progressed to AD (18) or remained stable (22). From these maps, the mean value and absolute difference of 37 signal and texture imaging features for 40 contralateral pairs of regions were measured. We used seven machine learning methods to analyze whether, by adding these imaging features to the neuropsychological studies currently used for diagnosis, we could more accurately identify patients who will progress to AD. The predictive models improved with the addition of signal and texture features. Additionally, features related to the signal and texture of the images were much more relevant than volumetric ones. Our results suggest that contralateral signal and texture features should be further investigated as potential biomarkers for the prediction of AD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21260,""
"Recent Advances in Endosonography-Elastography: Literature Review","Yamamiya, Irisawa, Hoshi, Yamabe, Izawa, Nagashima, Minaguchi, Yamaura, Yoshida, Kashima, Kunogi, Sakuma, Tominaga, Iijima, Goda","https://doi.org/10.3390/jcm10163739","20210831","PubMed","autoimmune pancreatitis; chronic pancreatitis; endoultrasonography; gastro-intestinal lesion; lymph node; pancreatic solid lesion; shear wave elastography; strain elastography; subepithelial lesion","Ultrasonographic elastography is a modality used to visualize the elastic properties of tissues. Technological advances in ultrasound equipment have supported the evaluation of elastography (EG) in endosonography (EUS). Currently, the usefulness of not only EUS-strain elastography (EUS-SE) but also EUS-shear wave elastography (EUS-SWE) has been reported. We reviewed the literature on the usefulness of EUS-EG for various diseases such as chronic pancreatitis, pancreatic solid lesion, autoimmune pancreatitis, lymph node, and gastrointestinal and subepithelial lesions. The importance of this new diagnostic parameter, ""tissue elasticity"" in clinical practice might be applied not only to the diagnosis of liver fibrosis but also to the elucidation of the pathogeneses of various gastrointestinal diseases, including pancreatic diseases, and to the evaluation of therapeutic effects. The most important feature of EUS-EG is that it is a non-invasive modality. This is an advantage not found in EUS-guided fine needle aspiration (EUS-FNA), which has made remarkable progress in the field of diagnostics in recent years. Further development of artificial intelligence (AI) is expected to improve the diagnostic performance of EUS-EG. Future research on EUS-EG is anticipated.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21261,""
"Current Status and Future Perspective of Artificial Intelligence in the Management of Peptic Ulcer Bleeding: A Review of Recent Literature","Yen, Wu, Chen, Lin, Tsai, Lin","https://doi.org/10.3390/jcm10163527","20210831","PubMed","artificial intelligence; bleeding; deep learning; peptic ulcer","With the decreasing incidence of peptic ulcer bleeding (PUB) over the past two decades, the clinician experience of managing patients with PUB has also declined, especially for young endoscopists. A patient with PUB management requires collaborative care involving the emergency department, gastroenterologist, radiologist, and surgeon, from initial assessment to hospital discharge. The application of artificial intelligence (AI) methods has remarkably improved people's lives. In particular, AI systems have shown great potential in many areas of gastroenterology to increase human performance. Colonoscopy polyp detection or diagnosis by an AI system was recently introduced for commercial use to improve endoscopist performance. Although PUB is a longstanding health problem, these newly introduced AI technologies may soon impact endoscopists' clinical practice by improving the quality of care for these patients. To update the current status of AI application in PUB, we reviewed recent relevant literature and provided future perspectives that are required to integrate such AI tools into real-world practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21262,""
"Content-Based Medical Image Retrieval and Intelligent Interactive Visual Browser for Medical Education, Research and Care","Sotomayor, Mendoza, CastaÃƒÂ±eda, FarÃƒÂ­as, Molina, Pereira, HÃƒÂ¤rtel, Solar, Araya","https://doi.org/10.3390/diagnostics11081470","20210830","PubMed","clinical; content-based image retrieval; education; imaging; interactive visual browser; query-by-example; research","Medical imaging is essential nowadays throughout medical education, research, and care. Accordingly, international efforts have been made to set large-scale image repositories for these purposes. Yet, to date, browsing of large-scale medical image repositories has been troublesome, time-consuming, and generally limited by text search engines. A paradigm shift, by means of a query-by-example search engine, would alleviate these constraints and beneficially impact several practical demands throughout the medical field. The current project aims to address this gap in medical imaging consumption by developing a content-based image retrieval (CBIR) system, which combines two image processing architectures based on deep learning. Furthermore, a first-of-its-kind intelligent visual browser was designed that interactively displays a set of imaging examinations with similar visual content on a similarity map, making it possible to search for and efficiently navigate through a large-scale medical imaging repository, even if it has been set with incomplete and curated metadata. Users may, likewise, provide text keywords, in which case the system performs a content- and metadata-based search. The system was fashioned with an anonymizer service and designed to be fully interoperable according to international standards, to stimulate its integration within electronic healthcare systems and its adoption for medical education, research and care. Professionals of the healthcare sector, by means of a self-administered questionnaire, underscored that this CBIR system and intelligent interactive visual browser would be highly useful for these purposes. Further studies are warranted to complete a comprehensive assessment of the performance of the system through case description and protocolized evaluations by medical imaging specialists.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21263,""
"iPMI: Machine Learning-Aided Identification of Parametrial Invasion in Women with Early-Stage Cervical Cancer","Charoenkwan, Shoombuatong, Nantasupha, Muangmool, Suprasert, Charoenkwan","https://doi.org/10.3390/diagnostics11081454","20210830","PubMed","cervical cancer; health informatics; machine learning; parametrial invasion; random forest","Radical hysterectomy is a recommended treatment for early-stage cervical cancer. However, the procedure is associated with significant morbidities resulting from the removal of the parametrium. Parametrial cancer invasion (PMI) is found in a minority of patients but the efficient system used to predict it is lacking. In this study, we develop a novel machine learning (ML)-based predictive model based on a random forest model (called iPMI) for the practical identification of PMI in women. Data of 1112 stage IA-IIA cervical cancer patients who underwent primary surgery were collected and considered as the training dataset, while data from an independent cohort of 116 consecutive patients were used as the independent test dataset. Based on these datasets, iPMI-Econ was then developed by using basic clinicopathological data available prior to surgery, while iPMI-Power was also introduced by adding pelvic node metastasis and uterine corpus invasion to the iPMI-Econ. Both 10-fold cross-validations and independent test results showed that iPMI-Power outperformed other well-known ML classifiers (e.g., logistic regression, decision tree, k-nearest neighbor, multi-layer perceptron, naive Bayes, support vector machine, and extreme gradient boosting). Upon comparison, it was found that iPMI-Power was effective and had a superior performance to other well-known ML classifiers in predicting PMI. It is anticipated that the proposed iPMI may serve as a cost-effective and rapid approach to guide important clinical decision-making.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21264,""
"Application of Artificial Intelligence in the MRI Classification Task of Human Brain Neurological and Psychiatric Diseases: A Scoping Review","Zhang, Li, Xu, Tang","https://doi.org/10.3390/diagnostics11081402","20210830","PubMed","artificial intelligence; deep learning; human brain-related diseases; machine learning; magnetic resonance image","Artificial intelligence (AI) for medical imaging is a technology with great potential. An in-depth understanding of the principles and applications of magnetic resonance imaging (MRI), machine learning (ML), and deep learning (DL) is fundamental for developing AI-based algorithms that can meet the requirements of clinical diagnosis and have excellent quality and efficiency. Moreover, a more comprehensive understanding of applications and opportunities would help to implement AI-based methods in an ethical and sustainable manner. This review first summarizes recent research advances in ML and DL techniques for classifying human brain magnetic resonance images. Then, the application of ML and DL methods to six typical neurological and psychiatric diseases is summarized, including Alzheimer's disease (AD), Parkinson's disease (PD), major depressive disorder (MDD), schizophrenia (SCZ), attention-deficit/hyperactivity disorder (ADHD), and autism spectrum disorder (ASD). Finally, the limitations of the existing research are discussed, and possible future research directions are proposed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21265,""
"Machine Learning and Deep Learning Methods for Skin Lesion Classification and Diagnosis: A Systematic Review","Kassem, Hosny, DamaÃ…Â¡eviÃ„Âius, Eltoukhy","https://doi.org/10.3390/diagnostics11081390","20210830","PubMed","deep learning; machine learning; racial bias; skin image segmentation; skin lesion classification; small data","Computer-aided systems for skin lesion diagnosis is a growing area of research. Recently, researchers have shown an increasing interest in developing computer-aided diagnosis systems. This paper aims to review, synthesize and evaluate the quality of evidence for the diagnostic accuracy of computer-aided systems. This study discusses the papers published in the last five years in ScienceDirect, IEEE, and SpringerLink databases. It includes 53 articles using traditional machine learning methods and 49 articles using deep learning methods. The studies are compared based on their contributions, the methods used and the achieved results. The work identified the main challenges of evaluating skin lesion segmentation and classification methods such as small datasets, ad hoc image selection and racial bias.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21266,""
"Topological Data Analysis for Eye Fundus Image Quality Assessment","AvilÃƒÂ©s-RodrÃƒÂ­guez, Nieto-HipÃƒÂ³lito, CosÃƒÂ­o-LeÃƒÂ³n, Romo-CÃƒÂ¡rdenas, SÃƒÂ¡nchez-LÃƒÂ³pez, Radilla-ChÃƒÂ¡vez, VÃƒÂ¡zquez-BriseÃƒÂ±o","https://doi.org/10.3390/diagnostics11081322","20210830","PubMed","computational ophthalmology; eye fundus images; image quality assessment; persistent homology; topological data analysis","The objective of this work is to perform image quality assessment (IQA) of eye fundus images in the context of digital fundoscopy with topological data analysis (TDA) and machine learning methods. Eye health remains inaccessible for a large amount of the global population. Digital tools that automize the eye exam could be used to address this issue. IQA is a fundamental step in digital fundoscopy for clinical applications; it is one of the first steps in the preprocessing stages of computer-aided diagnosis (CAD) systems using eye fundus images. Images from the EyePACS dataset were used, and quality labels from previous works in the literature were selected. Cubical complexes were used to represent the images; the grayscale version was, then, used to calculate a persistent homology on the simplex and represented with persistence diagrams. Then, 30 vectorized topological descriptors were calculated from each image and used as input to a classification algorithm. Six different algorithms were tested for this study (SVM, decision tree, k-NN, random forest, logistic regression (LoGit), MLP). LoGit was selected and used for the classification of all images, given the low computational cost it carries. Performance results on the validation subset showed a global accuracy of 0.932, precision of 0.912 for label ""quality"" and 0.952 for label ""no quality"", recall of 0.932 for label ""quality"" and 0.912 for label ""no quality"", AUC of 0.980, F1 score of 0.932, and a Matthews correlation coefficient of 0.864. This work offers evidence for the use of topological methods for the process of quality assessment of eye fundus images, where a relatively small vector of characteristics (30 in this case) can enclose enough information for an algorithm to yield classification results useful in the clinical settings of a digital fundoscopy pipeline for CAD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21267,""
"The Applications of Artificial Intelligence in Chest Imaging of COVID-19 Patients: A Literature Review","Laino, Ammirabile, Posa, Cancian, Shalaby, Savevski, Neri","https://doi.org/10.3390/diagnostics11081317","20210830","PubMed","COVID-19; artificial intelligence; chest CT; chest X-ray; computed-aided diagnosis","Diagnostic imaging is regarded as fundamental in the clinical work-up of patients with a suspected or confirmed COVID-19 infection. Recent progress has been made in diagnostic imaging with the integration of artificial intelligence (AI) and machine learning (ML) algorisms leading to an increase in the accuracy of exam interpretation and to the extraction of prognostic information useful in the decision-making process. Considering the ever expanding imaging data generated amid this pandemic, COVID-19 has catalyzed the rapid expansion in the application of AI to combat disease. In this context, many recent studies have explored the role of AI in each of the presumed applications for COVID-19 infection chest imaging, suggesting that implementing AI applications for chest imaging can be a great asset for fast and precise disease screening, identification and characterization. However, various biases should be overcome in the development of further ML-based algorithms to give them sufficient robustness and reproducibility for their integration into clinical practice. As a result, in this literature review, we will focus on the application of AI in chest imaging, in particular, deep learning, radiomics and advanced imaging as quantitative CT.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21268,""
"Shared Molecular Mechanisms of Hypertrophic Cardiomyopathy and Its Clinical Presentations: Automated Molecular Mechanisms Extraction Approach","GlavaÃ…Â¡ki, Velicki","https://doi.org/10.3390/life11080785","20210831","PubMed","atrial fibrillation; automated curation; cardiac fibrosis; data mining; heart failure; hypertrophic cardiomyopathy; left ventricular outflow tract obstruction; molecular mechanisms; myocardial ischemia; sudden cardiac death","Hypertrophic cardiomyopathy (HCM) is the most common inherited cardiovascular disease with a prevalence of 1 in 500 people and varying clinical presentations. Although there is much research on HCM, underlying molecular mechanisms are poorly understood, and research on the molecular mechanisms of its specific clinical presentations is scarce. Our aim was to explore the molecular mechanisms shared by HCM and its clinical presentations through the automated extraction of molecular mechanisms. Molecular mechanisms were congregated by a query of the INDRA database, which aggregates knowledge from pathway databases and combines it with molecular mechanisms extracted from abstracts and open-access full articles by multiple machine-reading systems. The molecular mechanisms were extracted from 230,072 articles on HCM and 19 HCM clinical presentations, and their intersections were found. Shared molecular mechanisms of HCM and its clinical presentations were represented as networks; the most important elements in the intersections' networks were found, centrality scores for each element of each network calculated, networks with reduced level of noise generated, and cooperatively working elements detected in each intersection network. The identified shared molecular mechanisms represent possible mechanisms underlying different HCM clinical presentations. Applied methodology produced results consistent with the information in the scientific literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21269,""
"Pseudogene Transcripts in Head and Neck Cancer: Literature Review and <i>In Silico</i> Analysis","Carron, Della Coletta, LourenÃƒÂ§o","https://doi.org/10.3390/genes12081254","20210830","PubMed","SNV; co-expression network; gene ontology enrichment; head and neck cancer; pseudogene transcripts","Once considered nonfunctional, pseudogene transcripts are now known to provide valuable information for cancer susceptibility, including head and neck cancer (HNC), a serious health problem worldwide, with about 50% unimproved overall survival over the last decades. The present review focuses on the role of pseudogene transcripts involved in HNC risk and prognosis. We combined current literature and <i>in silico</i> analyses from The Cancer Genome Atlas (TCGA) database to identify the most deregulated pseudogene transcripts in HNC and their genetic variations. We then built a co-expression network and performed gene ontology enrichment analysis to better understand the pseudogenes' interactions and pathways in HNC. In the literature, few pseudogenes have been studied in HNC. Our <i>in silico</i> analysis identified 370 pseudogene transcripts associated with HNC, where <i>SPATA31D5P</i>, <i>HERC2P3</i>, <i>SPATA31C2</i>, <i>MAGEB6P1</i>, <i>SLC25A51P1</i>, <i>BAGE2</i>, <i>DNM1P47</i>, <i>SPATA31C1</i>, <i>ZNF733P</i> and <i>OR2W5</i> were found to be the most deregulated and presented several genetic alterations. <i>NBPF25P</i>, <i>HSP90AB2P</i>, <i>ZNF658B</i> and <i>DPY19L2P3</i> pseudogenes were predicted to interact with 12 genes known to participate in HNC, <i>DNM1P47</i> was predicted to interact with the <i>TP53</i> gene, and <i>HLA-H</i> pseudogene was predicted to interact with <i>HLA-A</i> and <i>HLA-B</i> genes. The identified pseudogenes were associated with cancer biology pathways involving cell communication, response to stress, cell death, regulation of the immune system, regulation of gene expression, and Wnt signaling. Finally, we assessed the prognostic values of the pseudogenes with the Kaplan-Meier Plotter database, and found that expression of <i>SPATA31D5P</i>, <i>SPATA31C2</i>, <i>BAGE2</i>, <i>SPATA31C1</i>, <i>ZNF733P</i> and <i>OR2W5</i> pseudogenes were associated with patients' survival. Due to pseudogene transcripts' potential for cancer diagnosis, progression, and as therapeutic targets, our study can guide new research to HNC understanding and development of new target therapies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21270,""
"Clinical Phenotypic Spectrum of 4095 Individuals with Down Syndrome from Text Mining of Electronic Health Records","Havrilla, Zhao, Liu, Weng, Helbig, Bhoj, Wang","https://doi.org/10.3390/genes12081159","20210830","PubMed","Down syndrome; electronic health records; large-scale; longitudinal study; natural language processing; phenotype; phenotypic spectrum; text mining","Human genetic disorders, such as Down syndrome, have a wide variety of clinical phenotypic presentations, and characterizing each nuanced phenotype and subtype can be difficult. In this study, we examined the electronic health records of 4095 individuals with Down syndrome at the Children's Hospital of Philadelphia to create a method to characterize the phenotypic spectrum digitally. We extracted Human Phenotype Ontology (HPO) terms from quality-filtered patient notes using a natural language processing (NLP) approach MetaMap. We catalogued the most common HPO terms related to Down syndrome patients and compared the terms with those from a baseline population. We characterized the top 100 HPO terms by their frequencies at different ages of clinical visits and highlighted selected terms that have time-dependent distributions. We also discovered phenotypic terms that have not been significantly associated with Down syndrome, such as ""Proptosis"", ""Downslanted palpebral fissures"", and ""Microtia"". In summary, our study demonstrated that the clinical phenotypic spectrum of individual with Mendelian diseases can be characterized through NLP-based digital phenotyping on population-scale electronic health records (EHRs).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21271,""
"Feature selection for unsupervised machine learning of accelerometer data physical activity clusters - A systematic review","Jones, Catt, Davies, Edwardson, Mirkes, Khunti, Yates, Rowlands","https://doi.org/10.1016/j.gaitpost.2021.08.007","20211013","PubMed","Accelerometer; Clustering; Feature selection; K-means; Physical activity","Identifying clusters of physical activity (PA) from accelerometer data is important to identify levels of sedentary behaviour and physical activity associated with risks of serious health conditions and time spent engaging in healthy PA. Unsupervised machine learning models can capture PA in everyday free-living activity without the need for labelled data. However, there is scant research addressing the selection of features from accelerometer data. The aim of this systematic review is to summarise feature selection techniques applied in studies concerned with unsupervised machine learning of accelerometer-based device obtained physical activity, and to identify commonly used features identified through these techniques. Feature selection methods can reduce the complexity and computational burden of these models by removing less important features and assist in understanding the relative importance of feature sets and individual features in clustering. We conducted a systematic search of Pubmed, Medline, Google Scholar, Scopus, Arxiv and Web of Science databases to identify studies published before January 2021 which used feature selection methods to derive PA clusters using unsupervised machine learning models. A total of 13 studies were eligible for inclusion within the review. The most popular feature selection techniques were Principal Component Analysis (PCA) and correlation-based methods, with k-means frequently used in clustering accelerometer data. Cluster quality evaluation methods were diverse, including both external (e.g. cluster purity) or internal evaluation measures (silhouette score most frequently). Only four of the 13 studies had more than 25 participants and only four studies included two or more datasets. There is a need to assess multiple feature selection methods upon large cohort data consisting of multiple (3 or more) PA datasets. The cut-off criteria e.g. number of components, pairwise correlation value, explained variance ratio for PCA, etc. should be expressly stated along with any hyperparameters used in clustering.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21272,""
"A review on utilizing machine learning technology in the fields of electronic emergency triage and patient priority systems in telemedicine: Coherent taxonomy, motivations, open research challenges and recommendations for intelligent future work","Salman, Taha, Alsabah, Hussein, Mohammed, Aal-Nouman","https://doi.org/10.1016/j.cmpb.2021.106357","20210914","PubMed","Artificial Intelligence; Big Data; Data Mining; Healthcare Monitoring; Sensor; Triage; mHealth; Artificial Intelligence; Electronics; Humans; Machine Learning; Motivation; Technology; Telemedicine; Triage","With the remarkable increasing in the numbers of patients, the triaging and prioritizing patients into multi-emergency level is required to accommodate all the patients, save more lives, and manage the medical resources effectively. Triaging and prioritizing patients becomes particularly challenging especially for the patients who are far from hospital and use telemedicine system. To this end, the researchers exploiting the useful tool of machine learning to address this challenge. Hence, carrying out an intensive investigation and in-depth study in the field of using machine learning in E-triage and patient priority are essential and required. This research aims to (1) provide a literature review and an in-depth study on the roles of machine learning in the fields of electronic emergency triage (E-triage) and prioritize patients for fast healthcare services in telemedicine applications. (2) highlight the effectiveness of machine learning methods in terms of algorithms, medical input data, output results, and machine learning goals in remote healthcare telemedicine systems. (3) present the relationship between machine learning goals and the electronic triage processes specifically on the: triage levels, medical features for input, outcome results as outputs, and the relevant diseases. (4), the outcomes of our analyses are subjected to organize and propose a cross-over taxonomy between machine learning algorithms and telemedicine structure. (5) present lists of motivations, open research challenges and recommendations for future intelligent work for both academic and industrial sectors in telemedicine and remote healthcare applications. An intensive research is carried out by reviewing all articles related to the field of E-triage and remote priority systems that utilise machine learning algorithms and sensors. We have searched all related keywords to investigate the databases of Science Direct, IEEE Xplore, Web of Science, PubMed, and Medline for the articles, which have been published from January 2012 up to date. A new crossover matching between machine learning methods and telemedicine taxonomy is proposed. The crossover-taxonomy is developed in this study to identify the relationship between machine learning algorithm and the equivalent telemedicine categories whereas the machine learning algorithm has been utilized. The impact of utilizing machine learning is composed in proposing the telemedicine architecture based on synchronous (real-time/ online) and asynchronous (store-and-forward / offline) structure. In addition to that, list of machine learning algorithms, list of the performance metrics, list of inputs data and outputs results are presented. Moreover, open research challenges, the benefits of utilizing machine learning and the recommendations for new research opportunities that need to be addressed for the synergistic integration of multidisciplinary works are organized and presented accordingly. The state-of-the-art studies on the E-triage and priority systems that utilise machine learning algorithms in telemedicine architecture are discussed. This approach allows the researchers to understand the modernisation of healthcare systems and the efficient use of artificial intelligence and machine learning. In particular, the growing worldwide population and various chronic diseases such as heart chronic diseases, blood pressure and diabetes, require smart health monitoring systems in E-triage and priority systems, in which machine learning algorithms could be greatly beneficial. Although research directions on E-triage and priority systems that use machine learning algorithms in telemedicine vary, they are equally essential and should be considered. Hence, we provide a comprehensive review to emphasise the advantages of the existing research in multidisciplinary works of artificial intelligence, machine learning and healthcare services.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21273,""
"Lowering the Learning Curve: Intraoperative Automated Radiographic Visualization Tool Allows for Higher Accuracy of Cam Lesion Resection When Used By Novice Surgeon For Arthroscopic Femoroplasty","Beck, Chahla, Krivicich, Rasio, Taylor, Godbey, Nho","https://doi.org/10.1016/j.arthro.2021.08.020","20211003","PubMed","","To compare the accuracy of conventional fluoroscopy versus an intraoperative radiographic visualization tool in assisting a novice and experienced hip arthroscopist in comprehensive cam correction to a desired alpha angle (AA). A cadaveric study was performed using 28 hemi-pelvises with cam-type deformity (AA &gt; 55Ã‹Å¡) measured on anteroposterior, lateral, and Dunn-view radiographs. Two fellowship-trained hip arthroscopists each performed 14 arthroscopic femoroplasties. The specimens were randomly assigned: 14 of the procedures were performed by the experienced surgeon, with 7 using the automated radiographic visualization tool (Guided Femoroplasty) and 7 using routine fluoroscopy (Control). The same number of hips was assigned to the novice surgeon, completing 7 femoroplasties with and without the visualization tool. Each hip was imaged before and after femoroplasty in 6 different positions using intraoperative fluoroscopy to evaluate head-neck offset. Femoroplasty AAs were compared between groups with and without visualization tool use, as well as between surgeons. One-way analysis of variance analysis was performed to evaluate the consistency of cam resection. For the experienced hip arthroscopist, comparison of Guide Femoroplasty and Control groups resulted in similar accuracy when compared to the controls, with post-femoroplasty AA averages ranging from 41.4Ã‚Â° Ã‚Â± 3.8Ã‹Å¡ to 44.8Ã‚Â° Ã‚Â± 2.8Ã‹Å¡ (PÃ‚Â = .511) and 40.2Ã‚Â° Ã‚Â± 5.3Ã‹Å¡ to 45.6Ã‚Â° Ã‚Â± 2.2Ã‹Å¡ (PÃ‚Â = .225), respectively. For the novice hip arthroscopist, the Guided Femoroplasty group had higher accuracy, with post-femoroplasty AA averages ranging from 42.8Ã‚Â° Ã‚Â± 2.6Ã‹Å¡ to 46.1Ã‚Â° Ã‚Â± 7.2Ã‹Å¡(PÃ‚Â = .689) with and 39.8Ã‚Â° Ã‚Â± 3.1Ã‹Å¡ to 51.9Ã‚Â° Ã‚Â± 8.1Ã‹Å¡ (PÃ‚Â = .001) without the visualization tool. Comparison of procedure time did not show any statistically significant difference between the use of the radiographic visualization tool and controls for either surgeon (P &gt; .05 for all). Femoroplasty with and without the use of automated radiographic visualization tool results in accurate cam resection when used by both the experienced and novice surgeon. However, higher accuracy was observed when resecting to a desired AA performed by a novice surgeon using the visualization tool. Additionally, use of the visualization tool did not result in longer procedure times for either surgeon. The impact of incomplete cam resections and over-resection on patient outcomes in the literature has led to the recent development of automated intraoperative radiographic visualization tools that allow for assistance of cam resection accuracy for the treatment of femoroacetabular impingement syndrome. This cadaveric study demonstrates that femoroplasty with the use of an intraoperative automated radiographic visualization tool may result in more accurate cam resections.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21274,""
"Systematic review of predictive models of microbial water quality at freshwater recreational beaches","Heasley, Sanchez, Tustin, Young","https://doi.org/10.1371/journal.pone.0256785","20210829","PubMed","","Monitoring of fecal indicator bacteria at recreational waters is an important public health measure to minimize water-borne disease, however traditional culture methods for quantifying bacteria can take 18-24 hours to obtain a result. To support real-time notifications of water quality, models using environmental variables have been created to predict indicator bacteria levels on the day of sampling. We conducted a systematic review of predictive models of fecal indicator bacteria at freshwater recreational sites in temperate climates to identify and describe the existing approaches, trends, and their performance to inform beach water management policies. We conducted a comprehensive search strategy, including five databases and grey literature, screened abstracts for relevance, and extracted data using structured forms. Data were descriptively summarized. A total of 53 relevant studies were identified. Most studies (n = 44, 83%) were conducted in the United States and evaluated water quality using E. coli as fecal indicator bacteria (n = 46, 87%). Studies were primarily conducted in lakes (n = 40, 75%) compared to rivers (n = 13, 25%). The most commonly reported predictive model-building method was multiple linear regression (n = 37, 70%). Frequently used predictors in best-fitting models included rainfall (n = 39, 74%), turbidity (n = 31, 58%), wave height (n = 24, 45%), and wind speed and direction (n = 25, 47%, and n = 23, 43%, respectively). Of the 19 (36%) studies that measured accuracy, predictive models averaged an 81.0% accuracy, and all but one were more accurate than traditional methods. Limitations identifed by risk-of-bias assessment included not validating models (n = 21, 40%), limited reporting of whether modelling assumptions were met (n = 40, 75%), and lack of reporting on handling of missing data (n = 37, 70%). Additional research is warranted on the utility and accuracy of more advanced predictive modelling methods, such as Bayesian networks and artificial neural networks, which were investigated in comparatively fewer studies and creating risk of bias tools for non-medical predictive modelling.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21275,""
"Neonatal sepsis prediction through clinical decision support algorithms: A systematic review","Persad, Jost, HonorÃƒÂ©, Forsberg, Coste, Olsson, Rautiainen, Herlenius","https://doi.org/10.1111/apa.16083","20210913","PubMed","algorithm; clinical decision system; machine learning; neonatal sepsis; sepsis detection","To systematically summarise the current evidence of employing clinical decision support algorithms (CDSAs) using non-invasive parameters for sepsis prediction in neonates. A comprehensive search in PubMed, CENTRAL and EMBASE was conducted. Screening, data extraction and risk of bias were performed by two authors. The certainty of the evidence was assessed using GRADE. CRD42020205143. After abstract and full-text screening, 36 studies comprising 18,096 infants were included. Most CDSAs evaluated heart rate (HR)-based parameters. Two publications derived from one randomised-controlled trial assessing HR characteristics reported significant reduction in 30-day septicaemia-related mortality. Thirty-four non-randomised studies found promising yet inconclusive results. Heart rate-based parameters are reliable components of CDSAs for sepsis prediction, particularly in combination with additional vital signs and demographics. However, inconclusive evidence and limited standardisation restricts clinical implementation of CDSAs outside of a controlled research environment. Further experimentation and comparison of parameter combinations and testing of new CDSAs are warranted.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21276,""
"Fluence adaptation for contrast-based dose optimization in x-ray phase-contrast imaging","Wu, Xing, Zhang, Chen, Zhu, Zhang, Gao","https://doi.org/10.1002/mp.15189","20210910","PubMed","dose optimization; fluence adaptation; grating-based imaging; x-ray phase-contrast imaging","X-ray phase-contrast imaging (XPCI) can provide multiple contrasts with great potentials for clinical and industrial applications, including conventional attenuation, phase contrast, and dark field. Grating-based imaging (GBI) and edge-illumination (EI) are two promising types of XPCI as the conventional x-ray sources can be directly utilized. For the GBI and EI systems, the phase-stepping acquisition with multiple exposures at a constant fluence is usually adopted in the literature.This work, however, attempts to challenge such a constant fluence concept during the phase-stepping process and proposes a fluence adaptation mechanism for doseÃ‚Â reduction. Given the importance of patient radiation dose for clinical applications, numerous studies have tried to reduce patient dose in XPCI by altering imaging system designs, data acquisition, and information retrieval. Recently, analytic multiorder moment analysis has been proposed to improve the computing efficiency. In these algorithms, multiple contrasts can be calculated by summing together the weighted phase-stepping curves (PSCs) with some kernel functions, which suggests us that the raw data at different steps have different contributions for the noise in retrieved contrasts. Therefore, it is possible to improve the noise performance by adjusting the fluence distribution during the phase-stepping process directly. Based on analytic retrieval formulas and the Gaussian noise model for detected signals, we derived an optimal adaptive fluence distribution, which is proportional to the absolute weighting kernel functions and the root of original sample PSCs acquired under the constant fluence. Considering that the original sample PSC might be unavailable, we proposed two practical forms for the GBI and EI systems, which are also able to reduce the contrast noise when comparing with the constant fluence distribution. Since the kernel functions are target contrast-dependent, our proposed fluence adaptation mechanism provides a way of realizing a contrast-based dose optimization while keeping the same noiseÃ‚Â level. To validate our analyses, simulations and experiments are conducted for the GBI and EI systems. Simulated results demonstrate that the dose reduction ratio between our proposed fluence distributions and the typical constant one can be about 20% for the phase contrast, which is consistent with our theoretical predictions. Although the experimental noise reduction ratios are a little smaller than the theoretical ones, low-dose experiments observe better noise performance by our proposed method. Our simulated results also give out the effective ranges of the parameters of the PSCs, such as the visibility in the GBI, the standard deviation, and the mean value in the EI, providing a guidance for the use of our proposed approach inÃ‚Â practice. In this paper, we propose a fluence adaptation mechanism for contrast-based dose optimization in XPCI, which can be applied to the GBI and EI systems. Our proposed method explores a new direction for dose reduction, and may also be further extended to other types of XPCI systems and information retrievalÃ‚Â algorithms.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21277,""
"Computer-Aided Diagnosis of Diminutive Colorectal Polyps in Endoscopic Images: Systematic Review and Meta-analysis of Diagnostic Test Accuracy","Bang, Lee, Baik","https://doi.org/10.2196/29682","20211026","PubMed","artificial intelligence; colon; colonoscopy; deep learning; diminutive; polyps; Colonic Polyps; Colonoscopy; Colorectal Neoplasms; Computers; Diagnostic Tests, Routine; Humans; Narrow Band Imaging","Most colorectal polyps are diminutive and benign, especially those in the rectosigmoid colon, and the resection of these polyps is not cost-effective. Advancements in image-enhanced endoscopy have improved the optical prediction of colorectal polyp histology. However, subjective interpretability and inter- and intraobserver variability prohibits widespread implementation. The number of studies on computer-aided diagnosis (CAD) is increasing; however, their small sample sizes limit statistical significance. This review aims to evaluate the diagnostic test accuracy of CAD models in predicting the histology of diminutive colorectal polyps by using endoscopic images. Core databases were searched for studies that were based on endoscopic imaging, used CAD models for the histologic diagnosis of diminutive colorectal polyps, and presented data on diagnostic performance. A systematic review and diagnostic test accuracy meta-analysis were performed. Overall, 13 studies were included. The pooled area under the curve, sensitivity, specificity, and diagnostic odds ratio of CAD models for the diagnosis of diminutive colorectal polyps (adenomatous or neoplastic vs nonadenomatous or nonneoplastic) were 0.96 (95% CI 0.93-0.97), 0.93 (95% CI 0.91-0.95), 0.87 (95% CI 0.76-0.93), and 87 (95% CI 38-201), respectively. The meta-regression analysis showed no heterogeneity, and no publication bias was detected. Subgroup analyses showed robust results. The negative predictive value of CAD models for the diagnosis of adenomatous polyps in the rectosigmoid colon was 0.96 (95% CI 0.95-0.97), and this value exceeded the threshold of the diagnosis and leave strategy. CAD models show potential for the optical histological diagnosis of diminutive colorectal polyps via the use of endoscopic images. PROSPERO CRD42021232189; https://www.crd.york.ac.uk/prospero/display_record.php?RecordID=232189.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21278,""
"Active Learning in E-Learning Programs for Evidence-Based Nursing in Academic Settings: A Scoping Review","Song, Park","https://doi.org/10.3928/00220124-20210804-05","20210827","PubMed","Computer-Assisted Instruction; Education, Nursing; Evidence-Based Nursing; Humans; Problem-Based Learning; Students, Nursing","The use of e-learning in nursing education has increased substantially. The goal of this study is to identify how active e-learning for evidence-based practice (EBP) was implemented in academic settings. For a scoping review, literature from PubMed, CINAHL, and EMBASE was searched with keywords related to e-learning and EBP, and only articles pertaining to nursing academic settings were selected. Finally, 17 studies were included. Data on theories or instructional strategies and types and characteristics of online activities were extracted. Of the included studies, 14 had a pedagogical background. Frequently used activities included discussions, asynchronous communications, and a combination of student-student and student-teacher interactions. Critical appraisal was the primary learning content. This study summarizes evidence on active learning to enhance the EBP competency of nursing students through e-learning. To make EBP e-learning more meaningful, educators should plan, apply, and evaluate appropriate online activities. <b>[<i>J Contin Educ Nurs</i>. 2021;52(9):407-412.]</b>.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21279,""
"Biomarkers for Nonexudative Age-Related Macular Degeneration and Relevance for Clinical Trials: A Systematic Review","Fang, Gomez-Caraballo, Lad","https://doi.org/10.1007/s40291-021-00551-5","20210825","PubMed","","The purpose of the review was to identify structural, functional, blood-based, and other types of biomarkers for early, intermediate, and late nonexudative stages of age-related macular degeneration (AMD) and summarize the relevant data for proof-of-concept clinical trials. AMD is a leading cause of blindness in the aging population, yet no treatments exist for its most common nonexudative form. There are limited data on the diagnosis and progression of nonexudative AMD compared to neovascular AMD. Our objective was to provide a comprehensive, systematic review of recently published biomarkers (molecular, structural, and functional) for early AMD, intermediate AMD, and geographic atrophy and to evaluate the relevance of these biomarkers for use in future clinical trials. A literature search of PubMed, ScienceDirect, EMBASE, and Web of Science from January 1, 1996 to November 30, 2020 and a patent search were conducted. Search terms included ""early AMD,"" ""dry AMD,"" ""intermediate AMD,"" ""biomarkers for nonexudative AMD,"" ""fundus autofluorescence patterns,"" ""color fundus photography,"" ""dark adaptation,"" and ""microperimetry."" Articles were assessed for bias and quality with the Mixed-Methods Appraisal Tool. A total of 94 articles were included (61,842 individuals). Spectral-domain optical coherence tomography was superior at highlighting detailed structural changes in earlier stages of AMD. Fundus autofluorescence patterns were found to be most important in estimating progression of geographic atrophy. Delayed rod intercept time on dark adaptation was the most widely recommended surrogate functional endpoint for early AMD, while retinal sensitivity on microperimetry was most relevant for intermediate AMD. Combinational studies accounting for various patient characteristics and machine/deep-learning approaches were best suited for assessing individualized risk of AMD onset and progression. This systematic review supports the use of structural and functional biomarkers in early AMD and intermediate AMD, which are more reproducible and less invasive than the other classes of biomarkers described. The use of deep learning and combinational algorithms will gain increasing importance in future clinical trials of nonexudative AMD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21280,""
"The validity and reliability of computer-aided semen analyzers in performing semen analysis: a systematic review","Finelli, Leisegang, Tumallapalli, Henkel, Agarwal","https://doi.org/10.21037/tau-21-276","20210826","PubMed","Computer-aided sperm analyzers (CASA); computer-assisted sperm analysis; semen analysis; sperm concentration","Computer-aided sperm analyzers (CASA) are currently used worldwide for semen analysis. However, there are doubts about their reliability to fully substitute the human operator. Therefore, this study aimed to systematically review the current literature comparing results from semen evaluation by both CASA-based and manual approaches. A systematic screening of the literature was performed based on the PRISMA guidelines and by searching on PubMed, Scopus, and Embase databases. A total of 14 studies were included. Our results showed a high degree of correlation for sperm concentration and motility when analysis was performed either manually or by using a CASA system. However, CASA results showed increased variability in low (&lt;15 million/mL) and high (&gt;60 million/mL) concentration specimens, while sperm motility assessment was inaccurate in samples with higher concentration or in the presence of non-sperm cells and debris. Morphology results showed the highest level of difference, due to the high amount of heterogeneity seen between the shapes of the spermatozoa either in one sample or across multiple samples from the same subject. Overall, our study suggests CASA systems as a valid alternative for the evaluation of semen parameters in clinical practice, especially for sperm concentration and motility. However, further technological improvements are required before these devices can one day completely replace the human operator. Artificial intelligence-based CASA devices promise to offer higher efficiency of the analysis and improve the reliability of results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21281,""
"CogTale: an online platform for the evaluation, synthesis, and dissemination of evidence from cognitive interventions studies","Sabates, Belleville, Castellani, Dwolatzky, Hampstead, Lampit, Simon, Anstey, Goodenough, Mancuso, Marques, Sinnott, Bahar-Fuchs","https://doi.org/10.1186/s13643-021-01787-2","20211026","PubMed","Cognitive interventions; Dementia; Evidence synthesis; Older adults; Cognition; Cognition Disorders; Humans; Meta-Analysis as Topic; Systematic Reviews as Topic","Systematic reviews and meta-analyses are critical in health-related decision-making, and are considered the gold standard in research synthesis methods. However, with new trials being regularly published and with the development of increasingly rigorous standards of data synthesis, systematic reviews often require much expertise and long periods of time to be completed. Automation of some of the steps of evidence synthesis productions is a promising improvement in the field, capable of reducing the time and costs associated with the process.This article describes the development and main characteristics of a novel online repository of cognitive intervention studies entitled Cognitive Treatments Article Library and Evaluation (CogTale). The platform is currently in a Beta Release phase, as it is still under development. However, it already contains over 70 studies, and the CogTale team is continuously coding and uploading new studies into the repository. Key features include advanced search options, the capability to generate meta-analyses, and an up-to-date display of relevant published studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21282,""
"Applications of machine learning to undifferentiated chest pain in the emergency department: A systematic review","Stewart, Lu, Goudie, Bennamoun, Sprivulis, Sanfillipo, Dwivedi","https://doi.org/10.1371/journal.pone.0252612","20210827","PubMed","","Chest pain is amongst the most common reason for presentation to the emergency department (ED). There are many causes of chest pain, and it is important for the emergency physician to quickly and accurately diagnose life threatening causes such as acute myocardial infarction (AMI). Multiple clinical decision tools have been developed to assist clinicians in risk stratifying patients with chest. There is growing recognition that machine learning (ML) will have a significant impact on the practice of medicine in the near future and may assist with diagnosis and risk stratification. This systematic review aims to evaluate how ML has been applied to adults presenting to the ED with undifferentiated chest pain and assess if ML models show improved performance when compared to physicians or current risk stratification techniques. We conducted a systematic review of journal articles that applied a ML technique to an adult patient presenting to an emergency department with undifferentiated chest pain. Multiple databases were searched from inception through to November 2020. In total, 3361 articles were screened, and 23 articles were included. We did not conduct a metanalysis due to a high level of heterogeneity between studies in both their methods, and reporting. The most common primary outcomes assessed were diagnosis of acute myocardial infarction (AMI) (12 studies), and prognosis of major adverse cardiovascular event (MACE) (6 studies). There were 14 retrospective studies and 5 prospective studies. Four studies reported the development of a machine learning model retrospectively then tested it prospectively. The most common machine learning methods used were artificial neural networks (14 studies), random forest (6 studies), support vector machine (5 studies), and gradient boosting (2 studies). Multiple studies achieved high accuracy in both the diagnosis of AMI in the ED setting, and in predicting mortality and composite outcomes over various timeframes. ML outperformed existing risk stratification scores in all cases, and physicians in three out of four cases. The majority of studies were single centre, retrospective, and without prospective or external validation. There were only 3 studies that were considered low risk of bias and had low applicability concerns. Two studies reported integrating the ML model into clinical practice. Research on applications of ML for undifferentiated chest pain in the ED has been ongoing for decades. ML has been reported to outperform emergency physicians and current risk stratification tools to diagnose AMI and predict MACE but has rarely been integrated into practice. Many studies assessing the use of ML in undifferentiated chest pain in the ED have a high risk of bias. It is important that future studies make use of recently developed standardised ML reporting guidelines, register their protocols, and share their datasets and code. Future work is required to assess the impact of ML model implementation on clinical decision making, patient orientated outcomes, and patient and physician acceptability. International Prospective Register of Systematic Reviews registration number: CRD42020184977.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21283,""
"Semi-automated assessment of the principal diffusion direction in the corpus callosum: differentiation of idiopathic normal pressure hydrocephalus from neurodegenerative diseases","Caligiuri, Quattrone, Mechelli, La Torre, Quattrone","https://doi.org/10.1007/s00415-021-10762-9","20210824","PubMed","AlzheimerÃ¢â‚¬â„¢s disease; Corpus callosum; Diffusion tensor imaging; Idiopathic normal pressure hydrocephalus; Principal diffusion direction; Progressive supranuclear palsy","Idiopathic normal pressure hydrocephalus (iNPH) shares clinical and radiological features with progressive supranuclear palsy (PSP) and Alzheimer's disease (AD). Corpus callosum (CC) involvement in these disorders is well established on structural MRI and diffusion tensor imaging (DTI), but alterations overlap and lack specificity to underlying tissue changes. We propose a semi-automated approach to assess CC integrity in iNPH based on the spatial distribution of DTI-derived principal diffusion direction orientation (V1). We processed DTI data from 121 subjects (Site1: iNPHÃ¢â‚¬â€°=Ã¢â‚¬â€°23, PSPÃ¢â‚¬â€°=Ã¢â‚¬â€°27, controlsÃ¢â‚¬â€°=Ã¢â‚¬â€°14; ADNI: ADÃ¢â‚¬â€°=Ã¢â‚¬â€°35, controlsÃ¢â‚¬â€°=Ã¢â‚¬â€°22) to obtain V1, fractional anisotropy (FA) and mean diffusivity (MD) maps. To increase the estimation accuracy of DTI metrics, analyses were restricted to the midsagittal CC portion (Ã‚Â±Ã¢â‚¬â€°6 slices from midsagittal plane). Group-wise comparison of normalized altered voxel count in midsagittal CC was performed using Kruskal-Wallis tests, followed by post hoc comparisons (Bonferroni-corrected pÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.05). ROC analysis was used to evaluate the diagnostic power of DTI alterations compared to callosal volume. We found specific changes of V1 distribution in CC splenium of iNPH compared to AD and PSP, while MD and FA showed patterns of alterations common to all disorders. ROC curves showed that, compared to splenial volume, V1 represented the most accurate marker of iNPH diagnosis versus AD and PSP. Our results provide evidence that V1 is a powerful biomarker for distinguishing patients with iNPH from patients with AD or PSP. Indeed, our findings also provide more specific insight into the pathophysiological mechanisms that underlie tissue damage across iNPH and its mimics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21284,""
"Convolution neural network for the diagnosis of wireless capsule endoscopy: a systematic review and meta-analysis","Qin, Li, Fang, Xu, Wu, Zhang, Li, Liu, Li","https://doi.org/10.1007/s00464-021-08689-3","20210824","PubMed","Capsule endoscopy; Convolutional neural network; Deep learning","Wireless capsule endoscopy (WCE) is considered to be a powerful instrument for the diagnosis of intestine diseases. Convolution neural network (CNN) is a type of artificial intelligence that has the potential to assist the detection of WCE images. We aimed to perform a systematic review of the current research progress to the CNN application in WCE. A search in PubMed, SinoMed, and Web of Science was conducted to collect all original publications about CNN implementation in WCE. Assessment of the risk of bias was performed by Quality Assessment of Diagnostic Accuracy Studies-2 risk list. Pooled sensitivity and specificity were calculated by an exact binominal rendition of the bivariate mixed-effects regression model. I<sup>2</sup> was used for the evaluation of heterogeneity. 16 articles with 23 independent studies were included. CNN application to WCE was divided into detection on erosion/ulcer, gastrointestinal bleeding (GI bleeding), and polyps/cancer. The pooled sensitivity of CNN for erosion/ulcer is 0.96 [95% CI 0.91, 0.98], for GI bleeding is 0.97 (95% CI 0.93-0.99), and for polyps/cancer is 0.97 (95% CI 0.82-0.99). The corresponding specificity of CNN for erosion/ulcer is 0.97 (95% CI 0.93-0.99), for GI bleeding is 1.00 (95% CI 0.99-1.00), and for polyps/cancer is 0.98 (95% CI 0.92-0.99). Based on our meta-analysis, CNN-dependent diagnosis of erosion/ulcer, GI bleeding, and polyps/cancer approached a high-level performance because of its high sensitivity and specificity. Therefore, future perspective, CNN has the potential to become an important assistant for the diagnosis of WCE.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21285,""
"Literature Review on the Applications of Machine Learning and Blockchain Technology in Smart Healthcare Industry: A Bibliometric Analysis","Li, Shan, Li, Liu, Pu","https://doi.org/10.1155/2021/9739219","20210825","PubMed","","The emergence of machine learning (ML) and blockchain (BC) technology has greatly enriched the functions and services of healthcare, giving birth to the new field of ""smart healthcare."" This study aims to review the application of ML and BC technology in the smart medical industry by Web of Science (WOS) using bibliometric visualization. Through our research, we identify the countries with the greatest output, the major research subjects, funding funds, and the research hotspots in this field. We also find out the key themes and future research areas in application of ML and BC technology in healthcare area. We reveal the different aspects of research under the two technologies and how they relate to each other around five themes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21286,""
"Linking common human diseases to their phenotypes; development of a resource for human phenomics","Kafkas, Althubaiti, Gkoutos, Hoehndorf, Schofield","https://doi.org/10.1186/s13326-021-00249-x","20211028","PubMed","DiseaseÃ¢â‚¬â€œphenotype associations; Ontologies; Text mining; UK Biobank; Data Mining; Databases, Factual; Humans; Knowledge Bases; Phenomics; Phenotype","In recent years a large volume of clinical genomics data has become available due to rapid advances in sequencing technologies. Efficient exploitation of this genomics data requires linkage to patient phenotype profiles. Current resources providing disease-phenotype associations are not comprehensive, and they often do not have broad coverage of the disease terminologies, particularly ICD-10, which is still the primary terminology used in clinical settings. We developed two approaches to gather disease-phenotype associations. First, we used a text mining method that utilizes semantic relations in phenotype ontologies, and applies statistical methods to extract associations between diseases in ICD-10 and phenotype ontology classes from the literature. Second, we developed a semi-automatic way to collect ICD-10-phenotype associations from existing resources containing known relationships. We generated four datasets. Two of them are independent datasets linking diseases to their phenotypes based on text mining and semi-automatic strategies. The remaining two datasets are generated from these datasets and cover a subset of ICD-10 classes of common diseases contained in UK Biobank. We extensively validated our text mined and semi-automatically curated datasets by: comparing them against an expert-curated validation dataset containing disease-phenotype associations, measuring their similarity to disease-phenotype associations found in public databases, and assessing how well they could be used to recover gene-disease associations using phenotype similarity. We find that our text mining method can produce phenotype annotations of diseases that are correct but often too general to have significant information content, or too specific to accurately reflect the typical manifestations of the sporadic disease. On the other hand, the datasets generated from integrating multiple knowledgebases are more complete (i.e., cover more of the required phenotype annotations for a given disease). We make all data freely available at https://doi.org/10.5281/zenodo.4726713 .","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21287,""
"The Pipeline for Standardizing Russian Unstructured Allergy Anamnesis Using FHIR AllergyIntolerance Resource","Lenivtceva, Kopanitsa","https://doi.org/10.1055/s-0041-1733945","20210823","PubMed","","Ã¢â‚¬Æ’The larger part of essential medical knowledge is stored as free text which is complicated to process. Standardization of medical narratives is an important task for data exchange, integration, and semantic interoperability. Ã¢â‚¬Æ’The article aims to develop the end-to-end pipeline for structuring Russian free-text allergy anamnesis using international standards. Ã¢â‚¬Æ’The pipeline for free-text data standardization is based on FHIR (Fast Healthcare Interoperability Resources) and SNOMED CT (Systematized Nomenclature of Medicine Clinical Terms) to ensure semantic interoperability. The pipeline solves common tasks such as data preprocessing, classification, categorization, entities extraction, and semantic codes assignment. Machine learning methods, rule-based, and dictionary-based approaches were used to compose the pipeline. The pipeline was evaluated on 166 randomly chosen medical records. Ã¢â‚¬Æ’AllergyIntolerance resource was used to represent allergy anamnesis. The module for data preprocessing included the dictionary with over 90,000 words, including specific medication terms, and more than 20 regular expressions for errors correction, classification, and categorization modules resulted in four dictionaries with allergy terms (total 2,675 terms), which were mapped to SNOMED CT concepts. F-scores for different steps are: 0.945 for filtering, 0.90 to 0.96 for allergy categorization, 0.90 and 0.93 for allergens reactions extraction, respectively. The allergy terminology coverage is more than 95%. Ã¢â‚¬Æ’The proposed pipeline is a step to ensure semantic interoperability of Russian free-text medical records and could be effective in standardization systems for further data exchange and integration.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21288,""
"Systematic Review of the Effectiveness of Machine Learning Algorithms for Classifying Pain Intensity, Phenotype or Treatment Outcomes Using Electroencephalogram Data","Mari, Henderson, Maden, Nevitt, Duarte, Fallon","https://doi.org/10.1016/j.jpain.2021.07.011","20210918","PubMed","Machine learning; pain intensity; pain phenotypes; systematic review; treatment response","Recent attempts to utilize machine learning (ML) to predict pain-related outcomes from Electroencephalogram (EEG) data demonstrate promising results. The primary aim of this review was to evaluate the effectiveness of ML algorithms for predicting pain intensity, phenotypes or treatment response from EEG. Electronic databases MEDLINE, EMBASE, Web of Science, PsycINFO and The Cochrane Library were searched. A total of 44 eligible studies were identified, with 22 presenting attempts to predict pain intensity, 15 investigating the prediction of pain phenotypes and seven assessing the prediction of treatment response. A meta-analysis was not considered appropriate for this review due to heterogenos methods and reporting. Consequently, data were narratively synthesized. The results demonstrate that the best performing model of the individual studies allows for the prediction of pain intensity, phenotypes and treatment response with accuracies ranging between 62 to 100%, 57 to 99% and 65 to 95.24%, respectively. The results suggest that ML has the potential to effectively predict pain outcomes, which may eventually be used to assist clinical care. However, inadequate reporting and potential bias reduce confidence in the results. Future research should improve reporting standards and externally validate models to decrease bias, which would increase the feasibility of clinical translation. PERSPECTIVE: This systematic review explores the state-of-the-art machine learning methods for predicting pain intensity, phenotype or treatmentresponse from EEG data. Results suggest that machine learning may demonstrate clinical utility, pending further research and development. Areas for improvement, including standardized processing, reporting and the need for better methodological assessment tools, are discussed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21289,""
"Dysregulated resting state functional connectivity and obesity: A systematic review","Syan, McIntyre-Wood, Minuzzi, Hall, McCabe, MacKillop","https://doi.org/10.1016/j.neubiorev.2021.08.019","20211030","PubMed","BMI; Functional magnetic resonance imaging; Obesity; Overweight; Resting state functional connectivity","Obesity has been variously linked to differences in brain functional connectivity in regions associated with reward, emotional regulation and cognition, potentially revealing neural mechanisms contributing to its development and maintenance. This systematic review summarizes and critically appraises the existing literature on differences in resting state functional connectivity (Rs-FC) between overweight and individuals with obesity in relation healthy-BMI controls. Twenty-nine studies were identified and the results consistently support the hypothesis that obesity is associated with differences in Rs-FC. Specifically, obesity/overweight was consistently associated with (i) DMN hypoconnectivity and salience network hyperconnectivity; (ii) increased Rs-FC between the hypothalamus and reward, limbic and salience networks, and decreased Rs-FC between the hypothalamus and cognitive regions; (iii) increased power within regions associated with inhibition/emotional reasoning; (iv) decreased nodal efficiency, degree centrality, and global efficiency. Collectively, the results suggest obesity is associated with disrupted connectivity of brain networks responsible for cognition, reward, self-referential processing and emotional regulation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21290,""
"The expectations and acceptability of a smart nursing home model among Chinese elderly people: A mixed methods study protocol","Zhao, Sazlina, Rokhani, Su, Chew","https://doi.org/10.1371/journal.pone.0255865","20210826","PubMed","","Nursing homes integrated with smart information such as the Internet of Things, cloud computing, artificial intelligence, and digital health could improve not only the quality of care but also benefit the residents and health professionals by providing effective care and efficient medical services. However, a clear concept of a smart nursing home, the expectations and acceptability from the perspectives of the elderly people and their family members are still unclear. In addition, instruments to measure the expectations and acceptability of a smart nursing home are also lacking. The study aims to explore and determine the levels of these expectations, acceptability and the associated sociodemographic factors. This exploratory sequential mixed methods study comprises a qualitative study which will be conducted through a semi-structured interview to explore the expectations and acceptability of a smart nursing home among Chinese elderly people and their family members (Phase I). Next, a questionnaire will be developed and validated based on the results of a qualitative study in Phase I and a preceding scoping review on smart nursing homes by the same authors (Phase II). Lastly, a nationwide survey will be carried out to examine the levels of expectations and acceptability, and the associated sociodemographic factors with the different categories of expectations and acceptability (Phase III). With a better understanding of the Chinese elderly people's expectations and acceptability of smart technologies in nursing homes, a feasible smart nursing home model that incorporates appropriate technologies, integrates needed medical services and business concepts could be formulated and tested as a solution for the rapidly ageing societies in many developed and developing countries.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21291,""
"Systematic review of Pharmacogenomics Knowledgebase evidence for pharmacogenomic links to the dopamine reward pathway for heroin dependence","McCorkle, Kisor, Freiermuth, Sprague","https://doi.org/10.2217/pgs-2021-0023","20210921","PubMed","dopamine; heroin dependence; opioid use disorder; pharmacogenomics; substance abuse","Genetics play an importantÃ‚Â role in opioid use disorder (OUD);Ã‚Â however, few specific gene variants have been identified. Therefore, there is a need to further understand the pharmacogenomics influences on the pharmacodynamics of opioids. The Pharmacogenomics Knowledgebase (PharmGKB), a database that links genetic variation and drug interaction in the body, was queried to identify polymorphisms associated with heroin dependence in the context of opioid related disorders/OUD. Eight genes with 22 variants were identified as linked to increased risk of heroin dependence, with three genes and variants linked to decreased risk, although the level of evidence was moderate to low. Therefore, continued exploration of biomarker influences on OUD, reward pathways and other contributing circuitries is necessary to understand the true impact of genetics on OUD before integration into clinical guidelines.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21292,""
"Sysrev: A FAIR Platform for Data Curation and Systematic Evidence Review","Bozada, Borden, Workman, Del Cid, Malinowski, Luechtefeld","https://doi.org/10.3389/frai.2021.685298","20210824","PubMed","data extraction; data management; evidence review; machine learning; meta analysis; software; systematic review","Well-curated datasets are essential to evidence based decision making and to the integration of artificial intelligence with human reasoning across disciplines. However, many sources of data remain siloed, unstructured, and/or unavailable for complementary and secondary research. Sysrev was developed to address these issues. First, Sysrev was built to aid in systematic evidence reviews (SER), where digital documents are evaluated according to a well defined process, and where Sysrev provides an easy to access, publicly available and free platform for collaborating in SER projects. Secondly, Sysrev addresses the issue of unstructured, siloed, and inaccessible data in the context of generalized data extraction, where human and machine learning algorithms are combined to extract insights and evidence for better decision making across disciplines. Sysrev uses FAIR - Findability, Accessibility, Interoperability, and Reuse of digital assets - as primary principles in design. Sysrev was developed primarily because of an observed need to reduce redundancy, reduce inefficient use of human time and increase the impact of evidence based decision making. This publication is an introduction to Sysrev as a novel technology, with an overview of the features, motivations and use cases of the tool. <b>Methods:</b> Sysrev. com is a FAIR motivated web platform for data curation and SER. Sysrev allows users to create data curation projects called ""sysrevs"" wherein users upload documents, define review tasks, recruit reviewers, perform review tasks, and automate review tasks. <b>Conclusion:</b> Sysrev is a web application designed to facilitate data curation and SERs. Thousands of publicly accessible Sysrev projects have been created, accommodating research in a wide variety of disciplines. Described use cases include data curation, managed reviews, and SERs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21293,""
"Natural language processing for automated annotation of medication mentions in primary care visit conversations","Ganoe, Wu, Barr, Haslett, Dannenberg, Bonasia, Finora, Schoonmaker, Onsando, Ryan, Elwyn, Bruce, Das, Hassanpour","https://doi.org/10.1093/jamiaopen/ooab071","20210824","PubMed","clinic visit recording; medication information extraction; natural language processing","The objective of this study is to build and evaluate a natural language processing approach to identify medication mentions in primary care visit conversations between patients and physicians. Eight clinicians contributed to a data set of 85 clinic visit transcripts, and 10 transcripts were randomly selected from this data set as a development set. Our approach utilizes Apache cTAKES and Unified Medical Language System controlled vocabulary to generate a list of medication candidates in the transcribed text and then performs multiple customized filters to exclude common false positives from this list while including some additional common mentions of the supplements and immunizations. Sixty-five transcripts with 1121 medication mentions were randomly selected as an evaluation set. Our proposed method achieved an F-score of 85.0% for identifying the medication mentions in the test set, significantly outperforming existing medication information extraction systems for medical records with F-scores ranging from 42.9% to 68.9% on the same test set. Our medication information extraction approach for primary care visit conversations showed promising results, extracting about 27% more medication mentions from our evaluation set while eliminating many false positives in comparison to existing baseline systems. We made our approach publicly available on the web as an open-source software. Integration of our annotation system with clinical recording applications has the potential to improve patients' understanding and recall of key information from their clinic visits, and, in turn, to positively impact health outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21294,""
"Artificial intelligence in the management and treatment of burns: a systematic review","E Moura, Amin, Ekwobi","https://doi.org/10.1093/burnst/tkab022","20210824","PubMed","Artificial intelligence; Burn; Computer vision; Machine learning; Neural networks","Artificial intelligence (AI) is an innovative field with potential for improving burn care. This article provides an updated review on machine learning in burn care and discusses future challenges and the role of healthcare professionals in the successful implementation of AI technologies. A systematic search was carried out on MEDLINE, Embase and PubMed databases for English-language articles studying machine learning in burns. Articles were reviewed quantitatively and qualitatively for clinical applications, key features, algorithms, outcomes and validation methods. A total of 46 observational studies were included for review. Assessment of burn depth (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°26), support vector machines (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°19) and 10-fold cross-validation (<i>n</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°11) were the most common application, algorithm and validation tool used, respectively. AI should be incorporated into clinical practice as an adjunct to the experienced burns provider once direct comparative analysis to current gold standards outlining its benefits and risks have been studied. Future considerations must include the development of a burn-specific common framework. Authors should use common validation tools to allow for effective comparisons. Level I/II evidence is required to produce robust proof about clinical and economic impacts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21295,""
"Levels of Reading Comprehension in Higher Education: Systematic Review and Meta-Analysis","de-la-PeÃƒÂ±a, Luque-Rojas","https://doi.org/10.3389/fpsyg.2021.712901","20210824","PubMed","higher education; meta-analysis; reading comprehension; systematic review; university students","Higher education aims for university students to produce knowledge from the critical reflection of scientific texts. Therefore, it is necessary to develop a deep mental representation of written information. The objective of this research was to determine through a systematic review and meta-analysis the proportion of university students who have an optimal performance at each level of reading comprehension. Systematic review of empirical studies has been limited from 2010 to March 2021 using the Web of Science, Scopus, Medline, and PsycINFO databases. Two reviewers performed data extraction independently. A random-effects model of proportions was used for the meta-analysis and heterogeneity was assessed with <i>I</i> <sup>2</sup>. To analyze the influence of moderating variables, meta-regression was used and two ways were used to study publication bias. Seven articles were identified with a total sample of the seven of 1,044. The proportion of students at the literal level was 56% (95% CI = 39-72%, <i>I</i> <sup>2</sup> = 96.3%), inferential level 33% (95% CI = 19-46%, <i>I</i> <sup>2</sup> = 95.2%), critical level 22% (95% CI = 9-35%, <i>I</i> <sup>2</sup> = 99.04%), and organizational level 22% (95% CI = 6-37%, <i>I</i> <sup>2</sup> = 99.67%). Comparing reading comprehension levels, there is a significant higher proportion of university students who have an optimal level of literal compared to the rest of the reading comprehension levels. The results have to be interpreted with caution but are a guide for future research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21296,""
"Methods for Small Area Population Forecasts: State-of-the-Art and Research Needs","Wilson, Grossman, Alexander, Rees, Temple","https://doi.org/10.1007/s11113-021-09671-6","20210824","PubMed","Literature review; Population forecasts; Research needs; Small area","Small area population forecasts are widely used by government and business for a variety of planning, research and policy purposes, and often influence major investment decisions. Yet, the toolbox of small area population forecasting methods and techniques is modest relative to that for national and large subnational regional forecasting. In this paper, we assess the current state of small area population forecasting, and suggest areas for further research. The paper provides a review of the literature on small area population forecasting methods published over the period 2001-2020. The key themes covered by the review are extrapolative and comparative methods, simplified cohort-component methods, model averaging and combining, incorporating socioeconomic variables and spatial relationships, 'downscaling' and disaggregation approaches, linking population with housing, estimating and projecting small area component input data, microsimulation, machine learning, and forecast uncertainty. Several avenues for further research are then suggested, including more work on model averaging and combining, developing new forecasting methods for situations which current models cannot handle, quantifying uncertainty, exploring methodologies such as machine learning and spatial statistics, creating user-friendly tools for practitioners, and understanding more about how forecasts are used. The online version contains supplementary material available at 10.1007/s11113-021-09671-6.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21297,""
"Racial and Gender Discrimination in Hand Surgery Letters of Recommendation","Bradford, Akyeampong, Fleming, Dacus, Chhabra, DeGeorge","https://doi.org/10.1016/j.jhsa.2021.07.009","20210823","PubMed","Agency; communality; diversity; hand surgery; letter of recommendation","We sought to evaluate hand surgery applicants' letters of recommendations to understand whether applicant and letter writer demographics contribute to racial and gender bias. All applications submitted through the American Society for Surgery of the Hand match to a single institution fellowship program for the 2017 to 2019 application cycles were analyzed using validated text analysis software. Race/ethnicity information was derived from an analysis of applicant photos using the Face Secret Pro software. Primary outcome measures were differences in communal and agentic language used in letters of recommendation, stratified by both race/ethnicity and gender. A total of 912 letters of recommendation were analyzed for 233 applicants (51 female and 172 male). Of these, 88 were written by female letter writers and 824 were written by male letter writers. There were 8 Black, 12 Hispanic, 36 Asian, and 167 White applicants. Letter writers used more agentic language with Asian applicants and non-White applicants overall. Female letter writers used more communal terms and were not associated with applicant race or gender. Letters of recommendation in hand surgery demonstrate disparities in language based on race and gender. Alerting letter writers to the role of implicit bias will hopefully spur a discussion on tools to mitigate the use of biased language and provide a foundation for an equitable selection process. Efforts to improve policies and procedures pertaining to diversity and inclusion are paramount to ensuring that fellows more completely represent the population hand surgeons wish to serve.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21298,""
"Reply to ""Anatomical predictors of long-term urinary incontinence after robot-assisted laparoscopic prostatectomy: A systematic review""","MuÃƒÂ±oz-Calahorro, GarcÃƒÂ­a-SÃƒÂ¡nchez, Barrero-Candau, GarcÃƒÂ­a-Ramos, RodrÃƒÂ­guez-PÃƒÂ©rez, Medina-LÃƒÂ³pez","https://doi.org/10.1002/nau.24772","20211102","PubMed","Humans; Laparoscopy; Male; Prostatectomy; Robotics; Urinary Incontinence","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21299,""
"Seeing under the cover with a 3D U-Net: point cloud-based weight estimation of covered patients","Bigalke, Hansen, Diesel, Heinrich","https://doi.org/10.1007/s11548-021-02476-0","20210822","PubMed","3D U-Net; Clinical weight estimation; Covered patients; Deep learning; Point clouds","Body weight is a crucial parameter for patient-specific treatments, particularly in the context of proper drug dosage. Contactless weight estimation from visual sensor data constitutes a promising approach to overcome challenges arising in emergency situations. Machine learning-based methods have recently been shown to perform accurate weight estimation from point cloud data. The proposed methods, however, are designed for controlled conditions in terms of visibility and position of the patient, which limits their practical applicability. In this work, we aim to decouple accurate weight estimation from such specific conditions by predicting the weight of covered patients from voxelized point cloud data. We propose a novel deep learning framework, which comprises two 3D CNN modules solving the given task in two separate steps. First, we train a 3D U-Net to virtually uncover the patient, i.e. to predict the patient's volumetric surface without a cover. Second, the patient's weight is predicted from this 3D volume by means of a 3D CNN architecture, which we optimized for weight regression. We evaluate our approach on a lying pose dataset (SLP) under two different cover conditions. The proposed framework considerably improves on the baseline model by up to [Formula: see text] and reduces the gap between the accuracy of weight estimates for covered and uncovered patients by up to [Formula: see text]. We present a novel pipeline to estimate the weight of patients, which are covered by a blanket. Our approach relaxes the specific conditions that were required for accurate weight estimates by previous contactless methods and thus constitutes an important step towards fully automatic weight estimation in clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21300,""
"Machine learning with neuroimaging data to identify autism spectrum disorder: a systematic review and meta-analysis","Song, Topriceanu, Ilie-Ablachim, Kinali, Bisdas","https://doi.org/10.1007/s00234-021-02774-z","20210822","PubMed","Autism spectrum disorder; Machine learning; Neuroimaging; Systematic review and meta-analysis","AutismÃ‚Â Spectrum Disorder (ASD) is diagnosed through observation or interview assessments, which is time-consuming, subjective, and with questionable validity and reliability. Thus, we aimed to evaluate the role of machine learning (ML) with neuroimaging data to provide a reliable classification of ASD. A systematic search of PubMed, Scopus, and Embase was conducted to identify relevant publications. Quality Assessment of Diagnostic Accuracy Studies-2Ã‚Â (QUADAS-2) was used to assess the studies' quality. A bivariate random-effects model meta-analysis was employed to evaluate the pooled sensitivity,Ã‚Â the pooled specificity, and the diagnostic performance through the hierarchical summary receiver operating characteristic (HSROC) curveÃ‚Â of ML with neuroimaging data inÃ‚Â classifying ASD. Meta-regression was also performed. Forty-four studies (5697 ASD and 6013 typically developing individuals [TD] in total) were included in the quantitative analysis. The pooled sensitivity for differentiating ASD from TD individuals was 86.25 95% confidence interval [CI] (81.24, 90.08), while the pooled specificity was 83.31 95% CI (78.12, 87.48) with a combined area under the HSROC (AUC) of 0.889. Higgins I<sup>2</sup> (&gt;Ã¢â‚¬â€°90%) and Cochran's Q (pÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.0001) suggest a high degree of heterogeneity. In the bivariate model meta-regression, a higher pooled specificity was observed in studies not using a brain atlas (90.91 95% CI [80.67, 96.00], pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.032). In addition, a greater pooled sensitivity was seen in studies recruiting both males and females (89.04 95% CI [83.84, 92.72], pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.021), and combining imaging modalities (94.12 95% [85.43, 97.76], pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.036). ML with neuroimaging data is an exciting prospect in detecting individuals with ASD but further studiesÃ‚Â areÃ‚Â requiredÃ‚Â to improveÃ‚Â its reliability for usage in clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21301,""
"Comparative efficacy and cognitive function of magnetic seizure therapy vs electroconvulsive therapy for major depressive disorder: a systematic review and meta-analysis","Chen, Yang, Liu, Li, Wang, Yang, Hu, Li, Zhao, Li, Xu, Liu","https://doi.org/10.1038/s41398-021-01560-y","20211011","PubMed","Cognition; Depressive Disorder, Major; Electroconvulsive Therapy; Humans; Memory; Seizures","Magnetic seizure therapy (MST) has established efficacy in the treatment of depression and a growing evidence base in the treatment of depression. We conducted the first systematic review and meta-analysis of the efficacy of MST in anti-depressive treatment and its impact on cognitive function (INPLASY registration number: INPLASY202170061). We searched for controlled trials published in English between 1 January 2001 to 31 December 2020 in PubMed, EMBASE, Cochrane Library, Web of Science, and PsycINFO databases. The evaluation process strictly followed the Cochrane bias risk assessment tool into the literature, and Meta-analysis was performed according to the Cochrane System Reviewer's Manual. Data from a total of 285 patients from 10 studies were retained in the quantitative synthesis. The results showed no significant difference between MST and ECT in the antidepressant effect (SDM -0.13 [-0.78;0.52]). Compared with ECT, MST showed shorter recovery time (MD -5.67 [-9.75; -1.60]) and reorientation time (MD -14.67 [-27.96; -1.41]); and MST showed less cognitive impairment on the immediate recall of words (SDM 0.80 [0.35;1.25]), delayed recall of words (SDM 0.99 [0.01;0.74]), visual-spatial immediate memory (SDM 0.51 [0.20;0.83]), visual-spatial delayed memory (SDM 0.57 [0.11;1.02]), and the verbal fluency (SDM 0.51 [0.20;0.83]). Our evidence-based study is the first meta-analysis on the efficacy of MST in anti-depressive treatment and its effect on cognitive function. It showed that the curative effect of MST in anti-depressive treatment is equivalent to that of ECT. Besides, depressive patients with MST benefit more from cognitive function compared with ECT.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21302,""
"A systematic review of machine learning and automation in burn wound evaluation: A promising but developing frontier","Huang, Dang, Sheckter, Yenikomshian, Gillenwater","https://doi.org/10.1016/j.burns.2021.07.007","20210822","PubMed","Burn; Deep learning; Machine learning; Surgery","Visual evaluation is the most common method of evaluating burn wounds. Its subjective nature can lead to inaccurate diagnoses and inappropriate burn center referrals. Machine learning may provide an objective solution. The objective of this study is to summarize the literature on ML in burn wound evaluation. A systematic review of articles published between January 2000 and January 2021 was performed using PubMed and MEDLINE (OVID). Articles reporting on ML or automation to evaluate burn wounds were included. Keywords included burns, machine/deep learning, artificial intelligence, burn classification technology, and mobile applications. Data were extracted on study design, method of data acquisition, machine learning techniques, and machine learning accuracy. Thirty articles were included. Nine studies used machine learning and automation to estimate percent total body surface area (%TBSA) burned, 4 calculated fluid estimations, 19 estimated burn depth, 5 estimated need for surgery, and 2 evaluated scarring. Models calculating %TBSA burned demonstrated accuracies comparable to or better than paper methods. Burn depth classification models achieved accuracies of &gt;83%. Machine learning provides an objective adjunct that may improve diagnostic accuracy in evaluating burn wound severity. Existing models remain in the early stages with future studies needed to assess their clinical feasibility.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21303,""
"Automation as an equal team player for humans? - A view into the field and implications for research and practice","Rieth, Hagemann","https://doi.org/10.1016/j.apergo.2021.103552","20211026","PubMed","Autonomous agent; Human-automation interaction; Human-autonomy teaming","The practical reality and feasibility of Human-Autonomy Teaming (HAT) are analyzed from an experts' point of view, considering current possibilities of various fields. We aim to find out whether the topics discussed scientifically are also practically relevant, to identify requirements for successful HAT, and to derive further research needs. Intensive guideline-based interviews with 28 experts from different industries are conducted and compared to the results of our literature review. The topics discussed scientifically are also practically relevant. Today's technology is far from being able to meet the practical requirements for successful HAT, as postulated in the literature. Contrary to the Human-Automation Interaction, the concept of HAT is hardly applied in the field. Identified key aspects for successful HAT are converted into a model. Future research needs with practical impact exist especially in the area of heterarchy, system knowledge, anticipation of mental states, and consideration of human needs and emotions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21304,""
"Systematic review and meta-analysis of all randomized controlled trials comparing gynecologic laparoscopic procedures with and without robotic assistance","Marchand, Taher Masoud, Ware, Govindan, King, Ruther, Brazil, Calteux, Coriell, Ulibarri, Parise, Arroyo, Filippelli, Loli, Sainz","https://doi.org/10.1016/j.ejogrb.2021.07.038","20211005","PubMed","Laparoscopic surgery; Meta-analysis; Robot-assisted laparoscopic hysterectomy; Robotic assisted laparoscopic surgery; Robotic assisted surgery; Robotic laparoscopic surgery; Robotic surgery; Female; Humans; Laparoscopy; Length of Stay; Randomized Controlled Trials as Topic; Robotic Surgical Procedures","Following the publication of several high quality randomized controlled trials regarding the comparison of similar laparoscopic gynecologic procedures being performed with or without robotic assistance, we aimed to perform a systematic review to identify any differences in patient safety and expected incidence of complications in these procedures. Articles on ClinicalTrials.Gov, Embase, MEDLINE, PubMed, Scopus, and Web of Science databases were retrieved and screened for eligibility up to April 1st 2021. In addition to meeting our screening algorithm, we included studies that met all the following: randomized control trials (RCT), enrolling patients for indicated laparoscopic gynecologic procedures, and comparing Robotic Surgery (RS) with Laparoscopic Surgery (LS) in terms of safety or complications. Data was pooled as mean difference (MD) or risk ratio (RR) with a 95% confidence interval (CI). Ultimately, six studies were included in this meta-analysis. Pooled data revealed that RS and LS have similar risk for intraoperative complications (RRÃ‚Â =Ã‚Â 0.87; 95% CI [0.23, 3.36], PÃ‚Â =Ã‚Â 0.84), postoperative complications (RRÃ‚Â =Ã‚Â 1.07; 95% CI [0.57, 2.01], PÃ‚Â =Ã‚Â 0.83), significant intraoperative hemorrhage (RRÃ‚Â =Ã‚Â 1.40; 95% CI [0.59, 3.34], PÃ‚Â =Ã‚Â 0.44), postoperative hemorrhage (RRÃ‚Â =Ã‚Â 0.43; 95% CI [0.15, 1.22], PÃ‚Â =Ã‚Â 0.11), vaginal cuff dehiscence (RRÃ‚Â =Ã‚Â 1.13; 95% CI [0.24, 5.41], PÃ‚Â =Ã‚Â 0.88), postoperative wound infection, urinary tract infection, and urinary bladder or ureteral injury. RS had ""surgeon declared"" lower estimated blood loss (MDÃ‚Â =Ã‚Â 85.27; 95% CI [46.45, 124.09], PÃ‚Â &lt;Ã‚Â 0.00001) and shorter postoperative hospital stay (MDÃ‚Â =Ã‚Â 1.20; 95% CI [0.38, 2.01], PÃ‚Â =Ã‚Â 0.004). There was a statistically significant decrease in hospital stay and ""surgeon declared"" blood loss seen in the RS group. There was no statistically significant increase in risk of developing other postoperative complications between the LS and R groups.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21305,""
"Expected Costs of Primary Dental Treatments and Endoscopic Sinus Surgery for Odontogenic Sinusitis","Craig, Tataryn, Sibley, Mason, Deuel, Loyd, Nerenz, Goyal","https://doi.org/10.1002/lary.29825","20210826","PubMed","Odontogenic sinusitis; cost analysis; dental extraction; dental implant; endoscopic sinus surgery; root canal therapy","Treatment of odontogenic sinusitis (ODS) due to apical periodontitis (AP) is highly successful when both dental treatment and endoscopic sinus surgery (ESS) are performed. Variation exists in the literature with regard to types and timing of dental treatments and ESS when managing ODS. This study modeled expected costs of different primary dental and sinus surgical treatment pathways for ODS due to AP. Decision-tree economic model. Decision-tree models were created based on cost and treatment success probabilities. Using Medicare and consumer online databases, cost data were obtained for the following dental and sinus surgical treatments across the United States: root canal therapy (RCTx), revision RCTx, apicoectomy, extraction, dental implant, bone graft, and ESS (maxillary, Ã‚Â± anterior ethmoid, Ã‚Â± frontal). A literature review was performed to determine probabilities of dental and sinus disease resolution after different dental treatments. Expected costs were determined for primary dental extraction, RCTx, and ESS pathways, and sensitivity analyses were performed. Expected costs for the three different primary treatment pathways when dental care was in-network and all diseased sinuses opened during ESS were as follows: dental extraction ($4,753.83), RCTx ($4,677.34), and ESS ($7,319.85). ODS due to AP can be successfully treated with primary dental treatments, but ESS is still frequently required. Expected costs of primary dental extraction and RCTx were roughly equal. Primary ESS had a higher expected cost, but may still be preferred in patients with prominent sinonasal symptoms. Patients' insurance coverage may also impact decision-making. N/A Laryngoscope, 2021.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21306,""
"Efficacy of medicinal plant extracts as dental and periodontal antibiofilm agents: A systematic review of randomized clinical trials","Furquim Dos Santos Cardoso, Amaral Roppa, Antunes, Silva Moraes, Santi, Konrath","https://doi.org/10.1016/j.jep.2021.114541","20211001","PubMed","Antibiofilm agents; Essential oils; Periodontitis; Plant extracts; Polyphenols","The presence of biofilm in oral cavity is associated with dental plaque and related diseases, including gingivitis, periodontitis and inflammatory responses. Some medicinal plants traditionally used for biofilm-associated pathologies such as Camellia sinensis (L.) Kuntze, Punica granatum L. and Lippia sidoides Cham. are currently incorporated into dosage forms as antiplaque agents. To present the current application of medicinal plant extracts associated in drug dosages to control microbial biofilms, with emphasis on those present in the oral cavity, especially to treat dental plaque. A PRISMA-compliant systematic search was conducted using the PubMed, Web of Science and Scopus databases. After the abstract and full-text analysis, the Cochrane Collaboration's tools for clinical studies was applied to assess the methodological quality of randomized clinical trials. Of 964 potentially eligible studies, 47 studies met the inclusion criteria and were included in the systematic review. Camellia sinensis was the most commonly used species (8 studies), with positive results in reducing both the PI and GI in the form of mouthwash, toothpaste and gel. The Melaleuca alternifolia oil (5 studies) demonstrated low reduction in PI but important effects on GI scores. Azadirachta indica (4 studies) extracts presented efficacy similar to CHX to improve the periodontal parameters, including PI and GI. Ricinus communis oil (3 studies), despite reducing microbiological counts and GI, did not prove to be better than the hypochlorite solution, used as an alternative treatment for dentures. The main bioactive compounds described for the plant species are polyphenols, essential oils and alkaloids, most of them with identified antibiofilm activities. These active species could lead to future development of safer and newer treatments for oral biofilm-associated infections. However, more studies are needed to further understand the clinical relevance of their application.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21307,""
"Text-based multi-dimensional medical images retrieval according to the features-usage correlation","Safaei","https://doi.org/10.1007/s11517-021-02392-0","20210920","PubMed","Association pattern discovery; Features-usage correlation; Indexing; Information retrieval; Medical images; Query expansion; Text-based retrieval; Vertical fragmentation; Algorithms; Data Mining; Diagnostic Imaging","Emerging medical imaging applications in healthcare, the number and volume of medical images is growing dramatically. Information needs of users in such circumstances, either for clinical or research activities, make the role of powerful medical image search engines more significant. In this paper, a text-based multi-dimensional medical image indexing technique is proposed in which correlation of the features-usages (according to the user's queries) is considered to provide an off-the content indexing while taking users' interestingness into account. Assuming that each medical image has some extracted features (e.g., based on the DICOM standard), correlations of the features are discovered by performing data mining techniques (i.e., quantitative association pattern discovery), on the history of users' queries as a data set. Then, based on the pairwise correlation of the features of medical images (a.k.a. Affinity), set of the all features is fragmented into subsets (using method like the vertical fragmentation of the tables in distribution of relational DBs). After that, each of these subsets of the features turn into a hierarchy of the features (by applying a hierarchical clustering algorithm on that subset), subsequently all of these distinct hierarchies together make a multi-dimensional structure of the features of medical images, which is in fact the proposed text-based (feature-based) multi-dimensional index structure. Constructing and using such text-based multi-dimensional index structure via its specific required operations, medical image retrieval process would be improved in the underlying medical image search engine. Generally, an indexing technique is to provide a logical representation of documents in order to optimize the retrieval process. The proposed indexing technique is designed such that can improve retrieval of medical images in a medical image search engine in terms of its effectiveness and efficiency. Considering correlation of the features of the image would semantically improve precision (effectiveness) of the retrieval process, while traversing them through the hierarchy in one dimension would try to optimize (i.e., minimize) the resources to have a better efficiency. The proposed text-based multi-dimensional indexing technique is implemented using the open source search engine Lucene, and compared with the built-in indexing technique available in the Lucene search engine, and also with the Terrier platform (available for the benchmarking of information retrieval systems) and other the most related indexing techniques. Evaluation results of memory usage and time complexity analysis, beside the experimental evaluations efficiency and effectiveness measures show that the proposed multi-dimensional indexing technique significantly improves both efficiency and effectiveness for a medical image search engine.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21308,""
"Natural Language Processing Enabling COVID-19 Predictive Analytics to Support Data-Driven Patient Advising and Pooled Testing","Meystre, Heider, Kim, Davis, Obeid, Madory, Alekseyenko","https://doi.org/10.1093/jamia/ocab186","20210820","PubMed","Data Science [L01.305]; Machine Learning [G17.035.250.500]; Medical Informatics [L01.313.500]; Natural Language Processing (NLP) [L01.224.050.375.580]","The COVID-19 pandemic response at MUSC included virtual care visits for patients with suspected SARS-CoV-2 infection. The telehealth system used for these visits only exports a text note to integrate with the EHR, but structured and coded information about COVID-19 (e.g., exposure, risk factors, symptoms) was needed to support clinical care and early research as well as predictive analytics for data-driven patient advising and pooled testing. To capture COVID-19 information from multiple sources, a new data mart and a new Natural Language Processing (NLP) application prototype were developed. The NLP application combined reused components with dictionaries and rules crafted by domain experts. It was deployed as a web service for hourly processing of new data from patients assessed or treated for COVID-19. The extracted information was then used to develop algorithms predicting SARS-CoV-2 diagnostic test results based on symptoms and exposure information. The dedicated data mart and NLP application were developed and deployed in a mere 10-day sprint in March 2020. The NLP application was evaluated with good accuracy (85.8% recall and 81.5% precision). The SARS-CoV-2 testing predictive analytics algorithms were configured to provide patients with data-driven COVID-19 testing advices with a sensitivity of 81-92% and to enable pooled testing with a negative predictive value of 90-91% reducing the required tests to about 63%. SARS-CoV-2 testing predictive analytics and NLP successfully enabled data-driven patient advising and pooled testing.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21309,""
"Comparison of clinical efficacy of robotic right colectomy and laparoscopic right colectomy for right colon tumor: A systematic review and meta-analysis","Zhu, Xu, Pan","https://doi.org/10.1097/MD.0000000000027002","20210901","PubMed","Colectomy; Humans; Laparoscopy; Length of Stay; Robotic Surgical Procedures; Treatment Outcome","The purpose of this study was to compare the clinical efficacy of robotic right colectomy (RRC) and laparoscopic right colectomy (LRC) in the treatment of right colon tumor. We systematically searched PubMed, Web of science, EMBASE ClinicalTrials.gov and Cochrane Central Register for studies (studies published between January 2011 and June 2020). The included studies compared the clinical efficacy of RRC and LRC in the treatment of right colon tumor, and analyzed the perioperative data. Our meta-analysis included 10 studies involving 1180 patients who underwent 2 surgical procedures, RRC and LRC. This study showed that compared with LRC, there was no significant difference in first flatus passage (weighted mean difference [WMD]: -0.37, 95% CI: -1.09-0.36, PÃ¢â‚¬Å =Ã¢â‚¬Å .32), hospital length of stay (WMD: -0.23, 95% CI: -0.73-0.28, PÃ¢â‚¬Å =Ã¢â‚¬Å .32), reoperation (OR: 1.66, 95% CI: 0.67-4.10, PÃ¢â‚¬Å =Ã¢â‚¬Å .27), complication (OR: 0.83, 95% CI: 0.60-1.14, PÃ¢â‚¬Å =Ã¢â‚¬Å .25), mortality (OR: 0.45, 95% CI: 0.02-11.22, PÃ¢â‚¬Å =Ã¢â‚¬Å .63), wound infection (OR: 0.65, 95% CI: 0.34-1.25, PÃ¢â‚¬Å =Ã¢â‚¬Å .20), and anastomotic leak (OR: 0.73, 95% CI: 0.33-1.63, PÃ¢â‚¬Å =Ã¢â‚¬Å .44). This study showed that compared with LRC, the lymph nodes retrieved (WMD: 1.47, 95% CI: -0.00-2.94, PÃ¢â‚¬Å =Ã¢â‚¬Å .05) of RRC were similar, with slight advantages, and resulted in longer operative time (WMD: 65.20, 95% CI: 53.40-77.01, PÃ¢â‚¬Å &lt;Ã¢â‚¬Å .00001), less estimated blood loss (WMD: -13.43, 95% CI: -20.65-6.21, PÃ¢â‚¬Å =Ã¢â‚¬Å .0003), and less conversion to open surgery (OR: 0.30, 95% CI: 0.17-0.54, PÃ¢â‚¬Å &lt;Ã¢â‚¬Å .0001). RRC is equivalent to LRC with respect to first flatus passage, hospital length of stay, reoperation, complication, and results in less conversion to LRC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21310,""
"Long non-coding RNA as a potential biomarker for prognosis of glioma: A protocol for systematic review and meta-analysis","Xie, Li, Liu, Zhang, Wang, Chen, Yan","https://doi.org/10.1097/MD.0000000000026921","20210902","PubMed","Biomarkers, Tumor; Glioma; Humans; Meta-Analysis as Topic; Prognosis; RNA, Long Noncoding; Research Design; Systematic Reviews as Topic","The molecular mechanism of Glioma is still unclear, and there are few early diagnostic markers. Therefore, it is urgent to figure out effective preventive measures, active diagnostic methods and rapid treatment measures. In recent years, relevant studies have revealed that long non-coding RNA (lncRNA) is associated with the prognosis of Glioma. However, these results have not been supported by any evidence. Therefore, this study carried out a meta-analysis method to analyze the relationship between lncRNA and the prognosis of Glioma. In addition, bioinformatics analysis was conducted to investigate the mechanism and related pathways of lncRNAs in Glioma. We performed a systematic search in electronic databases, including China National Knowledge Infrastructure, Chinese Biomedical literature Database, Chinese Scientific and Journal Database, Wan Fang database, PubMed, EMBASE, Cochrane Library and Web of Science, to investigate the potential association between lncRNA expression and prognostic significance and clinical features in glioma patients. Hazards ratios (HRs) with corresponding 95% confidence intervals (CIs) were pooled to estimate the prognosis value of lncRNA by Stata16.0 software. The online tool AnnoLnc was applied to screen the co-expressed gene related to each lncRNA, David was used for gene ontology (GO) analysis and enrichment analysis of the signal pathway, and through Starbase, the possible competitive endogenous RNA network of lncRNAs was constructed. The results of this meta-analysis would be submitted to peer-reviewed journals for publication. This study will provide evidence-based medical evidence for lncRNA, so as to predict the prognosis of Glioma and bioinformatics analysis will provide ideas for the mechanism study on Glioma.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21311,""
"Neural mapping of prepulse-induced startle reflex modulation as indices of sensory information processing in healthy and clinical populations: A systematic review","Naysmith, Kumari, Williams","https://doi.org/10.1002/hbm.25631","20211023","PubMed","functional magnetic resonance imaging; prepulse facilitation; prepulse inhibition; sensory information processing; startle reflex","Startle reflex is modulated when a weaker sensory stimulus (""prepulse"") precedes a startling stimulus (""pulse""). Prepulse Inhibition (PPI) is the attenuation of the startle reflex (prepulse precedes pulse by 30-500Ã¢â‚¬â€°ms), whereas Prepulse Facilitation (PPF) is the enhancement of the startle reflex (prepulse precedes pulse by 500-6000Ã¢â‚¬â€°ms). Here, we critically appraise human studies using functional neuroimaging to establish brain regions associated with PPI and PPF. Of 10 studies, nine studies revealed thalamic, striatal and frontal lobe activation during PPI in healthy groups, and activation deficits in the cortico-striato-pallido-thalamic circuitry in schizophrenia (three studies) and Tourette Syndrome (two studies). One study revealed a shared network for PPI and PPF in frontal regions and cerebellum, with PPF networks recruiting superior medial gyrus and cingulate cortex. The main gaps in the literature are (i) limited PPF research and whether PPI and PPF operate on separate/shared networks, (ii) no data on sex differences in neural underpinnings of PPI and PPF, and (iii) no data on neural underpinnings of PPI and PPF in other clinical disorders.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21312,""
"Transformer-Based Named Entity Recognition for Parsing Clinical Trial Eligibility Criteria","Tian, Erdengasileng, Yang, Guo, Wu, Zhang, Bian, He","https://doi.org/10.1145/3459930.3469560","20210821","PubMed","Clinical Trial; Computing methodologies Ã¢â€ â€™ Information extraction; Eligibility Criteria Parsing; Named Entity Recognition; Transformer-Based Model","The rapid adoption of electronic health records (EHRs) systems has made clinical data available in electronic format for research and for many downstream applications. Electronic screening of potentially eligible patients using these clinical databases for clinical trials is a critical need to improve trial recruitment efficiency. Nevertheless, manually translating free-text eligibility criteria into database queries is labor intensive and inefficient. To facilitate automated screening, free-text eligibility criteria must be structured and coded into a computable format using controlled vocabularies. Named entity recognition (NER) is thus an important first step. In this study, we evaluate 4 state-of-the-art transformer-based NER models on two publicly available annotated corpora of eligibility criteria released by Columbia University (i.e., the Chia data) and Facebook Research (i.e.the FRD data). Four transformer-based models (i.e., BERT, ALBERT, RoBERTa, and ELECTRA) pretrained with general English domain corpora vs. those pretrained with PubMed citations, clinical notes from the MIMIC-III dataset and eligibility criteria extracted from all the clinical trials on ClinicalTrials.gov were compared. Experimental results show that RoBERTa pretrained with MIMIC-III clinical notes and eligibility criteria yielded the highest strict and relaxed F-scores in both the Chia data (i.e., 0.658/0.798) and the FRD data (i.e., 0.785/0.916). With promising NER results, further investigations on building a reliable natural language processing (NLP)-assisted pipeline for automated electronic screening are needed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21313,""
"Specialists, Scientists, and Sentiments: Word2Vec and Doc2Vec in Analysis of Scientific and Medical Texts","Chen, Sokolova","https://doi.org/10.1007/s42979-021-00807-1","20210821","PubMed","Clinical discharge summaries; Doc2Vec; Reuters science data; Unsupervised sentiment analysis; Word2Vec","Analyze performance of unsupervised embedding algorithms in sentiment analysis of knowledge-rich data sets. We apply state-of-the-art embedding algorithms Word2Vec and Doc2Vec as the learning techniques. The algorithms build word and document embeddings in an unsupervised manner. To assess the algorithms' performance, we define sentiment metrics and use a semantic lexicon SentiWordNet (SWN) to establish the benchmark measures. Our empirical results are obtained on the Obesity data set from i2b2 clinical discharge summaries and the Reuters Science dataset. We use the Welch's test to analyze the obtained sentiment evaluation. On the Obesity data, the Welch's test found significant difference between the SWN evaluation of the most positive and most negative texts. On the same data, the Word2Vec results support the SWN results, whereas the Doc2Vec results partially correspond to the Word2Vec and the SWN results. On the Reuters data, the Welch's test did not find significant difference between the SWN evaluation of the most positive and most negative texts. On the same data, Word2Vec and Doc2Vec results only in part correspond to the SWN results. In unsupervised sentiment analysis of medical and scientific texts, the Word2Vec sentiment analysis has been more consistent with the SentiWordNet sentiment assessment than the Doc2Vec sentiment analysis. The Welch's test of the SentiWordNet results has been a strong indicator of future correspondence between Word2Vec and SentiWordNet results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21314,""
"Leveraging data science to enhance suicide prevention research: a literature review","Wulz, Law, Wang, Wolkin","https://doi.org/10.1136/injuryprev-2021-044322","20210820","PubMed","media; public health; suicide/self-harm","The purpose of this research is to identify how data science is applied in suicide prevention literature, describe the current landscape of this literature and highlight areas where data science may be useful for future injury prevention research. We conducted a literature review of injury prevention and data science in April 2020 and January 2021 in three databases. For the included 99 articles, we extracted the following: (1) author(s) and year; (2) title; (3) study approach (4) reason for applying data science method; (5) data science method type; (6) study description; (7) data source and (8) focus on a disproportionately affected population. Results showed the literature on data science and suicide more than doubled from 2019 to 2020, with articles with individual-level approaches more prevalent than population-level approaches. Most population-level articles applied data science methods to describe (n=10) outcomes, while most individual-level articles identified risk factors (n=27). Machine learning was the most common data science method applied in the studies (n=48). A wide array of data sources was used for suicide research, with most articles (n=45) using social media and web-based behaviour data. Eleven studies demonstrated the value of applying data science to suicide prevention literature for disproportionately affected groups. Data science techniques proved to be effective tools in describing suicidal thoughts or behaviour, identifying individual risk factors and predicting outcomes. Future research should focus on identifying how data science can be applied in other injury-related topics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21315,""
"Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials","Mayer, Marro, Cabrio, Villata","https://doi.org/10.1016/j.artmed.2021.102098","20210908","PubMed","Argument mining; Biomedical natural language processing; Clinical decision support systems; Information extraction; PICO analysis; Randomized controlled trials; Algorithms; Databases, Factual; Electronic Health Records; Evidence-Based Medicine; Language; Natural Language Processing","In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities. Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records. In this paper, we go beyond the state of the art by proposing a new end-to-end pipeline to address argumentative outcome analysis on clinical trials. More precisely, our pipeline is composed of (i) an Argument Mining module to extract and classify argumentative components (i.e., evidence and claims of the trial) and their relations (i.e., support, attack), and (ii) an outcome analysis module to identify and classify the effects (i.e., improved, increased, decreased, no difference, no occurrence) of an intervention on the outcome of the trial, based on PICO elements. We annotated a dataset composed of more than 500 abstracts of Randomized Controlled Trials (RCT) from the MEDLINE database, leading to a labeled dataset with 4198 argument components, 2601 argument relations, and 3351 outcomes on five different diseases (i.e., neoplasm, glaucoma, hepatitis, diabetes, hypertension). We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1-score of.80 for outcome classification.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21316,""
"Data-based algorithms and models using diabetics real data for blood glucose and hypoglycaemia prediction - A systematic literature review","Felizardo, Garcia, Pombo, Megdiche","https://doi.org/10.1016/j.artmed.2021.102120","20210908","PubMed","Blood glucose level; Data-based algorithms or models; Diabetics real data; Hypoglycaemia or hypoglycemia; Prediction; Algorithms; Blood Glucose; Databases, Factual; Diabetes Mellitus; Humans; Hypoglycemia","Hypoglycaemia prediction play an important role in diabetes management being able to reduce the number of dangerous situations. Thus, it is relevant to present a systematic review on the currently available prediction algorithms and models for hypoglycaemia (or hypoglycemia in US English) prediction. This study aims to systematically review the literature on data-based algorithms and models using diabetics real data for hypoglycaemia prediction. Five electronic databases were screened for studies published from January 2014 to June 2020: ScienceDirect, IEEE Xplore, ACM Digital Library, SCOPUS, and PubMed. Sixty-three eligible studies were retrieved that met the inclusion criteria. The review identifies the current trend in this topic: most of the studies perform short-term predictions (82.5%). Also, the review pinpoints the inputs and shows that information fusion is relevant for hypoglycaemia prediction. Regarding data-based models (80.9%) and hybrid models (19.1%) different predictive techniques are used: Artificial neural network (22.2%), ensemble learning (27.0%), supervised learning (20.6%), statistic/probabilistic (7.9%), autoregressive (7.9%), evolutionary (6.4%), deep learning (4.8%) and adaptative filter (3.2%). Artificial Neural networks and hybrid models show better results. The data-based models for blood glucose and hypoglycaemia prediction should be able to provide a good balance between the applicability and performance, integrating complementary data from different sources or from different models. This review identifies trends and possible opportunities for research in this topic.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21317,""
"Med7: A transferable clinical natural language processing model for electronic health records","Kormilitzin, Vaci, Liu, Nevado-Holgado","https://doi.org/10.1016/j.artmed.2021.102086","20210908","PubMed","Active learning; Clinical natural language processing; Neural networks; Noisy labelling; Self-supervised learning; Electronic Health Records; Humans; Information Storage and Retrieval; Intensive Care Units; Natural Language Processing","Electronic health record systems are ubiquitous and the majority of patients' data are now being collected electronically in the form of free text. Deep learning has significantly advanced the field of natural language processing and the self-supervised representation learning and the transfer learning have become the methods of choice in particular when the high quality annotated data are limited. Identification of medical concepts and information extraction is a challenging task, yet important ingredient for parsing unstructured data into structured and tabulated format for downstream analytical tasks. In this work we introduced a named-entity recognition (NER) model for clinical natural language processing. The model is trained to recognise seven categories: drug names, route of administration, frequency, dosage, strength, form, duration. The model was first pre-trained on the task of predicting the next word, using a collection of 2 million free-text patients' records from MIMIC-III corpora followed by fine-tuning on the named-entity recognition task. The model achieved a micro-averaged F1 score of 0.957 across all seven categories. Additionally, we evaluated the transferability of the developed model using the data from the Intensive Care Unit in the US to secondary care mental health records (CRIS) in the UK. A direct application of the trained NER model to CRIS data resulted in reduced performance of F1Ã¢â‚¬Â¯=Ã¢â‚¬Â¯0.762, however after fine-tuning on a small sample from CRIS, the model achieved a reasonable performance of F1Ã¢â‚¬Â¯=Ã¢â‚¬Â¯0.944. This demonstrated that despite a close similarity between the data sets and the NER tasks, it is essential to fine-tune the target domain data in order to achieve more accurate results. The resulting model and the pre-trained embeddings are available at https://github.com/kormilitzin/med7.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21318,""
"The ethics of machine learning-based clinical decision support: an analysis through the lens of professionalisation theory","Heyen, Salloch","https://doi.org/10.1186/s12910-021-00679-3","20210927","PubMed","Algorithms; Artificial intelligence; Clinical decision support systems; Ethics; Machine learning; Patient autonomy; Physicians; PhysicianÃ¢â‚¬â€œpatient relationship; Profession; Professionalisation; Decision Support Systems, Clinical; Ethics, Medical; Female; Humans; Machine Learning; Physician-Patient Relations; Physicians","Machine learning-based clinical decision support systems (ML_CDSS) are increasingly employed in various sectors of health care aiming at supporting clinicians' practice by matching the characteristics of individual patients with a computerised clinical knowledge base. Some studies even indicate that ML_CDSS may surpass physicians' competencies regarding specific isolated tasks. From an ethical perspective, however, the usage of ML_CDSS in medical practice touches on a range of fundamental normative issues. This article aims to add to the ethical discussion by using professionalisation theory as an analytical lens for investigating how medical action at the micro level and the physician-patient relationship might be affected by the employment of ML_CDSS. Professionalisation theory, as a distinct sociological framework, provides an elaborated account of what constitutes client-related professional action, such as medical action, at its core and why it is more than pure expertise-based action. Professionalisation theory is introduced by presenting five general structural features of professionalised medical practice: (i) the patient has a concern; (ii) the physician deals with the patient's concern; (iii) s/he gives assistance without patronising; (iv) s/he regards the patient in a holistic manner without building up a private relationship; and (v) s/he applies her/his general expertise to the particularities of the individual case. Each of these five key aspects are then analysed regarding the usage of ML_CDSS, thereby integrating the perspectives of professionalisation theory and medical ethics. Using ML_CDSS in medical practice requires the physician to pay special attention to those facts of the individual case that cannot be comprehensively considered by ML_CDSS, for example, the patient's personality, life situation or cultural background. Moreover, the more routinized the use of ML_CDSS becomes in clinical practice, the more that physicians need to focus on the patient's concern and strengthen patient autonomy, for instance, by adequately integrating digital decision support in shared decision-making.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21319,""
"What can artificial intelligence and machine learning tell us? A review of applications to equine biomechanical research","Mouloodi, Rahmanpanah, Gohari, Burvill, Tse, Davies","https://doi.org/10.1016/j.jmbbm.2021.104728","20210929","PubMed","Artificial intelligence (AI); Artificial neural network (ANN); Bone mechanics; Horse biomechanics; Latest trend; Machine learning (ML); Algorithms; Animals; Artificial Intelligence; Horses; Machine Learning; Neural Networks, Computer","Artificial intelligence (AI) and machine learning (ML) are fascinating interdisciplinary scientific domains where machines are provided with an approximation of human intelligence. The conjecture is that machines are able to learn from existing examples, and employ this accumulated knowledge to fulfil challenging tasks such as regression analysis, pattern classification, and prediction. The horse biomechanical models have been identified as an alternative tool to investigate the effects of mechanical loading and induced deformations on the tissues and structures in humans. Many reported investigations into bone fatigue, subchondral bone damage in the joints of both humans and animals, and identification of vital parameters responsible for retaining integrity of anatomical regions during normal activities in all species are heavily reliant on equine biomechanical research. Horse racing is a lucrative industry and injury prevention in expensive thoroughbreds has encouraged the implementation of various measurement techniques, which results in massive data generation. ML substantially accelerates analysis and interpretation of data and provides considerable advantages over traditional statistical tools historically adopted in biomechanical research. This paper provides the reader with: a brief introduction to AI, taxonomy and several types of ML algorithms, working principle of a feedforward artificial neural network (ANN), and, a detailed review of the applications of AI, ML, and ANN in equine biomechanical research (i.e. locomotory system function, gait analysis, joint and bone mechanics, and hoof function). Reviewing literature on the use of these data-driven tools is essential since their wider application has the potential to: improve clinical assessments enabling real-time simulations, avoid and/or minimize injuries, and encourage early detection of such injuries in the first place.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21320,""
"The Relationship Between Muscle Strength and Body Composition Measures and Cancer-Related Fatigue: A Systematic Review and Meta-Analysis","Li, Chou, Shun","https://doi.org/10.1188/21.ONF.558-576","20211015","PubMed","body composition; cancer-related fatigue; meta-analysis; muscle strength; Body Composition; Fatigue; Hand Strength; Humans; Muscle Strength; Neoplasms; Quality of Life","Cancer-related fatigue (CRF) substantially affects daily living and quality of life, but objective CRF measures remain limited. This review aimed to identify the correlation between muscle strength and body composition measures and CRF, as well as potential objective indicators for assessing CRF. PubMedÃ‚Â®, MEDLINEÃ‚Â®, CINAHLÃ‚Â®/PsycINFOÃ‚Â®, and EmbaseÃ‚Â® were searched for studies published from January 2000 to January 2021. Study selection and quality assessment were conducted using the Critical Appraisals Skills Programme checklist and the Strengthening the Reporting of Observational Studies in Epidemiology statement. Comprehensive Meta-Analysis software was used to perform meta-analysis. 25 studies were selected, and 19 measures were analyzed. CRF negatively correlated with hand grip strength, knee extensor strength, and the sit-to-stand test. No significant correlation was found between body composition measures and CRF. The evidence suggests that muscle strength measures may be potential indicators for CRF assessment. Combining objective and subjective CRF assessments could assist clinicians in evaluating the effectiveness of CRF interventions more accurately.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21321,""
"Robotic-Assisted Versus Laparoscopic Revisional Bariatric Surgery: a Systematic Review and Meta-analysis on Perioperative Outcomes","Bertoni, Marengo, Garofalo, VolontÃƒÂ¨, La Regina, Gass, Mongelli","https://doi.org/10.1007/s11695-021-05668-4","20211025","PubMed","Bariatric surgery; Laparoscopic surgery; Morbid obesity; Revisional surgery; Robotic surgery; Bariatric Surgery; Humans; Laparoscopy; Obesity, Morbid; Postoperative Complications; Retrospective Studies; Robotic Surgical Procedures; Treatment Outcome","This systematic review and meta-analysis investigated the role of robotic-assisted surgery in patients undergoing revisional bariatric surgery (RBS). According to Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, a literature search of PubMed, Cochrane Library, Web of Science, and Google Scholar was performed: ((""sleeve""AND ""gastr*"")OR ""bariatric""OR ""gastric bypass"")AND(""robot*""OR ""DaVinci""OR ""Da Vinci"")AND(""revision*""OR ""conversion*""). In this review, six studies with 29,890 patients were included (2459 in the robotic group). No difference in postoperative complications (RR 1.070, 95%CI 0.930-1.231, pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.950), conversions to open surgery (RR 1.339, 95%CI 0.736-2.438, pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.339), length of stay (SMDÃ¢â‚¬â€°-Ã¢â‚¬â€°0.041, 95%CIÃ¢â‚¬â€°-Ã¢â‚¬â€°0.420-0.337, pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.831) or operative time (RR 0.219, 95%CIÃ¢â‚¬â€°-Ã¢â‚¬â€°0.539-0.977, pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.571) was found. This systematic review and meta-analysis showed no significant advantage of robotic-assisted RBS; on the other hand, it showed a non-inferior efficacy compared to standard laparoscopy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21322,""
"The impact of <i>catha edulis (vahl) forssk ex endl</i> (celestraceae) (khat) on pharmacokinetics of clinically used drugs","Aklillu, Engidawork","https://doi.org/10.1080/17425255.2021.1971194","20210913","PubMed","Catha edulis; Cytochrome P450 enzymes; Drug interaction; Khat alkaloids; Pharmacogenetics; Pharmacokinetics; Catha; Central Nervous System Stimulants; Genotype; Herb-Drug Interactions; Humans; Pharmacogenetics; Pharmacokinetics; Plant Extracts","Catha edulis (Vahl) Forssk. ex Endl. (Celestraceae) is used as a recreational drug on daily basis for its euphoric and psychostimulant effects. It is also chewed by individuals who are on medications, raising the possibility of drug-khat interaction. However, limited data are available in the literature, although clinically significant interactions are expected, as khat contains a complex mixture of pharmacologically active constituents. It provides an overview of the phytochemistry, pharmacokinetics, pharmacodynamics, and pharmacogenetics of khat based on the literature mined from PubMed, Google Scholar, and Cochrane databases. It also presents a detailed account of drug-khat interactions with specific examples and their clinical significance. The interactions mainly occur at the pharmacokinetics level and particular attention is paid for the phases of absorption and cytochrome P450 enzyme-mediated metabolism. Despite the increasing trend of khat chewing with medications among the populace and the potential risk for the occurrence of clinically significant interactions, there is paucity of data in the literature demonstrating the magnitude of the risk. The available data, however, clearly demonstrate that the consequence of drug-khat interaction is dependent on genotype. Genotyping, where feasible, could be used to improve clinical outcome and minimize adverse reactions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21323,""
"Global view on virus infection in non-human primates and implications for public health and wildlife conservation","Liu, Qian, Hong, Zhang, Li, Wang, Yang, Zhang, Wang, Nie, Fan, Zhang, Chen, Sha, Roos, Li","https://doi.org/10.24272/j.issn.2095-8137.2021.080","20210902","PubMed","Emerging infectious diseases; Inter-species transmission; NHP; One Health; Pandemic; Virus; Zoonosis; Animals; Animals, Wild; Conservation of Natural Resources; Global Health; Primates; Public Health; Virus Diseases; Viruses","Viruses can be transmitted from animals to humans (and vice versa) and across animal species. As such, host-virus interactions and transmission have attracted considerable attention. Non-human primates (NHPs), our closest evolutionary relatives, are susceptible to human viruses and certain pathogens are known to circulate between humans and NHPs. Here, we generated global statistics on VI-NHPs based on a literature search and public data mining. In total, 140 NHP species from 12 families are reported to be infected by 186 DNA and RNA virus species, 68.8% of which are also found in humans, indicating high potential for crossing species boundaries. The top 10 NHP species with high centrality in the NHP-virus network include two great apes (<i>Pan troglodytes</i>, <i>Pongo pygmaeus</i>) and eight Old World monkeys (<i>Macaca mulatta</i>, <i>M. fascicularis</i>, <i>M. leonina</i>, <i>Papio cynocephalus</i>, <i>Cercopithecus ascanius</i>, <i>C. erythrotis</i>, <i>Chlorocebus aethiops</i>, and <i>Allochrocebus lhoesti</i>). Given the wide distribution of Old World monkeys and their frequent contact with humans, there is a high risk of virus circulation between humans and such species. Thus, we suggest recurring epidemiological surveillance of NHPs, specifically Old World monkeys that are in frequent contact with humans, and other effective measures to prevent potential circulation and transmission of viruses. Avoidance of false positives and sampling bias should also be a focus in future work. Ã§â€”â€¦Ã¦Â¯â€™Ã¥ÂÂ¯Ã¤Â»Â¥Ã¤Â»Å½Ã¥Å Â¨Ã§â€°Â©Ã¤Â¼Â Ã¦Å¸â€œÃ§Â»â„¢Ã¤ÂºÂºÃ§Â±Â»Ã¯Â¼Å’Ã¥ÂÂÃ¤Â¹â€¹Ã¤ÂºÂ¦Ã§â€žÂ¶Ã¯Â¼â€ºÃ¥ÂÅ’Ã¦â€”Â¶Ã¤Â¹Å¸Ã¥ÂÂ¯Ã¤Â»Â¥Ã¥Å“Â¨Ã¥Å Â¨Ã§â€°Â©Ã¤Â¹â€¹Ã©â€”Â´Ã¤Â¼Â Ã¦â€™Â­Ã£â‚¬â€šÃ¨Â¿â„¢Ã¥Â¼â€¢Ã¨ÂµÂ·Ã¤Âºâ€ Ã¥â€¦Â¬Ã¤Â¼â€”Ã¥Â¯Â¹Ã¥Â®Â¿Ã¤Â¸Â»Ã¤Â¸Å½Ã§â€”â€¦Ã¦Â¯â€™Ã§Å¡â€žÃ§â€ºÂ¸Ã¤Âºâ€™Ã¤Â½Å“Ã§â€Â¨Ã¥â€™Å’Ã§â€”â€¦Ã¦Â¯â€™Ã¤Â¼Â Ã¦â€™Â­Ã¦â€“Â¹Ã¥Â¼ÂÃ§Å¡â€žÃ¥â€¦Â³Ã¦Â³Â¨Ã£â‚¬â€šÃ©ÂÅ¾Ã¤ÂºÂºÃ§ÂÂµÃ©â€¢Â¿Ã§Â±Â»Ã¥Å Â¨Ã§â€°Â©Ã¤Â½Å“Ã¤Â¸ÂºÃ¤ÂºÂºÃ§Â±Â»Ã§Å¡â€žÃ¦Â¼â€Ã¥Å’â€“Ã¨Â¿â€˜Ã¤ÂºÂ²Ã¯Â¼Å’Ã¦Ëœâ€œÃ¥Ââ€”Ã¤ÂºÂºÃ§Â±Â»Ã§â€”â€¦Ã¦Â¯â€™Ã§Å¡â€žÃ¥Â½Â±Ã¥â€œÂÃ¯Â¼Å’Ã¨â‚¬Å’Ã¤Â¸â€Ã¥Â·Â²Ã§Å¸Â¥Ã¦Å“â€°Ã¥Â¤Å¡Ã§Â§ÂÃ§â€”â€¦Ã¥Å½Å¸Ã¤Â½â€œÃ¥Å“Â¨Ã¤ÂºÂºÃ§Â±Â»Ã¥â€™Å’Ã©ÂÅ¾Ã¤ÂºÂºÃ§ÂÂµÃ©â€¢Â¿Ã§Â±Â»Ã¤Â¹â€¹Ã©â€”Â´Ã¤Â¼Â Ã¦â€™Â­Ã£â‚¬â€šÃ¦Ë†â€˜Ã¤Â»Â¬Ã¥Å¸ÂºÃ¤ÂºÅ½Ã¦â€“â€¡Ã§Å’Â®Ã¦ÂÅ“Ã§Â´Â¢Ã¥â€™Å’Ã¥â€¦Â¬Ã¥â€¦Â±Ã¦â€¢Â°Ã¦ÂÂ®Ã¦Å’â€“Ã¦Å½ËœÃ¯Â¼Å’Ã¥Â¯Â¹Ã¥â€¦Â¨Ã§ÂÆ’Ã¨Å’Æ’Ã¥â€ºÂ´Ã¥Â·Â²Ã¦Å Â¥Ã©Ââ€œÃ§Å¡â€žÃ©ÂÅ¾Ã¤ÂºÂºÃ§ÂÂµÃ©â€¢Â¿Ã§Â±Â»Ã¥Å Â¨Ã§â€°Â©Ã§Å¡â€žÃ§â€”â€¦Ã¦Â¯â€™Ã¦â€žÅ¸Ã¦Å¸â€œÃ¦Æ’â€¦Ã¥â€ ÂµÃ¨Â¿â€ºÃ¨Â¡Å’Ã¤Âºâ€ Ã§Â»Å¸Ã¨Â®Â¡Ã¥Ë†â€ Ã¦Å¾ÂÃ£â‚¬â€šÃ¦â€¢Â°Ã¦ÂÂ®Ã¦ËœÂ¾Ã§Â¤ÂºÃ¯Â¼Å’12Ã¤Â¸ÂªÃ§Â§â€˜Ã§Å¡â€ž140Ã§Â§ÂÃ©ÂÅ¾Ã¤ÂºÂºÃ§ÂÂµÃ©â€¢Â¿Ã§Â±Â»Ã§â€°Â©Ã§Â§ÂÃ¨Â¢Â«186Ã§Â§ÂDNAÃ¥â€™Å’RNAÃ§â€”â€¦Ã¦Â¯â€™Ã¦â€žÅ¸Ã¦Å¸â€œÃ¯Â¼Å’Ã¥â€¦Â¶Ã¤Â¸Â­68.8%Ã§Å¡â€žÃ§â€”â€¦Ã¦Â¯â€™Ã¤Â¹Å¸Ã¥Å“Â¨Ã¤ÂºÂºÃ§Â±Â»Ã¤Â¸Â­Ã¥Ââ€˜Ã§Å½Â°Ã¯Â¼Å’Ã¨Â¿â„¢Ã¨Â¡Â¨Ã¦ËœÅ½Ã§â€”â€¦Ã¦Â¯â€™Ã¨Â·Â¨Ã¨Â¶Å Ã§â€°Â©Ã§Â§ÂÃ¨Â¾Â¹Ã§â€¢Å’Ã¤Â¼Â Ã¦â€™Â­Ã§Å¡â€žÃ¦Â½Å“Ã¥Å“Â¨Ã©Â£Å½Ã©â„¢Â©Ã¥Â¾Ë†Ã¥Â¤Â§Ã£â‚¬â€šÃ©ÂÅ¾Ã¤ÂºÂºÃ§ÂÂµÃ©â€¢Â¿Ã§Â±Â»Ã¥â€™Å’Ã§â€”â€¦Ã¦Â¯â€™Ã§â€ºÂ¸Ã¤Âºâ€™Ã¤Â½Å“Ã§â€Â¨Ã§Å¡â€žÃ§Â½â€˜Ã§Â»Å“Ã¥Ë†â€ Ã¦Å¾ÂÃ¨Â¡Â¨Ã¦ËœÅ½Ã¯Â¼Å’2Ã§Â§ÂÃ§Â±Â»Ã¤ÂºÂºÃ§Å’Â¿Ã¯Â¼Ë†<i>Pan troglodytes</i>Ã¥â€™Å’<i>Pongo pygmaeus</i>Ã¯Â¼â€°Ã¥â€™Å’8Ã§Â§ÂÃ¦â€”Â§Ã¥Â¤Â§Ã©â„¢â€ Ã§Å’Â´Ã¯Â¼Ë†<i>Macaca mulatta</i>, <i>M. fascicularis</i>, <i>M. leonina</i>, <i>Papio cynocephalus</i>, <i>Ceropithecus ascanius</i>, <i>C. erythrotis</i>, <i>Chlorocebus aethiops</i>, <i>Allochrocebus lhoesti</i>Ã¯Â¼â€°Ã¤Â½ÂÃ¤ÂºÅ½Ã§Â½â€˜Ã§Â»Å“Ã§Å¡â€žÃ¤Â¸Â­Ã¥Â¿Æ’Ã¯Â¼Å’Ã¦ËœÂ¯Ã§â€”â€¦Ã¦Â¯â€™Ã¨Â·Â¨Ã§â€°Â©Ã§Â§ÂÃ¤Â¼Â Ã¦â€™Â­Ã§Å¡â€žÃ©Â«ËœÃ©Â£Å½Ã©â„¢Â©Ã¨Å â€šÃ§â€šÂ¹Ã£â‚¬â€šÃ©â„¢Â¤Ã¤Âºâ€ Ã§Â±Â»Ã¤ÂºÂºÃ§Å’Â¿Ã¤Â¹â€¹Ã¥Â¤â€“Ã¯Â¼Å’Ã¨Â®Â¸Ã¥Â¤Å¡Ã¦â€”Â§Ã¥Â¤Â§Ã©â„¢â€ Ã§Å’Â´Ã¥Ë†â€ Ã¥Â¸Æ’Ã¥Â¹Â¿Ã¦Â³â€ºÃ¯Â¼Å’Ã¥Â¹Â¶Ã¤Â¸â€Ã¤Â¸Å½Ã¤ÂºÂºÃ§Â±Â»Ã¦Å“â€°Ã§Ââ‚¬Ã©Â¢â€˜Ã§Â¹ÂÃ§Å¡â€žÃ¦Å½Â¥Ã¨Â§Â¦Ã¯Â¼Å’Ã¥â€ºÂ Ã¦Â­Â¤Ã¤ÂºÂºÃ§Â±Â»Ã¥â€™Å’Ã¦â€”Â§Ã¥Â¤Â§Ã©â„¢â€ Ã§Å’Â´Ã¤Â¹â€¹Ã©â€”Â´Ã¥Ââ€˜Ã§â€Å¸Ã§â€”â€¦Ã¦Â¯â€™Ã¤Â¼Â Ã¦â€™Â­Ã§Å¡â€žÃ©Â£Å½Ã©â„¢Â©Ã¤Â¹Å¸Ã¥Â¾Ë†Ã©Â«ËœÃ£â‚¬â€šÃ¦Ë†â€˜Ã¤Â»Â¬Ã¥Â»ÂºÃ¨Â®Â®Ã¥Å“Â¨Ã©ÂÅ¾Ã¤ÂºÂºÃ§ÂÂµÃ©â€¢Â¿Ã§Â±Â»Ã¤Â¸Â­Ã¯Â¼Å’Ã§â€°Â¹Ã¥Ë†Â«Ã¦ËœÂ¯Ã¥Å“Â¨Ã§Â»ÂÃ¥Â¸Â¸Ã¤Â¸Å½Ã¤ÂºÂºÃ§Â±Â»Ã¦Å½Â¥Ã¨Â§Â¦Ã§Å¡â€žÃ¦â€”Â§Ã¥Â¤Â§Ã©â„¢â€ Ã§Å’Â´Ã¤Â¸Â­Ã¥Â¼â‚¬Ã¥Â±â€¢Ã¦ÂµÂÃ¨Â¡Å’Ã§â€”â€¦Ã¥Â­Â¦Ã§â€ºâ€˜Ã¦Âµâ€¹Ã¯Â¼Å’Ã¤Â»Â¥Ã¥ÂÅ Ã©â€¡â€¡Ã¥Ââ€“Ã¥â€¦Â¶Ã¥Â®Æ’Ã¦Å“â€°Ã¦â€¢Ë†Ã¦Å½ÂªÃ¦â€“Â½Ã¦ÂÂ¥Ã©ËœÂ²Ã¦Â­Â¢Ã¦Â½Å“Ã¥Å“Â¨Ã§Å¡â€žÃ§â€”â€¦Ã¦Â¯â€™Ã¤Â¼Â Ã¦â€™Â­Ã£â‚¬â€šÃ¥ÂÅ’Ã¦â€”Â¶Ã¤Â¹Å¸Ã¥Â»ÂºÃ¨Â®Â®Ã¥Å“Â¨Ã¦Å“ÂªÃ¦ÂÂ¥Ã§Å¡â€žÃ§Â â€Ã§Â©Â¶Ã¥Â·Â¥Ã¤Â½Å“Ã¤Â¸Â­Ã©â€¡â€¡Ã§â€Â¨Ã§â€”â€¦Ã¦Â¯â€™Ã§Â»â€žÃ¥Â­Â¦Ã¥â€™Å’Ã¥Â¤Â§Ã¦â€¢Â°Ã¦ÂÂ®Ã¥Ë†â€ Ã¦Å¾ÂÃ§Å¡â€žÃ¦â€“Â¹Ã¦Â³â€¢Ã¯Â¼Å’Ã¤Â»Â¥Ã¥â€¡ÂÃ¥Â°â€˜Ã¥Å“Â¨Ã¦Â­Â¤Ã§Â±Â»Ã§Â â€Ã§Â©Â¶Ã¤Â¸Â­Ã¥Ââ€¡Ã©ËœÂ³Ã¦â‚¬Â§Ã§Â»â€œÃ¦Å¾Å“Ã¥â€™Å’Ã¦Å Â½Ã¦Â Â·Ã¥ÂÂÃ¥Â·Â®Ã§Å¡â€žÃ¤ÂºÂ§Ã§â€Å¸Ã£â‚¬â€š.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21324,""
"Development of a validated search filter for Ovid Embase for degenerative cervical myelopathy","Khan, Mowforth, Kuhn, Kotter, Davies","https://doi.org/10.1111/hir.12373","20210826","PubMed","embase; medline; data mining; indexing; information retrieval; literature searching; review and systematic search; review systematic; search strategies","Degenerative cervical myelopathy (DCM) is a recently proposed umbrella term for symptomatic cervical spinal cord compression secondary to degeneration of the spine. Currently literature searching for DCM is challenged by the inconsistent uptake of the term 'DCM' with many overlapping keywords and numerous synonyms. Here, we adapt our previous Ovid medline search filter for the Ovid embase database, to support comprehensive literature searching. Both embase and medline are recommended as a minimum for systematic reviews. References contained within embase identified in our prior study formed a 'development gold standard' reference database (NÃ‚Â =Ã‚Â 220). The search filter was adapted for embase and checked against the reference database. The filter was then validated against the 'validation gold standard'. A direct translation was not possible, as medline indexing for DCM and the keywords search field were not available in embase. We also used the 'focus' function to improve precision. The resulting search filter has 100% sensitivity in testing. We have developed a validated search filter capable of retrieving DCM references in embase with high sensitivity. In the absence of consistent terminology and indexing, this will support more efficient and robust evidence synthesis in the field.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21325,""
"Effects of low-level light therapy on xerostomia related to hyposalivation: a systematic review and meta-analysis of clinical trials","GoleÃ…Â¾, FrangeÃ…Â¾, Cankar, FrangeÃ…Â¾, Ovsenik, Nemeth","https://doi.org/10.1007/s10103-021-03392-0","20210819","PubMed","Low-level light therapy; Photobiomodulation; Saliva; Salivary glands; Salivation; Xerostomia","Hyposalivation is a condition represented by a reduced salivary flow and may include symptoms such as mouth dryness (xerostomia), loss of taste, pain, dysphagia, and dysphonia, all of which greatly affect an individual's quality of life.The aim of the present study was to systematically review the effects of low-level light therapy irradiation (photobiomodulation) on salivary gland function in patients with hyposalivation.The main question of the systematic review was: ""Does low-level light irradiation therapy of the salivary glands affect salivary flow rate or indicators of salivary function (ion and protein concentrations) in patients with xerostomia or hyposalivation?"" The question was based on the PICO (participant, intervention, control, outcome) principle and followed the PRISMA guidelines. Databases were explored and papers published between the years 1997 and 2020 were reviewed for the following Mesh-term keywords and their corresponding entry terms in different combinations: ""Low-level light therapy,"" ""Xerostomia,"" ""Saliva,"" ""Salivary glands,"" ""Salivation.""The initial sample consisted of 220 articles. Of those, 47 articles were used for full-text analysis and 18 were used for a systematic review, 14 were used in meta-analysis. According to their individual quality, most articles were classified as high quality of evidence according to the GRADE score. Meta-analysis of the evidence observed increase of unstimulated salivary flow 0.51 SMD compared to placebo (95% CI: 0.16-0.86), I<sup>2</sup>Ã¢â‚¬â€°=Ã¢â‚¬â€°50%, pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.005.The findings of our review revealed evidence of a beneficial effect of photobiomodulation therapy on salivary gland function. The therapy alleviates xerostomia and hyposalivation. However, these effects are reported short term only and did not induce lasting effects of photobiomodulation therapy on patients' quality of life.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21326,""
"DICE: A Drug Indication Classification and Encyclopedia for AI-Based Indication Extraction","Bhatt, Roberts, Chen, Li, Connor, Hatim, Mikailov, Tong, Liu","https://doi.org/10.3389/frai.2021.711467","20210820","PubMed","artificial intelligence; deep learning; drug indication; natural language processing; transformers","Drug labeling contains an 'INDICATIONS AND USAGE' that provides vital information to support clinical decision making and regulatory management. Effective extraction of drug indication information from free-text based resources could facilitate drug repositioning projects and help collect real-world evidence in support of secondary use of approved medicines. To enable AI-powered language models for the extraction of drug indication information, we used manual reading and curation to develop a <b>D</b>rug <b>I</b>ndication <b>C</b>lassification and <b>E</b>ncyclopedia (DICE) based on FDA approved human prescription drug labeling. A DICE scheme with 7,231 sentences categorized into five classes (indications, contradictions, side effects, usage instructions, and clinical observations) was developed. To further elucidate the utility of the DICE, we developed nine different AI-based classifiers for the prediction of indications based on the developed DICE to comprehensively assess their performance. We found that the transformer-based language models yielded an average MCC of 0.887, outperforming the word embedding-based Bidirectional long short-term memory (BiLSTM) models (0.862) with a 2.82% improvement on the test set. The best classifiers were also used to extract drug indication information in DrugBank and achieved a high enrichment rate (&gt;0.930) for this task. We found that domain-specific training could provide more explainable models without performance sacrifices and better generalization for external validation datasets. Altogether, the proposed DICE could be a standard resource for the development and evaluation of task-specific AI-powered, natural language processing (NLP) models.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21327,""
"Data extraction methods for systematic review (semi)automation: A living systematic review","Schmidt, Olorisade, McGuinness, Thomas, Higgins","https://doi.org/10.12688/f1000research.51117.1","20210913","PubMed","Data Extraction; Natural Language Processing; Reproducibility; Systematic Reviews; Text Mining; Automation; Databases, Bibliographic; MEDLINE; Publications; Research Report; Systematic Reviews as Topic","<b>Background:</b> The reliable and usable (semi)automation of data extraction can support the field of systematic review by reducing the workload required to gather information about the conduct and results of the included studies. This living systematic review examines published approaches for data extraction from reports of clinical studies. <b>Methods:</b> We systematically and continually search MEDLINE, Institute of Electrical and Electronics Engineers (IEEE), arXiv, and the <i>dblp computer science bibliography</i> databases. Full text screening and data extraction are conducted within an open-source living systematic review application created for the purpose of this review. This iteration of the living review includes publications up to a cut-off date of 22 April 2020. <b>Results:</b> In total, 53 publications are included in this version of our review. Of these, 41 (77%) of the publications addressed extraction of data from abstracts, while 14 (26%) used full texts. A total of 48 (90%) publications developed and evaluated classifiers that used randomised controlled trials as the main target texts. Over 30 entities were extracted, with PICOs (population, intervention, comparator, outcome) being the most frequently extracted. A description of their datasets was provided by 49 publications (94%), but only seven (13%) made the data publicly available. Code was made available by 10 (19%) publications, and five (9%) implemented publicly available tools. <b>Conclusions:</b> This living systematic review presents an overview of (semi)automated data-extraction literature of interest to different types of systematic review. We identified a broad evidence base of publications describing data extraction for interventional reviews and a small number of publications extracting epidemiological or diagnostic accuracy data. The lack of publicly available gold-standard data for evaluation, and lack of application thereof, makes it difficult to draw conclusions on which is the best-performing system for each data extraction target. With this living review we aim to review the literature continually.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21328,""
"Maternal Parenting Stress in the Face of Early Regulatory Disorders in Infancy: A Machine Learning Approach to Identify What Matters Most","Georg, SchrÃƒÂ¶der-Pfeifer, Cierpka, Taubner","https://doi.org/10.3389/fpsyt.2021.663285","20210820","PubMed","early regulatory disorders; infant mental health diagnostic; machine learning algorithms; parental self-efficacy; parenting stress","<b>Objective:</b> Early regulatory disorders (ERD) in infancy are typically associated with high parenting stress (PS). Theoretical and empirical literature suggests a wide range of factors that may contribute to PS related to ERD. The aim of this study was to identify key predictors of maternal PS within a large predictor data set in a sample of <i>N</i> = 135 mothers of infants diagnosed with ERD. <b>Methods:</b> We used machine learning to identify relevant predictors. Maternal PS was assessed with the Parenting Stress Index. The multivariate dataset assessed cross-sectionally consisted of 464 self-reported and clinically rated variables covering mother-reported psychological distress, maternal self-efficacy, parental reflective functioning, socio-demographics, each parent's history of illness, recent significant life events, former miscarriage/abortion, pregnancy, obstetric history, infants' medical history, development, and social environment. Variables were drawn from behavioral diaries on regulatory symptoms and parental co-regulative behavior as well as a clinical interview which was utilized to diagnose ERD and to assess clinically rated regulatory symptoms, quality of parent-infant relationship, organic/biological and psychosocial risks, and social-emotional functioning. <b>Results:</b> The final prediction model identified 11 important variables summing up to the areas maternal self-efficacy, psychological distress (particularly depression and anger-hostility), infant regulatory symptoms (particularly duration of fussing/crying), and age-appropriate physical development. The RMSE (i.e., prediction accuracy) of the final model applied to the test set was 21.72 (<i>R</i> <sup>2</sup> = 0.58). <b>Conclusions:</b> This study suggests that among behavioral, environmental, developmental, parent-infant relationship, and mental health variables, a mother's higher self-efficacy, psychological distress symptoms particularly depression and anger symptoms, symptoms in the child particularly fussing/crying symptoms, and age-inappropriate physical development are associated with higher maternal PS. With these factors identified, clinicians may more efficiently assess a mother's PS related to ERD in a low-risk help-seeking sample.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21329,""
"Identifying non-traditional electronic datasets for population-level surveillance and prevention of cardiometabolic diseases: a scoping review protocol","Rebinsky, Anderson, Morgenstern","https://doi.org/10.1136/bmjopen-2021-053485","20210827","PubMed","general diabetes; hypertension; information technology; ischaemic heart disease; lipid disorders; public health; Cardiovascular Diseases; Delivery of Health Care; Electronics; Humans; Peer Review; Research Design; Review Literature as Topic; Systematic Reviews as Topic","Cardiometabolic diseases, including cardiovascular disease, obesity and diabetes, are leading causes of death and disability worldwide. Modern advances in population-level disease surveillance are necessary and may inform novel opportunities for precision public health approaches to disease prevention. Electronic data sources, such as social media and consumer rewards points systems, have expanded dramatically in recent decades. These non-traditional datasets may enhance traditional clinical and public health datasets and inform cardiometabolic disease surveillance and population health interventions. However, the scope of non-traditional electronic datasets and their use for cardiometabolic disease surveillance and population health interventions has not been previously reviewed. The primary objective of this review is to describe the scope of non-traditional electronic datasets, and how they are being used for cardiometabolic disease surveillance and to inform interventions. The secondary objective is to describe the methods, such as machine learning and natural language processing, that have been applied to leverage these datasets. We will conduct a scoping review following recommended methodology. Search terms will be based on the three central concepts of non-traditional electronic datasets, cardiometabolic diseases and population health. We will search EMBASE, MEDLINE, CINAHL, Scopus, Web of Science and Cochrane Library peer-reviewed databases and will also conduct a grey literature search. Articles published from 2000 to present will be independently screened by two reviewers for inclusion at abstract and full-text stages, and conflicts will be resolved by a separate reviewer. We will report this data as per the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews. No ethics approval is required for this protocol and scoping review, as data will be used only from published studies with appropriate ethics approval. Results will be disseminated in a peer-reviewed publication.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21330,""
"Performance and Limitation of Machine Learning Algorithms for Diabetic Retinopathy Screening: Meta-analysis","Wu, Liu, Hsu, Ho, Lee","https://doi.org/10.2196/23863","20211025","PubMed","deep learning; diabetes; diabetic retinopathy; diagnostic accuracy; machine learning; neural network; Algorithms; Diabetes Mellitus; Diabetic Retinopathy; Diagnostic Techniques, Ophthalmological; Humans; Machine Learning; Neural Networks, Computer","Diabetic retinopathy (DR), whose standard diagnosis is performed by human experts, has high prevalence and requires a more efficient screening method. Although machine learning (ML)-based automated DR diagnosis has gained attention due to recent approval of IDx-DR, performance of this tool has not been examined systematically, and the best ML technique for use in a real-world setting has not been discussed. The aim of this study was to systematically examine the overall diagnostic accuracy of ML in diagnosing DR of different categories based on color fundus photographs and to determine the state-of-the-art ML approach. Published studies in PubMed and EMBASE were searched from inception to June 2020. Studies were screened for relevant outcomes, publication types, and data sufficiency, and a total of 60 out of 2128 (2.82%) studies were retrieved after study selection. Extraction of data was performed by 2 authors according to PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses), and the quality assessment was performed according to the Quality Assessment of Diagnostic Accuracy Studies 2 (QUADAS-2). Meta-analysis of diagnostic accuracy was pooled using a bivariate random effects model. The main outcomes included diagnostic accuracy, sensitivity, and specificity of ML in diagnosing DR based on color fundus photographs, as well as the performances of different major types of ML algorithms. The primary meta-analysis included 60 color fundus photograph studies (445,175 interpretations). Overall, ML demonstrated high accuracy in diagnosing DR of various categories, with a pooled area under the receiver operating characteristic (AUROC) ranging from 0.97 (95% CI 0.96-0.99) to 0.99 (95% CI 0.98-1.00). The performance of ML in detecting more-than-mild DR was robust (sensitivity 0.95; AUROC 0.97), and by subgroup analyses, we observed that robust performance of ML was not limited to benchmark data sets (sensitivity 0.92; AUROC 0.96) but could be generalized to images collected in clinical practice (sensitivity 0.97; AUROC 0.97). Neural network was the most widely used method, and the subgroup analysis revealed a pooled AUROC of 0.98 (95% CI 0.96-0.99) for studies that used neural networks to diagnose more-than-mild DR. This meta-analysis demonstrated high diagnostic accuracy of ML algorithms in detecting DR on color fundus photographs, suggesting that state-of-the-art, ML-based DR screening algorithms are likely ready for clinical applications. However, a significant portion of the earlier published studies had methodology flaws, such as the lack of external validation and presence of spectrum bias. The results of these studies should be interpreted with caution.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21331,""
"Cost-effectiveness of uterine balloon tamponade devices in managing atonic post-partum hemorrhage at public health facilities in India","Joshi, Shetty, Moray, Sachin, Chaurasia","https://doi.org/10.1371/journal.pone.0256271","20210821","PubMed","","Post-partum hemorrhage (PPH) is the leading direct cause of maternal mortality in India. Uterine balloon tamponade (UBT) is recommended for atonic PPH cases not responding to uterotonics. This study assessed cost-effectiveness of three UBT devices used in Indian public health settings. A decision tree model was built to assess cost-effectiveness of Bakri-UBT and low-cost ESM-UBT alternatives as compared to the recommended standard of care i.e. condom-UBT intervention. A hypothetical annual cohort of women eligible for UBT intervention after experiencing atonic PPH in Indian public health facilities were evaluated for associated costs and outcomes over life-time horizon using a disaggregated societal perspective. Costs by undertaking primary costing and clinical parameters from published literature were used. Incremental cost per Disability Adjusted Life Years (DALY) averted, number of surgeries and maternal deaths with the interventions were estimated. An India specific willingness to pay threshold of INR 24,211 (USD 375) was used to evaluate cost-effectiveness. Detailed sensitivity analysis and expected value of information analysis was undertaken. ESM-UBT at base-case Incremental Cost-Effectiveness Ratio (ICER) of INR -2,412 (USD 37) per DALY averted is a cost-saving intervention i.e. is less expensive and more effective as compared to condom-UBT. Probabilistic sensitivity analysis however shows an error probability of 0.36, indicating a degree of uncertainty around model results. Bakri-UBT at an ICER value of INR -126,219 (USD -1,957) per DALY averted incurs higher incremental societal costs and is less effective as compared to condom-UBT. Hence, Bakri-UBT is not cost-effective. For atonic PPH management in India, condom-UBT offers better value as compared to Bakri-UBT. Given the limited clinical effectiveness evidence and uncertainty in sensitivity analysis, cost-saving result for ESM-UBT must be considered with caution. Future research may focus on generating high quality comparative clinical evidence for UBT devices to facilitate policy decision making.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21332,""
"Predicted Influences of Artificial Intelligence on the Domains of Nursing: Scoping Review","Buchanan, Howitt, Wilson, Booth, Risling, Bamford","https://doi.org/10.2196/23939","20210825","PubMed","artificial intelligence; machine learning; nursing; patient-centered care; review; robotics","Artificial intelligence (AI) is set to transform the health system, yet little research to date has explored its influence on nurses-the largest group of health professionals. Furthermore, there has been little discussion on how AI will influence the experience of person-centered compassionate care for patients, families, and caregivers. This review aims to summarize the extant literature on the emerging trends in health technologies powered by AI and their implications on the following domains of nursing: administration, clinical practice, policy, and research. This review summarizes the findings from 3 research questions, examining how these emerging trends might influence the roles and functions of nurses and compassionate nursing care over the next 10 years and beyond. Using an established scoping review methodology, MEDLINE, CINAHL, EMBASE, PsycINFO, Cochrane Database of Systematic Reviews, Cochrane Central, Education Resources Information Center, Scopus, Web of Science, and ProQuest databases were searched. In addition to the electronic database searches, a targeted website search was performed to access relevant gray literature. Abstracts and full-text studies were independently screened by 2 reviewers using prespecified inclusion and exclusion criteria. Included articles focused on nursing and digital health technologies that incorporate AI. Data were charted using structured forms and narratively summarized. A total of 131 articles were retrieved from the scoping review for the 3 research questions that were the focus of this manuscript (118 from database sources and 13 from targeted websites). Emerging AI technologies discussed in the review included predictive analytics, smart homes, virtual health care assistants, and robots. The results indicated that AI has already begun to influence nursing roles, workflows, and the nurse-patient relationship. In general, robots are not viewed as replacements for nurses. There is a consensus that health technologies powered by AI may have the potential to enhance nursing practice. Consequently, nurses must proactively define how person-centered compassionate care will be preserved in the age of AI. Nurses have a shared responsibility to influence decisions related to the integration of AI into the health system and to ensure that this change is introduced in a way that is ethical and aligns with core nursing values such as compassionate care. Furthermore, nurses must advocate for patient and nursing involvement in all aspects of the design, implementation, and evaluation of these technologies. RR2-10.2196/17490.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21333,""
"Early Cost Effectiveness of Whole-Genome Sequencing as a Clinical Diagnostic Test for Patients with Inoperable Stage IIIB,C/IV Non-squamous Non-small-Cell Lung Cancer","Simons, RetÃƒÂ¨l, Ramaekers, Butter, Mankor, Paats, Aerts, Mfumbilwa, Roepman, CoupÃƒÂ©, Uyl-de Groot, van Harten, Joore","https://doi.org/10.1007/s40273-021-01073-y","20210818","PubMed","","Advanced non-small-cell lung cancer (NSCLC) harbours many genetic aberrations that can be targeted with systemic treatments. Whole-genome sequencing (WGS) can simultaneously detect these (and possibly new) molecular targets. However, the exact added clinical value of WGS is unknown. The objective of this study was to determine the early cost effectiveness of using WGS in diagnostic strategies compared with currently used molecular diagnostics for patients with inoperable stage IIIB,C/IV non-squamous NSCLC from a Dutch healthcare perspective. A decision tree represented the diagnostic pathway, and a cohort state transition model represented disease progression. Three diagnostic strategies were modelled: standard of care (SoC) alone, WGS as a diagnostic test, and SoC followed by WGS. Treatment effectiveness was based on a systematic review. Probabilistic cost-effectiveness analyses were performed, and threshold analyses (using Ã¢â€šÂ¬80,000 per quality-adjusted life-year [QALY]) was used to explore the early cost effectiveness of WGS. WGS as a diagnostic test resulted in more QALYs (0.002) and costs (Ã¢â€šÂ¬1534 [incremental net monetary benefit -Ã¢â€šÂ¬1349]), and SoC followed by WGS resulted in fewer QALYs (-0.002) and more costs (Ã¢â€šÂ¬1059 [-Ã¢â€šÂ¬1194]) compared with SoC alone. WGS as a diagnostic test was only cost effective if it was priced at Ã¢â€šÂ¬2000 per patient and identified 2.7% more actionable patients than SoC alone. Treating these additional identified patients with new treatments costing &gt;Ã¢â€šÂ¬4069 per month decreased the probability of cost effectiveness. Our analysis suggests that providing WGS as a diagnostic test is cost effective compared with SoC followed by WGS and SoC alone if costs for WGS decrease and additional patients with actionable targets are identified. This cost-effectiveness model can be used to incorporate new findings iteratively and to support ongoing decision making regarding the use of WGS in this rapidly evolving field.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21334,""
"The potential use of digital health technologies in the African context: a systematic review of evidence from Ethiopia","Manyazewal, Woldeamanuel, Blumberg, Fekadu, Marconi","https://doi.org/10.1038/s41746-021-00487-4","20210904","PubMed","","The World Health Organization (WHO) recently put forth a Global Strategy on Digital Health 2020-2025 with several countries having already achieved key milestones. We aimed to understand whether and how digital health technologies (DHTs) are absorbed in Africa, tracking Ethiopia as a key node. We conducted a systematic review, searching PubMed-MEDLINE, Embase, ScienceDirect, African Journals Online, Cochrane Central Registry of Controlled Trials, ClinicalTrials.gov, and the WHO International Clinical Trials Registry Platform databases from inception to 02 February 2021 for studies of any design that investigated the potential of DHTs in clinical or public health practices in Ethiopia. This review was registered with PROSPERO ( CRD42021240645 ) and it was designed to inform our ongoing DHT-enabled randomized controlled trial (RCT) (ClinicalTrials.gov ID: NCT04216420 ). We found 27,493 potentially relevant citations, among which 52 studies met the inclusion criteria, comprising a total of 596,128 patients, healthy individuals, and healthcare professionals. The studies involved six DHTs: mHealth (29 studies, 574,649 participants); electronic health records (13 studies, 4534 participants); telemedicine (4 studies, 465 participants); cloud-based application (2 studies, 2382 participants); information communication technology (3 studies, 681 participants), and artificial intelligence (1 study, 13,417 participants). The studies targeted six health conditions: maternal and child health (15), infectious diseases (14), non-communicable diseases (3), dermatitis (1), surgery (4), and general health conditions (15). The outcomes of interest were feasibility, usability, willingness or readiness, effectiveness, quality improvement, and knowledge or attitude toward DHTs. Five studies involved RCTs. The analysis showed that although DHTs are a relatively recent phenomenon in Ethiopia, their potential harnessing clinical and public health practices are highly visible. Their adoption and implementation in full capacity require more training, access to better devices such as smartphones, and infrastructure. DHTs hold much promise tackling major clinical and public health backlogs and strengthening the healthcare ecosystem in Ethiopia. More RCTs are needed on emerging DHTs including artificial intelligence, big data, cloud, cybersecurity, telemedicine, and wearable devices to provide robust evidence of their potential use in such settings and to materialize the WHO's Global Strategy on Digital Health.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21335,""
"Vaccine market access pathways in the EU27 and the United KingdomÃ¢â‚¬Â¯-Ã¢â‚¬Â¯analysis and recommendations for improvements","Laigle, Postma, Pavlovic, Cadeddu, Beck, Kapusniak, Toumi","https://doi.org/10.1016/j.vaccine.2021.07.040","20210923","PubMed","European Union; Market Access; Policy; Vaccine; COVID-19; Ecosystem; Health Policy; Humans; Immunization Programs; Pandemics; SARS-CoV-2; United Kingdom; Vaccines","Vaccine market access (VMA) pathways across the European Union (EU) and the United Kingdom (UK) are complex, lengthy, and heterogeneous, particularly when compared with pharmaceuticals. The knowledge base to inform recommendations for optimization of VMA is lacking. We therefore conducted a comprehensive evaluation of EU VMA pathways. Research in two phases included: (1) mapping VMA pathways in each EU member state (including the UK) based on a literature review, expert interviews, and mathematical archetyping; and (2) interviews with vaccine experts to identify barriers, drivers, and recommendations for regional VMA alignments. Key steps in VMA across the EU include horizon scanning, early advice, National Immunization Technical Advisory Group (NITAG) recommendation for inclusion in national immunization programs, health technology assessment (HTA), final decision and procurement. We found significant complexity and heterogeneity, particularly for early advice, and in the roles, decision-making criteria, and transparency of NITAGs and HTA bodies. The most important drivers for rapid VMA included demonstration of disease burden and vaccine benefit (e.g., efficacy, safety, economic). Key barriers were budget limitations and complexity/clarity of VMA processes (e.g., need for national-regional consensus, clarity on process initiation, and clarity on the role of HTA). Recommendations for alignment at EU and member-state levels include information sharing, joint clinical assessment, initiatives to address funding and political barriers, and improved transparency by decision-making bodies. Early engagement with vaccine stakeholders was a key recommendation for manufacturers. There is significant potential for alignment, collaboration, and improvement of VMA across the EU. Roles, responsibilities, and transparency of key bodies can be clarified. The COVID-19 pandemic response should stimulate policies to improve access to all vaccines, including routine ones, and form the foundation upon which a consistent vaccine ecosystem can be created for the EU, one that is resilient, consistent between member states, and fit for purpose.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21336,""
"Machine Learning Approach for Active Vaccine Safety Monitoring","Kim, Jang, Park, Jeong, Lim, Kim, Choi, Yoon","https://doi.org/10.3346/jkms.2021.36.e198","20210820","PubMed","Adverse Effects; Cross-over Studies; Machine Learning; Postmarketing Product Surveillance; Vaccines","Vaccine safety surveillance is important because it is related to vaccine hesitancy, which affects vaccination rate. To increase confidence in vaccination, the active monitoring of vaccine adverse events is important. For effective active surveillance, we developed and verified a machine learning-based active surveillance system using national claim data. We used two databases, one from the Korea Disease Control and Prevention Agency, which contains flu vaccination records for the elderly, and another from the National Health Insurance Service, which contains the claim data of vaccinated people. We developed a case-crossover design based machine learning model to predict the health outcome of interest events (anaphylaxis and agranulocytosis) using a random forest. Feature importance values were evaluated to determine candidate associations with each outcome. We investigated the relationship of the features to each event via a literature review, comparison with the Side Effect Resource, and using the Local Interpretable Model-agnostic Explanation method. The trained model predicted each health outcome of interest with a high accuracy (approximately 70%). We found literature supporting our results, and most of the important drug-related features were listed in the Side Effect Resource database as inducing the health outcome of interest. For anaphylaxis, flu vaccination ranked high in our feature importance analysis and had a positive association in Local Interpretable Model-Agnostic Explanation analysis. Although the feature importance of vaccination was lower for agranulocytosis, it also had a positive relationship in the Local Interpretable Model-Agnostic Explanation analysis. We developed a machine learning-based active surveillance system for detecting possible factors that can induce adverse events using health claim and vaccination databases. The results of the study demonstrated a potentially useful application of two linked national health record databases. Our model can contribute to the establishment of a system for conducting active surveillance on vaccination.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21337,""
"Creating efficiencies in the extraction of data from randomized trials: a prospective evaluation of a machine learning and text mining tool","Gates, Gates, Sim, Elliott, Pillay, Hartling","https://doi.org/10.1186/s12874-021-01354-2","20210827","PubMed","Clinical trials; Data collection; Efficiency; Machine learning; Systematic reviews; Text mining; Data Mining; Humans; Language; Machine Learning; Randomized Controlled Trials as Topic; Research Design","Machine learning tools that semi-automate data extraction may create efficiencies in systematic review production. We evaluated a machine learning and text mining tool's ability to (a) automatically extract data elements from randomized trials, and (b) save time compared with manual extraction and verification. For 75 randomized trials, we manually extracted and verified data for 21 data elements. We uploaded the randomized trials to an online machine learning and text mining tool, and quantified performance by evaluating its ability to identify the reporting of data elements (reported or not reported), and the relevance of the extracted sentences, fragments, and overall solutions. For each randomized trial, we measured the time to complete manual extraction and verification, and to review and amend the data extracted by the tool. We calculated the median (interquartile range [IQR]) time for manual and semi-automated data extraction, and overall time savings. The tool identified the reporting (reported or not reported) of data elements with median (IQR) 91% (75% to 99%) accuracy. Among the top five sentences for each data element at least one sentence was relevant in a median (IQR) 88% (83% to 99%) of cases. Among a median (IQR) 90% (86% to 97%) of relevant sentences, pertinent fragments had been highlighted by the tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6Ã‚Â h total extraction time across 75 randomized trials). Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool's ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. https://doi.org/10.7939/DVN/RQPJKS.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21338,""
"Effects and dose-response relationship of high-intensity interval training on cardiorespiratory fitness in overweight and obese adults: a systematic review and meta-analysis","Wang, Zhu, Wong, Chen, Siu, Baker, Sun","https://doi.org/10.1080/02640414.2021.1964800","20210817","PubMed","Intermittent training; adult obesity; doseÃ¢â‚¬â€œresponse relationship; physical fitness","This study aims to quantify the effects of high-intensity interval training (HIIT) on cardiorespiratory fitness (CRF) by considering potential moderators and to characterise dose-response relationships of HIIT variables that could maximise CRF improvements in overweight and obese adults. Following a comprehensive search through four electronic databases, 19 studies met eligibility criteria. Random-effects models were applied to weight all included studies and to compute the weighted mean standardised mean differences (SMD<sub>wm</sub>). Meta-analysis showed that HIIT was a highly effective approach for improving CRF in overweight and obese adults (SMD<sub>wm</sub>Ã‚Â =Ã‚Â 1.13). Effects were modified by sex and baseline CRF level. Dose-response relationship analysis provided some preliminary data regarding the training period, training intensity, and session duration. However, it is still not possible to provide accurate recommendations currently. Further studies are still needed to identify the most appropriate training variables to prescribe effective HIIT programmes for improving CRF in overweight and obese adults.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21339,""
"Prognostic scores for survival as decisional support for surgery in spinal metastases: a performance assessment systematic review","Smeijers, Depreitere","https://doi.org/10.1007/s00586-021-06954-6","20211021","PubMed","Machine learning; Performance assessment; Spinal metastasis; Survival prognostic score; Systematic review; Humans; Multicenter Studies as Topic; Nomograms; Prognosis; Prospective Studies; Retrospective Studies; Spinal Neoplasms","To review the evidence on the relative prognostic performance of the available prognostic scores for survival in spinal metastatic surgery in order to provide a recommendation for use in clinical practice. A systematic review of comparative external validation studies assessing the performance of prognostic scores for survival in independent cohorts was performedÃ‚Â according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) 2020 guidelines. Eligible studies were identified through Medline and Embase until May 2021. Studies were included when they compared at least four survival scoring systems in surgical or mixed cohorts across all primary tumor types. Predictive performance was assessed based on discrimination and calibration for 3-month, 1-year and overall survival, and generalizability was assessed based on the characteristics of the development cohort and external validation cohorts. Risk of bias and concern regarding applicability were assessed based on the 'Prediction model study Risk Of Bias Assessment Tool' (PROBAST). Twelve studies fulfilled the inclusion criteria and covered 17 scoring systems across 5.130 patients. Several scores suffer from suboptimal development and validation. The SORG Nomogram, developed in a large surgical cohort, showed good discrimination on 3-month and 1-year survival, good calibration and was superior in direct comparison with low risk of bias and low concern regarding applicability. Machine learning algorithms are promising as they perform equally well in direct comparison. Tokuhashi, Tomita and other traditional risk scores showed suboptimal performance. The SORG Nomogram and machine learning algorithms outline superior performance in survival prediction for surgery in spinal metastases. Further improvement by comparative validation in large multicenter, prospective cohorts can still be obtained. Given the heterogeneity of spinal metastases, superior methodology of development and validation is key in improving future machine learning systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21340,""
"A span-based joint model for extracting entities and relations of bacteria biotopes","Zuo, Zhang","https://doi.org/10.1093/bioinformatics/btab593","20210816","PubMed","","Information about bacteria biotopes is important for fundamental research and applications in microbiology. Bacteria Biotope (BB) task at BioNLP-OST 2019 focuses on the extraction of locations and phenotypes of microorganisms from PubMed abstracts and full-text excerpts. The subtask BB-rel+ner aims to recognize relevant entities and extract interrelationships about bacteria biotopes. The corresponding corpus owns some distinctive features (e.g. nested entities) which are challenging to deal with. Therefore, previous methods achieved low performance on entity and relation extraction and limited the mutual effect between named entity recognition and relation extraction. There is still much room for improvement. We propose a span-based model to extract entities and relations jointly from biomedical text regarding the bacteria biotopes. For alleviating the problem of annotated data deficiency in domain-specific task, we employ a BERT (Bidirectional Encoder Representations from Transformers) model pre-trained on the domain-specific corpus to encode sentences. Our model considers all spans in a sentence as potential entity mentions and computes relation scores between the most confident entity spans based on representations of spans and contexts between spans. Experiments on the BB-rel+ner 2019 corpus demonstrate that our model achieves significantly better performance than the state-of-the-art method, with a reduction of 21.6% slot error rate (SER) for extracting relations. Our model is also effective in recognizing nested entities. Furthermore, the model can be applied to the CHEMPROT corpus for joint extraction of chemical-protein entities and relations, achieving state-of-the-art performance. Our source code is available at https://github.com/zmmzGitHub/SpanMB_BERT. Supplementary data are available at Bioinformatics online.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21341,""
"The potential value of microRNA-145 for predicting prognosis in patients with ovarian cancer: A protocol for systematic review and meta-analysis","Chen, Xiao, Zeng, Yan","https://doi.org/10.1097/MD.0000000000026922","20210823","PubMed","Biomarkers, Tumor; Carcinoma, Ovarian Epithelial; Female; Gene Expression Profiling; Gene Expression Regulation, Neoplastic; Humans; MicroRNAs; Ovarian Neoplasms; Prognosis","As an anticancer gene, microRNA-145 (miRNA-145) inhibits the growth, migration, and invasion of cancer cells, and inhibits tumorigenesis by targeting various genes that are abnormally expressed in tumors. However, whether miRNA-145 can be applied as a biomarker for potential prognosis of ovarian cancer still remains controversial. Therefore, this study further explored the prognostic value and mechanism of miRNA-145 in ovarian cancer through meta-analysis and bioinformatics analysis. Eligible studies were identified by searching the China National Knowledge Infrastructure, Chinese Biomedical literature Database, Chinese Scientific and Journal Database, Wan Fang database, PubMed, EMBASE, and Web of Science up to July 2021. Pooled hazard ratios with 95% confidence intervals for patient survival were calculated to investigate the effects of miRNA-145 on the prognosis of ovarian cancer. Survival curves of differential expression of miRNA-145 were analyzed by Oncomir. The target genes of miRNA-145 were predicted by miRTARbase and Diana-Tarbase V7.0 database. Enrichr database was applied to analyze the target genes by gene ontology and Kyoto Encyclopedia of Genes and Genomes pathways. Protein-protein interaction network of target genes was constructed from STRING database. Cytoscape software was used to screen the hub genes to meet the requirements. The Gene Expression Profiling Interactive Analysis database was applied to analyze the survival outcomes of hub genes. The results of this meta-analysis would be submitted to peer-reviewed journals for publication. This study provides high-quality evidence to support the relationship between miRNA-145 expression and ovarian cancer prognosis. Through bioinformatics analysis, we further explored the mechanism of miRNA-145 in ovarian cancer and related pathways.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21342,""
"Nonpharmacological interventions for cancer-related fatigue in lung cancer patients: A protocol for an evidence map of overview of a network meta-analysis of existing trials","Zhao, Shi, Xiong, Zeng","https://doi.org/10.1097/MD.0000000000026864","20210831","PubMed","Complementary Therapies; Evidence-Based Practice; Fatigue; Humans; Lung Neoplasms; Network Meta-Analysis; Quality of Life; Research Design","Lung cancer is one of the most common cancers, the symptoms and treatment of which can cause negative emotions like anxiety, depression, and cancer-related fatigue (CRF). Nonpharmacological interventions, serving as alternative therapies, can greatly alleviate CRF in lung cancer patients. Previous meta-analyses have reported nonpharmacological interventions of CRF in lung cancer patients, but the results may be conflicting, and the reporting and methodological qualities remain unknown. Moreover, there is limited evidence to identify efficient and safe non-pharmacological interventions of CRF in lung cancer patients. This study aims to assess the therapeutic efficacy of nonpharmacological interventions of CRF in lung cancer patients through a network meta-analysis. Relevant literatures reporting non-pharmacological interventions of CRF in lung cancer patients published before June 2021 will be searched in online databases, including Wanfang, VP Information Chinese Journal Service Platform, China National Knowledge Infrastructure, Chinese BioMedicine Literature Database, PubMed, Embase, Cochrane, and Web of science. Two reviewers will be independently responsible for study selection, quality appraisal, and data extraction. Data analysis will be performed using the STATA14.0 and GEMTC 0.14.3 software. This meta-analysis will provide additional and stronger evidences for nonpharmacological interventions of CRF in lung cancer patients. Our findings will be conductive to make therapeutic decisions by clinicians. This study will provide a reliable evidence-based basis for non-pharmacological interventions of CRF in lung cancer patients. Ethical approval was not required for this study. The systematic review will be published in a peer-reviewed journal, presented at conferences, and shared on social media platforms. This review would be disseminated in a peer-reviewed journal or conference presentations. DOI 10.17605/OSF.IO/QRY42.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21343,""
"Comprehensive analyses of potential key genes in active tuberculosis: A systematic review","Chen, Liu, Liang, Xu, Zhang, Lu, Jiang, Chen, Li, Huang, Chen, Sun, Cen, Zhan","https://doi.org/10.1097/MD.0000000000026582","20210824","PubMed","Computational Biology; Gene Expression Profiling; Humans; Microarray Analysis; Tuberculosis","Tuberculosis (TB) is a global health problem that brings us numerous difficulties. Diverse genetic factors play a significant role in the progress of TB disease. However, still no key genes for TB susceptibility have been reported. This study aimed to identify the key genes of TB through comprehensive bioinformatics analysis. The series microarray datasets from the gene expression omnibus (GEO) database were analyzed. We used the online tool GEO2R to filtrate differentially expressed genes (DEGs) between TB and health control. Database for annotation can complete gene ontology function analysis as well as Kyoto Encyclopedia of Genes and Genomes pathway enrichment analysis. Protein-protein interaction (PPI) networks of DEGs were established by STRING online tool and visualized by Cytoscape software. Molecular Complex Detection can complete the analysis of modules in the PPI networks. Finally, the significant hub genes were confirmed by plug-in Genemania of Cytoscape, and verified by the verification cohort and protein test. There are a total of 143 genes were confirmed as DEGs, containing 48 up-regulated genes and 50 down-regulated genes. The gene ontology and Kyoto Encyclopedia of Genes and Genomes analysis show that upregulated DEGs were associated with cancer and phylogenetic, whereas downregulated DEGs mainly concentrate on inflammatory immunity. PPI networks show that signal transducer and activator of transcription 1 (STAT1), guanylate binding protein 5 (GBP5), 2'-5'-oligoadenylate synthetase 1 (OAS1), catenin beta 1 (CTNNB1), and guanylate binding protein 1 (GBP1) were identified as significantly different hub genes. We conclude that these genes, including TAT1, GBP5, OAS1, CTNNB1, GBP1 are a candidate as potential core genes in TB and treatment of TB in the future.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21344,""
"Applications of artificial intelligence (AI) in researches on non-alcoholic fatty liver disease(NAFLD) : A systematic review","Li, Wang, Zhang, Zhang, Jiao","https://doi.org/10.1007/s11154-021-09681-x","20210816","PubMed","ArtificialÃ‚Â intelligence (AI); MachineÃ‚Â learning (ML); Metabolic associated fatty liver disease (MAFLD); Non-alcoholic fatty liver disease (NAFLD); Non-alcoholic steatohepatitis (NASH)","Non-alcoholic fatty liver disease (NAFLD) is one of the most important causes of chronic liver disease in the world, it has been found that cardiovascular and renal risks and diseases are also highly prevalent in adults with NAFLD. Diagnosis and treatment of NAFLD face many challenges, although the medical science has been very developed. Efficiency, accuracy and individualization are the main goals to be solved. Evaluation of the severity of NAFLD involves a variety of clinical parameters, how to optimize non-invasive evaluation methods is a necessary issue that needs to be discussed in this field. Artificial intelligence (AI) has become increasingly widespread in healthcare applications, and it has been also brought many new insights into better analyzing chronic liver disease, including NAFLD. This paper reviewed AI related researches in NAFLD field published recently, summarized diagnostic models based on electronic health record and lab test, ultrasound and radio imaging, and liver histopathological data, described the application of therapeutic models in personalized lifestyle guidance and the development of drugs for NAFLD. In addition, we also analyzed present AI models in distinguishing healthy VS NAFLD/NASH, and fibrosis VS non-fibrosis in the evaluation of NAFLD progression. We hope to provide alternative directions for the future research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21345,""
"Classification and analysis of asynchronous communication content between care team members involved in breast cancer treatment","Steitz, Sulieman, Warner, Fabbri, Brown, Davis, Unertl","https://doi.org/10.1093/jamiaopen/ooab049","20210817","PubMed","breast cancer; burnout; electronic health records; multidisciplinary communication; workflow","A growing research literature has highlighted the work of managing and triaging clinical messages as a major contributor to professional exhaustion and burnout. The goal of this study was to discover and quantify the distribution of message content sent among care team members treating patients with breast cancer. We analyzed nearly two years of communication data from the electronic health record (EHR) between care team members at Vanderbilt University Medical Center. We applied natural language processing to perform sentence-level annotation into one of five information types: clinical, medical logistics, nonmedical logistics, social, and other. We combined sentence-level annotations for each respective message. We evaluated message content by team member role and clinic activity. Our dataset included 81Ã¢â‚¬â€°857 messages containing 613Ã¢â‚¬â€°877 sentences. Across all roles, 63.4% and 21.8% of messages contained logistical information and clinical information, respectively. Individuals in administrative or clinical staff roles sent 81% of all messages containing logistical information. There were 33.2% of messages sent by physicians containing clinical information-the most of any role. Our results demonstrate that EHR-based asynchronous communication is integral to coordinate care for patients with breast cancer. By understanding the content of messages sent by care team members, we can devise informatics initiatives to improve physicians' clerical burden and reduce unnecessary interruptions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21346,""
"Current Applications of Artificial Intelligence in Cleft Care: A Scoping Review","Dhillon, Chaudhari, Dhingra, Kuo, Sokhi, Alam, Ahmad","https://doi.org/10.3389/fmed.2021.676490","20210817","PubMed","artificial intelligence; cleft lip; cleft palate; craniofacial anomalies; machine learning; neural network","<b>Objective:</b> This scoping review aims to identify the various areas and current status of the application of artificial intelligence (AI) for aiding individuals with cleft lip and/or palate. <b>Introduction:</b> Cleft lip and/or palate contributes significantly toward the global burden on the healthcare system. Artificial intelligence is a technology that can help individuals with cleft lip and/or palate, especially those in areas with limited access to receive adequate care. <b>Inclusion Criteria:</b> Studies that used artificial intelligence to aid the diagnosis, treatment, or its planning in individuals with cleft lip and/or palate were included. <b>Methodology:</b> A search of the Pubmed, Embase, and IEEE Xplore databases was conducted using search terms artificial intelligence and cleft lip and/or palate. Gray literature was searched using Google Scholar. The study was conducted according to the PRISMA- ScR guidelines. <b>Results:</b> The initial search identified 458 results, which were screened based on title and abstracts. After the screening, removal of duplicates, and a full-text reading of selected articles, 26 publications were included. They explored the use of AI in cleft lip and/or palate to aid in decisions regarding diagnosis, treatment, especially speech therapy, and prediction. <b>Conclusion:</b> There is active interest and immense potential for the use of artificial intelligence in cleft lip and/or palate. Most studies currently focus on speech in cleft palate. Multi-center studies that include different populations, with collaboration amongst academicians and researchers, can further develop the technology.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21347,""
"Accuracy of Deep Learning Algorithms for the Diagnosis of Retinopathy of Prematurity by Fundus Images: A Systematic Review and Meta-Analysis","Zhang, Liu, Mitsuhashi, Matsuo","https://doi.org/10.1155/2021/8883946","20210817","PubMed","","Retinopathy of prematurity (ROP) occurs in preterm infants and may contribute to blindness. Deep learning (DL) models have been used for ophthalmologic diagnoses. We performed a systematic review and meta-analysis of published evidence to summarize and evaluate the diagnostic accuracy of DL algorithms for ROP by fundus images. We searched PubMed, EMBASE, Web of Science, and Institute of Electrical and Electronics Engineers Xplore Digital Library on June 13, 2021, for studies using a DL algorithm to distinguish individuals with ROP of different grades, which provided accuracy measurements. The pooled sensitivity and specificity values and the area under the curve (AUC) of summary receiver operating characteristics curves (SROC) summarized overall test performance. The performances in validation and test datasets were assessed together and separately. Subgroup analyses were conducted between the definition and grades of ROP. Threshold and nonthreshold effects were tested to assess biases and evaluate accuracy factors associated with DL models. Nine studies with fifteen classifiers were included in our meta-analysis. A total of 521,586 objects were applied to DL models. For combined validation and test datasets in each study, the pooled sensitivity and specificity were 0.953 (95% confidence intervals (CI): 0.946-0.959) and 0.975 (0.973-0.977), respectively, and the AUC was 0.984 (0.978-0.989). For the validation dataset and test dataset, the AUC was 0.977 (0.968-0.986) and 0.987 (0.982-0.992), respectively. In the subgroup analysis of ROP vs. normal and differentiation of two ROP grades, the AUC was 0.990 (0.944-0.994) and 0.982 (0.964-0.999), respectively. Our study shows that DL models can play an essential role in detecting and grading ROP with high sensitivity, specificity, and repeatability. The application of a DL-based automated system may improve ROP screening and diagnosis in the future.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21348,""
"Macular Optical Coherence Tomography Imaging in Glaucoma","Kamalipour, Moghimi","https://doi.org/10.18502/jovr.v16i3.9442","20210817","PubMed"," Glaucoma;  Imaging;  Macula;  Optical Coherence Tomography; Artificial Intelligence","The advent of spectral-domain optical coherence tomography has played a transformative role in posterior segment imaging of the eye. Traditionally, images of the optic nerve head and the peripapillary area have been used to evaluate the structural changes associated with glaucoma. Recently, there is growing evidence in the literature supporting the use of macular spectral-domain optical coherence tomography as a complementary tool for clinical evaluation and research purposes in glaucoma. Containing more than 50% of retinal ganglion cells in a multilayered pattern, macula is shown to be affected even at the earliest stages of glaucomatous structural damage. Risk assessment for glaucoma progression, earlier detection of glaucomatous structural damage, monitoring of glaucoma especially in advanced cases, and glaucoma evaluation in certain ocular conditions including eyes with high myopia, positive history of disc hemorrhage, and certain optic disc phenotypes are specific domains where macular imaging yields complementary information compared to optic nerve head and peripapillary evaluation using optical coherence tomography. Moreover, the development of artificial intelligence models in data analysis has enabled a tremendous opportunity to create an integrated representation of structural and functional alterations observed in glaucoma. In this study, we aimed at providing a brief review of the main clinical applications and future potential utility of macular spectral-domain optical coherence tomography in glaucoma.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21349,""
"Applied Research in Quality of Life: A Computational Literature Review","Weismayer","https://doi.org/10.1007/s11482-021-09969-9","20210817","PubMed","Applied Research in Quality of Life (ARQOL); Computational literature review (CLR); Latent Dirichlet allocation (LDA); Machine learning; Scientometrics; Text mining","As quality of life (QoL) is a highly interdisciplinary topic with a multitude of related research areas, it is beneficial to avail researchers of an overview of the different streams explored in the field. Furthermore, knowledge of prominent sub-domains helps researchers identify links and overlaps between QoL and their fields of interest. To meet these needs, a text-mining-based computational literature review (CLR) of the journal of <i>Applied Research in Quality of Life</i> (ARQOL) was conducted using a machine learning process, latent Dirichlet allocation (LDA), in combination with selection criteria for the decision on the number of topics. The outcome provides the reader with a list of the twelve most heavily discussed topics: 1) consumption &amp; materialism, 2) character strength, 3) spirituality, religiousness &amp; personal beliefs, 4) inequality, 5) leisure &amp; tourism, 6) health related QoL (HRQoL) I, 7) quality of working life (QWL), 8) childhood &amp; adolescence, 9) disparity &amp; development, 10) disorder, 11) community issues, and 12) health related QoL (HRQoL) II. In addition, authors, titles, and publication dates are listed for the top-5-ranked papers that most typify these topics. Subsequent content summaries of these papers reveal more detailed information, such as measurement constructs and theories.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21350,""
"Human and Machine Intelligence Together Drive Drug Repurposing in Rare Diseases","Challa, Zaleski, Jerome, Lavieri, Shirey-Rice, Barnado, Lindsell, Aronoff, Crofford, Harris, Alp Ikizler, Mayer, Holroyd, Pulley","https://doi.org/10.3389/fgene.2021.707836","20210817","PubMed","drug repurposing; evidence synthesis; machine learning; phenome wide association studies; precision medicine; rare diseases","Repurposing is an increasingly attractive method within the field of drug development for its efficiency at identifying new therapeutic opportunities among approved drugs at greatly reduced cost and time of more traditional methods. Repurposing has generated significant interest in the realm of rare disease treatment as an innovative strategy for finding ways to manage these complex conditions. The selection of which agents should be tested in which conditions is currently informed by both human and machine discovery, yet the appropriate balance between these approaches, including the role of artificial intelligence (AI), remains a significant topic of discussion in drug discovery for rare diseases and other conditions. Our drug repurposing team at Vanderbilt University Medical Center synergizes machine learning techniques like phenome-wide association study-a powerful regression method for generating hypotheses about new indications for an approved drug-with the knowledge and creativity of scientific, legal, and clinical domain experts. While our computational approaches generate drug repurposing hits with a high probability of success in a clinical trial, human knowledge remains essential for the hypothesis creation, interpretation, ""go-no go"" decisions with which machines continue to struggle. Here, we reflect on our experience synergizing AI and human knowledge toward realizable patient outcomes, providing case studies from our portfolio that inform how we balance human knowledge and machine intelligence for drug repurposing in rare disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21351,""
"Intersection of Data Science and Smart Destinations: A Systematic Review","Aguirre Montero, LÃƒÂ³pez-SÃƒÂ¡nchez","https://doi.org/10.3389/fpsyg.2021.712610","20210816","PubMed","COVID-19 pandemic; bibliometric review; conceptual analysis; data science; data science technologies; marketing data science; smart destinations","This systematic review adopts a formal and structured approach to review the intersection of data science and smart tourism destinations in terms of components found in previous research. The study period corresponds to 1995-2021 focusing the analysis mainly on the last years (2015-2021), identifying and characterizing the current trends on this research topic. The review comprises documentary research based on bibliometric and conceptual analysis, using the VOSviewer and SciMAT software to analyze articles from the Web of Science database. There is growing interest in this research topic, with more than 300 articles published annually. Data science technologies on which current smart destinations research is based include big data, smart data, data analytics, social media, cloud computing, the internet of things (IoT), smart card data, geographic information system (GIS) technologies, open data, artificial intelligence, and machine learning. Critical research areas for data science techniques and technologies in smart destinations are public tourism marketing, mobility-accessibility, and sustainability. Data analysis techniques and technologies face unprecedented challenges and opportunities post-coronavirus disease-2019 (COVID-19) to build on the huge amount of data and a new tourism model that is more sustainable, smarter, and safer than those previously implemented.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21352,""
"Expert-Augmented Computational Drug Repurposing Identified Baricitinib as a Treatment for COVID-19","Smith, Oechsle, Rawling, Savory, Lacoste, Richardson","https://doi.org/10.3389/fphar.2021.709856","20210817","PubMed","COVID-19; SARS-CoV-2; drug repurposing; human computer interaction; knowledge discovery and data mining; knowledge graph","The onset of the 2019 Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic necessitated the identification of approved drugs to treat the disease, before the development, approval and widespread administration of suitable vaccines. To identify such a drug, we used a visual analytics workflow where computational tools applied over an AI-enhanced biomedical knowledge graph were combined with human expertise. The workflow comprised rapid augmentation of knowledge graph information from recent literature using machine learning (ML) based extraction, with human-guided iterative queries of the graph. Using this workflow, we identified the rheumatoid arthritis drug baricitinib as both an antiviral and anti-inflammatory therapy. The effectiveness of baricitinib was substantiated by the recent publication of the data from the ACTT-2 randomised Phase 3 trial, followed by emergency approval for use by the FDA, and a report from the CoV-BARRIER trial confirming significant reductions in mortality with baricitinib compared to standard of care. Such methods that iteratively combine computational tools with human expertise hold promise for the identification of treatments for rare and neglected diseases and, beyond drug repurposing, in areas of biological research where relevant data may be lacking or hidden in the mass of available biomedical literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21353,""
"Effect of Robot-Assisted Therapy on Participation of People with Limited Upper Limb Functioning: A Systematic Review with GRADE Recommendations","Ferreira, Chaves, Oliveira, Martins, Vimieiro, Van Petten","https://doi.org/10.1155/2021/6649549","20210817","PubMed","Humans; Occupational Therapy; Robotics; Upper Extremity","Previous studies have suggested that robot-assisted therapy (RT) is effective in treating impairment and that it may also improve individuals' participation. To investigate the effect of RT on the participation of individuals with limited upper limb functioning (PROSPERO: CRD42019133880). <i>Data Sources</i>: PEDro, Embase, MEDLINE, CINAHL, Cochrane, AMED, and Compendex. <i>Inclusion Criteria</i>. We selected randomized or quasirandomized controlled studies comparing the effects of RT with minimal or other interventions on participation of individuals with limited upper limb functioning. <i>Data Extraction and Synthesis</i>. Methodological quality of the included studies was assessed using the 0-10 PEDro scale, and effect estimates were reported using standardized mean differences (SMDs) with 95% confidence intervals (CIs), and the certainty of the current evidence was assessed using the GRADE. Twelve randomized controlled studies involving 845 participants were included. The estimates of medium effects between RT and minimal intervention (MI) at a short-term follow-up were pooled, but there are no short-term effects between RT and OI. Standardized differences in means were as follows: 0.6 (95% CI 0.1 to 1.2) and 0.2 (95% CI -0.0 to 0.4). There were also no effects of additional RT in the short- or medium-term follow-up periods. Standardized differences in means were as follows: -0.6 (95% CI -1.1 to -0.1) and 0.2 (95% CI -0.3 to 0.8). The methodological quality of the included studies potentially compromised the effect estimates of RT. The existing evidence was very low-quality with many confounding variables between studies. For patients with upper limb neurological dysfunction, low-quality evidence supports RT over MI in terms of improving individual participation in the short term. The existing low- to very low-quality evidence does not support RT over OI in either the short- or medium-term follow-up periods with respect to community participation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21354,""
"Machine Learning in Drug Discovery: A Review","Dara, Dhamercherla, Jadav, Babu, Ahsan","https://doi.org/10.1007/s10462-021-10058-4","20210817","PubMed","Artificial intelligence; Digital pathology; Drug discovery; Machine learning; Prognostic biomarkers; Target validation","This review provides the feasible literature on drug discovery through ML tools and techniques that are enforced in every phase of drug development to accelerate the research process and deduce the risk and expenditure in clinical trials. Machine learning techniques improve the decision-making in pharmaceutical data across various applications like QSAR analysis, hit discoveries, de novo drug architectures to retrieve accurate outcomes. Target validation, prognostic biomarkers, digital pathology are considered under problem statements in this review. ML challenges must be applicable for the main cause of inadequacy in interpretability outcomes that may restrict the applications in drug discovery. In clinical trials, absolute and methodological data must be generated to tackle many puzzles in validating ML techniques, improving decision-making, promoting awareness in ML approaches, and deducing risk failures in drug discovery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21355,""
"The impact of artificial intelligence on clinical education: perceptions of postgraduate trainee doctors in London (UK) and recommendations for trainers","Banerjee, Chiew, Patel, Johns, Chappell, Linton, Cole, Francis, Szram, Ross, Zaman","https://doi.org/10.1186/s12909-021-02870-x","20210817","PubMed","Artificial intelligence; Clinical training; Machine learning; Medical education; Artificial Intelligence; Humans; London; Perception; Physicians; Surveys and Questionnaires; United Kingdom","Artificial intelligence (AI) technologies are increasingly used in clinical practice. Although there is robust evidence that AI innovations can improve patient care, reduce clinicians' workload and increase efficiency, their impact on medical training and education remains unclear. A survey of trainee doctors' perceived impact of AI technologies on clinical training and education was conducted at UK NHS postgraduate centers in London between October and December 2020. Impact assessment mirrored domains in training curricula such as 'clinical judgement', 'practical skills' and 'research and quality improvement skills'. Significance between Likert-type data was analysed using Fisher's exact test. Response variations between clinical specialities were analysed using k-modes clustering. Free-text responses were analysed by thematic analysis. Two hundred ten doctors responded to the survey (response rate 72%). The majority (58%) perceived an overall positive impact of AI technologies on their training and education. Respondents agreed that AI would reduce clinical workload (62%) and improve research and audit training (68%). Trainees were skeptical that it would improve clinical judgement (46% agree, pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.12) and practical skills training (32% agree, pÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.01). The majority reported insufficient AI training in their current curricula (92%), and supported having more formal AI training (81%). Trainee doctors have an overall positive perception of AI technologies' impact on clinical training. There is optimism that it will improve 'research and quality improvement' skills and facilitate 'curriculum mapping'. There is skepticism that it may reduce educational opportunities to develop 'clinical judgement' and 'practical skills'. Medical educators should be mindful that these domains are protected as AI develops. We recommend that 'Applied AI' topics are formalized in curricula and digital technologies leveraged to deliver clinical education.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21356,""
"Gastrointestinal cancer classification and prognostication from histology using deep learning: Systematic review","Kuntz, Krieghoff-Henning, Kather, Jutzi, HÃƒÂ¶hn, Kiehl, Hekler, Alwers, von Kalle, FrÃƒÂ¶hling, Utikal, Brenner, Hoffmeister, Brinker","https://doi.org/10.1016/j.ejca.2021.07.012","20210907","PubMed","Artificial intelligence; Colorectal cancer; Convolutional neural network; Deep learning; Digital biomarker; Esophageal cancer; Gastric cancer; Gastrointestinal cancer; Pathology","Gastrointestinal cancers account for approximately 20% of all cancer diagnoses and are responsible for 22.5% of cancer deaths worldwide. Artificial intelligence-based diagnostic support systems, in particular convolutional neural network (CNN)-based image analysis tools, have shown great potential in medical computer vision. In this systematic review, we summarise recent studies reporting CNN-based approaches for digital biomarkers for characterization and prognostication of gastrointestinal cancer pathology. Pubmed and Medline were screened for peer-reviewed papers dealing with CNN-based gastrointestinal cancer analyses from histological slides, published between 2015 and 2020.Seven hundred and ninety titles and abstracts were screened, and 58 full-text articles were assessed for eligibility. Sixteen publications fulfilled our inclusion criteria dealing with tumor or precursor lesion characterization or prognostic and predictive biomarkers: 14 studies on colorectal or rectal cancer, three studies on gastric cancer and none on esophageal cancer. These studies were categorised according to their end-points: polyp characterization, tumor characterization and patient outcome. Regarding the translation into clinical practice, we identified several studies demonstrating generalization of the classifier with external tests and comparisons with pathologists, but none presenting clinical implementation. Results of recent studies on CNN-based image analysis in gastrointestinal cancer pathology are promising, but studies were conducted in observational and retrospective settings. Large-scale trials are needed to assess performance and predict clinical usefulness. Furthermore, large-scale trials are required for approval of CNN-based prediction models as medical devices.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21357,""
"Automated ICD coding for primary diagnosis via clinically interpretable machine learning","Diao, Huo, Zhao, Yuan, Cui, Wang, Lian, Zhao","https://doi.org/10.1016/j.ijmedinf.2021.104543","20210831","PubMed","Computer-assisted coding; ICD code; Machine learning; Primary diagnosis; Algorithms; Clinical Coding; Hospitalization; Humans; International Classification of Diseases; Machine Learning","Computer-assisted clinical coding (CAC) based on automated coding algorithms has been expected to improve the International Classification of Disease, tenth version (ICD-10) coding quality and productivity, whereas studies oriented to primary diagnosis auto-coding are limited in the Chinese context. This study aims at developing a machine learning (ML) model for automated primary diagnosis ICD-10 coding. A total of 71,709 admissions in Fuwai hospital were included to carry out this study, corresponding to 168 primary diagnosis ICD-10 codes. Based on clinical implications, two feature engineering methods were used to process discharge diagnosis and procedure texts into sequential features and sequential grouping features respectively by which two kinds of models were built and compared. One baseline model using one-hot encoding features was considered. Light Gradient Boosting Machine (LightGBM) was adopted as the classifier, and grid search and cross-validation were used to select the optimal hyperparameters. SHapley Additive exPlanations (SHAP) values were applied to give the interpretability of models. Our best prediction model was developed based on sequential grouping features. It showed good performance in the test phase with accuracy and macro-averaged F1 (Macro-F1) of 95.2% and 88.3% respectively. The comparison of the models demonstrated the effectiveness of the sequential information and the grouping strategy in boosting model performance (P-valueÃ‚Â &lt;Ã‚Â 0.01). Subgroup analysis of the best model on each individual code manifested that 91.1% of the codes achieved the F1 over 70.0%. Our model has been demonstrated its effectiveness for automated primary diagnosis coding in the Chinese context and its results are interpretable. Hence, it has the potential to assist clinical coders to improve coding efficiency and quality in Chinese inpatient settings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21358,""
"Improving broad-coverage medical entity linking with semantic type prediction and large-scale datasets","Vashishth, Newman-Griffis, Joshi, Dutt, RosÃƒÂ©","https://doi.org/10.1016/j.jbi.2021.103880","20211020","PubMed","Distant supervision; Entity typing; Information extraction; Medical concept normalization; Medical entity linking; Natural language processing; Information Storage and Retrieval; Natural Language Processing; Semantics; Software","Biomedical natural language processing tools are increasingly being applied for broad-coverage information extraction-extracting medical information of all types in a scientific document or a clinical note. In such broad-coverage settings, linking mentions of medical concepts to standardized vocabularies requires choosing the best candidate concepts from large inventories covering dozens of types. This study presents a novel semantic type prediction module for biomedical NLP pipelines and two automatically-constructed, large-scale datasets with broad coverage of semantic types. We experiment with five off-the-shelf biomedical NLP toolkits on four benchmark datasets for medical information extraction from scientific literature and clinical notes. All toolkits adopt a staged approach of mention detection followed by two stages of medical entity linking: (1) generating a list of candidate concepts, and (2) picking the best concept among them. We introduce a semantic type prediction module to alleviate the problem of overgeneration of candidate concepts by filtering out irrelevant candidate concepts based on the predicted semantic type of a mention. We present MedType, a fully modular semantic type prediction model which we integrate into the existing NLP toolkits. To address the dearth of broad-coverage training data for medical information extraction, we further present WikiMed and PubMedDS, two large-scale datasets for medical entity linking. Semantic type filtering improves medical entity linking performance across all toolkits and datasets, often by several percentage points of F-1. Further, pretraining MedType on our novel datasets achieves state-of-the-art performance for semantic type prediction in biomedical text. Semantic type prediction is a key part of building accurate NLP pipelines for broad-coverage information extraction from biomedical text. We make our source code and novel datasets publicly available to foster reproducible research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21359,""
"Training sample selection: Impact on screening automation in diagnostic test accuracy reviews","van Altena, Spijker, Leeflang, Olabarriaga","https://doi.org/10.1002/jrsm.1518","20210826","PubMed","computerised support; cosine similarity; machine learning; screening automation; training sample selection","When performing a systematic review, researchers screen the articles retrieved after a broad search strategy one by one, which is time-consuming. Computerised support of this screening process has been applied with varying success. This is partly due to the dependency on large amounts of data to develop models that predict inclusion. In this paper, we present an approach to choose which data to use in model training and compare it with established approaches. We used a dataset of 50 Cochrane diagnostic test accuracy reviews, and each was used as a target review. From the remaining 49 reviews, we selected those that most closely resembled the target review's clinical topic using the cosine similarity metric. Included and excluded studies from these selected reviews were then used to develop our prediction models. The performance of models trained on the selected reviews was compared against models trained on studies from all available reviews. The prediction models performed best with a larger number of reviews in the training set and on target reviews that had a research subject similar to other reviews in the dataset. Our approach using cosine similarity may reduce computational costs for model training and the duration of the screening process.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21360,""
"Cardiorespiratory fitness in breast cancer survivors: a randomised controlled trial of home-based smartphone supported high intensity interval training","Ochi, Tsuji, Narisawa, Shimizu, Kuchiba, Suto, Jimbo, Takayama, Ueno, Sakurai, Matsuoka","https://doi.org/10.1136/bmjspcare-2021-003141","20210814","PubMed","breast; quality of life; rehabilitation; supportive care; survivorship","A strategy for maintaining and/or improving cardiorespiratory fitness (CRF) in the growing population of cancer survivors is of major clinical importance, especially in the COVID-19 era. The effect of unsupervised high-intensity interval training (HIIT) on increasing CRF in breast cancer survivors is unknown. The purpose of this study was to determine whether the newly developed habit-B programme, which involves home-based smartphone-supported HIIT using body weight exercises, improves CRF in early-stage breast cancer survivors. This single-centre, 12-week, parallel-group, single-blind, randomised controlled trial involved 50Ã¢â‚¬â€°women with stage I-IIa breast cancer, aged 20-59 years, who had completed initial treatment except for hormone therapy. Participants were randomised to either the exercise or control group. The primary outcome was the 12-week change in peak oxygen uptake [Formula: see text]. Other outcomes included muscle strength, 6Ã¢â‚¬â€°min walk test, resting heart rate, physical activity, fatigue, safety and quality of life. The change in [Formula: see text] and leg strength increased significantly in the exercise group compared with the control group (p&lt;0.01). Changes in other outcomes were not significantly different between the groups. A home-based HIIT intervention can lead to improve CRF and muscle strength in early-stage breast cancer survivors.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21361,""
"Clinical implementation of deep-learning based auto-contouring tools-Experience of three French radiotherapy centers","Robert, Munoz, Moreau, Mazurier, Sidorski, Gasnier, Beldjoudi, GrÃƒÂ©goire, Deutsch, Meyer, Simon","https://doi.org/10.1016/j.canrad.2021.06.023","20210930","PubMed","Apprentissage profond; Auto-contouring; Automatic delineation; Clinical implementation; Deep-learning; DÃƒÂ©linÃƒÂ©ation automatique; ImplÃƒÂ©mentation clinique; Radiotherapy; RadiothÃƒÂ©rapie; Segmentation automatique; Deep Learning; Europe; Humans; Neoplasms; Organs at Risk; Practice Guidelines as Topic; Radiation Oncology; Radiotherapy Planning, Computer-Assisted; Radiotherapy, Image-Guided; Societies, Medical; Workload","Deep-learning (DL)-based auto-contouring solutions have recently been proposed as a convincing alternative to decrease workload of target volumes and organs-at-risk (OAR) delineation in radiotherapy planning and improve inter-observer consistency. However, there is minimal literature of clinical implementations of such algorithms in a clinical routine. In this paper we first present an update of the state-of-the-art of DL-based solutions. We then summarize recent recommendations proposed by the European society for radiotherapy and oncology (ESTRO) to be followed before any clinical implementation of artificial intelligence-based solutions in clinic. The last section describes the methodology carried out by three French radiation oncology departments to deploy CE-marked commercial solutions. Based on the information collected, a majority of OAR are retained by the centers among those proposed by the manufacturers, validating the usefulness of DL-based models to decrease clinicians' workload. Target volumes, with the exception of lymph node areas in breast, head and neck and pelvic regions, whole breast, breast wall, prostate and seminal vesicles, are not available in the three commercial solutions at this time. No implemented workflows are currently available to continuously improve the models, but these can be adapted/retrained in some solutions during the commissioning phase to best fit local practices. In reported experiences, automatic workflows were implemented to limit human interactions and make the workflow more fluid. Recommendations published by the ESTRO group will be of importance for guiding physicists in the clinical implementation of patient specific and regular quality assurances.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21362,""
"Whole-brain morphological alterations associated with trigeminal neuralgia","Mo, Zhang, Hu, Luo, Zhang","https://doi.org/10.1186/s10194-021-01308-5","20210817","PubMed","Machine learning; Multivariate analysis; Surface-based analysis; Systematic review; Trigeminal neuralgia; Brain; Gyrus Cinguli; Humans; Magnetic Resonance Imaging; Neuroimaging; Trigeminal Neuralgia","Novel neuroimaging strategies have the potential to offer new insights into the mechanistic basis for trigeminal neuralgia (TN). The present study aims to conduct whole-brain morphometry analyses of TN patients and to assess the value of group-level neocortical and subcortical structural patterns as tools for diagnostic biomarker exploration. Cortical thickness, surface area, and myelin levels in the neocortex were measured via magnetic resonance imaging (MRI). The radial distance and the Jacobian determinant of the subcortex in 43 TN patients and 43 matched controls were compared. Pattern learning algorithms were employed to establish the utility of group-level MRI findings as tools for predicting TN. An additional 40 control patients with hemifacial spasms were then evaluated to assess algorithm sensitivity and specificity. TN patients exhibited reductions in cortical indices in the anterior cingulate cortex (ACC), the midcingulate cortex (MCC), and the posterior cingulate cortex (PCC) relative to controls. They further presented with widespread subcortical volume reduction that was most evident in the putamen, the thalamus, the accumbens, the pallidum, and the hippocampus. Whole brain-level morphological alterations successfully enable automated TN diagnosis with high specificity (TN: 95.35Ã¢â‚¬â€°%; disease controls: 46.51Ã¢â‚¬â€°%). TN is associated with a distinctive whole-brain structural neuroimaging pattern, underscoring the value of machine learning as an approach to differentiating between morphological phenotypes, ultimately revealing the full spectrum of this disease and highlighting relevant diagnostic biomarkers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21363,""
"Applications of IoT for achieving sustainability in agricultural sector: A comprehensive review","Maroli, Narwane, Gardas","https://doi.org/10.1016/j.jenvman.2021.113488","20210921","PubMed","Agriculture; Environmental management; Internet of things; Supply chain; Sustainability; Agriculture; Databases, Factual","This research aims to achieve a holistic understanding of the current IoT scenario by conducting a comparative analysis of the prevailing literature regarding IoT applications in the agricultural domain. Also, it proposes a framework for IoT adoption in the case sector. A systematic literature review was conducted with a methodology that focused on scientific articles authored in the English language that were published in peer-reviewed journals in the last five years. Initially, 179 research papers were extracted from the SCOPUS database and finally, 82 relevant articles were considered for the study which were classified into various categories and studied thoroughly. Based on a comprehensive survey of the selected articles four research questions were identified and successfully addressed. The results highlighted that research efforts pertaining to IoT applications of agriculture have matured from their initial conceptual stage and now reached the implementation phase. Also, it was observed that Machine Learning based algorithms were utilized extensively in recent research studies. For the first time, an exhaustive study has been conducted holistically to comprehend the recent advances in the field of IoT applications for the agricultural sector.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21364,""
"PharmGKB, an Integrated Resource of Pharmacogenomic Knowledge","Gong, Whirl-Carrillo, Klein","https://doi.org/10.1002/cpz1.226","20210817","PubMed","drug response; genetic variation; knowledge base; pharmacogenetics; pharmacogenomics; Genotype; Humans; Knowledge Bases; Pharmacogenetics; Phenotype; Research","The Pharmacogenomics Knowledgebase (PharmGKB) is an integrated online knowledge resource for the understanding of how genetic variation contributes to variation in drug response. Our focus includes not only pharmacogenomic information useful for clinical implementation (e.g., drug dosing guidelines and annotated drug labels), but also information to catalyze scientific research and drug discovery (e.g., variant-drug annotations and drug-centered pathways). As of April 2021, the annotated content of PharmGKB spans 715 drugs, 1761 genes, 227 diseases, 165 clinical guidelines, and 784 drug labels. We have manually curated data from more than 9000 published papers to generate the content of PharmGKB. Recently, we have also implemented an automated natural language processing (NLP) tool to broaden our coverage of the pharmacogenomic literature. This article contains a basic protocol describing how to navigate the PharmGKB website to retrieve information on how genes and genetic variations affect drug efficacy and toxicity. It also includes a protocol on how to use PharmGKB to facilitate interpretation of findings for a pharmacogenomic variant genotype or metabolizer phenotype. PharmGKB is freely available at http://www.pharmgkb.org. Ã‚Â© 2021 Wiley Periodicals LLC. Basic Protocol 1: Navigating the homepage of PharmGKB and searching by drug Basic Protocol 2: Using PharmGKB to facilitate interpretation of pharmacogenomic variant genotypes or metabolizer phenotypes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21365,""
"Use of 816 consecutive burn wound biopsies to inform a histologic algorithm for burn depth categorization","Phelan, Holmes Iv, Hickerson, Cockerell, Shupp, Carter","https://doi.org/10.1093/jbcr/irab158","20210813","PubMed","algorithm; artificial intelligence; burn biopsy; burn depth; human","Burn experts are only 77% accurate when subjectively assessing burn depth, leaving almost a quarter of patients to undergo unnecessary surgery or conversely suffer a delay in treatment. To aid clinicians in burn depth assessment (BDA), new technologies are being studied with machine learning algorithms calibrated to histologic standards. Our group has iteratively created a theoretical burn biopsy algorithm (BBA) based on histologic analysis, and subsequently informed it with the largest burn wound biopsy repository in the literature. Here, we sought to report that process. The was an IRB-approved, prospective, multicenter study. A BBA was created a priori and refined in an iterative manner. Patients with burn wounds assessed by burn experts as requiring excision and autograft underwent 4mm biopsies procured every 25cm 2. Serial still photos were obtained at enrollment and at excision intraoperatively. Burn biopsies were histologically assessed for presence/absence of epidermis, papillary dermis, reticular dermis, and proportion of necrotic adnexal structures by a dermatopathologist using H&amp;E with whole slide scanning. First degree and superficial 2 nd degree were considered to be burn wounds likely to have healed without surgery, while deep 2 nd and 3 rd degree burns were considered unlikely to heal by 21 days. Biopsy pathology results were correlated with still photos by five burn experts for consensus of final burn depth diagnosis. Sixty-six subjects were enrolled with 117 wounds and 816 biopsies. The BBA was used to categorize subjects' wounds into 4 categories: 7% of burns were categorized as 1 st degree, 13% as superficial 2 nd degree, 43% as deep 2 nd degree, and 37% as 3 rd degree. Therefore 20% of burn wounds were incorrectly judged as needing excision and grafting by the clinical team as per the BBA. As H&amp;E is unable to assess the viability of papillary and reticular dermis, with time our team came to appreciate the greater importance of adnexal structure necrosis over dermal appearance in assessing healing potential. Our study demonstrates that a BBA with objective histologic criteria can be used to categorize BDA with clinical misclassification rates consistent with past literature. This study serves as the largest analysis of burn biopsies by modern day burn experts and the first to define histologic parameters for BDA.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21366,""
"Clinical Target Volume Auto-Segmentation of Esophageal Cancer for Radiotherapy After Radical Surgery Based on Deep Learning","Cao, Pei, Ge, Zheng","https://doi.org/10.1177/15330338211034284","20210820","PubMed","clinical target volume; dilated convolution; esophageal cancer; radiotherapy; segmentation","Radiotherapy plays an important role in controlling the local recurrence of esophageal cancer after radical surgery. Segmentation of the clinical target volume is a key step in radiotherapy treatment planning, but it is time-consuming and operator-dependent. This paper introduces a deep dilated convolutional U-network to achieve fast and accurate clinical target volume auto-segmentation of esophageal cancer after radical surgery. The deep dilated convolutional U-network, which integrates the advantages of dilated convolution and the U-network, is an end-to-end architecture that enables rapid training and testing. A dilated convolution module for extracting multiscale context features containing the original information on fine texture and boundaries is integrated into the U-network architecture to avoid information loss due to down-sampling and improve the segmentation accuracy. In addition, batch normalization is added to the deep dilated convolutional U-network for fast and stable convergence. In the present study, the training and validation loss tended to be stable after 40 training epochs. This deep dilated convolutional U-network model was able to segment the clinical target volume with an overall mean Dice similarity coefficient of 86.7% and a respective 95% Hausdorff distance of 37.4 mm, indicating reasonable volume overlap of the auto-segmented and manual contours. The mean Cohen kappa coefficient was 0.863, indicating that the deep dilated convolutional U-network was robust. Comparisons with the U-network and attention U-network showed that the overall performance of the deep dilated convolutional U-network was best for the Dice similarity coefficient, 95% Hausdorff distance, and Cohen kappa coefficient. The test time for segmentation of the clinical target volume was approximately 25 seconds per patient. This deep dilated convolutional U-network could be applied in the clinical setting to save time in delineation and improve the consistency of contouring.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21367,""
"Three-dimensional facial hard tissue symmetry in a healthy Caucasian population group: a systematic review","Morgan, Suryani, Shujaat, Jacobs","https://doi.org/10.1007/s00784-021-04126-w","20211025","PubMed","Bone; CT-CBCT; Humans; Symmetry; Three-dimensional; Cone-Beam Computed Tomography; Facial Bones; Humans; Imaging, Three-Dimensional; Population Groups; Tomography, X-Ray Computed","The aim of this study was to quantify the symmetry of the facial hard tissue structures using three-dimensional radiographic imaging modalities in a normal Caucasian population group. Electronic literature search was conducted in the following databases: PubMed, Embase, Web of Science, and Cochrane Library up to February 2021. The studies assessing symmetry of facial bones using computed tomography (CT) and cone beam CT were included. The initial search revealed 8811 studies. Full-text analysis was performed on 33 studies. Only 10 studies were found eligible based on the inclusion criteria. The qualitative analysis revealed that a significant variability existed in relation to the methodologies applied for symmetry quantification. The current review suggested that the overall relative symmetry of the normal Caucasian population group varied depending on the skeletal structure being assessed; however, majority of the observations showed a symmetry within the range of 1Ã‚Â mm without any significant difference between left and right sides. The quantification of facial hard tissue structure symmetry is vital for the diagnosis and treatment planning of orthodontic and/or maxillofacial surgical procedures. Prospero registration number CRD42020169908.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21368,""
"Challenges of Building, Deploying, and Using AI-Enabled Telepsychiatry Platforms for Clinical Practice Among Urban Indians: A Qualitative Study","Thenral M, Annamalai","https://doi.org/10.1177/0253717620973414","20210814","PubMed","AI in mental health; Indians; Telepsychiatry; challenges; qualitative research","Published literature shows the overall challenges associated with artificial intelligence (AI)-enabled medicine and telepsychiatry more from the western perspective, with no specific mention from the perspective of individual stakeholders or Indians. This study was conceptualized to understand the perceived challenges of building, deploying, and using AI-enabled telepsychiatry for clinical practice from the perspectives of psychiatrist, patients, and the technology experts (who build such services) in urban India. Between February 2020 and April 2020, a semistructured topic guide was drafted for qualitative exploratory study among psychiatrists (<i>n</i> = 14), their patients (<i>n</i> = 14), technology experts (<i>n</i> = 13), and Chief Executive Officers (CEOs) (<i>n</i> = 5) of health technology incubation centers. Interviews were conducted over the phone, recorded, and analyzed using the grounded theory approach. Almost all respondents cited ethical, legal, accountability, and regulatory implications as challenges. The major issues stated by patients were privacy/confidentiality, ethical violations, security/ hacking, and data ownership. Psychiatrists cited lack of clinical validation, lack of established studies or trials, iatrogenic risk, and healthcare infrastructure issues as the main challenges. Technology experts stated data-related issues as the major challenge. The CEOs quoted the lack of interdisciplinary experts as one of the main challenges in building deployable AI-enabled telepsychiatry in India. There are challenges to deploy an AI-enabled telepsychiatry platform in India. There is a need to constitute an interdisciplinary team to systematically address these challenges. Deployment of AI-enabled telepsychiatry is not possible without clinical validation and addressing current challenges.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21369,""
"Cost-effectiveness Analysis of Dienogest Compared With Gonadotropin-Releasing Hormone Agonist After Conservative Surgery for Endometriosis in China","Dai, Shi, Huang, Duan, Qiu, Ha, Huang, Xiao, Liu, Xuan","https://doi.org/10.1016/j.clinthera.2021.07.002","20210813","PubMed","GnRH-a; conservative surgery; cost-effectiveness analysis; dienogest; endometriosis; goserelin","Although the clinical effect of dienogest for endometriosis after conservative surgery has been proven, the cost-effectiveness of this new pharmacotherapy remains to be determined. We aimed to assess the health economic implications of dienogest versus a gonadotropin-releasing hormone agonist (GnRH-a; goserelin in the Chinese setting. A decision tree model was developed to evaluate the cost-effectiveness of dienogest compared with a GnRH-a (goserelin) after conservative surgery for endometriosis during a 2-year time horizon from the perspective of a health care system in China. The cost of drugs, use of outpatient care facilities, administration of medications, routine laboratory work and imaging studies, and treatment of drug-related adverse events were considered. We obtained clinical efficacy data from the peer-reviewed literature. Base case findings were further tested with 1-way and probabilistic sensitivity analyses. The model projects that treatment with dienogest would result in a modest incremental 0.02 quality-adjusted life-year gains compared with a GnRH-a (goserelin) (1.48 vs 1.46) at a cost saving of Ã‚Â¥7274 (Ã‚Â¥22,809 vs Ã‚Â¥30,164). Probabilistic sensitivity analysis found that dienogest has a 100% probability of % being considered cost-effective compared with a GnRH-a (goserelin) at the willingness-to-pay threshold of 3 times the gross domestic product per capita (Ã‚Â¥64,644Ã‚Â Ãƒâ€”Ã‚Â 3) of China in 2018 (Ã‚Â¥1Ã‚Â =Ã‚Â US$0.1454 and Ã¢â€šÂ¬0.1248). Dienogest is more effective and cost-saving compared with a GnRH-a (goserelin) in the treatment of patients with endometriosis after conservative surgery in China.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21370,""
"Thyroid lobectomy as a cost-effective approach in low-risk papillary thyroid cancer versus active surveillance","Youssef, Attia, Omar, Aboueisha, Freeman, Shama, Kandil","https://doi.org/10.1016/j.surg.2021.05.057","20210813","PubMed","","An ongoing debate exists over the optimal management of low-risk papillary thyroid cancer. The American Thyroid Association supports the concept of active surveillance to manage low-risk papillary thyroid cancer; however, the cost-effectiveness of active surveillance has not yet been established. We sought to perform a cost-effectiveness analysis comparing active surveillance versus surgical intervention for patients in the United States. A Markov decision tree model was developed to compare active surveillance and thyroid lobectomy. Our reference case is a 40-year-old female who was diagnosed with unifocal (&lt;15 mm), low-risk papillary thyroid cancer. Probabilistic outcomes, costs, and health utilities were determined using an extensive literature review. The willingness-to-pay threshold was set at $50,000/quality-adjusted life year gained. Sensitivity analyses were performed to account for uncertainty in the model's variables. Lobectomy provided a final effectiveness of 21.7/quality-adjusted life years, compared with 17.3/quality-adjusted life years for active surveillance. Furthermore, incremental cost effectiveness ratio for lobectomy versus active surveillance was $19,560/quality-adjusted life year (&lt;willing-to-pay threshold of $50,000/quality-adjusted life year), and thus surgical intervention proved to be cost-effective in patients between 40 and 69 years old. Further analysis revealed that, at the age of 69 years, active surveillance is more cost-effective than lobectomy, with a final effectiveness of 17.3/quality-adjusted life years. Compared to active surveillance, the incremental cost effectiveness ratio for lobectomy at the age of 69 was $27,235/quality-adjusted life year, which decreases quality-adjusted life years by 1.5. Lobectomy is a cost-effective strategy in middle-aged patients with low-risk papillary thyroid cancer. In contrast, active surveillance is cost-effective beginning at the age of 69. Identification of such nuances can help physicians and patients determine the best, most individualized long-term management strategy for low-risk papillary thyroid cancer.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21371,""
"Factors associated with brain ageing - a systematic review","Wrigglesworth, Ward, Harding, Nilaweera, Wu, Woods, Ryan","https://doi.org/10.1186/s12883-021-02331-4","20211015","PubMed","Age prediction; Age-related brain changes; Biomarker; Brain ageing; BrainAGE; Machine learning; Neuroimaging; Predicted age difference; Adult; Aged; Aging; Brain; Cross-Sectional Studies; Female; Humans; Middle Aged; Neuroimaging; Prospective Studies; Young Adult","Brain age is a biomarker that predicts chronological age using neuroimaging features. Deviations of this predicted age from chronological age is considered a sign of age-related brain changes, or commonly referred to as brain ageing. The aim of this systematic review is to identify and synthesize the evidence for an association between lifestyle, health factors and diseases in adult populations, with brain ageing. This systematic review was undertaken in accordance with the PRISMA guidelines. A systematic search of Embase and Medline was conducted to identify relevant articles using search terms relating to the prediction of age from neuroimaging data or brain ageing. The tables of two recent review papers on brain ageing were also examined to identify additional articles. Studies were limited to adult humans (aged 18Ã¢â‚¬â€°years and above), from clinical or general populations. Exposures and study design of all types were also considered eligible. A systematic search identified 52 studies, which examined brain ageing in clinical and community dwelling adults (mean age between 21 to 78Ã¢â‚¬â€°years, ~Ã¢â‚¬â€°37% were female). Most research came from studies of individuals diagnosed with schizophrenia or Alzheimer's disease, or healthy populations that were assessed cognitively. From these studies, psychiatric and neurologic diseases were most commonly associated with accelerated brain ageing, though not all studies drew the same conclusions. Evidence for all other exposures is nascent, and relatively inconsistent. Heterogenous methodologies, or methods of outcome ascertainment, were partly accountable. This systematic review summarised the current evidence for an association between genetic, lifestyle, health, or diseases and brain ageing. Overall there is good evidence to suggest schizophrenia and Alzheimer's disease are associated with accelerated brain ageing. Evidence for all other exposures was mixed or limited. This was mostly due to a lack of independent replication, and inconsistency across studies that were primarily cross sectional in nature. Future research efforts should focus on replicating current findings, using prospective datasets. A copy of the review protocol can be accessed through PROSPERO, registration number CRD42020142817 .","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21372,""
"A Fine-Tuned Bidirectional Encoder Representations From Transformers Model for Food Named-Entity Recognition: Algorithm Development and Validation","Stojanov, Popovski, Cenikj, KorouÃ…Â¡iÃ„â€¡ Seljak, Eftimov","https://doi.org/10.2196/28229","20211026","PubMed","BERT; bidirectional encoder representations from transformers; fine-tuning BERT; food information extraction; information extraction; machine learning; named-entity recognition; natural language processing; semantic annotation; Algorithms; Humans; Information Storage and Retrieval; Machine Learning; Natural Language Processing; Semantics","Recently, food science has been garnering a lot of attention. There are many open research questions on food interactions, as one of the main environmental factors, with other health-related entities such as diseases, treatments, and drugs. In the last 2 decades, a large amount of work has been done in natural language processing and machine learning to enable biomedical information extraction. However, machine learning in food science domains remains inadequately resourced, which brings to attention the problem of developing methods for food information extraction. There are only few food semantic resources and few rule-based methods for food information extraction, which often depend on some external resources. However, an annotated corpus with food entities along with their normalization was published in 2019 by using several food semantic resources. In this study, we investigated how the recently published bidirectional encoder representations from transformers (BERT) model, which provides state-of-the-art results in information extraction, can be fine-tuned for food information extraction. We introduce FoodNER, which is a collection of corpus-based food named-entity recognition methods. It consists of 15 different models obtained by fine-tuning 3 pretrained BERT models on 5 groups of semantic resources: food versus nonfood entity, 2 subsets of Hansard food semantic tags, FoodOn semantic tags, and Systematized Nomenclature of Medicine Clinical Terms food semantic tags. All BERT models provided very promising results with 93.30% to 94.31% macro F1 scores in the task of distinguishing food versus nonfood entity, which represents the new state-of-the-art technology in food information extraction. Considering the tasks where semantic tags are predicted, all BERT models obtained very promising results once again, with their macro F1 scores ranging from 73.39% to 78.96%. FoodNER can be used to extract and annotate food entities in 5 different tasks: food versus nonfood entities and distinguishing food entities on the level of food groups by using the closest Hansard semantic tags, the parent Hansard semantic tags, the FoodOn semantic tags, or the Systematized Nomenclature of Medicine Clinical Terms semantic tags.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21373,""
"Model-driven Deep Learning Method for Pancreatic Cancer Segmentation Based on Spiral-transformation","Chen, Chen, Li, Zhang, Lin, Qian","https://doi.org/10.1109/TMI.2021.3104460","20210812","PubMed","","Pancreatic cancer is a lethal malignant tumor with one of the worst prognoses. Accurate segmentation of pancreatic cancer is vital in clinical diagnosis and treatment. Due to the unclear boundary and small size of cancers, it is challenging to both manually annotate and automatically segment cancers. Considering 3D information utilization and small sample sizes, we propose a model-driven deep learning method for pancreatic cancer segmentation based on spiral transformation. Specifically, a spiral-transformation algorithm with uniform sampling was developed to map 3D images onto 2D planes while preserving the spatial relationship between textures, thus addressing the challenge in effectively applying 3D contextual information in a 2D model. This study is the first to introduce spiral transformation in a segmentation task to provide effective data augmentation, alleviating the issue of small sample size. Moreover, a transformation-weight-corrected module was embedded into the deep learning model to unify the entire framework. It can achieve 2D segmentation and corresponding 3D rebuilding constraint to overcome non-unique 3D rebuilding results due to the uniform and dense sampling. A smooth regularization based on rebuilding prior knowledge was also designed to optimize segmentation results. The extensive experiments showed that the proposed method achieved a promising segmentation performance on multi-parametric MRIs, where T2, T1, ADC, DWI images obtained the DSC of 65.6%, 64.0%, 64.5%, 65.3%, respectively. This method can provide a novel paradigm to efficiently apply 3D information and augment sample sizes in the development of artificial intelligence for cancer segmentation. Our source codes will be released at https://github.com/SJTUBME-QianLab/Spiral-Segmentation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21374,""
"Practical Aspects of Implementing and Applying Health Care Cloud Computing Services and Informatics to Cancer Clinical Trial Data","Ronquillo, Lester","https://doi.org/10.1200/CCI.21.00018","20211101","PubMed","Cloud Computing; Delivery of Health Care; Ecosystem; Humans; Informatics; Neoplasms; Precision Medicine","Cloud computing has led to dramatic growth in the volume, variety, and velocity of cancer data. However, cloud platforms and services present new challenges for cancer research, particularly in understanding the practical tradeoffs between cloud performance, cost, and complexity. The goal of this study was to describe the practical challenges when using a cloud-based service to improve the cancer clinical trial matching process. We collected information for all interventional cancer clinical trials from ClinicalTrials.gov and used the Google Cloud Healthcare Natural Language Application Programming Interface (API) to analyze clinical trial Title and Eligibility Criteria text. An informatics pipeline leveraging interoperability standards summarized the distribution of cancer clinical trials, genes, laboratory tests, and medications extracted from cloud-based entity analysis. There were a total of 38,851 cancer-related clinical trials found in this study, with the distribution of cancer categories extracted from Title text significantly different than in ClinicalTrials.gov (<i>P</i> &lt; .001). Cloud-based entity analysis of clinical trial criteria identified a total of 949 genes, 1,782 laboratory tests, 2,086 medications, and 4,902 National Cancer Institute Thesaurus terms, with estimated detection accuracies ranging from 12.8% to 89.9%. A total of 77,702 API calls processed an estimated 167,179 text records, which took a total of 1,979 processing-minutes (33.0 processing-hours), or approximately 1.5 seconds per API call. Current general-purpose cloud health care tools-like the Google service in this study-should not be used for automated clinical trial matching unless they can perform effective extraction and classification of the clinical, genetic, and medication concepts central to precision oncology research. A strong understanding of the practical aspects of cloud computing will help researchers effectively navigate the vast data ecosystems in cancer research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21375,""
"An automated approach to identify scientific publications reporting pharmacokinetic parameters","Gonzalez Hernandez, Carter, Iso-SipilÃƒÂ¤, Goldsmith, Almousa, Gastine, Lilaonitkul, Kloprogge, Standing","https://doi.org/10.12688/wellcomeopenres.16718.1","20210813","PubMed","Bioinformatics; Information extraction; Machine Learning; Natural Language Processing; Pharmacokinetics; Pharmacometrics; Text mining","Pharmacokinetic (PK) predictions of new chemical entities are aided by prior knowledge from other compounds. The development of robust algorithms that improve preclinical and clinical phases of drug development remains constrained by the need to search, curate and standardise PK information across the constantly-growing scientific literature. The lack of centralised, up-to-date and comprehensive repositories of PK data represents a significant limitation in the drug development pipeline.In this work, we propose a machine learning approach to automatically identify and characterise scientific publications reporting PK parameters from in vivo data, providing a centralised repository of PK literature. A dataset of 4,792 PubMed publications was labelled by field experts depending on whether in vivo PK parameters were estimated in the study. Different classification pipelines were compared using a bootstrap approach and the best-performing architecture was used to develop a comprehensive and automatically-updated repository of PK publications. The best-performing architecture encoded documents using unigram features and mean pooling of BioBERT embeddings obtaining an F1 score of 83.8% on the test set. The pipeline retrieved over 121K PubMed publications in which in vivo PK parameters were estimated and it was scheduled to perform weekly updates on newly published articles. All the relevant documents were released through a publicly available web interface (https://app.pkpdai.com) and characterised by the drugs, species and conditions mentioned in the abstract, to facilitate the subsequent search of relevant PK data. This automated, open-access repository can be used to accelerate the search and comparison of PK results, curate ADME datasets, and facilitate subsequent text mining tasks in the PK domain.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21376,""
"Deep negative volume segmentation","Belikova, Rogov, Rybakov, Maslov, Dylov","https://doi.org/10.1038/s41598-021-95526-1","20211013","PubMed","","Clinical examination of three-dimensional image data of compound anatomical objects, such as complex joints, remains a tedious process, demanding the time and the expertise of physicians. For instance, automation of the segmentation task of the TMJ (temporomandibular joint) has been hindered by its compound three-dimensional shape, multiple overlaid textures, an abundance of surrounding irregularities in the skull, and a virtually omnidirectional range of the jaw's motion-all of which extend the manual annotation process to more than an hour per patient. To address the challenge, we invent a new workflow for the 3D segmentation task: namely, we propose to segment empty spaces between all the tissues surrounding the object-the so-called negative volume segmentation. Our approach is an end-to-end pipeline that comprises a V-Net for bone segmentation, a 3D volume construction by inflation of the reconstructed bone head in all directions along the normal vector to its mesh faces. Eventually confined within the skull bones, the inflated surface occupies the entire ""negative"" space in the joint, effectively providing a geometrical/topological metric of the joint's health. We validate the idea on the CT scans in a 50-patient dataset, annotated by experts in maxillofacial medicine, quantitatively compare the asymmetry given the left and the right negative volumes, and automate the entire framework for clinical adoption.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21377,""
"Does robotic-assisted unicompartmental knee arthroplasty have lower complication and revision rates than the conventional procedure? A systematic review and meta-analysis","Sun, Liu, Hou, Hu, Zhang","https://doi.org/10.1136/bmjopen-2020-044778","20210813","PubMed","adult orthopaedics; adult surgery; knee; orthopaedic &amp; trauma surgery; Arthroplasty, Replacement, Knee; Case-Control Studies; Humans; Osteoarthritis, Knee; Reproducibility of Results; Robotic Surgical Procedures; Treatment Outcome","We conducted this systematic review and meta-analysis of studies on patients who underwent unicompartmental knee arthroplasty (UKA) to compare the complication rates, revision rates and non-implant-specific complications between robotic-assisted and conventional UKA. Systematic review and meta-analysis. The PubMed, Embase, Web of Science and Cochrane databases were searched up to 30 June 2020. Case-control studies comparing robotic-assisted and conventional UKA. Data from all eligible articles were independently extracted by two authors. We analysed the differences in outcomes between robotic-assisted and conventional UKA by calculating the corresponding 95% CIs and pooled relative risks (RRs). Heterogeneity was assessed using the Ãâ€¡<sup>2</sup> and I<sup>2</sup> tests. All analyses were performed using the 'metafor' package of R V.3.6.2 software. A total of 16 studies involving 50Ã¢â‚¬â€°024 patients were included in the final meta-analysis. We found that robotic-assisted UKA had fewer complications (RR: 0.52, 95%Ã¢â‚¬â€°CI: 0.28 to 0.96, p=0.036) and lower revision rates (RR: 0.42, 95%Ã¢â‚¬â€°CI: 0.20 to 0.86, p=0.017) than conventional UKA. We observed no significant differences in non-implant-specific complications between the two surgical techniques (RR: 0.80, 95%Ã¢â‚¬â€°CI: 0.61 to 1.04, p=0.96). No publication bias was found in this meta-analysis. This study provides evidence that robotic-assisted UKA has fewer complications and lower revision rates than conventional UKA; however, owing to important limitations, the results lack reliability, and more studies are required. CRD42021246927.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21378,""
"Systematic Review of Artificial Intelligence in Acute Respiratory Distress Syndrome for COVID-19 Lung Patients: A Biomedical Imaging Perspective","Suri, Agarwal, Gupta, Puvvula, Viskovic, Suri, Alizad, El-Baz, Saba, Fatemi, Naidu","https://doi.org/10.1109/JBHI.2021.3103839","20211025","PubMed","","SARS-CoV-2 has infected over ~165 million people worldwide causing Acute Respiratory Distress Syndrome (ARDS) and has killed ~3.4 million people. Artificial Intelligence (AI) has shown to benefit in the biomedical image such as X-ray/Computed Tomography in diagnosis of ARDS, but there are limited AI-based systematic reviews (aiSR). The purpose of this study is to understand the Risk-of-Bias (RoB) in a non-randomized AI trial for handling ARDS using novel AtheroPoint-AI-Bias (AP(ai)Bias). Our hypothesis for acceptance of a study to be in low RoB must have a mean score of 80% in a study. Using the PRISMA model, 42 best AI studies were analyzed to understand the RoB. Using the AP(ai)Bias paradigm, the top 19 studies were then chosen using the raw-cutoff of 1.9. This was obtained using the intersection of the cumulative plot of mean score vs. study and score distribution. Finally, these studies were benchmarked against ROBINS-I and PROBAST paradigm. Our observation showed that AP(ai)Bias, ROBINS-I, and PROBAST had only 32%, 16%, and 26% studies, respectively in low-moderate RoB (cutoff&gt;2.5), however none of them met the RoB hypothesis. Further, the aiSR analysis recommends six primary and six secondary recommendations for the non-randomized AI for ARDS. The primary recommendations for improvement in AI-based ARDS design inclusive of (i) comorbidity, (ii) inter-and intra-observer variability studies, (iii) large data size, (iv) clinical validation, (v) granularity of COVID-19 risk, and (vi) cross-modality scientific validation. The AI is an important component for diagnosis of ARDS and the recommendations must be followed to lower the RoB.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21379,""
"COVID 19 repercussions in ophthalmology: a narrative review","Dos Santos Martins, Dos Santos Martins, Dos Santos Martins, Marinho, Schor","https://doi.org/10.1590/1516-3180.2021.0113.R1.0504221","20210816","PubMed","Artificial Intelligence; Brazil; COVID-19; Humans; Ophthalmology; SARS-CoV-2","The new coronavirus of 2019 (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has spread globally and has repercussions within ophthalmological care. It has caused ocular manifestations in some patients, which can spread through eye secretions. The purpose of this review was to summarize the currently available evidence on COVID-19 with regard to its implications for ophthalmology. Narrative review developed by a research group at Universidade Federal de SÃƒÂ£o Paulo (UNIFESP), SÃƒÂ£o Paulo (SP), Brazil, and at Ludwig-Maximilians-UniversitÃƒÂ¤t, Munich, Germany. We searched the literature on the repercussions of COVID-19 within ophthalmological care, using the MEDLINE and LILACS databases, with the keywords ""COVID-19"", ""ophthalmology"" and ""coronavirus"", from January 1, 2020, to March 27, 2021. Clinical trials, meta-analysis, randomized controlled trials, reviews and systematic reviews were identified. We retrieved 884 references, of which 42 were considered eligible for intensive review and critical analysis. Most of the studies selected reported the evidence regarding COVID-19 and its implications for ophthalmology. Knowledge of eye symptoms and ocular transmission of the virus remains incomplete. New clinical trials with larger numbers of patients may answer these questions in the future. Moreover, positively, implementation of innovative changes in medicine such as telemedicine and artificial intelligence may assist in diagnosing eye diseases and in training and education for students.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21380,""
"Epidemiology and aetiology of male and female sexual dysfunctions related to pelvic ring injuries: a systematic review","Rovere, Perna, Meccariello, De Mauro, Smimmo, Proietti, Falez, Maccauro, Liuzza","https://doi.org/10.1007/s00264-021-05153-8","20211025","PubMed","Dyspareunia; Lumbosacral plexus; Pelvic ring injuries; Penile erection; Sexual disfunction; Causality; Female; Fractures, Bone; Humans; Incidence; Lumbosacral Plexus; Male; Pelvic Bones; Retrospective Studies","Pelvic ring injuries, frequently caused by high energy trauma, are associated with high rates of morbidity and mortality (5-33%), often due to significant blood loss and disruption of the lumbosacral plexus, genitourinary system, and gastrointestinal system. The aim of the present study is to perform a systematic literature review on male and female sexual dysfunctions related to traumatic lesions of the pelvic ring. Scopus, Cochrane Library MEDLINE via PubMed, and Embase were searched using the keywords: ""Pelvic fracture,"" ""Pelvic Ring Fracture,"" ""Pelvic Ring Trauma,"" ""Pelvic Ring injury,"" ""Sexual dysfunction,"" ""Erectile dysfunction,"" ""dyspareunia,"" and their MeSH terms in any possible combination. The following questions were formulated according to the PICO (population (P), intervention (I), comparison (C), and outcome (O)) scheme: Do patients suffering from pelvic fracture (P) report worse clinical outcomes (C), in terms of sexual function (O), when urological injury occurs (I)? Is the sexual function (O) influenced by the type of fracture (I)? After screening 268 articles by title and abstract, 77 were considered eligible for the full-text analysis. Finally 17 studies that met inclusion criteria were included in the review. Overall, 1364 patients (902 males and 462 females, M/F ratio: 1.9) suffering from pelvic fractures were collected. Pelvic fractures represent challenging entities, often concomitant with systemic injuries and subsequent morbidity. Anatomical consideration, etiology, correlation between sexual dysfunction and genitourinary lesions, or pelvic fracture type were investigated. There are evidences in the literature that the gravity and frequency of SD are related with the pelvic ring fracture type. In fact, patients with APC, VS (according Young-Burgess), or C (according Tile) fracture pattern reported higher incidence and gravity of SD. Only a week association could be found between GUI and incidence and gravity of SD, and relationship between surgical treatment and SD. Electrophysiological tests should be routinely used in patient suffering from SD after pelvic ring injuries.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21381,""
"Classification of true progression after radiotherapy of brain metastasis on MRI using artificial intelligence: a systematic review and meta-analysis","Kim, Cho, Sunwoo, Baik, Bae, Choi, Jung, Kim","https://doi.org/10.1093/noajnl/vdab080","20210812","PubMed","artificial intelligence; magnetic resonance imaging; radiosurgery; radiotherapy; systematic review","Classification of true progression from nonprogression (eg, radiation-necrosis) after stereotactic radiotherapy/radiosurgery of brain metastasis is known to be a challenging diagnostic task on conventional magnetic resonance imaging (MRI). The scope and status of research using artificial intelligence (AI) on classifying true progression are yet unknown. We performed a systematic literature search of MEDLINE and EMBASE databases to identify studies that investigated the performance of AI-assisted MRI in classifying true progression after stereotactic radiotherapy/radiosurgery of brain metastasis, published before November 11, 2020. Pooled sensitivity and specificity were calculated using bivariate random-effects modeling. Meta-regression was performed for the identification of factors contributing to the heterogeneity among the studies. We assessed the quality of the studies using the Quality Assessment of Diagnostic Accuracy Studies 2 (QUADAS-2) criteria and a modified version of the radiomics quality score (RQS). Seven studies were included, with a total of 485 patients and 907 tumors. The pooled sensitivity and specificity were 77% (95% CI, 70-83%) and 74% (64-82%), respectively. All 7 studies used radiomics, and none used deep learning. Several covariates including the proportion of lung cancer as the primary site, MR field strength, and radiomics segmentation slice showed a statistically significant association with the heterogeneity. Study quality was overall favorable in terms of the QUADAS-2 criteria, but not in terms of the RQS. The diagnostic performance of AI-assisted MRI seems yet inadequate to be used reliably in clinical practice. Future studies with improved methodologies and a larger training set are needed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21382,""
"National and provincial impact and cost-effectiveness of Haemophilus influenzae type b conjugate vaccine in China: a modeling analysis","Zhang, Garcia, Yu, Knoll, Lai, Xu, Jing, Qin, Yin, Wahl, Fang","https://doi.org/10.1186/s12916-021-02049-7","20211018","PubMed","Child health; China; Haemophilus influenzae type b; Health economics; Immunization; China; Cost-Benefit Analysis; Haemophilus Infections; Haemophilus Vaccines; Haemophilus influenzae type b; Humans; Immunization Programs; Vaccines, Conjugate","Globally, Haemophilus influenzae type b (Hib) vaccine has substantially reduced the burden of Hib invasive disease. However, China remains the only country not to include Hib vaccine into its national immunization program (NIP), although it accounts for 11% of global Hib deaths. We aimed to assess the cost-effectiveness of including Hib vaccine in China's NIP at the national and provincial levels. Using a decision-tree Markov state transition model, we estimated the cost-effectiveness of Hib vaccine in the NIP compared to the status quo of Hib vaccine in the private market for the 2017 birth cohort. Treatment costs and vaccine program costs were calculated from Chinese Center for Disease Control and Prevention (CDC) and national insurance databases. Epidemiological data and other model parameters were obtained from published literature. Cases and deaths averted, quality-adjusted life years (QALYs) gained, and incremental cost-effectiveness ratios (ICER) were predicted by province. Deterministic and probabilistic sensitivity analyses were performed to explore model uncertainty. Including Hib vaccine in the NIP was projected to prevent approximately 2700 deaths (93% reduction) and 235,700 cases of Hib disease (92% reduction) for the 2017 birth cohort at the national level. Hib vaccine was cost-effective nationally (US$ 8001 per QALY gained) compared to the GDP per capita and cost-effective in 15 of 31 provinces. One-way and scenario sensitivity analyses indicated results were robust when varying model parameters, and in probabilistic sensitivity analysis, Hib vaccine had a 64% probability of being cost-effective nationally. Introducing Hib vaccine in China's NIP is cost-effective nationally and in many provinces. Less socioeconomically developed provinces with high Hib disease burden and low access to Hib vaccine in the current private market, such as those in the west region, would benefit the most from adding Hib vaccine to the NIP. In the absence of a national policy decision on Hib vaccine, this analysis provides evidence for provincial governments to include Hib vaccine into local immunization programs to substantially reduce disease burden and treatment costs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21383,""
"Applications of augmented reality in the neurosurgical operating room: A systematic review of the literature","Chidambaram, Stifano, Demetres, Teyssandier, Palumbo, Redaelli, Olivi, Apuzzo, Pannullo","https://doi.org/10.1016/j.jocn.2021.06.032","20211004","PubMed","Augmented reality; Imaging; Mixed reality; Technology; Artificial Intelligence; Augmented Reality; Humans; Neuronavigation; Neurosurgical Procedures; Operating Rooms","Advancements in imaging techniques are key forces of progress in neurosurgery. The importance of accurate visualization of intraoperative anatomy cannot be overemphasized and is commonly delivered through traditional neuronavigation. Augmented Reality (AR) technology has been tested and applied widely in various neurosurgical subspecialties in intraoperative, clinical use and shows promise for the future. This systematic review of the literature explores the ways in which AR technology has been successfully brought into the operating room (OR) and incorporated into clinical practice. A comprehensive literature search was performed in the following databases from inception-April 2020: Ovid MEDLINE, Ovid EMBASE, and The Cochrane Library. Studies retrieved were then screened for eligibility against predefined inclusion/exclusion criteria. A total of 54 articles were included in this systematic review. The studies were sub- grouped into brain and spine subspecialties and analyzed for their incorporation of AR in the neurosurgical clinical setting. AR technology has the potential to greatly enhance intraoperative visualization and guidance in neurosurgery beyond the traditional neuronavigation systems. However, there are several key challenges to scaling the use of this technology and bringing it into standard operative practice including accurate and efficient brain segmentation of magnetic resonance imaging (MRI) scans, accounting for brain shift, reducing coregistration errors, and improving the AR device hardware. There is also an exciting potential for future work combining AR with multimodal imaging techniques and artificial intelligence to further enhance its impact in neurosurgery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21384,""
"Prediction of delirium using data mining: A systematic review","Chua, Wrigley, Hair, Sahathevan","https://doi.org/10.1016/j.jocn.2021.07.029","20211004","PubMed","Association mining; Big data; Data mining; Delirium; Machine learning; Systematic review; Area Under Curve; Data Mining; Delirium; Humans; Length of Stay; Retrospective Studies","Delirium remains a significant cause of morbidity, mortality and economic burden to society. ""Big data"" refers to data of significantly large volume, obtained from a variety of resources, which is created and processed at high velocity. We conducted a systematic review and meta-analysis exploring whether big data could predict the incidence of delirium of patients in the inpatient setting. Medline, Embase, the Cochrane Library, Web of Science, CINAHL, clinicaltrials.gov, who.int and IEEE Xplore were searched using MeSH terms ""big data"", ""data mining"", ""delirium"" and ""confusion"" up to 30th September 2019. We included both randomised and observational studies. The primary outcome of interest was development of delirium and the secondary outcomes of interest were type of statistical methods used, variables included in the mining algorithms and clinically important outcomes such as mortality and length of hospital stay. The quality of studies was graded using the CHARMs checklist. Six retrospective single centre observational studies were included (nÃ‚Â =Ã‚Â 178,091), of which 17, 574 participants developed delirium. Studies were of generally of low to moderate quality. The most commonly studied method was random forest, followed by support vector machine and artificial neural networks. The model with best performance for delirium prediction was random forest, with area under receiver operating curve (AUROC) ranging from 0.78 to 0.91. Sensitivity ranged from 0.59 to 0.81 and specificity ranged from 0.73 to 0.92. Our systematic review suggests that machine-learning techniques can be utilised to predict delirium.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21385,""
"Robot-assisted gait training in individuals with spinal cord injury: A systematic review for the clinical effectiveness of Lokomat","Alashram, Annino, Padua","https://doi.org/10.1016/j.jocn.2021.07.019","20211004","PubMed","Impairments; Lokomat; Rehabilitation; Robotic-assisted gait training; Spinal cord injury; Gait; Humans; Pilot Projects; Quality of Life; Randomized Controlled Trials as Topic; Robotics; Spinal Cord Injuries; Treatment Outcome; Walking","Spinal cord injury (SCI) is a critical medical condition that causes numerous impairments leading to accompanying disability. Robotic-assisted gait training (RAGT) offers many advantages, including the capability to increase the intensity and total duration of training while maintaining a physiological gait pattern. The effects of the RAGT 'Lokomat' on various impairments following SCI remain unclear. This review was conducted to examine the impacts of the RAGT 'Lokomat' on the impairments following SCI. We searched PubMed, SCOPUS, PEDro, REHABDATA, MEDLINE, EMBASE, and web of science from inception to January 2021. Experimental studies examining the effects of the Lokomat on the impairments following incomplete SCI were selected. The methodological quality was assessed using the Physiotherapy Evidence Database (PEDro) scale. Sixteen studies were met the inclusion criteria. Thirteen were randomized controlled trials, two were clinical trials, and one was a pilot study. The scores on the PEDro scale ranged from two to eight, with a median score of six. The results showed evidence for the beneficial effects of the Lokomat on many motor impairments following incomplete SCI. The Lokomat may improve gait speed, walking distance, strength, range of motion, and mobility after incomplete SCI. There is insufficient evidence for the effect of the Lokomat on balance, depression, cardiorespiratory fitness, and quality of life. The effects of the Lokomat on the lower extremity spasticity were limited.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21386,""
"Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma","Li, Sun, Cheng, Ruan, Liu, Chen, Xu, Gao, Feng, Qi","https://doi.org/10.1186/s12885-021-08647-1","20211018","PubMed","Artificial neural network; Esophageal squamous cell carcinoma; Logical regression; Machine learning; Random forest; Stratifin; Support vector machine; eXtreme gradient boosting; Algorithms; Biomarkers, Tumor; Computational Biology; Esophageal Squamous Cell Carcinoma; Gene Expression Profiling; Humans; Kaplan-Meier Estimate; Machine Learning; Prognosis; Reproducibility of Results; Transcriptome","A plethora of prognostic biomarkers for esophageal squamous cell carcinoma (ESCC) that have hitherto been reported are challenged with low reproducibility due to high molecular heterogeneity of ESCC. The purpose of this study was to identify the optimal biomarkers for ESCC using machine learning algorithms. Biomarkers related to clinical survival, recurrence or therapeutic response of patients with ESCC were determined through literature database searching. Forty-eight biomarkers linked to recurrence or prognosis of ESCC were used to construct a molecular interaction network based on NetBox and then to identify the functional modules. Publicably available mRNA transcriptome data of ESCC downloaded from Gene Expression Omnibus (GEO) and The Cancer Genome Atlas (TCGA) datasets included GSE53625 and TCGA-ESCC. Five machine learning algorithms, including logical regression (LR), support vector machine (SVM), artificial neural network (ANN), random forest (RF) and XGBoost, were used to develop classifiers for prognostic classification for feature selection. The area under ROC curve (AUC) was used to evaluate the performance of the prognostic classifiers. The importances of identified molecules were ranked by their occurrence frequencies in the prognostic classifiers. Kaplan-Meier survival analysis and log-rank test were performed to determine the statistical significance of overall survival. A total of 48 clinically proven molecules associated with ESCC progression were used to construct a molecular interaction network with 3 functional modules comprising 17 component molecules. The 131,071 prognostic classifiers using these 17 molecules were built for each machine learning algorithm. Using the occurrence frequencies in the prognostic classifiers with AUCs greater than the mean value of all 131,071 AUCs to rank importances of these 17 molecules, stratifin encoded by SFN was identified as the optimal prognostic biomarker for ESCC, whose performance was further validated in another 2 independent cohorts. The occurrence frequencies across various feature selection approaches reflect the degree of clinical importance and stratifin is an optimal prognostic biomarker for ESCC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21387,""
"Affective Communication for Socially Assistive Robots (SARs) for Children with Autism Spectrum Disorder: A Systematic Review","Cano, GonzÃƒÂ¡lez, Gil-Iranzo, Albiol-PÃƒÂ©rez","https://doi.org/10.3390/s21155166","20210811","PubMed","affective computing; affective humanÃ¢â‚¬â€œrobot interaction; autism spectrum disorders; socially assistive robots; therapeutic intervention; Autism Spectrum Disorder; Child; Communication; Emotions; Humans; Robotics; Social Behavior","Research on affective communication for socially assistive robots has been conducted to enable physical robots to perceive, express, and respond emotionally. However, the use of affective computing in social robots has been limited, especially when social robots are designed for children, and especially those with autism spectrum disorder (ASD). Social robots are based on cognitive-affective models, which allow them to communicate with people following social behaviors and rules. However, interactions between a child and a robot may change or be different compared to those with an adult or when the child has an emotional deficit. In this study, we systematically reviewed studies related to computational models of emotions for children with ASD. We used the Scopus, WoS, Springer, and IEEE-Xplore databases to answer different research questions related to the definition, interaction, and design of computational models supported by theoretical psychology approaches from 1997 to 2021. Our review found 46 articles; not all the studies considered children or those with ASD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21388,""
"User Experience in Social Robots","Shourmasti, Colomo-Palacios, Holone, Demi","https://doi.org/10.3390/s21155052","20210811","PubMed","UX evaluation; human-robot interaction; social robots; systematic literature review; Delivery of Health Care; Humans; Robotics; Social Interaction; Surveys and Questionnaires; Technology","Social robots are increasingly penetrating our daily lives. They are used in various domains, such as healthcare, education, business, industry, and culture. However, introducing this technology for use in conventional environments is not trivial. For users to accept social robots, a positive user experience is vital, and it should be considered as a critical part of the robots' development process. This may potentially lead to excessive use of social robots and strengthen their diffusion in society. The goal of this study is to summarize the extant literature that is focused on user experience in social robots, and to identify the challenges and benefits of UX evaluation in social robots. To achieve this goal, the authors carried out a systematic literature review that relies on PRISMA guidelines. Our findings revealed that the most common methods to evaluate UX in social robots are questionnaires and interviews. UX evaluations were found out to be beneficial in providing early feedback and consequently in handling errors at an early stage. However, despite the importance of UX in social robots, robot developers often neglect to set UX goals due to lack of knowledge or lack of time. This study emphasizes the need for robot developers to acquire the required theoretical and practical knowledge on how to perform a successful UX evaluation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21389,""
"Cortical thickness in clinical moyamoya disease: A magnetic resonance imaging study","Tompkins, Levman, Ijner, Shiohama, Takahashi","https://doi.org/10.1002/jdn.10146","20210827","PubMed","cortical thickness; machine learning; magnetic resonance imaging; moyamoya; paediatric","Moyamoya disease (MMD) is a progressive cerebrovascular disorder, with an unknown pathogenesis and aetiology. MMD is characterized by steno-occlusive changes at the terminal portion of the internal carotid artery (ICA), which is accompanied by variable development of the basal collaterals, also known as moyamoya vessels. Patients with MMD show variable patterns of brain damage and may experience recurrent multiple transient ischaemic attacks, intracranial bleeding and cerebral infarction. In this study, we investigate the potential for structural T1 magnetic resonance imaging (MRI) to help characterize abnormal cortical development in MMD clinically, with an analysis of both average and variability of regional cortical thicknesses. This study also included a machine learning analysis to assess the predictive capacity of the cortical thickness abnormalities observed in this research. This study included 993 MRI examinations from neurotypical controls and 269 MRI examinations from MMD patients. Results demonstrate abnormal cortical presentation of the insula, caudate, postcentral, precuneus and cingulate regions, in agreement with previous literature cortical thickness findings as well as alternative methods such as functional MRI (fMRI) and digital angiography. To the best of our knowledge, this is the first manuscript to report cortical thickness abnormalities in the middle temporal visual area in MMD and the first study to report on cortical thickness variability abnormalities in MMD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21390,""
"The Moral Consideration of Artificial Entities: A Literature Review","Harris, Anthis","https://doi.org/10.1007/s11948-021-00331-8","20211027","PubMed","Artificial intelligence; Ethics; Moral consideration; Philosophy of technology; Rights; Robots; Ethical Theory; Ethicists; Humans; Morals; Problem Solving","Ethicists, policy-makers, and the general public have questioned whether artificial entities such as robots warrant rights or other forms of moral consideration. There is little synthesis of the research on this topic so far. We identify 294 relevant research or discussion items in our literature review of this topic. There is widespread agreement among scholars that some artificial entities could warrant moral consideration in the future, if not also the present. The reasoning varies, such as concern for the effects on artificial entities and concern for the effects on human society. Beyond the conventional consequentialist, deontological, and virtue ethicist ethical frameworks, some scholars encourage ""information ethics"" and ""social-relational"" approaches, though there are opportunities for more in-depth ethical research on the nuances of moral consideration of artificial entities. There is limited relevant empirical data collection, primarily in a few psychological studies on current moral and social attitudes of humans towards robots and other artificial entities. This suggests an important gap for psychological, sociological, economic, and organizational research on how artificial entities will be integrated into society and the factors that will determine how the interests of artificial entities are considered.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21391,""
"Post-Space Treatment Influences the Bond Strength In Endodontically Treated Teeth: A Systematic Review and Meta-Analysis of In Vitro Studies","Bohrer, Fontana, Rocha, Kaizer","https://doi.org/10.2341/19-277-LIT","20211020","PubMed","Dentin; Humans; Lasers, Solid-State; Root Canal Preparation; Smear Layer; Tooth, Nonvital","This systematic review of in vitro studies investigated the influence of the post-space treatment used to remove the smear layer on the bond strength of the post to root canal dentin. In vitro studies included in this study were identified from PubMed/MEDLINE, Lilacs, and Scopus databases up until March 2019, without limits on publication year or language. Two reviewers independently selected the studies based on the inclusion and exclusion criteria, extracted the data, and evaluated the risk of bias of all studies. A random effects model was used for pairwise meta-analyses (control vs. post-space preparation groups) at a significance level of p&lt;0.05. Of the 2,832 potentially eligible studies, 453 studies were selected for full-text analysis, and 75 were included in this systematic review. Only one study was considered to have a low risk of bias. Overall, post-space treatment significantly improves the bond strength to root canal dentin (p&lt;0.00001). Post-space treatment has a positive influence on the bond strength of the post to root canal dentin. In this review, the post-space treatments that improve the adhesive resistance of the post were ethanol, sodium hypochlorite, and ethylene diamine tetra-acetic acid (NaOCl + EDTA), NaOCl + EDTA + ultrasound, erbium-doped yttrium aluminium garnet laser (Er:YAG laser), neodymium-doped yttrium aluminium garnet laser (Nd:YAG laser), and diode laser.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21392,""
"Pharmacological Interventions for the Management of Cancer-Related Fatigue Among Cancer Survivors: Systematic Review and Meta-Analysis","Sun, Chen, Cheung, Wu, Xiao, Chung","https://doi.org/10.1177/15347354211038008","20211011","PubMed","cancer survivors; drug therapy; fatigue; meta-analysis; systematic review; Cancer Survivors; Fatigue; Humans; Neoplasms; Quality of Life","Current guidelines have different recommendations on applying pharmacological interventions for managing cancer-related fatigue (CRF) among cancer survivors. This systematic review aims to synthesize clinical evidence on pharmacological interventions for managing CRF. Five databases were searched for potential randomized controlled trials (RCTs) from their inception until October 2020. RCTs assessing the effect of pharmacological treatments for CRF among cancer survivors were considered eligible. Clinical significance was determined by comparing the estimated effect with that of minimal important difference (MID). The risk of bias of each included RCT was appraised using the Cochrane risk of bias tool for randomized trials 2. Data were synthesized using random-effect pairwise meta-analyses. A total of 15 RCTs (1238 participants) were included. The majority presented some concerns of bias arising from the randomization process and selection of the reported results. Meta-analysis showed that psychostimulant and wakefulness agents had statistically significant while clinically insignificant effects on the treatment of CRF (pooled weighted mean difference [WMD]: 2.8, 95% confidence interval [CI]: 0.2-5.4, <i>I</i><sup>2</sup>: 0%, 3 RCTs, MID: 3.0-6.0). Three natural products, including Renshen Yangrong Tang (mean difference [MD]: -16.1, 95% CI: -8.9 to -23.3, MID: -17.3 to -11.4), Tualang honey (MD: 11.2, 95% CI: 7.1-15.3, MID: 3.0-6.0), and Shenmai injection plus Peptisorb (MD: -1.6, 95% CI: -2.1 to -1.1, MID: -1.1 to -0.8) demonstrated statistically and clinically significant effect in reducing CRF. Existing evidence showed promising effects of 3 natural products in reducing CRF among cancer survivors. The results from this study need to be further confirmed with well-designed and adequately powered RCTs that use validated instruments for the measurement of CRF.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21393,""
"Deep fusion learning facilitates anatomical therapeutic chemical recognition in drug repurposing and discovery","Wang, Liu, Zhang, He, Qin, Li, Lu","https://doi.org/10.1093/bib/bbab289","20210809","PubMed","anatomical therapeutic; chemical classification; convolutional neural network; deep fusion; drug discovery; drug repurposing; learning graph","The advent of large-scale biomedical data and computational algorithms provides new opportunities for drug repurposing and discovery. It is of great interest to find an appropriate data representation and modeling method to facilitate these studies. The anatomical therapeutic chemical (ATC) classification system, proposed by the World Health Organization (WHO), is an essential source of information for drug repurposing and discovery. Besides, computational methods are applied to predict drug ATC classification. We conducted a systematic review of ATC computational prediction studies and revealed the differences in data sets, data representation, algorithm approaches, and evaluation metrics. We then proposed a deep fusion learning (DFL) framework to optimize the ATC prediction model, namely DeepATC. The methods based on graph convolutional network, inferring biological network and multimodel attentive fusion network were applied in DeepATC to extract the molecular topological information and low-dimensional representation from the molecular graph and heterogeneous biological networks. The results indicated that DeepATC achieved superior model performance with area under the curve (AUC) value at 0.968. Furthermore, the DFL framework was performed for the transcriptome data-based ATC prediction, as well as another independent task that is significantly relevant to drug discovery, namely drug-target interaction. The DFL-based model achieved excellent performance in the above-extended validation task, suggesting that the idea of aggregating the heterogeneous biological network and node's (molecule or protein) self-topological features will bring inspiration for broader drug repurposing and discovery research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21394,""
"Fatigue prevalence in men treated for prostate cancer: A systematic review and meta-analysis","Luo, Yang, Wu, Wang, Li, Zhang","https://doi.org/10.12998/wjcc.v9.i21.5932","20210810","PubMed","Fatigue; Meta-analysis; Prevalence; Prostate cancer; Systematic review","The side effects of prostate cancer (PCa) treatment are very prominent, with cancer-related fatigue (CRF) being the most common. Fatigue is a distressing symptom that interferes with daily functioning and seriously affects patient quality of life during, and for many years after, treatment. However, compared with other types of cancer, such as breast cancer, little is known about the prevalence of PCa-related fatigue. To determine the prevalence of CRF in patients with PCa. A systematic search of EMBASE, PubMed, Web of Science, Cochrane Library, Chinese National Knowledge Infrastructure, WANFANG DATA, Technology Journal Database and the Chinese Biological Medical Database was conducted up to July 28, 2020. Included studies measured the incidence of PCa-related fatigue and differentiated fatigue outcomes (incidence) between treatment modalities and fatigue assessment times. In our meta-analysis, both fixed and random-effects models were used to estimate the pooled prevalence of PCa-related fatigue. Subgroup analyses were performed using treatment modalities and fatigue assessment times. Publication and sensitivity bias analyses were performed to test the robustness of the associations. Fourteen studies, involving 4736 patients, were eligible for the review. The pooled CRF prevalence was 40% in a total sample of 4736 PCa patients [95% confidence interval (CI): 29-52; <i>P</i> &lt; 0.01; <i>I</i> <sup>2</sup> = 98%]. The results of the subgroup analyses showed the prevalence of CRF after androgen deprivation therapy treatment, radical prostatectomy and radiotherapy to be 42% (95%CI: 20-67, <i>P</i> &lt; 0.01, <i>I</i> <sup>2</sup> = 91%), 21% (95%CI: 16-26, <i>P</i> = 0.87, <i>I</i> <sup>2</sup> = 0%) and 40% (95%CI: 22-58, <i>P</i> &lt; 0.01, <i>I</i> <sup>2</sup> = 90%), respectively. The prevalence of acute and persistent fatigue was 44% (95%CI: 25-64; <i>P</i> &lt; 0.01; <i>I</i> <sup>2</sup> = 93%) and 29% (95%CI: 25-32; <i>P</i> = 0.30; <i>I</i> <sup>2</sup> = 17%), respectively. Our meta-analysis showed that fatigue is a common symptom in men with PCa, especially those using hormone therapy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21395,""
"Artificial Intelligence in the Imaging of Gastric Cancer: Current Applications and Future Direction","Qin, Deng, Jiang, Hu, Song","https://doi.org/10.3389/fonc.2021.631686","20210810","PubMed","artificial intelligence; clinical applications and challenges; deep learning; gastric cancer; hand-crafted radiomics; methodologies","Gastric cancer (GC) is one of the most common cancers and one of the leading causes of cancer-related death worldwide. Precise diagnosis and evaluation of GC, especially using noninvasive methods, are fundamental to optimal therapeutic decision-making. Despite the recent rapid advancements in technology, pretreatment diagnostic accuracy varies between modalities, and correlations between imaging and histological features are far from perfect. Artificial intelligence (AI) techniques, particularly hand-crafted radiomics and deep learning, have offered hope in addressing these issues. AI has been used widely in GC research, because of its ability to convert medical images into minable data and to detect invisible textures. In this article, we systematically reviewed the methodological processes (data acquisition, lesion segmentation, feature extraction, feature selection, and model construction) involved in AI. We also summarized the current clinical applications of AI in GC research, which include characterization, differential diagnosis, treatment response monitoring, and prognosis prediction. Challenges and opportunities in AI-based GC research are highlighted for consideration in future studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21396,""
"Gene Mutation Classification through Text Evidence Facilitating Cancer Tumour Detection","Gupta, Wu, Arora, Gupta, Chaudhary, Hua","https://doi.org/10.1155/2021/8689873","20210810","PubMed","","A cancer tumour consists of thousands of genetic mutations. Even after advancement in technology, the task of distinguishing genetic mutations, which act as driver for the growth of tumour with passengers (Neutral Genetic Mutations), is still being done manually. This is a time-consuming process where pathologists interpret every genetic mutation from the clinical evidence manually. These clinical shreds of evidence belong to a total of nine classes, but the criterion of classification is still unknown. The main aim of this research is to propose a multiclass classifier to classify the genetic mutations based on clinical evidence (i.e., the text description of these genetic mutations) using Natural Language Processing (NLP) techniques. The dataset for this research is taken from Kaggle and is provided by the Memorial Sloan Kettering Cancer Center (MSKCC). The world-class researchers and oncologists contribute the dataset. Three text transformation models, namely, CountVectorizer, TfidfVectorizer, and Word2Vec, are utilized for the conversion of text to a matrix of token counts. Three machine learning classification models, namely, Logistic Regression (LR), Random Forest (RF), and XGBoost (XGB), along with the Recurrent Neural Network (RNN) model of deep learning, are applied to the sparse matrix (keywords count representation) of text descriptions. The accuracy score of all the proposed classifiers is evaluated by using the confusion matrix. Finally, the empirical results show that the RNN model of deep learning has performed better than other proposed classifiers with the highest accuracy of 70%.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21397,""
"Immune2vec: Embedding B/T Cell Receptor Sequences in Ã¢â€žÂ <i><sup>N</sup></i> Using Natural Language Processing","Ostrovsky-Berman, Frankel, Polak, Yaari","https://doi.org/10.3389/fimmu.2021.680687","20211026","PubMed","BCR repertoire; NLP; biological sequence embedding; computational immunology; word2vec; Algorithms; Animals; Computational Biology; Gene Rearrangement, B-Lymphocyte; Gene Rearrangement, T-Lymphocyte; High-Throughput Nucleotide Sequencing; Humans; Natural Language Processing; Receptors, Antigen, B-Cell; Receptors, Antigen, T-Cell; Software; Workflow","The adaptive branch of the immune system learns pathogenic patterns and remembers them for future encounters. It does so through dynamic and diverse repertoires of T- and B- cell receptors (TCR and BCRs, respectively). These huge immune repertoires in each individual present investigators with the challenge of extracting meaningful biological information from multi-dimensional data. The ability to embed these DNA and amino acid textual sequences in a vector-space is an important step towards developing effective analysis methods. Here we present Immune2vec, an adaptation of a natural language processing (NLP)-based embedding technique for BCR repertoire sequencing data. We validate Immune2vec on amino acid 3-gram sequences, continuing to longer BCR sequences, and finally to entire repertoires. Our work demonstrates Immune2vec to be a reliable low-dimensional representation that preserves relevant information of immune sequencing data, such as n-gram properties and IGHV gene family classification. Applying Immune2vec along with machine learning approaches to patient data exemplifies how distinct clinical conditions can be effectively stratified, indicating that the embedding space can be used for feature extraction and exploratory data analysis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21398,""
"An Ensemble Matrix Completion Model for Predicting Potential Drugs Against SARS-CoV-2","Li, Wang, Xu","https://doi.org/10.3389/fmicb.2021.694534","20210810","PubMed","SARS-CoV-2; computational drug repurposing; matrix completion; virus-drug association prediction; weighted voting ensemble model","Because of the catastrophic outbreak of global coronavirus disease 2019 (COVID-19) and its strong infectivity and possible persistence, computational repurposing of existing approved drugs will be a promising strategy that facilitates rapid clinical treatment decisions and provides reasonable justification for subsequent clinical trials and regulatory reviews. Since the effects of a small number of conditionally marketed vaccines need further clinical observation, there is still an urgent need to quickly and effectively repurpose potentially available drugs before the next disease peak. In this work, we have manually collected a set of experimentally confirmed virus-drug associations through the publicly published database and literature, consisting of 175 drugs and 95 viruses, as well as 933 virus-drug associations. Then, because the samples are extremely sparse and unbalanced, negative samples cannot be easily obtained. We have developed an ensemble model, EMC-Voting, based on matrix completion and weighted soft voting, a semi-supervised machine learning model for computational drug repurposing. Finally, we have evaluated the prediction performance of EMC-Voting by fivefold crossing-validation and compared it with other baseline classifiers and prediction models. The case study for the virus SARS-COV-2 included in the dataset demonstrates that our model achieves the outperforming AUPR value of 0.934 in virus-drug association's prediction.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21399,""
"The Probability of Lung Cancer in Patients With Incidentally Detected Pulmonary Nodules: Clinical Characteristics and Accuracy of Prediction Models","Vachani, Zheng, Amy Liu, Huang, Osuji, Gould","https://doi.org/10.1016/j.chest.2021.07.2168","20210906","PubMed","clinical prediction models; lung cancer; non-small cell lung cancer; pulmonary nodule","The frequency of cancer and accuracy of prediction models have not been studied in large, population-based samples of patients with incidental pulmonary nodules measuring &gt; 8Ã‚Â mm in diameter. How does the frequency of cancer vary by size and smoking history among patients with incidental nodules? How accurate are two widely used models for identifying cancer in these patients? We assembled a retrospective cohort of individuals with incidental nodules measuring &gt; 8Ã‚Â mm in diameter identified by chest CT imaging between 2006 and 2016. We used a validated natural language processing algorithm to identify nodules and their characteristics by scanning the text of dictated radiology reports. We reported patient and nodule characteristics stratified by the presence or absence of a lung cancer diagnosis within 27Ã‚Â months of nodule identification and estimated the area under the receiver operating characteristic curve (AUC) to compare the accuracy of the Mayo Clinic and Brock models for identifying cancer. The sample included 23,780 individuals with a nodule measuring &gt; 8Ã‚Â mm, including 2,356 patients (9.9%) with a lung cancer diagnosis within 27Ã‚Â months of nodule identification. Cancer was diagnosed in 5.4%Ã‚Â of never smokers, 12.2%Ã‚Â of former smokers, and 17.7%Ã‚Â of current smokers. Cancer was diagnosed in 5.7%Ã‚Â of patients with nodules measuring 9 to 15Ã‚Â mm, 12.1%Ã‚Â of patients with nodules &gt; 15 to 20Ã‚Â mm, and 18.4%Ã‚Â of patients with nodules &gt; 20 to 30Ã‚Â mm. In the full sample, the Mayo Clinic model (AUC, 0.747; 95%Ã‚Â CI, 0.737-0.757) was more accurate than the Brock model (AUC, 0.713; 95%Ã‚Â CI, 0.702-0.724; PÃ‚Â &lt; .0001). When restricted to ever smokers, the Mayo Clinic model was still more accurate. Both models overestimated the probability of cancer. Almost 10%Ã‚Â of patients with an incidental pulmonary nodule measuring &gt; 8Ã‚Â mm in diameter will receive a lung cancer diagnosis. Existing prediction models have only fair accuracy and overestimate the probability of cancer.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21400,""
"Computer-aided detection versus advanced imaging for detection of colorectal neoplasia: a systematic review and network meta-analysis","Spadaccini, Iannone, Maselli, Badalamenti, Desai, Chandrasekar, Patel, Fugazza, Pellegatta, Galtieri, Lollo, Carrara, Anderloni, Rex, Savevski, Wallace, Bhandari, Roesch, Gralnek, Sharma, Hassan, Repici","https://doi.org/10.1016/S2468-1253(21)00215-6","20211001","PubMed","Adenoma; Artificial Intelligence; Colonoscopy; Colorectal Neoplasms; Diagnostic Imaging; Endoscopy, Digestive System; Female; Humans; Image Processing, Computer-Assisted; Male; Network Meta-Analysis; Randomized Controlled Trials as Topic","Computer-aided detection (CADe) techniques based on artificial intelligence algorithms can assist endoscopists in detecting colorectal neoplasia. CADe has been associated with an increased adenoma detection rate, a key quality indicator, but the utility of CADe compared with existing advanced imaging techniques and distal attachment devices is unclear. For this systematic review and network meta-analysis, we did a comprehensive search of PubMed/Medline, Embase, and Scopus databases from inception to Nov 30, 2020, for randomised controlled trials investigating the effectiveness of the following endoscopic techniques in detecting colorectal neoplasia: CADe, high definition (HD) white-light endoscopy, chromoendoscopy, or add-on devices (ie, systems that increase mucosal visualisation, such as full spectrum endoscopy [FUSE] or G-EYE balloon endoscopy). We collected data on adenoma detection rates, sessile serrated lesion detection rates, the proportion of large adenomas detected per colonoscopy, and withdrawal times. A frequentist framework, random-effects network meta-analysis was done to compare artificial intelligence with chromoendoscopy, increased mucosal visualisation systems, and HD white-light endoscopy (the control group). We estimated odds ratios (ORs) for the adenoma detection rate, sessile serrated lesion detection rate, and proportion of large adenomas detected per colonoscopy, and calculated mean differences for withdrawal time, with 95% CIs. Risk of bias and certainty of evidence were assessed with the Grading of Recommendations Assessment, Development and Evaluation (GRADE) approach. 50 randomised controlled trials, comprising 34Ã¢â‚¬â€°445 participants, were included in our main analysis (six trials of CADe, 18 of chromoendoscopy, and 26 of increased mucosal visualisation systems). HD white-light endoscopy was the control technique in all 50 studies. Compared with the control technique, the adenoma detection rate was 7Ã‚Â·4% higher with CADe (OR 1Ã‚Â·78 [95% CI 1Ã‚Â·44-2Ã‚Â·18]), 4Ã‚Â·4% higher with chromoendoscopy (1Ã‚Â·22 [1Ã‚Â·08-1Ã‚Â·39]), and 4Ã‚Â·1% higher with increased mucosal visualisation systems (1Ã‚Â·16 [1Ã‚Â·04-1Ã‚Â·28]). CADe ranked as the superior technique for adenoma detection (with moderate confidence in hierarchical ranking); cross-comparisons of CADe with other imaging techniques showed a significant increase in the adenoma detection rate with CADe versus increased mucosal visualisation systems (OR 1Ã‚Â·54 [95% CI 1Ã‚Â·22-1Ã‚Â·94]; low certainty of evidence) and with CADe versus chromoendoscopy (1Ã‚Â·45 [1Ã‚Â·14-1Ã‚Â·85]; moderate certainty of evidence). When focusing on large adenomas (Ã¢â€°Â¥10 mm) there was a significant increase in the detection of large adenomas only with CADe (OR 1Ã‚Â·69 [95% CI 1Ã‚Â·10-2Ã‚Â·60], moderate certainty of evidence) when compared to HD white-light endoscopy; CADe ranked as the superior strategy for detection of large adenomas. CADe also seemed to be the superior strategy for detection of sessile serrated lesions (with moderate confidence in hierarchical ranking), although no significant increase in the sessile serrated lesion detection rate was shown (OR 1Ã‚Â·37 [95% CI 0Ã‚Â·65-2Ã‚Â·88]). No significant difference in withdrawal time was reported for CADe compared with the other techniques. Based on the published literature, detection rates of colorectal neoplasia are higher with CADe than with other techniques such as chromoendoscopy or tools that increase mucosal visualisation, supporting wider incorporation of CADe strategies into community endoscopy services. None.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21401,""
"Cutaneous myiasis in skin cancer and malignant wounds: a systematic review","Cuestas, Pedraza, Herrera, Motta, Cuestas, Forero, Porras, Urrea, Galvis, Galvis, Bernal, Alvarado, Bula, Velasquez, Villalba, Lamus, Ariza, Bayona, Gutierrez, Segura, PatiÃƒÂ±o, Perafan, Ramirez-Rodriguez, Rolon","https://doi.org/10.1111/ijd.15672","20210807","PubMed","","Cutaneous myiasis in patients with malignant wounds or skin cancer is a rare and undesirable event with limited epidemiological data. A subregister of reports, lack of education in the population, inadequate empirical treatments, and medical underestimation are components of a public health problem that threatens patients' lives. We conducted a systematic review of the literature of cutaneous myiasis associated with malignant wounds and skin cancer, characterizing sociodemographic variables, risk factors, clinical and histological features, and treatment. Additionally, we present a demonstrative case with the adequate taxonomic evaluation. Cutaneous myiasis is an underestimated and poorly managed infestation, which can generate severe complications in oncological patients. This is the first systematic review in the literature about this clinical scenario, which provides information to the physician and clinical researcher about the epidemiological gaps and what has been published so far. Findings from the current review have helped to display the sociodemographic, epidemiological, and clinical behavior of myiasis in skin cancer and malignant wounds. Its contribution to the greater tumor tissue destruction is clear; however, more studies are required. The therapeutic management in these patients is equally clarified.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21402,""
"Alginate scaffolds improve functional recovery after spinal cord injury","Jahandideh, Noori, Rahimi, Hamblin, Behroozi, Ramezani, Ramezani","https://doi.org/10.1007/s00068-021-01760-7","20210807","PubMed","Alginate; Functional recovery; Scaffold; Spinal cord injury","In this systematic review and meta-analysis, the use of alginate for the repair of the damaged spinal cord was investigated. After an extensive search of databases including MEDLINE, SCOPUS, EMBASE and Web of Science, an initial screening was performed based on inclusion and exclusion criteria. The full text of related articles was reviewed and data mining was performed. Data were analyzed by calculating the mean of ratios between treated and untreated groups using STATA software. Subgroup analysis was also performed due to heterogeneity. Articles were subjected to quality control and PRISMA guidelines were followed. Twelve studies and 17 experiments were included in the study. After SCI, alginate hydrogel had a moderate effect on motor function recovery (SMDÃ¢â‚¬â€°=Ã¢â‚¬â€°0.64; 95% CI 0.28-1.00; p &lt;Ã¢â‚¬â€°0.0001) and alginate scaffolds loaded with drugs, growth factors, or cells on the SCI group compared with untreated SCI animals showed has a strong effect in the treatment of SCI (SMDÃ¢â‚¬â€°=Ã¢â‚¬â€°2.82; 95% CI 1.49-4.145; pÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.0001). Treatment with drug/cell in combination with alginate was more strongly significant compared to the groups treated with drug/cell alone (SMDÃ¢â‚¬â€°=Ã¢â‚¬â€°4.55; 95% CI 1.42-7.69; pÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.0001). Alginate alone or in combination therapy when used as an implant, had a more significant effect than injection. These findings suggest that alginate is an efficient scaffold for functional recovery and even a much better scaffold for drug/cell delivery after SCI.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21403,""
"Automatic airway segmentation from computed tomography using robust and efficient 3-D convolutional neural networks","Garcia-Uceda, Selvan, Saghir, Tiddens, de Bruijne","https://doi.org/10.1038/s41598-021-95364-1","20211012","PubMed","","This paper presents a fully automatic and end-to-end optimised airway segmentation method for thoracic computed tomography, based on the U-Net architecture. We use a simple and low-memory 3D U-Net as backbone, which allows the method to process large 3D image patches, often comprising full lungs, in a single pass through the network. This makes the method simple, robust and efficient. We validated the proposed method on three datasets with very different characteristics and various airway abnormalities: (1) a dataset of pediatric patients including subjects with cystic fibrosis, (2) a subset of the Danish Lung Cancer Screening Trial, including subjects with chronic obstructive pulmonary disease, and (3) the EXACT'09 public dataset. We compared our method with other state-of-the-art airway segmentation methods, including relevant learning-based methods in the literature evaluated on the EXACT'09 data. We show that our method can extract highly complete airway trees with few false positive errors, on scans from both healthy and diseased subjects, and also that the method generalizes well across different datasets. On the EXACT'09 test set, our method achieved the second highest sensitivity score among all methods that reported good specificity.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21404,""
"Overview of therapeutic potentiality of Angelica sinensis for ischemic stroke","Han, Chen, Zhang, Liu, Yang, Xu, Zhao","https://doi.org/10.1016/j.phymed.2021.153652","20210929","PubMed","Angelica sinensis; Ischemic Stroke; Mechanisms; Therapeutic effects; Angelica sinensis; Brain Ischemia; Drugs, Chinese Herbal; Humans; Ischemic Stroke","Ischemic stroke is a common cerebrovascular disease. Due to sudden interruption of blood flow by arterial thrombus, amounts of neurons in ischemic central and penumbral regions occur necrosis and apoptosis resulting in serious injury of neurological function. Chinese medicines have a great advantage in ischemic stroke treatment and recovery, especially Angelica sinensis. There are a large number of studies reported that Angelica injection and A. sinensis active compounds. We systematically reviewed the effects and mechanisms of A. sinensis in recent years according to the guidelines of the Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) statements, and excavated its therapeutic potentiality for exploring more effective and safe compounds for ischemic stroke precision treatment. A. sinensis extracts and active compounds, such as Z-ligustilide, 3-n-Butylphthalide, and ferulic acid have significant effects of anti-inflammation, anti-oxidative stress, angiogenesis, neurogenesis, anti-platelet aggregation, anti-atherosclerosis, protection of vessels, which contributes to improvement of neurological function on ischemic stroke. A. sinensis is a key agent for ischemic stroke treatment, and worth deeply excavating its therapeutic potentiality with the aid of pharmacological network, computer-aided drug design, artificial intelligence, big data and multi-scale modelling techniques.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21405,""
"A Machine Learning Tool to Predict the Antibacterial Capacity of Nanoparticles","Mirzaei, Furxhi, Murphy, Mullins","https://doi.org/10.3390/nano11071774","20210809","PubMed","antibacterial effect; antimicrobial capacity; biofilm; machine learning; nanoparticles","The emergence and rapid spread of multidrug-resistant bacteria strains are a public health concern. This emergence is caused by the overuse and misuse of antibiotics leading to the evolution of antibiotic-resistant strains. Nanoparticles (NPs) are objects with all three external dimensions in the nanoscale that varies from 1 to 100 nm. Research on NPs with enhanced antimicrobial activity as alternatives to antibiotics has grown due to the increased incidence of nosocomial and community acquired infections caused by pathogens. Machine learning (ML) tools have been used in the field of nanoinformatics with promising results. As a consequence of evident achievements on a wide range of predictive tasks, ML techniques are attracting significant interest across a variety of stakeholders. In this article, we present an ML tool that successfully predicts the antibacterial capacity of NPs while the model's validation demonstrates encouraging results (<i>R</i><sup>2</sup> = 0.78). The data were compiled after a literature review of 60 articles and consist of key physico-chemical (p-chem) properties and experimental conditions (exposure variables and bacterial clustering) from in vitro studies. Following data homogenization and pre-processing, we trained various regression algorithms and we validated them using diverse performance metrics. Finally, an important attribute evaluation, which ranks the attributes that are most important in predicting the outcome, was performed. The attribute importance revealed that NP core size, the exposure dose, and the species of bacterium are key variables in predicting the antibacterial effect of NPs. This tool assists various stakeholders and scientists in predicting the antibacterial effects of NPs based on their p-chem properties and diverse exposure settings. This concept also aids the safe-by-design paradigm by incorporating functionality tools.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21406,""
"Transcriptomic Hallmarks of Ischemia-Reperfusion Injury","Movahed, Brockie, Hong, Fehlings","https://doi.org/10.3390/cells10071838","20211027","PubMed","RNA-seq; ischemia reperfusion injury; transcriptomics; Animals; Cardiovascular Agents; Cell- and Tissue-Based Therapy; Cerebral Cortex; Gene Expression Profiling; Gene Expression Regulation; Gene Ontology; Gene Regulatory Networks; Humans; Ischemic Postconditioning; Ischemic Preconditioning; Kidney; Liver; Metabolic Networks and Pathways; Mice; Molecular Sequence Annotation; Myocardium; NF-kappa B; Rats; Reperfusion Injury; Sequence Analysis, RNA; Signal Transduction; Spinal Cord; Transcriptome; Tumor Necrosis Factor-alpha","Ischemia reperfusion injury (IRI) is associated with a broad array of life-threatening medical conditions including myocardial infarct, cerebral stroke, and organ transplant. Although the pathobiology and clinical manifestations of IRI are well reviewed by previous publications, IRI-related transcriptomic alterations are less studied. This study aimed to reveal a transcriptomic hallmark for IRI by using the RNA-sequencing data provided by several studies on non-human preclinical experimental models. In this regard, we focused on the transcriptional responses of IRI in an acute time-point up to 48 h. We compiled a list of highly reported genes in the current literature that are affected in the context of IRI. We conducted Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analyses and found many of the up-regulated genes to be involved in cell survival, cell surface signaling, response to oxidative stress, and inflammatory response, while down-regulated genes were predominantly involved in ion transport. Furthermore, by GO analysis, we found that multiple inflammatory and stress response processes were affected after IRI. Tumor necrosis factor alpha (TNF) and nuclear factor kappa-light-chain-enhancer of activated B cells (NF-ÃŽÂºB) signaling pathways were also highlighted in the Kyoto Encyclopedia of Genes and Genomes enrichment analysis. In the last section, we discuss the treatment approaches and their efficacy for IRI by comparing RNA sequencing data from therapeutic interventions with the results of our cross-comparison of differentially expressed genes and pathways across IRI.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21407,""
"Predictive Design Model for Low-Dimensional Organic-Inorganic Halide Perovskites Assisted by Machine Learning","Lyu, Moore, Liu, Yu, Wu","https://doi.org/10.1021/jacs.1c05441","20210818","PubMed","","Low-dimensional organic-inorganic halide perovskites have attracted interest for their properties in exciton dynamics, broad-band emission, magnetic spin selectivity. However, there is no quantitative model for predicting the structure-directing effect of organic cations on the dimensionality of these low-dimensional perovskites. Here, we report a machine learning (ML)-assisted approach to predict the dimensionality of lead iodide-based perovskites. A literature review reveals 86 reported amines that are classified into ""2D""-forming and ""non-2D""-forming based on the dimensionality of their perovskites. Machining learning models were trained and tested based on the classification and descriptor features of these ammonium cations. Four structural features, including steric effect index, eccentricity, largest ring size, and hydrogen-bond donor, have been identified as the key controlling factors. On the basis of these features, a quantified equation is created to calculate the probability of forming 2D perovskite for a selected amine. To further illustrate its predicting capability, the built model is applied to several untested amines, and the predicted dimensionality is verified by growing single crystals of perovskites from these amines. This work represents a step toward predicting the crystal structures of low dimensional hybrid halide perovskites using ML as a tool.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21408,""
"A Genomic Approach to Delineating the Occurrence of Scoliosis in Arthrogryposis Multiplex Congenita","Latypova, Creadore, Dahan-Oliel, Gustafson, Wei-Hung Hwang, Bedard, Shazand, van Bosse, Giampietro, Dieterich","https://doi.org/10.3390/genes12071052","20211015","PubMed","Amyoplasia; CNV (copy number variant); DA (distal arthrogryposis); DECIPHER (DatabasE of genomiC variation and Phenotype in Humans using Ensemble Resources); HPO (human phenotype ontology); IGF2; IPA (ingenuity pathway analysis); MYOD; akinesia; scoliosis","Arthrogryposis multiplex congenita (AMC) describes a group of conditions characterized by the presence of non-progressive congenital contractures in multiple body areas. Scoliosis, defined as a coronal plane spine curvature of Ã¢â€°Â¥10 degrees as measured radiographically, has been reported to occur in approximately 20% of children with AMC. To identify genes that are associated with both scoliosis as a clinical outcome and AMC, we first queried the DECIPHER database for copy number variations (CNVs). Upon query, we identified only two patients with both AMC and scoliosis (AMC-SC). The first patient contained CNVs in three genes (<i>FBN2</i>, <i>MGF10</i>, and <i>PITX1)</i>, while the second case had a CNV in <i>ZC4H2</i>. Looking into small variants, using a combination of Human Phenotype Ontogeny and literature searching, 908 genes linked with scoliosis and 444 genes linked with AMC were identified. From these lists, 227 genes were associated with AMC-SC. Ingenuity Pathway Analysis (IPA) was performed on the final gene list to gain insight into the functional interactions of genes and various categories. To summarize, this group of genes encompasses a diverse group of cellular functions including transcription regulation, transmembrane receptor, growth factor, and ion channels. These results provide a focal point for further research using genomics and animal models to facilitate the identification of prognostic factors and therapeutic targets for AMC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21409,""
"Placebo response and its predictors in Attention Deficit Hyperactivity Disorder: a meta-analysis and comparison of meta-regression and MetaForest","Castells, Saez, Barcheni, Cunill, Serrano, LÃƒÂ³pez, van Lissa","https://doi.org/10.1093/ijnp/pyab054","20210806","PubMed","Attention Deficit Hyperactivity Disorder; MetaForest; machine learning; meta-analysis; meta-regression; placebo response","High placebo response in ADHD can reduce medication-placebo differences, jeopardizing the development of new medicines. This research aims to 1) determine placebo response in ADHD, 2) compare the accuracy of meta-regression and MetaForest in predicting placebo response, and 3) determine the covariates associated with placebo response. A systematic review with meta-analysis (SRMA) of RPCCTs investigating pharmacological interventions for ADHD was performed. Placebo response was defined as the change from baseline in ADHD symptom severity assessed according to the 18-item, clinician-rated, DSM-based rating scale. The effect of study design-, intervention- and patient-related covariates in predicting placebo response was studied by means of meta-regression and MetaForest. Ninety-four studies including 6,614 patients randomized to placebo were analysed. Overall, placebo response was -8.9 points, representing a 23.1% reduction in the severity of ADHD symptoms. Cross-validated accuracy metrics for meta-regression were R 2 = 0.0012 and RMSE = 3.3219 for meta-regression and 0.0382 and 3.2599 for MetaForest. Placebo response amongst ADHD patients increased by 63% between 2001 and 2020 and was larger in the US than in other regions of the world. Strong placebo response was found in ADHD patients. Both meta-regression and MetaForest showed poor performance in predicting placebo response. ADHD symptom improvement with placebo has markedly increased over the last two decades and is grater in the US than the rest of the world.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21410,""
"HIV-1 molecular epidemiology in Bangladesh: A systematic review","Molla, Yeasmin, Ghosh, Nafisa, Islam, Saif-Ur-Rahman","https://doi.org/10.1002/hsr2.344","20210807","PubMed","Bangladesh; HIVÃ¢â‚¬Â1; molecular epidemiology; prevalence; subtypes; systematic review","It is postulated that molecular methods along with mathematical modeling can provide critical inference regarding epidemiological parameters, transmission dynamics, spatiotemporal characteristics, and intervention efficacy. Hence, studying molecular epidemiology of human immunodeficiency virus (HIV)-1 infection, especially in resource-limited settings and with a large diaspora of the migrant population such as that of Bangladesh, is of paramount importance. The purpose of this systematic review was to concisely present and discuss the findings from previous studies conducted in Bangladesh regarding HIV-1 subtype prevalence. Articles were retrieved from six publicly available databases regarding HIV-1 molecular epidemiology using keywords HIV, HIV-1, subtype(s), Bangladesh, and any combination of aforementioned keywords using Boolean operators. A total of 14 articles were downloaded and screened for suitability. Finally, five studies, containing pooled sequences from 317 individuals, were included in this systematic review. Results revealed a preponderance of subtype C among HIV-1 infected population (51.10%), followed by circulating recombinant form (CRF)_07BC (15.46%), CRF_01AE (5.68%), A1 (4.73%), CRF_02AG (3.47%), G (3.15%), CRF_62BC (2.84%), B (2.21%), and other subtypes and recombinant forms in small percentages. Subtype C was largely predominant in intravenous drug users as well as female sex workers, whereas the migrant population exhibited a diverse subtype including rare recombinant forms, largely due to their travel in the Middle East and other South East Asian countries. With the number of HIV-1 infections increasing among the general population and a steady increase in the migrant population, molecular epidemiological data are required to curb the progression of the HIV-1 epidemic in Bangladesh.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21411,""
"ACO2 clinicobiological dataset with extensive phenotype ontology annotation","Guehlouz, Foulonneau, Amati-Bonneau, Charif, Colin, Bris, Desquiret-Dumas, Milea, Gohier, Procaccio, Bonneau, den Dunnen, Lenaers, Reynier, FerrÃƒÂ©","https://doi.org/10.1038/s41597-021-00984-x","20210821","PubMed","","Pathogenic variants of the aconitaseÃ‚Â 2 gene (ACO2) are responsible for a broad clinical spectrum involving optic nerve degeneration, ranging from isolated optic neuropathy with recessive or dominant inheritance, to complex neurodegenerative syndromes with recessive transmission. We created the first public locus-specific database (LSDB) dedicated to ACO2 within the ""Global Variome shared LOVD"" using exclusively the Human Phenotype Ontology (HPO), a standard vocabulary for describing phenotypic abnormalities. All the variants and clinical cases listed in the literature were incorporated into the database, from which we produced a dataset. We followed a rational and comprehensive approach based on the HPO thesaurus, demonstrating that ACO2 patients should not be classified separately between isolated and syndromic cases. Our data highlight that certain syndromic patients do not have optic neuropathy and provide support for the classification of the recurrent pathogenic variants c.220C&gt;G and c.336C&gt;G as likely pathogenic. Overall, our data records demonstrate that the clinical spectrum of ACO2 should be considered as a continuum of symptoms and refines the classification of some common variants.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21412,""
"An update on cancer-related fatigue in older adults: A narrative review","Soones, Ombres, Escalante","https://doi.org/10.1016/j.jgo.2021.07.006","20210806","PubMed","Cancer-related fatigue; Non-pharmacologic interventions; Pharmacologic interventions","Up to 70% of older adults report fatigue after a cancer diagnosis. For many of these patients, cancer-related fatigue (CRF) persists for years after cancer treatment and is associated with significant disability. Despite this, little has been written on the diagnosis and management of CRF in older adults. To address this gap, we performed a narrative review of the literature on CRF in older adults and used literature from the general population when evidence was lacking to provide guidance to clinical providers on how to tailor care to this population. We recommend evidence-based options for evaluating CRF and address their limitations in the assessment of older adults. We also provide guidance and a treatment algorithm on evaluating CRF using the Comprehensive Geriatrics Assessment. Lastly, we present evidence for the use of non-pharmacologic and pharmacologic therapies in the management of CRF in older adults.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21413,""
"Comparative efficacy of single-inhaler triple therapies for COPD: A protocol for systematic review and network meta-analysis","Jiang, Hu, Leung","https://doi.org/10.1371/journal.pone.0255545","20211008","PubMed","","2021 Global Initiative for Chronic Obstructive Lung Disease (GOLD) Reports recommends that patients with clinically significant symptoms and exacerbations of chronic obstructive pulmonary disease (COPD) should escalate to triple therapy, a combined use of inhaled corticosteroids (ICS), long-acting muscarinic antagonists (LAMA) and long-acting b2-agonists (LABA)(ICS/LAMA/LABA). Triple therapy in fixed-dose combinations (FDCs), i.e., combining ICS, LABA with LAMA and administrating by a single inhalation device, has appeared in recent years. This study aims to compare the efficacy of triple therapy in FDCs in treating patients with moderate to severe COPD. Literature search will be conducted on PubMed, Embase and Web of science, according to pre-specified and corresponding search strategies, for relevant reports published since the inception dates of the databases. Randomised controlled trials (RCT) which compared the triple therapy in FDCs with other pharmacological therapies will be included. The Cochrane risk of bias assessment tool (RoB 2) will be used to assess the RCT quality. The outcomes will be analyzed as rate ratios and mean differences under a random-effects model in a frequentist network meta-analysis (NMA). Additional statistical analyses including subgroup analysis, sensitivity analysis, and publication bias analysis will be performed to assess the evidential heterogeneity and robustness. The strength of evidence from the NMA will be evaluated with the Grading of Recommendation, Assessment, Development and Evaluation (GRADE) methods. No ethics approval is required as this systematic review and network meta-analysis do not collect confidential personal data and do not carry out interventions in treating patients. CRD42021240823.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21414,""
"Engaging medical students and residents in nephrology education: an updated scoping review","Prasad, Sanger, Chanchlani, Kirpalani, Noone","https://doi.org/10.1007/s40620-021-01135-6","20210805","PubMed","Career interest; Educational strategies; Medical education; Mentorship; Nephrology","There is global recognition that interest in nephrology among pediatric and adult trainees is waning, while the burden of kidney disease continues to wax. There is a growing need to engage trainees in nephrology education. The objective of this study was to systematically review the literature on nephrology education for medical students and residents published in the last six years, collate the findings, and extract major themes in order to better define the gaps in this field. A systematic literature search was conducted on four major academic search engines including MEDLINE (OvidSP), ERIC, EMBASE and Web of Science until October 22, 2020, retrieving a total of 2,694 studies. Forty studies published after September 2014 met the inclusion and exclusion criteria. These studies were analyzed based on study focus, type of study design, and outcomes. The studies fell into three main areas of focus: (a) factors that influence interest in nephrology careers (b) current gaps in nephrology knowledge and (c) innovative educational strategies. Barriers to engaging learners in nephrology include a lack of exposure, lack of mentorship, and perceived complexity of nephrology. Baseline awareness is deficient in the management of chronic kidney disease and acute kidney injury. Applying active learning strategies may reduce the perceived barriers to understanding nephrology. The importance of engaging the future nephrology workforce is well-recognized. Nephrologist educators should focus their efforts in studying curriculum interventions and their impact not only on learner satisfaction, but also future behavior, career choices, and patient outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21415,""
"Artificial intelligence in orthopedic implant model classification: a systematic review","Ren, Yi","https://doi.org/10.1007/s00256-021-03884-8","20210805","PubMed","Arthroplasty; Artificial intelligence; Deep learning; Hardware; Implant; Machine learning; Neural network; Orthopedic surgery; Radiology","Although artificial intelligence models have demonstrated high accuracy in identifying specific orthopedic implant models from imaging, which is an important and time-consuming task, the scope of prior works and performance of prior models have not been evaluated. We performed a systematic review to summarize the scope, methodology, and performance of artificial intelligence algorithms in classifying orthopedic implant models. We performed a literature search in PubMed, EMBASE, and the Cochrane Library for studies published up to March 10, 2021, using search terms related to ""artificial intelligence"", ""orthopedic"", ""implant"", and ""arthroplasty"". Studies were assessed using a modified version of the methodologic index for non-randomized studies. Reported outcomes included area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, and specificity. The search identified 2689 records, of which 11 were included in the final review. The number of implant models evaluated ranged from 2 to 27. Five studies reported overall AUC across all included models which ranged from 0.94 to 1.0. Overall accuracy values ranged from 0.804 to 1.0. One study compared AI model performance with that of three surgeons, reporting similar performance. There was a large degree of variation in methodology and reporting quality. Artificial intelligence algorithms have demonstrated strong performance in classifying orthopedic implant models from radiographs. Further research is needed to compare artificial intelligence alone and as an adjunct with human experts in implant identification. Future studies should aim to adhere to rigorous artificial intelligence development methods and thorough, transparent reporting of methods and results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21416,""
"A Machine Learning Tool Using Digital Microscopy (Morphogo) for the Identification of Abnormal Lymphocytes in the Bone Marrow","Tang, Fu, Wang, Chen","https://doi.org/10.1159/000518382","20210830","PubMed","Bone marrow; Digital pathology; Lymphocyte; Machine learning; Morphological analysis; Bone Marrow Cells; Bone Marrow Examination; Diagnosis, Computer-Assisted; Humans; Image Interpretation, Computer-Assisted; Lymphocytes; Lymphoma; Machine Learning; Microscopy; Predictive Value of Tests; Reproducibility of Results; Retrospective Studies","Morphological analysis of the bone marrow is an essential step in the diagnosis of hematological disease. The conventional analysis of bone marrow smears is performed under a manual microscope, which is labor-intensive and subject to interobserver variability. The morphological differential diagnosis of abnormal lymphocytes from normal lymphocytes is still challenging. The digital pathology methods integrated with advances in machine learning enable new diagnostic features/algorithms from digital bone marrow cell images in order to optimize classification, thus providing a robust and faster screening diagnostic tool. We have developed a machine learning system, Morphogo, based on algorithms to discriminate abnormal lymphocytes from normal lymphocytes using digital imaging analysis. We retrospectively reviewed 347 cases of bone marrow digital images. Among them, 53 cases had a clinical history and the diagnosis of marrow involvement with lymphoma was confirmed either by morphology or flow cytometry. We split the 53 cases into two groups for training and testing with 43 and 10 cases, respectively. The selected 15,353 cell images were reviewed by pathologists, based on morphological visual appearance, from 43 patients whose diagnosis was confirmed by complementary tests. To expand the range and the precision of recognizing the lymphoid cells in the marrow by automated digital microscopy systems, we developed an algorithm that incorporated color and texture in addition to geometrical cytological features of the variable lymphocyte images which were applied as the training data set. The selected images from the 10 patients were analyzed by the trained artificial intelligence-based recognition system and compared with the final diagnosis rendered by pathologists. The positive predictive value for the identification of the categories of reactive/normal lymphocytes and abnormal lymphoid cells was 99.04%. It seems likely that further training and improvement of the algorithms will facilitate further subclassification of specific lineage subset pathology, e.g., diffuse large B-cell lymphoma from chronic lymphocytic leukemia/small lymphocytic lymphoma, follicular lymphoma, mantle cell lymphoma or even hairy cell leukemia in cases of abnormal malignant lymphocyte classes in the future. This research demonstrated the feasibility of digital pathology and emerging machine learning approaches to automatically diagnose lymphoma cells in the bone marrow based on cytological-histological analyses.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21417,""
"AI MSK clinical applications: orthopedic implants","Yi, Mutasa, Fritz","https://doi.org/10.1007/s00256-021-03879-5","20210805","PubMed","","Artificial intelligence (AI) and deep learning have multiple potential uses in aiding the musculoskeletal radiologist in the radiological evaluation of orthopedic implants. These include identification of implants, characterization of implants according to anatomic type, identification of specific implant models, and evaluation of implants for positioning and complications. In addition, natural language processing (NLP) can aid in the acquisition of clinical information from the medical record that can help with tasks like prepopulating radiology reports. Several proof-of-concept works have been published in the literature describing the application of deep learning toward these various tasks, with performance comparable to that of expert musculoskeletal radiologists. Although much work remains to bring these proof-of-concept algorithms into clinical deployment, AI has tremendous potential toward automating these tasks, thereby augmenting the musculoskeletal radiologist.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21418,""
"Multi-Compartment Spatially-Derived Radiomics From Optical Coherence Tomography Predict Anti-VEGF Treatment Durability in Macular Edema Secondary to Retinal Vascular Disease: Preliminary Findings","Sil Kar, Sevgi, Dong, Srivastava, Madabhushi, Ehlers","https://doi.org/10.1109/JTEHM.2021.3096378","20210922","PubMed","Diabetic macular edema (DME); Intravitreal Aflibercept Injection (IAI); optical coherence tomography (OCT); radiomics; vascular endothelial growth factor (VEGF)","Diabetic macular edema (DME) and retinal vein occlusion (RVO) are the leading causes of visual impairments across the world. Vascular endothelial growth factor (VEGF) stimulates breakdown of blood-retinal barrier that causes accumulation of fluid within macula. Anti-VEGF therapy is the first-line treatment for both the diseases; however, the degree of response varies for individual patients. The main objective of this work was to identify the (i) texture-based radiomics features within individual fluid and retinal tissue compartments of baseline spectral-domain optical coherence tomography (SD-OCT) images and (ii) the specific spatial compartments that contribute most pertinent features for predicting therapeutic response. A total of 962 texture-based radiomics features were extracted from each of the fluid and retinal tissue compartments of OCT images, obtained from the PERMEATE study. Top-performing features selected from the consensus of different feature selection methods were evaluated in conjunction with four different machine learning classifiers: Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), Random Forest (RF), and Support Vector Machine (SVM) in a cross-validated approach to distinguish eyes tolerating extended interval dosing (non-rebounders) and those requiring more frequent dosing (rebounders). Combination of fluid and retinal tissue features yielded a cross-validated area under receiver operating characteristic curve (AUC) of 0.78Ã‚Â±0.08 in distinguishing rebounders from non-rebounders. This study revealed that the texture-based radiomics features pertaining to IRF subcompartment were most discriminating between rebounders and non-rebounders to anti-VEGF therapy. Clinical Impact: With further validation, OCT-based imaging biomarkers could be used for treatment management of DME patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21419,""
"Deep learning for pulmonary embolism detection on computed tomography pulmonary angiogram: a systematic review and meta-analysis","Soffer, Klang, Shimon, Barash, Cahan, Greenspana, Konen","https://doi.org/10.1038/s41598-021-95249-3","20211011","PubMed","","Computed tomographic pulmonary angiography (CTPA) is the gold standard for pulmonary embolism (PE) diagnosis. However, this diagnosis is susceptible to misdiagnosis. In this study, we aimed to perform a systematic review of current literature applying deep learning for the diagnosis of PE on CTPA. MEDLINE/PUBMED were searched for studies that reported on the accuracy of deep learning algorithms for PE on CTPA. The risk of bias was evaluated using the QUADAS-2 tool. Pooled sensitivity and specificity were calculated. Summary receiver operating characteristic curves were plotted. Seven studies met our inclusion criteria. A total of 36,847 CTPA studies were analyzed. All studies were retrospective. Five studies provided enough data to calculate summary estimates. The pooled sensitivity and specificity for PE detection were 0.88 (95% CI 0.803-0.927) and 0.86 (95% CI 0.756-0.924), respectively. Most studies had a high risk of bias. Our study suggests that deep learning models can detect PE on CTPA with satisfactory sensitivity and an acceptable number of false positive cases. Yet, these are only preliminary retrospective works, indicating the need for future research to determine the clinical impact of automated PE detection on patient care. Deep learning models are gradually being implemented in hospital systems, and it is important to understand the strengths and limitations of these algorithms.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21420,""
"Artificial Intelligence in Undergraduate Medical Education: A Scoping Review","Lee, Wu, Li, Kulasegaram","https://doi.org/10.1097/ACM.0000000000004291","20211101","PubMed","","Artificial intelligence (AI) is a rapidly growing phenomenon poised to instigate large-scale changes in medicine. However, medical education has not kept pace with the rapid advancements of AI. Despite several calls to action, the adoption of teaching on AI in undergraduate medical education (UME) has been limited. This scoping review aims to identify gaps and key themes in the peer-reviewed literature on AI training in UME. The scoping review was informed by Arksey and O'Malley's methodology. Seven electronic databases including MEDLINE and EMBASE were searched for articles discussing the inclusion of AI in UME between January 2000 and July 2020. A total of 4,299 articles were independently screened by 3 co-investigators and 22 full-text articles were included. Data were extracted using a standardized checklist. Themes were identified using iterative thematic analysis. The literature addressed: (1) a need for an AI curriculum in UME, (2) recommendations for AI curricular content including machine learning literacy and AI ethics, (3) suggestions for curriculum delivery, (4) an emphasis on cultivating ""uniquely human skills"" such as empathy in response to AI-driven changes, and (5) challenges with introducing an AI curriculum in UME. However, there was considerable heterogeneity and poor consensus across studies regarding AI curricular content and delivery. Despite the large volume of literature, there is little consensus on what and how to teach AI in UME. Further research is needed to address these discrepancies and create a standardized framework of competencies that can facilitate greater adoption and implementation of a standardized AI curriculum in UME.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21421,""
"Natural language processing for the assessment of cardiovascular disease comorbidities: The cardio-Canary comorbidity project","Berman, Biery, Ginder, Hulme, Marcusa, Leiva, Wu, Cardin, Hainer, Bhatt, Di Carli, Turchin, Blankstein","https://doi.org/10.1002/clc.23687","20211015","PubMed","cardiovascular comorbidities; natural language processing; Algorithms; Animals; Canaries; Cardiovascular Diseases; Comorbidity; Electronic Health Records; Humans; Natural Language Processing","Accurate ascertainment of comorbidities is paramount in clinical research. While manual adjudication is labor-intensive and expensive, the adoption of electronic health records enables computational analysis of free-text documentation using natural language processing (NLP) tools. We sought to develop highly accurate NLP modules to assess for the presence of five key cardiovascular comorbidities in a large electronic health record system. One-thousand clinical notes were randomly selected from a cardiovascular registry at Mass General Brigham. Trained physicians manually adjudicated these notes for the following five diagnostic comorbidities: hypertension, dyslipidemia, diabetes, coronary artery disease, and stroke/transient ischemic attack. Using the open-source Canary NLP system, five separate NLP modules were designed based on 800 ""training-set"" notes and validated on 200 ""test-set"" notes. Across the five NLP modules, the sentence-level and note-level sensitivity, specificity, and positive predictive value was always greater than 85% and was most often greater than 90%. Accuracy tended to be highest for conditions with greater diagnostic clarity (e.g. diabetes and hypertension) and slightly lower for conditions whose greater diagnostic challenges (e.g. myocardial infarction and embolic stroke) may lead to less definitive documentation. We designed five open-source and highly accurate NLP modules that can be used to assess for the presence of important cardiovascular comorbidities in free-text health records. These modules have been placed in the public domain and can be used for clinical research, trial recruitment and population management at any institution as well as serve as the basis for further development of cardiovascular NLP tools.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21422,""
"Deep learning in knee imaging: a systematic review utilizing a Checklist for Artificial Intelligence in Medical Imaging (CLAIM)","Si, Zhong, Huo, Xuan, Zhuang, Hu, Wang, Zhang, Yao","https://doi.org/10.1007/s00330-021-08190-4","20210804","PubMed","Artificial intelligence; Deep learning; Knee; Quality improvement","Our purposes were (1) to explore the methodologic quality of the studies on the deep learning in knee imaging with CLAIM criterion and (2) to offer our vision for the development of CLAIM to assure high-quality reports about the application of AI to medical imaging in knee joint. A Checklist for Artificial Intelligence in Medical Imaging systematic review was conducted from January 1, 2015, to June 1, 2020, using PubMed, EMBASE, and Web of Science databases. A total of 36 articles discussing deep learning applications in knee joint imaging were identified, divided by imaging modality, and characterized by imaging task, data source, algorithm type, and outcome metrics. A total of 36 studies were identified and divided into: X-ray (44.44%) and MRI (55.56%). The mean CLAIM score of the 36 studies was 27.94 (standard deviation, 4.26), which was 66.53% of the ideal score of 42.00. The CLAIM items achieved an average good inter-rater agreement (ICC 0.815, 95% CI 0.660-0.902). In total, 32 studies performed internal cross-validation on the data set, while only 4 studies conducted external validation of the data set. The overall scientific quality of deep learning in knee imaging is insufficient; however, deep learning remains a promising technology for diagnostic or predictive purpose. Improvements in study design, validation, and open science need to be made to demonstrate the generalizability of findings and to achieve clinical applications. Widespread application, pre-trained scoring procedure, and modification of CLAIM in response to clinical needs are necessary in the future. Ã¢â‚¬Â¢ Limited deep learning studies were established in knee imaging with mean score of 27.94, which was 66.53% of the ideal score of 42.00, commonly due to invalidated results, retrospective study design, and absence of a clear definition of the CLAIM items in detail. Ã¢â‚¬Â¢ A previous trained data extraction instrument allowed reaching moderate inter-rater agreement in the application of the CLAIM, while CLAIM still needs improvement in scoring items and result reporting to become a wide adaptive tool in reviews of deep learning studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21423,""
"EGFRisopred: a machine learning-based classification model for identifying isoform-specific inhibitors against EGFR and HER2","Saini, Agarwal","https://doi.org/10.1007/s11030-021-10284-6","20210804","PubMed","Classification models; EGFR; HER2; IBK; Machine learning; Random forest","The EGFR kinase pathway is one of the most frequently activated signaling pathways in human cancers. EGFR and HER2 are the two significant members of this pathway, which are attractive drug targets of clinical relevance in lung and breast cancer. Therefore, identifying EGFR- and HER2-specific inhibitors is one of the important challenges in cancer drug discovery. To address this issue, a dataset of 519 compounds having inhibitory activity against both the isoforms, i.e., EGFR and HER2, was collected from the literature and developed a knowledge-based computational classification model for predicting the specificity of a molecule for an isoform (EGFR/HER2) with precision. A total of seventy-two classification models using nine fingerprint types, four classifiers (IBK, NB, SMO and RF) and two different datasets (EGFR and HER2 isoform specific) were developed. It was observed that the models developed using random forest and IBK performed better for EGFR- and HER2-specific datasets, respectively. Scaffold and functional group analysis led to the identification of prevalent core and fragments in each of the datasets. The accuracy of the selected best performing models was also evaluated using the decoy dataset. We have also developed an application EGFRisopred, which integrates the best performing models and permits the user to predict the specificity of a compound as an EGFR-/HER2-specific anticancer agent. It is expected that the tool's availability as a free utility will allow researchers to identify new inhibitors against these targets important in cancer.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21424,""
"Role of deep learning in early detection of COVID-19: Scoping review","Alzubaidi, Zubaydi, Bin-Salem, Abd-Alrazaq, Ahmed, Househ","https://doi.org/10.1016/j.cmpbup.2021.100025","20210910","PubMed","AI, Artificial intelligence; CNN, Convolutional Neural Network; COVID-19; COVID-19, Corona Virus 2019; CT, Computed Tomography; CXR, Chest X-Ray Radiography; Coronavirus; DL, Deep Learning; Deep learning; Machine learning; RNN, Recurrent Neural Network; SARS-CoV-2, Severe Acute Respiratory Syndrome Coronavirus 2; ULS, Ultrasonography; WHO, World Health Organization","Since the onset of the COVID-19 pandemic, the world witnessed disruption on an unprecedented scale affecting our daily lives including but not limited to healthcare, business, education, and transportation. Deep Learning (DL) is a branch of Artificial intelligence (AI) applications, the recent growth of DL includes features that could be helpful in fighting the COVID-19 pandemic. Utilizing such features could support public health efforts. Investigate the literature available in the use of DL technology to support dealing with the COVID-19 crisis. We summarize the literature that uses DL features to analyze datasets for the purpose of a quick COVID-19 detection. This review follows PRISMA Extension for Scoping Reviews (PRISMA-ScR). We have scanned the most two commonly used databases (IEEE, ACM). Search terms were identified based on the target intervention (DL) and the target population (COVID-19). Two authors independently handled study selection and one author assigned for data extraction. A narrative approach is used to synthesize the extracted data. We retrieved 53 studies and after passing through PRISMA excluding criteria, only 17 studies are considered in this review. All studies used deep learning for detection of COVID-19 cases in early stage based on different diagnostic modalities. Convolutional Neural Network (CNN) and Transfer Learning (TL) were the most commonly used techniques. The included studies showed that DL techniques has significant impact on early detection of COVID-19 with high accuracy rate. However, most of the proposed methods are still in development and not tested in a clinical setting. Further investigation and collaboration are required from the research community and healthcare professionals in order to develop and standardize guidelines for use of DL in the healthcare domain.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21425,""
"Predicted Influences of Artificial Intelligence on Nursing Education: Scoping Review","Buchanan, Howitt, Wilson, Booth, Risling, Bamford","https://doi.org/10.2196/23933","20210806","PubMed","artificial intelligence; education; nursing; review","It is predicted that artificial intelligence (AI) will transform nursing across all domains of nursing practice, including administration, clinical care, education, policy, and research. Increasingly, researchers are exploring the potential influences of AI health technologies (AIHTs) on nursing in general and on nursing education more specifically. However, little emphasis has been placed on synthesizing this body of literature. A scoping review was conducted to summarize the current and predicted influences of AIHTs on nursing education over the next 10 years and beyond. This scoping review followed a previously published protocol from April 2020. Using an established scoping review methodology, the databases of MEDLINE, Cumulative Index to Nursing and Allied Health Literature, Embase, PsycINFO, Cochrane Database of Systematic Reviews, Cochrane Central, Education Resources Information Centre, Scopus, Web of Science, and Proquest were searched. In addition to the use of these electronic databases, a targeted website search was performed to access relevant grey literature. Abstracts and full-text studies were independently screened by two reviewers using prespecified inclusion and exclusion criteria. Included literature focused on nursing education and digital health technologies that incorporate AI. Data were charted using a structured form and narratively summarized into categories. A total of 27 articles were identified (20 expository papers, six studies with quantitative or prototyping methods, and one qualitative study). The population included nurses, nurse educators, and nursing students at the entry-to-practice, undergraduate, graduate, and doctoral levels. A variety of AIHTs were discussed, including virtual avatar apps, smart homes, predictive analytics, virtual or augmented reality, and robots. The two key categories derived from the literature were (1) influences of AI on nursing education in academic institutions and (2) influences of AI on nursing education in clinical practice. Curricular reform is urgently needed within nursing education programs in academic institutions and clinical practice settings to prepare nurses and nursing students to practice safely and efficiently in the age of AI. Additionally, nurse educators need to adopt new and evolving pedagogies that incorporate AI to better support students at all levels of education. Finally, nursing students and practicing nurses must be equipped with the requisite knowledge and skills to effectively assess AIHTs and safely integrate those deemed appropriate to support person-centered compassionate nursing care in practice settings. RR2-10.2196/17490.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21426,""
"An ALE meta-analytical review of the neural correlates of abstract and concrete words","Bucur, Papagno","https://doi.org/10.1038/s41598-021-94506-9","20211008","PubMed","","Several clinical studies have reported a double dissociation between abstract and concrete concepts, suggesting that they are processed by at least partly different networks in the brain. However, neuroimaging data seem not in line with neuropsychological reports. Using the ALE method, we run a meta-analysis on 32 brain-activation imaging studies that considered only nouns and verbs. Five clusters were associated with concrete words, four clusters with abstract words. When only nouns were selected three left activation clusters were found to be associated with concrete stimuli and only one with abstract nouns (left IFG). These results confirm that concrete and abstract words processing involves at least partially segregated brain areas, the IFG being relevant for abstract nouns and verbs while more posterior temporoparietal-occipital regions seem to be crucial for processing concrete words, in contrast with the neuropsychological literature that suggests a temporal anterior involvement for concrete words. We investigated the possible reasons that produce different outcomes in neuroimaging and clinical studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21427,""
"Detecting formal thought disorder by deep contextualized word representations","Sarzynska-Wawer, Wawer, Pawlak, Szymanowska, Stefaniak, Jarkiewicz, Okruszek","https://doi.org/10.1016/j.psychres.2021.114135","20211027","PubMed","Deep learning; Language; Natural language processing; Schizophrenia; Communication; Humans; Language; Language Disorders; Schizophrenia; Speech","Computational linguistics has enabled the introduction of objective tools that measure some of the symptoms of schizophrenia, including the coherence of speech associated with formal thought disorder (FTD). Our goal was to investigate whether neural network based utterance embeddings are more accurate in detecting FTD than models based on individual indicators. The present research used a comprehensive Embeddings from Language Models (ELMo) approach to represent interviews with patients suffering from schizophrenia (N=35) and with healthy people (N=35). We compared its results to the approach described by Bedi etÃ‚Â al. (2015), referred to here as the coherence model. Evaluations were also performed by a clinician using the Scale for the Assessment of Thought, Language and Communication (TLC). Using all six TLC questions the ELMo obtained an accuracy of 80% in distinguishing patients from healthy people. Previously used coherence models were less accurate at 70%. The classifying clinician was accurate 74% of the time. Our analysis shows that both ELMo and TLC are sensitive to the symptoms of disorganization in patients. In this study methods using text representations from language models were more accurate than those based solely on the assessment of FTD, and can be used as measures of disordered language that complement human clinical ratings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21428,""
"Efficacy of topical non-steroidal immunomodulators in the treatment of oral lichen planus: a systematic review and meta-analysis","da Silva, de Lima, Rados, Visioli","https://doi.org/10.1007/s00784-021-04072-7","20210819","PubMed","Cyclosporine; Oral lichen planus; Pimecrolimus; Retinoids; Tacrolimus; Thalidomide; Topical treatment; Administration, Topical; Humans; Immunologic Factors; Immunosuppressive Agents; Lichen Planus, Oral; Steroids; Treatment Outcome","The aim of this systematic review was to assess the efficacy and safety of topical non-steroidal immunomodulators (TNSIs) for oral lichen planus (OLP) treatment. A search strategy designed for this purpose retrieved 1156 references. After analysis of titles and abstracts, 75 studies were selected for full-text analysis. Only randomized controlled clinical trials were selected, resulting in 28 studies included for qualitative and quantitative analysis. The meta-analysis showed similar benefits in clinical response and symptom resolution between tacrolimus 0.1% and pimecrolimus 1% in comparison to topical steroids (TS). Pimecrolimus showed superior efficacy of clinical response but not for symptom resolution compared to placebo. Tacrolimus and pimecrolimus showed better performance preventing symptom relapse, while pimecrolimus also prevented clinical relapse better than TS. Cyclosporine was superior to placebo; however, TS showed better efficacy of clinical response. Thalidomide and retinoid were assessed in only one trial each, and both showed similar efficacy to TS. Rapamycin also presented similar clinical response to TS; however, the later showed greater reduction of symptoms. Mycophenolate mofetil 2% mucoadhesive was no better than placebo. No serious adverse effects have been reported. Cyclosporine showed a higher frequency and variety of adverse effects. Topical tacrolimus and pimecrolimus are safe and effective alternatives for OLP treatment. TS are usually the first choice for OLP treatment. Because some oral lesions may have a low response to treatment with TS, more topical therapeutic options, such as TNSIs, should be considered before systemic steroids are used.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21429,""
"Ethical Considerations Associated with ""Humanitarian Drones"": A Scoping Literature Review","Wang, Christen, Hunt","https://doi.org/10.1007/s11948-021-00327-4","20211027","PubMed","Disasters; Drones; Ethics; Humanitarian aid; Humanitarian innovation; Humans; Organizations; Privacy; Robotics","The use of drones (or unmanned aerial vehicles, UVAs) in humanitarian action has emerged rapidly in the last decade and continues to expand. These so-called 'humanitarian drones' represent the first wave of robotics applied in the humanitarian and development contexts, providing critical information through mapping of crisis-affected areas and timely delivery of aid supplies to populations in need. Alongside these emergent uses of drones in the aid sector, debates have arisen about potential risks and challenges, presenting diverse perspectives on the ethical, legal, and social implications of humanitarian drones. Guided by the methodology introduced by Arksey and O'Malley, this scoping review offers an assessment of the ethical considerations discussed in the academic and gray literature based on a screening of 1,188 articles, from which we selected and analyzed 47 articles. In particular, we used a hybrid approach of qualitative content analysis, along with quantitative landscape mapping, to inductively develop a typology of ethical considerations associated with humanitarian drones. The results yielded 11 key areas of concern: (1) minimizing harm, (2) maximizing welfare, (3) substantive justice, (4) procedural justice, (5) respect for individuals, (6) respect for communities, (7) regulatory gaps, (8) regulatory dysfunction, (9) perceptions of humanitarian aid and organizations, (10) relations between humanitarian organizations and industry, and (11) the identity of humanitarian aid providers and organizations. Our findings illuminate topics that have been the focus of extensive attention (such as minimizing risks of harm and protecting privacy), traces the evolution of this discussion over time (i.e., an initial focus on mapping drones and the distinction of humanitarian from military use, toward the ethics of cargo drones carrying healthcare supplies and samples), and points to areas that have received less consideration (e.g., whether sustainability and shared benefits will be compromised if private companies' interest in humanitarian drones wanes once new markets open up). The review can thus help to situate and guide further analysis of drone use in humanitarian settings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21430,""
"AI musculoskeletal clinical applications: how can AI increase my day-to-day efficiency?","Shin, Kim, Lee","https://doi.org/10.1007/s00256-021-03876-8","20210803","PubMed","Artificial intelligence; Deep learning; Machine learning; Musculoskeletal system","Artificial intelligence (AI) is expected to bring greater efficiency in radiology by performing tasks that would otherwise require human intelligence, also at a much faster rate than human performance. In recent years, milestone deep learning models with unprecedented low error rates and high computational efficiency have shown remarkable performance for lesion detection, classification, and segmentation tasks. However, the growing field of AI has significant implications for radiology that are not limited to visual tasks. These are essential applications for optimizing imaging workflows and improving noninterpretive tasks. This article offers an overview of the recent literature on AI, focusing on the musculoskeletal imaging chain, including initial patient scheduling, optimized protocoling, magnetic resonance imaging reconstruction, image enhancement, medical image-to-image translation, and AI-aided image interpretation. The substantial developments of advanced algorithms, the emergence of massive quantities of medical data, and the interest of researchers and clinicians reveal the potential for the growing applications of AI to augment the day-to-day efficiency of musculoskeletal radiologists.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21431,""
"Habitat suitability mapping of the black coral Leiopathes glaberrima to support conservation of vulnerable marine ecosystems","Lauria, Massi, Fiorentino, Milisenda, Cillari","https://doi.org/10.1038/s41598-021-95256-4","20211005","PubMed","","The black coral Leiopathes glaberrima is an important habitat forming species that supports benthic biodiversity. Due to its high sensitivity to fishing activities, it has been classified as indicator of Vulnerable Marine Ecosystems (VMEs). However, the information on its habitat selection and large-scale spatial distribution in the Mediterranean Sea is poor. In this study a thorough literature review on the occurrence of L. glaberrima across the Mediterranean Sea was undertaken. Predictive modelling was carried out to produce the first continuous map of L. glaberrima suitable habitat in the central sector of the Mediterranean Sea. MaxEnt modeling was used to predict L. glaberrima probability of presence as a function of seven environmental predictors (bathymetry, slope, aspect North-South and East-West, kinetic energy due to currents at the seabed, seabed habitat types and sea bottom temperature). Our results show that bathymetry, slope and aspect are the most important factors driving L. glaberrima spatial distribution, while in less extent the other environmental variables. This study adds relevant information on the spatial distribution of vulnerable deep water corals in relation to the environmental factors in the Mediterranean Sea. It provides an important background for marine spatial planning especially for prioritizing areas for the conservation of VMEs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21432,""
"A cost-utility analysis of 18F-fluorocholine-positron emission tomography imaging for localizing primary hyperparathyroidism in the United States","Yap, Hope, Graves, Kluijfhout, Shen, Gosnell, Sosa, Roman, Duh, Suh","https://doi.org/10.1016/j.surg.2021.03.075","20210803","PubMed","","Primary hyperparathyroidism historically necessitated bilateral neck exploration to remove abnormal parathyroid tissue. Improved localization allows for focused parathyroidectomy with lower complication risks. Recently, positron emission tomography using radiolabeled 18F-fluorocholine demonstrated high accuracy in detecting these lesions, but its cost-effectiveness has not been studied in the United States. A decision tree modeled patients who underwent parathyroidectomy for primary hyperparathyroidism using single preoperative localization modalities: (1) positron emission tomography using radiolabeled 18F-fluorocholine, (2) 4-dimensional computed tomography, (3) ultrasound, and (4) sestamibi single photon emission computed tomography (SPECT). All patients underwent either focused parathyroidectomy versus bilateral neck exploration, with associated cost ($) and clinical outcomes measured in quality-adjusted life-years gained. Model parameters were informed by literature review and Medicare costs. Incremental cost-utility ratios were calculated in US dollars/quality-adjusted life-years gained, with a willingness-to-pay threshold set at $100,000/quality-adjusted life-year. One-way, 2-way, and threshold sensitivity analyses were performed. Positron emission tomography using radiolabeled 18F-fluorocholine gained the most quality-adjusted life-years (23.9) and was the costliest ($2,096), with a total treatment cost of $11,245 or $470/quality-adjusted life-year gained. Sestamibi single photon emission computed tomography and ultrasound were dominated strategies. Compared with 4-dimentional computed tomography, the incremental cost-utility ratio for positron emission tomography using radiolabeled 18F-fluorocholine was $91,066/quality-adjusted life-year gained in our base case analysis, which was below the willingness-to-pay threshold. In 1-way sensitivity analysis, the incremental cost-utility ratio was sensitive to test accuracy, positron emission tomography using radiolabeled 18F-fluorocholine price, postoperative complication probabilities, proportion of bilateral neck exploration patients needing overnight hospitalization, and life expectancy. Our model elucidates scenarios in which positron emission tomography using radiolabeled 18F-fluorocholine can potentially be a cost-effective imaging option for primary hyperparathyroidism in the United States. Further investigation is needed to determine the maximal cost-effectiveness for positron emission tomography using radiolabeled 18F-fluorocholine in selected populations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21433,""
"Contribution of ""Omic"" Studies to the Understanding of Cadasil A Systematic Review","MuiÃƒÂ±o, FernÃƒÂ¡ndez-Cadenas, Arboix","https://doi.org/10.3390/ijms22147357","20210817","PubMed","CADASIL; genomic; proteomic; transcriptomic; CADASIL; Cysteine; Gastrointestinal Microbiome; Gene Frequency; Gene Ontology; Genetic Association Studies; Genome-Wide Association Study; Genomics; Humans; Models, Molecular; Mutation; Nerve Tissue Proteins; Prevalence; Prognosis; Protein Aggregation, Pathological; Protein Conformation; Protein Domains; Proteomics; Receptor, Notch3; Sequence Analysis, DNA; Transcriptome","CADASIL (Cerebral Autosomal Dominant Arteriopathy with Subcortical Infarcts and Leukoencephalopathy) is a small vessel disease caused by mutations in <i>NOTCH3</i> that lead to an odd number of cysteines in the epidermal growth factor (EGF)-like repeat domain, causing protein misfolding and aggregation. The main symptoms are migraines, psychiatric disorders, recurrent strokes, and dementia. Omic technologies allow the massive study of different molecules for understanding diseases in a non-biased manner or even for discovering targets and their possible treatments. We analyzed the progress in understanding CADASIL that has been made possible by omics sciences. For this purpose, we included studies that focused on CADASIL and used omics techniques, searching bibliographic resources, such as PubMed. We excluded studies with other phenotypes, such as migraine or leukodystrophies. A total of 18 articles were reviewed. Due to the high prevalence of <i>NOTCH3</i> mutations considered pathogenic to date in genomic repositories, one can ask whether all of them produce CADASIL, different degrees of the disease, or whether they are just a risk factor for small vessel disease. Besides, proteomics and transcriptomics studies found that the molecules that are significantly altered in CADASIL are mainly related to cell adhesion, the cytoskeleton or extracellular matrix components, misfolding control, autophagia, angiogenesis, or the transforming growth factor ÃŽÂ² (TGFÃŽÂ²) signaling pathway. The omics studies performed on CADASIL have been useful for understanding the biological mechanisms and could be key factors for finding potential drug targets.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21434,""
"Outcomes of complex robot-assisted laparoscopic ureteral reimplantation after failed ipsilateral endoscopic treatment of vesicoureteral reflux","Janssen, Kirsch","https://doi.org/10.1016/j.jpurol.2021.05.029","20211014","PubMed","Dextranomer/hyaluronic acid; Robotics; Ureteral reimplant; Vesicoureteral reflux; Child; Dextrans; Female; Humans; Hyaluronic Acid; Laparoscopy; Male; Replantation; Retrospective Studies; Robotic Surgical Procedures; Robotics; Treatment Outcome; Ureter; Vesico-Ureteral Reflux","Endoscopic injection (EI) has been considered a minimally invasive option with high success rates. However, in clinical settings where EI has failed, and after repeat injections or worsening clinical presentation, different treatment modalities may be offered. Open ureteral reimplantation has emerged as a safe option in patients who have failed EI for VUR treatment. Currently there is limited literature describing success of complex robot-assisted laparoscopic ureteral reimplantation (RALUR) following primary EI for vesicoureteral reflux (VUR). We aim to describe our surgical technique and outcomes using RALUR approach following failed EI for VUR. We hypothesize RALUR can be a safe, salvage option in patients who have failed EI for VUR in the setting of recurrent VUR or ureterovesical junction obstruction (UVJO). A single site, retrospective study using electronic medical records of all patients who underwent RALUR between 2013 and 2019 following history of previous ipsilateral EI using dextranomer/hyaluronic acid (DHA) for diagnosis of vesicoureteral reflux (VUR) was conducted. Primary outcomes were radiographic resolution and/or clinical resolution. A total of 17 RALUR procedures were reviewed in 16 patients. There were 14 females (87.5%) and 2 males (12.5%). Seven patients had two prior EI. Median (range) age at time of RALUR was 10.1 (5.7-17.9) years, and the average time between EI and RALUR was 5.9 years [1-13]. The average VUR recurrence grade after failed EI was 3 (ranges 2-4) on preoperative VCUG. History of bilateral EI using dextranomer/hyaluronic acid (DHA), was observed in 14 patients. Surgical diagnosis at time of RALUR included persistent VUR (NÃ‚Â =Ã‚Â 10) or symptomatic ureterovesical junction obstruction (UVJO, NÃ‚Â =Ã‚Â 6). Mean console times were 102Ã‚Â min (range 70-240Ã‚Â min) for RALUR vs 128Ã‚Â min (range 70-180Ã‚Â min) for cases requiring ureteral tailoring. Six complications occurred in 16 patients (37.6%): Using the Clavien-Dindo classification scale, four patients (25%) were grade I, one (6.3%) grade II, and one (6.3%) was grade IIIb, which required additional procedures for ureteral obstruction. RALUR after failed EI should be considered a reasonably safe and effective surgical approach in older children with persistent VUR or acquired UVJO.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21435,""
"FRL: An Integrative Feature Selection Algorithm Based on the Fisher Score, Recursive Feature Elimination, and Logistic Regression to Identify Potential Genomic Biomarkers","Ge, Luo, Zhang, Meng, Chen","https://doi.org/10.1155/2021/4312850","20211025","PubMed","Algorithms; Biomarkers; Biomarkers, Tumor; Cluster Analysis; Databases, Genetic; Gene Expression Profiling; Genome; Genomics; High-Throughput Nucleotide Sequencing; Humans; Neoplasms; Oligonucleotide Array Sequence Analysis; Precision Medicine; ROC Curve; Regression Analysis; Reproducibility of Results; Support Vector Machine","Accurate screening on cancer biomarkers contributes to health assessment, drug screening, and targeted therapy for precision medicine. The rapid development of high-throughput sequencing technology has identified abundant genomic biomarkers, but most of them are limited to single-cancer analysis. Based on the combination of Fisher score, Recursive feature elimination, and Logistic regression (FRL), this paper proposes an integrative feature selection algorithm named FRL to explore potential cancer genomic biomarkers on cancer subsets. Fisher score is initially used to calculate the weights of genes to rapidly reduce the dimension. Recursive feature elimination and Logistic regression are then jointly employed to extract the optimal subset. Compared to the current differential expression analysis tool GEO2R based on the Limma algorithm, FRL has greater classification precision than Limma. Compared with five traditional feature selection algorithms, FRL exhibits excellent performance on accuracy (ACC) and F1-score and greatly improves computational efficiency. On high-noise datasets such as esophageal cancer, the ACC of FRL is 30% superior to the average ACC achieved with other traditional algorithms. As biomarkers found in multiple studies are more reliable and reproducible, and reveal stronger association on potential clinical value than single analysis, through literature review and spatial analyses of gene functional enrichment and functional pathways, we conduct cluster analysis on 10 diverse cancers with high mortality and form a potential biomarker module comprising 19 genes. All genes in this module can serve as potential biomarkers to provide more information on the overall oncogenesis mechanism for the detection of diverse early cancers and assist in targeted anticancer therapies for further developments in precision medicine.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21436,""
"Myoelectric control of robotic lower limb prostheses: a review of electromyography interfaces, control paradigms, challenges and future directions","Fleming, Stafford, Huang, Hu, Ferris, Huang","https://doi.org/10.1088/1741-2552/ac1176","20210803","PubMed","EMG; gait and balance; human motor control; neuralÃ¢â‚¬â€œmachine interface; robotic lower limb protheses; Amputees; Artificial Limbs; Electromyography; Humans; Locomotion; Muscle, Skeletal; Robotic Surgical Procedures","<i>Objective.</i>Advanced robotic lower limb prostheses are mainly controlled autonomously. Although the existing control can assist cyclic movements during locomotion of amputee users, the function of these modern devices is still limited due to the lack of neuromuscular control (i.e. control based on human efferent neural signals from the central nervous system to peripheral muscles for movement production). Neuromuscular control signals can be recorded from muscles, called electromyographic (EMG) or myoelectric signals. In fact, using EMG signals for robotic lower limb prostheses control has been an emerging research topic in the field for the past decade to address novel prosthesis functionality and adaptability to different environments and task contexts. The objective of this paper is to review robotic lower limb Prosthesis control via EMG signals recorded from residual muscles in individuals with lower limb amputations.<i>Approach.</i>We performed a literature review on surgical techniques for enhanced EMG interfaces, EMG sensors, decoding algorithms, and control paradigms for robotic lower limb prostheses.<i>Main results.</i>This review highlights the promise of EMG control for enabling new functionalities in robotic lower limb prostheses, as well as the existing challenges, knowledge gaps, and opportunities on this research topic from human motor control and clinical practice perspectives.<i>Significance.</i>This review may guide the future collaborations among researchers in neuromechanics, neural engineering, assistive technologies, and amputee clinics in order to build and translate true bionic lower limbs to individuals with lower limb amputations for improved motor function.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21437,""
"Robotic Applications in Orthodontics: Changing the Face of Contemporary Clinical Care","Adel, Zaher, El Harouni, Venugopal, Premjani, Vaid","https://doi.org/10.1155/2021/9954615","20211025","PubMed","Automation; Equipment Design; Forecasting; Humans; Orthodontic Wires; Orthodontics; Pattern Recognition, Automated; Robotics; Software; Stomatognathic System","The last decade (2010-2021) has witnessed the evolution of robotic applications in orthodontics. This review scopes and analyzes published orthodontic literature in eight different domains: (1) robotic dental assistants; (2) robotics in diagnosis and simulation of orthodontic problems; (3) robotics in orthodontic patient education, teaching, and training; (4) wire bending and customized appliance robotics; (5) nanorobots/microrobots for acceleration of tooth movement and for remote monitoring; (6) robotics in maxillofacial surgeries and implant placement; (7) automated aligner production robotics; and (8) TMD rehabilitative robotics. A total of 1,150 records were searched, of which 124 potentially relevant articles were retrieved in full. 87 studies met the selection criteria following screening and were included in the scoping review. The review found that studies pertaining to arch wire bending and customized appliance robots, simulative robots for diagnosis, and surgical robots have been important areas of research in the last decade (32%, 22%, and 16%). Rehabilitative robots and nanorobots are quite promising and have been considerably reported in the orthodontic literature (13%, 9%). On the other hand, assistive robots, automated aligner production robots, and patient robots need more scientific data to be gathered in the future (1%, 1%, and 6%). Technological readiness of different robotic applications in orthodontics was further assessed. The presented eight domains of robotic technologies were assigned to an estimated technological readiness level according to the information given in the publications. Wire bending robots, TMD robots, nanorobots, and aligner production robots have reached the highest levels of technological readiness: 9; diagnostic robots and patient robots reached level 7, whereas surgical robots and assistive robots reached lower levels of readiness: 4 and 3, respectively.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21438,""
"An Evidence-Based Framework for Evaluating Pharmacogenomics Knowledge for Personalized Medicine","Whirl-Carrillo, Huddart, Gong, Sangkuhl, Thorn, Whaley, Klein","https://doi.org/10.1002/cpt.2350","20210914","PubMed","Databases, Genetic; Drug Labeling; Drug Prescriptions; Humans; Knowledge Bases; Pharmacogenetics; Precision Medicine; Prescription Drugs; Reproducibility of Results","Clinical annotations are one of the most popular resources available on the Pharmacogenomics Knowledgebase (PharmGKB). Each clinical annotation summarizes the association between variant-drug pairs, shows relevant findings from the curated literature, and is assigned a level of evidence (LOE) to indicate the strength of support for that association. Evidence from the pharmacogenomic literature is curated into PharmGKB as variant annotations, which can be used to create new clinical annotations or added to existing clinical annotations. This means that the same clinical annotation can be worked on by multiple curators over time. As more evidence is curated into PharmGKB, the task of maintaining consistency when assessing all the available evidence and assigning an LOE becomes increasingly difficult. To remedy this, a scoring system has been developed to automate LOE assignment to clinical annotations. Variant annotations are scored according to certain attributes, including study size, reported P value, and whether the variant annotation supports or fails to find an association. Clinical guidelines or US Food and Drug Administration (FDA)-approved drug labels which give variant-specific prescribing guidance are also scored. The scores of all annotations attached to a clinical annotation are summed together to give a total score for the clinical annotation, which is used to calculate an LOE. Overall, the system increases transparency, consistency, and reproducibility in LOE assignment to clinical annotations. In combination with increased standardization of how clinical annotations are written, use of this scoring system helps to ensure that PharmGKB clinical annotations continue to be a robust source of pharmacogenomic information.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21439,""
"What is the evidence for clinical use of advanced technology in unicompartmental knee arthroplasty?","Mittal, Meshram, Kim","https://doi.org/10.1002/rcs.2302","20210903","PubMed","UKA; UKR; arthroplasty; computer navigation; knee; patient-specific instrumentation; replacement; robotic; unicompartmental; unicondylar; Arthroplasty, Replacement, Knee; Humans; Knee Joint; Knee Prosthesis; Osteoarthritis, Knee; Robotic Surgical Procedures; Technology; Treatment Outcome","With an aim of improving prosthesis survivorship of unicompartmental knee arthroplasty (UKA), use of computer-assisted technologies (CATs) such as robotics, has been on the rise to reduce intraoperative errors in surgical technique. In light of recent influx of CATs in the UKA, a review of these innovations will help providers to understand their clinical utility. A systematic literature search was performed following Preferred Reporting Items for Systematic Review and Meta-Analysis guidelines. Among 19 studies comparing robot-assisted UKA with conventional UKA, only 32% were randomized control trials, 47% reported minimum mean follow-up of 2 years, and 21% evaluated prosthesis survival. Similar results were obtained for navigation-assisted UKA and UKA performed with patient-specific instrumentation. While CATs seem to reduce the surgical errors in UKA, the evidence on the efficacy of any of the studied CATs to improve survivorship remains limited and there are issues related to cost-effectiveness, learning curve, and increase in operating time.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21440,""
"A Commentary on ""Long-term oncological outcomes in robotic versus laparoscopic approach for rectal cancer: A systematic review and meta-analysis"" [Int J Surg 80 (2020) 225-230]","Li","https://doi.org/10.1016/j.ijsu.2021.106006","20211021","PubMed","Humans; Laparoscopy; Rectal Neoplasms; Robotic Surgical Procedures; Robotics","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21441,""
"The Evidence Behind Robot-Assisted Abdominopelvic Surgery : A Systematic Review","Dhanani, Olavarria, Bernardi, Lyons, Holihan, Loor, Haynes, Liang","https://doi.org/10.7326/M20-7006","20210920","PubMed","Abdomen; Evidence-Based Medicine; Humans; Laparoscopy; Laparotomy; Pelvis; Postoperative Complications; Robotic Surgical Procedures","Use of robot-assisted surgery has increased dramatically since its advent in the 1980s, and nearly all surgical subspecialties have adopted it. However, whether it has advantages compared with laparoscopy or open surgery is unknown. To assess the quality of evidence and outcomes of robot-assisted surgery compared with laparoscopy and open surgery in adults. PubMed, EMBASE, Scopus, and the Cochrane Central Register of Controlled Trials were searched from inception to April 2021. Randomized controlled trials that compared robot-assisted abdominopelvic surgery with laparoscopy, open surgery, or both. Two reviewers independently extracted study data and risk of bias. A total of 50 studies with 4898 patients were included. Of the 39 studies that reported incidence of Clavien-Dindo complications, 4 (10%) showed fewer complications with robot-assisted surgery. The majority of studies showed no difference in intraoperative complications, conversion rates, and long-term outcomes. Overall, robot-assisted surgery had longer operative duration than laparoscopy, but no obvious difference was seen versus open surgery. Heterogeneity was present among and within the included surgical subspecialties, which precluded meta-analysis. Several trials may not have been powered to assess relevant differences in outcomes. There is currently no clear advantage with existing robotic platforms, which are costly and increase operative duration. With refinement, competition, and cost reduction, future versions have the potential to improve clinical outcomes without the existing disadvantages. None. (PROSPERO: CRD42020182027).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21442,""
"Effectiveness of robot therapy in the management of behavioural and psychological symptoms for individuals with dementia: A systematic review and meta-analysis","Ong, Tang, Tam","https://doi.org/10.1016/j.jpsychires.2021.05.077","20210805","PubMed","Dementia; Effectiveness; Robot therapy; Systematic review and meta-analysis; Anxiety; Dementia; Depression; Humans; Quality of Life; Robotics","Robot therapy presents a promising alternative in dementia care. However, its effectiveness has not been verified comprehensively. This systematic review and meta-analysis aim at evaluating the effectiveness of robot therapy in the management of behavioural and psychological symptoms for individuals with dementia. Studies assessing the effectiveness of robot therapy were identified using 10 academic research databases: CENTRAL, CINAHL, CNKI, The Cochrane Library, Embase, IEEE Xplore, MEDLINE, PubMed, Scopus, and ProQuest Dissertations &amp; Theses. Additional references were identified from the reference lists of included studies and relevant reviews. Data extraction and risk of bias assessment were conducted independently by two review authors. Meta-analyses and subgroup analyses were performed and the heterogeneity of studies was examined. 18 published articles from 14 studies involving a total of 1256 participants were included. Participants with robot therapy had a significant decrease in agitation (SMD -0.38, 95% CI -0.66, -0.09; pÃ‚Â =Ã‚Â 0.01) and a significant increase in social interaction (SMD 0.49, 95% CI 0.01, 0.97; pÃ‚Â =Ã‚Â 0.04) while effects for depression, anxiety, cognitive status, and quality of life were not statistically significant. Results from this review show that robot therapy can effectively reduce agitation and increase social interactions for individuals with dementia. Future clinical practice should consider the potential of robot therapy as an option to be implemented into current dementia programmes. Further large-scale trials are required for the thorough investigation of different intervention formats and robot types, while considering potential confounding factors.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21443,""
"Using machine learning to predict severe hypoglycaemia in hospital","Fralick, Dai, Pou-Prom, Verma, Mamdani","https://doi.org/10.1111/dom.14472","20211018","PubMed","hypoglycaemia; Hospitals; Humans; Hypoglycemia; Logistic Models; Machine Learning; Retrospective Studies","To predict the risk of hypoglycaemia using machine-learning techniques in hospitalized patients. We conducted a retrospective cohort study of patients hospitalized under general internal medicine (GIM) and cardiovascular surgery (CV) at a tertiary care teaching hospital in Toronto, Ontario. Three models were generated using supervised machine learning: least absolute shrinkage and selection operator (LASSO) logistic regression; gradient-boosted trees; and a recurrent neural network. Each model included baseline patient data and time-varying data. Natural-language processing was used to incorporate text data from physician and nursing notes. We included 8492 GIM admissions and 8044 CV admissions. Hypoglycaemia occurred in 16% of GIM admissions and 13% of CV admissions. The area under the curve for the models in the held-out validation set was approximately 0.80 on the GIM ward and 0.82 on the CV ward. When the threshold for hypoglycaemia was lowered to 2.9Ã¢â‚¬â€°mmol/L (52Ã¢â‚¬â€°mg/dL), similar results were observed. Among the patients at the highest decile of risk, the positive predictive value was approximately 50% and the sensitivity was 99%. Machine-learning approaches can accurately identify patients at high risk of hypoglycaemia in hospital. Future work will involve evaluating whether implementing this model with targeted clinical interventions can improve clinical outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21444,""
"A homological approach to a mathematical definition of pulmonary fibrosis and emphysema on computed tomography","Tanabe, Kaji, Sato, Yokoyama, Oguma, Tanizawa, Handa, Sakajo, Hirai","https://doi.org/10.1152/japplphysiol.00150.2021","20210812","PubMed","computed tomography; deep learning; fibrosis; lung disease; persistent homology; Emphysema; Humans; Idiopathic Pulmonary Fibrosis; Lung; Pulmonary Disease, Chronic Obstructive; Pulmonary Emphysema; Retrospective Studies; Tomography, X-Ray Computed","Three-dimensional imaging is essential to evaluate local abnormalities and understand structure-function relationships in an organ. However, quantifiable and interpretable methods to localize abnormalities remain unestablished. Visual assessments are prone to bias, machine learning methods depend on training images, and the underlying decision principle is usually difficult to interpret. Here, we developed a homological approach to mathematically define emphysema and fibrosis in the lungs on computed tomography (CT). With the use of persistent homology, the density of homological features, including connected components, tunnels, and voids, was extracted from the volumetric CT scans of lung diseases. A pair of CT values at which each homological feature appeared (birth) and disappeared (death) was computed by sweeping the threshold levels from higher to lower CT values. Consequently, fibrosis and emphysema were defined as voxels with dense voids having a longer lifetime (birth-death difference) and voxels with dense connected components having a lower birth, respectively. In an independent dataset including subjects with idiopathic pulmonary fibrosis (IPF), chronic obstructive pulmonary disease (COPD), and combined pulmonary fibrosis and emphysema (CPFE), the proposed definition enabled accurate segmentation with comparable quality to deep learning in terms of Dice coefficients. Persistent homology-defined fibrosis was closely associated with physiological abnormalities such as impaired diffusion capacity and long-term mortality in subjects with IPF and CPFE, and persistent homology-defined emphysema was associated with impaired diffusion capacity in subjects with COPD. The present persistent homology-based evaluation of structural abnormalities could help explore the clinical and physiological impacts of structural changes and morphological mechanisms of disease progression.<b>NEW &amp; NOTEWORTHY</b> This study proposes a homological approach to mathematically define a three-dimensional texture feature of emphysema and fibrosis on chest computed tomography using persistent homology. The proposed definition enabled accurate segmentation with comparable quality to deep learning while offering higher interpretability than deep learning-based methods.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21445,""
"Minimizing minimally invasive surgery: Current status of the single-port robotic surgery in Urology","Garisto, Bertolo, Reese, Bove, Kaouk","https://doi.org/10.1016/j.acuroe.2021.04.011","20211025","PubMed","LESS; Puerto ÃƒÂºnico; Robot; Single-port; Single-site; Sitio ÃƒÂºnico; Minimally Invasive Surgical Procedures; Retrospective Studies; Robotic Surgical Procedures; Urologic Surgical Procedures; Urology","The novel da Vinci Single-Port (SP) robotic platform received the US FDA approval in 2018. The device, specifically conceived for single-site approach, is pushing through the limits of minimally invasive surgery. We sought to provide a comprehensive overview of the current status of the clinical experiences accomplished by the da Vinci SP in urology, and to discuss future perspectives. A non-systematic literature review was performed focusing on single port articles in urological surgery using Medline/PubMed and Embase search electronic engines. The authors analyzed findings and a brief report of the clinical experience for surgical procedures completed by the SP platform was described. The current data available from single-port robotic established the safety and feasibility of urologic procedures using this novel platform. However, the results come from single-center case series, small cohorts and retrospective studies that need to be cautiously interpreted. Additional evidence is required to determine the asset of the SP platform in the urological community. The SP robotic system opens new frontiers on the surgical scenery facilitating the completion of urological surgeries through a single incision. Further comparative studies will be required to assess perioperative and long-term oncological and functional outcomes among SP, multi-arm robotic and open approaches.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21446,""
"Robotic versus laparoscopic distal pancreatectomies: AÃ‚Â systematic review and meta-analysis on costs and perioperative outcome","Di Martino, Caruso, D'Ovidio, NÃƒÂºÃƒÂ±ez-Alfonsel, BurdiÃƒÂ³ Pinilla, Quijano Collazo, Vicente, Ielpo","https://doi.org/10.1002/rcs.2295","20210903","PubMed","distal pancreatectomy; hepato-pancreato-biliary; pancreas; pancreatectomy; robot design; robotic pancreatectomy; Humans; Laparoscopy; Length of Stay; Operative Time; Pancreatectomy; Pancreatic Neoplasms; Postoperative Complications; Robotic Surgical Procedures; Treatment Outcome","The aim of this meta-analysis is to compare perioperative outcomes and costs of robotic and laparoscopic distal pancreatectomy (RDP and LDP). In accordance with the PRISMA guidelines, we searched Medline, EMBASE, Cochrane and Web of Science for reports published before December 2020. The literature search identified 11 papers (1Ã¢â‚¬â€°187 patients). RDP showed a lower conversion rate (odds ratio: 2.56, 95% confidence intervals [CI]: 1.31 to 5.00) with no significant differences in bleeding and operative time, complicationsÃ‚Â Ã¢â€°Â¥Ã‚Â Clavien-Dindo grade III, pancreatic fistulas and length of stay. Despite RDP presenting higher costs in all included studies, none of these differences were significant. However, RDP showed higher total costs than LDP (standardized mean differences [SMD]: -1.18, 95% CI: -1.97 to -0.39). A subgroup analysis according to the continent of origin showed that studies coming from Asian research groups kept showing significant differences (SMD: -2.62, 95% CI: -3.38 to -1.85), while Western groups did not confirm these findings. Based on low-quality evidence, despite some potential technical advantages, RDP still seems to be costlier than LDP.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21447,""
"Relationship between resting-state fMRI functional connectivity with motor and language outcome after perinatal brain injury - A systematic review","NÃƒÂ­ Bhroin, Molloy, Bokde","https://doi.org/10.1016/j.ejpn.2021.05.007","20211012","PubMed","Brain development; Functional connectivity; Neurodevelopmental impairment; Perinatal brain injury; Resting-state fMRI; Systematic review; Brain; Brain Injuries; Brain Mapping; Humans; Magnetic Resonance Imaging; Neural Pathways","Perinatal brain injury is a significant cause of adverse neurodevelopmental outcomes. The objective of this systematic review was to identify patterns of altered brain function, quantified using functional connectivity (FC) changes in resting-state fMRI (rs-fMRI) data, that were associated with motor and language outcomes in individuals with a history of perinatal brain injury. A systematic search using electronic databases was conducted to identify relevant studies. A total of 10 studies were included in the systematic review, representing 260 individuals with a history of perinatal brain injury. Motor and language outcomes were measured at time points ranging from 4 months to 29 years 1 month. Relations between FC and motor measures revealed increased intra-hemispheric FC, reduced inter-hemispheric FC and impaired lateralization of motor-related brain regions associated with motor outcomes. Altered FC within sensorimotor, visual, cerebellum and frontoparietal networks, and between sensorimotor, visual, auditory and higher-order networks, including cerebellum, frontoparietal, default-mode, salience, self-referential and attentional networks were also associated with motor outcomes. In studies assessing the relationship between rs-fMRI and language outcome, reduced intra-hemispheric FC, increased inter-hemispheric FC and right-hemisphere lateralization of language-related brain regions correlated with language outcomes. Evidence from this systematic review suggests a possible association between diaschisis and motor and language impairments in individuals after perinatal brain lesions. These findings support the need to explore the contributions of additional brain regions functionally connected but remote from the primary lesioned brain area for targeted treatments and appropriate intervention, though more studies with increased standardization across neuroimaging and neurodevelopmental assessments are needed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21448,""
"Effects of robotic care interventions for dementia care: A systematic review and meta-analysis randomised controlled trials","Saragih, Tonapa, Sun, Chia-Ju, Lee","https://doi.org/10.1111/jocn.15856","20211011","PubMed","dementia; meta-analysis; robotic care intervention; Anxiety; Dementia; Humans; Quality of Life; Randomized Controlled Trials as Topic; Robotic Surgical Procedures","The role of robotic care has been studied because it may be a care option applicable to dementia care. However, the effects of robotic care in dementia care are still inconclusive. To explore the span of the effects of robotic care intervention among patients with dementia. Systematic review and meta-analysis. This study searched systematically using the following databases: Academic Search Complete, CINAHL, Cochrane Library, MEDLINE, PubMed, SocINDEX, UpToDate (OVID) and Web of Science. The eligibility criteria were patients with dementia, randomised controlled trials and publications in English. The PEDro scale was used to assess the methodological quality in the included studies. The meta-analysis was performed using a fixed-effects model to calculate the pooled effects of robotic care interventions. STATA 16.0 was used for statistical analysis. The results are reported according to the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) guidelines. A total of 15 studies met the eligibility criteria and included 1684 participants. Overall, the robotic care interventions had positive effects on agitation (SMDÃ‚Â =Ã‚Â 0.09; 95% CI [-0.22-0.33]), anxiety (SMDÃ‚Â =Ã‚Â -0.07; 95% CI [-0.42-0.28]), cognitive function (SMDÃ‚Â =Ã‚Â 0.16; 95% CI [-0.08-0.40]), depression (SMDÃ‚Â =Ã‚Â -0.35; 95% CI [-0.69-0.02]), neuropsychiatric symptoms (SMDÃ‚Â =Ã‚Â 0.16; 95% CI [-0.29-0.61]), total hours of sleep during daytime (SMDÃ‚Â =Ã‚Â -0.31; 95% CI [-0.55 to 0.07]) and quality of life (SMDÃ‚Â =Ã‚Â 0.24; 95% CI [-0.23-0.70]). Robotic care intervention may be an effective and alternative intervention for improving the health outcomes for people with dementia. The robotic care effect on anxiety should be confirmed. Further studies may consider the frequency, duration of intervention and possible negative outcomes after robotic care interventions. As a non-pharmacological approach, nursing staff may consider the robotic care intervention in providing care for patients with dementia since this intervention has clinical benefits.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21449,""
"Robotic versus laparoscopic gastrectomy for gastric cancer: an umbrella review of systematic reviews and meta-analyses","Marano, Fusario, Savelli, Marrelli, Roviello","https://doi.org/10.1007/s13304-021-01059-7","20211015","PubMed","Adult surgery; Gastrointestinal tumours; Oncology; Robotic surgery; Systematic review; Gastrectomy; Humans; Laparoscopy; Length of Stay; Postoperative Complications; Robotic Surgical Procedures; Stomach Neoplasms; Systematic Reviews as Topic; Treatment Outcome","An umbrella review was performed to summarize literature data and to investigate benefits and harm of robotic gastrectomy (RG) compared to laparoscopic (LG) approach. To overcome the intrinsic limitations of laparoscopy, the robotic approach is claimed to facilitate lymph-node dissection and complex reconstruction after gastrectomy, to assure oncologic safety also in advanced gastric cancer. A literature search was conducted in PubMed, Cochrane and Embase databases for all meta-analyses published up to December 2019. The search strategy was previously published in a protocol. We selected fourteen meta-analyses comparing outcomes between LG and RG with curative intent in patients with diagnosis of resectable gastric cancer. We highlight that RG has a longer operation time, inferior blood loss, reduction in hospital stay and a more rapid recovery of bowel function. In meta-analyses with statistical significance the number of nodes removed in RG is higher than LG and the distal margin of resection is higher. There is no difference in terms of total complication rate, mortality, morbidity, anastomotic leakage, anastomotic stenosis, intestinal obstruction and in conversion rate to open technique. The safety and efficacy of robotic gastrectomy are not clearly supported by strong evidence, suggesting that the outcomes reported for each surgical technique need to be interpreted with caution, in particular for the meta-analyses in which the heterogeneity is large. Certainly, robotic gastrectomy is associated with shorter time to oral intake, lesser intraoperative bleeding and longer operation time with an acceptable level of evidence. On the other hand, the data regarding other outcomes are insufficient as well as non-significant, from an evidence point of view, to draw any robust conclusion.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21450,""
"Is there a difference between navigated and non-navigated robot cohorts in robot-assisted spine surgery? A multicenter, propensity-matched analysis of 2,800 screws and 372 patients","Lee, Zuckerman, Buchanan, Boddapati, Mathew, Leung, Park, Pham, Buchholz, Khan, Pollina, Mullin, Jazini, Haines, Schuler, Good, Lombardi, Lehman","https://doi.org/10.1016/j.spinee.2021.05.015","20211027","PubMed","Fluoroscopic radiation time; Mazor x; Mazor x stealth; Multicenter; Robot abandonment; Robot-assisted spine surgery; Screw accuracy; Spinal fusion; Adolescent; Adult; Humans; Pedicle Screws; Robotic Surgical Procedures; Robotics; Spinal Fusion; Spine","Robot-assisted spine surgery continues to rapidly develop as evidenced by the growing literature in recent years. In addition to demonstrating excellent pedicle screw accuracy, early studies have explored the impact of robot-assisted spine surgery on reducing radiation time, length of hospital stay, operative time, and perioperative complications in comparison to conventional freehand technique. Recently, the Mazor X Stealth Edition was introduced in 2018. This robotic system integrates Medtronic's Stealth navigation technology into the Mazor X platform, which was introduced in 2016. It is unclear what the impact of these advancements have made on clinical outcomes. To compare the outcomes and complications between the most recent iterations of the Mazor Robot systems: Mazor X and Mazor X Stealth Edition. Multicenter cohort PATIENT SAMPLE: Among four different institutions, we included adult (Ã¢â€°Â¥18 years old) patients who underwent robot-assisted spine surgery with either the Mazor X (non-navigated robot) or Stealth (navigated robot) platforms. Primary outcomes included robot time per screw, fluoroscopic radiation time, screw accuracy, robot abandonment, and clinical outcomes with a minimum 90 day follow up. A one-to-one propensity-score matching algorithm based on perioperative factors (e.g. demographics, comorbidities, primary diagnosis, open vs. percutaneous instrumentation, prior spine surgery, instrumented levels, pelvic fixation, interbody fusion, number of planned robot screws) was employed to control for the potential selection bias between the two robotic systems. Chi-square/fisher exact test and t-test/ANOVA were used for categorical and continuous variables, respectively. From a total of 646 patients, a total of 372 adult patients were included in this study (X: 186, Stealth: 186) after propensity score matching. The mean number of instrumented levels was 4.3. The mean number of planned robot screws was 7.8. Similar total operative time and robot time per screw occurred between cohorts (p&gt;0.05). However, Stealth achieved significantly shorter fluoroscopic radiation time per screw (Stealth: 7.2 seconds vs. X: 10.4 seconds, p&lt;.001) than X. The screw accuracy for both robots was excellent (Stealth: 99.6% vs. X: 99.1%, p=0.120). In addition, Stealth achieved a significantly lower robot abandonment rate (Stealth: 0% vs. X: 2.2%, p=0.044). Furthermore, a lower blood transfusion rate was observed for Stealth than X (Stealth: 4.3% vs. X: 10.8%, p=0.018). Non-robot related complications such as dura tear, motor/sensory deficits, return to the operating room during same admission, and length of stay was similar between robots (p&gt;0.05). The 90-day complication rates were low and similar between robot cohorts (Stealth: 5.4% vs. X: 3.8%, p=0.456). In this multicenter study, both robot systems achieved excellent screw accuracy and low robot time per screw. However, using Stealth led to significantly less fluoroscopic radiation time, lower robot abandonment rates, and reduced blood transfusion rates than Mazor X. Other factors including length of stay, and 90-day complications were similar.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21451,""
"Do robot-related complications influence 1 year reoperations and other clinical outcomes after robot-assisted lumbar arthrodesis? A multicenter assessment of 320 patients","Lee, Buchanan, Boddapati, Mathew, Marciano, Park, Leung, Buchholz, Pollina, Jazini, Haines, Schuler, Good, Lombardi, Lehman","https://doi.org/10.1186/s13018-021-02452-z","20211026","PubMed","Complications; Lumbar fusion; Mazor X; Reoperations; Robot-assisted spine surgery; Adolescent; Adult; Aged; Aged, 80 and over; Arthrodesis; Blood Transfusion; Female; Humans; Intraoperative Complications; Length of Stay; Lumbar Vertebrae; Male; Middle Aged; Reoperation; Risk; Risk Factors; Robotic Surgical Procedures; Spinal Fusion; Time Factors; Treatment Outcome; Young Adult","Robot-assisted platforms in spine surgery have rapidly developed into an attractive technology for both the surgeon and patient. Although current literature is promising, more clinical data is needed. The purpose of this paper is to determine the effect of robot-related complications on clinical outcomes METHODS: This multicenter study included adult (Ã¢â€°Â¥18 years old) patients who underwent robot-assisted lumbar fusion surgery from 2012-2019. The minimum follow-up was 1 year after surgery. Both bivariate and multivariate analyses were performed to determine if robot-related factors were associated with reoperation within 1 year after primary surgery. A total of 320 patients were included in this study. The mean (standard deviation) Charlson Comorbidity Index was 1.2 (1.2) and 52.5% of patients were female. Intraoperative robot complications occurred in 3.4% of patients and included intraoperative exchange of screw (0.9%), robot abandonment (2.5%), and return to the operating room for screw exchange (1.3%). The 1-year reoperation rate was 4.4%. Robot factors, including robot time per screw, open vs. percutaneous, and robot system, were not statistically different between those who required revision surgery and those who did not (P&gt;0.05). Patients with robot complications were more likely to have prolonged length of hospital stay and blood transfusion, but were not at higher risk for 1-year reoperations. The most common reasons for reoperation were wound complications (2.2%) and persistent symptoms due to inadequate decompression (1.5%). In the multivariate analysis, robot related factors and complications were not independent risk factors for 1-year reoperations. This is the largest multicenter study to focus on robot-assisted lumbar fusion outcomes. Our findings demonstrate that 1-year reoperation rates are low and do not appear to be influenced by robot-related factors and complications; however, robot-related complications may increase the risk for greater blood loss requiring a blood transfusion and longer length of stay.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21452,""
"Robotic gastric surgery: a monocentric case series and review of the literature","Staderini, Giudici, Coratti, Bisogni, Cammelli, Barbato, Gatto, Manetti, Braccini, Cianchi","https://doi.org/10.23736/S2724-5691.21.08769-1","20211028","PubMed","Gastrectomy; Humans; Laparoscopy; Retrospective Studies; Robotic Surgical Procedures; Stomach Neoplasms","The technical complexity of D2 lymphadenectomy and esophago-jejunal anastomosis are the main factors that limit the application of laparoscopic surgery in the treatment of gastric cancer. Robotic assisted gastric surgery provides potential technical advantages over conventional laparoscopy but an improvement in clinical outcomes after robotic surgery has not been demonstrated yet. Data from 128 consecutive patients who had undergone robotic gastrectomy for gastric cancer at our center institution from April 2017 to June 2020 where retrospectively reviewed from a prospectively updated database. A narrative review was then carried out on PubMed, Embase and Scopus using the following keywords: ""gastric cancer,"" ""robotic surgery,"" ""robotic gastrectomy"" and ""robotic gastric surgery"". Ninety-eight patients underwent robotic distal gastrectomy and 30 underwent robotic total gastrectomy. The mean value of estimated blood loss was 99.5 ml. No patients required conversion to laparoscopy or open surgery. The median number of retrieved lymph nodes was 42. No tumor involvement of the proximal or distal margin was found in any patient. The median time to first flatus and first oral feeding was on postoperative day 3 and 5, respectively. We registered 6 leakages (4.6%), namely, 1 duodenal stump leakage and 5 anastomotic leakages. No 30-day surgical related mortality was recorded. The median length of hospital stay was 10.5 days (range 4-37). Published data and our experience suggest that the robotic approach for gastric cancer is safe and feasible with potential advantages over conventional laparoscopy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21453,""
"Robotic liver surgery: literature review and future perspectives","Mangano, Valle, Masrur, Bustos, Gruessner, Giulianotti","https://doi.org/10.23736/S2724-5691.21.08495-9","20211028","PubMed","Hepatectomy; Laparoscopy; Liver; Retrospective Studies; Robotic Surgical Procedures","Minimally invasive liver resections (MILR) have been gaining popularity over the last decades. MILR provides superior peri-operative outcome. Despite these advantages, the penetrance of MILR in the clinical setting has been limited, and it was slowed down, among other factors, also by the laparoscopic technological limitations. A literature review has been carried out (Pubmed, Embase and Scopus platforms) focusing on the role of robotic surgery in MILR. The literature review results are presented and our additional remarks on the topic are discussed. Robotic MILR has been helping to expand the penetrance of MIS in liver surgery by making possible increasingly more challenging procedures. Minor resections still represent most of the robotic liver surgery data currently available. Robotic liver surgery is safe and effective, and it shows perioperative outcomes comparable with laparoscopic and open surgery. The oncological efficacy, within the limitations of the current level of evidence (mostly retrospective studies and literature heterogeneity), seems to show promising result. High quality prospective randomized studies, the use of prospective registry data, and multi-institutional efforts are needed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21454,""
"Robotic bariatric surgery for the obesity: a systematic review and meta-analysis","Zhang, Miao, Ren, Li","https://doi.org/10.1007/s00464-020-08283-z","20210929","PubMed","Bariatric surgery; Laparoscopic; Meta-analysis; Obesity; Robotic; Bariatric Surgery; Humans; Laparoscopy; Length of Stay; Obesity; Obesity, Morbid; Postoperative Complications; Robotic Surgical Procedures; Treatment Outcome","The aim of this meta-analysis is to evaluate the safety and efficacy of bariatric surgery (BS) in patients with obesity by robotic bariatric surgery (RBS) compared with laparoscopic bariatric surgery (LBS). The study was performed through searching in Pubmed, Web of Science, Embase database and Cochrane Library until March 31, 2020 comparing RBS with LBS. Data were calculated on the following endpoints: operative time, length of hospital stay, reoperation within 30Ã‚Â days, overall complications, leak, stricture, pulmonary embolisms, estimated blood loss and mortality. Data as relative risks (OR), or weighted mean difference (WMD) were summarized with 95% confidence interval (CI). Risk of publication bias was assessed through standard methods. Thirty eligible trials including 7,239 robotic and 203,181 laparoscopic surgery cases showed that RBS was referred to attain longer operative time [WMDÃ¢â‚¬â€°=Ã¢â‚¬â€°27.61Ã‚Â min; 95%CI (16.27-38.96); PÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.01] and lower mortality [OR 2.40; 95% CI (1.24-4.64); PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.009] than LBS. Length of hospital stay [WMDÃ¢â‚¬â€°=Ã¢â‚¬â€°-Ã¢â‚¬â€°0.02; 95% CI (-Ã¢â‚¬â€°0.19-0.15); PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.819], reoperation within 30Ã‚Â days [OR 1.36; 95% CI (0.65-2.82); PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.411], overall complications [OR 0.88; 95% CI (0.68-1.15); PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.362], leak [OR 1.04; 95% CI (0.43-2.51); PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.933], stricture [OR 1.05; 95% CI (0.52-2.12); PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.895], pulmonary embolisms [OR 1.97; 95% CI (0.93-4.17); PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.075], estimated blood loss[WMDÃ¢â‚¬â€°=Ã¢â‚¬â€°-Ã¢â‚¬â€°1.93; 95% CI (-Ã¢â‚¬â€°4.61-0.75); PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.158] were almost similar in both RBS group and LBS group. Three was no statistically significant difference between RRYGB and LRYGB in EWL%, no statistical significance between RSG and LSG after 1Ã‚Â year, 2Ã‚Â years and 3Ã‚Â years. RBS presented lower mortality within 90Ã‚Â days and longer operative time in this meta-analysis with similar safety and efficacy for the obesity compared with LBS in other outcomes. Additionally, RBS might be beneficial in the future if it would be evaluated in comprehensive and long-term endpoints.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21455,""
"Tricky Diagnosis and Robot-laparoscopic Surgical Approach to Disseminated Peritoneal Leiomyomatosis","Barison, Alvarenga-Bezerra, MaranhÃƒÂ£o, Gomes","https://doi.org/10.1016/j.jmig.2021.04.006","20211026","PubMed","Disseminated myoma; Pelvic deperitonization; Radical hysterectomy; Robotic surgery; Female; Humans; Hysterectomy; Laparoscopy; Leiomyomatosis; Middle Aged; Pregnancy; Robotics; Uterine Myomectomy; Uterine Neoplasms","To show the challenging diagnosis of, and safe robotic surgical approach to, a rare case of disseminated peritoneal leiomyomatosis (DPL). A clinical case shown by a sequential demonstration of investigation, diagnosis, and surgical approach, with narrated video footage. DPL is a rare disease, with only a little more than 150 cases reported in the literature [1]. It is defined by subperitoneal proliferation of benign smooth muscle cell nodules, macroscopically mimicking peritoneal carcinomatosis [2]. The etiology remains unclear, but different hypotheses have been put forward, such as subperitoneal mesenchymal stem cell metaplasia and iatrogenic origin after myomectomy [3]. Despite its usual benign behavior, DPL can rarely present with malignant degeneration, and therefore a complete resection of multiple lesions is recommended [4]. This case involves a 45-year-old patient presenting with dysmenorrhea, abdominal pain, and major abnormal uterine bleeding, requiring previous blood transfusion and no response after 2 years of clinical treatment. She had a previous cesarean delivery, with no reproductive desire at present and no history of other pelvic surgeries. Pelvic examination showed an enlarged mobile uterus at the height of the pubic symphysis, and both ultrasonography and magnetic resonance imaging confirmed an enlarged uterus due to multiple myomas. (1) Diagnostic laparoscopy with implant biopsies and uterine curettage for investigation of DPL and its differential diagnoses, followed by robot-assisted laparoscopic approach, with key strategies for a safe performance. (2) Radical hysterectomy with bilateral salpingo-oophorectomy, omentectomy, and wide pelvic peritoneal resection were performed. (3) For this complex procedure, the identification and preservation of important landmarks and pelvic anatomy were mandatory, as well as removal of all surgical specimens in monobloc. Final pathology report: disseminated leiomyomatosis with no evidence of malignancy. The patient had no complications after surgery and was discharged on the second postoperative day with mild abdominal pain. DPL diagnosis can be tricky owing to its macroscopic similarity to peritoneal carcinomatosis and the difficulty of identification in imaging examinations. Moreover, the robotic platform can be a helpful and safe tool for the surgical treatment of DPL and complete resection of all peritoneal lesions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21456,""
"Are social robots ready yet to be used in care and therapy of autism spectrum disorder: A systematic review of randomized controlled trials","Salimi, Jenabi, Bashirian","https://doi.org/10.1016/j.neubiorev.2021.04.009","20210915","PubMed","Autism spectrum disorder; Health outcomes; Neurodevelopmental disorder; Randomized controlled trial; Social robot; Systematic review; Autism Spectrum Disorder; Autistic Disorder; Humans; Randomized Controlled Trials as Topic; Robotics; Social Interaction","Autism is a neurodevelopmental disorder that affects the everyday life of people who have this lifelong condition. Robots hold great promise for uplifting therapy and care of the affected population. We searched Scopus, Medline, ScienceDirect, Web of Science, and PubMed databases for randomized controlled trials that had evaluated robot use in the therapy of people with autism, to see how effective social robots have been incorporated in autism care. Out of 240 papers initially identified, 19 satisfied the inclusion criteria and were fully evaluated. Overall, 10 different robots were utilized in the trials, out of which, four were non-humanoids. The number of papers with positive results for using robots on the main and secondary parameters was 11 and 5, respectively. Three papers reported that robot groups did not achieve better results than others. Robots in the papers included here were mainly added as the ""entertainment agent"" to elicit greater engagement from the participants, which is understandable, as robots at this stage might not be ready yet to deliver high-end care.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21457,""
"Evaluation of cost-effectiveness among open, laparoscopic and robotic distal pancreatectomy: A systematic review and meta-analysis","Partelli, Ricci, Cinelli, Montorsi, Ingaldi, Andreasi, Crippa, Alberici, Casadei, Falconi","https://doi.org/10.1016/j.amjsurg.2021.03.066","20210909","PubMed","Cost-effectiveness; Distal pancreatectomy; Laparoscopic; Pancreas; Robotic; Cost-Benefit Analysis; Humans; Laparoscopy; Length of Stay; Pancreatectomy; Patient Readmission; Prospective Studies; Publication Bias; Randomized Controlled Trials as Topic; Retrospective Studies; Robotic Surgical Procedures","The cost-effectiveness of minimally invasive distal pancreatectomy (MIDP) is still a matter of debate. This study compares the cost-effectiveness of open (ODP), laparoscopic (LDP) and robotic distal pancreatectomy (RDP). Pubmed, Web of Science and Cochrane Library databases were searched. Studies comparing cost-effectiveness of ODP and MIDP were included. A total of 1052 titles were screened and 16 articles were included in the study, 2431 patients in total. LDP resulted the most cost-efficient procedure, with a mean total cost of 14,682Ã‚Â Ã‚Â±Ã‚Â 5665 Ã¢â€šÂ¬ and the lowest readmission rates. ODP had lower surgical procedure costs, 3867Ã‚Â Ã‚Â±Ã‚Â 768 Ã¢â€šÂ¬. RDP was the safest approach regarding hospital stay costs (5239Ã‚Â Ã‚Â±Ã‚Â 1741 Ã¢â€šÂ¬), length of hospital stay, morbidity, clinically relevant pancreatic fistula and reoperations. In this meta-analysis MIDP resulted as the most cost-effective approach. LDP seems to be protective against high costs, but RDP seems to be safer.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21458,""
"Anatomical predictors of long-term urinary incontinence after robot-assisted laparoscopic prostatectomy: A systematic review","MuÃƒÂ±oz-Calahorro, GarcÃƒÂ­a-SÃƒÂ¡nchez, Barrero-Candau, GarcÃƒÂ­a-Ramos, RodrÃƒÂ­guez-PÃƒÂ©rez, Medina-LÃƒÂ³pez","https://doi.org/10.1002/nau.24652","20210930","PubMed","pelvic floor measurements; postprostatectomy incontinence; preoperatory magnetic resonance imaging; robot-assisted laparoscopic prostatectomy; Humans; Laparoscopy; Male; Postoperative Complications; Prostatectomy; Prostatic Neoplasms; Robotic Surgical Procedures; Urinary Incontinence","There is scarce evidence of anatomical risk factors that might affect long-term post-prostatectomy incontinence (PPI) in patients undergoing robot-assisted laparoscopic prostatectomy (RALP). This systematic review aims to identify anatomical measurements in preoperative magnetic resonance imaging (MRI) that might be associated with increased risk of urinary incontinence (UI) 1 year after RALP. A comprehensive search on Pubmed and Scopus databases up to November 2020 was performed. Eight articles met the inclusion criteria and were finally selected. The selected studies included 1146 patients. Seven articles focused on membranous urethral length (MUL); all of them related MUL to long-term PPI in univariate analysis and five of them in multivariate analysis. Four studies presented MUL difference to measure the magnitude of the effect. Average MUL (mm) was 15.9 (SD, 2.6), 16.1 (95% confidence interval [CI]: 13.9-18.9), 12.1 (95% CI 9.7-14.9) and 14.5 in continent patients and 13.9 (SD, 2.9), 10 (95% CI: 8.7-12.1), 10.3 (95% CI: 8.7-12.4) and 9.3 in incontinent patients, with statistically significant differences in all cases. Five studies presented the odds ratio as a result; although there was substantial heterogeneity in the methods used to obtain it, there was consistency in finding an inverse association between MUL and PPI. Other measurements including prostatic-urethral angle, membranous urethral thickness, intraprostatic urethral length and intravesical prostatic protrusion have been reported in few studies, and no association with long-term PPI was found. Levator ani muscle thickness was related to long-term PPI in one article. Greater MUL on preoperative MRI is associated with lower risk of UI 1 year after RALP.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21459,""
"Modelling the inhibitors of cold supply chain using fuzzy interpretive structural modeling and fuzzy MICMAC analysis","Sharma, Abbas, Siddiqui","https://doi.org/10.1371/journal.pone.0249046","20210914","PubMed","Food Storage; Food Supply; Frozen Foods; Fuzzy Logic; Logistic Models; Workforce","The Cold Supply Chain (CSC) is an integral part of the supply chain of perishable products. The aim of this research is to examine the inhibitors that have a major impact on the performance of CSC operations in the United Arab Emirates (UAE). This study provides a synthesis and suggests a hierarchical model among CSC inhibitors and their respective relevance. The hierarchical synthesis of twelve (12) primary CSC inhibitors is achieved through a comprehensive literature review and consultation with academics and CSC professionals. This study used semi-structured interviews, a fuzzy interpretive structural modeling (FISM) and a Fuzzy-MICMAC (FMICMAC) analysis to explore and establish the relationship between and among identified inhibitors. FISM is used to examine the interaction between inhibitors, while FMICMAC analysis is used to examine the nature of inhibitors on the basis of their dependence and driving power. The results of the FISM and FMICMAC analysis show the inter-relationships and relative dominance of identified inhibitors. The results show that some inhibitors are of high strategic importance due to their high driving power and low dependence. These inhibitors seek more management attention in order to improve their effectiveness. The result of a hierarchical model helps to understand the influence of a particular inhibitor on others. 'Higher capital and operating costs' occupy the highest level in the FISM model. The 'fragmented cold supply chains', 'lack of skilled labor', 'inadequate information system infrastructure' and 'lack of commitment by top level management' had strong driving power but weak dependence, which characterizes them as independent inhibitors. Management should be extra careful when dealing with these inhibitors as they influence the effects of other variables at the top of the FISM hierarchy in the overall management of the cold supply chain. The study also suggests a number of recommendations for addressing these inhibitors in cold supply chains operating in the UAE. With due attention and care for these inhibitors, the operation of the cold supply chains is likely to be even more successful.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21460,""
"Laparoscopic versus robotic-assisted Heller myotomy for the treatment of achalasia: A systematic review with meta-analysis","Xie, Vatsan, Gangemi","https://doi.org/10.1002/rcs.2253","20210818","PubMed","Heller myotomy; achalasia; laparoscopy; meta-analysis; minimal invasive surgery; robotic-assisted laparoscopy; Esophageal Achalasia; Fundoplication; Heller Myotomy; Humans; Laparoscopy; Retrospective Studies; Robotic Surgical Procedures; Treatment Outcome","Robotic-assisted laparoscopic Heller myotomy has been proposed as an alternative minimally invasive approach to traditional laparoscopy for the treatment of achalasia. This systematic review aims to compare the safety and post-operative outcomes of the two procedures. Systematic literature search was performed in MEDLINE through Ovid, Scopus and Cochrane to identify clinical trials and retrospective analyses. Outcome measures used for meta-analysis included operative time, estimated blood loss, length of stay, 30-day readmission, intraoperative oesophageal perforation, conversion, mortality, morbidity, symptom relief beyond 1Ã‚Â year, re-intervention for recurrent symptoms and gastroesophageal reflux during follow-up rates. Seven studies were selected with a total of 3214 patients. The only factor to be statistically different is intraoperative oesophageal perforation rate, which is lower in robotic-assisted Heller myotomy compared to laparoscopic (odds ratioÃ‚Â =Ã‚Â 0.1139; 95% confidence interval [0.0334, 0.3887]; pÃ‚Â =Ã‚Â 0.0005). The results suggest a robotic approach is associated with improved patient safety.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21461,""
"A systematic review and meta-analysis of conventional laparoscopic versus robot-assisted laparoscopic pyeloplasty in infants","Chandrasekharam, Babu","https://doi.org/10.1016/j.jpurol.2021.03.009","20211014","PubMed","Child; Humans; Infant; Kidney Pelvis; Laparoscopy; Robotic Surgical Procedures; Robotics; Treatment Outcome; Ureteral Obstruction; Urologic Surgical Procedures","While there are several reports confirming the safety and efficacy of laparoscopic pyeloplasty (LP) and robot-assisted laparoscopic pyeloplasty (RALP) in children there have been none comparing LP and RALP specifically in infants. In this meta-analysis, we have compared the outcomes of LP and RALP in infants. Pubmed (Medline), Publon, Index Medicus and Embase were searched using the search terms: pyeloplasty (laparoscopic OR robot-assisted) AND (infant), to identify all papers pertaining to LP and RALP. Systematic review was performed to identify information regarding number of patients/renal units, age, body weight, operating time, hospital stay, success and complications. Meta-analysis of heterogeneity was reported with I2statistics. Once heterogeneity was found low, the pooled outcomes were compared with student's t test and Fishers exact test, wherever appropriate. After screening a total of 267 articles, 18 articles were included (10 articles on LP, 7 on RALP, 1 reporting both), comprising 323 renal units for LP and 173 renal units for RALP. With low heterogeneity (I2: 0%) both groups were considered to have been conducted under similar conditions for fixed effect model. There was no significant difference between the success rates of LP or RALP (97.5% vs 94.8%; pÃ‚Â =Ã‚Â 0.21). The mean age at operation was significantly lower for LP (5.6Ã‚Â Ã‚Â±Ã‚Â 1.8 months) than RALP (7.2Ã‚Â Ã‚Â±Ã‚Â 1.2 months, PÃ‚Â =Ã‚Â 0.0001). The duration of surgery was 137Ã‚Â Ã‚Â±Ã‚Â 45Ã‚Â min for LP while significantly higher at 179Ã‚Â Ã‚Â±Ã‚Â 49Ã‚Â min for RALP (pÃ‚Â =Ã‚Â 0.0001). The mean (s.d) time to discharge was 2.0 (1.9) days for LP while 1.3 (0.4) days for RALP. The overall complication rate was significantly higher (summary table) for RALP than LP (pÃ‚Â =Ã‚Â 0.03), mainly due to more port-site hernias in RALP. In the present study, we found that the success of LP and RALP in infants was similar. RALP in infants had longer duration of surgery, similar hospital stay and higher Clavien-3 complications than LP. While several studies have reported favorable outcomes for RALP over LP in children, this was not the case in infants. The smaller workspace, in an infant, can significantly limit the mobility of robotic instruments and increase the chance of port-site conflicts or trocar collisions. The use of larger robotic ports and instruments in the small space of infant abdomen might have been responsible for higher complications in RALP, including significantly larger number of port-site hernias. This meta-analysis represents the early experience of most RALP in infants, and it is possible that with experience RALP outcomes in infants also will catch up with LP. Miniaturization of robotic instruments might render RALP the future standard of care for pyeloplasty in infants.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21462,""
"Clinical and Cost Outcomes of Robot-Assisted Inguinal Hernia Repair: A Systematic Review","Ye, Tang, Shenoy, Mederos, Mak, Booth, Wilson, Gunnar, Girgis, Maggard-Gibbons, Begashaw, Childers, Shekelle","https://doi.org/10.1016/j.jamcollsurg.2020.12.066","20210930","PubMed","Cost-Benefit Analysis; Hernia, Inguinal; Herniorrhaphy; Hospital Costs; Humans; Laparoscopy; Operative Time; Postoperative Complications; Recurrence; Robotic Surgical Procedures; Treatment Outcome","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21463,""
"Postoperative outcomes, lymph node dissection and effects on costs among thoracotomy, video-assisted and robotic-assisted lobectomy for clinical stage I non-small cell lung cancer","Gullo, Gagliardo, Palazzolo, Porrello, Gulotta, Lo Faso, Gulotta","https://doi.org/10.23736/S2724-5691.20.08395-9","20211028","PubMed","Carcinoma, Non-Small-Cell Lung; Humans; Length of Stay; Lung Neoplasms; Lymph Node Excision; Pneumonectomy; Retrospective Studies; Robotic Surgical Procedures; Thoracotomy","Thoracotomy, video-assisted thoracoscopic surgery (VATS) and robotic assisted thoracoscopic surgery (RATS)-lobectomy are widely accepted procedures for the surgical treatment of clinical (c)stage I non- small cell lung cancer (NSCLC). In the current literature which procedure gives more benefits is still debated. We present a comparison between these three procedures in term of advantages and postoperative outcomes. A multicentric study about 259 lobectomies from 2013 to 2019: 128 patients underwent TL, 96 VATS and 35 RATS. Different variables were retrospectively analyzed among these three cohorts of patients with diagnosis of cStage I NSCLC. Rate of major complications comparable in VATS, RATS and TL; Advantages for RATS in minor complications (TL 34.4% vs. VATS 18.75% vs. RATS 8.57%. P=0.0015), postoperative days in Intensive Care Unit, days to chest tube removal, length of postoperative hospitalization (P&lt;0.0001) and number of lymph nodes dissected (P=0.0257). Operating times are shorter in VATS than RATS (P&lt;0.05). Pain (NRS Scale) is comparable. TL remains the conventional approach for stage II-IIIA(N2) NSCLC. RATS showed great advantages, but its higher operating time and costs, mostly, today don't justify its adoption as gold standard for the surgical treatment of cStage I NSCLC, instead of VATS.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21464,""
"Economic analysis of open versus laparoscopic versus robotic hepatectomy: a systematic review and meta-analysis","Ziogas, Evangeliou, Mylonas, Athanasiadis, Cherouveim, Geller, Schulick, Alexopoulos, Tsoulfas","https://doi.org/10.1007/s10198-021-01277-1","20210917","PubMed","Economic cost; Laparoscopic liver resection; Meta-analysis; Open liver resection; Robotic liver resection; Systematic review; Costs and Cost Analysis; Hepatectomy; Humans; Laparoscopy; Length of Stay; Retrospective Studies; Robotic Surgical Procedures; Treatment Outcome","Following the publication of reports from landmark international consensuses (Louisville 2008 and Morioka 2014), minimally invasive hepatectomy became widely accepted as a legitimate alternative to open surgery. We aimed to compare the operative, hospitalization, and total economic costs of open (OLR) vs. laparoscopic (LLR) vs. robotic liver resection (RLR). We performed a systematic literature review (end-of-search date: July 3, 2020) according to the PRISMA statement. Random-effects meta-analyses were conducted. Quality assessment was performed with the Cochrane Risk of Bias tool for randomized controlled trials, and the Newcastle-Ottawa Scale for non-randomized studies. Thirty-eight studies reporting on 3847 patients (1783 OLR; 1674 LLR; 390 RLR) were included. The operative costs of LLR were significantly higher than those of OLR, while subgroup analysis also showed higher operative costs in the LLR group for major hepatectomy, but no statistically significant difference for minor hepatectomy. Hospitalization costs were significantly lower in the LLR group, with subgroup analyses indicating lower costs for LLR in both major and minor hepatectomy series. No statistically significant difference was observed regarding total costs between LLR and OLR both overall and on subgroup analyses in either major or minor hepatectomy series. Meta-analyses showed higher operative, hospitalization, and total costs for RLR vs. LLR, but no statistically significant difference regarding total costs for RLR vs. OLR. LLR's higher operative costs are offset by lower hospitalization costs compared to OLR leading to no statistically significant difference in total costs, while RLR appears to be a more expensive alternative approach.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21465,""
"Is lymphangitic streaking associated with different pathogens?","Kimia, Voskoboynik, Hudgins, Harper, Landschaft, Kupiec, Kimia","https://doi.org/10.1016/j.ajem.2021.02.055","20210830","PubMed","Lymphangitis; Paronychia; Streaking; Child; Cross-Sectional Studies; Electronic Health Records; Female; Gram-Negative Bacterial Infections; Humans; Lymphangitis; Male; Methicillin-Resistant Staphylococcus aureus; Natural Language Processing; Paronychia; Retrospective Studies; Staphylococcal Infections","Little is known regarding the differences in microbiology associated with cellulitis or abscess with or without lymphangitic streaking. The objective of our study is to assess whether there are differences in the pathogens identified from wound cultures of patients with paronychia with and without associated lymphangitis. Retrospective cross-sectional study at a tertiary pediatric emergency department over 25Ã‚Â years. We opted to assess patients with paronychia of the finger, assuming that these cases will have a greater variety of causative pathogens compared to other cases of cellulitis and soft tissue abscess that are associated with nail biting. Case identification was conducted using a computerized text-screening search that was refined by manual chart review. We included patients from 1Ã‚Â month to 20Ã‚Â years of age who underwent an incision and drainage (I&amp;D) of a paronychia and had a culture obtained. The presence or absence of lymphangitis was determined from the clinical narrative in the medical record. We excluded patients treated with antibiotics prior to I&amp;D as well as immune-compromised patients. We used descriptive statistics for prevalence and Ãâ€¡2 tests for categorical variables. Two hundred sixty-six patients met inclusion criteria. The median age was 9.7Ã‚Â years [IQR 4.7, 15.4] and 45.1% were female. Twenty-two patients (8.3%) had lymphangitic streaking associated with their paronychia. Patients with lymphangitis streaking were similar to those without lymphangitis in terms of age and sex (pÃ‚Â =Ã‚Â 0.52 and pÃ‚Â =Ã‚Â 0.82, respectively). Overall, the predominant bacteria was MSSA (40%) followed by MRSA (26%). No significant differences were found between the pathogens in the 22 patients with associated lymphangitis compared to the 244 patients without. Staphylococcus aureus represent the majority of pathogens in paronychia, although streptococcal species and gram-negative bacteria were also common. Among patients with paronychia of the finger, there seems to be no association between pathogen type and presence of lymphangitic streaking.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21466,""
"Minimally invasive versus open radical resection surgery for hilar cholangiocarcinoma: Comparable outcomes associated with advantages of minimal invasiveness","Tang, Qiu, Deng, Liu, Cheng, Liu, Du","https://doi.org/10.1371/journal.pone.0248534","20211012","PubMed","Bile Duct Neoplasms; Blood Loss, Surgical; Humans; Klatskin Tumor; Length of Stay; Minimally Invasive Surgical Procedures; Postoperative Complications; Robotic Surgical Procedures","Minimally invasive surgery (MIS) provides a new approach for patients with hilar cholangiocarcinoma (HCCA). However, whether it can achieve similar outcomes to traditional open surgery (OS) remains controversial. To assess the safety and feasibility of MIS for HCCA, a systematic review and meta-analysis was performed to compare the outcomes of MIS with OS. Seventeen outcomes were assessed. Nine studies involving 382 patients were included. MIS was comparable in blood transfusion rate, R0 resection rate, lymph nodes received, overall morbidity, severe morbidity (Clavien-Dindo classification &gt; = 3), bile leakage rate, wound infection rate, intra-abdominal infection rate, days until oral feeding, 1-year overall survival, 2-year overall survival and postoperative mortality with OS. Although operation time was longer (mean difference (MD) = 93.51, 95% confidence interval (CI) = 64.10 to 122.91, P &lt; 0.00001) and hospital cost (MD = 0.68, 95% CI = 0.03 to 1.33, P = 0.04) was higher in MIS, MIS was associated with advantages of minimal invasiveness, that was less blood loss (MD = -81.85, 95% CI = -92.09 to -71.62, P &lt; 0.00001), less postoperative pain (MD = -1.21, 95% CI = -1.63 to -0.79, P &lt; 0.00001), and shorter hospital stay (MD = -4.22, 95% CI = -5.65 to -2.80, P &lt; 0.00001). The safety and feasibility of MIS for HCCA is acceptable in selected patients. MIS is a remarkable alternative to OS for providing comparable outcomes associated with a benefit of minimal invasiveness and its application should be considered more.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21467,""
"Use of the Scan-and-Plan Workflow in Next-Generation Robot-Assisted Pedicle Screw Insertion: Retrospective Cohort Study and Literature Review","Mao, Khan, Soliman, Levy, McGuire, Starling, Hess, Agyei, Meyers, Mullin, Pollina","https://doi.org/10.1016/j.wneu.2021.02.119","20210913","PubMed","Accuracy of pedicle screw placement; Navigation-assisted spinal surgery; Robotic guidance; Robotic workflow; Spinal stabilization; Adult; Aged; Cohort Studies; Female; Humans; Male; Medical Errors; Middle Aged; Neurosurgical Procedures; Pedicle Screws; Postoperative Complications; Retrospective Studies; Robotic Surgical Procedures; Spinal Fusion; Spine; Workflow","To report our experience using the scan-and-plan workflow and review current literature on surgical efficiency, safety, and accuracy of next-generation robot-assisted (RA) spine surgery. The records of patients who underwent RA pedicle screw fixation were reviewed. The accuracy of pedicle screw placement was determined based on the Ravi classification system. To evaluate workflow efficiency, 3 demographically matched cohorts were created to analyze differences in time per screw placement (defined as operating room [OR] time divided by number of screws placed). Group A had &lt;4 screws placed, Group B had 4 screws placed, and Group C had &gt;4 screws placed. Intraoperative errors and postoperative complications were collected to elucidate safety. Eighty-four RA cases (306 pedicle screws) were included for analysis. The mean number of screws placed was 2.1 Ã‚Â± 0.3 in Group A and 6.4 Ã‚Â± 1.2 in Group C; 4 screws were placed in Group B patients. The accuracy rate (Ravi grade I) was 98.4%. Screw placement time was significantly longer in Group A (101 Ã‚Â± 37.7 minutes) than Group B (50.5 Ã‚Â± 25.4 minutes) or C (43.6 Ã‚Â± 14.7 minutes). There were no intraoperative complications, robot failures, or in-hospital complications requiring a return to the OR. The scan-and-plan workflow allowed for a high degree of accuracy. It was a safe method that provided a smooth and efficient OR workflow without registration errors or robotic failures. After the placement of 4 pedicle screws, the per-screw time remained constant. Further studies regarding efficiency and utility in multilevel procedures are necessary.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21468,""
"Reinforcement Learning in Neurocritical and Neurosurgical Care: Principles and Possible Applications","Liu, Qiao, Altinel","https://doi.org/10.1155/2021/6657119","20210910","PubMed","Algorithms; Brain Injuries, Traumatic; Brain Neoplasms; Computational Biology; Critical Care; Decision Making, Computer-Assisted; Humans; Learning; Neurosurgery; Reinforcement, Psychology","Dynamic decision-making was essential in the clinical care of surgical patients. Reinforcement learning (RL) algorithm is a computational method to find sequential optimal decisions among multiple suboptimal options. This review is aimed at introducing RL's basic concepts, including three basic components: the state, the action, and the reward. Most medical studies using reinforcement learning methods were trained on a fixed observational dataset. This paper also reviews the literature of existing practical applications using reinforcement learning methods, which can be further categorized as a statistical RL study and a computational RL study. The review proposes several potential aspects where reinforcement learning can be applied in neurocritical and neurosurgical care. These include sequential treatment strategies of intracranial tumors and traumatic brain injury and intraoperative endoscope motion control. Several limitations of reinforcement learning are representations of basic components, the positivity violation, and validation methods.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21469,""
"Systematic review of perioperative and oncologic outcomes of minimally-invasive surgery for hilar cholangiocarcinoma","Cipriani, Ratti, Fiorentini, Reineke, Aldrighetti","https://doi.org/10.1007/s13304-021-01006-6","20211015","PubMed","Klatskin hilar cholangiocarcinoma; Laparoscopic liver resection; Minimally-invasive liver resection; Robot-assisted liver resection; Robotic liver resection; Bile Duct Neoplasms; Cholangiocarcinoma; Hepatectomy; Humans; Klatskin Tumor; Laparoscopy; Minimally Invasive Surgical Procedures; Robotic Surgical Procedures; Treatment Outcome","Most surgeons have traditionally been reluctant toward minimally-invasive surgery for bile duct tumors. This study aimed to perform a systematic literature review on perioperative and oncologic results of pure laparoscopic and robotic curative-intent surgery for hilar cholangiocarcinoma. According to the PRISMA statement, a systematic review was conducted into Pubmed, EMBASE and Cochrane. A critical appraisal of study was performed according to the Joanna Briggs Institute tools. Nineteen studies (12 on pure laparoscopy and 7 on robotics) were included: 7 case reports, 9 case series, 3 case-control (193 patients). The pooled conversion, morbidity, biliary leak and mortality rates were 5.5%, 43%, 16.4% and 4%. The weighted mean of operative time, blood loss and postoperative stay were 388Ã‚Â min, 446Ã‚Â mL and 14Ã‚Â days. For pure laparoscopy, the pooled R0 rate was 86%; overall survival and disease-free survival rates ranged from 85 to 100% and from 80 to 100% (median observation time 6-18Ã‚Â months). For robotic surgeries, the pooled R0 rate was 69% and overall survival rates ranged from 90 to 100% (median observation time 5-15Ã‚Â months). Case reports were overall of high quality, case series of moderate / high-quality, case-control studies ranged from low to high quality. In selected patients, minimally-invasive surgery for Klatskin tumors appears feasible, safe, satisfactory for perioperative outcomes and adequate for oncologic results. However, the results are based on few studies, limited in patient numbers and with allocation criteria more restrictive than open, reporting short follow-up and mainly with non-comparative design: evidence of higher quality is recommended.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21470,""
"Use of intraoperative fluorescence to enhance robot-assisted radical prostatectomy","Rajakumar, Yassin, Musbahi, Harris, Lopez, Bryant, Tullis, Vojnovic, Hamdy, Lamb","https://doi.org/10.2217/fon-2020-0370","20211014","PubMed","ICG; RARP; fluorescence; intraoperative imaging; nerve-sparing; prostate cancer; robot-assisted radical prostatectomy; robotic surgery; Fluorescence; Fluorescent Dyes; Humans; Intraoperative Period; Lymph Nodes; Male; Organ Sparing Treatments; Prostate; Prostatectomy; Prostatic Neoplasms; Robotic Surgical Procedures","Robot-assisted radical prostatectomy has become the standard of care for the removal of localized prostate cancer. Positive outcomes depend upon the precise removal of the prostate and associated tissue without damage to nearby structures. This process can be aided by fluorescence-guided surgery to enhance the visual contrast between different structures. HereÃ‚Â the authors have conducted a systematic review using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines to identify ten investigations into the use of fluorescence-guided surgery in robot-assisted radical prostatectomy. These studies used fluorescent tracers to identify structures, including the prostate, neurovascular bundle and lymph nodes. These studies demonstrate the safe and effective use of fluorescence-guided surgery in robot-assisted radical prostatectomy and pave the way for further developments in this field.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21471,""
"Full robotic multivisceral resections: the Modena experience and literature review","Piccoli, Esposito, Pecchini, Francescato, Colli, Gozzo, Trapani, Alboni, Rocco","https://doi.org/10.1007/s13304-020-00939-8","20211015","PubMed","Combined robotic multiorgan procedures; Deep infiltrating endometriosis; Robotic multiquadrant surgery; Robotic multivisceral resections; Synchronous colorectal and renal cancer; Colectomy; Female; Humans; Laparoscopy; Operative Time; Postoperative Complications; Robotic Surgical Procedures; Robotics","The robotic platform is becoming a multidisciplinary tool, versatile, and suitable for multiple procedures. Combined multivisceral resections may represent an alternative to sequential procedures with a potential favorable impact on postoperative morbidity, and on the timing of administration of adjuvant chemotherapy. We herein present our initial experience with full robotic multivisceral resections, and a review of the literature available. Between January 2018 and April 2020, 11 patients underwent multivisceral full robotic abdominal surgery: 4 patients presented with two synchronous tumors, 4 with primary cancer associated with a benign condition and 3 cases involved deep infiltrating endometriosis. Surgical teams enrolled were: General Surgery, Urology and Gynecology. A systematic bibliographic research up to April 2020 was conducted in PubMed. 4 colorectal resections combined with partial or radical nephrectomy were performed, as well as 2 right colectomies in combination with right adrenalectomy and gastric banding removal, 2 radical prostatectomies with Nissen Fundoplication and abdominal wall hernia repair, and 3 resections of deep pelvic endometriosis with colorectal involvement. Mean total operative time was 367Ã‚Â min. No intraoperative complication or conversion to open was registered. Overall postoperative complication rate was 18.2%. 26 papers were included in the review (10 case series and 16 case reports) with a total of 156 combined multivisceral robotic procedures recorded. Robotic combined multivisceral resections proved to be safe and feasible when performed in high volume centers by expert surgeons. The heterogeneity of reports does not allow for a standardization of the procedure. Further studies and accumulation of experience are needed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21472,""
"The Emerging Role of Robotic Single-site Approach for Myomectomy: A Systematic Review of the Literature","Giovannopoulou, Prodromidou, Blontzos, Iavazzo","https://doi.org/10.1177/1553350620988227","20211015","PubMed","evidence-based surgery; gynecologic laparoscopy; robotic surgery; Adult; Female; Humans; Leiomyoma; Operative Time; Prospective Studies; Retrospective Studies; Robotic Surgical Procedures; Uterine Myomectomy; Uterine Neoplasms","<i>Objective.</i> To review the existing studies on single-site robotic myomectomy and test the safety and feasibility of this innovative minimally invasive technique. <i>Data Sources.</i> PubMed, Scopus, Google Scholar (from their inception to October 2019), as well as Clinicaltrials.gov databases up to April 2020. <i>Methods of Study Selection.</i> Clinical trials (prospective or retrospective) that reported the outcomes of single-site robotic myomectomy, with a sample of at least 20 patients were considered eligible for the review. <i>Results.</i> The present review was performed in accordance with the guidelines for Systematic Reviews and Meta-Analyses (PRISMA). Four (4) studies met the inclusion criteria, and a total of 267 patients were included with a mean age from 37.1 to 39.1Ã‚Â years and BMI from 21.6 to 29.4Ã‚Â kg/m2. The mean operative time ranged from 131.4 to 154.2Ã‚Â min, the mean docking time from 5.1 to 5.45Ã‚Â min, and the mean blood loss from 57.9 to 182.62Ã‚Â ml. No intraoperative complications were observed, and a conversion rate of 3.8% was reported by a sole study. The overall postoperative complication rate was estimated at 2.2%, and the mean hospital stay ranged from 0.57 to 4.7Ã‚Â days. No significant differences were detected when single-site robotic myomectomy was compared to the multiport technique concerning operative time, blood loss, and total complication rate. <i>Conclusion.</i> Our findings support the safety of single-site robotic myomectomy and its equivalency with the multiport technique on the most studied outcomes. Further studies are needed to conclude on the optimal minimally invasive technique for myomectomy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21473,""
"Learning curve of laparoscopic and robotic pancreas resections: a systematic review","Chan, Wang, Syn, Goh","https://doi.org/10.1016/j.surg.2020.11.046","20210902","PubMed","Humans; Laparoscopy; Learning Curve; Minimally Invasive Surgical Procedures; Operative Time; Pancreatectomy; Pancreatic Neoplasms; Pancreaticoduodenectomy; Robotic Surgical Procedures","Minimally invasive pancreatic resection has been shown recently in some randomized trials to be superior in selected perioperative outcomes compared with open resection when performed by experienced surgeons. However, minimally invasive pancreatic resection is associated with a long learning curve. This study aims to summarize the current evidence on the learning curve of minimally invasive pancreatic resection and define the number of cases required to surmount the learning curve. A systematic search was performed on PubMed, Embase, Scopus, and the Cochrane database using a detailed search strategy. Studies that did not describe the learning curve were excluded from the study. Data on the method of learning curve analysis, single surgeon versus institutional learning curve, and outcome measures were extracted and analyzed. A total of 32 studies were included in the pooled analysis: 12 on laparoscopic pancreatoduodenectomy, 9 on robotic pancreatoduodenectomy, 12 on laparoscopic distal pancreatectomy, and 3 on robotic distal pancreatectomy. Sample population was comparable between laparoscopic pancreatoduodenectomy and robotic pancreatoduodenectomy (median 63 vs 65). Six of 12 studies and 7 of 9 studies used nonarbitrary methods of analysis in laparoscopic pancreatoduodenectomy and robotic pancreatoduodenectomy, respectively. Operating time was used as the single outcome measure in 4 of 12 studies in laparoscopic pancreatoduodenectomy and 5 of 9 studies in robotic pancreatoduodenectomy. Overall, there was no significant difference between the number of cases required to surmount the learning curve for laparoscopic pancreatoduodenectomy versus robotic pancreatoduodenectomy (laparoscopic pancreatoduodenectomy 34.1 [95% confidence interval 30.7-37.7] versus robotic pancreatoduodenectomy 36.7 [95% confidence interval 32.9-41.0]; PÃ‚Â = .8241) and laparoscopic distal pancreatectomy versus robotic distal pancreatectomy (laparoscopic distal pancreatectomy 25.3 [95% confidence interval 22.5-28.3] versus robotic distal pancreatectomy 20.7 [95% confidence interval 15.8-26.5]; PÃ‚Â = .5997.) CONCLUSION: This study provides a detailed summary of existing evidence around the learning curve in minimally invasive pancreatic resection. There was no significant difference between the learning curve for robotic pancreatoduodenectomy versus laparoscopic pancreatoduodenectomy and robotic distal pancreatectomy versus laparoscopic distal pancreatectomy. These findings were limited by the retrospective nature and heterogeneity of the studies published to date.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21474,""
"Artificial Intelligence: the ""<i>Trait D'Union</i>"" in Different Analysis Approaches of Autism Spectrum Disorder Studies","Marciano, Venutolo, Ingenito, Verbeni, Terracciano, Plunk, Garaci, Cavallo, Fasano","https://doi.org/10.2174/0929867328666210203205221","20211025","PubMed","Autism; artificial intelligence; autism spectrum disorders; machine learning; metabolome; microbiome; multi-omics.; Artificial Intelligence; Autism Spectrum Disorder; Child; Humans; Machine Learning; Neuroimaging; Phenotype","Autistic Spectrum Disorder (ASD) is a neurodevelopmental condition affecting approximately 1 out of 70 (range 1:59 - 1:89) children worldwide. It is characterized by a delay in cognitive capabilities, repetitive and restricted behaviors and deficit in communication and social interaction. Several factors seem to be associated with ASD development; its heterogeneous nature makes the diagnosis difficult and slow since it is essentially based on screening tools focused on stereotypical and repetitive behaviors, gait, facial emotion expression and speech assessments. Recently, artificial intelligence (AI) has been widely used to investigate ASD with the overall goal of simplifying and speeding up the diagnostic process as well as making earlier access to therapies possible. The aim of this review is to provide an overview of the state-of-the-art research in the ASD field, identifying and describing machine learning (ML) approaches in ASD literature that could be used by clinicians to improve diagnostic capability and treatment efficiency. A systematic search was conducted and the resulting articles were subdivided into several categories reflecting the different fields of study associated with ASD research. The existing literature has widely demonstrated the potential of ML in several types of ASD study analyses: behavior, gait, speech, facial emotion expression, neuroimaging, genetics, and metabolomics. Therefore, AI techniques are becoming increasingly implemented and accepted, so highlighting the power of ML approaches to extract and obtain knowledge from a large volume of data. This makes ML a promising tool for future ASD research and clinical endeavors suggesting possible avenues for improving ASD screening, diagnostic and therapeutic tools.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21475,""
"Robotic versus laparoscopic hepatectomy for malignancy: A systematic review and meta-analysis","Hu, Guo, Xu, Xia, Wang, Liu, Fu","https://doi.org/10.1016/j.asjsur.2020.12.016","20210831","PubMed","Laparoscopic; Malignancy; Meta-analysis; Robotic hepatectomy; Hepatectomy; Humans; Laparoscopy; Length of Stay; Liver Neoplasms; Multicenter Studies as Topic; Operative Time; Postoperative Complications; Robotic Surgical Procedures; Treatment Outcome","The aim of this study was to compare the clinical safety and efficacy of robotic hepatectomy (RH) versus conventional laparoscopic hepatectomy (LH) for malignancy using meta-analysis. A systematic literature search was performed using PubMed, EMBASE, Medline and the Cochrane Library databases up to September 2020 for studies, which limited to comparative articles of RH or LH for malignant tumors. Stata14.0 was performed in the meta-analysis. Six studies with a total of 1093 patients (345 RH and 748 LH) were eligible for inclusion. Operative time, tumor size, open procedure rate and the proportion of right hepatectomy were found to be significantly different between RH and LH in the pooled analysis (PÃ‚Â &lt;Ã‚Â 0.05). Compared to LH, RH was associated with longer operative time, larger tumor size, lower open procedure rate and more common use for right hepatectomy. On the other hand, there was no difference in the operative time, estimated blood loss (EBL), blood transfusion rate, hospital stay, R0 resection rate, complications, resection margin, left lateral sectionectomy and left hepatectomy (PÃ‚Â &gt;Ã‚Â 0.05). For malignant tumors that require hepatectomy, robotic approaches have demonstrated similar safety and feasibility to laparoscopy, with lower open procedure rate, were suitable for larger tumor size, and have a high right hepatectomy utilization rate. These results still need to be confirmed by multicenter, high-quality randomized controlled studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21476,""
"Robot-Assisted Therapy for Upper Extremity Motor Impairment After Stroke: A Systematic Review and Meta-Analysis","Wu, Cheng, Zhang, Yang, Cai","https://doi.org/10.1093/ptj/pzab010","20210820","PubMed","Meta-Analysis; Randomized Controlled Trial; Stroke; Unilateral/Bilateral Robot-Assisted Therapy; Upper Extremity; Exoskeleton Device; Humans; Randomized Controlled Trials as Topic; Recovery of Function; Robotics; Stroke Rehabilitation; Upper Extremity","The purpose of this study was to review the effects of robot-assisted therapy (RT) for improving poststroke upper extremity motor impairment. The PubMed, Embase, Medline, and Web of Science databases were searched from inception to April 8, 2020. Randomized controlled trials that were conducted to evaluate the effects of RT on upper extremity motor impairment poststroke and that used Fugl-Meyer assessment for upper extremity scores as an outcome were included. Two authors independently screened articles, extracted data, and assessed the methodological quality of the included studies using the Physiotherapy Evidence Database (PEDro) scale. A random-effects meta-analysis was performed to pool the effect sizes across the studies. Forty-one randomized controlled trials with 1916 stroke patients were included. Compared with dose-matched conventional rehabilitation, RT significantly improved the Fugl-Meyer assessment for upper extremity scores of the patients with stroke, with a small effect size (Hedges gÃ‚Â =Ã‚Â 0.25; 95% CI, 0.11-0.38; I2Ã‚Â =Ã‚Â 45.9%). The subgroup analysis revealed that the effects of unilateral RT, but not that of bilateral RT, were superior to conventional rehabilitation (Hedges gÃ‚Â =Ã‚Â 0.32; 95% CI, 0.15-0.50; I2Ã‚Â =Ã‚Â 55.9%). Regarding the type of robot devices, the effects of the end effector device (Hedges gÃ‚Â =Ã‚Â 0.22; 95% CI, 0.09-0.36; I2Ã‚Â =Ã‚Â 35.4%), but not the exoskeleton device, were superior to conventional rehabilitation. Regarding the stroke stage, the between-group difference (ie, RT vs convention rehabilitation) was significant only for people with late subacute or chronic stroke (Hedges gÃ‚Â =Ã‚Â 0.33; 95% CI,Ã‚Â 0.16-0.50; I2Ã‚Â =Ã‚Â 34.2%). RT might be superior to conventional rehabilitation in improving upper extremity motor impairment in people after stroke with notable upper extremity hemiplegia and limited potential for spontaneous recovery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21477,""
"Texture Analysis in the Evaluation of COVID-19 Pneumonia in Chest X-Ray Images: A Proof of Concept Study","Cavallo, Troisi, Forcina, Mari, Forte, Sperandio, Pagano, Cavallo, Floris, Garaci","https://doi.org/10.2174/1573405617999210112195450","20211101","PubMed","COVID-19; X-ray; interstitial pneumonia; pneumonia; radiomics; texture analysis.; thorax; COVID-19; Humans; Proof of Concept Study; SARS-CoV-2; Tomography, X-Ray Computed; X-Rays","One of the most challenging aspects related to Covid-19 is to establish the presence of infection in an early phase of the disease. Texture analysis might be an additional tool for the evaluation of Chest X-ray in patients with clinical suspicion of Covid-19 related pneumonia. To evaluate the diagnostic performance of texture analysis and machine learning models for the diagnosis of Covid-19 interstitial pneumonia in Chest X-ray images. Chest X-ray images were accessed from a publicly available repository(https://www.kaggle. com/tawsifurrahman/covid19-radiography-database). Lung areas were manually segmented using a polygonal region of interest covering both lung areas, using MaZda, a freely available software for texture analysis. A total of 308 features per ROI was extracted. One hundred-ten Covid-19 Chest X-ray images were selected for the final analysis. Six models, namely NB, GLM, DL, GBT, ANN, and PLS-DA were selected and ensembled. According to Youden's index, the Covid-19 Ensemble Machine Learning Score showing the highest area under the curve (0.971Ã‚Â±0.015) was 132.57. Assuming this cut-off the Ensemble model performance was estimated by evaluating both true and false positive/negative, resulting in 91.8% accuracy with 93% sensitivity and 90% specificity. Moving the cut-off value to -100, although the accuracy resulted lower (90.6%), the Ensemble Machine Learning showed 100% sensitivity, with 80% specificity. Texture analysis of Chest X-ray images and machine learning algorithms may help in differentiating patients with Covid-19 pneumonia. Despite several limitations, this study can lay the ground for future research works in this field and help to develop more rapid and accurate screening tools for these patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21478,""
"Site selection for artificial recharge with treated wastewater with the integration of multi-criteria evaluation and ELECTRE III","Mahmoudi, Aydi, Ibrahim","https://doi.org/10.1007/s11356-021-12354-6","20210826","PubMed","Analytical hierarchy process; Artificial recharge; Multi-criteria evaluation; Treated wastewater; Weighted linear combination; Fuzzy Logic; Geographic Information Systems; Groundwater; Waste Water; Water","The suitable location selection for artificial recharge with treated wastewater is an important issue, especially in arid and semiarid countries as a result of rapid population growth, increasing water demand, excessive use of groundwater resources, and mismanagement of limited freshwater resources. However, the determination of suitable sites is a complex process affected the environment, social, and economic concerns. This study shows the integration of the geographic information system (GIS) and the multi-criteria evaluation (MCE) to determine a suitable artificial recharge site with treated wastewater for Ariana, Tunisia. According to the literature review, data available on artificial recharge and regional characteristics, thirteen constraints and five factors were determined to choose the best potential site for artificial recharge. The constraints helped the determination of unsuitable sites with Boolean logic, while factors, standardized using fuzzy logic and weighted with the analytic hierarchy process (AHP), helped to identify suitable locations. All criteria were overlaid on a decision structure after two scenarios based on environment and economic were identified with a weighted linear combination (WLC) that selects the suitable sites for artificial recharge. The results indicated that three potential sites were suitable for artificial recharge with treated wastewater. Finally, the ELECTRE III method was used to classify the three determining potential areas to order the best locations for aquifer recharge with treated water according to their characteristics from higher to lower weighted: distance from the road, geometric form of the site, cost of the site, and distance from wetlands.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21479,""
"Pancreatic fistulas following distal pancreatectomy are unrelated to the texture quality of the pancreas","Eshmuminov, Karpovich, Kapp, TÃƒÂ¶pfer, Endhardt, Oberkofler, Petrowsky, Lenggenhager, Tschuor, Clavien","https://doi.org/10.1007/s00423-020-02071-y","20210924","PubMed","Distal pancreatectomy; Pancreatic fistula; Pancreatic texture; Humans; Pancreas; Pancreatectomy; Pancreatic Ducts; Pancreatic Fistula; Postoperative Complications; Retrospective Studies; Risk Factors; Robotics","The relevance of pancreatic texture for pancreatic fistula (POPF) formation after distal pancreatectomy (DP) remains ill defined. Recent POPF definition adjustments and common subjective pancreatic texture assessment are further drawbacks in the investigation of pancreatic texture as a factor for POPF development after DP. The predictive value of pancreatic texture by histologic assessment was investigated for POPF formation after DP, respecting the updated 2016 fistula definition. Histologic evaluation at the resection margin included amount of steatosis, degree of fibrosis, and pancreatic duct size. A total of 102 patients who underwent DP were included. Thirty-six patients developed POPF. There was no difference in histologic variables in patients with and without POPF. In the univariate analysis, none of the three histologic features showed significant correlation with POPF formation. The ROC (receiver operating characteristic) curve demonstrated poor utility for the grade of steatosis 0.481Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°0.058 (pÃ‚Â =Ã¢â‚¬â€°0.75) and grade of fibrosis 0.466Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°0.058 (pÃ‚Â =Ã¢â‚¬â€°0.57) as predictive factors for POPF formation. Results indicate that pancreatic texture does not predict POPF formation following DP. This is particularly relevant in the context of the increasing use of robotic and laparoscopic approaches for DPs with limited clinical pancreatic texture assessment by palpation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21480,""
"Robotic-Assisted Peripheral Nerve Surgery: A Systematic Review","Chen, Goh, Goh, Chao, Huang, Kuo, Sung, Chuieng-Yi Lu, Chuang, Chang","https://doi.org/10.1055/s-0040-1722183","20210818","PubMed","Animals; Humans; Neurosurgical Procedures; Peripheral Nerves; Reconstructive Surgical Procedures; Robotic Surgical Procedures; Robotics","Ã¢â‚¬Æ’Robotic-assisted techniques are a tremendous revolution in modern surgery, and the advantages and indications were well discussed in different specialties. However, the use of robotic technique in plastic and reconstructive surgery is still very limited, especially in the field of peripheral nerve reconstruction. This study aims to identify current clinical applications for peripheral nerve reconstruction, and to evaluate the advantages and disadvantages to establish potential uses in the future. Ã¢â‚¬Æ’A review was conducted in the literatures from PubMed focusing on currently published robotic peripheral nerve intervention techniques. Eligible studies included related animal model, cadaveric and human studies. Reviews on robotic microsurgical technique unrelated to peripheral nerve intervention and non-English articles were excluded. The differences of wound assessment and nerve management between robotic-assisted and conventional approach were compared. Ã¢â‚¬Æ’Total 19 studies including preclinical experimental researches and clinical reports were listed and classified into brachial plexus reconstruction, peripheral nerve tumors management, peripheral nerve decompression or repair, peripheral nerve harvesting, and sympathetic trunk reconstruction. There were three animal studies, four cadaveric studies, eight clinical series, and four studies demonstrating clinical, animal, or cadaveric studies simultaneously. In total 53 clinical cases, only 20 (37.7%) cases were successfully approached with minimal invasive and intervened robotically; 17 (32.1%) cases underwent conventional approach and the nerves were intervened robotically; 12 (22.6%) cases converted to open approach but still intervened the nerve by robot; and 4 (7.5%) cases failed to approach robotically and converted to open surgery entirely. Ã¢â‚¬Æ’Robotic-assisted surgery is still in the early stage in peripheral nerve surgery. We believe the use of the robotic system in this field will develop to become popular in the future, especially in the fields that need cooperation with other specialties to provide the solutions for challenging circumstances.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21481,""
"A progressive scholarly acceptance analysis of robot-assisted arthroplasty: a review of the literature and prediction of future research trends","Misso, Zhen, Kelly, Collopy, Clark","https://doi.org/10.1007/s11701-020-01173-5","20211028","PubMed","Literature review; Progressive scholarly acceptance; Robot-assisted arthroplasty; Total hip arthroplasty; Total knee arthroplasty; Unicompartmental knee arthroplasty; Arthroplasty, Replacement, Knee; Bibliometrics; Humans; Robotic Surgical Procedures; Robotics","Robot-assisted arthroplasty (RAA) is increasingly practised in orthopaedic surgery. The aim of this study was to perform a bibliometric analysis of all published primary research into RAA and to apply the Progressive Scholarly Acceptance (PSA) model to evaluate its acceptance as an orthopaedic surgical technique. A literature search was performed that included all peer-reviewed, primary, English language publications on RAA from its introduction in 1992 up to 2019. RAA was defined as robot-assisted hip or knee arthroplasty. A bibliometric analysis was performed to categorise articles by type of study and level of evidence. Studies were also categorised as initial investigations (II) or refining studies (RS). A PSA analysis was performed, with the end-point being defined as the point in time when the number of RS exceeded the number of II. Of the 199 studies originating from 19 countries and 101 institutions, only 16 (8.04%) were randomised-controlled trials. Fifty-one percent of studies had been published since 2015. Using PSA analysis, 161 (80.9%) studies were categorised as II and 38 (19.1%) were categorised as RS. This demonstrates that RAA has not yet reached the point of scholarly acceptance. Scholarly acceptance of RAA as an orthopaedic surgical technique has yet to be reached. However, there has been an exponential increase in the number of publications on RAA in the last 5Ã‚Â years, reflecting renewed interest this technique. We predict that, for the next 5Ã‚Â years, RAA will remain in the experimental phase due to the rapid development of new technology in this field.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21482,""
"Social Robot Interventions for People with Dementia: A Systematic Review on Effects and Quality of Reporting","Hirt, Ballhausen, Hering, Kliegel, Beer, Meyer","https://doi.org/10.3233/JAD-200347","20210916","PubMed","Dementia; robotics; systematic review; technology; Dementia; Humans; Research; Robotics; Social Behavior","Using non-pharmacological interventions is a current approach in dementia care to manage responsive behaviors, to maintain functional capacity, and to reduce emotional stress. Novel technologies such as social robot interventions might be useful to engage people with dementia in activities and interactions as well as to improve their cognitive, emotional, and physical status. Assessing the effects and the quality of reporting of social robot interventions for people with dementia. In our systematic review, we included quasi-experimental and experimental studies published in English, French, or German, irrespective of publication year. Searching CINAHL, Cochrane Library, MEDLINE, PsycINFO, and Web of Science Core Collection was supplemented by citation tracking and free web searching. To assess the methodological quality of included studies, we used tools provided by the Joanna Briggs Institute. To assess the reporting of the interventions, we applied CReDECI 2 and TIDieR. We identified sixteen studies published between 2012 and 2018, including two to 415 participants with mostly non-defined type of dementia. Eight studies had an experimental design. The predominant robot types were pet robots (i.e., PARO). Most studies addressed behavioral, emotion-related, and functional outcomes with beneficial, non-beneficial, and mixed results. Predominantly, cognitive outcomes were not improved. Overall, studies were of moderate methodological quality. Heterogeneous populations, intervention characteristics, and measured outcomes make it difficult to generalize the results with regard to clinical practice. The impact of social robot interventions on behavioral, emotion-related, and functional outcomes should therefore be assessed considering the severity of dementia and intervention characteristics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21483,""
"Systematic review and updated network meta-analysis comparing open, laparoscopic, and robotic pancreaticoduodenectomy","Aiolfi, Lombardo, Bonitta, Danelli, Bona","https://doi.org/10.1007/s13304-020-00916-1","20211015","PubMed","Laparoscopic pancreaticoduodenectomy; Network meta-analysis; Open pancreaticoduodenectomy; Pancreaticoduodenectomy; Robotic pancreaticoduodenectomy; Bayes Theorem; Humans; Laparoscopy; Network Meta-Analysis; Pancreatic Neoplasms; Pancreaticoduodenectomy; Postoperative Complications; Robotic Surgical Procedures","The treatment of periampullary and pancreatic head neoplasms is evolving. While minimally invasive Pancreaticoduodenectomy (PD) has gained worldwide interest, there has been a debate on its related outcomes. The purpose of this paper was to provide an updated evidence comparing short-term surgical and oncologic outcomes within Open Pancreaticoduodenectomy (OpenPD), Laparoscopic Pancreaticoduodenectomy (LapPD), and Robotic Pancreaticoduodenectomy (RobPD). MEDLINE, Web of Science, PubMed, Cochrane Central Library, and ClinicalTrials.gov were referred for systematic search. A Bayesian network meta-analysis was executed. Forty-one articles (56,440 patients) were included; 48,382 (85.7%) underwent OpenPD, 5570 (9.8%) LapPD, and 2488 (4.5%) RobPD. Compared to OpenPD, LapPD and RobPD had similar postoperative mortality [Risk Ratio (RR)Ã¢â‚¬â€°=Ã¢â‚¬â€°1.26; 95%CrI 0.91-1.61 and RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.78; 95%CrI 0.54-1.12)], clinically relevant (grade B/C) postoperative pancreatic fistula (POPF) (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°1.12; 95%CrI 0.82-1.43 and RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.87; 95%CrI 0.64-1.14, respectively), and severe (Clavien-DindoÃ¢â‚¬â€°Ã¢â€°Â¥Ã¢â‚¬â€°3) postoperative complications (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°1.03; 95%CrI 0.80-1.46 and RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.93; 95%CrI 0.65-1.14, respectively). Compared to OpenPD, both LapPD and RobPD had significantly reduced hospital length-of-stay, estimated blood loss, infectious, pulmonary, overall complications, postoperative bleeding, and hospital readmission. No differences were found in the number of retrieved lymph nodes and R0. OpenPD, LapPD, and RobPD seem to be comparable across clinically relevant POPF, severe complications, postoperative mortality, retrieved lymphnodes, and R0. LapPD and RobPD appears to be safer in terms of infectious, pulmonary, and overall complications with reduced hospital readmission We advocate surgeons to choose their preferred surgical approach according to their expertise, however, the adoption of minimally invasive techniques may possibly improve patients' outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21484,""
"Comparative Effectiveness of Surgical Approaches for Lung Cancer","Manerikar, Querrey, Cerier, Kim, Odell, Pesce, Bharat","https://doi.org/10.1016/j.jss.2020.10.020","20210921","PubMed","Lung cancer; Meta-analysis; Non-small cell lung cancer (NSCLC); Randomized controlled trials (RCTs); Retrospective observational studies; Robot-assisted thoracoscopic surgery (RATS); Video-assisted thoracoscopic surgery (VATS); Humans; Lung Neoplasms; Neoplasm Staging; Pneumonectomy; Postoperative Complications; Propensity Score; Risk Assessment; Robotic Surgical Procedures; Thoracic Surgery, Video-Assisted; Thoracotomy; Time Factors; Treatment Outcome","The magnitude of association and quality of evidence comparing surgical approaches for lung cancer resection has not been analyzed. This has resulted in conflicting information regarding the relative superiority of the different approaches and disparate opinions on the optimal surgical treatment. We reviewed and systematically analyzed all published data comparing near- (30-d) and long-term mortality for minimally invasive to open surgical approaches for lung cancer. Comprehensive search of EMBASE, MEDLINE, and the Cochrane Library, from January 2009 to August 2019, was performed to identify the studies and those that passed bias assessment were included in the analysis utilizing propensity score matching techniques. Meta-analysis was performed using random-effects and fixed-effects models. Risk of bias was assessed via the Newcastle-Ottawa Scale and the ROBINS-I tool. The study was registered in PROSPERO (CRD42020150923) prior to analysis. Overall, 1382 publications were identified but 19 studies were included encompassing 47,054 patients after matching. Minimally invasive techniques were found to be superior with respect to near-term mortality in early and advanced-stage lung cancer (risk ratio 0.45, 95% confidence interval [CI] 0.21-0.95, I<sup>2</sup>Ã‚Â =Ã‚Â 0%) as well as for elderly patients (odds ratio 0.45, 95% CI 0.31-0.65, I<sup>2</sup>Ã‚Â =Ã‚Â 30%), but did not demonstrate benefit for high-risk patients (odds ratio 0.74, 95% CI 0.06-8.73, I<sup>2</sup>Ã‚Â =Ã‚Â 78%). However, no difference was found in long-term survival. We performed the first systematic review and meta-analysis to compare surgical approaches for lung cancer which indicated that minimally invasive techniques may be superior to thoracotomy in near-term mortality, but there is no difference in long-term outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21485,""
"Risk factors and outcomes of conversion in minimally invasive distal pancreatectomy: a systematic review","Balduzzi, van der Heijde, Alseidi, Dokmak, Kendrick, Polanco, Sandford, Shrikhande, Vollmer, Wang, Zeh, Hilal, Asbun, Besselink","https://doi.org/10.1007/s00423-020-02043-2","20210924","PubMed","Conversion; Conversion to open surgery; Laparoscopic distal pancreatectomy; Minimally invasive distal pancreatectomy; Robotic distal pancreatectomy; Humans; Laparoscopy; Pancreatectomy; Pancreatic Neoplasms; Risk Factors; Robotic Surgical Procedures; Treatment Outcome","The reported conversion rates for minimally invasive distal pancreatectomy (MIDP) range widely from 2 to 38%. The identification of risk factors for conversion may help surgeons during preoperative planning and patient counseling. Moreover, the impact of conversion on outcomes of MIDP is unknown. A systematic review was conducted as part of the 2019 Miami International Evidence-Based Guidelines on Minimally Invasive Pancreas Resection (IG-MIPR). The PubMed, Cochrane, and Embase databases were searched for studies concerning conversion to open surgery in MIDP. Of the 828 studies screened, eight met the eligibility criteria, resulting in a combined dataset including 2592 patients after MIDP. The overall conversion rate was 17.1% (range 13.0-32.7%) with heterogeneity between studies associated with the definition of conversion adopted. Only one study divided conversion into elective and emergency conversion. The main indications for conversion were vascular involvement (23.7%), concern for oncological radicality (21.9%), and bleeding (18.9%). The reported risk factors for conversion included a malignancy as an indication for surgery, the proximity of the tumor to vascular structures in preoperative imaging, higher BMI or visceral fat, and multi-organ resection or extended resection. Contrasting results were seen in terms of blood loss and length of stay in comparing converted MIDP and completed MIDP patients. The identified risk factors for conversion from this study can be used for patient selection and counseling. Surgeon experience should be considered when contemplating MIDP for a complex patient. Future studies should divide conversion into elective and emergency conversion.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21486,""
"Laparoscopic versus Robotic Peripheral Pancreatectomy: A Systematic Review and Meta-analysis","Mavrovounis, Diamantis, Perivoliotis, Symeonidis, Volakakis, Tepetes","https://www.google.com/search?q=Laparoscopic+versus+Robotic+Peripheral+Pancreatectomy:+A+Systematic+Review+and+Meta-analysis.","20210820","PubMed","Humans; Laparoscopy; Pancreatectomy; Robotics; Treatment Outcome","The current systematic review and meta-analysis aimed to compare Laparoscopic Distal Pancreatectomy (LPD) with Robotic Distal Pancreatectomy (RDP) in terms of length of hospital stay (LOS), perioperative, postoperative and economic parameters. A systematic review of the literature was undertaken and data from studies fulfilling the predetermined inclusion criteria were extracted. Meta-analyses were performed to combine the results of various studies in the forms of Weighted Mean Difference (WMD), Odds Ratio (OR) and Risk Difference (RD), as appropriate. A significantly lower LOS (WMD:0.75, 95%CI:0.17-1.33) and longer operative duration (WMD:-28.29, 95%CI:-49.98--6.6) for the RDP group was found. The rate of open conversion was higher in the LDP group (OR:2.38, 95%CI:1.75-3.22), while the rate of spleen preservation was lower (OR:0.49, 95%CI:0.31-0.79). No significant difference was noted in the intraoperative blood loss (WMD:34, 95%CI:-10.28-78.29), postoperative blood transfusion (OR:0.99, 95%CI:0.66-1.49) and overall morbidity analyses (OR:1.08, 95%CI:0.88-1.32). A significantly higher yield of lymph nodes was achieved in the RDP group (WMD:-2.09, 95%CI:-4.17--0.01), while no differences were found when positive resection margins (RD:0.02, 95%CI:-0.02-0.07) and specimen length (WMD:0.08, 95%CI:0.42-0.58) were considered. Finally, RDP was associated with significantly higher operative (WMD:-2733.42, 95%CI:-4189.77--1277.08) and total (WMD:-3799.68, 95%CI: -4438.39--3160.98) costs. RDP seems to be a viable option for both benign and malignant pancreatic disorders, although there are concerns regarding economic parameters. Large randomized controlled trials will shed more light on the subject.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21487,""
"Systematic review of radiomic biomarkers for predicting immune checkpoint inhibitor treatment outcomes","Zhang, de A F Fonseca, Shi, Zhu, Dekker, Bermejo, Wee","https://doi.org/10.1016/j.ymeth.2020.11.005","20211101","PubMed","Computed tomography; Immune response; Immunotherapy; Radiomics; Solid cancers; Systematic review; Treatment response; Carcinoma, Non-Small-Cell Lung; Deep Learning; Drug Resistance, Neoplasm; Humans; Image Processing, Computer-Assisted; Immune Checkpoint Inhibitors; Lung; Lung Neoplasms; Prognosis; Treatment Outcome","Systemic therapy agents targeting immune checkpoint inhibitors have been approved for use since 2011. This type of therapy aims to trigger a patient's immune response to attack tumor cells, rather than acting against the tumor directly. Radiomics is an automated method of medical image analysis that is now being actively investigated for predictive markers of treatment response in immunotherapy. To conduct an early systematic review determining the current status of radiomic features as potential predictive markers of immunotherapy response. Provide a detailed critical appraisal of methodological quality of models, as this informs the degree of confidence about current reports of model performance. In addition, to offer some recommendations for future studies that could establish robust evidence for radiomic features as immunotherapy response markers. A PubMed citation search was conducted for publications up to and including April 2020, followed by full-text screening. A total of seven articles meeting the eligibility criteria were examined in detail for study characteristics, model information and methodological quality. The review was conducted in the Cochrane style but has not been prospectively registered. Results are reported following Preferred Reporting Items for Systematic Review and Meta-Analysis Protocols (PRISMA) guidelines. A total of seven studies were examined in detail, comprising non-small cell lung cancer, metastatic melanoma and a diverse assortment of solid tumors. Methodological robustness of reviewed studies varied greatly. Principal shortcomings were lack of prospective registration, and deficiencies in feature selection and dimensionality reduction, model calibration, clinical utility and external validation. A few studies with overall moderate to good methodological quality were identified. These results suggest that current state-of-the-art performance of radiomics in regards to discrimination (area under the curve or concordance index) is in the vicinity of 0.7, but the very small number of studies to date prevents any conclusive remarks to be made. We recommended future improvements in regards to prospective study registration, clinical utility, methodological procedure and data sharing. Radiomics has a potentially significant role for predicting immunotherapy response. Additional multi-institutional studies with robust methodological underpinning and repeated external validations are required to establish the (added) value of radiomics within the pantheon of clinical tools for decision-making in immunotherapy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21488,""
"A digital health profile &amp; maturity assessment toolkit: cocreation and testing in the Pacific Islands","Liaw, Zhou, Ansari, Gao","https://doi.org/10.1093/jamia/ocaa255","20210813","PubMed","cocreation; digital health; evaluation; implementation; informatics; maturity assessment; Artificial Intelligence; Big Data; Delivery of Health Care; Humans; Medical Informatics Applications; Pacific Islands; Telemedicine","Countries need to determine their level of digital health capability maturity to assess and mobilize their knowledge, skills, and resources to systematically develop, implement, evaluate, scale up and maintain large-scale implementations of standards-based interoperable digital health tools. Develop a Digital Health Profile and Maturity Assessment Toolkit (DHPMAT) to assist Pacific Island Countries (PICs) to harness digital tools to support national health priorities. A literature review guided the development of the conceptual framework to underpin the DHPMAT. Key informants collaborated to collect key digital health features and indicators to inform their country's digital health maturity assessment. The DHPMAT was tested with country stakeholders at a Pacific Health Information Network workshop in 2019. A comprehensive list of indicators to describe country digital health profiles (DHP). A digital health maturity assessment tool that uses criteria codeveloped with country stakeholders to assess essential digital health foundations and quality improvement. DHPs created and maturity assessed and packaged into individualized DHPMATs for 13 PICs. PIC users perceived the DHPMAT as useful, especially the congruence with the 2017 WHO WPRO Regional Strategy but noted a ""cognitive overload"" from a plethora of complex digital health toolkits. The cocreation approach optimized currency, accuracy, and appropriateness of information in the DHP, understanding, and use of the DHPMAT to facilitate informed iterative discussion by PICs on their digital health maturity to harness digital tools to strengthen country health systems. The DHPMAT can rationalize the choice and use of existing tools and reduce cognitive overload.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21489,""
"Intracorporeal versus extracorporeal urinary diversion following robot-assisted radical cystectomy: a meta-analysis, cumulative analysis, and systematic review","Tanneru, Jazayeri, Kumar, Alam, Norez, Nguyen, Bazargani, Ganapathi, Bandyk, Marino, Koochekpour, Gautam, Balaji, Costa","https://doi.org/10.1007/s11701-020-01174-4","20211011","PubMed","ECUD; Extracorporeal urinary diversion; ICUD; Intracorporeal urinary diversion; RARC; Blood Loss, Surgical; Blood Transfusion; Cystectomy; Female; Humans; Male; Neoplasm Invasiveness; Postoperative Complications; Robotic Surgical Procedures; Treatment Outcome; Urinary Bladder Neoplasms; Urinary Diversion","Over the last decade, the increased utilization of robot-assisted radical cystectomy (RARC) in the surgical treatment of muscle-invasive bladder cancer has led to an uptrend in intracorporeal urinary diversions (ICUD). However, the operative results comparing ICUD to extracorporeal urinary diversion (ECUD) have varied widely. We performed a meta-analysis to analyze perioperative outcomes and complications of ICUD compared to ECUD following RARC. This study is registered at International Prospective Register of Systematic Reviews (PROSPERO) CRD42020164074. A systematic literature review was conducted using PubMed, EMBASE, and Cochrane databases in August 2019. A total of six studies comparing ICUD vs ECUD were identified and meta-analysis was conducted on these studies. In addition, a cumulative analysis was also performed on 83 studies that reported perioperative outcomes after RARC and ICUD or ECUD. The Weighed Mean Difference of operative time and blood loss between ICUD and ECUD group was (16; 95% confidence interval -Ã¢â‚¬â€°34 to 66) and (-Ã¢â‚¬â€°86; 95% confidence interval -Ã¢â‚¬â€°124 to -Ã¢â‚¬â€°48), respectively. ICUD and ECUD had comparable early (30-day) and mid-term (30-90-day) complication rate (RR 1.19; 95% confidence interval 0.71-2.0; pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.5) and (RR 0.91; 95% confidence interval 0.71-1.15 pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.4) respectively. In the 83 studies that were included in the cumulative analysis, the mean operative time for ileal conduit and neobladders by ICUD were 307 and 428Ã‚Â min, respectively, compared to ECUD 428 and 426Ã‚Â min, respectively. ICUD and ECUD have comparable short- and mid-term complication rate. The ICUD group has lower blood loss and lower rate of blood transfusion compared to ECUD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21490,""
"Accelerate PhenoÃ¢â€žÂ¢ blood culture detection system: a literature review","Cenci, Paggi, Socio, Bozza, Camilloni, Pietrella, Mencacci","https://doi.org/10.2217/fmb-2020-0177","20211013","PubMed","Accelerate PhenoÃ¢â€žÂ¢; MIC; blood culture; fast diagnostics; sepsis; Anti-Bacterial Agents; Antimicrobial Stewardship; Automation; Bacteria; Blood Culture; Humans; Microbial Sensitivity Tests; Sepsis","Accelerate PhenoÃ¢â€žÂ¢ (ACC) is a fully automated system providing rapid identification of a panel of bacteria and yeasts, and antimicrobial susceptibility testingÃ‚Â of common bacterial pathogens responsible forÃ‚Â bloodstream infectionsÃ‚Â and sepsis. Diagnostic accuracy for identification ranges from 87.9 to 100%, and antimicrobial susceptibility testing categorical agreement is higher than 91%. The present review includes peer-reviewed studies on ACC published to date. Both interventional and hypothetical studies evidenced the potential positive clinical role of ACC in the management and therapy of patients with bloodstream infections and sepsis, due to the important reduction in timeÃ‚Â to report, suggesting a crucial impact on the therapeutic management of these patients, provided the presence of a hospital antimicrobial stewardship program, a 24/7 laboratory operating time and a strict collaboration between clinical microbiologist and clinician. Further prospective multicenter studies are necessary to explore the impact of this system on mortality, lengthÃ‚Â of stayÃ‚Â and spread of multidrug-resistant organisms.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21491,""
"Robot-Assisted Arm Training versus Therapist-Mediated Training after Stroke: A Systematic Review and Meta-Analysis","Chen, Wang, Fan, Gu, Yasin, Xiao, Huang, Huang","https://doi.org/10.1155/2020/8810867","20211015","PubMed","Activities of Daily Living; Arm; Humans; Quality of Life; Robotics; Stroke; Stroke Rehabilitation","More than two-thirds of stroke patients have arm motor impairments and function deficits on hospital admission, leading to diminished quality of life and reduced social participation. Robot-assisted training (RAT) is a promising rehabilitation program for upper extremity while its effect is still controversial due to heterogeneity in clinical trials. We performed a systematic review and meta-analysis to compare robot-assisted training (RAT) versus therapist-mediated training (TMT) for arm rehabilitation after stroke. We searched the following electronic databases: MEDLINE, EMBASE, Cochrane EBM Reviews, and Physiotherapy Evidence Database (PEDro). Studies of moderate or high methodological quality (PEDro score Ã¢â€°Â¥4) were included and analyzed. We assessed the effects of RAT versus TMT for arm rehabilitation after stroke with testing the noninferiority of RAT. A small effect size of -2 score for mean difference in Fugl-Meyer Assessment of the Upper Extremity (FMA-UE) and Cohen's <i>d</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°-0.2 for standardized mean difference (SMD) were set as noninferiority margin. Thirty-five trials with 2241 participants met inclusion criteria. The effect size for arm motor impairment, capacity, activities of daily living, and social participation were 0.763 (WMD, 95% CI: 0.404 to 1.123), 0.109 (SMD, 95% CI: -0.066 to 0.284), 0.049 (SMD, 95% CI: -0.055 to 0.17), and -0.061 (SMD, 95% CI: -0.196 to 0.075), respectively. This systematic review and meta-analysis demonstrated that robot-assisted training was slightly superior in motor impairment recovery and noninferior to therapist-mediated training in improving arm capacity, activities of daily living, and social participation, which supported the use of RAT in clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21492,""
"Robot-assisted adrenalectomy: state of the art","Materazzi, Rossi","https://doi.org/10.1007/s13304-020-00915-2","20211015","PubMed","Adrenal gland; Adrenalectomy; Laparoscopic; Retroperitoneal; Robotic; Adrenal Gland Neoplasms; Adrenalectomy; Humans; Laparoscopy; Operative Time; Robotic Surgical Procedures; Robotics","Currently, laparoscopic adrenalectomy is worldwide considered the gold standard technique. Both transperitoneal and retroperitoneal approaches have proved their efficacy with excellent outcomes. Since the introduction of da Vinci System (Intuitive Surgical, Sunnyvale, CA), robotic surgery has made many steps forward gaining progressively more diffusion in the field of general and endocrine surgery. The robotic technique offers advantages to overcome some laparoscopic shortcomings (rigid instruments, loss of 3D vision, unstable camera). Indeed, the robotic system is provided of stereoscopic 3D-magnified vision, additional degree of freedom, tremor-filtering technology and a stable camera. Recently, several case series have demonstrated the feasibility and the safety of robot-assisted adrenalectomy in high-volume centers with outcomes comparable to laparoscopic adrenalectomy. Notwithstanding, the technical advantages of the robotic system have not yet demonstrated significant improvements in terms of outcomes to undermine laparoscopic adrenalectomy. Moreover, robotic adrenalectomy harbor inherits drawbacks, such as longer operative time and elevated costs, that limit its use. In particular, the high cost associated with the use of the robotic system is primarily related to the purchase and the maintenance of the unit, the high instruments cost and the longer operative time. Notably, these aspects make robotic adrenalectomy up to 2.3 times more costly than laparoscopic adrenalectomy. This literature review summarizes the current available studies and provides an overview about the robotic scenario including applicability, technical details and surgical outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21493,""
"Safety and efficacy of robot-assisted versus open pancreaticoduodenectomy: a meta-analysis of multiple worldwide centers","Zhang, Huang, Zhang, Che","https://doi.org/10.1007/s13304-020-00912-5","20211015","PubMed","Complications; Meta-analysis; Open surgery; Pancreaticoduodenectomy; Robotic surgery; Humans; Length of Stay; Operative Time; Pancreatectomy; Pancreatic Fistula; Pancreaticoduodenectomy; Postoperative Complications; Robotics","The objective of the study is to compare the safety and efficacy of robot-assisted pancreaticoduodenectomy (PD) with open PD. The PubMed, EMBASE and Cochrane Library databases were searched for the literature available from their respective inception dates up to May 2020 to find studies comparing robot-assisted pancreaticoduodenectomy (RPD) with open pancreaticoduodenectomy (OPD). The RevMan 5.3 statistical software was used for analysis to evaluate surgical outcome and oncology safety. The combination ratio (RR) and weighted mean difference (WMD) and their 95% confidence intervals (CIs) were calculated using fixed-effect or random effect models. 18 cohort studies from 16 medical centers were eligible with a total of 5795 patients including 1420 RPD group patients and 4375 OPD group patients. The RPD group fared better than the OPD group in terms of estimated blood loss (EBL) (WMDÃ¢â‚¬â€°=Ã¢â‚¬â€°-Ã¢â‚¬â€°175.65, 95% CI (-Ã¢â‚¬â€°251.85, -Ã¢â‚¬â€°99.44), PÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.00001), wound infection rate (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.60, 95% CI (0.44, 0.81), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.001), reoperation rate (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.61, 95% CI (0.41, 0.91), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.02), hospital day (WMDÃ¢â‚¬â€°=Ã¢â‚¬â€°-Ã¢â‚¬â€°2.95, 95% CI (-Ã¢â‚¬â€°5.33, -Ã¢â‚¬â€°0.56), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.02), intraoperative blood transfusion (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.56, 95% CI (0.42, 0.76), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.0001), overall complications (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.78, 95% CI (0.64, 0.95), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.01), and clinical postoperative pancreatic fistula (POPF) (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.54, 95% CI (0.41, 0.70), PÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.0001). In terms of lymph node clearance (WMDÃ¢â‚¬â€°=Ã¢â‚¬â€°0.48, 95% CI (-Ã¢â‚¬â€°2.05, 3.02), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.71), R0 rate (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°1.05, 95% CI (1.00, 1.11), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.05), postoperative pancreatic fistula (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°1, 95% CI (0.85, 1.19), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.97), bile leakage (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.99, 95% CI (0.54, 1.83), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.98), delayed gastric emptying (DGE) (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.79, 95% CI (0.60, 1.03), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.08), 90-day mortality (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.82, 95% CI (0.62, 1.10), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.19), and severe complications (RRÃ¢â‚¬â€°=Ã¢â‚¬â€°0.98, 95% CI (0.71, 1.36), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.91), and there were no significant differences between the two groups. Robotic surgery was inferior to open surgery in terms of operational time (WMDÃ¢â‚¬â€°=Ã¢â‚¬â€°80.85, 95% CI (16.09, 145.61), PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.01). RPD is not inferior to OPD, and it is even more advantageous for EBL, wound infection rate, reoperation rate, hospital stay, intraoperative transfusion, overall complications and clinical POPF. However, these findings need to be further verified by high-quality randomized controlled trials.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21494,""
"Robotic-assisted surgery in medial unicompartmental knee arthroplasty: does it improve the precision of the surgery and its clinical outcomes? Systematic review","NegrÃƒÂ­n, Ferrer, IÃƒÂ±iguez, Duboy, Saavedra, LarraÃƒÂ­n, Jabes, Barahona","https://doi.org/10.1007/s11701-020-01162-8","20210913","PubMed","Arthroplasty; Knee; Robotic surgery; Robotic-assisted surgery; Robotics; Unicompartmental knee arthroplasty; Unicondylar knee; Arthroplasty, Replacement, Knee; Female; Femur; Humans; Learning Curve; Male; Osteoarthritis, Knee; Pain, Postoperative; Prosthesis Failure; Robotic Surgical Procedures; Tibia; Treatment Outcome","There is a high prevalence of knee osteoarthritis that affects only the medial tibiofemoral compartment. In this group of patients with severe disease, the medial unicompartmental knee arthroplasty (UKA) is an excellent choice. However, this technique has a great learning curve due to the lower tolerance of improper positioning and alignment. In this context, the robotic-assisted surgery (RAS) arises as an option to improve the accuracy and secondarily enhance the clinical outcomes related to the UKA. The objective in this study is to determine if there are significant advantages with the use of RAS over conventional surgery (CS). In the systematic review of the literature, classification of the results in three main subjects: (A) precision and alignment; (B) functional results and clinical parameters; (C) survivorship. We found 272 studies, of which 15 meet the inclusion and exclusion criteria. There is mostly described that RAS significantly improves the accuracy in position (80-100% of planned versus performed PÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.05), alignment (2-3 times less error variance PÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.05) and selection of the proper size of the implants (69.23% of correct size femoral implants versus 16.67% using CS PÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.0154). Recently, there is mild evidence about benefits in the early rehabilitation and post-operative pain, but in all studies reviewed, there is no advantages of RAS in the long-term functional evaluation. There is no strong literature that supports a longer survival of the prothesis with RAS, being the longest mean follow-up reported of 29.6Ã‚Â months. RAS is a useful tool in increasing the precision of the medial UKA implant placement. However, there is still a lack of evidence that properly correlates this improvement in accuracy with better clinical, functional and survival results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21495,""
"Initial intraoperative experience with robotic-assisted pedicle screw placement with stealth navigation in pediatric spine deformity: an evaluation of the first 40 cases","Gonzalez, Ghessese, Cook, Hedequist","https://doi.org/10.1007/s11701-020-01159-3","20211028","PubMed","Cobb angle; Mazor robot; Pediatric deformity; Robotic navigation; Scoliosis; Spine surgery; Adolescent; Child; Humans; Pedicle Screws; Retrospective Studies; Robotic Surgical Procedures; Scoliosis; Spinal Fusion; Spine; Surgery, Computer-Assisted","Pedicle screw fixation in pediatric spine surgery has become common practice given the fixation stability and improved curve correction. However, due to proximity to vital structures, accuracy is paramount. Literature has reported accuracy rates from 87.5 to 90% using traditional freehand techniques. This study presents our initial experience with pedicle screw placement using the newest generation of spinal robotics for treatment of pediatric spinal deformity. A cohort of patients, aged 8-21Ã‚Â years, undergoing spinal fusion surgery using robotic-assisted technology was reviewed. Diagnoses, Cobb angles, surgical time, robot time, number of screws placed, and complications were recorded. Accuracy of screw placement was assessed based on analysis of successful screw execution, evaluation screw position using intraoperative fluoroscopy and post-operative radiographs, and clinical evaluation. The average age was 14.5Ã‚Â years. Prevalent diagnoses included idiopathic (65%) and neuromuscular scoliosis (13%). Mean preoperative curve measured 66.8Ã‚Â°. The median time for operation was 235 minutes with medians of 8 levels fused and 5 screws placed per patient. Of the 314 screws placed, we recorded a 98.7% accuracy rate. Lateral deviation was the most common cause of malpositioning. Post-operative plain films revealed no grossly misplaced screws. There were no perioperative neurologic deficits or malpositioned screws requiring reoperation. This is the first reported series of navigated spinal robotics used for pedicle screw placement in children. Our clinical success rate was 98.7% and there were no clinically relevant screw related complications. The study shows promising initial results of combined robotic-navigation techniques in pediatric patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21496,""
"Perioperative, postoperative and anatomical outcomes of robotic sacrocolpopexy","Kilic, Lee, Lewis, Demirkiran, Dursun, Unlu","https://doi.org/10.1080/01443615.2020.1789958","20211026","PubMed","Pelvic organ prolapse; robotic surgery; robotic-assisted sacrocolpopexy; Colposcopy; Feasibility Studies; Female; Humans; Intraoperative Complications; Middle Aged; Pelvic Floor; Pelvic Organ Prolapse; Perioperative Period; Postoperative Complications; Postoperative Period; Reoperation; Retrospective Studies; Robotic Surgical Procedures; Sacrum; Treatment Outcome","The study aimed to analyse the anatomical, perioperative and postoperative outcomes of the robotic-assisted sacrocolpopexy (RSCP). After obtaining Institutional Review Board (IRB #19-0167) approval, our retrospective case series included 144 consecutive patients that underwent an RSCP for symptomatic stage II pelvic organ prolapse (POP) or symptomatic/asymptomatic stage III/IV POP. Patient information included operative parameters, perioperative and postoperative complications, readmissions and reoperation. Demographics and baseline characteristics were summarised by frequencies and percentages for categorical variables, and by mean/median, standard deviation, and ranges for continuous variables. In our study, concomitant surgeries with sacrocolpopexy consisted of hysterectomy, Burch colposuspension and midurethral sling. The anatomical success rate was 87.5% and the reoperation rate was 10.4%. The mean follow-up time was 12.5 (Ã‚Â±8.7) months. Intraoperative complications 13 (9%) were bowel serosal abrasion, bladder wall injuries, trochar site bleeds, subcutaneous emphysema and a retroperitoneal haematoma. Our results suggest that RSCP is a feasible and safe approach for the treatment of POP with a low complication rate and favourable medium-term outcomes regarding anatomical and symptomatic results.Impact statement<b>What is already known on this subject?</b> Pelvic organ prolapse affects more than 25% of women in the United States. Apical and anterior compartment defects are challenging cases and sacrocolpopexy is considered the gold standard treatment option for apical and anterior compartment defects. As technology has advanced, minimally invasive approaches have been popular with their pros.<b>What</b> <b>the results of this study add?</b> We present the highest volume case series in the literature from our tertiary care centre for robotic-assisted sacrocolpopexy (RSCP). Our results suggest that RSCP is a feasible and safe approach for the treatment of POP with a low complication rate and favourable 1-year outcomes regarding anatomical and subjective results.<b>What</b> <b>the implications</b> <b>are</b> <b>of these findings for clinical practice and/or further research?</b> Robotic-assisted sacrocolpopexy has the potential to gain more popularity in the near future based on accumulating data on its feasibility and safety results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21497,""
"Robotic interval debulking surgery for advanced epithelial ovarian cancer: current challenge or future direction? A systematic review","Psomiadou, Prodromidou, Fotiou, Lekka, Iavazzo","https://doi.org/10.1007/s11701-020-01155-7","20210913","PubMed","Interval debulking surgery; Ovarian cancer; Robotic surgery; Blood Loss, Surgical; Carcinoma, Ovarian Epithelial; Cytoreduction Surgical Procedures; Female; Follow-Up Studies; Humans; Laparotomy; Length of Stay; Neoadjuvant Therapy; Neoplasm Recurrence, Local; Operative Time; Ovarian Neoplasms; Postoperative Complications; Robotic Surgical Procedures; Survival Rate; Treatment Outcome","We evaluated the effectiveness, safety and efficacy of robotic interval debulking surgery (IDS) in advanced epithelial ovarian cancer (EOC) treated with neoadjuvant chemotherapy (NACT). We conducted a systematic review of the published relevant studies. ÃŽâ€˜ total of 102 patients were evaluated. Mean operative time ranged from 164 to 312Ã‚Â min (meanÃ¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°SD: 246Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°61Ã‚Â min) while mean estimated blood loss ranged from 106.9 to 262.5Ã‚Â ml (meanÃ¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°SD: 168Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°68Ã‚Â ml) and postoperative blood transfusion rate was 19% (nÃ¢â‚¬â€°=Ã¢â‚¬â€°19/98). Complete cytoreduction rate (R0 resection) was achieved in 75 patients (76.5%), whereas residual diseaseÃ¢â‚¬â€°Ã¢â€°Â¤Ã¢â‚¬â€°1Ã‚Â cm in 21 women (21.5%). Mean hospital stay was 2.4Ã‚Â days. No intraoperative and six postoperative (14.6%) complications were reported. Laparotomy conversion rate was 9.2% (9/98) mostly in the terms of achieving complete cytoreduction and 30-day mortality rate was 9.2% (nÃ¢â‚¬â€°=Ã¢â‚¬â€°9/98). The median overall survival varied from 39.7 to 47.2Ã‚Â months, while the progression-free survival ranged from 20.6 to 21.2Ã‚Â months during a median follow-up period from 2 to 86Ã‚Â months (median 25.3Ã‚Â months). A total of 60 women (61%) developed disease recurrence. One of the studies reported significantly improved OS and PFS in patients who underwent robotic IDS when compared to those who had laparotomy either during or before the addition of robotic surgery in the management of advanced ovarian cancer disease (47.2 vs 37.8 vs 37.9, pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.004 for OS and 20.6 vs 13.9 vs 11.9, pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.005 for PFS, respectively). The same was also observed when controlling the parameters of age and stage for patients in the robotic arm (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.02). Robotic interval debulking surgeryÃ‚Â can be considered in the management of advanced ovarian cancer patients after receiving neoadjuvant chemotherapy. Larger meta-analyses including multicenter randomized control trials are necessary to specify the exact profile of the patients that could benefit from this treatment strategy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21498,""
"Meta-analysis of retroperitoneal vs transperitoneal laparoscopic and robot-assisted pyeloplasty for the management of pelvi-ureteric junction obstruction","Chua, Ming, Kim, Milford, Silangcruz, Ren, Rickard, Lorenzo","https://doi.org/10.1111/bju.15264","20211007","PubMed","#EndoUrology; #Urology; laparoscopy; pyeloplasty; retroperitoneal; transperitoneal; Humans; Kidney Pelvis; Laparoscopy; Peritoneum; Retroperitoneal Space; Robotic Surgical Procedures; Ureteral Obstruction; Urologic Surgical Procedures","To determine differences in perioperative outcomes between retroperitoneal and transperitoneal approaches for laparoscopic pyeloplasty (LP) to manage pelvi-ureteric junction obstruction (PUJO) through a meta-analysis of comparative studies. A systematic search was performed in January 2020. Comparative studies were evaluated according to Cochrane Collaboration recommendations. Assessed outcomes included success and complication rates, conversion to open surgery, operative time (OT), length of hospital stay (LOS), estimated blood loss (EBL), analgesic requirements, regular diet resumption, and drain duration. Relative risk (RR) and standardised mean difference (SMD) with 95% confidence intervals (CIs) were extrapolated. Subgroup analyses were performed according to study design and techniques. International Prospective Register of Systematic Reviews (PROSPERO) number: CRD42020163303. A total of 18 studies describing 2007 cases were included. Overall pooled effect estimates did not show statistically significant differences between the approaches with regards to success rate (RR 0.99; 95% CI 0.97, 1.01), complications (RR 1.09; 95% CI 0.82, 1.45), OT (SMD 0.61; 95% CI -0.04, 1.26), LOS (SMD -0.30; 95% CI -0.63, 0.04), EBL (SMD -0.53; 95% CI -1.26, 0.21), or analgesic requirements (SMD -0.51; 95% CI -1.23, 0.21). Compared to the transperitoneal approach, retroperitoneal LP had a higher conversion rate (RR 2.40; 95% CI 1.23, 4.66); however, patients resumed diets earlier (SMD -2.49; 95% CI -4.17, -0.82) and had shorter drain duration (SMD -0.31; 95% CI -0.57, -0.05). The evidence suggests that there are no significant differences in success rate, OT and complications between transperitoneal and retroperitoneal LP. Conversion rates are higher with the retroperitoneal approach; however, return to diet occurs faster and drain duration is shorter when compared to the transperitoneal approach.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21499,""
"Minimally invasive esophagectomy: clinical evidence and surgical techniques","Mann, Berlth, Hadzijusufovic, Lang, Grimminger","https://doi.org/10.1007/s00423-020-02003-w","20210924","PubMed","Esophageal cancer; Esophagectomy; Minimal invasive esophagectomy; Robot-assisted minimal invasive esophagectomy; Esophageal Neoplasms; Esophagectomy; Humans; Lymph Node Excision; Minimally Invasive Surgical Procedures; Robotic Surgical Procedures; Treatment Outcome","Surgical esophagectomy plays a crucial role in the curative and palliative treatment of esophageal cancer. Thereby, minimally invasive esophagectomy (MIE) is increasingly applied all over the world. Combining minimal invasiveness with improved possibilities for meticulous dissection, robot-assisted minimal invasive esophagectomy (RAMIE) has been implemented in many centers. This review focuses on the development of MIE as well as RAMIE and their value based on evidence in current literature. Although MIE and RAMIE are highly complex procedures, they can be performed safely with improved postoperative outcome and equal oncological results compared with open esophagectomy (OE). RAMIE offers additional advantages regarding surgical dissection, lymphadenectomy, and extended indications for advanced tumors.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21500,""
"MAKO CT-based robotic arm-assisted system is a reliable procedure for total knee arthroplasty: a systematic review","Batailler, Fernandez, Swan, Servien, Haddad, Catani, Lustig","https://doi.org/10.1007/s00167-020-06283-z","20211015","PubMed","Computerized tomography; MAKO; Patient outcomes; Radiological assessment; Robotic surgical procedure; Total knee replacement; Arthroplasty, Replacement, Knee; Humans; Knee Joint; Osteoarthritis, Knee; Robotic Surgical Procedures; Tomography, X-Ray Computed","The aim of this study was to investigate the clinical and radiological results of the MAKO CT-based robotic-assisted system for total knee arthroplasty (TKA). A PRISMA systematic review was conducted using four databases (MEDLINE, EMBASE, Pubmed, GOOGLE SCHOLAR) to identify all clinical and radiological studies reporting information regarding the use and results of the CT-based robotic-assisted system to perform TKA between 2016 and 2020. The main investigated outcome criteria were postoperative pain, analgesia requirements, clinical scores, knee range of motion, implant positioning and the revision rate. The ROBINS-I tool (Risk Of Bias In Non-randomized Studies of Interventions) was used to evaluate the quality of included studies and the risk of bias. A total of 36 studies were identified, of which 26 met inclusion criteria. Of these 26 studies, 14 were comparative. The follow-up varied from 30Ã‚Â days to 17Ã‚Â months. This CT-based, saw cutting Robotic TKA is associated with a significantly lower postoperative pain score (2.6 versus 4.5) and with significantly reduced time to hospital discharge (77Ã‚Â h versus 105), compared with conventional TKA. The two comparative studies assessing functional outcomes at 1Ã‚Â year reported significantly better functional scores with CT-based robotic TKA compared with conventional TKA (WOMAC score: 6Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°6 versus 9Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°8 (pÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.05); KSS function score: 80 versus 73 (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.005)). Only three comparative studies assessed implant positioning, and these reported better implant positioning with CT-based robotic-assisted TKA. The CT-based robotic-assisted system for TKA reduced postoperative pain and improved implant positioning with equal or slightly superior improvement of the functional outcomes at one year, compared to conventional TKA. Systematic review level IV.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21501,""
"Comparison of robotic-assisted versus conventional unicompartmental knee arthroplasty for the treatment of single compartment knee osteoarthritis: A meta-analysis","Zhang, Xu, Zhang, Chen, Fang, Wang","https://doi.org/10.1002/rcs.2170","20210818","PubMed","knee osteoarthritis; meta-analysis; robotic-assisted; unicompartmental arthroplasty; Arthroplasty, Replacement, Knee; Humans; Knee Joint; Osteoarthritis, Knee; Range of Motion, Articular; Robotic Surgical Procedures; Treatment Outcome","The robotic-assisted unicompartmental knee arthroplasty (UKA) is proposed to improve the accuracy of component positioning. We conducted a literature search in Medline, Embase, Web of Science and the Cochrane Library until April 2020. Our meta-analysis included 10 articles, involving 1231 knees. Our meta-analysis demonstrated that the robotic group had significantly better results in outliers of limb alignment (p &lt; 0.001) and outliers of tibial alignment (p &lt; 0.001). No statistical differences were found in the American Knee Society Score (p = 0.63), range of motion (p = 0.93), pain (p = 0.27), rate of revisions (p = 0.73) and rate of complications (p = 0.67). Robotic-assisted UKA has better component position accuracy compared with conventional UKA. But there was no significant difference in clinical results. In order to further evaluate the utility of robotic-assisted UKA, long-term follow-up randomized controlled trials (RCTs) are needed, as well as studies to evaluate the correlation between postoperative alignment and long-term clinical results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21502,""
"Urological and sexual function after robotic and laparoscopic surgery for rectal cancer: A systematic review, meta-analysis and meta-regression","Wee, Kuo, Ngu","https://doi.org/10.1002/rcs.2164","20210818","PubMed","laparoscopy; rectal surgery; robotics; sexual function; urological function; Digestive System Surgical Procedures; Humans; Laparoscopy; Male; Postoperative Complications; Rectal Neoplasms; Robotic Surgical Procedures; Robotics; Treatment Outcome","This systematic review sought to compare the urogenital functions after laparoscopic (LAP) and robotic (ROB) surgery for rectal cancer. This study conformed to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Twenty-six studies (n = 2709 for ROB, n = 2720 for LAP) were included. There was a lower risk of 30-day urinary retention in the ROB group (risk ratios 0.78, 95% confidence interval [CI] 0.61-0.99), but the long-term risk was comparable (p = 0.460). Meta-regression showed a small, positive relationship between age and risk of 30-day urinary retention in both the ROB (p = 0.034) and LAP groups (p = 0.004). The International Prostate Symptom Score was better in the ROB group at 3 months (mean difference [MD] -1.58, 95% CI -3.10 to -0.05). The International Index of Erectile Function score was better in the ROB group at 6 months (MD 4.06, 95% CI 2.38 - 5.74). While robotics may improve urogenital function after rectal surgery, the quality of evidence is low based on the Grading of Recommendations, Assessment, Development and Evaluation approach.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21503,""
"Totally robotic caudate lobe liver resection: Bridge over troubled water","CaÃƒÂ±ada Trofo Surjan, do Prado Silveira","https://doi.org/10.1002/rcs.2152","20210818","PubMed","hepatectomy; liver neoplasms; robotics; Hepatectomy; Humans; Laparoscopy; Liver Neoplasms; Robotic Surgical Procedures; Water","Minimally invasive hepatectomy has well-known advantages over the traditional open approach. Inherent limitations of laparoscopy make major hepatectomies and the resection of upper and posterior segments a great technical challenge. The robotic approach overcomes most of these limitations, and this technology is most useful in the resection of the deeply located caudate lobe. We describe the robotic caudate lobe resection technical aspects, using the first robotic resection of the caudate lobe to treat a biphenotypic hepatocholangiocarcinoma to illustrate the procedure. We also performed a literature review on the current status of the robotic approach to segment (Sg) 1. Technical approach to the robotic caudate lobe resection is described in a patient with uneventful post-operative recovery. Literature review demonstrated only four previous authors reporting the use of this technique. We present a step-by-step approach to the hepatic Sg 1 resection by robotic approach.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21504,""
"Laparoscopic versus robotic right colectomy with extra-corporeal or intra-corporeal anastomosis: a systematic review and meta-analysis","Genova, Pantuso, Cipolla, Latteri, Abdalla, Paquet, Brunetti, de'Angelis, Di Saverio","https://doi.org/10.1007/s00423-020-01985-x","20210924","PubMed","Extra-corporeal anastomosis; Intra-corporeal anastomosis; Laparoscopic right colectomy; Meta-analysis; Robotic right colectomy; Anastomosis, Surgical; Colectomy; Humans; Laparoscopy; Length of Stay; Operative Time; Prospective Studies; Retrospective Studies; Robotic Surgical Procedures; Treatment Outcome","The aim of the present systematic review and meta-analysis is to compare laparoscopic right colectomy (LRC) versus robotic right colectomy (RRC) using homogeneous subgroup analyses for extra-corporeal anastomosis (EA) and intra-corporeal anastomosis (IA). MEDLINE, Scopus, and Web of Science databases were searched up to April 2020 for prospective or retrospective studies comparing LRC versus RRC on at least one short- or long-term outcome. The primary outcome was the length of hospital stay (LOS). The secondary outcomes included operative and pathological results, survival, and total costs. LRC and RRC were compared using three homogeneous subgroups: without distinction by the type of anastomosis, EA only, and IA only. Pooled data analyses were performed using mean difference (MD) and random effects model. Thirty-seven of 448 studies were selected. The included patients were 21,397 for the LRC group and 2796 for the RRC group. Regardless for the type of anastomosis, RRC showed shorter LOS, lower blood loss, lower conversion rate, shorter time to flatus, and lower overall complication rate compared with LRC, but longer operative time and higher total costs. In the EA subgroup, RRC showed similar LOS, longer operative time, and higher costs compared with LRC, the other outcomes being similar. In the IA subgroup, RRC showed shorter LOS and longer operative time compared with LRC, with no difference for the remaining outcomes. Most included articles are retrospective, providing low-quality evidence and limiting conclusions. The more frequent use of the IA seems to explain the advantages of RRC over LRC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21505,""
"Robotic spine surgery: a review of the present status","Kalidindi, Sharma, Jagadeesh, Sath, Chhabra","https://doi.org/10.1080/03091902.2020.1799098","20210805","PubMed","Robotic spine surgery; literature review; robotic pedicle screw; spine robotic surgery; History, 20th Century; History, 21st Century; Humans; Robotic Surgical Procedures; Spine","With technological advancements being introduced and dominating many fields, spine surgery is no exception. In view of the patient safety and surgeon's comfort, robotics has been introduced in spine surgery. Due to small corridors for work, little room for inaccuracy, lengthy and tedious procedures, spine surgery is an ideal scenario for robotics to establish as the standard of care. Spine robotics received their first FDA clearance in 2004. New generation of spine robotics with integrated navigation systems has become available now. The primary role of spine robotics, at present, is to aid pedicle screw fixation. High quality studies have been performed to establish its role in increasing the accuracy of pedicle fixation. Studies have also reported decreased radiation and decreased operative time with spine robotics. However, few studies have reported otherwise. It is still in its nascent stage in both industrial view and surgeon familiarity. Continued research to overcome the challenges such as high cost and steep learning curve is crucial for its widespread use. Also, expanding the scope of spine robotics beyond pedicle screw fixation such as osteotomies and dural procedures would be an area for potential research. This review is intended to provide an overview of various studies in the field of robotic spine surgery and its present status.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21506,""
"DZC DIAG: mobile application based on expert system to aid in the diagnosis of dengue, Zika, and chikungunya","de AraÃƒÂºjo, de Araujo, Cavalcanti, de Lacerda Vidal, da Silva","https://doi.org/10.1007/s11517-020-02233-6","20210811","PubMed","Chikungunya virus; Dengue; Expert system; Zika virus; mHealth; Brazil; Chikungunya Fever; Dengue; Diagnosis, Computer-Assisted; Diagnostic Errors; Expert Systems; Humans; Knowledge Bases; Mobile Applications; Physicians; User-Computer Interface; Zika Virus Infection","Dengue, Zika, and chikungunya are epidemic diseases transmitted by the Aedes mosquito. These virus infections can be so severe to the point of bringing on mobility and neurological problems, or even death. Expert systems (ES) can be used as tools for the identification of patterns intended to solve problems in the same way as a professional specialist would. This work aimed to develop an ES in the form of an Android application to serve as a supportive tool in the diagnosis of these arboviruses. The goal is to associate the set of symptoms from a patient to a score related to the likelihood of them having these diseases. To make this possible, we implemented a rule-based ES which considers the presence of symptoms itself and the relation between them to associate the case under analysis to others found in the literature. We performed 96 tests (32 for each illness), and our system had a success rate of 96.88%. Resident physicians of a public hospital also analyzed these clinical cases and achieved an average success rate of 72.92%. Comparing the results of the method proposed and errors made by health professionals, we showed an improvement in the effectiveness of clinical diagnoses. Graphical abstract Figure - DZC DIAG Operating Flowchart: the physicians record patients' data and answer a series of questions related to the patient's symptoms; after all the questions, the result is generated by the expert system (score for dengue, Zika, and chikungunya); and it is saved in the same device where the test was done and uploaded online to a FTP.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21507,""
"Reporting of methodologies used for clonogenic assays to determine radiosensitivity","Oike, Komatsu, Komatsu, Nachankar, Darwis, Shibata, Ohno","https://doi.org/10.1093/jrr/rraa064","20210927","PubMed","cancer; clonogenic assays; radiation; radiosensitivity; replicates; Biological Assay; Cell Line, Tumor; Cell Survival; Cells, Cultured; Gamma Rays; Humans; Neoplasms; Neural Networks, Computer; Radiation Oncology; Radiation Tolerance; Reproducibility of Results; Research Design; Treatment Outcome; Tumor Stem Cell Assay; X-Rays","Radiotherapy treatment strategies should be personalized based on the radiosensitivity of individual tumors. Clonogenic assays are the gold standard method for in vitro assessment of radiosensitivity. Reproducibility is the critical factor for scientific rigor; however, this is reduced by insufficient reporting of methodologies. In reality, the reporting standards of methodologies pertaining to clonogenic assays remain unclear. To address this, we performed a literature search and qualitative analysis of the reporting of methodologies pertaining to clonogenic assays. A comprehensive literature review identified 1672 papers that report the radiosensitivity of human cancer cells based on clonogenic assays. From the identified papers, important experimental parameters (i.e. number of biological replicates, technical replicates, radiation source and dose rate) were recorded and analyzed. We found that, among the studies, (i) 30.5% did not report biological or technical replicates; (ii) 47.0% did not use biological or technical replicates; (iii) 3.8% did not report the radiation source; and (iv) 32.3% did not report the dose rate. These data suggest that reporting of methodologies pertaining to clonogenic assays in a considerable number of previously published studies is insufficient, thereby threatening reproducibility. This highlights the need to raise awareness of standardization of the methodologies used to conduct clonogenic assays.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21508,""
"Perioperative outcomes and safety of robotic vs open cystectomy: a systematic review and meta-analysis of 12,640 cases","Clement, Pearce, Gabr, Rai, Al-Ansari, Aboumarzouk","https://doi.org/10.1007/s00345-020-03385-8","20210916","PubMed","Bladder cancer; Cystectomy; Meta-analysis; Minimally invasive; Robotics; Cystectomy; Humans; Robotic Surgical Procedures; Treatment Outcome; Urinary Bladder Neoplasms","Robotic radical cystectomy (RRC) has become a commonly utilised alternative to open radical cystectomy (ORC). We performed a systematic review and meta-analysis of RRC vs ORC focusing on perioperative outcomes and safety. Medline, EMBASE and CENTRAL were searched from January 2000 to April 2020 following the Preferred Reporting Items for Systematic Review and Meta-analysis Statement for study selection. In total, 47 studies (5 randomised controlled trials, 42 non-randomised comparative studies) comprising 12,640 patients (6572 ORC, 6068 RRC) were included. There was no difference in baseline demographics between the groups apart from males were more likely to undergo ORC (OR 0.77, 95% CI 0.69-0.85). Those with muscle-invasive disease were more likely to undergo RRC (OR 1.21, 95% CI 1.09-1.34), and those with high-risk non-muscle-invasive bladder cancer were more likely to undergo ORC (OR 0.80, 95% CI 0.72-0.89). RRC had a significantly longer operating time, less blood loss and lower transfusion rate. There was no difference in lymph node yield, rate of positive surgical margins, or Clavien-Dindo Grade I-II complications between the two groups. However, the RRC group were less likely to experience Clavien-Dindo Grade III-IV (OR 1.56, 95% CI 1.30-1.89) and overall complications (OR 1.45, 95% CI 1.26-1.68) than the ORC group. The mortality rate was higher in ORC although this did not reach statistical significance (OR 1.52, 95% CI 0.99-2.35). RRC has significantly lower blood loss, transfusion rate and is associated with fewer high grade and overall complications compared to ORC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21509,""
"DoesÃ‚Â health and social care provision for the community dwelling older population help to reduce unplanned secondary care, support timely discharge and improve patient well-being? A mixed method meta-review of systematic reviews","Dawson, Kunonga, Beyer, Spiers, Booker, McDonald, Cameron, Craig, Hanratty, Salisbury, Huntley","https://doi.org/10.12688/f1000research.25277.1","20211021","PubMed","community-dwelling older population; health care; meta-review; patient well-being; social care; systematic reviews; unplanned admissions; Humans; Independent Living; Patient Discharge; Research Design; Secondary Care; Social Support","<b>Background:</b> This study aimed to identify and examine systematic review evidence of health and social care interventions for the community-dwelling older population regarding unplanned hospital admissions, timely hospital discharge and patient well-being. <b>Methods:</b> A meta-review was conducted using Joanna Briggs and PRISMA guidance. A search strategy was developed: eight bibliographic medical and social science databases were searched, and references of included studies checked. Searches were restricted to OECD countries and to systematic reviews published between January 2013-March 2018. Data extraction and quality appraisal was undertaken by one reviewer with a random sample screened independently by two others. <b>Results:</b> Searches retrieved 21,233 records; using data mining techniques, we identified 8,720 reviews. Following title and abstract and full-paper screening, 71 systematic reviews were included: 62 quantitative, seven qualitative and two mixed methods reviews. There were 52 reviews concerned with healthcare interventions and 19 reviews concerned with social care interventions. This meta-review summarises the evidence and evidence gaps of nine broad types of health and social care interventions. It scrutinises the presence of research in combined health and social care provision, finding it lacking in both definition and detail given. This meta-review debates the overlap of some of the person-centred support provided by community health and social care provision. Research recommendations have been generated by this process for both primary and secondary research. Finally, it proposes that research recommendations can be delivered on an ongoing basis if meta-reviews are conducted as living systematic reviews. <b>Conclusions:</b> This meta-review provides evidence of the effect of health and social care interventions for the community-dwelling older population and identification of evidence gaps. It highlights the lack of evidence for combined health and social care interventions and for the impact of social care interventions on health care outcomes. <b>Registration:</b> PROSPERO ID CRD42018087534; registered on 15 March 2018.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21510,""
"Anesthesia management for robotic assisted radical prostatectomy Single center experince","Ince, Ozkan, Ors, Zor, YÃ„Â±ldÃ„Â±rÃ„Â±m","https://www.google.com/search?q=Anesthesia+management+for+robotic+assisted+radical+prostatectomy.+Single+center+experince.","20210816","PubMed","Anesthesia; Humans; Laparoscopy; Male; Prostatectomy; Prostatic Neoplasms; Retrospective Studies; Robotic Surgical Procedures; Treatment Outcome","The aim of this study was to present our experiences for anesthesia management in patients undergoing robot-assisted radical prostatectomy (RARP) in light of current literature data. This clinical retrospective study included 103 patients who underwent robot-assisted radical prostatectomy. All patient data were obtained from the patient files and anesthesia follow-up forms. Demographic datas, intraoperative fluids, blood products requirement and blood gas parameters were recorded. A total 15 of 103 patients data were lack, the remaining 88 patients were evaluated. Combination of crystalloid and colloid was used for intravenous fluid management. About 11% of patients required transfusion during surgery. The mean pH and pO2 values of the patients were observed to decrease whereas pCO2 and lactate values increased. Radical Prostatectomy can be performed either using open technique as a traditional approach or laparoscopic or robot-assisted technique as a minimally invasive approach. Today, minimally invasive approaches have replaced traditional open prostatectomy. Anaesthesia management of these minimally invasive techniques is very different and challenging from open technique in many aspects. Although minimally invasive techniques have good surgical outcomes such as less blood loss, smaller surgical incision, and shorter hospitalization, these techniques bring new problems that anesthesiologists have to deal with. Increased RARP operations has led to the anesthesiologists more likely to encounter perioperative problems. Anesthesia, Minimally invasive techniques, Radical prostatectomy. La prostatectomia radicale puÃƒÂ² essere eseguita utilizzando la tecnica a Ã¢â‚¬Å“cielo apertoÃ¢â‚¬Â come approccio tradizionale o la tecnica laparoscopica o robot-assistita come approccio minimamente invasivo. Oggi, gli approcci minimamente invasivi hanno sostituito la tradizionale prostatectomia a Ã¢â‚¬Å“cielo apertoÃ¢â‚¬Â. La gestione dellÃ¢â‚¬â„¢anestesia di queste tecniche minimamente invasive ÃƒÂ¨ molto diversa e impegnativa rispetto alla tecnica a Ã¢â‚¬Å“cielo apertoÃ¢â‚¬Â sotto molti aspetti. Lo scopo di questo studio ÃƒÂ¨ quello di presentare le nostre esperienze sulla gestione dellÃ¢â‚¬â„¢anestesia in pazienti sottoposti a prostatectomia radicale robot-assistita (RARP) e confrontarla con i dati attuali della letteratura. Si tratta di uno studio clinico retrospettivo che comprende 103 pazienti sottoposti a prostatectomia radicale robot-assistita. Tutti i dati dei pazienti sono stati ottenuti dalle cartelle cliniche dei pazienti e dai moduli di follow-up sullÃ¢â‚¬â„¢anestesia. Sono stati registrati dati demografici, infusione di liquidi intraoperatoriamente, fabbisogno di derivati del sangue e parametri dellÃ¢â‚¬â„¢rmogasanalisi. Mancano i dati di 15 sul totale di 103 pazienti, e la valutazione ÃƒÂ¨ stata fatta sui restanti 88 pazienti. Una combinazione di cristalloidi e colloidi ÃƒÂ¨ stata utilizzata per lÃ¢â‚¬â„¢infusione endovenosa intraoperatoria. Circa lÃ¢â‚¬â„¢11% dei pazienti ha richiesto trasfusioni durante lÃ¢â‚¬â„¢intervento chirurgico. ÃƒË† stato osservato che i valori medi di pH e pO2 dei pazienti diminuivano mentre aumentavano quelli della pCO2 e del lattato. Sebbene le tecniche minimamente invasive abbiano buoni esiti chirurgici come una minore perdita di sangue, una piÃƒÂ¹ piccola incisione chirurgica e un ricovero piÃƒÂ¹ breve, queste tecniche portano nuovi problemi che gli anestesisti devono affrontare. LÃ¢â‚¬â„¢aumento delle operazioni RARP ha portato gli anestesisti ad avere maggiori probabilitÃƒ di incontrare problemi perioperatori.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21511,""
"Establishing a successful robotic surgery program and improving operating room efficiency: literature review and our experience report","Giedelman, Covas Moschovas, Bhat, Brunelle, Ogaya-Pinies, Roof, Corder, Patel, Palmer","https://doi.org/10.1007/s11701-020-01121-3","20211011","PubMed","Robotic surgery; Robotic surgery program; da Vinci robot; Efficiency; Efficiency, Organizational; Facility Design and Construction; Humans; Laparoscopy; Marketing of Health Services; Operating Rooms; Patient Care Team; Quality Improvement; Quality of Health Care; Robotic Surgical Procedures","The benefits and outcomes of robotic surgery are well established in the literature across multiple specialties. The increasing need for and dissemination of this technology associated with high costs, demand adequate planning during its implementation. Therefore, after years of training several robotic surgeons and establishing multiple robotic programs worldwide, the purpose of this article is to focus on the necessary elements in the initial phase of establishing a robotics program. We summarized in our article crucial factors when implementing a robotic program. Therefore, we explained in detail the critical aspects of the program design, implementation, marketing, research and outcomes, and ultimately improving efficiency. The creation of a robotics planning committee composed of several hospital individuals contributes in different lines of work such as cost evaluation, staff training, and OR modifications. A multidisciplinary approach and a robotic lead surgeon are also recommended to guarantee surgical volume and satisfactory outcomes. Furthermore, market analysis should evaluate the competition with other centres and potential surgical candidates in that area. Data collection should also be considered a vital element of the program organization, which assures quality control and helps to diagnose any program deficiency. We believe that the robotic program should be individualized according to the economy and reality of each centre. The success and duration of a robotic surgery program depend on long-term results. Therefore, careful planning with a robotic committee defining the types of procedures to be performed and appropriate multidisciplinary training to avoid surgery cancelations are crucial factors in establishing a successful program.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21512,""
"European Society of Coloproctology Colorectal Robotic Surgery Training for the Trainers Course - the first pilot experience","Eardley, Matzel, GÃƒÂ³mez Ruiz, Khan, Riley, Donnelly, Tou","https://doi.org/10.1111/codi.15265","20210818","PubMed","colon; rectum; robotic surgical procedure; robotics; surgery; training; Colorectal Neoplasms; Colorectal Surgery; Curriculum; Humans; Robotic Surgical Procedures; Robotics","Currently, there is no established colorectal specific robotic surgery Train the Trainer (TTT) course. The aim was to develop and evaluate such a course which can then be further developed to be incorporated within the planned European Society of Coloproctology (ESCP)/European School of Coloproctology (ESC) robotic colorectal surgery training curriculum. After identifying the need for such a course within a training programme, the course was developed by a subgroup of the ESCP/ESC. A scoping literature review was performed and the content and materials for the course were developed by a team consisting of two gastroenterologists with a combined experience of 30Ã‚Â years of facilitating TTT courses, a robotic surgeon and proctor with laparoscopic TTT faculty experience and experienced robotic and laparoscopic colorectal trainers. The course was evaluated by asking delegates to complete pre- and post-course questionnaires. There were eight delegates on the course from across Europe. Delegates increased their knowledge of each of the course learning objectives and identified learning points in order to change practice. The feedback from the delegates of the course was positive across several areas and all felt that they had achieved their own personal objectives in attending the course. This pilot robotic colorectal TTT course has achieved its aim and demonstrated many positives. There is a need for such a course and the evaluation processes have provided opportunities for reflection, which will allow the development/tailoring of future robotic colorectal TTT courses to help develop robotic training further.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21513,""
"Robotic-assisted approaches to GERD following sleeve gastrectomy","Bellorin, Dolan, Vigiola-Cruz, Al Hussein Alawamlh, Pomp, Dakin, Afaneh","https://doi.org/10.1007/s00464-020-07753-8","20210929","PubMed","Bariatrics; Bypass; GERD; Robotics; Sleeve; Gastrectomy; Gastric Bypass; Gastroesophageal Reflux; Humans; Obesity, Morbid; Retrospective Studies; Robotic Surgical Procedures; Treatment Outcome","Sleeve gastrectomy (SG) is the most common bariatric operation in the United States but increases the incidence of gastroesophageal reflux disease (GERD). The aim of our study was to describe our experience with robotic-assisted management of intractable GERD after SG. A systematic review of a prospectively maintained database was performed of consecutive patients undergoing robotic-assisted magnetic sphincter augmentation placement after sleeve gastrectomy (MSA-S group) or conversion to Roux-en-Y gastric bypass (RYGB group) for GERD from 2015 to 2019 at our tertiary- care bariatric center. These were compared to a consecutive group of patients undergoing robotic-assisted magnetic sphincter augmentation placement (MSA group) for GERD without a history of bariatric surgery from 2016 to 2019. The primary outcome was perioperative morbidity. Secondary outcomes were operative time (OT), 90-day re-intervention rate, length of stay, symptom resolution and weight change. There were 51 patients included in this study; 18 patients in the MSA group, 13 patients in the MSA-S group, and 20 patients in the RYGB group. There was no significant difference in age, gender, ASA score, preoperative endoscopic findings, or DeMeester scores (PÃ¢â‚¬â€°&gt;Ã¢â‚¬â€°0.05). BMI was significantly higher in patients undergoing RYGB compared to MSA or MSA-S (PÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.0001). There were significant differences in OT between the MSA and RYGB groups (PÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.0001) and MSA-S and RYGB groups (PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.009), but not MSA group to MSA-S group (PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.51). There was no significant difference in intraoperative and postoperative morbidity (PÃ¢â‚¬â€°=Ã¢â‚¬â€°1.0 and PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.60, respectively). 30-day morbidity: 5.6% (MSA), 15.4% (MSA-S) and 15% (RYGB). There was no difference on PPI discontinuation among groups, with more than 80% success rate in all. The use of the robotic platform in the different approaches available for treatment of GERD after SG appears to be a feasible option with low morbidity and high success rate. Further data is needed to support our findings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21514,""
"Effects of non-facilitated meaningful activities for people with dementia in long-term care facilities: A systematic review","Jones, Liu, Murfield, Moyle","https://doi.org/10.1016/j.gerinurse.2020.06.001","20210917","PubMed","Dementia; Long-term care; Meaningful activities; Non-facilitated; Older people; Aged; Animals; Dementia; Humans; Long-Term Care; Nursing Homes; Robotics; Social Interaction","This systematic review sought to evaluate the effectiveness of non-facilitated meaningful activities for older people with dementia in long-term care facilities. Searches were conducted in PubMed; CINAHL; EMBASE; Web of science; PsycINFO; Cochrane; ProQuest; and ClinicalTrials.gov to identify articles published between January 2004 and October 2019. A total of six studies were included. Results implied that current randomised controlled trials or controlled trials about non-facilitated meaningful activities for people with living dementia in long-term care facilitates are limited, but those included in this review were of adequate methodological quality. Meaningful non-facilitated activities, such as music, stimulated family presence, animal-like social robot PARO/plush toy and lifelike dolls, may have beneficial effects on agitation, emotional well-being, feelings of pleasure, engagement, and sleep quality. However, there remains a lack of conclusive and robust evidence to support these psychological and physiological effects of non-facilitated meaningful activities for older people with dementia living in long-term care facilities by care staff.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21515,""
"Analysis of performance factors in 240 consecutive cases of robot-assisted flexible ureteroscopic stone treatment","Klein, Charalampogiannis, Fiedler, Wakileh, GÃƒÂ¶zen, Rassweiler","https://doi.org/10.1007/s11701-020-01103-5","20210913","PubMed","Learning curve; Robotic endourology; Robotic technology; Robotic ureteroscopy; Stone surgery; Ureteroscopy; Adult; Female; Humans; Kidney Calculi; Length of Stay; Male; Middle Aged; Operative Time; Pliability; Postoperative Complications; Robotic Surgical Procedures; Treatment Outcome; Ureteroscopy","Flexible ureteroscopy is the keystone of modern kidney stone treatment. Although a simple surgical technique achieves good clinical results and a low complication rate, there are high demands on the surgeon's dexterity and ergonomic restrictions. Robotic-assisted flexible ureteroscopy (rfURS) could overcome these limitations. After 4Ã‚Â years of use of rfURS at a tertiary stone center, performance factors were analyzed to define the role of rfURS in kidney stone management. A rfURS system was installed in August 2014 at the SLK Kliniken (Heilbronn, Germany). Treatment data of NÃ¢â‚¬â€°=Ã¢â‚¬â€°240 consecutive patients undergoing rfURS were prospectively collected and analyzed. The patient cohort represents typical stone formers. NÃ¢â‚¬â€°=Ã¢â‚¬â€°240 renal units containing 443 stones with an average stone load of 1798Ã‚Â mm<sup>3</sup> were treated. Surgical parameters as well as the peri- and postoperative complications were recorded, analyzed and compared to the current data in the literature. OR time 91Ã‚Â min, stone treatment time 55Ã‚Â min, stone treatment efficacy 33Ã‚Â mm<sup>3</sup>/min; perioperative complications 5.4%; robot times: preparation 5Ã‚Â min, docking 5Ã‚Â min, console time to stone contact 6Ã‚Â min, console time 75Ã‚Â min; postoperative complications 6.7%; postoperative length of stay 1.5Ã‚Â days; stone-free rate (residuals &lt;Ã¢â‚¬â€°2Ã‚Â mm) 90% and re-treatment rate 8.75%. This consecutive series represents real-life data about the utilization of rfURS. The detailed analysis of performance factors revealed the successful utilization of the first generation of robotic systems in endourologic stone surgery, and indicates that the robot performs comparably to conventional flexible URS. Optimal ergonomics maintain the surgeon's endurance in long-lasting surgeries.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21516,""
"Transition from laparoscopic to robotic rectal resection: outcomes and learning curve of the initial 100 cases","Olthof, Giesen, Vijfvinkel, Roos, Dekker","https://doi.org/10.1007/s00464-020-07731-0","20210922","PubMed","Rectal cancer; Rectal resection; Robot-assisted surgery; Robotic; Humans; Laparoscopy; Learning Curve; Male; Proctectomy; Prospective Studies; Rectal Neoplasms; Retrospective Studies; Robotic Surgical Procedures; Treatment Outcome","Following several landmark trials, laparoscopic rectal resection has reached standard clinical practice. Current literature is undecided on the advantages of robotic rectal resection and little is known on its learning curve. This study aimed to compare the outcomes of the first 100 robotic rectal resections to the laparoscopic approach in a teaching hospital experienced in laparoscopic colorectal surgery. A retrospective analysis was conducted of a prospective cohort of all consecutive rectal resections between January 2012 and September 2019 at a single center. All laparoscopic cases were compared to the robotic approach. Outcomes included operative time, morbidity, anastomotic leakage, and hospital stay. Out of the 326 consecutive resections, 100 were performed robotically and 220 laparoscopically, the remaining 6 open cases were excluded. Median operative time was lower for robotic cases (147 (121-167) versus 162 (120-218) minutes PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.024). Overall morbidity was lower in robotic cases (25% versus 50%, PÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.001), while major morbidity was similar. Anastomotic leakage was observed in 11% (8/70) of robotic and 15% (18/120) of laparoscopic anastomoses, despite more anastomoses in the robotic group (70%, 70/100 versus 55%, 120/220, PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.001). Median length of stay was 4 (4-7) days after a robotic and 6 (5-9) days after a laparoscopic procedure. Implementation of a robotic rectal resection program in an experienced laparoscopic surgery center was associated with reduced operative time, length of stay, and fewer complications despite a learning curve.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21517,""
"A Coupled FEM-SPH Modeling Technique to Investigate the Contractility of Biohybrid Thin Films","Vannozzi, Mazzocchi, Hasebe, Takeoka, Fujie, Ricotti","https://doi.org/10.1002/adbi.201900306","20210930","PubMed","bio-hybrid robots; bioactuators; finite element modeling; living machines; smooth particle hydrodynamics; soft microrobots; thin films; Animals; Cell Line; Dimethylpolysiloxanes; Finite Element Analysis; Humans; Hydrostatic Pressure; Membranes, Artificial; Mice; Muscle Contraction; Muscle Fibers, Skeletal; Muscle, Skeletal; Myoblasts; Polyesters; Robotics; Tissue Engineering","Biohybrid actuators have the potential to overcome the limitations of traditional actuators employed in robotics, thanks to the unique features of living contractile muscle cells, which can be used to power artificial elements. This paper describes a computational approach for the estimation of the contractile capabilities of skeletal muscle cell-powered biohybrid actuators based on polymeric thin films. The proposed model grounds on the coupling between finite element modeling and smooth particle hydrodynamics. This allows describing the overall condition, including the viscous forces caused by the surrounding liquid medium, in which biohybrid systems are normally immersed. The model is calibrated by analyzing the contractile behavior of polydimethylsiloxane films coupled with skeletal muscle cells, reported in the literature as muscular thin films. Afterward, it is applied to poly (D, L-lactic acid) thin films to explore the behavior of these systems, due to myotubes cultured on them, evaluating the role of thickness, tissue maturation status, and hydrostatic pressure on the contractile performance. These results pave the way toward a novel optimization approach of biohybrid robot design relying on the simulation of all the boundary conditions, thus reducing the need for extensive trial-and-error efforts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21518,""
"Integrative analysis of key candidate genes and signaling pathways in autoimmune thyroid dysfunction related to anti-CTLA-4 therapy by bioinformatics","Zhang, Garofano, Wu, Schmid, Krawitz, Essler, Schmidt-Wolf","https://doi.org/10.1007/s10637-020-00952-z","20210910","PubMed","Autoimmune thyroid dysfunction; CTLA-4; Differentially expressed genes; Immune checkpoint blockade; Signaling pathway; Animals; Autoimmune Diseases; Biomarkers; CTLA-4 Antigen; Computational Biology; Gene Expression Regulation, Neoplastic; Gene Ontology; Humans; Hyperthyroidism; Hypothyroidism; Immune Checkpoint Inhibitors; Mice; Protein Interaction Maps; Signal Transduction","Cytotoxic T lymphocyte-associated antigen-4 (CTLA-4), the first immune checkpoint to be targeted clinically, has provided an effective treatment option for various malignancies. However, the clinical advantages associated with CTLA-4 inhibitors can be offset by the potentially severe immune-related adverse events (IRAEs), including autoimmune thyroid dysfunction. To investigate the candidate genes and signaling pathways involving in autoimmune thyroid dysfunction related to anti-CTLA-4 therapy, integrated differentially expressed genes (DEGs) were extracted from the intersection of genes from Gene Expression Omnibus (GEO) datasets and text mining. The functional enrichment was performed by gene ontology (GO) annotation and Kyoto encyclopedia of genes and genomes (KEGG) pathway analysis. Protein-protein interaction (PPI) network, module enrichment, and hub gene identification were constructed and visualized by the online Search Tool for the Retrieval of Interacting Genes (STRING) and Cytoscape software. A total of 22 and 17 integrated human DEGs in hypothyroidism and hyperthyroidism group related to anti-CTLA-4 therapy were identified, respectively. Functional enrichment analysis revealed 24 GO terms and 1 KEGG pathways in the hypothyroid group and 21 GO terms and 2 KEGG pathways in the hyperthyroidÃ‚Â group. After PPI network construction, the top five hub genes associated with hypothyroidism were extracted, including ALB, MAPK1, SPP1, PPARG, and MIF, whereas those associated with hyperthyroidism were ALB, FCGR2B, CD44, LCN2, and CD74. The identification of the candidate key genes and enriched signaling pathways provides potential biomarkers for autoimmune thyroid dysfunction related to anti-CTLA-4 therapy and might contribute to the future diagnosis and management of IRAEs for cancer patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21519,""
"Reinforcement learning application in diabetes blood glucose control: A systematic review","Tejedor, Woldaregay, Godtliebsen","https://doi.org/10.1016/j.artmed.2020.101836","20210818","PubMed","Artificial pancreas; Blood glucose control; Closed-loop; Insulin infusion; Reinforcement learning; Algorithms; Blood Glucose; Blood Glucose Self-Monitoring; Diabetes Mellitus, Type 1; Exercise; Humans; Insulin","Reinforcement learning (RL) is a computational approach to understanding and automating goal-directed learning and decision-making. It is designed for problems which include a learning agent interacting with its environment to achieve a goal. For example, blood glucose (BG) control in diabetes mellitus (DM), where the learning agent and its environment are the controller and the body of the patient respectively. RL algorithms could be used to design a fully closed-loop controller, providing a truly personalized insulin dosage regimen based exclusively on the patient's own data. In this review we aim to evaluate state-of-the-art RL approaches to designing BG control algorithms in DM patients, reporting successfully implemented RL algorithms in closed-loop, insulin infusion, decision support and personalized feedback in the context of DM. An exhaustive literature search was performed using different online databases, analyzing the literature from 1990 to 2019. In a first stage, a set of selection criteria were established in order to select the most relevant papers according to the title, keywords and abstract. Research questions were established and answered in a second stage, using the information extracted from the articles selected during the preliminary selection. The initial search using title, keywords, and abstracts resulted in a total of 404 articles. After removal of duplicates from the record, 347 articles remained. An independent analysis and screening of the records against our inclusion and exclusion criteria defined in Methods section resulted in removal of 296 articles, leaving 51 relevant articles. A full-text assessment was conducted on the remaining relevant articles, which resulted in 29 relevant articles that were critically analyzed. The inter-rater agreement was measured using Cohen Kappa test, and disagreements were resolved through discussion. The advances in health technologies and mobile devices have facilitated the implementation of RL algorithms for optimal glycemic regulation in diabetes. However, there exists few articles in the literature focused on the application of these algorithms to the BG regulation problem. Moreover, such algorithms are designed for control tasks as BG adjustment and their use have increased recently in the diabetes research area, therefore we foresee RL algorithms will be used more frequently for BG control in the coming years. Furthermore, in the literature there is a lack of focus on aspects that influence BG level such as meal intakes and physical activity (PA), which should be included in the control problem. Finally, there exists a need to perform clinical validation of the algorithms.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21520,""
"Three-dimensional Printed Drill Guides Versus Fluoroscopic-guided Freehand Technique for Pedicle Screw Placement: A Systematic Review and Meta-analysis of Radiographic, Operative, and Clinical Outcomes","Wallace, Butt, Aleem, Patel","https://doi.org/10.1097/BSD.0000000000001023","20211011","PubMed","Fluoroscopy; Humans; Pedicle Screws; Postoperative Complications; Printing, Three-Dimensional; Robotic Surgical Procedures; Spinal Fusion; Treatment Outcome","A systematic review and meta-analysis. The objective of this study was to compare surgical, clinical, and radiographic outcomes of 3-dimensional printed (3DP) drill guides to the fluoroscopic-guided, freehand placement of pedicle screws in the spine. 3DP is a budding technology in spine surgery and has recently been applied to patient-specific drill guides for pedicle screw placement. Several authors have reported the benefits of these drill guides, but no clear consensus exists on their utility. A comprehensive search of the literature was conducted and independent reviewers assessed eligibility for included studies. Outcomes analyzed included: total operation time, estimated blood loss, screw accuracy, pain score, Japanese Orthopedic Association score, and postoperative complications. Weighted mean differences (WMD) and weighted risk differences were calculated using a random-effects model. Six studies with a total of 205 patients were included. There were significantly lower operation times [WMD=-32.32Ã¢â‚¬â€°min, 95% confidence interval (CI)=-53.19 to -11.45] and estimated blood loss (WMD=-51.42Ã¢â‚¬â€°mL, 95% CI=-81.12 to -21.72) in procedures performed with 3DP drill guides as compared with freehand technique. The probability of ""excellent"" screw placement was significantly higher in 3DP guides versus freehand (weighted risk difference=-0.12, 95% CI=-0.17 to 0.07); however, no differences were observed in ""poor"" or ""good"" screw placement. There were no significant differences between groups in pain scores or Japanese Orthopedic Association scores. No difference in the rate of surgical complications was noted between the groups. Pedicle screws placed with 3DP drill guides may result in shorter operative time, less blood loss, and a greater probability of excellent screw placement as compared with those placed with freehand techniques. We conclude that 3DP guides may potentially develop into an efficient and accurate option for pedicle screw placement. However, more prospective, randomized controlled trials are needed to strengthen the confidence of these conclusions. Level III.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21521,""
"The Use of Enhanced Technologies in Robotic Surgery and Its Impact on Outcomes in Rectal Cancer: A Systematic Review","Tejedor, Sagias, Khan","https://doi.org/10.1177/1553350620928277","20211015","PubMed","indocyanine green; robotic colorectal; robotic resection; robotic surgery; Adult; Anastomotic Leak; Humans; Laparoscopy; Rectal Neoplasms; Rectum; Robotic Surgical Procedures; Treatment Outcome","The main advantage of the robotic approach is the surgical precision that the technology offers. It is particularly useful in rectal cancer as this is a technically challenging procedure. The technological advantage of the robot leads to better postoperative outcomes. Apart from the 3D vision and endowrist instrumentation in comparison to laparoscopy, the options of using fluorescence imaging, endowrist stapler, and table motion have revolutionised the way of performing an anterior resection. Thus, the true benefit of these advances will be the quality of the surgery, which leads to better postoperative outcomes. This article focuses on the current status of applications of new modalities and technology development in robotic rectal surgery. A systematic literature search was performed using PubMed, MEDLINE, and cochrane database. The studies included were considered based on the following (1) articles written in English, (2) full text is available, (3) whether the topic is related to the use of novel technologies during robotic rectal surgery, and (4) sample: adult patients and malignant rectal disease. The primary end point was to analyse the current use of technological advances in robotic rectal surgery. Only a few studies are currently available on the use of these different technologies in robotic colorectal surgery. Many of these reports describe promising results, although with short-term outcomes. The use of technologies in robotic colorectal surgery is safe and feasible and can be used together to improve short-term outcomes. Intraoperative fluorescence angiography has demonstrated to reduce the rate of anastomotic leak, whereas the robotic stapler and the table motion simplify anatomic resection.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21522,""
"The robotic single-port platform for gynecologic surgery: a systematic review of the literature and meta-analysis","Capozzi, Armano, Rosati, Tropea, Biondi","https://doi.org/10.1007/s13304-020-00812-8","20211015","PubMed","Complications; Gynecological surgery; Hysterectomy; Outcomes; Robotic single-site surgery; Female; Gynecologic Surgical Procedures; Humans; Hysterectomy; Laparoscopy; Operative Time; Robotic Surgical Procedures","Since the first robotic single-site hysterectomy was performed, the research focused on the use of robotic single-site surgery (RSSS) for all gynecological conditions. This review aims to examine the studies available in the literature on RSSS in gynecology both for benign and malignant indications. The systematic review was carried out in agreement with the preferred reporting items for systematic reviews and meta-analyses statement (PRISMA). All the articles were grouped into three sets based on the surgical indication (Group 1, 2, and 3 for benign, malignant, and mixed diseases, respectively). Two hundred and fifty total studies were analyzed, and 27 articles were included in the review. A total of 1065 patients were included in the analysis. Of these, 605 patients were included in group 1, 260 in group 2, and 200 in group 3. Ten (1.7%) patients with benign pathology, 16 (6.2%) patients with malignant disease, and 5 (2.5%) patients with both diseases developed major complications. Two (0.3%) patients in group 1, 3 (1.2%) patients in group 2 and 5 (2.5%) in group 3 were converted to a different type of surgery. No significant differences were found between groups for BMI (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.235), operative time (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.723), estimated blood loss (EBL) (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.342), and hospital stay (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.146). The complications and conversions incidence through pooled analysis showed a higher general conversion rate (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.012) in group 3 (3.0%) and higher complications rate (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.001) in group 2 (5.3%) compared to the other groups. RSSS seems to be a feasible and safe procedure for all gynecological surgical procedures. A long-term analysis would be necessary before considering the RSSS oncologically safe for patients with malignant disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21523,""
"A systematic review of MAKO-assisted unicompartmental knee arthroplasty","Lin, Yan, Ye, Zhao","https://doi.org/10.1002/rcs.2124","20210818","PubMed","MAKO; joint replacement; robot system; unicompartmental knee arthroplasty; Arthroplasty, Replacement, Knee; Humans; Knee Joint; Learning Curve; Osteoarthritis, Knee; Robotic Surgical Procedures; Treatment Outcome","Unicompartmental knee arthroplasty (UKA), which has many potential advantages compared with total knee arthroplasty, was widely used across the world in recent years. The introduction of the robot systems greatly makes up for the defects of the conventional UKA surgery such as higher complication rates and revision rates. MAKO system, a new image-guided robot system relies on a preoperative computed tomography scan to assist in preoperative mapping and planning, offers an opportunity to improve the outcome of UKA surgeries. In order to have a more comprehensive and in-depth understanding of MAKO-assisted UKA, the studies on MAKO-assisted UKA were summarized. MAKO-assisted UKA is better than conventional UKA surgery on implant accuracy, soft tissue balance, patient function scores and satisfaction, complications rates, and learning curve in short-term outcome; however, the mid-term and long-term outcomes of MAKO-assisted UKA need to be further studied.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21524,""
"Perioperative outcomes of robot-assisted vs video-assisted and traditional open thoracic surgery for lung cancer: A systematic review and network meta-analysis","Hu, Chen, Dai, Zhu, Gonzalez-Rivas, Jiang, Li, Zhang","https://doi.org/10.1002/rcs.2123","20210818","PubMed","lung cancer; meta-analysis; robotic surgery; thoracoscopic surgery; thoracotomy; Humans; Length of Stay; Lung Neoplasms; Network Meta-Analysis; Pneumonectomy; Retrospective Studies; Robotics; Thoracic Surgery; Thoracic Surgery, Video-Assisted","The superiority of robot-assisted thoracic surgery (RATS) over video-assisted thoracic surgery (VATS) and thoracotomy remains controversial for lung cancer. A network meta-analysis (NMA) and pairwise meta-analysis (PMA) were performed to evaluate the perioperative outcomes using five databases. Thirty-two studies involving 6593 patients were included for analysis. The NMA showed that RATS had similar operative time, conversion rate to thoracotomy, number of lymph node, postoperative morbidity, and length of hospital stay with VATS, except for lower 30-day mortality. Compared with thoracotomy, longer operative time and shorter hospital stay were observed in RATS, but no significant difference was observed in number of lymph node, postoperative morbidity, and 30-day mortality in both NMA and PMA. In lobectomy/segmentectomy subgroup, all outcomes, except for operative time of RATS vs VATS and number of lymph node, were similar with overall analyses. RATS had comparable perioperative outcomes with VATS and open surgery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21525,""
"A systematic review on Transoral robotic surgery (TORS) for carcinoma of unknown primary origin: Has tongue base mucosectomy become indispensable?","van Weert, Rijken, Plantone, Bloemena, Vergeer, Lissenberg-Witte, Leemans","https://doi.org/10.1111/coa.13565","20211008","PubMed","cancer; head and neck surgery; neck lump; Head and Neck Neoplasms; Humans; Mouth; Mouth Mucosa; Natural Orifice Endoscopic Surgery; Neoplasms, Unknown Primary; Robotic Surgical Procedures; Tongue","Transoral robotic surgery (TORS) is increasingly used in head and neck surgery and in carcinoma of unknown primary (CUP) origin specifically. Due to the rising incidence of human papillomavirus (HPV)-related oropharyngeal squamous cell carcinoma (OPSCC), there is a rationale for finding ways to de-escalate treatment strategies. This review aims to test the hypothesis that TORS is a meaningful adjunct in the diagnostic (and therapeutic) pathway in CUP in head and neck. A structured search of the literature was performed with the search terms 'TORS' and 'Carcinoma of Unknown Primary'. Two hundred and seventy four cases of CUP in which TORS was used were identified for further analysis. Workup for CUP was comparable in all series with regard to physical examination, fine and/or gross needle examination of cervical nodes, fibre optic endoscopy, imaging and robot assisted mucosectomy of the base of tongue (BOT). Identification rate of the primary tumour was 72% on average (range 17%- 90%), and 55%- 96% were HPV positive. Clear margins were achieved in 60% (range 0%-85%) of resected occult tumours. Complication rate of TORS BOT mucosectomy was low with mainly grade I-III sequelae according to Clavien-Dindo. Transoral robotic surgery seems to be a useful and safe adjunct in the diagnostic and therapeutic pathway in case of CUP in an era of increasing incidence of HPV-positive OPSCC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21526,""
"Robotic vs laparoscopic total mesorectal excision for rectal cancers: has a paradigm change occurred? A systematic review by updated meta-analysis","Gavriilidis, Wheeler, Spinelli, de'Angelis, Simopoulos, Di Saverio","https://doi.org/10.1111/codi.15084","20210818","PubMed","MIS colorectal; Robotic; colorectal cancer; colorectal research; colorectal surgery; laparoscopic; meta-analysis; rectal cancer; robotic surgery; systematic review; total mesorectal excision; Humans; Laparoscopy; Operative Time; Rectal Neoplasms; Robotic Surgical Procedures; Robotics; Treatment Outcome","The debate about the oncological adequacy, safety and efficiency of robotic vs laparoscopic total mesorectal excision for rectal cancers continues. Therefore, an updated, traditional and cumulative meta-analysis was performed with the aim of assessing the new evidence on this topic. A systematic search of the literature for data pertaining to the last 25Ã‚Â years was performed. Fixed- and random-effects models were used to cumulatively assess the accumulation of evidence over time. Patients with a significantly higher body mass index (BMI), tumours located approximately 1Ã‚Â cm further distally and more patients undergoing neoadjuvant therapy were included in the robotic total mesorectal excision (RTME) cohort compared with those in the laparoscopic total mesorectal excision (LTME) cohort [RTME, mean difference (MD)Ã‚Â =Ã‚Â 0.22 (0.07, 0.36), PÃ‚Â =Ã‚Â 0.005; LTME, MDÃ‚Â =Ã‚Â -0.97 (-1.57, 0.36), PÃ‚Â &lt;Ã‚Â 0.002; ORÃ‚Â =Ã‚Â 1.47 (1.11, 1.93), PÃ‚Â =Ã‚Â 0.006]. Significantly lower conversion rates to open surgery were observed in the RTME cohort than in the LTME cohort [ORÃ‚Â =Ã‚Â 0.33 (0.24, 0.46), PÃ‚Â &lt;Ã‚Â 0.001]. Operative time in the LTME cohort was significantly reduced (by 50Ã‚Â min) compared with the RTME cohort. Subgroup analysis of the three randomized controlled trials (RCTs) challenged all the significant results of the main analysis and demonstrated nonsignificant differences between the RTME cohort and LTME cohort. Although the RTME cohort included patients with a significantly higher BMI, more distal tumours and more patients undergoing neoadjuvant therapy, this cohort demonstrated lower conversion rates to open surgery when compared with the LTME cohort. However, subgroup analysis of the RCTs demonstrated nonsignificant differences between the two procedures.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21527,""
"A systematic review of the true benefit of robotic surgery: Ergonomics","Wee, Kuo, Ngu","https://doi.org/10.1002/rcs.2113","20210818","PubMed","ergonomics; laparoscopy; robotics; Ergonomics; Humans; Laparoscopy; Robotic Surgical Procedures; Robotics; Surgeons","Ergonomics, as defined by the optimization of one's physical environment to enhance work performance, is an important consideration in surgery. While there have been reviews on the ergonomics of laparoscopy, this has not been the case for robotic surgery despite the rising number of publications. This study was performed in accordance to the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines. A search was performed on main databases to identify relevant articles. Twenty-nine articles were included, comprising 3074 participants. Studies employing objective measurement tools showed that robotics conferred superior ergonomic benefits and reduced work load compared to laparoscopy, for both surgeons and trainees. Survey studies also demonstrated that self-reported discomfort was lower in robotic procedures compared to laparoscopy and open surgery. Compared to other subspecialities, gynecological procedures seem to be associated with greater surgeon-reported strain. Robotic surgery is ergonomically superior to open and laparoscopic surgery. However, rates of physical strain remain significant and should be addressed by formal ergonomic training and adequate console familiarization.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21528,""
"Deidentification of free-text medical records using pre-trained bidirectional transformers","Johnson, Bulgarelli, Pollard","https://doi.org/10.1145/3368555.3384455","20210806","PubMed","HIPAA; PHI; deidentification; electronic health records; named entity recognition; natural language processing; neural networks","The ability of caregivers and investigators to share patient data is fundamental to many areas of clinical practice and biomedical research. Prior to sharing, it is often necessary to remove identifiers such as names, contact details, and dates in order to protect patient privacy. Deidentification, the process of removing identifiers, is challenging, however. High-quality annotated data for developing models is scarce; many target identifiers are highly heterogenous (for example, there are uncountable variations of patient names); and in practice anything less than perfect sensitivity may be considered a failure. As a result, patient data is often withheld when sharing would be beneficial, and identifiable patient data is often divulged when a deidentified version would suffice. In recent years, advances in machine learning methods have led to rapid performance improvements in natural language processing tasks, in particular with the advent of large-scale pretrained language models. In this paper we develop and evaluate an approach for deidentification of clinical notes based on a bidirectional transformer model. We propose human interpretable evaluation measures and demonstrate state of the art performance against modern baseline models. Finally, we highlight current challenges in deidentification, including the absence of clear annotation guidelines, lack of portability of models, and paucity of training data. Code to develop our model is open source, allowing for broad reuse.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21529,""
"Robot-Assisted versus Conventional Total and Unicompartmental Knee Arthroplasty: A Meta-analysis of Radiological and Functional Outcomes","Chin, Tan, Chua, Budiono, Syn, O'Neill","https://doi.org/10.1055/s-0040-1701440","20211014","PubMed","Arthroplasty, Replacement, Knee; Humans; Knee Joint; Observational Studies as Topic; Osteoarthritis, Knee; Prospective Studies; Robotic Surgical Procedures; Treatment Outcome","The study aims to provide an up-to-date systematic review and meta-analysis comparing radiological and functional outcomes of total knee arthroplasty (TKA) and unicompartmental knee arthroplasty (UKA) using either robotic assistance or conventional methods from the latest assemblage of evidence. This study was conducted according to PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) and MOOSE (Meta-analysis of Observational Studies in Epidemiology) guidelines. All studies in PubMed, EMBASE, Medline, and Cochrane that reported radiological and functional outcomes after TKA or UKA with either robotic or conventional methods were included in the review. Selected endpoints for random effects, pairwise meta-analysis included operative details, radiological outcomes (mechanical axis, component angle deviation, and outliers), and functional outcomes (American Knee Society Score, Knee Society Function Score, revision and complication rate, range of motion (ROM), Hospital for Special Surgery score, and Western Ontario and McMaster Universities Osteoarthritis Index). A total of 23 studies comprising 2,765 knees were included from the initial search. Robot-assisted TKA and UKA were associated with significantly better component angle alignment accuracy (low-to-high quality evidence) at the cost of significantly greater operation time. Robot-assisted UKA was found to have significantly better short-term functional outcomes compared with conventional UKA (moderate-to-high quality evidence). Robot-assisted TKA, however, did not exhibit significantly better short- and midterm subjective knee outcome scores compared with its conventional counterpart (high-quality evidence). Robot-assisted TKA and UKA were associated with nonstatistically significant improved ROM and lesser rates of revision. Robot-assisted total and unicompartmental knee arthroplasty leads to better radiological outcomes, with no significant differences in mid- and long-term functional outcomes compared with conventional methods for the former. Larger prospective studies with mid- and long-term outcomes are required to further substantiate findings from the present study.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21530,""
"Internal hernia beneath the obturator nerve after robot-assisted lateral lymph node dissection for rectal cancer: A case report and literature review","Uehara, Yamazaki, Kameyama, Iwaya, Gohda, Chinen, Kubota, Aoki, Kobayashi, Sato, Yokoyama, Kuwabara, Otani","https://doi.org/10.1111/ases.12795","20210818","PubMed","hernia; obturator nerve; rectal cancer; Hernia, Obturator; Humans; Internal Hernia; Lymph Node Excision; Male; Middle Aged; Obturator Nerve; Rectal Neoplasms; Robotic Surgical Procedures","A 63-year-old man who underwent robot-assisted laparoscopic low anterior resection and right lateral lymph node dissection (LLND) for rectal cancer presented with right thigh pain, nausea, vomiting, and abdominal pain on postoperative day 17. CT revealed dilated small bowel in the pelvis, and a small bowel loop was detected outside the internal iliac artery branch. Emergent laparoscopic surgery revealed the migration of the small bowel into the space beneath the right obturator nerve. The herniated bowel was reduced, and the obturator nerve was sharply dissected from the herniated bowel and preserved. The hernial orifice was left unrepaired. Postoperative recovery was uneventful, and the right thigh pain disappeared. It is important to consider the possibility of internal herniation beneath the obturator nerve after minimally invasive lateral lymph node dissection for rectal cancer.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21531,""
"Robot-assisted laparoscopic ureteral reconstruction for ureter endometriosis: Case series and literature review","Hung, Hsu, Jiang, Chao, Wang, Chen, Huang, Chen, Lin","https://doi.org/10.1097/JCMA.0000000000000249","20210830","PubMed","Adult; Endometriosis; Female; Humans; Laparoscopy; Middle Aged; Reconstructive Surgical Procedures; Retrospective Studies; Robotic Surgical Procedures; Ureter; Ureteral Obstruction","The aim of this report was to review experience from a single hospital in treating ureteral obstruction related to endometriosis with robot-assisted laparoscopic ureteral reconstruction. This retrospective analysis study (Canadian Task Force classification II-3) was conducted at an academic tertiary hospital. Five female patients with hydronephrosis without significant elevation of serum creatinine levels were enrolled. Ureteral endometriosis with obstruction was suspected on radiological images. Previous treatment with double-J stenting with or without medical treatment had failed in all of the patients. We performed robot-assisted laparoscopic segmental resection for ureteral endometriosis and reconstructed the ureter through ureteroureterostomy (RUU) or ureteroneocystostomy (RUC). The involved ureters included left lower ureter in three patients and right lower ureter in two patients. RUU was performed in four patients and RUC in one patient. All of the operations were completed smoothly without complications. All ureteral endometrioses were successfully resected, and follow-up sonography or intravenous pyelography showed resolution of hydronephrosis in all of the patients. Our experience proves the feasibility and efficacy of a robot-assisted approach for this rare situation with good outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21532,""
"Robotic-Assisted versus Manual Unicompartmental Knee Arthroplasty: Contemporary Systematic Review and Meta-analysis of Early Functional Outcomes","Gaudiani, Samuel, Kamath, Courtney, Lee","https://doi.org/10.1055/s-0040-1701455","20211014","PubMed","Arthroplasty, Replacement, Knee; Humans; Knee Joint; Osteoarthritis, Knee; Robotic Surgical Procedures; Treatment Outcome","Robotic-assisted unicompartmental knee arthroplasty (RA-UKA) aims to improve accuracy of component placement. Studies have shown improvement in radiographic positioning/alignment with RA-UKA but have not addressed clinical outcome measures (COMs). The purpose of this study was to determine if RA-UKA is associated with improved early revision rates and functional outcome scores (FOS) compared with manual UKA. A systematic review of all English language articles from 1999 to 2019 on RA-UKA using Medline, EMBASE, Scopus, and Web of Science databases identified 277 studies. Seven (three randomized controlled trials) met inclusion criteria. Revision rates/FOS were aggregated for RA-UKA and manual UKA; a forest plot was constructed utilizing inverse variance/Mantel-Haenszel fixed-effects meta-analysis. The seven articles included a total of 363 RA-UKA patients and 425 manual UKA patients. Mean age was 66Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°3.5 and 65Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°4.0 years, and mean body mass index (BMI) was 26.8Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°2.1 and 27.1Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°1.5Ã¢â‚¬â€°kg/m<sup>2</sup>, respectively. Mean follow-up was 25.5 months (4.5-48) and 29.1 months (4.5-48) for RA-UKA and manual UKA, respectively. At latest follow-up, RA-UKA patients showed a 26%Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°12 improvement in COMs versus 24%Ã¢â‚¬â€°Ã‚Â±Ã¢â‚¬â€°12 improvement for manual UKA patients (<i>p</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°0.6). The revision rate was 3% for both groups (<i>p</i>Ã¢â‚¬â€°=Ã¢â‚¬â€°0.8); however, a meta-analysis of RCTs showed no difference. Robotic and manual UKAs offer comparable improvements in pain, FOS, and revision rates. The effects of follow-up duration, ceiling effects of COMs, and surgeon experience remain unknown. Future studies comparing robotic versus manual UKAs with longer term follow-up may inform further benefits of each, with respect to component durability, alignment, and functional improvement.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21533,""
"Ultrasound Bone Segmentation: A Scoping Review of Techniques and Validation Practices","Pandey, Quader, Guy, Garbi, Hodgson","https://doi.org/10.1016/j.ultrasmedbio.2019.12.014","20210819","PubMed","Computer-assisted diagnosis; Computer-assisted surgery; Scoping review; Ultrasound bone segmentation; Bone and Bones; Deep Learning; Humans; Image Processing, Computer-Assisted; Ultrasonography","Ultrasound bone segmentation is an important yet challenging task for many clinical applications. Several works have emerged attempting to improve and automate bone segmentation, which has led to a variety of computational techniques, validation practices and applied clinical scenarios. We characterize this exciting and growing body of research by reviewing published ultrasound bone segmentation techniques. We review 56 articles in detail and categorize and discuss the image analysis techniques that have been used for bone segmentation. We highlight the general trends of this field in terms of clinical motivation, image analysis techniques, ultrasound modalities and the types of validation practices used to quantify segmentation performance. Finally, we present an outlook on promising areas of research based on the unaddressed needs for solving ultrasound bone segmentation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21534,""
"A Game Changer: 'The Use of Digital Technologies in the Management of Upper Limb Rehabilitation'","Ballantyne, Rea","https://doi.org/10.1007/978-3-030-31904-5_9","20200123","PubMed","Leap motion; Rehabilitation; Robotics; Technology; Upper limbs; Virtual reality; Biomedical Technology; Humans; Quality of Life; Recovery of Function; Robotics; Stroke; Stroke Rehabilitation; Upper Extremity; Virtual Reality","Hemiparesis is a symptom of residual weakness in half of the body, including the upper extremity, which affects the majority of post stroke survivors. Upper limb function is essential for daily life and reduction in movements can lead to tremendous decline in quality of life and independence. Current treatments, such as physiotherapy, aim to improve motor functions, however due to increasing NHS pressure, growing recognition on mental health, and close scrutiny on disease spending there is an urgent need for new approaches to be developed rapidly and sufficient resources devoted to stroke disease. Fortunately, a range of digital technologies has led to revived rehabilitation techniques in captivating and stimulating environments. To gain further insight, a meta-analysis literature search was carried out using the Preferred Reporting Items for Systematic Review and Meta-Analyses (PRISMA) method. Articles were categorized and pooled into the following groups; pro/anti/neutral for the use of digital technology. Additionally, most literature is rationalised by quantitative and qualitative findings. Findings displayed, the majority of the inclusive literature is supportive of the use of digital technologies in the rehabilitation of upper extremity following stroke. Overall, the review highlights a wide understanding and promise directed into introducing devices into a clinical setting. Analysis of all four categories; (1) Digital Technology, (2) Virtual Reality, (3) Robotics and (4) Leap Motion displayed varying qualities both-pro and negative across each device. Prevailing developments on use of these technologies highlights an evolutionary and revolutionary step into utilizing digital technologies for rehabilitation purposes due to the vast functional gains and engagement levels experienced by patients. The influx of more commercialised and accessible devices could alter stroke recovery further with initial recommendations for combination therapy utilizing conventional and digital resources.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21535,""
"An empirical assessment of baseline feature location techniques","Razzaq, Le Gear, Exton, Buckley","https://doi.org/10.1007/s10664-019-09734-5","20211101","PubMed","Concept location; Feature location; Information retrieval; Systematic literature review","Feature Location (FL) aims to locate observable functionalities in source code. Considering its key role in software maintenance, a vast array of automated and semi-automated Feature Location Techniques (FLTs) have been proposed. To compare FLTs, an open, standard set of non-subjective, reproducible ""compare-to"" FLT techniques (baseline techniques) should be used for evaluation. In order to relate the performance of FLTs compared against different baseline techniques, these compare-to techniques should be evaluated against each other. But evaluation across FLTs is confounded by empirical designs that incorporate different FL goals and evaluation criteria. This paper moves towards standardizing FLT comparability by assessing eight baseline techniques in an empirical design that addresses these confounding factors. These baseline techniques are assessed in twelve case studies to rank their performance. Results of the case studies suggest that different baseline techniques perform differently and that VSM-Lucene and LSI-Matlab performed better than other implementations. By presenting the relative performances of baseline techniques this paper facilitates empirical cross-comparison of existing and future FLTs. Finally, the results suggest that the performance of FLTs partially depends on system/benchmark characteristics, in addition to the FLTs themselves.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21536,""
"Highest ambulatory speed using Lokomat gait training for individuals with a motor-complete spinal cord injury: a clinical pilot study","van Silfhout, VÃƒÂ¡Ã…Ë†a, PÃ„â€¢tiokÃƒÂ½, Edwards, Bartels, van de Meent, Hosman","https://doi.org/10.1007/s00701-019-04189-5","20201016","PubMed","Ambulation; Exoskeleton; Lokomat; Spinal cord injury; Walking speed; Adult; Exercise Therapy; Exoskeleton Device; Female; Humans; Male; Middle Aged; Muscle Spasticity; Pilot Projects; Robotics; Spinal Cord Injuries; Walking Speed","Motor impairment and loss of ambulatory function are major consequences of a spinal cord injury (SCI). Exoskeletons are robotic devices that allow SCI patients with limited ambulatory function to walk. The mean walking speed of SCI patients using an exoskeleton is low: 0.26Ã‚Â m/s. Moreover, literature shows that a minimum speed of 0.59Ã‚Â m/s is required to replace wheelchairs in the community. To investigate the highest ambulatory speed for SCI patients in a Lokomat. This clinical pilot study took place in the Rehabilitation Center Kladruby, in Kladruby (Czech Republic). Six persons with motor-complete sub-acute SCI were recruited. Measurements were taken at baseline and directly after a 30Ã‚Â min Lokomat training. The highest achieved walking speed, vital parameters (respiratory frequency, heart rate, and blood pressure), visual analog scale for pain, and modified Ashworth scale for spasticity were recorded for each person. The highest reached walking speed in the Lokomat was on average 0.63Ã‚Â m/s (SD 0.03Ã‚Â m/s). No negative effects on the vital parameters, pain, or spasticity were observed. A significant decrease in pain after the Lokomat training was observed: 95% CI [0.336, 1.664] (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.012). This study shows that it is possible for motor-complete SCI individuals to ambulate faster on a Lokomat (on average 0.63Ã‚Â m/s) than what is currently possible with over-ground exoskeletons. No negative effects were observed while ambulating on a Lokomat. Further research investigating walking speed in exoskeletons after SCI is recommended.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21537,""
"Analysis of knowledge bases and research focuses of cerebral ischemia-reperfusion from the perspective of mapping knowledge domain","Qin, Zhang, Liu","https://doi.org/10.1016/j.brainresbull.2019.12.004","20210820","PubMed","Bibliometrics; Cerebral ischemia-reperfusion; CiteSpace; Mapping knowledge domain; VOSviewer; Visualization; Animals; Apoptosis; Bibliometrics; Blood-Brain Barrier; Brain; Brain Ischemia; Disease Models, Animal; Humans; Infarction, Middle Cerebral Artery; Knowledge Bases; Oxidative Stress; Reperfusion; Reperfusion Injury","Cerebral ischemia-reperfusion (IR) has attracted wide attention as a serious clinical problem. So far, the field has accumulated a large amount of scientific research literature. To clarify the temporal and spatial distribution characteristics of research resources, knowledge bases and research focuses, a visual analysis was performed on 5814 articles cited in the WoS databases from 2004 to 2019. This analysis was based on bibliometrics and mapping knowledge domain (MKD) analysis with VOSviewer, and CiteSpace 5.4.R4. The results can be elaborated from four aspects. First, the volume of publications in this area is on the rise. Second, the United States and China are the active regions. The USA is the central region of cerebral ischemia-reperfusion research. Third, the knowledge bases of IR have focused on five major areas of ""Suitable small-animal models"", ""A framework with further study"", ""Molecular signaling targets by oxidative stress"", ""Finding new potential targets for therapy"" and ""Protective effect of multiple transient ischemia"". Fourth, the research focuses consist of three representative areas: ""Oxidative stress closelyd with cerebral ischemia-reperfusion"", ""Neuronal apoptosis and neuronal protection"", and ""Neuroprotective effect of the blood-brain barrier"".","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21538,""
"Safe implementation of minimally invasive pancreas resection: a systematic review","Moekotte, Rawashdeh, Asbun, Coimbra, Edil, Jarufe, Jeyarajah, Kendrick, Pessaux, Zeh, Besselink, Abu Hilal, Hogg","https://doi.org/10.1016/j.hpb.2019.11.005","20211025","PubMed","Humans; Laparoscopy; Pancreatectomy; Pancreaticoduodenectomy; Robotic Surgical Procedures; Treatment Outcome","Minimally invasive pancreas resection (MIPR) has been expanding in the past decade. Excellent outcomes have been reported, however, safety concerns exist. The aim of this study was to define prerequisites for performing MIPR with the objective to guide safe implementation of MIPR into clinical practice. This systematic review was conducted as part of the 2019 Miami International Evidence-Based Guidelines on Minimally Invasive Pancreas Resection (IG-MIPR). PubMed, Embase and Cochrane databases were searched for literature concerning the implementation of MIPR between 1946 and November 2018. Quality assessment was according to The Scottish Intercollegiate Guidelines Network (SIGN). Overall, 1150 studies were screened, of which 32 studies with 8519 patients were included in this systematic review. Training programs for minimally invasive distal pancreatectomy, laparoscopic pancreatoduodenectomy and robotic pancreatoduodenectomy have been described with acceptable outcomes during the learning curve and improved outcomes after training. Learning curve studies have revealed an association between growing experience and improving perioperative outcomes. In addition, the association between higher center volume and lower mortality and morbidity has been reported by several studies. When embarking on MIPR, it is recommended to participate in a dedicated training program, to assure a sufficient volume, especially when implementing minimally invasive pancreatoduodenectomy, (20 procedures recommended annually), and prospectively collect and closely monitor outcomes for continuous quality assessment, this can be achieved through institutional databases and participation in national or international registries.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21539,""
"A systematic review and network meta-analysis of different surgical approaches for pancreaticoduodenectomy","Kamarajah, Bundred, Marc, Jiao, Hilal, Manas, White","https://doi.org/10.1016/j.hpb.2019.09.016","20210927","PubMed","Humans; Laparoscopy; Network Meta-Analysis; Pancreatic Neoplasms; Pancreaticoduodenectomy; Robotic Surgical Procedures","Minimally invasive pancreaticoduodenectomy (MIPD) is a demanding surgical procedure, thus explaining its slow expansion and limited popularity amongst Hepato-Pancreatico-Biliary (HPB) surgeons. However, three main advantages of robotic assisted pancreaticoduodenectomy (PD) including improved dexterity, 3D vision less surgical fatigue, may overcome some of the hurdles and ultimately lead to a wider adoption. This systematic review and network meta-analysis aims to evaluate the current literature on open and MIPD. A systematic literature search was conducted for studies reporting robotic, laparoscopic and open surgery for PD. Network meta-analysis of intraoperative (operating time, blood loss, transfusion rate), postoperative (overall and major complications, pancreatic fistula, delayed gastric emptying, length of hospital stay) and oncological outcomes (R0 resection, lymphadenectomy) were performed. Sixty-one studies including 62,529 patients were included in the network meta-analysis, of which 3% (nÃ‚Â =Ã‚Â 2131) were totally robotic (TR) and 10% (nÃ‚Â =Ã‚Â 6514) were totally laparoscopic (TL). There were no significant differences between surgical techniques for major complications, overall and grade B/C fistula, biliary leak, mortality and R0 resections. Transfusion rates were significantly lower in TR compared to TL and open. Operative time for TR was longer compared with open and TL. Both TL and TR were associated with significantly lower rates of wound infections, pulmonary complications, shorter length of stay and higher lymph nodes examined when compared to open. TR was associated with significantly lower conversion rates than TL. In summary, this network meta-analysis highlights the variability in techniques within MIPD and compares other variations to the conventional open PD. Current evidence appears to demonstrate MIPD, both laparoscopic and robotic techniques are associated with improved rates of surgical site infections, pulmonary complications, and a shorter hospital stay, with no compromise in oncological outcomes for cancer resections.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21540,""
"Person transfer assist systems: a literature review","Sivakanthan, Blaauw, Greenhalgh, Koontz, Vegter, Cooper","https://doi.org/10.1080/17483107.2019.1673833","20211005","PubMed","Patient lifting; assisted transfer aid and wheelchair transfer device; dependent transfer devices; patient transfers; robotic transfer device; self-help device; Caregivers; Equipment Design; Humans; Moving and Lifting Patients; Robotics; Self-Help Devices; Wheelchairs; Wounds and Injuries","Novel developments in the robotics field have produced systems that can support person wheelchair transfers, maximize safety and reduce caregiver burden. The purpose of this study was to identify and describe these systems, their usability (or satisfaction), the context for which they have been or can be used and how they have been evaluated to determine evidence for their effectiveness. Available research on Person Transfer Assist Systems (PTAS) was systematically gathered using similar standards to the PRISMA guidelines. The search terms were derived from common terms and via exploring similar review articles. Initial search terms displayed 1330 articles and by using the inclusion/exclusion criteria 96 articles were selected for abstract review. After full- text reviewing 48 articles were included. 29 articles concerned research in robotic transfer systems, 10 articles used both ceiling and floor-mounted lifts and 9 articles used only floor-mounted lifts as an intervention/control group. The results of this analysis identified a few usability evaluations for robotic transfer prototypes, especially ones comparing prototypes to existing marketed devices. Robotic device research is a recent development within assistive technology. Whilst usability evaluations provided evidence that a robotic device will provide better service to the user, the sample number of subjects used are minimal in comparison to any of the intervention/control group articles. Experimental studies between PTASs are required to support technological advancements. Caregiver injury risk has been the focus for most of the comparison articles; however, few articles focus on the implications to the person.IMPLICATIONS FOR REHABILITATIONCeiling mounted lifts are preferred over floor-based lifts due to lower injury rates.Many robotic transfer systems have been developed; however, there is a paucity of quantitative and qualitative studies.Based on the results of this review, rehabilitation settings are recommended to use ceiling over floor assist systems, and it is recommended to provide training on using devices to assist with patient transfers to lower the risk of injuries.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21541,""
"A comparison of open, laparoscopic and robotic total mesorectal excision: trial sequential analysis and network meta-analysis","Zheng, Zhang, Wang, Ge, Wei, Bi, Deng, Wang, Li, Wang","https://doi.org/10.1111/codi.14872","20210818","PubMed","analysis; network meta-analysis; randomized controlled trial; rectal cancer; total mesorectal excision; trial sequential; Humans; Laparoscopy; Network Meta-Analysis; Rectal Neoplasms; Robotic Surgical Procedures; Treatment Outcome","Total mesorectal excision (TME) for rectal cancer can be achieved by employing open (OpTME), laparoscopic (LaTME) and robotic (RoTME) approaches but which of these has the best outcome?Ã‚Â The aim of present study is to identify the most effective technique for rectal cancer by comparing all outcomes. Randomized controlled trials (RCTs) which compared at least two TME strategies were identified by literature search of electronic databases of articles published to June 2018. Network meta-analysis with trial sequential analysis was performed using a frequentist approach with random-effects meta-analysis. Data collection and analysis We conducted a systematic search of PubMed, EmBase, the Cochrane Library, CNKI, and Web of Science.Ã‚Â Titles and abstracts of the retrieved publications were independently and blindly assessed by two authors. Twenty-two RCTs with 4882 rectal cancer patients were included in this analysis. The trial sequential analysis demonstrated that the cumulative Z-curve crossed either the traditional boundary or the trial sequential monitoring boundaries, suggesting that OpTME resulted in a more complete TME specimen than LaTME (relative risk 1.05, 95% confidence interval 1.01-1.08). Network meta-analysis showed there was no significant difference in the other comparisons. Based on the P score of completeness of the TME specimen and circumferential resection margin positivity, the best technique was OpTME, followed by RoTME and then LaTME. However, this order was reversed when complications and mortality were considered. RoTME led to better lymph node harvest. Although OpTME may give better pathological specimens, minimally invasive techniques may have advantages when considering lymph node harvest, complications and mortality. More RCTs are needed to determine which technique actually gives the best chance of survival.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21542,""
"Sequential adaptive variables and subject selection for GEE methods","Chen, Wang, Chang","https://doi.org/10.1111/biom.13160","20210826","PubMed","active learning; adaptive sampling; generalized estimating equations; sequential estimation; stopping time; Algorithms; Antibodies, Neutralizing; Biometry; Computer Simulation; Data Interpretation, Statistical; Databases, Factual; Humans; Interferon beta-1b; Logistic Models; Machine Learning; Models, Statistical; Multiple Sclerosis, Relapsing-Remitting; Multivariate Analysis; Probability; Randomized Controlled Trials as Topic; Sample Size","Modeling correlated or highly stratified multiple-response data is a common data analysis task in many applications, such as those in large epidemiological studies or multisite cohort studies. The generalized estimating equations method is a popular statistical method used to analyze these kinds of data, because it can manage many types of unmeasured dependence among outcomes. Collecting large amounts of highly stratified or correlated response data is time-consuming; thus, the use of a more aggressive sampling strategy that can accelerate this process-such as the active-learning methods found in the machine-learning literature-will always be beneficial. In this study, we integrate adaptive sampling and variable selection features into a sequential procedure for modeling correlated response data. Besides reporting the statistical properties of the proposed procedure, we also use both synthesized and real data sets to demonstrate the usefulness of our method.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21543,""
"Novel single-layer continuous suture of pancreaticojejunostomy for robotic pancreaticoduodenectomy","Liu, Zhao, Gao, Zhao, Tan, Wang, Liu","https://doi.org/10.1002/jhbp.682","20211015","PubMed","Pancreatic fistula; Pancreaticoduodenectomy; Pancreaticojejunostomy; Robotic surgery; Anastomosis, Surgical; Humans; Pancreatic Fistula; Pancreaticoduodenectomy; Pancreaticojejunostomy; Postoperative Complications; Robotic Surgical Procedures; Sutures","The best technique for pancreatic anastomosis after pancreaticoduodenectomy (PD) remains controversial, and the procedure for robotic PD (RPD) has not been previously reported. This study aimed to evaluate the safety and feasibility of a novel technique of pancreaticojejunostomy (PJ) for RPD. The demographics and perioperative outcomes of a consecutive series of RPD patients who underwent single-layer continuous suture (SCS) for PJ between September 2018 and November 2018 were analyzed. Thirty patients were included in the study. Twenty patients had a soft pancreas, and 15 patients had a small main pancreatic duct (MPD) (&lt;3Ã‚Â mm). The mean operative time was 234.1Ã‚Â min, the mean duration of PJ was 14.9Ã‚Â min, and the median estimated blood loss was 100.0Ã‚Â ml. No patients required conversion to laparotomy. Postoperative pancreatic fistula (POPF) included seven cases of Grade A and two cases of Grade B. No case of Grade C POPF occurred. The mean postoperative hospital stay was 12.3Ã‚Â days. No 90-day readmission or mortality was observed. Neither pancreatic texture nor MPD size affected the perioperative outcomes. Single-layer continuous suture is easy to perform and is associated with favorable clinical outcomes, regardless of the pancreatic duct size and texture.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21544,""
"Classification of Microcalcification Clusters in Digital Mammograms Using a Stack Generalization Based Classifier","Alam, R E Denton, Zwiggelaar","https://doi.org/10.3390/jimaging5090076","20210903","PubMed","classification; digital mammogram; microcalcification; morphological features; stack generalization","This paper presents a machine learning based approach for the discrimination of malignant and benign microcalcification (MC) clusters in digital mammograms. A series of morphological operations was carried out to facilitate the feature extraction from segmented microcalcification. A combination of morphological, texture, and distribution features from individual MC components and MC clusters were extracted and a correlation-based feature selection technique was used. The clinical relevance of the selected features is discussed. The proposed method was evaluated using three different databases: Optimam Mammography Image Database (OMI-DB), Digital Database for Screening Mammography (DDSM), and Mammographic Image Analysis Society (MIAS) database. The best classification accuracy ( 95.00 Ã‚Â± 0.57 %) was achieved for OPTIMAM using a stack generalization classifier with 10-fold cross validation obtaining an A z value equal to 0.97 Ã‚Â± 0.01 .","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21545,""
"Management of Sickle Cell Intrahepatic Cholestasis: An Argument in Favor of Automated Exchange Transfusion","Adkins, Savani, Booth","https://doi.org/10.2991/chi.d.190630.001","20211002","PubMed","Apheresis; Exchange transfusion; Red blood cell exchange; Sickle cell disease; Sickle cell hepatopathy","Sickle cell disease patients are commonly treated at transfusion medicine services, and understanding of the hepatic manifestations of the disease is key for optimal management, specifically, in individuals presenting with sickle cell intrahepatic cholestasis <b>(SCIC)</b>. SCIC represents a rare, severe hepatic crisis wherein sinusoidal red cell sickling leads to massive hepatocyte dysfunction and cholestatic laboratory findings. Acute SCIC is defined by abdominal pain with progressive hepatic injury associated with hyperbilirubinemia, renal failure, encephalopathy, and coagulopathy. Patients are generally managed with red blood cell exchange transfusion (RBCEx), when available, as this is a potentially fatal condition. Simple transfusion may be utilized in resource-poor environment or when patients refuse RBCEx. As less than 50 adult cases have been described in the literature, many of them with limited follow-up, randomized clinical trials comparing RBCEx with other treatments are currently unfeasible. Likewise, a chronic form exists, but is less well characterized, and is associated with persistent bilirubinemia and a variable course in terms of progressive hepatic disease. We undertake a brief review of the literature and discuss two cases of SCIC managed with RBCEx at our institution.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21546,""
"Successful patient-oriented surgical outcomes in robotic vs laparoscopic right hemicolectomy for cancer - a systematic review","Waters, Cheung, Peacock, Heriot, Warrier, O'Riordain, Pillinger, Lynch, Stevenson","https://doi.org/10.1111/codi.14822","20210818","PubMed","laparoscopic right hemicolectomy; right hemicolectomy; robotic surgery; successful patient-oriented surgical outcomes; Colectomy; Female; Humans; Infant, Newborn; Laparoscopy; Length of Stay; Postoperative Complications; Quality of Life; Robotic Surgical Procedures; Treatment Outcome; Uterine Cervical Neoplasms","Minimally invasive surgical approaches for cancer of the right colon have been well described with significant patient and equivalent oncological benefits. Robotic surgery has advanced in its ability to provide multi-quadrant abdominal access, leading the surgical community to widen its application outside of the pelvis to other abdominal compartments. Globally it is being realized that a patient's surgical episode of care is becoming the epicentre of cancer treatment. In order to establish the role of robotic surgery in a patient's episode of care, 'successful patient-oriented surgical' parameters in right hemicolectomy for malignancy were measured. The objective was to examine the rates of successful patient-oriented surgical outcomes in robotic right hemicolectomy (RRH) compared to laparoscopic right hemicolectomy (LRH) for cancer. A systematic search of MEDLINE (Ovid: 1946-present), PubMed (NCBI), Embase (Ovid: 1966-present) and Cochrane Library was conducted using PRISMA for parameters of successful patient-oriented surgical outcomes in RRH and LRH for malignancy alone. The parameters measured included postoperative ileus, anastomotic complication, surgical wound infection, length of stay (LOS), incisional hernia rate, conversion to open, margin status, lymph node harvest and overall morbidity and mortality. There were 15 studies which included 831 RRH patients and 3241 LRH patients, with a median age of 62-74Ã‚Â years. No study analysed the concept of successful patient-oriented surgical outcomes. There was no significant difference in the incidence of postoperative ileus, with less time to first flatus in RRH (2.0-2.7Ã‚Â days, compared with 2.5-4.0Ã‚Â days, PÃ‚Â &lt;Ã‚Â 0.05). Anastomotic leak rate in one study reported a significant increase in LRH compared to RRH (PÃ‚Â &lt;Ã‚Â 0.05, 0% vs 8.3%). Significantly decreased LOS following RRH was outlined in six studies. One study reported a significantly higher rate of incisional hernias following LRH with extracorporeal anastomoses compared to RRH with intracorporeal anastomoses. Overall rates of conversion to open surgery were less with RRH (0%-3.9% vs 0%-18%, PÃ‚Â &lt;Ã‚Â 0.001, 0.05). One study outlined significantly higher rates of incomplete resection with an open right hemicolectomy compared with minimally invasive laparoscopic and robotic resections, with positive margin rates of 2.3%, 0.9% and 0% respectively (PÃ‚Â &lt;Ã‚Â 0.001). Two studies reported significantly higher lymph node harvest in RRH (PÃ‚Â &lt;Ã‚Â 0.05). Overall morbidity and 30-day mortality were comparable in both approaches. Thirty-day morbidity and mortality were comparable between the two approaches, with patients undergoing RRH having lower anastomotic complications, increased lymph node harvest, and reduced LOS, conversion to open and incisional hernia rates in a number of studies. There are limited data on surgical approach and impact on quality of life and what patients deem successful surgical outcomes. There is a further need for a randomized controlled trial examining successful patient-oriented outcomes in right hemicolectomy for malignancy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21547,""
"Implementing undergraduate quality improvement","Martin, Wylie, Dubras, McKee, Sethi","https://doi.org/10.1111/tct.13041","20210818","PubMed","Humans; Learning; London; Quality Improvement; Students","All clinicians need to have knowledge and expertise to undertake quality improvement (QI). In 2016, a London medical school initiated a core QI and evidence-based practice module for fourth-year students. We describe the structure and content of the module and analyse QI projects (QIPs) and student feedback. We collected data on QIPs, including number and location, adherence to QI methodology and level of improvement achieved. We also examined end-of-module feedback with free text analysis of the written comments. A total of 398 students completed 99 QIPs: 90% were based in secondary care and 10% were based in primary care. A total of 72 projects (72%) led to improvements in clinical care, with 14% achieving their stated aim. Adherence to methodology was high: 75% had a 'SMART (specific, measurable, achievable, realistic and timely)' aim; 96% implemented at least one plan-do-study-act (PDSA) cycle (range 1-4), and appropriate run charts for measures occurred in 80% of projects. QIPs were categorised based on their outcome: self-help and self-care, 12%; efficiency, 16%; prevention and early detection, 14%; drug safety, 11%; improvement to pathways and protocols, 44%; and improving patient experience 3%. The implementation challenges encountered were: suboptimal supervisor preparedness; student time limitations; and difficulties with the virtual learning platform. However, the experiences that QIPs offered in preparation for postgraduate training were appreciated by students. We have demonstrated that students are able to robustly apply QI methodologies, equipping them to act as agents for change, learning as they do, and meaningfully improving QI capacity and capability in local health systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21548,""
"Smartphone-based systems for physical rehabilitation applications: A systematic review","Moral-Munoz, Zhang, Cobo, Herrera-Viedma, Kaber","https://doi.org/10.1080/10400435.2019.1611676","20210902","PubMed","physical therapy; smartphone; tele-rehabilitation","Tele-(remote) rehabilitation is attracting increased attention from society, including the research community and commercial marketplace with an estimated global market value of $160 billion. Meanwhile, mobile device-based healthcare (""mHealth"") has appeared as a revolutionary approach to tele-rehabilitation practice. This paper presents a systematic review of the literature on smartphone-based systems designed for remote facilitation of physical rehabilitation. A total of 74 documents from Web of Science search results were reviewed. Systems were classified based on target medical conditions, and a taxonomy of technology was created along with identification of monitored activities. Beyond monitoring, some systems also provide patient-caregiver communication and progress management functions. The review identifies major research interests in stroke, cardiac disease, balance impairment and joint/limb rehabilitation; however, there is a lack of attention to other diseases. There are also few systems that have computerized existing clinical tests. On the basis of the review, design recommendations are formulated to encourage implementation of advanced functionalities, usability considerations, and system validation based on clinical evidence. Results of this study may help researchers and companies to design functions and interactions of smartphone-based rehabilitation systems or to select technology.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21549,""
"Associations between single nucleotide polymorphisms and erythrocyte parameters in humans: A systematic literature review","Timmer, Tanck, Huis In 't Veld, Veldhuisen, Daams, de Kort, van der Schoot, van den Hurk","https://doi.org/10.1016/j.mrrev.2019.01.002","20200302","PubMed","Genome-wide association study; Hematocrit; Hemoglobin; Red cell count; Red cell indices; Systematic review; Animals; Erythrocyte Indices; Erythrocytes; Genome-Wide Association Study; Hemoglobins; Humans; Polymorphism, Single Nucleotide","Individual variations in erythrocyte parameters are influenced by factors like sex, age, diet and season. Genetic variations have also been associated with erythrocyte parameters. The aim of this systematic review is to provide an overview of associations between single nucleotide polymorphisms (SNPs) and erythrocyte parameters in humans. A systematic review protocol was published at the international prospective register of systematic reviews (registration number CRD42016053052). Literature searches were conducted in Medline and Embase. Studies were included if: investigating a(n) causality/association/correlation; population-based; investigating a human population of Caucasian/mixed-ethnic descent; and written in English, Dutch or German. Study quality was assessed using the quality of genetic association studies tool. In total, 4385 studies were screened on title/abstract and 194 studies were screened on full text. Inclusion criteria were met by 13 candidate gene studies (nÃ¢â‚¬â€°=Ã¢â‚¬â€°126-49,488) and eight genome-wide association studies (GWASes, nÃ¢â‚¬â€°=Ã¢â‚¬â€°1664-116,666). One moderate and six good quality GWAS(es) identified 1237 SNPs located in/near 241 genes. SNPs in/near ten genes were found to be associated with one or more erythrocyte parameter(s) by multiple GWASes, namely HIST1H2AC, MPST, SLC17A1 and SLC17A3 with mean cell hemoglobin (MCH), HIST1H1T and KCTD17 with MCH and mean cell volume (MCV), HBS1L and MYB with MCH, MCV and red cell count (RCC), HFE with MCH, MCV and hemoglobin, and TMPRSS6 with MCH, MCV, hemoglobin and mean cell hemoglobin concentration (MCHC). Four genes were found across multiple erythrocyte parameters by one study in each parameter. Fourteen SNPs were associated with one or more erythrocyte parameter(s) in multiple cohorts, namely rs129128, rs17342717, rs228129 and rs5756504 (MCH), rs4895441, rs7775698, rs9376092 and rs9494145 (MCH, MCV, RCC), rs6569992 (MCH, RCC), rs1800562 (hemoglobin, MCH, MCV), rs130624 and rs198846 (MCH, MCV), rs4820268 and rs855791 (MCH, MCV, MCHC). Further research on these fourteen genes in erythropoiesis is recommended, especially eight whose role in erythropoiesis is unclear.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21550,""
"Integration of Microbiology, Pharmacology, Immunology, and Infectious Disease Using Active Teaching and Self-Directed Learning","Steinel, Palmer, Nowicki, Lee, Nelson, Whiteley, Lee","https://doi.org/10.1007/s40670-018-00689-8","20210831","PubMed","Active learning; Basic sciences; Co-teaching; Flipped classrooms; Integrated curriculum; Problem based learning; Self-Direceted learning; Self-regulated learning","In an era of decreasing basic science curriculum at medical schools, we sought to re-imagine how to optimally deliver three core basic science disciplines (microbiology, pharmacology, and immunology) together with infectious disease in a 5-week course. This course, developed as part of a new 1-year pre-clinical basic science curriculum at the recently established Dell Medical School (DMS) at the University of Texas at Austin, featured a fully integrated curriculum in which the majority of the sessions were team-taught. This course, in line with the goals and missions of DMS, presented material using primarily self-directed and active learning approaches. Here, we describe the format and content of the course. We present our strategy and rationale for selecting these particular learning modalities and topics for pre-class and in-class coverage, using educational and cognitive psychology literature as a guide. We also discuss how, based on feedback from both student evaluations and performance data, the course evolved over the first two iterations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21551,""
"Changes to an Active Learning Curriculum in Osteopathic Medical Education: Effects on Exam Outcomes and Board Scores","Zaveri, Coty, McCarver, Vidic, Nolan, Nath, Vanier","https://doi.org/10.1007/s40670-018-00674-1","20210831","PubMed","Active learning; Preclinical medical education; Problem-based learning","With the introduction of McMaster University's problem-based, self-directed learning and cognitive integration in the medical school curriculum, learning in small groups has been gaining popularity with medical schools worldwide. Problem-based learning (PBL) places emphasis on the value of basic medical sciences as the basis of learning medicine using clinical problems. For a successful outcome, a PBL curriculum needs to have a student-centered learning environment, problem-based design and facilitation, and assessment of learning in PBL domains. We describe a PBL program that has been used for undergraduate medical education, including changes made to learning resources and assessment. The changes required input from both faculty educators and students, and success depended on buy-in into the process. One of the changes included implementing the use of standard textbooks, which students use as the primary source of information during self-directed learning. Another change was the use of several reliable, valid, and cost-effective high-stakes written exams from internal and external sources, to promote spaced retrieval of biomedical facts and clinical contexts. By making these and other changes, we have been able to achieve pass rates and board scores which are consistently above the national average for 12Ã‚Â years. We conclude that in order to ensure sustainable successful outcomes, it is important to keep our program dynamic by making improvements in the PBL domains and assessment methods, taking into consideration students' course evaluations of the learning environment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21552,""
"A survey of word embeddings for clinical text","Khattak, Jeblee, Pou-Prom, Abdalla, Meaney, Rudzicz","https://doi.org/10.1016/j.yjbinx.2019.100057","20210813","PubMed","Clinical data; Natural language processing; Word embeddings","Representing words as numerical vectors based on the contexts in which they appear has become the de facto method of analyzing text with machine learning. In this paper, we provide a guide for training these representations on clinical text data, using a survey of relevant research. Specifically, we discuss different types of word representations, clinical text corpora, available pre-trained clinical word vector embeddings, intrinsic and extrinsic evaluation, applications, and limitations of these approaches. This work can be used as a blueprint for clinicians and healthcare workers who may want to incorporate clinical text features in their own models and applications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21553,""
"Comparing breast cancer treatments using automatically detected surrogate and clinically relevant outcomes entities from text","Blake, Kehm","https://doi.org/10.1016/j.yjbinx.2019.100005","20210813","PubMed","Breast cancer outcomes; Evidence-based medicine; Machine learning; Outcome extraction; Systematic reviews; Text mining","Population, intervention, comparison and outcome (PICO) facets of clinical studies are required both for physicians in a clinical setting and for reviewers as they compare the effectiveness of different treatment strategies. Automated methods developed for the first three of these facets identify entities, but outcome detection has been limited to identifying the entire sentence. We frame outcome detection as a noun phrase prediction task and use semi-supervised learning to detect new outcomes (aka endpoints) from the method section of 88Ã¢â‚¬Â¯K MEDLINE abstracts. A manual analysis showed that 96.7% of all outcomes can be captured using a noun phrase representation. With respect to the machine learning classifiers, the Support Vector Machine produced higher precision, F1-score, and accuracy than the General Linear Model when evaluated with respect to the initial gold standard of survivorship seed terms and a manual gold standard that considered all outcomes. However, the best model does not employ machine learning, but rather leverages list structure and resulted in 90.14 precision, 60.69 recall, 75.41 F1-score, and 92.60 accuracy with respect to the manual gold standard of all outcomes. Finally we developed a silver standard with a precision of 89.28 and recall of 86.77 compared to the manual gold standard and used the silver standard to identify all outcomes reported for five breast cancer treatments. The increased precision afforded by this approach reveals that in contrast to chemotherapy and targeted therapy, the surrogate outcome disease free survival (DFS) is reported more frequently than the clinically relevant outcome overall survival (OS) for hormone therapies, which is consistent with findings that DFS translates into firm OS improvements in a hormone therapy setting.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21554,""
"Measuring semantic similarity of clinical trial outcomes using deep pre-trained language representations","Koroleva, Kamath, Paroubek","https://doi.org/10.1016/j.yjbinx.2019.100058","20210813","PubMed","Deep learning; Natural Language Processing; Pre-trained language representations; Semantic similarity; Spin detection; Trial outcomes","Outcomes are variables monitored during a clinical trial to assess the impact of an intervention on humans' health.Automatic assessment of semantic similarity of trial outcomes is required for a number of tasks, such as detection of outcome switching (unjustified changes of pre-defined outcomes of a trial) and implementation of Core Outcome Sets (minimal sets of outcomes that should be reported in a particular medical domain). We aimed at building an algorithm for assessing semantic similarity of pairs of primary and reported outcomes.We focused on approaches that do not require manually curated domain-specific resources such as ontologies and thesauri. We tested several approaches, including single measures of similarity (based on strings, stems and lemmas, paths and distances in an ontology, and vector representations of phrases), classifiers using a combination of single measures as features, and a deep learning approach that consists in fine-tuning pre-trained deep language representations.We tested language models provided by BERT (trained on general-domain texts), BioBERT and SciBERT (trained on biomedical and scientific texts, respectively).We explored the possibility of improving the results by taking into account the variants for referring to an outcome (e.g.the use of a measurement tool name instead on the outcome name; the use of abbreviations).We release an open corpus with annotation for similarity of pairs of outcomes. Classifiers using a combination of single measures as features outperformed the single measures, while deep learning algorithms using BioBERT and SciBERT models outperformed the classifiers.BioBERT reached the best F-measure of 89.75%.The addition of variants of outcomes did not improve the results for the best-performing single measures nor for the classifiers, but it improved the performance of deep learning algorithms: BioBERT achieved an F-measure of93.38%. Deep learning approaches using pre-trained language representations outperformed other approaches for similarity assessment of trial outcomes, without relying on any manually curated domain-specific resources (ontologies and other lexical resources). Addition of variants of outcomes further improved the performance of deep learning algorithms.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21555,""
"PMCVec: Distributed phrase representation for biomedical text processing","Gero, Ho","https://doi.org/10.1016/j.yjbinx.2019.100047","20210813","PubMed","Biomedical NLP; Phrase embeddings; PubMed abstracts","Distributed semantic representation of biomedical text can be beneficial for text classification, named entity recognition, query expansion, human comprehension, and information retrieval. Despite the success of high-quality vector space models such as Word2Vec and GloVe, they only provide unigram word representations and the semantics for multi-word phrases can only be approximated by composition. This is problematic in biomedical text processing where technical phrases for diseases, symptoms, and drugs should be represented as single entities to capture the correct meaning. In this paper, we introduce PMCVec, an unsupervised technique that generates important phrases from PubMed abstracts and learns embeddings for single words and multi-word phrases simultaneously. Evaluations performed on benchmark datasets produce significant performance gains both qualitatively and quantitatively.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21556,""
"High Throughput Phenotyping for Dimensional Psychopathology in Electronic Health Records","McCoy, Yu, Hart, Castro, Brown, Rosenquist, Doyle, Vuijk, Cai, Perlis","https://doi.org/10.1016/j.biopsych.2018.01.011","20190905","PubMed","Computed phenotype; Electronic health record; Natural language processing; Research Domain Criteria; Topic modeling; Transdiagnostic; Adult; Cohort Studies; Electronic Health Records; Female; Hospitalization; Humans; Male; Mental Disorders; Middle Aged; Natural Language Processing; Neuropsychological Tests; Phenotype; Psychiatric Status Rating Scales; Psychopathology","Relying on diagnostic categories of neuropsychiatric illness obscures the complexity of these disorders. Capturing multiple dimensional measures of neuropathology could facilitate the clinical and neurobiological investigation of cognitive and behavioral phenotypes. We developed a natural language processing-based approach to extract five symptom dimensions, based on the National Institute of Mental Health Research Domain Criteria definitions, from narrative clinical notes. Estimates of Research Domain Criteria loading were derived from a cohort of 3619 individuals with 4623 hospital admissions. We applied this tool to a large corpus of psychiatric inpatient admission and discharge notes (2010-2015), and using the same cohort we examined face validity, predictive validity, and convergent validity with gold standard annotations. In mixed-effect models adjusted for sociodemographic and clinical features, greater negative and positive symptom domains were associated with a shorter length of stay (ÃŽÂ²Ã‚Â =Ã‚Â -.88, pÃ‚Â = .001 and ÃŽÂ²Ã‚Â =Ã‚Â -1.22, p &lt; .001, respectively), while greater social and arousal domain scores were associated with a longer length of stay (ÃŽÂ²Ã‚Â = .93, p &lt; .001 and ÃŽÂ²Ã‚Â = .81, pÃ‚Â = .007, respectively). In fully adjusted Cox regression models, a greater positive domain score at discharge was also associated with a significant increase in readmission risk (hazard ratioÃ‚Â = 1.22, pÃ‚Â &lt;Ã‚Â .001). Positive and negative valence domains were correlated with expert annotation (by analysis of variance [dfÃ‚Â = 3], R<sup>2</sup>Ã‚Â = .13 and .19, respectively). Likewise, in a subset of patients, neurocognitive testing was correlated with cognitive performance scores (p &lt; .008 for three of six measures). This shows that natural language processing can be used to efficiently and transparently score clinical notes in terms of cognitive and psychopathologic domains.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21557,""
"Evaluation of a Broad-Spectrum Partially Automated Adverse Event Surveillance System: A Potential Tool for Patient Safety Improvement in Hospitals With Limited Resources","Saikali, Tanios, Saab","https://doi.org/10.1097/PTS.0000000000000442","20210921","PubMed","","The aim of the study was to evaluate the sensitivity and resource efficiency of a partially automated adverse event (AE) surveillance system for routine patient safety efforts in hospitals with limited resources. Twenty-eight automated triggers from the hospital information system's clinical and administrative databases identified cases that were then filtered by exclusion criteria per trigger and then reviewed by an interdisciplinary team. The system, developed and implemented using in-house resources, was applied for 45 days of surveillance, for all hospital inpatient admissions (N = 1107). Each trigger was evaluated for its positive predictive value (PPV). Furthermore, the sensitivity of the surveillance system (overall and by AE category) was estimated relative to incidence ranges in the literature. The surveillance system identified a total of 123 AEs among 283 reviewed medical records, yielding an overall PPV of 52%. The tool showed variable levels of sensitivity across and within AE categories when compared with the literature, with a relatively low overall sensitivity estimated between 21% and 44%. Adverse events were detected in 23 of the 36 AE categories defined by an established harm classification system. Furthermore, none of the detected AEs were voluntarily reported. The surveillance system showed variable sensitivity levels across a broad range of AE categories with an acceptable PPV, overcoming certain limitations associated with other harm detection methods. The number of cases captured was substantial, and none had been previously detected or voluntarily reported. For hospitals with limited resources, this methodology provides valuable safety information from which interventions for quality improvement can be formulated.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21558,""
"Interventions to prevent occupational noise-induced hearing loss","Tikka, Verbeek, Kateman, Morata, Dreschler, Ferrite","https://doi.org/10.1002/14651858.CD006396.pub4","20170912","PubMed","Audiometry; Coal Mining; Controlled Before-After Studies; Ear Protective Devices; Engineering; Health Education; Hearing Loss, Noise-Induced; Humans; Noise, Occupational; Occupational Diseases; Program Evaluation; Randomized Controlled Trials as Topic","This is the second update of a Cochrane Review originally published in 2009. Millions of workers worldwide are exposed to noise levels that increase their risk of hearing disorders. There is uncertainty about the effectiveness of hearing loss prevention interventions. To assess the effectiveness of non-pharmaceutical interventions for preventing occupational noise exposure or occupational hearing loss compared to no intervention or alternative interventions. We searched the CENTRAL; PubMed; Embase; CINAHL; Web of Science; BIOSIS Previews; Cambridge Scientific Abstracts; and OSH UPDATE to 3 October 2016. We included randomised controlled trials (RCT), controlled before-after studies (CBA) and interrupted time-series (ITS) of non-clinical interventions under field conditions among workers to prevent or reduce noise exposure and hearing loss. We also collected uncontrolled case studies of engineering controls about the effect on noise exposure. Two authors independently assessed study eligibility and risk of bias and extracted data. We categorised interventions as engineering controls, administrative controls, personal hearing protection devices, and hearing surveillance. We included 29 studies. One study evaluated legislation to reduce noise exposure in a 12-year time-series analysis but there were no controlled studies on engineering controls for noise exposure. Eleven studies with 3725 participants evaluated effects of personal hearing protection devices and 17 studies with 84,028 participants evaluated effects of hearing loss prevention programmes (HLPPs). Effects on noise exposure Engineering interventions following legislationOne ITS study found that new legislation in the mining industry reduced the median personal noise exposure dose in underground coal mining by 27.7 percentage points (95% confidence interval (CI) -36.1 to -19.3 percentage points) immediately after the implementation of stricter legislation. This roughly translates to a 4.5 dB(A) decrease in noise level. The intervention was associated with a favourable but statistically non-significant downward trend in time of the noise dose of -2.1 percentage points per year (95% CI -4.9 to 0.7, 4 year follow-up, very low-quality evidence). Engineering intervention case studiesWe found 12 studies that described 107 uncontrolled case studies of immediate reductions in noise levels of machinery ranging from 11.1 to 19.7 dB(A) as a result of purchasing new equipment, segregating noise sources or installing panels or curtains around sources. However, the studies lacked long-term follow-up and dose measurements of workers, and we did not use these studies for our conclusions. Hearing protection devicesIn general hearing protection devices reduced noise exposure on average by about 20 dB(A) in one RCT and three CBAs (57 participants, low-quality evidence). Two RCTs showed that, with instructions for insertion, the attenuation of noise by earplugs was 8.59 dB better (95% CI 6.92 dB to 10.25 dB) compared to no instruction (2 RCTs, 140 participants, moderate-quality evidence). Administrative controls: information and noise exposure feedbackOn-site training sessions did not have an effect on personal noise-exposure levels compared to information only in one cluster-RCT after four months' follow-up (mean difference (MD) 0.14 dB; 95% CI -2.66 to 2.38). Another arm of the same study found that personal noise exposure information had no effect on noise levels (MD 0.30 dB(A), 95% CI -2.31 to 2.91) compared to no such information (176 participants, low-quality evidence). Effects on hearing loss Hearing protection devicesIn two studies the authors compared the effect of different devices on temporary threshold shifts at short-term follow-up but reported insufficient data for analysis. In two CBA studies the authors found no difference in hearing loss from noise exposure above 89 dB(A) between muffs and earplugs at long-term follow-up (OR 0.8, 95% CI 0.63 to 1.03 ), very low-quality evidence). Authors of another CBA study found that wearing hearing protection more often resulted in less hearing loss at very long-term follow-up (very low-quality evidence). Combination of interventions: hearing loss prevention programmesOne cluster-RCT found no difference in hearing loss at three- or 16-year follow-up between an intensive HLPP for agricultural students and audiometry only. One CBA study found no reduction of the rate of hearing loss (MD -0.82 dB per year (95% CI -1.86 to 0.22) for a HLPP that provided regular personal noise exposure information compared to a programme without this information.There was very-low-quality evidence in four very long-term studies, that better use of hearing protection devices as part of a HLPP decreased the risk of hearing loss compared to less well used hearing protection in HLPPs (OR 0.40, 95% CI 0.23 to 0.69). Other aspects of the HLPP such as training and education of workers or engineering controls did not show a similar effect.In three long-term CBA studies, workers in a HLPP had a statistically non-significant 1.8 dB (95% CI -0.6 to 4.2) greater hearing loss at 4 kHz than non-exposed workers and the confidence interval includes the 4.2 dB which is the level of hearing loss resulting from 5 years of exposure to 85 dB(A). In addition, of three other CBA studies that could not be included in the meta-analysis, two showed an increased risk of hearing loss in spite of the protection of a HLPP compared to non-exposed workers and one CBA did not. There is very low-quality evidence that implementation of stricter legislation can reduce noise levels in workplaces. Controlled studies of other engineering control interventions in the field have not been conducted. There is moderate-quality evidence that training of proper insertion of earplugs significantly reduces noise exposure at short-term follow-up but long-term follow-up is still needed.There is very low-quality evidence that the better use of hearing protection devices as part of HLPPs reduces the risk of hearing loss, whereas for other programme components of HLPPs we did not find such an effect. The absence of conclusive evidence should not be interpreted as evidence of lack of effectiveness. Rather, it means that further research is very likely to have an important impact.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21559,""
"Noradrenergic dysregulation in the pathophysiology of PTSD","Hendrickson, Raskind","https://doi.org/10.1016/j.expneurol.2016.05.014","20170504","PubMed","Noradrenergic; Posttraumatic stress disorder (PTSD); Prazosin; Adrenergic Neurons; Amygdala; Animals; Disease Models, Animal; Humans; Norepinephrine; Prefrontal Cortex; Stress Disorders, Post-Traumatic","A central role for noradrenergic dysregulation in the pathophysiology of post-traumatic stress disorder (PTSD) is increasingly suggested by both clinical and basic neuroscience research. Here, we integrate recent findings from clinical and animal research with the earlier literature. We first review the evidence for net upregulation of the noradrenergic system and its responsivity to stress in individuals with PTSD. Next, we trace the evidence that the ÃŽÂ±<sub>1</sub> noradrenergic receptor antagonist prazosin decreases many of the symptoms of PTSD from initial clinical observations, to case series, to randomized controlled trials. Finally, we review the basic science work that has begun to explain the mechanism for this efficacy, as well as to explore its possible limitations and areas for further advancement. We suggest a view of the noradrenergic system as a central, modifiable link in a network of interconnected stress-response systems, which also includes the amygdala and its modulation by medial prefrontal cortex. Particular attention is paid to the evidence for bidirectional signaling between noradrenaline and corticotropin-releasing factor (CRF) in coordinating these interconnected systems. The multiple different ways in which the sensitivity and reactivity of the noradrenergic system may be altered in PTSD are highlighted, as is the evidence for possible heterogeneity in the pathophysiology of PTSD between different individuals who appear clinically similar. We conclude by noting the importance moving forward of improved measures of noradrenergic functioning in clinical populations, which will allow better recognition of clinical heterogeneity and further assessment of the functional implications of different aspects of noradrenergic dysregulation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21560,""
"Operative Versus Nonoperative Treatment of Jones Fractures: A Decision Analysis Model","Bishop, Braun, Hunt","https://www.google.com/search?q=Operative+Versus+Nonoperative+Treatment+of+Jones+Fractures:+A+Decision+Analysis+Model.","20160829","PubMed","Adult; Aged; Decision Support Techniques; Female; Foot Injuries; Fractures, Bone; Humans; Male; Metatarsal Bones; Middle Aged; Young Adult","Optimal management of metadiaphyseal fifth metatarsal fractures (Jones fractures) remains controversial. Decision analysis can optimize clinical decision-making based on available evidence and patient preferences. We conducted a study to establish the determinants of decision-making and to determine the optimal treatment strategy for Jones fractures using a decision analysis model. Probabilities for potential outcomes of operative and nonoperative treatment of Jones fractures were determined from a review of the literature. Patient preferences for outcomes were obtained by questionnaire completed by 32 healthy adults with no history of foot fracture. Derived values were used in the model as a measure of utility. A decision tree was constructed, and fold-back and sensitivity analyses were performed to determine optimal treatment. Nonoperative treatment was associated with a value of 7.74, and operative treatment with an intramedullary screw was associated with a value of 7.88 given the outcome probabilities and utilities studied, making operative treatment the optimal strategy. When parameters were varied, nonoperative treatment was favored when the likelihood of healing with nonoperative treatment rose above 82% and when the probability of healing after surgery fell below 92%. In this decision analysis model, operative fixation is the preferred management strategy for Jones fractures. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21561,""
"Network-Based Identification and Prioritization of Key Regulators of Coronary Artery Disease Loci","Zhao, Chen, Freudenberg, Meng, Rajpal, Yang","https://doi.org/10.1161/ATVBAHA.115.306725","20170619","PubMed","coronary artery disease; gene expression; gene regulatory networks; genome-wide association study; genomics; Animals; Bayes Theorem; Case-Control Studies; Computational Biology; Computer Simulation; Coronary Artery Disease; Databases, Genetic; Gene Expression Profiling; Gene Expression Regulation; Gene Regulatory Networks; Genetic Loci; Genetic Predisposition to Disease; Genome-Wide Association Study; Genomics; Humans; Lumican; Mice; Neural Networks, Computer; Phenotype; Protein Interaction Maps; STAT3 Transcription Factor; Signal Transduction","Recent genome-wide association studies of coronary artery disease (CAD) have revealed 58 genome-wide significant and 148 suggestive genetic loci. However, the molecular mechanisms through which they contribute to CAD and the clinical implications of these findings remain largely unknown. We aim to retrieve gene subnetworks of the 206 CAD loci and identify and prioritize candidate regulators to better understand the biological mechanisms underlying the genetic associations. We devised a new integrative genomics approach that incorporated (1) candidate genes from the top CAD loci, (2) the complete genetic association results from the 1000 genomes-based CAD genome-wide association studies from the Coronary Artery Disease Genome Wide Replication and Meta-Analysis Plus the Coronary Artery Disease consortium, (3) tissue-specific gene regulatory networks that depict the potential relationship and interactions between genes, and (4) tissue-specific gene expression patterns between CAD patients and controls. The networks and top-ranked regulators according to these data-driven criteria were further queried against literature, experimental evidence, and drug information to evaluate their disease relevance and potential as drug targets. Our analysis uncovered several potential novel regulators of CAD such as LUM and STAT3, which possess properties suitable as drug targets. We also revealed molecular relations and potential mechanisms through which the top CAD loci operate. Furthermore, we found that multiple CAD-relevant biological processes such as extracellular matrix, inflammatory and immune pathways, complement and coagulation cascades, and lipid metabolism interact in the CAD networks. Our data-driven integrative genomics framework unraveled tissue-specific relations among the candidate genes of the CAD genome-wide association studies loci and prioritized novel network regulatory genes orchestrating biological processes relevant to CAD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21562,""
"Performance evaluation of endoscopic Cerenkov luminescence imaging system: in vitro and pseudotumor studies","Cao, Chen, Kang, Lin, Liu, Hu, Nie, Wu, Wang, Liang, Tian","https://doi.org/10.1364/BOE.5.003660","20141031","PubMed","(170.3660) Light propagation in tissues; (170.6935) Tissue characterization; (170.7050) Turbid media","By integrating the clinically used endoscope with the emerging Cerenkov luminescence imaging (CLI) technology, a new endoscopic Cerenkov luminescence imaging (ECLI) system was developed. The aim is to demonstrate the potential of translating CLI to clinical studies of gastrointestinal (GI) tract diseases. We systematically evaluated the feasibility and performance of the developed ECLI system with a series of in vitro and pseudotumor experiments. The ECLI system is comprised of an electron multiplying charge coupled device (EMCCD) camera coupled with a clinically used endoscope via an optical adapter. A 1951-USAF test board was used to measure the white-light lateral resolution, while a homemade test chart filled with (68)Ga was employed to measure the CL lateral resolution. Both in vitro and pseudotumor experiments were conducted to obtain the sensitivity of the ECLI system. The results were validated with that of CLI using EMCCD only, and the relative attenuation ratio of the ECLI system was calculated. Results showed that The white-light lateral resolution of the ECLI system was 198 Ã‚Âµm, and the luminescent lateral resolution was better than 1 mm. Sensitivity experiments showed a theoretical sensitivity of [Formula: see text] ([Formula: see text]) and [Formula: see text] ([Formula: see text]) for the in vitro and pseudotumor studies, respectively. The relative attenuation ratio of ECLI to CLI was about 96%. The luminescent lateral resolution of the ECLI system was comparable with that of positron emission tomography (PET). The pseudotumor study illustrated the feasibility and applicability of the ECLI system in living organisms, indicating the potential for translating the CLI technology to the clinic. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21563,""
"Integrative data mining highlights candidate genes for monogenic myopathies","Abath Neto, Tassy, Biancalana, Zanoteli, PourquiÃƒÂ©, Laporte","https://doi.org/10.1371/journal.pone.0110888","20150629","PubMed","Data Mining; Gene Ontology; Gene Regulatory Networks; Genetic Association Studies; Genetic Predisposition to Disease; Humans; Muscular Diseases; Phenotype","Inherited myopathies are a heterogeneous group of disabling disorders with still barely understood pathological mechanisms. Around 40% of afflicted patients remain without a molecular diagnosis after exclusion of known genes. The advent of high-throughput sequencing has opened avenues to the discovery of new implicated genes, but a working list of prioritized candidate genes is necessary to deal with the complexity of analyzing large-scale sequencing data. Here we used an integrative data mining strategy to analyze the genetic network linked to myopathies, derive specific signatures for inherited myopathy and related disorders, and identify and rank candidate genes for these groups. Training sets of genes were selected after literature review and used in Manteia, a public web-based data mining system, to extract disease group signatures in the form of enriched descriptor terms, which include functional annotation, human and mouse phenotypes, as well as biological pathways and protein interactions. These specific signatures were then used as an input to mine and rank candidate genes, followed by filtration against skeletal muscle expression and association with known diseases. Signatures and identified candidate genes highlight both potential common pathological mechanisms and allelic disease groups. Recent discoveries of gene associations to diseases, like B3GALNT2, GMPPB and B3GNT1 to congenital muscular dystrophies, were prioritized in the ranked lists, suggesting a posteriori validation of our approach and predictions. We show an example of how the ranked lists can be used to help analyze high-throughput sequencing data to identify candidate genes, and highlight the best candidate genes matching genomic regions linked to myopathies without known causative genes. This strategy can be automatized to generate fresh candidate gene lists, which help cope with database annotation updates as new knowledge is incorporated. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21564,""
"Automatic identification of methotrexate-induced liver toxicity in patients with rheumatoid arthritis from the electronic medical record","Lin, Karlson, Dligach, Ramirez, Miller, Mo, Braggs, Cagan, Gainer, Denny, Savova","https://doi.org/10.1136/amiajnl-2014-002642","20160222","PubMed","electronic medical record; liver toxicity; methotrexate; natural language processing; pharmacogenetic; rheumatoid arthritis; Algorithms; Arthritis, Rheumatoid; Chemical and Drug Induced Liver Injury; Electronic Health Records; Humans; Immunosuppressive Agents; Liver; Methotrexate","To improve the accuracy of mining structured and unstructured components of the electronic medical record (EMR) by adding temporal features to automatically identify patients with rheumatoid arthritis (RA) with methotrexate-induced liver transaminase abnormalities. Codified information and a string-matching algorithm were applied to a RA cohort of 5903 patients from Partners HealthCare to select 1130 patients with potential liver toxicity. Supervised machine learning was applied as our key method. For features, Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) was used to extract standard vocabulary from relevant sections of the unstructured clinical narrative. Temporal features were further extracted to assess the temporal relevance of event mentions with regard to the date of transaminase abnormality. All features were encapsulated in a 3-month-long episode for classification. Results were summarized at patient level in a training set (N=480 patients) and evaluated against a test set (N=120 patients). The system achieved positive predictive value (PPV) 0.756, sensitivity 0.919, F1 score 0.829 on the test set, which was significantly better than the best baseline system (PPV 0.590, sensitivity 0.703, F1 score 0.642). Our innovations, which included framing the phenotype problem as an episode-level classification task, and adding temporal information, all proved highly effective. Automated methotrexate-induced liver toxicity phenotype discovery for patients with RA based on structured and unstructured information in the EMR shows accurate results. Our work demonstrates that adding temporal features significantly improved classification results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21565,""
"Robotic surgery for rectal cancer: current immediate clinical and oncological outcomes","Araujo, Seid, Klajner","https://doi.org/10.3748/wjg.v20.i39.14359","20150624","PubMed","Colorectal surgery; Minimally invasive; Rectal neoplasms; Robotics; Surgical procedures; Blood Loss, Surgical; Digestive System Surgical Procedures; Humans; Laparoscopy; Length of Stay; Operative Time; Postoperative Complications; Rectal Neoplasms; Risk Factors; Robotic Surgical Procedures; Robotics; Time Factors; Treatment Outcome","Laparoscopic rectal surgery continues to be a challenging operation associated to a steep learning curve. Robotic surgical systems have dramatically changed minimally invasive surgery. Three-dimensional, magnified and stable view, articulated instruments, and reduction of physiologic tremors leading to superior dexterity and ergonomics. Therefore, robotic platforms could potentially address limitations of laparoscopic rectal surgery. It was aimed at reviewing current literature on short-term clinical and oncological (pathological) outcomes after robotic rectal cancer surgery in comparison with laparoscopic surgery. A systematic review was performed for the period 2002 to 2014. A total of 1776 patients with rectal cancer underwent minimally invasive robotic treatment in 32 studies. After robotic and laparoscopic approach to oncologic rectal surgery, respectively, mean operating time varied from 192-385 min, and from 158-297 min; mean estimated blood loss was between 33 and 283 mL, and between 127 and 300 mL; mean length of stay varied from 4-10 d; and from 6-15 d. Conversion after robotic rectal surgery varied from 0% to 9.4%, and from 0 to 22% after laparoscopy. There was no difference between robotic (0%-41.3%) and laparoscopic (5.5%-29.3%) surgery regarding morbidity and anastomotic complications (respectively, 0%-13.5%, and 0%-11.1%). Regarding immediate oncologic outcomes, respectively among robotic and laparoscopic cases, positive circumferential margins varied from 0% to 7.5%, and from 0% to 8.8%; the mean number of retrieved lymph nodes was between 10 and 20, and between 11 and 21; and the mean distal resection margin was from 0.8 to 4.7 cm, and from 1.9 to 4.5 cm. Robotic rectal cancer surgery is being undertaken by experienced surgeons. However, the quality of the assembled evidence does not support definite conclusions about most studies variables. Robotic rectal cancer surgery is associated to increased costs and operating time. It also seems to be associated to reduced conversion rates. Other short-term outcomes are comparable to conventional laparoscopy techniques, if not better. Ultimately, pathological data evaluation suggests that oncologic safety may be preserved after robotic total mesorectal excision. However, further studies are required to evaluate oncologic safety and functional results. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21566,""
"Functional evaluation of out-of-the-box text-mining tools for data-mining tasks","Jung, LePendu, Iyer, Bauer-Mehren, Percha, Shah","https://doi.org/10.1136/amiajnl-2014-002902","20150518","PubMed","electronic health records; natural language processing; text mining; Artificial Intelligence; Data Mining; Databases as Topic; Drug Interactions; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Humans; Natural Language Processing; Obesity","The trade-off between the speed and simplicity of dictionary-based term recognition and the richer linguistic information provided by more advanced natural language processing (NLP) is an area of active discussion in clinical informatics. In this paper, we quantify this trade-off among text processing systems that make different trade-offs between speed and linguistic understanding. We tested both types of systems in three clinical research tasks: phase IV safety profiling of a drug, learning adverse drug-drug interactions, and learning used-to-treat relationships between drugs and indications. We first benchmarked the accuracy of the NCBO Annotator and REVEAL in a manually annotated, publically available dataset from the 2008 i2b2 Obesity Challenge. We then applied the NCBO Annotator and REVEAL to 9 million clinical notes from the Stanford Translational Research Integrated Database Environment (STRIDE) and used the resulting data for three research tasks. There is no significant difference between using the NCBO Annotator and REVEAL in the results of the three research tasks when using large datasets. In one subtask, REVEAL achieved higher sensitivity with smaller datasets. For a variety of tasks, employing simple term recognition methods instead of advanced NLP methods results in little or no impact on accuracy when using large datasets. Simpler dictionary-based methods have the advantage of scaling well to very large datasets. Promoting the use of simple, dictionary-based methods for population level analyses can advance adoption of NLP in practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21567,""
"Assessing the role of a medication-indication resource in the treatment relation extraction from clinical text","Bejan, Wei, Denny","https://doi.org/10.1136/amiajnl-2014-002954","20160222","PubMed","MEDI; SemRep; natural language processing; treatment relation extraction; Algorithms; Humans; Information Storage and Retrieval; Knowledge Bases; Pharmaceutical Preparations; RxNorm; Semantics; Unified Medical Language System","To evaluate the contribution of the MEDication Indication (MEDI) resource and SemRep for identifying treatment relations in clinical text. We first processed clinical documents with SemRep to extract the Unified Medical Language System (UMLS) concepts and the treatment relations between them. Then, we incorporated MEDI into a simple algorithm that identifies treatment relations between two concepts if they match a medication-indication pair in this resource. For a better coverage, we expanded MEDI using ontology relationships from RxNorm and UMLS Metathesaurus. We also developed two ensemble methods, which combined the predictions of SemRep and the MEDI algorithm. We evaluated our selected methods on two datasets, a Vanderbilt corpus of 6864 discharge summaries and the 2010 Informatics for Integrating Biology and the Bedside (i2b2)/Veteran's Affairs (VA) challenge dataset. The Vanderbilt dataset included 958 manually annotated treatment relations. A double annotation was performed on 25% of relations with high agreement (Cohen's ÃŽÂº = 0.86). The evaluation consisted of comparing the manual annotated relations with the relations identified by SemRep, the MEDI algorithm, and the two ensemble methods. On the first dataset, the best F1-measure results achieved by the MEDI algorithm and the union of the two resources (78.7 and 80, respectively) were significantly higher than the SemRep results (72.3). On the second dataset, the MEDI algorithm achieved better precision and significantly lower recall values than the best system in the i2b2 challenge. The two systems obtained comparable F1-measure values on the subset of i2b2 relations with both arguments in MEDI. Both SemRep and MEDI can be used to extract treatment relations from clinical text. Knowledge-based extraction with MEDI outperformed use of SemRep alone, but superior performance was achieved by integrating both systems. The integration of knowledge-based resources such as MEDI into information extraction systems such as SemRep and the i2b2 relation extractors may improve treatment relation extraction from clinical text.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21568,""
"Adaptive semantic tag mining from heterogeneous clinical research texts","Hao, Weng","https://doi.org/10.3414/ME13-01-0130","20161213","PubMed","Medical informatics; clinical trials; component-based architecture; semantic tags; text mining; Algorithms; Biomedical Research; Clinical Trials as Topic; Data Mining; Humans; Medical Informatics Computing; Publications; Semantics","To develop an adaptive approach to mine frequent semantic tags (FSTs) from heterogeneous clinical research texts. We develop a ""plug-n-play"" framework that integrates replaceable unsupervised kernel algorithms with formatting, functional, and utility wrappers for FST mining. Temporal information identification and semantic equivalence detection were two example functional wrappers. We first compared this approach's recall and efficiency for mining FSTs from ClinicalTrials.gov to that of a recently published tag-mining algorithm. Then we assessed this approach's adaptability to two other types of clinical research texts: clinical data requests and clinical trial protocols, by comparing the prevalence trends of FSTs across three texts. Our approach increased the average recall and speed by 12.8% and 47.02% respectively upon the baseline when mining FSTs from ClinicalTrials.gov, and maintained an overlap in relevant FSTs with the base- line ranging between 76.9% and 100% for varying FST frequency thresholds. The FSTs saturated when the data size reached 200 documents. Consistent trends in the prevalence of FST were observed across the three texts as the data size or frequency threshold changed. This paper contributes an adaptive tag-mining framework that is scalable and adaptable without sacrificing its recall. This component-based architectural design can be potentially generalizable to improve the adaptability of other clinical text mining methods.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21569,""
"Fronto-parietal network oscillations reveal relationship between working memory capacity and cognitive control","Gulbinaite, van Rijn, Cohen","https://doi.org/10.3389/fnhum.2014.00761","20141017","PubMed","EEG; cognitive control; connectivity; fronto-parietal; theta; working memory capacity","Executive-attention theory proposes a close relationship between working memory capacity (WMC) and cognitive control abilities. However, conflicting results are documented in the literature, with some studies reporting that individual variations in WMC predict differences in cognitive control and trial-to-trial control adjustments (operationalized as the size of the congruency effect and congruency sequence effects, respectively), while others report no WMC-related differences. We hypothesized that brain network dynamics might be a more sensitive measure of WMC-related differences in cognitive control abilities. Thus, in the present study, we measured human EEG during the Simon task to characterize WMC-related differences in the neural dynamics of conflict processing and adaptation to conflict. Although high- and low-WMC individuals did not differ behaviorally, there were substantial WMC-related differences in theta (4-8 Hz) and delta (1-3 Hz) connectivity in fronto-parietal networks. Group differences in local theta and delta power were relatively less pronounced. These results suggest that the relationship between WMC and cognitive control abilities is more strongly reflected in large-scale oscillatory network dynamics than in spatially localized activity or in behavioral task performance. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21570,""
"Unfolding Physiological State: Mortality Modelling in Intensive Care Units","Ghassemi, Naumann, Doshi-Velez, Brimmer, Joshi, Rumshisky, Szolovits","https://doi.org/10.1145/2623330.2623742","20211021","PubMed","","Accurate knowledge of a patient's disease state and trajectory is critical in a clinical setting. Modern electronic healthcare records contain an increasingly large amount of data, and the ability to automatically identify the factors that influence patient outcomes stand to greatly improve the efficiency and quality of care. We examined the use of latent variable models (viz. Latent Dirichlet Allocation) to decompose free-text hospital notes into meaningful features, and the predictive power of these features for patient mortality. We considered three prediction regimes: (1) baseline prediction, (2) dynamic (time-varying) outcome prediction, and (3) retrospective outcome prediction. In each, our prediction task differs from the familiar time-varying situation whereby data accumulates; since fewer patients have long ICU stays, as we move forward in time fewer patients are available and the prediction task becomes increasingly difficult. We found that latent topic-derived features were effective in determining patient mortality under three timelines: inhospital, 30 day post-discharge, and 1 year post-discharge mortality. Our results demonstrated that the latent topic features important in predicting hospital mortality are very different from those that are important in post-discharge mortality. In general, latent topic features were more predictive than structured features, and a combination of the two performed best. The time-varying models that combined latent topic features and baseline features had AUCs that reached 0.85, 0.80, and 0.77 for in-hospital, 30 day post-discharge and 1 year post-discharge mortality respectively. Our results agreed with other work suggesting that the first 24 hours of patient information are often the most predictive of hospital mortality. Retrospective models that used a combination of latent topic features and structured features achieved AUCs of 0.96, 0.82, and 0.81 for in-hospital, 30 day, and 1-year mortality prediction. Our work focuses on the dynamic (time-varying) setting because models from this regime could facilitate an on-going severity stratification system that helps direct care-staff resources and inform treatment strategies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21571,""
"Online discourse on fibromyalgia: text-mining to identify clinical distinction and patient concerns","Park, Ryu","https://doi.org/10.12659/MSM.890793","20150529","PubMed","Data Mining; Fibromyalgia; Humans","The purpose of this study was to evaluate the possibility of using text-mining to identify clinical distinctions and patient concerns in online memoires posted by patients with fibromyalgia (FM). A total of 399 memoirs were collected from an FM group website. The unstructured data of memoirs associated with FM were collected through a crawling process and converted into structured data with a concordance, parts of speech tagging, and word frequency. We also conducted a lexical analysis and phrase pattern identification. After examining the data, a set of FM-related keywords were obtained and phrase net relationships were set through a web-based visualization tool. The clinical distinction of FM was verified. Pain is the biggest issue to the FM patients. The pains were affecting body parts including 'muscles,' 'leg,' 'neck,' 'back,' 'joints,' and 'shoulders' with accompanying symptoms such as 'spasms,' 'stiffness,' and 'aching,' and were described as 'sever,' 'chronic,' and 'constant.' This study also demonstrated that it was possible to understand the interests and concerns of FM patients through text-mining. FM patients wanted to escape from the pain and symptoms, so they were interested in medical treatment and help. Also, they seemed to have interest in their work and occupation, and hope to continue to live life through the relationships with the people around them. This research shows the potential for extracting keywords to confirm the clinical distinction of a certain disease, and text-mining can help objectively understand the concerns of patients by generalizing their large number of subjective illness experiences. However, it is believed that there are limitations to the processes and methods for organizing and classifying large amounts of text, so these limits have to be considered when analyzing the results. The development of research methodology to overcome these limitations is greatly needed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21572,""
"Targeted Local Support Vector Machine for Age-Dependent Classification","Chen, Wang, Chen, Marder, Zeng","https://doi.org/10.1080/01621459.2014.881743","20211021","PubMed","HuntingtonÃ¢â‚¬â„¢s disease; Local smoothing; Reproducing kernel Hilbert space; Risk bound; Statistical learning","We develop methods to accurately predict whether pre-symptomatic individuals are at risk of a disease based on their various marker profiles, which offers an opportunity for early intervention well before definitive clinical diagnosis. For many diseases, existing clinical literature may suggest the risk of disease varies with some markers of biological and etiological importance, for example age. To identify effective prediction rules using nonparametric decision functions, standard statistical learning approaches treat markers with clear biological importance (e.g., age) and other markers without prior knowledge on disease etiology interchangeably as input variables. Therefore, these approaches may be inadequate in singling out and preserving the effects from the biologically important variables, especially in the presence of potential noise markers. Using age as an example of a salient marker to receive special care in the analysis, we propose a local smoothing large margin classifier implemented with support vector machine (SVM) to construct effective age-dependent classification rules. The method adaptively adjusts age effect and separately tunes age and other markers to achieve optimal performance. We derive the asymptotic risk bound of the local smoothing SVM, and perform extensive simulation studies to compare with standard approaches. We apply the proposed method to two studies of premanifest Huntington's disease (HD) subjects and controls to construct age-sensitive predictive scores for the risk of HD and risk of receiving HD diagnosis during the study period.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21573,""
"A review of ultrasound common carotid artery image and video segmentation techniques","Loizou","https://doi.org/10.1007/s11517-014-1203-5","20150416","PubMed","Aged; Carotid Artery, Common; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Tunica Intima; Ultrasonography; Video Recording","The determination of the wall thickness [intima-media thickness (IMT)], the delineation of the atherosclerotic carotid plaque, the measurement of the diameter in the common carotid artery (CCA), as well as the grading of its stenosis are important for the evaluation of the atherosclerosis disease. All these measurements are also considered to be significant markers for the clinical evaluation of the risk of stroke. A number of CCA segmentation techniques have been proposed in the last few years either for the segmentation of the intima-media complex (IMC), the lumen of the CCA, or for the atherosclerotic carotid plaque from ultrasound images or videos of the CCA. The present review study proposes and discusses the methods and systems introduced so far in the literature for performing automated or semi-automated segmentation in ultrasound images or videos of the CCA. These are based on edge detection, active contours, level sets, dynamic programming, local statistics, Hough transform, statistical modeling, neural networks, and an integration of the above methods. Furthermore, the performance of these systems is evaluated and discussed based on various evaluation metrics. We finally propose the best performing method that can be used for the segmentation of the IMC and the atherosclerotic carotid plaque in ultrasound images and videos. We end the present review study with a discussion of the different image and video CCA segmentation techniques, future perspectives, and further extension of these techniques to ultrasound video segmentation and wall tracking of the CCA. Future work on the segmentation of the CCA will be focused on the development of integrated segmentation systems for the complete segmentation of the CCA as well as the segmentation and motion analysis of the plaque and or the IMC from ultrasound video sequences of the CCA. These systems will improve the evaluation, follow up, and treatment of patients affected by advanced atherosclerosis disease conditions. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21574,""
"Post-endodontic treatment of incisors and premolars among dental practitioners in Saarland: an interactive Web-based survey","Mitov, DÃƒÂ¶rr, Nothdurft, Draenert, Pospiech","https://doi.org/10.1007/s00784-014-1326-y","20180118","PubMed","Bicuspid; Dental Materials; Dental Restoration, Permanent; Germany; Humans; Incisor; Internet; Post and Core Technique; Practice Patterns, Dentists'; Surveys and Questionnaires; Tooth, Nonvital","The aim of the present study was to evaluate the trend of dental practitioners in the federal state of Saarland in Germany in regard to restoring endodontically treated teeth using a Web-based survey. An interactive Web-based survey instrument was developed, including seven clinical scenarios, presented by photographs of natural incisor and premolar with different types of cavities. Following a decision tree adapted to the clinical treatment, questions on different aspects of the post-endodontic treatment were asked. All 615 members of the Saarland Dental Association (SDA) were asked to participate in the survey. A total of 33 % completed the survey. The majority of the participants believed in the reinforcement effect of the ferrule design, as well as the post placement. The vast majority of the responding practitioners (92 %) adapted their treatment strategies to a high extent to the destruction degree of the endodontically treated tooth. Fiber-reinforced composite (FRC) posts are the most popular prefabricated post type, regardless of the cavity size and tooth localization. Significant differences between the dentists according to the degree of experience were detected only for the use of glass-ionomer cements as core buildup material. The predominant post-endodontic treatment strategies of German dental practitioners are only partly in agreement with the current literature. There is a clear trend toward the increasing use of metal-free post and core materials. Although the participants showed a general adoption of modern materials and techniques, different patterns of post-endodontic treatment were revealed that were not consistent with approaches supported by the literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21575,""
"Emerging technologies for the clinical microbiology laboratory","Buchan, Ledeboer","https://doi.org/10.1128/CMR.00003-14","20150610","PubMed","Automation, Laboratory; Genetic Techniques; Humans; Mass Spectrometry; Microbiological Techniques","In this review we examine the literature related to emerging technologies that will help to reshape the clinical microbiology laboratory. These topics include nucleic acid amplification tests such as isothermal and point-of-care molecular diagnostics, multiplexed panels for syndromic diagnosis, digital PCR, next-generation sequencing, and automation of molecular tests. We also review matrix-assisted laser desorption ionization-time of flight (MALDI-TOF) and electrospray ionization (ESI) mass spectrometry methods and their role in identification of microorganisms. Lastly, we review the shift to liquid-based microbiology and the integration of partial and full laboratory automation that are beginning to impact the clinical microbiology laboratory.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21576,""
"Comparative analysis of a novel disease phenotype network based on clinical manifestations","Chen, Zhang, Zhang, Xu","https://doi.org/10.1016/j.jbi.2014.09.007","20151214","PubMed","Disease phenotype network; Network analysis; Ontology; Algorithms; Computational Biology; Databases, Genetic; Gene Expression Regulation; Gene Regulatory Networks; Genotype; Humans; Marfan Syndrome; Models, Statistical; Mutation; Phenotype; Reproducibility of Results; Unified Medical Language System","Systems approaches to analyzing disease phenotype networks in combination with protein functional interaction networks have great potential in illuminating disease pathophysiological mechanisms. While many genetic networks are readily available, disease phenotype networks remain largely incomplete. In this study, we built a large-scale Disease Manifestation Network (DMN) from 50,543 highly accurate disease-manifestation semantic relationships in the United Medical Language System (UMLS). Our new phenotype network contains 2305 nodes and 373,527 weighted edges to represent the disease phenotypic similarities. We first compared DMN with the networks representing genetic relationships among diseases, and demonstrated that the phenotype clustering in DMN reflects common disease genetics. Then we compared DMN with a widely-used disease phenotype network in previous gene discovery studies, called mimMiner, which was extracted from the textual descriptions in Online Mendelian Inheritance in Man (OMIM). We demonstrated that DMN contains different knowledge from the existing phenotype data source. Finally, a case study on Marfan syndrome further proved that DMN contains useful information and can provide leads to discover unknown disease causes. Integrating DMN in systems approaches with mimMiner and other data offers the opportunities to predict novel disease genetics. We made DMN publicly available at nlp/case.edu/public/data/DMN. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21577,""
"Managing the complexity of doing it all: an exploratory study on students' experiences when trained stepwise in conducting consultations","Aper, Reniers, Derese, Veldhuijzen","https://doi.org/10.1186/1472-6920-14-206","20150513","PubMed","Attitude of Health Personnel; Clinical Clerkship; Clinical Competence; Communication; Curriculum; Focus Groups; Humans; Mentors; Netherlands; Patient Simulation; Problem Solving; Referral and Consultation; Students, Medical","At most medical schools the components required to conduct a consultation, medical knowledge, communication, clinical reasoning and physical examination skills, are trained separately. Afterwards, all the knowledge and skills students acquired must be integrated into complete consultations, an art that lies at the heart of the medical profession. Inevitably, students experience conducting consultations as complex and challenging. Literature emphasizes the importance of three didactic course principles: moving from partial tasks to whole task learning, diminishing supervisors' support and gradually increasing students' responsibility. This study explores students' experiences of an integrated consultation course using these three didactic principles to support them in this difficult task. Six focus groups were conducted with 20 pre-clerkship and 19 clerkship students in total. Discussions were audiotaped, transcribed and analysed by Nvivo using the constant comparative strategy within a thematic analysis. Conducting complete consultations motivated students in their learning process as future physician. Initially, students were very much focused on medical problem solving. Completing the whole task of a consultation obligated them to transfer their theoretical medical knowledge into applicable clinical knowledge on the spot. Furthermore, diminishing the support of a supervisor triggered students to reflect on their own actions but contrasted with their increased appreciation of critical feedback. Increasing students' responsibility stimulated their active learning but made some students feel overloaded. These students were anxious to miss patient information or not being able to take the right decisions or to answer patients' questions, which sometimes resulted in evasive coping techniques, such as talking faster to prevent the patient asking questions. The complex task of conducting complete consultations should be implemented early within medical curricula because students need time to organize their medical knowledge into applicable clinical knowledge. An integrated consultation course should comprise a step-by-step teaching strategy with a variety of supervisors' feedback modi, adapted to students' competence. Finally, students should be guided in formulating achievable standards to prevent them from feeling overloaded in practicing complete consultations with simulated or real patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21578,""
"Angiopoietin-1, angiopoietin-2 and bicarbonate as diagnostic biomarkers in children with severe sepsis","Wang, Bhandari, Giuliano, O Hern, Shattuck, Kirby","https://doi.org/10.1371/journal.pone.0108461","20151201","PubMed","Age Factors; Angiopoietin-1; Angiopoietin-2; Bicarbonates; Biomarkers; Cluster Analysis; Humans; Intensive Care Units, Pediatric; Prognosis; Reproducibility of Results; Sensitivity and Specificity; Sepsis; Severity of Illness Index; Support Vector Machine","Severe pediatric sepsis continues to be associated with high mortality rates in children. Thus, an important area of biomedical research is to identify biomarkers that can classify sepsis severity and outcomes. The complex and heterogeneous nature of sepsis makes the prospect of the classification of sepsis severity using a single biomarker less likely. Instead, we employ machine learning techniques to validate the use of a multiple biomarkers scoring system to determine the severity of sepsis in critically ill children. The study was based on clinical data and plasma samples provided by a tertiary care center's Pediatric Intensive Care Unit (PICU) from a group of 45 patients with varying sepsis severity at the time of admission. Canonical Correlation Analysis with the Forward Selection and Random Forests methods identified a particular set of biomarkers that included Angiopoietin-1 (Ang-1), Angiopoietin-2 (Ang-2), and Bicarbonate (HCO[Formula: see text]) as having the strongest correlations with sepsis severity. The robustness and effectiveness of these biomarkers for classifying sepsis severity were validated by constructing a linear Support Vector Machine diagnostic classifier. We also show that the concentrations of Ang-1, Ang-2, and HCO[Formula: see text] enable predictions of the time dependence of sepsis severity in children. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21579,""
"Cost analysis of voriconazole versus liposomal amphotericin B for primary therapy of invasive aspergillosis among patients with haematological disorders in Germany and Spain","Ostermann, Solano, Jarque, Garcia-Vidal, Gao, Barrueta, De Salas-Cansado, Stephens, Xue, Weber, Charbonneau","https://doi.org/10.1186/2050-6511-15-52","20150331","PubMed","Amphotericin B; Antifungal Agents; Aspergillosis; Costs and Cost Analysis; Germany; Hematologic Diseases; Spain; Voriconazole","The current healthcare climate demands pharmacoeconomic evaluations for different treatment strategies incorporating drug acquisition costs, costs incurred for hospitalisation, drug administration and preparation, diagnostic and laboratory testing and drug-related adverse events (AEs). Here we evaluate the pharmacoeconomics of voriconazole versus liposomal amphotericin B as first-line therapies for invasive aspergillosis (IA) in patients with haematological malignancy and prolonged neutropenia or who were undergoing haematopoietic stem-cell transplantation in Germany or Spain. A decision analytic model based on a decision tree was constructed to estimate the potential treatment costs of voriconazole versus liposomal amphotericin B. Each model pathway was defined by the probability of an event occurring and the costs of clinical outcomes. Outcome probabilities and cost inputs were derived from the published literature, clinical trials, expert panels and local database costs. In the base case, patients who failed to respond to first-line therapy were assumed to experience a single switch between comparator drugs or the other drug was added as second-line treatment. Base-case evaluation included only drug-management costs and additional hospitalisation costs due to severe AEs associated with first- and second-line therapies. Sensitivity analyses were conducted to assess the robustness of the results. Cost estimates were inflated to 2011 euros (Ã¢â€šÂ¬). Based on clinical trial success rates of 52.8% (voriconazole) and 50.0% (liposomal amphotericin B), voriconazole had lower total treatment costs compared with liposomal amphotericin B in both Germany (Ã¢â€šÂ¬ 12,256 versus Ã¢â€šÂ¬ 18,133; length of therapy [LOT]Ã¢â‚¬â€°=Ã¢â‚¬â€°10-day intravenous [IV]Ã¢â‚¬â€°+Ã¢â‚¬â€°5-day oral voriconazole and 15-day IV liposomal amphotericin B) and Spain (Ã¢â€šÂ¬ 8,032 versus Ã¢â€šÂ¬ 10,516; LOTÃ¢â‚¬â€°=Ã¢â‚¬â€°7-day IVÃ¢â‚¬â€°+Ã¢â‚¬â€°8-day oral voriconazole and 15-day IV liposomal amphotericin B). Assuming the same efficacy (50.0%) in first-line therapy, voriconazole maintained a lower total treatment cost compared with liposomal amphotericin B. Cost savings were primarily due to the lower drug acquisition costs and shorter IV LOT associated with voriconazole. Sensitivity analyses showed that the results were sensitive to drug price, particularly the cost of liposomal amphotericin B. Voriconazole is likely to be cost-saving compared with liposomal amphotericin B when used as a first-line treatment for IA in Germany and Spain.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21580,""
"A random set scoring model for prioritization of disease candidate genes using protein complexes and data-mining of GeneRIF, OMIM and PubMed records","Jiang, Edwards, Thomsen, Workman, Guldbrandtsen, SÃƒÂ¸rensen","https://doi.org/10.1186/1471-2105-15-315","20141118","PubMed","Algorithms; Data Mining; Databases, Genetic; Disease; Gene Regulatory Networks; Genome-Wide Association Study; Genomics; Humans; Likelihood Functions; Models, Statistical; Phenotype; Protein Interaction Maps; Proteins; PubMed; Reproducibility of Results","Prioritizing genetic variants is a challenge because disease susceptibility loci are often located in genes of unknown function or the relationship with the corresponding phenotype is unclear. A global data-mining exercise on the biomedical literature can establish the phenotypic profile of genes with respect to their connection to disease phenotypes. The importance of protein-protein interaction networks in the genetic heterogeneity of common diseases or complex traits is becoming increasingly recognized. Thus, the development of a network-based approach combined with phenotypic profiling would be useful for disease gene prioritization. We developed a random-set scoring model and implemented it to quantify phenotype relevance in a network-based disease gene-prioritization approach. We validated our approach based on different gene phenotypic profiles, which were generated from PubMed abstracts, OMIM, and GeneRIF records. We also investigated the validity of several vocabulary filters and different likelihood thresholds for predicted protein-protein interactions in terms of their effect on the network-based gene-prioritization approach, which relies on text-mining of the phenotype data. Our method demonstrated good precision and sensitivity compared with those of two alternative complex-based prioritization approaches. We then conducted a global ranking of all human genes according to their relevance to a range of human diseases. The resulting accurate ranking of known causal genes supported the reliability of our approach. Moreover, these data suggest many promising novel candidate genes for human disorders that have a complex mode of inheritance. We have implemented and validated a network-based approach to prioritize genes for human diseases based on their phenotypic profile. We have devised a powerful and transparent tool to identify and rank candidate genes. Our global gene prioritization provides a unique resource for the biological interpretation of data from genome-wide association studies, and will help in the understanding of how the associated genetic variants influence disease or quantitative phenotypes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21581,""
"Single-Nucleotide Polymorphisms Within MicroRNAs Sequences and Their 3' UTR Target Sites May Regulate Gene Expression in Gastrointestinal Tract Cancers","Saadatian, Masotti, Nariman Saleh Fam, Alipoor, Bastami, Ghaedi","https://doi.org/10.5812/ircmj.16659","20140919","PubMed","Colorectal Neoplasms; Esophageal Neoplasms; Gastric Neoplasms; Gastrointestinal Neoplasms; MicroRNAs; Single Nucleotide Polymorphisms","Esophageal, stomach, and colorectal cancers are commonly lethal gastrointestinal tract (GIT) neoplasms, causing almost two million deaths worldwide each year. some environmental risk factors are acknowledged; however, genetic defects can significantly contribute to predisposition to GIT cancers. Accordingly, recent works have shown that single-nucleotide polymorphisms (SNPs) within miRNAs coding sequence (miR-SNPs) and miRNA target sites (target-SNPs) may further contribute to increased risk of developing cancer. In this study, we comprehensively identified miRNA-target gene pairs implicated in GIT cancers and catalogued the presence of potentially functional miR-SNPs and target-SNPs that impair the correct functional recognition. Using bioinformatics tools, manual literature review, and a highly accurate dataset of experimentally validated miRNA-target gene interactions, we compiled a list of miRNA-target genes pairs related to GIT cancers and prioritized them into different groups based on the levels of experimental support. Functional annotations (gene ontology) were applied to these pairs in each group to gain further information. We identified 97 pairs in which both miRNAs and target genes were implicated in GIT cancers. Several pairs, denoted as highly polymorphic pairs, had both miR-SNPs and target-SNPs. In addition, more than 5000 miRNA-target gene pairs were identified in which, according to the previous reports, either the miRNAs or the target genes had a direct involvement in GIT cancers. More than 800 target-SNPs are located in regulatory regions that were extracted from the ENCODE project through the RegulomeDB database. Of these, 20 were classified as expression quantitative trait loci (eQTLs). Our work provided a comprehensive source of prioritized and annotated candidate polymorphisms inside miRNAs and their target sites in GIT cancers, which would facilitate the process of choosing right candidate miRNA-target genes and related polymorphisms for future association or functional studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21582,""
"Robotic radical nephrectomy for renal cell carcinoma: a systematic review","Asimakopoulos, Miano, Annino, Micali, Spera, Iorio, Vespasiani, Gaston","https://doi.org/10.1186/1471-2490-14-75","20150407","PubMed","Blood Loss, Surgical; Carcinoma, Renal Cell; Hospital Costs; Humans; Kidney Neoplasms; Laparoscopy; Length of Stay; Nephrectomy; Operative Time; Postoperative Complications; Robotics","Laparoscopic radical nephrectomy (LRN) is the actual gold-standard for the treatment of clinically localized renal cell carcinoma (RCC) (cT1-2 with no indications for nephron-sparing surgery). Limited evidence is currently available on the role of robotics in the field of radical nephrectomy. The aim of the current study was to provide a systematic review of the current evidence on the role of robotic radical nephrectomy (RRN) and to analyze the comparative studies between RRN and open nephrectomy (ON)/LRN. A Medline search was performed between 2000-2013 with the terms ""robotic radical nephrectomy"", ""robot-assisted laparoscopic nephrectomy"", ""radical nephrectomy"". Six RRN case-series and four comparative studies between RRN and (ON)/pure or hand-assisted LRN were identified. Current literature produces a low level of evidence for RRN in the treatment of RCC, with only one prospective study available. Mean operative time (OT) ranges between 127.8-345 min, mean estimated blood loss (EBL) ranges between 100-273.6 ml, and mean hospital stay (HS) ranges between 1.2-4.3 days. The comparison between RRN and LRN showed no differences in the evaluated outcomes except for a longer OT for RRN as evidenced in two studies. Significantly higher direct costs and costs of the disposable instruments were also observed for RRN. The comparison between RRN and ON showed that ON is characterized by shorter OT but higher EBL, higher need of postoperative analgesics and longer HS. No advantage of robotics over standard laparoscopy for the treatment of clinically localized RCC was evidenced. Promising preliminary results on oncologic efficacy of RRN have been published on the T3a-b disease. Fields of wider application of robotics should be researched where indications for open surgery still persist.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21583,""
"RADB: a database of rheumatoid arthritis-related polymorphisms","Zhang, Luan, Shang, Duan, Tang, Shi, Lv, Zhu, Li, Lv, Zhang, Liu, Chen, Jiang","https://doi.org/10.1093/database/bau090","20150220","PubMed","Antirheumatic Agents; Arthritis, Rheumatoid; Cardiovascular Diseases; Databases, Genetic; Gene Ontology; Genetic Predisposition to Disease; Genome-Wide Association Study; Humans; Internet; Polymorphism, Genetic; Risk; Software; User-Computer Interface","Rheumatoid arthritis (RA) is an autoimmune disease that has a complex genetic basis. Therefore, it is important to explore the genetic background of RA. The extensive recent application of polymorphic genetic markers, especially single nucleotide polymorphisms, has presented us with a large quantity of genetic data. In this study, we developed the Database of Rheumatoid Arthritis-related Polymorphisms (RADB), to integrate all the RA-related genetic polymorphisms and provide a useful resource for researchers. We manually extracted the RA-related polymorphisms from 686 published reports, including RA susceptibility loci, polymorphisms associated with particular clinical features of RA, polymorphisms associated with drug response in RA and polymorphisms associated with a higher risk of cardiovascular disease in RA. Currently, RADB V1.0 contains 3235 polymorphisms that are associated with 636 genes and refer to 68 countries. The detailed information extracted from the literature includes basic information about the articles (e.g., PubMed ID, title and abstract), population information (e.g., country, geographic area and sample size) and polymorphism information (e.g., polymorphism name, gene, genotype, odds ratio and 95% confidence interval, P-value and risk allele). Meanwhile, useful annotations, such as hyperlinks to dbSNP, GenBank, UCSC, Gene Ontology and Kyoto Encyclopedia of Genes and Genomes pathway, are included. In addition, a tool for meta-analysis was developed to summarize the results of multiple studies. The database is freely available at http://www.bioapp.org/RADB. Database URL: http://www.bioapp.org/RADB.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21584,""
"Resting state fMRI feature-based cerebral glioma grading by support vector machine","Wu, Qian, Tao, Yin, Ding, Zhang, Yu","https://doi.org/10.1007/s11548-014-1111-z","20160223","PubMed","Brain Neoplasms; Glioma; Humans; Magnetic Resonance Imaging; Neoplasm Grading; Sensitivity and Specificity; Support Vector Machine","PURPOSEÃ‚Â : Tumor grading plays an essential role in the optimal selection of solid tumor treatment. Noninvasive methods are needed for clinical grading of tumors. This study aimed to extract parameters of resting state blood oxygenation level-dependent functional magnetic resonance imaging (RS-fMRI) in the region of glioma and use the extracted features for tumor grading. METHODSÃ‚Â : Tumor segmentation was performed with both conventional MRI and RS-fMRI. Four typical parameters, signal intensity difference ratio, signal intensity correlation (SIC), fractional amplitude of low-frequency fluctuation (fALFF) and regional homogeneity (ReHo), were defined to analyze tumor regions. Mann-Whitney [Formula: see text] test was employed to identify statistical difference of these four parameters between low-grade glioma (LGG) and high-grade glioma (HGG), respectively. Support vector machine (SVM) was employed to assess the diagnostic contributions of these parameters. RESULTSÃ‚Â : Compared with LGG, HGG had more complex anatomical morphology and BOLD-fMRI features in the tumor region. SIC [Formula: see text], fALFF ([Formula: see text]) and ReHo ([Formula: see text]) were selected as features for classification according to the test [Formula: see text] value. The accuracy, sensitivity and specificity of SVM classification were better than 80, where SIC had the best classification accuracy (89). CONCLUSIONÃ‚Â : Parameters of RS-fMRI are effective to classify the tumor grade in glioma cases. The results indicate that this technique has clinical potential to serve as a complementary diagnostic tool. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21585,""
"LabeledIn: cataloging labeled indications for human drugs","Khare, Li, Lu","https://doi.org/10.1016/j.jbi.2014.08.004","20150824","PubMed","Corpus annotation; Drug indications; Drug labels; Natural language processing; Documentation; Drug Labeling; Drug Therapy; Humans; Natural Language Processing; Software","Drug-disease treatment relationships, i.e., which drug(s) are indicated to treat which disease(s), are among the most frequently sought information in PubMedÃ‚Â®. Such information is useful for feeding the Google Knowledge Graph, designing computational methods to predict novel drug indications, and validating clinical information in EMRs. Given the importance and utility of this information, there have been several efforts to create repositories of drugs and their indications. However, existing resources are incomplete. Furthermore, they neither label indications in a structured way nor differentiate them by drug-specific properties such as dosage form, and thus do not support computer processing or semantic interoperability. More recently, several studies have proposed automatic methods to extract structured indications from drug descriptions; however, their performance is limited by natural language challenges in disease named entity recognition and indication selection. In response, we report LabeledIn: a human-reviewed, machine-readable and source-linked catalog of labeled indications for human drugs. More specifically, we describe our semi-automatic approach to derive LabeledIn from drug descriptions through human annotations with aids from automatic methods. As the data source, we use the drug labels (or package inserts) submitted to the FDA by drug manufacturers and made available in DailyMed. Our machine-assisted human annotation workflow comprises: (i) a grouping method to remove redundancy and identify representative drug labels to be used for human annotation, (ii) an automatic method to recognize and normalize mentions of diseases in drug labels as candidate indications, and (iii) a two-round annotation workflow for human experts to judge the pre-computed candidates and deliver the final gold standard. In this study, we focused on 250 highly accessed drugs in PubMed Health, a newly developed public web resource for consumers and clinicians on prevention and treatment of diseases. These 250 drugs corresponded to more than 8000 drug labels (500 unique) in DailyMed in which 2950 candidate indications were pre-tagged by an automatic tool. After being reviewed independently by two experts, 1618 indications were selected, and additional 97 (missed by computer) were manually added, with an inter-annotator agreement of 88.35% as measured by the Kappa coefficient. Our final annotation results in LabeledIn consist of 7805 drug-disease treatment relationships where drugs are represented as a triplet of ingredient, dose form, and strength. A systematic comparison of LabeledIn with an existing computer-derived resource revealed significant discrepancies, confirming the need to involve humans in the creation of such a resource. In addition, LabeledIn is unique in that it contains detailed textual context of the selected indications in drug labels, making it suitable for the development of advanced computational methods for the automatic extraction of indications from free text. Finally, motivated by the studies on drug nomenclature and medication errors in EMRs, we adopted a fine-grained drug representation scheme, which enables the automatic identification of drugs with indications specific to certain dose forms or strengths. Future work includes expanding our coverage to more drugs and integration with other resources. The LabeledIn dataset and the annotation guidelines are available at http://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21586,""
"Assessment of movement quality in robot- assisted upper limb rehabilitation after stroke: a review","Nordin, Xie, WÃƒÂ¼nsche","https://doi.org/10.1186/1743-0003-11-137","20150915","PubMed","Biomechanical Phenomena; Humans; Movement; Robotics; Stroke Rehabilitation; Upper Extremity",": Studies of stroke patients undergoing robot-assisted rehabilitation have revealed various kinematic parameters describing movement quality of the upper limb. However, due to the different level of stroke impairment and different assessment criteria and interventions, the evaluation of the effectiveness of rehabilitation program is undermined. This paper presents a systematic review of kinematic assessments of movement quality of the upper limb and identifies the suitable parameters describing impairments in stroke patients. A total of 41 different clinical and pilot studies on different phases of stroke recovery utilizing kinematic parameters are evaluated. Kinematic parameters describing movement accuracy are mostly reported for chronic patients with statistically significant outcomes and correlate strongly with clinical assessments. Meanwhile, parameters describing feed-forward sensorimotor control are the most frequently reported in studies on sub-acute patients with significant outcomes albeit without correlation to any clinical assessments. However, lack of measures in coordinated movement and proximal component of upper limb enunciate the difficulties to distinguish the exploitation of joint redundancies exhibited by stroke patients in completing the movement. A further study on overall measures of coordinated movement is recommended. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21587,""
"Analysis of gene expression profiles of soft tissue sarcoma using a combination of knowledge-based filtering with integration of multiple statistics","Takahashi, Nakayama, Ishibashi, Doi, Ichinohe, Ikuyo, Takahashi, Marui, Yasuhara, Nakamura, Sugita, Sakamoto, Yoshida, Hasegawa, Takahashi","https://doi.org/10.1371/journal.pone.0106801","20151207","PubMed","Algorithms; Biomarkers, Tumor; Female; Gene Expression Profiling; Gene Expression Regulation, Neoplastic; Humans; Knowledge Bases; Male; Middle Aged; Neoplasm Proteins; Oligonucleotide Array Sequence Analysis; Prognosis; STAT1 Transcription Factor; Sarcoma; Soft Tissue Neoplasms; Software; Survival Analysis","The diagnosis and treatment of soft tissue sarcomas (STS) have been difficult. Of the diverse histological subtypes, undifferentiated pleomorphic sarcoma (UPS) is particularly difficult to diagnose accurately, and its classification per se is still controversial. Recent advances in genomic technologies provide an excellent way to address such problems. However, it is often difficult, if not impossible, to identify definitive disease-associated genes using genome-wide analysis alone, primarily because of multiple testing problems. In the present study, we analyzed microarray data from 88 STS patients using a combination method that used knowledge-based filtering and a simulation based on the integration of multiple statistics to reduce multiple testing problems. We identified 25 genes, including hypoxia-related genes (e.g., MIF, SCD1, P4HA1, ENO1, and STAT1) and cell cycle- and DNA repair-related genes (e.g., TACC3, PRDX1, PRKDC, and H2AFY). These genes showed significant differential expression among histological subtypes, including UPS, and showed associations with overall survival. STAT1 showed a strong association with overall survival in UPS patients (logrank p = 1.84 Ãƒâ€” 10(-6) and adjusted p value 2.99 Ãƒâ€” 10(-3) after the permutation test). According to the literature, the 25 genes selected are useful not only as markers of differential diagnosis but also as prognostic/predictive markers and/or therapeutic targets for STS. Our combination method can identify genes that are potential prognostic/predictive factors and/or therapeutic targets in STS and possibly in other cancers. These disease-associated genes deserve further preclinical and clinical validation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21588,""
"Mapping knowledge translation and innovation processes in Cancer Drug Development: the case of liposomal doxorubicin","Fajardo-Ortiz, Duran, Moreno, Ochoa, CastaÃƒÂ±o","https://doi.org/10.1186/s12967-014-0227-9","20150526","PubMed","Antineoplastic Agents; Diffusion of Innovation; Doxorubicin; Drug Discovery; Gene Ontology; Humans; Information Services; Knowledge; Maps as Topic; Medical Subject Headings; Neoplasms; Polyethylene Glycols; Translational Medical Research","We explored how the knowledge translation and innovation processes are structured when theyresult in innovations, as in the case of liposomal doxorubicin research. In order to map the processes, a literature network analysis was made through Cytoscape and semantic analysis was performed by GOPubmed which is based in the controlled vocabularies MeSH (Medical Subject Headings) and GO (Gene Ontology). We found clusters related to different stages of the technological development (invention, innovation and imitation) and the knowledge translation process (preclinical, translational and clinical research), and we were able to map the historic emergence of Doxil as a paradigmatic nanodrug. This research could be a powerful methodological tool for decision-making and innovation management in drug delivery research. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21589,""
"Outcomes of robotic sacrocolpopexy: a systematic review and meta-analysis","Hudson, Northington, Lyles, Karp","https://doi.org/10.1097/SPV.0000000000000070","20150514","PubMed","Aged; Female; Gynecologic Surgical Procedures; Humans; Laparoscopy; Middle Aged; Pelvic Organ Prolapse; Postoperative Complications; Robotics; Sacrococcygeal Region; Surgical Mesh; Treatment Outcome","Robotic sacrocolpopexy has been rapidly incorporated into surgical practice without comprehensive and systematically published outcome data. The aim of this study was to systematically review the currently published peer-reviewed literature on robotic-assisted laparoscopic sacrocolpopexy with more than 6 months of anatomic outcome data. Studies were selected after applying predetermined inclusion and exclusion criteria to a MEDLINE search. Two independent reviewers blinded to each other's results abstracted demographic data, perioperative information, and postoperative outcomes. The primary outcome assessed was anatomic success rate defined as less than or equal to pelvic organ prolapse quantification system (POP-Q) stage 1. A random effects model was performed for the meta-analysis of selected outcomes. Thirteen studies were selected for the systematic review. Meta-analysis yielded a combined estimated success rate of 98.6% (95% confidence interval, 97.0%-100%). The combined estimated rate of mesh exposure/erosion was 4.1% (95% confidence interval, 1.4%-6.9%), and the rate of reoperation for mesh revision was 1.7%. The rates of reoperation for recurrent apical and nonapical prolapse were 0.8% and 2.5%, respectively. The most common surgical complication (excluding mesh erosion) was cystotomy (2.8%), followed by wound infection (2.4%). The outcomes of this analysis indicate that robotic sacrocolpopexy is an effective surgical treatment of apical prolapse with high anatomic cure rate and low rate of complications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21590,""
"Automated mapping of clinical terms into SNOMED-CT An application to codify procedures in pathology","Allones, Martinez, Taboada","https://doi.org/10.1007/s10916-014-0134-x","20150709","PubMed","Automation; Clinical Coding; National Library of Medicine (U.S.); Natural Language Processing; Pathology; Quality Improvement; Spain; Systematized Nomenclature of Medicine; United States","Clinical terminologies are considered a key technology for capturing clinical data in a precise and standardized manner, which is critical to accurately exchange information among different applications, medical records and decision support systems. An important step to promote the real use of clinical terminologies, such as SNOMED-CT, is to facilitate the process of finding mappings between local terms of medical records and concepts of terminologies. In this paper, we propose a mapping tool to discover text-to-concept mappings in SNOMED-CT. Name-based techniques were combined with a query expansion system to generate alternative search terms, and with a strategy to analyze and take advantage of the semantic relationships of the SNOMED-CT concepts. The developed tool was evaluated and compared to the search services provided by two SNOMED-CT browsers. Our tool automatically mapped clinical terms from a Spanish glossary of procedures in pathology with 88.0% precision and 51.4% recall, providing a substantial improvement of recall (28% and 60%) over other publicly accessible mapping services. The improvements reached by the mapping tool are encouraging. Our results demonstrate the feasibility of accurately mapping clinical glossaries to SNOMED-CT concepts, by means a combination of structural, query expansion and named-based techniques. We have shown that SNOMED-CT is a great source of knowledge to infer synonyms for the medical domain. Results show that an automated query expansion system overcomes the challenge of vocabulary mismatch partially.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21591,""
"Robotic versus laparoscopic right colectomy: a meta-analysis","Xu, Li, Sun, Li, Zhen, Wang, Xu","https://doi.org/10.1186/1477-7819-12-274","20150609","PubMed","Clinical Trials as Topic; Colectomy; Humans; Laparoscopy; Length of Stay; Outcome and Process Assessment, Health Care; Robotics","The objective of this meta-analysis was to compare the clinical safety and efficacy of robotic right colectomy (RRC) with conventional laparoscopic right colectomy (LRC). A literature search was performed for comparative studies reporting perioperative outcomes of RRC and LRC. The methodological quality of the selected studies was assessed. Depending on statistical heterogeneity, the fixed effects model or the random effects model were used for the meta-analysis. Operative time, estimated blood loss, length of hospital stay, conversion rates to open surgery, postoperative complications, and related outcomes were evaluated. Seven studies, including 234 RRC cases and 415 conventional LRC cases, were analyzed. The meta-analysis showed that RRC had longer operative times (PÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.00001), lower estimated blood losses (PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.0002), lower postoperative overall complications (PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.02), and significantly faster bowel function recovery (PÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°0.00001). There were no differences in the length of hospital stay (PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.12), conversion rates to open surgery (PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.48), postoperative ileus (PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.08), anastomosis leakage (PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.28), and bleeding (PÃ¢â‚¬â€°=Ã¢â‚¬â€°0.95). Compared to LRC, RRC was associated with reduced estimated blood losses, reduced postoperative complications, longer operative times, and a significantly faster recovery of bowel function. Other perioperative outcomes were equivalent.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21592,""
"LiverCancerMarkerRIF: a liver cancer biomarker interactive curation system combining text mining and expert annotations","Dai, Wu, Lin, Reyes, Dela Rosa, Syed-Abdul, Tsai, Hsu","https://doi.org/10.1093/database/bau085","20150220","PubMed","Biomarkers, Tumor; Computational Biology; Data Curation; Data Mining; Database Management Systems; Humans; Internet; Liver Neoplasms; User-Computer Interface","Biomarkers are biomolecules in the human body that can indicate disease states and abnormal biological processes. Biomarkers are often used during clinical trials to identify patients with cancers. Although biomedical research related to biomarkers has increased over the years and substantial effort has been expended to obtain results in these studies, the specific results obtained often contain ambiguities, and the results might contradict each other. Therefore, the information gathered from these studies must be appropriately integrated and organized to facilitate experimentation on biomarkers. In this study, we used liver cancer as the target and developed a text-mining-based curation system named LiverCancerMarkerRIF, which allows users to retrieve biomarker-related narrations and curators to curate supporting evidence on liver cancer biomarkers directly while browsing PubMed. In contrast to most of the other curation tools that require curators to navigate away from PubMed and accommodate distinct user interfaces or Web sites to complete the curation process, our system provides a user-friendly method for accessing text-mining-aided information and a concise interface to assist curators while they remain at the PubMed Web site. Biomedical text-mining techniques are applied to automatically recognize biomedical concepts such as genes, microRNA, diseases and investigative technologies, which can be used to evaluate the potential of a certain gene as a biomarker. Through the participation in the BioCreative IV user-interactive task, we examined the feasibility of using this novel type of augmented browsing-based curation method, and collaborated with curators to curate biomarker evidential sentences related to liver cancer. The positive feedback received from curators indicates that the proposed method can be effectively used for curation. A publicly available online database containing all the aforementioned information has been constructed at http://btm.tmu.edu.tw/livercancermarkerrif in an attempt to facilitate biomarker-related studies. http://btm.tmu.edu.tw/LiverCancerMarkerRIF/","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21593,""
"Evaluating the state of the art in disorder recognition and normalization of the clinical narrative","Pradhan, Elhadad, South, Martinez, Christensen, Vogel, Suominen, Chapman, Savova","https://doi.org/10.1136/amiajnl-2013-002544","20150518","PubMed","Clinical Notes; Disorder Identifciation; Information Extraction; Named Entity Recognition; Natural Language Processing; Word Sense Disambiguation; Biological Ontologies; Datasets as Topic; Disease; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Systematized Nomenclature of Medicine; Unified Medical Language System; Vocabulary, Controlled","The ShARe/CLEF eHealth 2013 Evaluation Lab Task 1 was organized to evaluate the state of the art on the clinical text in (i) disorder mention identification/recognition based on Unified Medical Language System (UMLS) definition (Task 1a) and (ii) disorder mention normalization to an ontology (Task 1b). Such a community evaluation has not been previously executed. Task 1a included a total of 22 system submissions, and Task 1b included 17. Most of the systems employed a combination of rules and machine learners. We used a subset of the Shared Annotated Resources (ShARe) corpus of annotated clinical text--199 clinical notes for training and 99 for testing (roughly 180Ã¢â‚¬â€¦K words in total). We provided the community with the annotated gold standard training documents to build systems to identify and normalize disorder mentions. The systems were tested on a held-out gold standard test set to measure their performance. For Task 1a, the best-performing system achieved an F1 score of 0.75 (0.80 precision; 0.71 recall). For Task 1b, another system performed best with an accuracy of 0.59. Most of the participating systems used a hybrid approach by supplementing machine-learning algorithms with features generated by rules and gazetteers created from the training data and from external resources. The task of disorder normalization is more challenging than that of identification. The ShARe corpus is available to the community as a reference standard for future studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21594,""
"An economic evaluation of maxillary implant overdentures based on six vs four implants","Listl, Fischer, Giannakopoulos","https://doi.org/10.1186/1472-6831-14-105","20141219","PubMed","Cost-Benefit Analysis; Decision Trees; Dental Implants; Dental Prosthesis, Implant-Supported; Dental Restoration Failure; Denture Retention; Denture, Complete, Upper; Denture, Overlay; Humans; Jaw, Edentulous; Markov Chains; Maxilla; Models, Economic; Monte Carlo Method; Patient Care Planning; Patient Preference; Patient Satisfaction; Probability; Treatment Outcome","The purpose of the present study was to assess the value for money achieved by bar-retained implant overdentures based on six implants compared with four implants as treatment alternatives for the edentulous maxilla. A Markov decision tree model was constructed and populated with parameter estimates for implant and denture failure as well as patient-centred health outcomes as available from recent literature. The decision scenario was modelled within a ten year time horizon and relied on cost reimbursement regulations of the German health care system. The cost-effectiveness threshold was identified above which the six-implant solution is preferable over the four-implant solution. Uncertainties regarding input parameters were incorporated via one-way and probabilistic sensitivity analysis based on Monte-Carlo simulation. Within a base case scenario of average treatment complexity, the cost-effectiveness threshold was identified to be 17,564 Ã¢â€šÂ¬ per year of denture satisfaction gained above of which the alternative with six implants is preferable over treatment including four implants. Sensitivity analysis yielded that, depending on the specification of model input parameters such as patients' denture satisfaction, the respective cost-effectiveness threshold varies substantially. The results of the present study suggest that bar-retained maxillary overdentures based on six implants provide better patient satisfaction than bar-retained overdentures based on four implants but are considerably more expensive. Final judgements about value for money require more comprehensive clinical evidence including patient-centred health outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21595,""
"""Big data"" and the electronic health record","Ross, Wei, Ohno-Machado","https://doi.org/10.15265/IY-2014-0003","20170508","PubMed","Electronic health records; data mining; natural language processing; privacy; quality improvement; security; Computational Biology; Data Mining; Decision Support Systems, Clinical; Electronic Health Records; Medical Records Systems, Computerized; Natural Language Processing; Pharmacovigilance; Social Media","Implementation of Electronic Health Record (EHR) systems continues to expand. The massive number of patient encounters results in high amounts of stored data. Transforming clinical data into knowledge to improve patient care has been the goal of biomedical informatics professionals for many decades, and this work is now increasingly recognized outside our field. In reviewing the literature for the past three years, we focus on ""big data"" in the context of EHR systems and we report on some examples of how secondary use of data has been put into practice. We searched PubMed database for articles from January 1, 2011 to November 1, 2013. We initiated the search with keywords related to ""big data"" and EHR. We identified relevant articles and additional keywords from the retrieved articles were added. Based on the new keywords, more articles were retrieved and we manually narrowed down the set utilizing predefined inclusion and exclusion criteria. Our final review includes articles categorized into the themes of data mining (pharmacovigilance, phenotyping, natural language processing), data application and integration (clinical decision support, personal monitoring, social media), and privacy and security. The increasing adoption of EHR systems worldwide makes it possible to capture large amounts of clinical data. There is an increasing number of articles addressing the theme of ""big data"", and the concepts associated with these articles vary. The next step is to transform healthcare big data into actionable knowledge.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21596,""
"Big data - smart health strategies Findings from the yearbook 2014 special theme","Koutkias, Thiessard","https://doi.org/10.15265/IY-2014-0031","20170508","PubMed","Big data; cloud computing; personalized medicine; smart health; strategies; Cloud Computing; Computational Biology; Data Mining; Databases, Factual; Electronic Health Records; Medical Informatics; Precision Medicine","To select best papers published in 2013 in the field of big data and smart health strategies, and summarize outstanding research efforts. A systematic search was performed using two major bibliographic databases for relevant journal papers. The references obtained were reviewed in a two-stage process, starting with a blinded review performed by the two section editors, and followed by a peer review process operated by external reviewers recognized as experts in the field. The complete review process selected four best papers, illustrating various aspects of the special theme, among them: (a) using large volumes of unstructured data and, specifically, clinical notes from Electronic Health Records (EHRs) for pharmacovigilance; (b) knowledge discovery via querying large volumes of complex (both structured and unstructured) biological data using big data technologies and relevant tools; (c) methodologies for applying cloud computing and big data technologies in the field of genomics, and (d) system architectures enabling high-performance access to and processing of large datasets extracted from EHRs. The potential of big data in biomedicine has been pinpointed in various viewpoint papers and editorials. The review of current scientific literature illustrated a variety of interesting methods and applications in the field, but still the promises exceed the current outcomes. As we are getting closer towards a solid foundation with respect to common understanding of relevant concepts and technical aspects, and the use of standardized technologies and tools, we can anticipate to reach the potential that big data offer for personalized medicine and smart health strategies in the near future.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21597,""
"Big data in medicine is driving big changes","Martin-Sanchez, Verspoor","https://doi.org/10.15265/IY-2014-0020","20170508","PubMed","Medical informatics; data mining; information storage and retrieval; information systems; text mining; Biomedical Research; Computational Biology; Data Mining; Databases, Factual; Humans; Medical Informatics; Social Media","To summarise current research that takes advantage of ""Big Data"" in health and biomedical informatics applications. Survey of trends in this work, and exploration of literature describing how large-scale structured and unstructured data sources are being used to support applications from clinical decision making and health policy, to drug design and pharmacovigilance, and further to systems biology and genetics. The survey highlights ongoing development of powerful new methods for turning that large-scale, and often complex, data into information that provides new insights into human health, in a range of different areas. Consideration of this body of work identifies several important paradigm shifts that are facilitated by Big Data resources and methods: in clinical and translational research, from hypothesis-driven research to data-driven research, and in medicine, from evidence-based practice to practice-based evidence. The increasing scale and availability of large quantities of health data require strategies for data management, data linkage, and data integration beyond the limits of many existing information systems, and substantial effort is underway to meet those needs. As our ability to make sense of that data improves, the value of the data will continue to increase. Health systems, genetics and genomics, population and public health; all areas of biomedicine stand to benefit from Big Data and the associated technologies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21598,""
"Structuring text and standardizing data for clinical and population health applications","Ohno-Machado","https://doi.org/10.1136/amiajnl-2014-003171","20141013","PubMed","Electronic Health Records; Natural Language Processing","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21599,""
"Texture feature analysis for computer-aided diagnosis on pulmonary nodules","Han, Wang, Zhang, Han, Song, Li, Moore, Lu, Zhao, Liang","https://doi.org/10.1007/s10278-014-9718-8","20151019","PubMed","Databases, Factual; Humans; Imaging, Three-Dimensional; Lung Neoplasms; Pattern Recognition, Automated; Principal Component Analysis; ROC Curve; Radiographic Image Interpretation, Computer-Assisted; Sensitivity and Specificity; Solitary Pulmonary Nodule; Tomography, X-Ray Computed","Differentiation of malignant and benign pulmonary nodules is of paramount clinical importance. Texture features of pulmonary nodules in CT images reflect a powerful character of the malignancy in addition to the geometry-related measures. This study first compared three well-known types of two-dimensional (2D) texture features (Haralick, Gabor, and local binary patterns or local binary pattern features) on CADx of lung nodules using the largest public database founded by Lung Image Database Consortium and Image Database Resource Initiative and then investigated extension from 2D to three-dimensional (3D) space. Quantitative comparison measures were made by the well-established support vector machine (SVM) classifier, the area under the receiver operating characteristic curves (AUC) and the p values from hypothesis t tests. While the three feature types showed about 90% differentiation rate, the Haralick features achieved the highest AUC value of 92.70% at an adequate image slice thickness, where a thinner or thicker thickness will deteriorate the performance due to excessive image noise or loss of axial details. Gain was observed when calculating 2D features on all image slices as compared to the single largest slice. The 3D extension revealed potential gain when an optimal number of directions can be found. All the observations from this systematic investigation study on the three feature types can lead to the conclusions that the Haralick feature type is a better choice, the use of the full 3D data is beneficial, and an adequate tradeoff between image thickness and noise is desired for an optimal CADx performance. These conclusions provide a guideline for further research on lung nodule differentiation using CT imaging.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21600,""
"Automated tissue classification framework for reproducible chronic wound assessment","Mukherjee, Manohar, Das, Achar, Mitra, Chakraborty","https://doi.org/10.1155/2014/851582","20150417","PubMed","Bayes Theorem; Burns; Chronic Disease; Diabetic Foot; Humans; Image Processing, Computer-Assisted; Photography; Support Vector Machine; Wounds and Injuries","The aim of this paper was to develop a computer assisted tissue classification (granulation, necrotic, and slough) scheme for chronic wound (CW) evaluation using medical image processing and statistical machine learning techniques. The red-green-blue (RGB) wound images grabbed by normal digital camera were first transformed into HSI (hue, saturation, and intensity) color space and subsequently the ""S"" component of HSI color channels was selected as it provided higher contrast. Wound areas from 6 different types of CW were segmented from whole images using fuzzy divergence based thresholding by minimizing edge ambiguity. A set of color and textural features describing granulation, necrotic, and slough tissues in the segmented wound area were extracted using various mathematical techniques. Finally, statistical learning algorithms, namely, Bayesian classification and support vector machine (SVM), were trained and tested for wound tissue classification in different CW images. The performance of the wound area segmentation protocol was further validated by ground truth images labeled by clinical experts. It was observed that SVM with 3rd order polynomial kernel provided the highest accuracies, that is, 86.94%, 90.47%, and 75.53%, for classifying granulation, slough, and necrotic tissues, respectively. The proposed automated tissue classification technique achieved the highest overall accuracy, that is, 87.61%, with highest kappa statistic value (0.793). ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21601,""
"NutriChem: a systems chemical biology resource to explore the medicinal value of plant-based foods","Jensen, Panagiotou, Kouskoumvekaki","https://doi.org/10.1093/nar/gku724","20150629","PubMed","Databases, Factual; Diet; Disease; Humans; Internet; Phenotype; Phytochemicals; Plants, Edible; Preventive Medicine","There is rising evidence of an inverse association between chronic diseases and diets characterized by rich fruit and vegetable consumption. Dietary components may act directly or indirectly on the human genome and modulate multiple processes involved in disease risk and disease progression. However, there is currently no exhaustive resource on the health benefits associated to specific dietary interventions, or a resource covering the broad molecular content of food. Here we present the first release of NutriChem, available at http://cbs.dtu.dk/services/NutriChem-1.0, a database generated by text mining of 21 million MEDLINE abstracts for information that links plant-based foods with their small molecule components and human disease phenotypes. NutriChem contains text-mined data for 18478 pairs of 1772 plant-based foods and 7898 phytochemicals, and 6242 pairs of 1066 plant-based foods and 751 diseases. In addition, it includes predicted associations for 548 phytochemicals and 252 diseases. To the best of our knowledge this database is the only resource linking the chemical space of plant-based foods with human disease phenotypes and provides a foundation for understanding mechanistically the consequences of eating behaviors on health. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21602,""
"Natural language processing of radiology reports for the detection of thromboembolic diseases and clinically relevant incidental findings","Pham, NÃƒÂ©vÃƒÂ©ol, Lavergne, Yasunaga, ClÃƒÂ©ment, Meyer, Morello, Burgun","https://doi.org/10.1186/1471-2105-15-266","20141012","PubMed","Algorithms; Computational Biology; Humans; Incidental Findings; Natural Language Processing; Pulmonary Embolism; Radiology; Research Report; Tomography, X-Ray Computed","Natural Language Processing (NLP) has been shown effective to analyze the content of radiology reports and identify diagnosis or patient characteristics. We evaluate the combination of NLP and machine learning to detect thromboembolic disease diagnosis and incidental clinically relevant findings from angiography and venography reports written in French. We model thromboembolic diagnosis and incidental findings as a set of concepts, modalities and relations between concepts that can be used as features by a supervised machine learning algorithm. A corpus of 573 radiology reports was de-identified and manually annotated with the support of NLP tools by a physician for relevant concepts, modalities and relations. A machine learning classifier was trained on the dataset interpreted by a physician for diagnosis of deep-vein thrombosis, pulmonary embolism and clinically relevant incidental findings. Decision models accounted for the imbalanced nature of the data and exploited the structure of the reports. The best model achieved an F measure of 0.98 for pulmonary embolism identification, 1.00 for deep vein thrombosis, and 0.80 for incidental clinically relevant findings. The use of concepts, modalities and relations improved performances in all cases. This study demonstrates the benefits of developing an automated method to identify medical concepts, modality and relations from radiology reports in French. An end-to-end automatic system for annotation and classification which could be applied to other radiology reports databases would be valuable for epidemiological surveillance, performance monitoring, and accreditation in French hospitals.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21603,""
"Feasibility and user perception of a fully automated push-based multiple-session alcohol intervention for university students: randomized controlled trial","Bendtsen, Bendtsen","https://doi.org/10.2196/mhealth.3233","20140807","PubMed","SMS; alcohol intervention; email; multiple-session intervention; push-based intervention; students; text messages","In recent years, many electronic health behavior interventions have been developed in order to reach individuals with unhealthy behaviors, such as risky drinking. This is especially relevant for university students, many of whom are risky drinkers. This study explored the acceptability and feasibility in a nontreatment-seeking group of university students (including both risk and nonrisk drinkers), of a fully automated, push-based, multiple-session, alcohol intervention, comparing two modes of delivery by randomizing participants to receive the intervention either by SMS text messaging (short message service, SMS) or by email. A total of 5499 students at LuleÃƒÂ¥ University in northern Sweden were invited to participate in a single-session alcohol assessment and feedback intervention; 28.04% (1542/5499) students completed this part of the study. In total, 29.44% (454/1542) of those participating in the single-session intervention accepted to participate further in the extended multiple-session intervention lasting for 4 weeks. The students were randomized to receive the intervention messages via SMS or email. A follow-up questionnaire was sent immediately after the intervention and 52.9% (240/454) responded. No difference was seen regarding satisfaction with the length and frequency of the intervention, regardless of the mode of delivery. Approximately 15% in both the SMS (19/136) and email groups (15/104) would have preferred the other mode of delivery. On the other hand, more students in the SMS group (46/229, 20.1%) stopped participating in the intervention during the 4-week period compared with the email group (10/193, 5.2%). Most students in both groups expressed satisfaction with the content of the messages and would recommend the intervention to a fellow student in need of reducing drinking. A striking difference was seen regarding when a message was read; 88.2% (120/136) of the SMS group read the messages within 1 hour in contrast to 45.2% (47/104) in the email group. In addition, 83.1% (113/136) in the SMS group stated that they read all or almost all the messages, compared with only 63.5% (66/104) in the email group. Based on the feedback from the students, an extended, multiple-session, push-based intervention seems to be a feasible option for students interested in additional support after a single-session alcohol intervention. SMS as a mode of delivery seems to have some advantages over email regarding when a message is read and the proportion of messages read. However, more students in the SMS group stopped the intervention than in the email group. Based on these promising findings, further studies comparing the effectiveness of single-session interventions with extended multiple-session interventions delivered separately or in combination are warranted.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21604,""
"Technologies as support tools for persons with autistic spectrum disorder: a systematic review","Aresti-Bartolome, Garcia-Zapirain","https://doi.org/10.3390/ijerph110807767","20150331","PubMed","Child Development Disorders, Pervasive; Communication; Humans; Imitative Behavior; Learning; Robotics; Social Behavior; Telemedicine; Virtual Reality Exposure Therapy","This study analyzes the technologies most widely used to work on areas affected by the Autistic Spectrum Disorder (ASD). Technologies can focus on the strengths and weaknesses of this disorder as they make it possible to create controlled environments, reducing the anxiety produced by real social situations. Extensive research has proven the efficiency of technologies as support tools for therapy and their acceptation by ASD sufferers and the people who are with them on a daily basis. This article is organized by the types of systems developed: virtual reality applications, telehealth systems, social robots and dedicated applications, all of which are classified by the areas they center on: communication, social learning and imitation skills and other ASD-associated conditions. 40.5% of the research conducted is found to be focused on communication as opposed to 37.8% focused on learning and social imitation skills and 21.6% which underlines problems associated with this disorder. Although most of the studies reveal how useful these tools are in therapy, they are generic tools for ASD sufferers in general, which means there is a lack of personalised tools to meet each person's needs. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21605,""
"Generalising semantic category disambiguation with large lexical resources for fun and profit","Stenetorp, Pyysalo, Ananiadou, Tsujii","https://doi.org/10.1186/2041-1480-5-26","20140805","PubMed","Approximate string matching; Domain adaptation; Freebase; Lexical resources; Named entity recognition; Semantic category disambiguation","Semantic Category Disambiguation (SCD) is the task of assigning the appropriate semantic category to given spans of text from a fixed set of candidate categories, for example Protein to ""Fibrin"". SCD is relevant to Natural Language Processing tasks such as Named Entity Recognition, coreference resolution and coordination resolution. In this work, we study machine learning-based SCD methods using large lexical resources and approximate string matching, aiming to generalise these methods with regard to domains, lexical resources and the composition of data sets. We specifically consider the applicability of SCD for the purposes of supporting human annotators and acting as a pipeline component for other Natural Language Processing systems. While previous research has mostly cast SCD purely as a classification task, we consider a task setting that allows for multiple semantic categories to be suggested, aiming to minimise the number of suggestions while maintaining high recall. We argue that this setting reflects aspects which are essential for both a pipeline component and when supporting human annotators. We introduce an SCD method based on a recently introduced machine learning-based system and evaluate it on 15 corpora covering biomedical, clinical and newswire texts and ranging in the number of semantic categories from 2 to 91. With appropriate settings, our system maintains an average recall of 99% while reducing the number of candidate semantic categories on average by 65% over all data sets. Machine learning-based SCD using large lexical resources and approximate string matching is sensitive to the selection and granularity of lexical resources, but generalises well to a wide range of text domains and data sets given appropriate resources and parameter settings. By substantially reducing the number of candidate categories while only very rarely excluding the correct one, our method is shown to be applicable to manual annotation support tasks and use as a high-recall component in text processing pipelines. The introduced system and all related resources are freely available for research purposes at: https://github.com/ninjin/simsem.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21606,""
"Comparison of warfarin therapy clinical outcomes following implementation of an automated mobile phone-based critical laboratory value text alert system","Lin, Kang, Lin, Lee, Wu, Chen, Tseng","https://doi.org/10.1186/1755-8794-7-S1-S13","20150330","PubMed","Adult; Aged; Aged, 80 and over; Anticoagulants; Attitude of Health Personnel; Automation; Clinical Laboratory Techniques; Drug Dosage Calculations; Drug Monitoring; Drug Prescriptions; Hemorrhage; Hospitals, Teaching; Humans; Male; Middle Aged; Patient Safety; Physicians; Prothrombin Time; Reminder Systems; Retrospective Studies; Text Messaging; Treatment Outcome; Warfarin; Young Adult","Computerized alert and reminder systems have been widely accepted and applied to various patient care settings, with increasing numbers of clinical laboratories communicating critical laboratory test values to professionals via either manual notification or automated alerting systems/computerized reminders. Warfarin, an oral anticoagulant, exhibits narrow therapeutic range between treatment response and adverse events. It requires close monitoring of prothrombin time (PT)/international normalized ratio (INR) to ensure patient safety. This study was aimed to evaluate clinical outcomes of patients on warfarin therapy following implementation of a Personal Handy-phone System-based (PHS) alert system capable of generating and delivering text messages to communicate critical PT/INR laboratory results to practitioners' mobile phones in a large tertiary teaching hospital. A retrospective analysis was performed comparing patient clinical outcomes and physician prescribing behavior following conversion from a manual laboratory result alert system to an automated system. Clinical outcomes and practitioner responses to both alert systems were compared. Complications to warfarin therapy, warfarin utilization, and PT/INR results were evaluated for both systems, as well as clinician time to read alert messages, time to warfarin therapy modification, and monitoring frequency. No significant differences were detected in major hemorrhage and thromboembolism, warfarin prescribing patterns, PT/INR results, warfarin therapy modification, or monitoring frequency following implementation of the PHS text alert system. In both study periods, approximately 80% of critical results led to warfarin discontinuation or dose reduction. Senior physicians' follow-up response time to critical results was significantly decreased in the PHS alert study period (46.3% responded within 1 day) compared to the manual notification study period (24.7%; P = 0.015). No difference in follow-up response time was detected for junior physicians. Implementation of an automated PHS-based text alert system did not adversely impact clinical or safety outcomes of patients on warfarin therapy. Approximately 80% immediate recognition of text alerts was achieved. The potential benefits of an automated PHS alert for senior physicians were demonstrated.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21607,""
"Automated real-time text messaging as a means for rapidly identifying acute stroke patients for clinical trials","Jegzentis, Nowe, Brunecker, Endres, Haferkorn, Ploner, Steinbrink, Jungehulsing","https://doi.org/10.1186/1745-6215-15-304","20151030","PubMed","Aged; Aged, 80 and over; Algorithms; Automation; Clinical Trials as Topic; Emergency Service, Hospital; Female; Hospital Information Systems; Humans; Male; Middle Aged; Stroke; Text Messaging; Time Factors","Recruiting stroke patients into acute treatment trials is challenging because of the urgency of clinical diagnosis, treatment, and trial inclusion. Automated alerts that identify emergency patients promptly may improve trial performance. The main purposes of this project were to develop an automated real-time text messaging system to immediately inform physicians of patients with suspected stroke and to test its feasibility in the emergency setting. An electronic standardized stroke algorithm (SSA) was implemented in the clinical information system (CIS) and linked to a remote data capture system. Within 10 minutes following the documentation and storage of basic information to CIS, a text message was triggered for patients with suspected stroke and sent to a dedicated trial physician. Each text message provided anonymized information on the exact department and unit, date and time of admission, age, sex, and National Institute of Health Stroke Scale (NIHSS) of the patient. All necessary information needed to generate a text message was already available - routine processes in the emergency department were not affected by the automated real-time text messaging system. The system was tested for three 4-week periods. Feasibility was analyzed based on the number of patients correctly identified by the SSA and the door-to-message time. In total, 513 text messages were generated for patients with suspected stroke (median age 74 years (19-106); 50.3% female; median NIHSS 4 (0-41)), representing 96.6% of all cases. For 48.3% of these text messages, basic documentation was completed within less than 1 hour and a text message was sent within 60 minutes after patient admission. The system proved to be stable in generating text messages using IT-based CIS to identify acute stroke trial patients. The system operated on information which is documented routinely and did not result in a higher workload. Delays between patient admission and the text message were caused by delayed completion of basic documentation. To use the automated real-time text messaging system to immediately identify emergency patients suitable for acute stroke trials, further development needs to focus on eliminating delays in documentation for the SSA in the emergency department.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21608,""
"Finding pathway-modulating genes from a novel Ontology Fingerprint-derived gene network","Qin, Matmati, Tsoi, Mohanty, Gao, Tang, Lawson, Hannun, Zheng","https://doi.org/10.1093/nar/gku678","20150115","PubMed","Bayes Theorem; Gene Ontology; Gene Regulatory Networks; Genes, Fungal; Metabolic Networks and Pathways; PubMed; Sphingolipids; Yeasts","To enhance our knowledge regarding biological pathway regulation, we took an integrated approach, using the biomedical literature, ontologies, network analyses and experimental investigation to infer novel genes that could modulate biological pathways. We first constructed a novel gene network via a pairwise comparison of all yeast genes' Ontology Fingerprints--a set of Gene Ontology terms overrepresented in the PubMed abstracts linked to a gene along with those terms' corresponding enrichment P-values. The network was further refined using a Bayesian hierarchical model to identify novel genes that could potentially influence the pathway activities. We applied this method to the sphingolipid pathway in yeast and found that many top-ranked genes indeed displayed altered sphingolipid pathway functions, initially measured by their sensitivity to myriocin, an inhibitor of de novo sphingolipid biosynthesis. Further experiments confirmed the modulation of the sphingolipid pathway by one of these genes, PFA4, encoding a palmitoyl transferase. Comparative analysis showed that few of these novel genes could be discovered by other existing methods. Our novel gene network provides a unique and comprehensive resource to study pathway modulations and systems biology in general.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21609,""
"MÃƒÂ¡s-o-menos: a simple sign averaging method for discrimination in genomic data analysis","Zhao, Parmigiani, Huttenhower, Waldron","https://doi.org/10.1093/bioinformatics/btu488","20150109","PubMed","Algorithms; Breast Neoplasms; Female; Gene Expression Profiling; Genomics; Humans; Ovarian Neoplasms; Survival Analysis; Urinary Bladder Neoplasms","The successful translation of genomic signatures into clinical settings relies on good discrimination between patient subgroups. Many sophisticated algorithms have been proposed in the statistics and machine learning literature, but in practice simpler algorithms are often used. However, few simple algorithms have been formally described or systematically investigated. We give a precise definition of a popular simple method we refer to as mÃƒÂ¡s-o-menos, which calculates prognostic scores for discrimination by summing standardized predictors, weighted by the signs of their marginal associations with the outcome. We study its behavior theoretically, in simulations and in an extensive analysis of 27 independent gene expression studies of bladder, breast and ovarian cancer, altogether totaling 3833 patients with survival outcomes. We find that despite its simplicity, mÃƒÂ¡s-o-menos can achieve good discrimination performance. It performs no worse, and sometimes better, than popular and much more CPU-intensive methods for discrimination, including lasso and ridge regression. MÃƒÂ¡s-o-menos is implemented for survival analysis as an option in the survHD package, available from http://www.bitbucket.org/lwaldron/survhd and submitted to Bioconductor.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21610,""
"In search of neural endophenotypes of postpartum psychopathology and disrupted maternal caregiving","Moses-Kolko, Horner, Phillips, Hipwell, Swain","https://doi.org/10.1111/jne.12183","20150520","PubMed","attachment; brain imaging; caregiving; postpartum depression; Caregivers; Depression, Postpartum; Female; Humans; Magnetic Resonance Imaging; Mothers; Phenotype; Pregnancy","This is a selective review that provides the context for the study of perinatal affective disorder mechanisms and outlines directions for future research. We integrate existing literature along neural networks of interest for affective disorders and maternal caregiving: (i) the salience/fear network; (ii) the executive network; (iii) the reward/social attachment network; and (iv) the default mode network. Extant salience/fear network research reveals disparate responses and corticolimbic coupling to various stimuli based upon a predominantly depressive versus anxious (post-traumatic stress disorder) clinical phenotype. Executive network and default mode connectivity abnormalities have been described in postpartum depression (PPD), although studies are very limited in these domains. Reward/social attachment studies confirm a robust ventral striatal response to infant stimuli, including cry and happy infant faces, which is diminished in depressed, insecurely attached and substance-using mothers. The adverse parenting experiences received and the attachment insecurity of current mothers are factors that are associated with a diminution in infant stimulus-related neural activity similar to that in PPD, and raise the need for additional studies that integrate mood and attachment concepts in larger study samples. Several studies examining functional connectivity in resting state and emotional activation functional magnetic resonance imaging paradigms have revealed attenuated corticolimbic connectivity, which remains an important outcome that requires dissection with increasing precision to better define neural treatment targets. Methodological progress is expected in the coming years in terms of refining clinical phenotypes of interest and experimental paradigms, as well as enlarging samples to facilitate the examination of multiple constructs. Functional imaging promises to determine neural mechanisms underlying maternal psychopathology and impaired caregiving, such that earlier and more precise detection of abnormalities will be possible. Ultimately, the discovery of such mechanisms will promote the refinement of treatment approaches toward maternal affective disturbance, parenting behaviours and the augmentation of parenting resiliency. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21611,""
"Using informatics and the electronic medical record to describe antimicrobial use in the clinical management of diarrhea cases at 12 companion animal practices","Anholt, Berezowski, Ribble, Russell, Stephen","https://doi.org/10.1371/journal.pone.0103190","20160118","PubMed","Animals; Anti-Infective Agents; Canada; Clinical Laboratory Techniques; Data Mining; Diagnosis, Differential; Diarrhea; Electronic Health Records; Humans; Medical Informatics; Pets; Practice Patterns, Physicians'; Veterinarians","Antimicrobial drugs may be used to treat diarrheal illness in companion animals. It is important to monitor antimicrobial use to better understand trends and patterns in antimicrobial resistance. There is no monitoring of antimicrobial use in companion animals in Canada. To explore how the use of electronic medical records could contribute to the ongoing, systematic collection of antimicrobial use data in companion animals, anonymized electronic medical records were extracted from 12 participating companion animal practices and warehoused at the University of Calgary. We used the pre-diagnostic, clinical features of diarrhea as the case definition in this study. Using text-mining technologies, cases of diarrhea were described by each of the following variables: diagnostic laboratory tests performed, the etiological diagnosis and antimicrobial therapies. The ability of the text miner to accurately describe the cases for each of the variables was evaluated. It could not reliably classify cases in terms of diagnostic tests or etiological diagnosis; a manual review of a random sample of 500 diarrhea cases determined that 88/500 (17.6%) of the target cases underwent diagnostic testing of which 36/88 (40.9%) had an etiological diagnosis. Text mining, compared to a human reviewer, could accurately identify cases that had been treated with antimicrobials with high sensitivity (92%, 95% confidence interval, 88.1%-95.4%) and specificity (85%, 95% confidence interval, 80.2%-89.1%). Overall, 7400/15,928 (46.5%) of pets presenting with diarrhea were treated with antimicrobials. Some temporal trends and patterns of the antimicrobial use are described. The results from this study suggest that informatics and the electronic medical records could be useful for monitoring trends in antimicrobial use. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21612,""
"A methodology for a minimum data set for rare diseases to support national centers of excellence for healthcare and research","Choquet, Maaroufi, de Carrara, Messiaen, Luigi, Landais","https://doi.org/10.1136/amiajnl-2014-002794","20150518","PubMed","common data elements; interoperability; metadata; minimum data set; national health program; rare diseases; Biomedical Research; Common Data Elements; Data Collection; Datasets as Topic; France; Humans; Rare Diseases; Systems Integration","Although rare disease patients make up approximately 6-8% of all patients in Europe, it is often difficult to find the necessary expertise for diagnosis and care and the patient numbers needed for rare disease research. The second French National Plan for Rare Diseases highlighted the necessity for better care coordination and epidemiology for rare diseases. A clinical data standard for normalization and exchange of rare disease patient data was proposed. The original methodology used to build the French national minimum data set (F-MDS-RD) common to the 131 expert rare disease centers is presented. To encourage consensus at a national level for homogeneous data collection at the point of care for rare disease patients, we first identified four national expert groups. We reviewed the scientific literature for rare disease common data elements (CDEs) in order to build the first version of the F-MDS-RD. The French rare disease expert centers validated the data elements (DEs). The resulting F-MDS-RD was reviewed and approved by the National Plan Strategic Committee. It was then represented in an HL7 electronic format to maximize interoperability with electronic health records. The F-MDS-RD is composed of 58 DEs in six categories: patient, family history, encounter, condition, medication, and questionnaire. It is HL7 compatible and can use various ontologies for diagnosis or sign encoding. The F-MDS-RD was aligned with other CDE initiatives for rare diseases, thus facilitating potential interconnections between rare disease registries. The French F-MDS-RD was defined through national consensus. It can foster better care coordination and facilitate determining rare disease patients' eligibility for research studies, trials, or cohorts. Since other countries will need to develop their own standards for rare disease data collection, they might benefit from the methods presented here.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21613,""
"Fully automated production of diverse 18F-labeled PET tracers on the ELIXYS multireactor radiosynthesizer without hardware modification","Lazari, Collins, Shen, Farhoud, Yeh, Maraglia, Chin, Nathanson, Moore, van Dam","https://doi.org/10.2967/jnmt.114.140392","20150522","PubMed","18F-FAC; 18F-FEAU; 18F-FMAU; automated radiosynthesis; radiochemistry kits; Animals; Chemistry Techniques, Synthetic; Chromatography, High Pressure Liquid; Female; Fluorodeoxyglucose F18; Mice; Mice, Inbred BALB C; Positron-Emission Tomography; Quality Control; Radiopharmaceuticals; Software; Whole Body Imaging","Fully automated radiosynthesizers are continuing to be developed to meet the growing need for the reliable production of PET tracers made under current good manufacturing practice guidelines. There is a current trend toward supporting kitlike disposable cassettes that come preconfigured for particular tracers, thus eliminating the need for cleaning protocols between syntheses and enabling quick transitions to synthesizing other tracers. Though ideal for production, these systems are often limited for the development of novel tracers because of pressure, temperature, and chemical compatibility considerations. This study demonstrated the versatile use of the ELIXYS fully automated radiosynthesizer to adapt and produce 8 different (18)F-labeled PET tracers of varying complexity. Three-reactor syntheses of 2-deoxy-2-(18)F-fluoro-ÃŽÂ²-d-arabinofuranosylcytosine (d-(18)F-FAC), 2-deoxy-2-(18)F-fluoro-5-methyl-ÃŽÂ²-l-arabinofuranosyluracil (l-(18)F-FMAU), and 2-deoxy-2-(18)F-fluoro-5-ethyl-ÃŽÂ²-d-arabinofuranosyluracil (d-(18)F-FEAU) along with the 1-reactor syntheses of d-(18)F-FEAU, (18)F-FDG, 3-deoxy-3-(18)F-fluoro-l-thymidine ((18)F-FLT), (18)F-fallypride, 9-(4-(18)F-fluoro-3-hydroxymethylbutyl)-guanine ((18)F-FHBG), and N-succinimidyl-4-(18)F-fluorobenzoate ((18)F-SFB), were all produced using ELIXYS without the need for any hardware modifications or reconfiguration. Synthesis protocols were adapted and slightly modified from those in the literature but were not fully optimized. Furthermore, (18)F-FLT, (18)F-FDG, and (18)F-fallypride were produced sequentially on the same day and used for preclinical imaging of A431 tumor-bearing severe combined immunodeficient mice and wild-type BALB/c mice. To assess future translation to the clinical setting, several batches of tracers were subjected to a full set of quality control tests. All tracers were produced with radiochemical yields comparable to those in the literature. (18)F-FLT, (18)F-FDG, and (18)F-fallypride were successfully used to image the mice, with results consistent with those reported in the literature. All tracers that were subjected to clinical quality control tests passed. The ELIXYS radiosynthesizer facilitates rapid tracer development and is capable of producing multiple (18)F-labeled PET tracers suitable for clinical applications using the same hardware setup.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21614,""
"How are medical students trained to locate biomedical information to practice evidence-based medicine? A review of the 2007-2012 literature","Maggio, Kung","https://doi.org/10.3163/1536-5050.102.3.008","20150410","PubMed","Australia; Curriculum; Czech Republic; Education, Medical, Undergraduate; Evidence-Based Medicine; Health Knowledge, Attitudes, Practice; Humans; Information Storage and Retrieval; Iran; Periodicals as Topic; Students, Medical; Teaching; United States","This study describes how information retrieval skills are taught in evidence-based medicine (EBM) at the undergraduate medical education (UGME) level. The authors systematically searched MEDLINE, Scopus, Educational Resource Information Center, Web of Science, and Evidence-Based Medicine Reviews for English-language articles published between 2007 and 2012 describing information retrieval training to support EBM. Data on learning environment, frequency of training, learner characteristics, resources and information skills taught, teaching modalities, and instructor roles were compiled and analyzed. Twelve studies were identified for analysis. Studies were set in the United States (9), Australia (1), the Czech Republic (1), and Iran (1). Most trainings (7) featured multiple sessions with trainings offered to preclinical students (5) and clinical students (6). A single study described a longitudinal training experience. A variety of information resources were introduced, including PubMed, DynaMed, UpToDate, and AccessMedicine. The majority of the interventions (10) were classified as interactive teaching sessions in classroom settings. Librarians played major and collaborative roles with physicians in teaching and designing training. Unfortunately, few studies provided details of information skills activities or evaluations, making them difficult to evaluate and replicate. This study reviewed the literature and characterized how EBM search skills are taught in UGME. Details are provided on learning environment, frequency of training, level of learners, resources and skills trained, and instructor roles. The results suggest a number of steps that librarians can take to improve information skills training including using a longitudinal approach, integrating consumer health resources, and developing robust assessments.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21615,""
"Potential therapeutic targets for oral cancer: ADM, TP53, EGFR, LYN, CTLA4, SKIL, CTGF, CD70","Bundela, Sharma, Bisen","https://doi.org/10.1371/journal.pone.0102610","20151123","PubMed","Adrenomedullin; CD27 Ligand; CTLA-4 Antigen; Connective Tissue Growth Factor; Data Mining; Drug Delivery Systems; ErbB Receptors; Gene Expression Profiling; Gene Expression Regulation, Neoplastic; Humans; India; Intracellular Signaling Peptides and Proteins; Male; Molecular Sequence Annotation; Mouth Neoplasms; Neoplasm Proteins; Proto-Oncogene Proteins; Tumor Suppressor Protein p53; src-Family Kinases","In India, oral cancer has consistently ranked among top three causes of cancer-related deaths, and it has emerged as a top cause for the cancer-related deaths among men. Lack of effective therapeutic options is one of the main challenges in clinical management of oral cancer patients. We interrogated large pool of samples from oral cancer gene expression studies to identify potential therapeutic targets that are involved in multiple cancer hallmark events. Therapeutic strategies directed towards such targets can be expected to effectively control cancer cells. Datasets from different gene expression studies were integrated by removing batch-effects and was used for downstream analyses, including differential expression analysis. Dependency network analysis was done to identify genes that undergo marked topological changes in oral cancer samples when compared with control samples. Causal reasoning analysis was carried out to identify significant hypotheses, which can explain gene expression profiles observed in oral cancer samples. Text-mining based approach was used to detect cancer hallmarks associated with genes significantly expressed in oral cancer. In all, 2365 genes were detected to be differentially expressed genes, which includes some of the highly differentially expressed genes like matrix metalloproteinases (MMP-1/3/10/13), chemokine (C-X-C motif) ligands (IL8, CXCL-10/-11), PTHLH, SERPINE1, NELL2, S100A7A, MAL, CRNN, TGM3, CLCA4, keratins (KRT-3/4/13/76/78), SERPINB11 and serine peptidase inhibitors (SPINK-5/7). XIST, TCEAL2, NRAS and FGFR2 are some of the important genes detected by dependency and causal network analysis. Literature mining analysis annotated 1014 genes, out of which 841 genes were statistically significantly annotated. The integration of output of various analyses, resulted in the list of potential therapeutic targets for oral cancer, which included targets such as ADM, TP53, EGFR, LYN, CTLA4, SKIL, CTGF and CD70. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21616,""
"Representation of information about family relatives as structured data in electronic health records","Zhou, Lu, Vitale, Mar, Chang, Dhopeshwarkar, Rocha","https://doi.org/10.4338/ACI-2013-10-RA-0080","20150227","PubMed","HL7; SNOMED; Terminology; electronic health records; family history; natural language processing; Adult; Electronic Health Records; Family Relations; Female; Humans; Male; Medical Informatics; Natural Language Processing; Terminology as Topic","The ability to manage and leverage family history information in the electronic health record (EHR) is crucial to delivering high-quality clinical care. We aimed to evaluate existing standards in representing relative information, examine this information documented in EHRs, and develop a natural language processing (NLP) application to extract relative information from free-text clinical documents. We reviewed a random sample of 100 admission notes and 100 discharge summaries of 198 patients, and also reviewed the structured entries for these patients in an EHR system's family history module. We investigated the two standards used by Stage 2 of Meaningful Use (SNOMED CT and HL7 Family History Standard) and identified coverage gaps of each standard in coding relative information. Finally, we evaluated the performance of the MTERMS NLP system in identifying relative information from free-text documents. The structure and content of SNOMED CT and HL7 for representing relative information are different in several ways. Both terminologies have high coverage to represent local relative concepts built in an ambulatory EHR system, but gaps in key concept coverage were detected; coverage rates for relative information in free-text clinical documents were 95.2% and 98.6%, respectively. Compared to structured entries, richer family history information was only available in free-text documents. Using a comprehensive lexicon that included concepts and terms of relative information from different sources, we expanded the MTERMS NLP system to extract and encode relative information in clinical documents and achieved a corresponding precision of 100% and recall of 97.4%. Comprehensive assessment and user guidance are critical to adopting standards into EHR systems in a meaningful way. A significant portion of patients' family history information is only documented in free-text clinical documents and NLP can be used to extract this information.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21617,""
"Fast spectroscopic multiple analysis (FASMA) for brain tumor classification: a clinical decision support system utilizing multi-parametric 3T MR data","Tsolaki, Svolos, Kousi, Kapsalaki, Fezoulidis, Fountas, Theodorou, Kappas, Tsougos","https://doi.org/10.1007/s11548-014-1088-7","20160223","PubMed","Brain; Brain Neoplasms; Decision Support Systems, Clinical; Glioma; Humans; Magnetic Resonance Imaging; Magnetic Resonance Spectroscopy; Support Vector Machine","A clinical decision support system (CDSS) for brain tumor classification can be used to assist in the diagnosis and grading of brain tumors. A Fast Spectroscopic Multiple Analysis (FASMA) system that uses combinations of multiparametric MRI data sets was developed as a CDSS for brain tumor classification. MRI metabolic ratios and spectra, from long and short TE, respectively, as well as diffusion and perfusion data were acquired from the intratumoral and peritumoral area of 126 patients with untreated intracranial tumors. These data were categorized based on the pathology, and different machine learning methods were evaluated regarding their classification performance for glioma grading and differentiation of infiltrating versus non-infiltrating lesions. Additional databases were embedded to the system, including updated literature values of the related MR parameters and typical tumor characteristics (imaging and histological), for further comparisons. Custom Graphical User Interface (GUI) layouts were developed to facilitate classification of the unknown cases based on the user's available MR data. The highest classification performance was achieved with a support vector machine (SVM) using the combination of all MR features. FASMA correctly classified 89 and 79% in the intratumoral and peritumoral area, respectively, for cases from an independent test set. FASMA produced the correct diagnosis, even in the misclassified cases, since discrimination between infiltrative versus non-infiltrative cases was possible. FASMA is a prototype CDSS, which integrates complex quantitative MR data for brain tumor characterization. FASMA was developed as a diagnostic assistant that provides fast analysis, representation and classification for a set of MR parameters. This software may serve as a teaching tool on advanced MRI techniques, as it incorporates additional information regarding typical tumor characteristics derived from the literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21618,""
"A brain centred view of psychiatric comorbidity in tinnitus: from otology to hodology","Salviati, Bersani, Valeriani, Minichino, Panico, Romano, Mazzei, Testugini, Altissimi, Cianfrone","https://doi.org/10.1155/2014/817852","20141006","PubMed","Animals; Auditory Cortex; Brain; Diffusion Tensor Imaging; Electroencephalography; Humans; Magnetic Resonance Imaging; Magnetoencephalography; Mental Disorders; Positron-Emission Tomography; Prefrontal Cortex; Tinnitus","Introduction. Comorbid psychiatric disorders are frequent among patients affected by tinnitus. There are mutual clinical influences between tinnitus and psychiatric disorders, as well as neurobiological relations based on partially overlapping hodological and neuroplastic phenomena. The aim of the present paper is to review the evidence of alterations in brain networks underlying tinnitus physiopathology and to discuss them in light of the current knowledge of the neurobiology of psychiatric disorders. Methods. Relevant literature was identified through a search on Medline and PubMed; search terms included tinnitus, brain, plasticity, cortex, network, and pathways. Results. Tinnitus phenomenon results from systemic-neurootological triggers followed by neuronal remapping within several auditory and nonauditory pathways. Plastic reorganization and white matter alterations within limbic system, arcuate fasciculus, insula, salience network, dorsolateral prefrontal cortex, auditory pathways, ffrontocortical, and thalamocortical networks are discussed. Discussion. Several overlapping brain network alterations do exist between tinnitus and psychiatric disorders. Tinnitus, initially related to a clinicoanatomical approach based on a cortical localizationism, could be better explained by an holistic or associationist approach considering psychic functions and tinnitus as emergent properties of partially overlapping large-scale neural networks. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21619,""
"Training modalities in robot-mediated upper limb rehabilitation in stroke: a framework for classification based on a systematic review","Basteris, Nijenhuis, Stienen, Buurke, Prange, Amirabdollahian","https://doi.org/10.1186/1743-0003-11-111","20150915","PubMed","Exercise Therapy; Humans; Robotics; Stroke Rehabilitation; Upper Extremity","Robot-mediated post-stroke therapy for the upper-extremity dates back to the 1990s. Since then, a number of robotic devices have become commercially available. There is clear evidence that robotic interventions improve upper limb motor scores and strength, but these improvements are often not transferred to performance of activities of daily living. We wish to better understand why. Our systematic review of 74 papers focuses on the targeted stage of recovery, the part of the limb trained, the different modalities used, and the effectiveness of each. The review shows that most of the studies so far focus on training of the proximal arm for chronic stroke patients. About the training modalities, studies typically refer to active, active-assisted and passive interaction. Robot-therapy in active assisted mode was associated with consistent improvements in arm function. More specifically, the use of HRI features stressing active contribution by the patient, such as EMG-modulated forces or a pushing force in combination with spring-damper guidance, may be beneficial.Our work also highlights that current literature frequently lacks information regarding the mechanism about the physical human-robot interaction (HRI). It is often unclear how the different modalities are implemented by different research groups (using different robots and platforms). In order to have a better and more reliable evidence of usefulness for these technologies, it is recommended that the HRI is better described and documented so that work of various teams can be considered in the same group and categories, allowing to infer for more suitable approaches. We propose a framework for categorisation of HRI modalities and features that will allow comparing their therapeutic benefits. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21620,""
"Text mining of cancer-related information: review of current status and future directions","SpasiÃ„â€¡, Livsey, Keane, NenadiÃ„â€¡","https://doi.org/10.1016/j.ijmedinf.2014.06.009","20150330","PubMed","Cancer; Data mining; Electronic medical records; Natural language processing; Computational Biology; Data Mining; Humans; Information Storage and Retrieval; Medical Oncology; Neoplasms","This paper reviews the research literature on text mining (TM) with the aim to find out (1) which cancer domains have been the subject of TM efforts, (2) which knowledge resources can support TM of cancer-related information and (3) to what extent systems that rely on knowledge and computational methods can convert text data into useful clinical information. These questions were used to determine the current state of the art in this particular strand of TM and suggest future directions in TM development to support cancer research. A review of the research on TM of cancer-related information was carried out. A literature search was conducted on the Medline database as well as IEEE Xplore and ACM digital libraries to address the interdisciplinary nature of such research. The search results were supplemented with the literature identified through Google Scholar. A range of studies have proven the feasibility of TM for extracting structured information from clinical narratives such as those found in pathology or radiology reports. In this article, we provide a critical overview of the current state of the art for TM related to cancer. The review highlighted a strong bias towards symbolic methods, e.g. named entity recognition (NER) based on dictionary lookup and information extraction (IE) relying on pattern matching. The F-measure of NER ranges between 80% and 90%, while that of IE for simple tasks is in the high 90s. To further improve the performance, TM approaches need to deal effectively with idiosyncrasies of the clinical sublanguage such as non-standard abbreviations as well as a high degree of spelling and grammatical errors. This requires a shift from rule-based methods to machine learning following the success of similar trends in biological applications of TM. Machine learning approaches require large training datasets, but clinical narratives are not readily available for TM research due to privacy and confidentiality concerns. This issue remains the main bottleneck for progress in this area. In addition, there is a need for a comprehensive cancer ontology that would enable semantic representation of textual information found in narrative reports.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21621,""
"Machine learning, medical diagnosis, and biomedical engineering research - commentary","Foster, Koprowski, Skufca","https://doi.org/10.1186/1475-925X-13-94","20150226","PubMed","Artificial Intelligence; Biomedical Engineering; Diagnostic Techniques and Procedures; Hashimoto Disease; Humans","A large number of papers are appearing in the biomedical engineering literature that describe the use of machine learning techniques to develop classifiers for detection or diagnosis of disease. However, the usefulness of this approach in developing clinically validated diagnostic techniques so far has been limited and the methods are prone to overfitting and other problems which may not be immediately apparent to the investigators. This commentary is intended to help sensitize investigators as well as readers and reviewers of papers to some potential pitfalls in the development of classifiers, and suggests steps that researchers can take to help avoid these problems. Building classifiers should be viewed not simply as an add-on statistical analysis, but as part and parcel of the experimental process. Validation of classifiers for diagnostic applications should be considered as part of a much larger process of establishing the clinical validity of the diagnostic technique. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21622,""
"Network based integrated analysis of phenotype-genotype data for prioritization of candidate symptom genes","Li, Zhou, Peng, Liu, Zhang, Hu, Yu, Jia, Sun","https://doi.org/10.1155/2014/435853","20150223","PubMed","Algorithms; Computational Biology; Gene Regulatory Networks; Genetic Association Studies; Genome-Wide Association Study; Humans; Medicine, Chinese Traditional; PubMed","Symptoms and signs (symptoms in brief) are the essential clinical manifestations for individualized diagnosis and treatment in traditional Chinese medicine (TCM). To gain insights into the molecular mechanism of symptoms, we develop a computational approach to identify the candidate genes of symptoms. This paper presents a network-based approach for the integrated analysis of multiple phenotype-genotype data sources and the prediction of the prioritizing genes for the associated symptoms. The method first calculates the similarities between symptoms and diseases based on the symptom-disease relationships retrieved from the PubMed bibliographic database. Then the disease-gene associations and protein-protein interactions are utilized to construct a phenotype-genotype network. The PRINCE algorithm is finally used to rank the potential genes for the associated symptoms. The proposed method gets reliable gene rank list with AUC (area under curve) 0.616 in classification. Some novel genes like CALCA, ESR1, and MTHFR were predicted to be associated with headache symptoms, which are not recorded in the benchmark data set, but have been reported in recent published literatures. Our study demonstrated that by integrating phenotype-genotype relationships into a complex network framework it provides an effective approach to identify candidate genes of symptoms.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21623,""
"Toward personalizing treatment for depression: predicting diagnosis and severity","Huang, LePendu, Iyer, Tai-Seale, Carrell, Shah","https://doi.org/10.1136/amiajnl-2014-002733","20150511","PubMed","data mining; depression; electronic health records; ontology; personalized medicine; Depressive Disorder; Diagnosis, Differential; Electronic Health Records; Female; Humans; Male; Models, Psychological; Precision Medicine; ROC Curve; Severity of Illness Index","Depression is a prevalent disorder difficult to diagnose and treat. In particular, depressed patients exhibit largely unpredictable responses to treatment. Toward the goal of personalizing treatment for depression, we develop and evaluate computational models that use electronic health record (EHR) data for predicting the diagnosis and severity of depression, and response to treatment. We develop regression-based models for predicting depression, its severity, and response to treatment from EHR data, using structured diagnosis and medication codes as well as free-text clinical reports. We used two datasets: 35,000 patients (5000 depressed) from the Palo Alto Medical Foundation and 5651 patients treated for depression from the Group Health Research Institute. Our models are able to predict a future diagnosis of depression up to 12Ã¢â‚¬â€¦months in advance (area under the receiver operating characteristic curve (AUC) 0.70-0.80). We can differentiate patients with severe baseline depression from those with minimal or mild baseline depression (AUC 0.72). Baseline depression severity was the strongest predictor of treatment response for medication and psychotherapy. It is possible to use EHR data to predict a diagnosis of depression up to 12Ã¢â‚¬â€¦months in advance and to differentiate between extreme baseline levels of depression. The models use commonly available data on diagnosis, medication, and clinical progress notes, making them easily portable. The ability to automatically determine severity can facilitate assembly of large patient cohorts with similar severity from multiple sites, which may enable elucidation of the moderators of treatment response in the future.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21624,""
"Noninvasive image texture analysis differentiates K-ras mutation from pan-wildtype NSCLC and is prognostic","Weiss, Ganeshan, Miles, Campbell, Cheung, Frank, Korn","https://doi.org/10.1371/journal.pone.0100244","20150221","PubMed","Aged; Aged, 80 and over; Carcinoma, Non-Small-Cell Lung; Disease-Free Survival; Female; Humans; Lung Neoplasms; Male; Middle Aged; Mutation; Neoplasm Staging; Proto-Oncogene Proteins; Proto-Oncogene Proteins p21(ras); Survival Rate; ras Proteins","Non-invasive characterization of a tumor's molecular features could enhance treatment management. Quantitative computed tomography (CT) based texture analysis (QTA) has been used to derive tumor heterogeneity information, and the appearance of the tumors has been shown to relate to patient outcome in non-small cell lung cancer (NSCLC) and other cancers. In this study, we examined the potential of tumoral QTA to differentiate K-ras mutant from pan-wildtype tumors and its prognostic potential using baseline pre-treatment non-contrast CT imaging in NSCLC. Tumor DNA from patients with early-stage NSCLC was analyzed on the LungCarta Panel. Cases with a K-ras mutation or pan-wildtype for 26 oncogenes and tumor suppressor genes were selected for QTA. QTA was applied to regions of interest in the primary tumor. Non-parametric Mann Whitney test assessed the ability of the QTA, clinical and patient characteristics to differentiate between K-ras mutation from pan-wildtype. A recursive decision tree was developed to determine whether the differentiation of K-ras mutant from pan-wildtype tumors could be improved by sequential application of QTA parameters. Kaplan-Meier survival analysis assessed the ability of these markers to predict survival. QTA was applied to 48 cases identified, 27 had a K-ras mutation and 21 cases were pan-wildtype. Positive skewness and lower kurtosis were significantly associated with the presence of a K-ras mutation. A five node decision tree had sensitivity, specificity, and accuracy values (95% CI) of 96.3% (78.1-100), 81.0% (50.5-97.4), and 89.6% (72.9-97.0); respectively. Kurtosis was a significant predictor of OS and DFS, with a lower kurtosis value linked with poorer survival. Lower kurtosis and positive skewness are significantly associated with K-ras mutations. A QTA feature such as kurtosis is prognostic for OS and DFS. Non-invasive QTA can differentiate the presence of K-ras mutation from pan-wildtype NSCLC and is associated with patient survival.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21625,""
"Clinic-genomic association mining for colorectal cancer using publicly available datasets","Liu, Feng, Li, Pan, Su, Yang, Song, Duan, Deng","https://doi.org/10.1155/2014/170289","20150212","PubMed","Colorectal Neoplasms; Data Mining; Databases, Genetic; Datasets as Topic; Gene Expression Regulation, Neoplastic; Genomics; Humans; Software","In recent years, a growing number of researchers began to focus on how to establish associations between clinical and genomic data. However, up to now, there is lack of research mining clinic-genomic associations by comprehensively analysing available gene expression data for a single disease. Colorectal cancer is one of the malignant tumours. A number of genetic syndromes have been proven to be associated with colorectal cancer. This paper presents our research on mining clinic-genomic associations for colorectal cancer under biomedical big data environment. The proposed method is engineered with multiple technologies, including extracting clinical concepts using the unified medical language system (UMLS), extracting genes through the literature mining, and mining clinic-genomic associations through statistical analysis. We applied this method to datasets extracted from both gene expression omnibus (GEO) and genetic association database (GAD). A total of 23,517 clinic-genomic associations between 139 clinical concepts and 7914 genes were obtained, of which 3474 associations between 31 clinical concepts and 1689 genes were identified as highly reliable ones. Evaluation and interpretation were performed using UMLS, KEGG, and Gephi, and potential new discoveries were explored. The proposed method is effective in mining valuable knowledge from available biomedical big data and achieves a good performance in bridging clinical data with genomic data for colorectal cancer.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21626,""
"Posterior cingulate cortex-related co-activation patterns: a resting state FMRI study in propofol-induced loss of consciousness","Amico, Gomez, Di Perri, Vanhaudenhuyse, Lesenfants, Boveroux, Bonhomme, Brichant, Marinazzo, Laureys","https://doi.org/10.1371/journal.pone.0100012","20150219","PubMed","Adult; Anesthesia, General; Anesthetics, Intravenous; Auditory Cortex; Brain Mapping; Consciousness; Female; Frontal Lobe; Gyrus Cinguli; Humans; Magnetic Resonance Imaging; Male; Neural Pathways; Propofol; Thalamus; Unconsciousness; Visual Cortex; Wakefulness","Recent studies have been shown that functional connectivity of cerebral areas is not a static phenomenon, but exhibits spontaneous fluctuations over time. There is evidence that fluctuating connectivity is an intrinsic phenomenon of brain dynamics that persists during anesthesia. Lately, point process analysis applied on functional data has revealed that much of the information regarding brain connectivity is contained in a fraction of critical time points of a resting state dataset. In the present study we want to extend this methodology for the investigation of resting state fMRI spatial pattern changes during propofol-induced modulation of consciousness, with the aim of extracting new insights on brain networks consciousness-dependent fluctuations. Resting-state fMRI volumes on 18 healthy subjects were acquired in four clinical states during propofol injection: wakefulness, sedation, unconsciousness, and recovery. The dataset was reduced to a spatio-temporal point process by selecting time points in the Posterior Cingulate Cortex (PCC) at which the signal is higher than a given threshold (i.e., BOLD intensity above 1 standard deviation). Spatial clustering on the PCC time frames extracted was then performed (number of clustersÃ¢â‚¬Å =Ã¢â‚¬Å 8), to obtain 8 different PCC co-activation patterns (CAPs) for each level of consciousness. The current analysis shows that the core of the PCC-CAPs throughout consciousness modulation seems to be preserved. Nonetheless, this methodology enables to differentiate region-specific propofol-induced reductions in PCC-CAPs, some of them already present in the functional connectivity literature (e.g., disconnections of the prefrontal cortex, thalamus, auditory cortex), some others new (e.g., reduced co-activation in motor cortex and visual area). In conclusion, our results indicate that the employed methodology can help in improving and refining the characterization of local functional changes in the brain associated to propofol-induced modulation of consciousness.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21627,""
"Pathway reconstruction of airway remodeling in chronic lung diseases: a systems biology approach","Najafi, Masoudi-Nejad, Ghanei, Nourani, Moeini","https://doi.org/10.1371/journal.pone.0100094","20150219","PubMed","Airway Remodeling; Asthma; Chronic Disease; Data Mining; Databases, Genetic; Gene Regulatory Networks; Humans; Lung; Mustard Gas; Protein Interaction Mapping; Pulmonary Disease, Chronic Obstructive; Systems Biology","Airway remodeling is a pathophysiologic process at the clinical, cellular, and molecular level relating to chronic obstructive airway diseases such as chronic obstructive pulmonary disease (COPD), asthma and mustard lung. These diseases are associated with the dysregulation of multiple molecular pathways in the airway cells. Little progress has so far been made in discovering the molecular causes of complex disease in a holistic systems manner. Therefore, pathway and network reconstruction is an essential part of a systems biology approach to solve this challenging problem. In this paper, multiple data sources were used to construct the molecular process of airway remodeling pathway in mustard lung as a model of airway disease. We first compiled a master list of genes that change with airway remodeling in the mustard lung disease and then reconstructed the pathway by generating and merging the protein-protein interaction and the gene regulatory networks. Experimental observations and literature mining were used to identify and validate the master list. The outcome of this paper can provide valuable information about closely related chronic obstructive airway diseases which are of great importance for biologists and their future research. Reconstructing the airway remodeling interactome provides a starting point and reference for the future experimental study of mustard lung, and further analysis and development of these maps will be critical to understanding airway diseases in patients. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21628,""
"The neural basis of time-varying resting-state functional connectivity","Keilholz","https://doi.org/10.1089/brain.2014.0250","20150722","PubMed","EEG; dynamic analysis; functional connectivity; neural activity; resting-state fMRI; Animals; Brain; Brain Mapping; Brain Waves; Electroencephalography; Humans; Magnetic Resonance Imaging; Magnetoencephalography; Nerve Net; Rest; Time Factors","Dynamic network analysis based on resting-state magnetic resonance imaging (rsMRI) is a fairly new and potentially powerful tool for neuroscience and clinical research. Dynamic analysis can be sensitive to changes that occur in psychiatric or neurologic disorders and can detect variations related to performance on individual trials in healthy subjects. However, the appearance of time-varying connectivity can also arise in signals that share no temporal information, complicating the interpretation of dynamic functional connectivity studies. Researchers have begun utilizing simultaneous imaging and electrophysiological recording to elucidate the neural basis of the networks and their variability in animals and in humans. In this article, we review findings that link changes in electrically recorded brain states to changes in the networks obtained with rsMRI and discuss some of the challenges inherent in interpretation of these studies. The literature suggests that multiple brain processes may contribute to the dynamics observed, and we speculate that it may be possible to separate particular aspects of the rsMRI signal to enhance sensitivity to certain types of neural activity, providing new tools for basic neuroscience and clinical research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21629,""
"Review of robotics in foregut and bariatric surgery","Toro, Lin, Patel","https://doi.org/10.1007/s00464-014-3646-z","20150709","PubMed","Bariatric Surgery; Digestive System Surgical Procedures; Humans; Laparoscopy; Robotic Surgical Procedures; Treatment Outcome","In the last decade, the robotic platform has been used in different surgical fields. However, the field of foregut and bariatric surgery is still evolving. Most surgeons still prefer laparoscopic techniques because it has proven clinical benefits, does not require complex setups, and does not have high costs compared with that of robotics. The aim of this article is to review the outcomes of foregut and bariatric surgery and its potential clinical advantages. We performed a search on PUBMED for the most relevant articles published in the field of robotic bariatric and foregut surgery in the last 15 years. More than 40 articles were selected and included on this review. Several systematic reviews were also included. Very few randomized clinical trials are available. For the most part, robotic procedures were associated with better ergonomics for the surgeon, better visualization of the anatomy, easier fine dissection (i.e., lymphadenectomy) when required, and higher costs. In foregut surgery, the robotic system is associated with a significant lower rate of mucosal perforation in Heller myotomy compared to laparoscopy. In bariatric surgery, the clinical advantages have not been well documented yet; however, it seems robotics shortens the learning curve of Roux-en-Y gastric bypass (RYGB). Foregut and bariatric robotic surgery is a surgical field still in development. For the vast majority of the procedures in this area, the clinical outcomes of robotic surgery are the same of standard laparoscopy. However, the use of robots in selected cases may have specific advantages and may overcome the limitations of laparoscopic surgery. More research is needed, especially large and well-designed randomized clinical trials, to elucidate more accurate conclusions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21630,""
"Promoting physical therapists' of research evidence to inform clinical practice: part 1--theoretical foundation, evidence, and description of the PEAK program","Tilson, Mickan","https://doi.org/10.1186/1472-6920-14-125","20141219","PubMed","Curriculum; Evidence-Based Medicine; Humans; Physical Therapy Modalities; Physical Therapy Specialty; Translational Medical Research","There is a need for theoretically grounded and evidence-based interventions that enhance the use of research evidence in physical therapist practice. This paper and its companion paper introduce the Physical therapist-driven Education for Actionable Knowledge translation (PEAK) program, an educational program designed to promote physical therapists' integration of research evidence into clinical decision-making. The pedagogical foundations for the PEAK educational program include Albert Bandura's social cognitive theory and Malcolm Knowles's adult learning theory. Additionally, two complementary frameworks of knowledge translation, the Promoting Action on Research Implementation in Health Services (PARiHS) and Knowledge to Action (KTA) Cycle, were used to inform the organizational elements of the program. Finally, the program design was influenced by evidence from previous attempts to facilitate the use of research in practice at the individual and organizational levels. The 6-month PEAK program consisted of four consecutive and interdependent components. First, leadership support was secured and electronic resources were acquired and distributed to participants. Next, a two-day training workshop consisting of didactic and small group activities was conducted that addressed the five steps of evidence based practice. For five months following the workshop, participants worked in small groups to review and synthesize literature around a group-selected area of common clinical interest. Each group contributed to the generation of a ""Best Practices List"" - a list of locally generated, evidence-based, actionable behaviors relevant to the groups' clinical practice. Ultimately, participants agreed to implement the Best Practices List in their clinical practice. This, first of two companion papers, describes the underlying pedagogical theories, knowledge translation frameworks, and research evidence used to derive the PEAK program - an educational program designed to promote the use of research evidence to inform physical therapist practice. The four components of the program are described in detail. The companion paper reports the results of a mixed methods feasibility analysis of this complex educational intervention.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21631,""
"Towards symbiosis in knowledge representation and natural language processing for structuring clinical practice guidelines","Weng, Payne, Velez, Johnson, Bakken","https://www.google.com/search?q=Towards+symbiosis+in+knowledge+representation+and+natural+language+processing+for+structuring+clinical+practice+guidelines.","20150624","PubMed","Database Management Systems; Databases, Factual; Information Storage and Retrieval; Knowledge Bases; Natural Language Processing; New York; Practice Guidelines as Topic; Semantics; Vocabulary, Controlled","The successful adoption by clinicians of evidence-based clinical practice guidelines (CPGs) contained in clinical information systems requires efficient translation of free-text guidelines into computable formats. Natural language processing (NLP) has the potential to improve the efficiency of such translation. However, it is laborious to develop NLP to structure free-text CPGs using existing formal knowledge representations (KR). In response to this challenge, this vision paper discusses the value and feasibility of supporting symbiosis in text-based knowledge acquisition (KA) and KR. We compare two ontologies: (1) an ontology manually created by domain experts for CPG eligibility criteria and (2) an upper-level ontology derived from a semantic pattern-based approach for automatic KA from CPG eligibility criteria text. Then we discuss the strengths and limitations of interweaving KA and NLP for KR purposes and important considerations for achieving the symbiosis of KR and NLP for structuring CPGs to achieve evidence-based clinical practice. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21632,""
"Pretreatment attrition and formal withdrawal during treatment and their predictors: an exploratory study of the anxiety online data","Al-Asadi, Klein, Meyer","https://doi.org/10.2196/jmir.2989","20150420","PubMed","Internet interventions; e-mental health; eTherapy; predictors, anxiety disorders; pretreatment attrition; treatment withdrawal dropouts; Algorithms; Analysis of Variance; Anxiety Disorders; Datasets as Topic; Female; Humans; Internet; Logistic Models; Male; Patient Dropouts; Quality of Life; Social Support; Telemedicine","Although in its infancy, the field of e-mental health interventions has been gaining popularity and afforded considerable research attention. However, there are many gaps in the research. One such gap is in the area of attrition predictors at various stages of assessment and treatment delivery. This exploratory study applied univariate and multivariate analysis to a large dataset provided by the Anxiety Online (now called Mental Health Online) system to identify predictors of attrition in treatment commencers and in those who formally withdrew during treatment based on 24 pretreatment demographic and personal variables and one clinical measure. Participants were assessed using a complex online algorithm that resulted in primary and secondary diagnoses in accordance with the Diagnostic and Statistical Manual of Mental Disorders, Fourth Edition, Text Revision (DSM-IV-TR). Those who received a primary or secondary diagnosis of 1 of 5 anxiety disorders (generalized anxiety disorder, social anxiety disorder, obsessive-compulsive disorder, posttraumatic stress disorder, and panic disorder) were offered an online 12-week disorder-specific treatment program. Of 9394 potential participants, a total of 3880 clients enrolled and 5514 did not enroll in one of the treatment programs following the completion of pretreatment assessment measures (pretreatment attrition rate: 58.70%). A total of 3199 individuals did not formally withdraw from the 12-week treatment cycle, whereas 142 individuals formally dropped out (formal withdrawal during treatment dropout rate of 4.25%). The treatment commencers differed significantly (P&lt;.001-.03) from the noncommencers on several variables (reason for registering, mental health concerns, postsecondary education, where first heard about Anxiety Online, Kessler-6 score, stage of change, quality of life, relationship status, preferred method of learning, and smoking status). Those who formally withdrew during treatment differed significantly (P=.002-.03) from those who did not formally withdraw in that they were less likely to express concerns about anxiety, stress, and depression; to rate their quality of life as very poor, poor, or good; to report adequate level of social support; and to report readiness to make or were in the process of making changes. This exploratory study identified predictors of pretreatment attrition and formal withdrawal during treatment dropouts for the Anxiety Online program. Australian and New Zealand Clinical Trials Registry ACTRN121611000704998; http://www.anzctr.org.au/trial_view.aspx?ID=336143 (Archived by WebCite at http://www.webcitation.org/618r3wvOG).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21633,""
"MiningABs: mining associated biomarkers across multi-connected gene expression datasets","Cheng, DeBoever, Frazer, Liu, Tseng","https://doi.org/10.1186/1471-2105-15-173","20141117","PubMed","Algorithms; Biomarkers, Tumor; Data Mining; Gene Expression; Gene Expression Profiling; Genetic Markers; Humans; Neoplasms","Human disease often arises as a consequence of alterations in a set of associated genes rather than alterations to a set of unassociated individual genes. Most previous microarray-based meta-analyses identified disease-associated genes or biomarkers independent of genetic interactions. Therefore, in this study, we present the first meta-analysis method capable of taking gene combination effects into account to efficiently identify associated biomarkers (ABs) across different microarray platforms. We propose a new meta-analysis approach called MiningABs to mine ABs across different array-based datasets. The similarity between paired probe sequences is quantified as a bridge to connect these datasets together. The ABs can be subsequently identified from an ""improved"" common logit model (c-LM) by combining several sibling-like LMs in a heuristic genetic algorithm selection process. Our approach is evaluated with two sets of gene expression datasets: i) 4 esophageal squamous cell carcinoma and ii) 3 hepatocellular carcinoma datasets. Based on an unbiased reciprocal test, we demonstrate that each gene in a group of ABs is required to maintain high cancer sample classification accuracy, and we observe that ABs are not limited to genes common to all platforms. Investigating the ABs using Gene Ontology (GO) enrichment, literature survey, and network analyses indicated that our ABs are not only strongly related to cancer development but also highly connected in a diverse network of biological interactions. The proposed meta-analysis method called MiningABs is able to efficiently identify ABs from different independently performed array-based datasets, and we show its validity in cancer biology via GO enrichment, literature survey and network analyses. We postulate that the ABs may facilitate novel target and drug discovery, leading to improved clinical treatment. Java source code, tutorial, example and related materials are available at ""http://sourceforge.net/projects/miningabs/"".","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21634,""
"A model-based cost-effectiveness analysis of a grommets-led care pathway for children with cleft palate affected by otitis media with effusion","Mohiuddin, Payne, Fenwick, O'Brien, Bruce","https://doi.org/10.1007/s10198-014-0610-8","20160309","PubMed","Child; Child, Preschool; Cleft Palate; Cost-Benefit Analysis; Decision Trees; Female; Hearing Aids; Hearing Loss; Humans; Infant; Male; Middle Ear Ventilation; Models, Econometric; Otitis Media with Effusion; Quality-Adjusted Life Years; State Medicine; Uncertainty; United Kingdom","There is a paucity of evidence to guide the management of otitis media with effusion (OME), which is a common problem causing significant hearing impairment in children with cleft palate. The insertion of grommets is currently being used to correct hearing impairment and prevent complications of unmanaged OME, but there is ongoing discussion about whether theÃ‚Â benefits of grommets outweighÃ‚Â the costs and risks. A decision-tree model was developed to assess the surgical insertion of grommets with two non-surgical alternatives (hearing-aids and do-nothing strategies) in cleft palate children with persistent bilateral OME. The model assumed a 2-year time horizon and a UK National Health Service perspective. Outcomes were valued using quality-adjusted life-years (QALYs) estimated by linking utility values with potential hearing gains measured in decibels. Multiple data sources were used, including reviews of the clinical effectiveness, resource use and utility literature, and supplemented with expert opinion. Uncertainty in the model parameters was assessed using probabilistic sensitivity analysis. Expected value of perfect information analysis was used to calculate the potential value of future research. The results from the probabilistic sensitivity analysis indicated that the grommets strategy was associated with an incremental cost-effectiveness ratio of Ã‚Â£9,065 per QALY gained compared with the do-nothing strategy, and the hearing-aids strategy was extended dominated by the grommets strategy. The population expected value of perfect information was Ã‚Â£5,194,030 at a willingness to pay threshold of Ã‚Â£20,000 per QALY, implying that future research could be potentially worthwhile. This study found some evidence that the insertion of grommets to manage cleft palate children with bilateral OME is likely to be cost-effective, but further research is required to inform this treatment choice. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21635,""
"Automated semantic annotation of rare disease cases: a case study","Taboada, RodrÃƒÂ­guez, MartÃƒÂ­nez, Pardo, Sobrido","https://doi.org/10.1093/database/bau045","20140826","PubMed","Automation; Biological Ontologies; Data Mining; Humans; PubMed; Rare Diseases; Semantics","As the number of clinical reports in the peer-reviewed medical literature keeps growing, there is an increasing need for online search tools to find and analyze publications on patients with similar clinical characteristics. This problem is especially critical and challenging for rare diseases, where publications of large series are scarce. Through an applied example, we illustrate how to automatically identify new relevant cases and semantically annotate the relevant literature about patient case reports to capture the phenotype of a rare disease named cerebrotendinous xanthomatosis. Our results confirm that it is possible to automatically identify new relevant case reports with a high precision and to annotate them with a satisfactory quality (74% F-measure). Automated annotation with an emphasis to entirely describe all phenotypic abnormalities found in a disease may facilitate curation efforts by supplying phenotype retrieval and assessment of their frequency. Availability and Supplementary information: http://www.usc.es/keam/PhenotypeÃ‚Â Annotation/. Database URL: http://www.usc.es/keam/PhenotypeAnnotation/","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21636,""
"Do editorial policies support ethical research? A thematic text analysis of author instructions in psychiatry journals","Strech, Metz, KnÃƒÂ¼ppel","https://doi.org/10.1371/journal.pone.0097492","20150805","PubMed","Biomedical Research; Editorial Policies; Ethics Committees, Research; Ethics, Research; Guidelines as Topic; Humans; Informed Consent; Periodicals as Topic; Psychiatry; Publishing; Research","According to the Declaration of Helsinki and other guidelines, clinical studies should be approved by a research ethics committee and seek valid informed consent from the participants. Editors of medical journals are encouraged by the ICMJE and COPE to include requirements for these principles in the journal's instructions for authors. This study assessed the editorial policies of psychiatry journals regarding ethics review and informed consent. The information given on ethics review and informed consent and the mentioning of the ICMJE and COPE recommendations were assessed within author's instructions and online submission procedures of all 123 eligible psychiatry journals. While 54% and 58% of editorial policies required ethics review and informed consent, only 14% and 19% demanded the reporting of these issues in the manuscript. The TOP-10 psychiatry journals (ranked by impact factor) performed similarly in this regard. Only every second psychiatry journal adheres to the ICMJE's recommendation to inform authors about requirements for informed consent and ethics review. Furthermore, we argue that even the ICMJE's recommendations in this regard are insufficient, at least for ethically challenging clinical trials. At the same time, ideal scientific design sometimes even needs to be compromised for ethical reasons. We suggest that features of clinical studies that make them morally controversial, but not necessarily unethical, are analogous to methodological limitations and should thus be reported explicitly. Editorial policies as well as reporting guidelines such as CONSORT should be extended to support a meaningful reporting of ethical research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21637,""
"DiseaseConnect: a comprehensive web server for mechanism-based disease-disease connections","Liu, Tseng, Li, Wu, Mayzus, Rzhetsky, Sun, Waterman, Chen, Chaudhary, Loscalzo, Crandall, Zhou","https://doi.org/10.1093/nar/gku412","20140918","PubMed","Comorbidity; Disease; Drug Therapy; Gene Expression; Humans; Internet; MicroRNAs; Polymorphism, Single Nucleotide; Software","The DiseaseConnect (http://disease-connect.org) is a web server for analysis and visualization of a comprehensive knowledge on mechanism-based disease connectivity. The traditional disease classification system groups diseases with similar clinical symptoms and phenotypic traits. Thus, diseases with entirely different pathologies could be grouped together, leading to a similar treatment design. Such problems could be avoided if diseases were classified based on their molecular mechanisms. Connecting diseases with similar pathological mechanisms could inspire novel strategies on the effective repositioning of existing drugs and therapies. Although there have been several studies attempting to generate disease connectivity networks, they have not yet utilized the enormous and rapidly growing public repositories of disease-related omics data and literature, two primary resources capable of providing insights into disease connections at an unprecedented level of detail. Our DiseaseConnect, the first public web server, integrates comprehensive omics and literature data, including a large amount of gene expression data, Genome-Wide Association Studies catalog, and text-mined knowledge, to discover disease-disease connectivity via common molecular mechanisms. Moreover, the clinical comorbidity data and a comprehensive compilation of known drug-disease relationships are additionally utilized for advancing the understanding of the disease landscape and for facilitating the mechanism-based development of new drug treatments. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21638,""
"Diagnostic assessment by dynamic contrast-enhanced and diffusion-weighted magnetic resonance in differentiation of breast lesions under different imaging protocols","Cai, Liu, Peng, Wu, Li","https://doi.org/10.1186/1471-2407-14-366","20150224","PubMed","Adolescent; Adult; Aged; Algorithms; Artificial Intelligence; Breast Neoplasms; Contrast Media; Diagnosis, Differential; Diffusion Magnetic Resonance Imaging; Female; Gadolinium DTPA; Humans; Image Interpretation, Computer-Assisted; Middle Aged; Predictive Value of Tests; Prognosis; Retrospective Studies; Young Adult","The apparent diffusion coefficient (ADC) is a highly diagnostic factor in discriminating malignant and benign breast masses in diffusion-weighted magnetic resonance imaging (DW-MRI). The combination of ADC and other pictorial characteristics has improved lesion type identification accuracy. The objective of this study was to reassess the findings on an independent patient group by changing the magnetic field from 1.5-Tesla to 3.0-Tesla. This retrospective study consisted of a training group of 234 female patients, including 85 benign and 149 malignant lesions, imaged using 1.5-Tesla MRI, and a test group of 95 female patients, including 19 benign and 85 malignant lesions, imaged using 3.0-Tesla MRI. The lesion of interest was segmented from the raw image and four sets of measurements describing the morphology, kinetics, DW-MRI, and texture of the pictorial properties of each lesion were obtained. Each lesion was characterized by 28 features in total. Three classical machine-learning algorithms were used to build prediction models on the training group, which evaluated the prognostic performance of the multi-sided features in three scenarios. To reduce information redundancy, five highly diagnostic factors were selected to obtain a compact yet informative characterization of the lesion status. Three classification models were built on the training of 1.5-Tesla patients and were tested on the independent 3.0-Tesla test group. The following results were found. i) Characterization of breast masses in a multi-sided way dramatically increased prediction performance. The usage of all features gave a higher performance in both sensitivity and specificity than any individual feature groups or their combinations. ii) ADC was a highly effective factor in improving the sensitivity in discriminating malignant from benign masses. iii) Five features, namely ADC, Sum Average, Entropy, Elongation, and Sum Variance, were selected to achieve the highest performance in diagnosis of the 3.0-Tesla patient group. The combination of ADC and other multi-sided characteristics can increase the capability of discriminating malignant and benign breast lesions, even under different imaging protocols. The selected compact feature subsets achieved a high diagnostic performance and thus are promising in clinical applications for discriminating lesion type and for personalized treatment planning.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21639,""
"Outcomes of minimally invasive simple prostatectomy for benign prostatic hyperplasia: a systematic review and meta-analysis","Lucca, Shariat, Hofbauer, Klatte","https://doi.org/10.1007/s00345-014-1324-3","20151215","PubMed","Blood Loss, Surgical; Humans; Laparoscopy; Length of Stay; Male; Minimally Invasive Surgical Procedures; Organ Size; Prostate; Prostatectomy; Prostatic Hyperplasia; Robotic Surgical Procedures; Treatment Outcome","(1) To assess the outcomes of minimally invasive simple prostatectomy (MISP) for the treatment of symptomatic benign prostatic hyperplasia in men with large prostates and (2) to compare them with open simple prostatectomy (OSP). A systematic review of outcomes of MISP for benign prostatic hyperplasia with meta-analysis was conducted. The article selection process was conducted according to the PRISMA guidelines. Twenty-seven observational studies with 764 patients were analyzed. The mean prostate volume was 113.5 ml (95 % CI 106-121). The mean increase in Qmax was 14.3 ml/s (95 % CI 13.1-15.6), and the mean improvement in IPSS was 17.2 (95 % CI 15.2-19.2). Mean duration of operation was 141 min (95 % CI 124-159), and the mean intraoperative blood loss was 284 ml (95 % CI 243-325). One hundred and four patients (13.6 %) developed a surgical complication. In comparative studies, length of hospital stay (WMD -1.6 days, p = 0.02), length of catheter use (WMD -1.3 days, p = 0.04) and estimated blood loss (WMD -187 ml, p = 0.015) were significantly lower in the MISP group, while the duration of operation was longer than in OSP (WMD 37.8 min, p &lt; 0.0001). There were no differences in improvements in Qmax, IPSS and perioperative complications between both procedures. The small study sizes, publication bias, lack of systematic complication reporting and short follow-up are limitations. MISP seems an effective and safe treatment option. It provides similar improvements in Qmax and IPSS as OSP. Despite taking longer, it results in less blood loss and shorter hospital stay. Prospective randomized studies comparing OSP, MISP and laser enucleation are needed to define the standard surgical treatment for large prostates.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21640,""
"Structuring osteosarcoma knowledge: an osteosarcoma-gene association database based on literature mining and manual annotation","Poos, Smida, Nathrath, Maugg, Baumhoer, Neumann, Korsching","https://doi.org/10.1093/database/bau042","20140826","PubMed","Cyclin-Dependent Kinase Inhibitor p21; Data Mining; Databases, Genetic; Gene Expression Regulation, Neoplastic; Genetic Predisposition to Disease; Humans; MicroRNAs; Molecular Sequence Annotation; Osteosarcoma","Osteosarcoma (OS) is the most common primary bone cancer exhibiting high genomic instability. This genomic instability affects multiple genes and microRNAs to a varying extent depending on patient and tumor subtype. Massive research is ongoing to identify genes including their gene products and microRNAs that correlate with disease progression and might be used as biomarkers for OS. However, the genomic complexity hampers the identification of reliable biomarkers. Up to now, clinico-pathological factors are the key determinants to guide prognosis and therapeutic treatments. Each day, new studies about OS are published and complicate the acquisition of information to support biomarker discovery and therapeutic improvements. Thus, it is necessary to provide a structured and annotated view on the current OS knowledge that is quick and easily accessible to researchers of the field. Therefore, we developed a publicly available database and Web interface that serves as resource for OS-associated genes and microRNAs. Genes and microRNAs were collected using an automated dictionary-based gene recognition procedure followed by manual review and annotation by experts of the field. In total, 911 genes and 81 microRNAs related to 1331 PubMed abstracts were collected (last update: 29 October 2013). Users can evaluate genes and microRNAs according to their potential prognostic and therapeutic impact, the experimental procedures, the sample types, the biological contexts and microRNA target gene interactions. Additionally, a pathway enrichment analysis of the collected genes highlights different aspects of OS progression. OS requires pathways commonly deregulated in cancer but also features OS-specific alterations like deregulated osteoclast differentiation. To our knowledge, this is the first effort of an OS database containing manual reviewed and annotated up-to-date OS knowledge. It might be a useful resource especially for the bone tumor research community, as specific information about genes or microRNAs is quick and easily accessible. Hence, this platform can support the ongoing OS research and biomarker discovery. Database URL: http://osteosarcoma-db.uni-muenster.de. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21641,""
"Augmenting multi-instance multilabel learning with sparse bayesian models for skin biopsy image analysis","Zhang, Yin, Su, Huang, Lao, Liang, Ou, Zhang","https://doi.org/10.1155/2014/305629","20150114","PubMed","Artificial Intelligence; Bayes Theorem; Biopsy; Dermoscopy; Documentation; Humans; Image Enhancement; Microscopy; Natural Language Processing; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Skin; Skin Diseases; Staining and Labeling","Skin biopsy images can reveal causes and severity of many skin diseases, which is a significant complement for skin surface inspection. Automatic annotation of skin biopsy image is an important problem for increasing efficiency and reducing the subjectiveness in diagnosis. However it is challenging particularly when there exists indirect relationship between annotation terms and local regions of a biopsy image, as well as local structures with different textures. In this paper, a novel method based on a recent proposed machine learning model, named multi-instance multilabel (MIML), is proposed to model the potential knowledge and experience of doctors on skin biopsy image annotation. We first show that the problem of skin biopsy image annotation can naturally be expressed as a MIML problem and then propose an image representation method that can capture both region structure and texture features, and a sparse Bayesian MIML algorithm which can produce probabilities indicating the confidence of annotation. The proposed algorithm framework is evaluated on a real clinical dataset containing 12,700 skin biopsy images. The results show that it is effective and prominent. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21642,""
"Public health impact and cost-effectiveness of intranasal live attenuated influenza vaccination of children in Germany","Damm, Eichner, Rose, Knuf, Wutzler, Liese, KrÃƒÂ¼ger, Greiner","https://doi.org/10.1007/s10198-014-0586-4","20160208","PubMed","Administration, Intranasal; Adolescent; Analgesics; Anti-Bacterial Agents; Child; Child, Preschool; Cost-Benefit Analysis; Germany; Humans; Influenza Vaccines; Influenza, Human; Models, Econometric; Otitis Media; Pneumonia; Public Health; Quality-Adjusted Life Years; Vaccines, Attenuated","In 2011, intranasally administered live attenuated influenza vaccine (LAIV) was approved in the EU for prophylaxis of seasonal influenza in 2-17-year-old children. Our objective was to estimate the potential epidemiological impact and cost-effectiveness of an LAIV-based extension of the influenza vaccination programme to healthy children in Germany. An age-structured dynamic model of influenza transmission was developed and combined with a decision-tree to evaluate different vaccination strategies in the German health care system. Model inputs were based on published literature or were derived by expert consulting using the Delphi technique. Unit costs were drawn from German sources. Under base-case assumptions, annual routine vaccination of children aged 2-17 years with LAIV assuming an uptake of 50% would prevent, across all ages, 16 million cases of symptomatic influenza, over 600,000 cases of acute otitis media, nearly 130,000 cases of community-acquired pneumonia, nearly 1.7 million prescriptions of antibiotics and over 165,000 hospitalisations over 10 years. The discounted incremental cost-effectiveness ratio was &lt;euro&gt; 1,228 per quality-adjusted life year gained from a broad third-party payer perspective (including reimbursed direct costs and specific transfer payments), when compared with the current strategy of vaccinating primarily risk groups with the conventional trivalent inactivated vaccine. Inclusion of patient co-payments and indirect costs in terms of productivity losses resulted in discounted 10-year cost savings of &lt;euro&gt; 3.4 billion. In conclusion, adopting universal influenza immunisation of healthy children and adolescents would lead to a substantial reduction in influenza-associated disease at a reasonable cost to the German statutory health insurance system. On the basis of the epidemiological and health economic simulation results, a recommendation of introducing annual routine influenza vaccination of children 2-17 years of age might be taken into consideration.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21643,""
"Evaluating the effects of machine pre-annotation and an interactive annotation interface on manual de-identification of clinical text","South, Mowery, Suo, Leng, FerrÃƒÂ¡ndez, Meystre, Chapman","https://doi.org/10.1016/j.jbi.2014.05.002","20150330","PubMed","Anonymization; Clinical corpora; Confidentiality; De-identification; Electronic health records; Medical informatics; Natural language processing; Patient data privacy; Electronic Health Records; Health Insurance Portability and Accountability Act; United States; User-Computer Interface","The Health Insurance Portability and Accountability Act (HIPAA) Safe Harbor method requires removal of 18 types of protected health information (PHI) from clinical documents to be considered ""de-identified"" prior to use for research purposes. Human review of PHI elements from a large corpus of clinical documents can be tedious and error-prone. Indeed, multiple annotators may be required to consistently redact information that represents each PHI class. Automated de-identification has the potential to improve annotation quality and reduce annotation time. For instance, using machine-assisted annotation by combining de-identification system outputs used as pre-annotations and an interactive annotation interface to provide annotators with PHI annotations for ""curation"" rather than manual annotation from ""scratch"" on raw clinical documents. In order to assess whether machine-assisted annotation improves the reliability and accuracy of the reference standard quality and reduces annotation effort, we conducted an annotation experiment. In this annotation study, we assessed the generalizability of the VA Consortium for Healthcare Informatics Research (CHIR) annotation schema and guidelines applied to a corpus of publicly available clinical documents called MTSamples. Specifically, our goals were to (1) characterize a heterogeneous corpus of clinical documents manually annotated for risk-ranked PHI and other annotation types (clinical eponyms and person relations), (2) evaluate how well annotators apply the CHIR schema to the heterogeneous corpus, (3) compare whether machine-assisted annotation (experiment) improves annotation quality and reduces annotation time compared to manual annotation (control), and (4) assess the change in quality of reference standard coverage with each added annotator's annotations. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21644,""
"An elective course in aromatherapy science","Esposito, Bystrek, Klein","https://doi.org/10.5688/ajpe78479","20150112","PubMed","active learning; aromatherapy; elective course; pharmaceutical sciences; Aromatherapy; Curriculum; Education, Pharmacy; Educational Measurement; Herb-Drug Interactions; Humans; Medication Errors; Oils, Volatile; Problem-Based Learning; Program Evaluation; Surveys and Questionnaires; Teaching","To evaluate the impact of an innovative team-taught elective course on second-year (P2) students' knowledge and skills relating to the relationship between aromatherapy and pharmacy. An Aromatherapy Science elective course was offered to P2 students in an accelerated doctor of pharmacy (PharmD) degree program and was designed to provide an elective course experience while focusing on active-learning skills such as group work, student-led presentations, and in-class activities. Lectures were designed to reinforce core curricular threads from the basic sciences within the pharmaceutical sciences department while highlighting key aromatherapy principles. Course evaluations, grades, and student self-assessments were used to evaluate student fulfillment and knowledge gained. Students agreed this hands-on course integrated pharmaceutical science experiences, enriched their pharmacy education, and provided knowledge to enhance their confidence in describing essential oil uses, drug interactions, and key aromatherapy clinical implications. Students agreed this course prepared them to identify essential oil therapeutic uses and potential essential oil-drug interactions, and interpret literature. The introduction of aromatherapy principles to pharmacy students will prepare a new generation of healthcare professionals on the role of alternative medicines.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21645,""
"[Neuroimaging in psychiatry: multivariate analysis techniques for diagnosis and prognosis]","Kambeitz, Koutsouleris","https://doi.org/10.1007/s00115-014-4022-x","20150825","PubMed","Algorithms; Artificial Intelligence; Brain; Computer Simulation; Data Interpretation, Statistical; Humans; Image Interpretation, Computer-Assisted; Mental Disorders; Models, Statistical; Multivariate Analysis; Neuroimaging; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity","Multiple studies successfully applied multivariate analysis to neuroimaging data demonstrating the potential utility of neuroimaging for clinical diagnostic and prognostic purposes. Summary of the current state of research regarding the application of neuroimaging in the field of psychiatry. Literature review of current studies. Results of current studies indicate the potential application of neuroimaging data across various diagnoses, such as depression, schizophrenia, bipolar disorder and dementia. Potential applications include disease classification, differential diagnosis and prediction of disease course. The results of the studies are heterogeneous although some studies report promising findings. Further multicentre studies are needed with clearly specified patient populations to systematically investigate the potential utility of neuroimaging for the clinical routine.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21646,""
"A systematic review of transanal minimally invasive surgery (TAMIS) from 2010 to 2013","Martin-Perez, Andrade-Ribeiro, Hunter, Atallah","https://doi.org/10.1007/s10151-014-1148-6","20150514","PubMed","Anal Canal; Endoscopy, Gastrointestinal; Humans; Microsurgery; Rectal Neoplasms; Robotics","Transanal minimally invasive surgery (TAMIS) was introduced as an alternative to transanal endoscopic microsurgery in 2010. Over the past 4Ã‚Â years, considerable international experience has been gained with this approach. Most published reports focus on TAMIS for local excision of rectal neoplasia, but there are other important applications such as transanal mesorectal excision for rectal cancer. This comprehensive review details the progress with TAMIS since its inception. Robotic transanal surgery is a natural evolution of TAMIS still in its early infancy, which is also reviewed. A comprehensive search of PubMed, EMBASE, the Cochrane Library, and Web of Knowledge was performed. Since the inception of TAMIS in 2009, 33 retrospective studies and case reports, and 3 abstracts have been published on TAMIS for local excision of rectal neoplasms, which represents a combined nÃ‚Â =Ã‚Â 390 TAMIS procedures performed worldwide using eight different types of TAMIS platforms. A total of 152 lesions were excised for benign disease including adenomas and high-grade dysplasias (39Ã‚Â %), 209 for malignancy for carcinomas in situ and adenocarcinomas (53.5Ã‚Â %). Twenty-nine (7.5Ã‚Â %) of TAMIS resections were for other pathology, of which the majority (23/29) were neuroendocrine lesions. The remaining resections were for mucocele, gastrointestinal stromal tumor, melanoma, and fibrosis. Robotic-TAMIS has also been reported, however, data are extremely limited as there are only 7 case reports (combined nÃ‚Â =Ã‚Â 11) in the published literature. Success with Robotic-TAMIS has been demonstrated with various patient positions and by use of a special glove port. Transanal total mesorectal excision using the TAMIS platform has also been demonstrated is several small series, and the feasibility of performing pure transanal total mesorectal excision has also been reported. Combined, nÃ‚Â =Ã‚Â 78 cases of transanal total mesorectal excision have been performed using TAMIS. The advantages of TAMIS-assisted transanal total mesorectal excision are discussed. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21647,""
"Evaluation of an exercise field test using heart rate monitors to assess cardiorespiratory fitness and heart rate recovery in an asymptomatic population","Coolbaugh, Anderson, Wilson, Hawkins, Amsterdam","https://doi.org/10.1371/journal.pone.0097704","20150115","PubMed","Adolescent; Adult; Asymptomatic Diseases; Exercise Test; Exercise Tolerance; Female; Heart Rate; Humans; Male; Middle Aged; Respiratory Physiological Phenomena; Running; Walking; Young Adult","Measures of cardiorespiratory fitness (CRF) and heart rate recovery (HRR) can improve risk stratification for cardiovascular disease, but these measurements are rarely made in asymptomatic individuals due to cost. An exercise field test (EFT) to assess CRF and HRR would be an inexpensive method for cardiovascular disease risk assessment in large populations. This study assessed 1) the predictive accuracy of a 12-minute run/walk EFT for estimating CRF ([Formula: see text]) and 2) the accuracy of HRR measured after an EFT using a heart rate monitor (HRM) in an asymptomatic population. Fifty subjects (48% women) ages 18-45 years completed a symptom-limited exercise tolerance test (ETT) (Bruce protocol) and an EFT on separate days. During the ETT, [Formula: see text] was measured by a metabolic cart, and heart rate was measured continuously by a HRM and a metabolic cart. EFT distance and sex independently predicted[Formula: see text]. The average absolute difference between observed and predicted [Formula: see text] was 0.26 Ã‚Â± 3.27 mlÃ‚Â·kg-1Ã‚Â·min-1 for our model compared to 7.55 Ã‚Â± 3.64 mlÃ‚Â·kg-1Ã‚Â·min-1 for the Cooper model. HRM HRR data were equivalent to respective metabolic cart values during the ETT. HRR at 1 minute post-exercise during ETT compared to the EFT had a moderate correlation (r=0.75, p&lt;0.001). A more accurate model to estimate CRF from a 12-minute run/walk EFT was developed, and HRR can be measured using a HRM in an asymptomatic population outside of clinical settings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21648,""
"Patient-level temporal aggregation for text-based asthma status ascertainment","Wu, Juhn, Sohn, Liu","https://doi.org/10.1136/amiajnl-2013-002463","20141013","PubMed","Asthma epidemiology; Information extraction; Natural language processing; Patient classification; Algorithms; Artificial Intelligence; Asthma; Child; Classification; Decision Making, Computer-Assisted; Humans; Mathematical Concepts; Natural Language Processing; Pediatrics; Time","To specify the problem of patient-level temporal aggregation from clinical text and introduce several probabilistic methods for addressing that problem. The patient-level perspective differs from the prevailing natural language processing (NLP) practice of evaluating at the term, event, sentence, document, or visit level. We utilized an existing pediatric asthma cohort with manual annotations. After generating a basic feature set via standard clinical NLP methods, we introduce six methods of aggregating time-distributed features from the document level to the patient level. These aggregation methods are used to classify patients according to their asthma status in two hypothetical settings: retrospective epidemiology and clinical decision support. In both settings, solid patient classification performance was obtained with machine learning algorithms on a number of evidence aggregation methods, with Sum aggregation obtaining the highest F1 score of 85.71% on the retrospective epidemiological setting, and a probability density function-based method obtaining the highest F1 score of 74.63% on the clinical decision support setting. Multiple techniques also estimated the diagnosis date (index date) of asthma with promising accuracy. The clinical decision support setting is a more difficult problem. We rule out some aggregation methods rather than determining the best overall aggregation method, since our preliminary data set represented a practical setting in which manually annotated data were limited. Results contrasted the strengths of several aggregation algorithms in different settings. Multiple approaches exhibited good patient classification performance, and also predicted the timing of estimates with reasonable accuracy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21649,""
"High-throughput screen of natural product libraries for hsp90 inhibitors","Davenport, Balch, Galam, Girgis, Hall, Blagg, Matts","https://doi.org/10.3390/biology3010101","20140516","PubMed","","Hsp90 has become the target of intensive investigation, as inhibition of its function has the ability to simultaneously incapacitate proteins that function in pathways that represent the six hallmarks of cancer. While a number of Hsp90 inhibitors have made it into clinical trials, a number of short-comings have been noted, such that the search continues for novel Hsp90 inhibitors with superior pharmacological properties. To identify new potential Hsp90 inhibitors, we have utilized a high-throughput assay based on measuring Hsp90-dependent refolding of thermally denatured luciferase to screen natural compound libraries. Over 4,000 compounds were screen with over 100 hits. Data mining of the literature indicated that 51 compounds had physiological effects that Hsp90 inhibitors also exhibit, and/or the ability to downregulate the expression levels of Hsp90-dependent proteins. Of these 51 compounds, seven were previously characterized as Hsp90 inhibitors. Four compounds, anthothecol, garcinol, piplartine, and rottlerin, were further characterized, and the ability of these compounds to inhibit the refolding of luciferase, and reduce the rate of growth of MCF7 breast cancer cells, correlated with their ability to suppress the Hsp90-dependent maturation of the heme-regulated eIF2ÃŽÂ± kinase, and deplete cultured cells of Hsp90-dependent client proteins. Thus, this screen has identified an additional 44 compounds with known beneficial pharmacological properties, but with unknown mechanisms of action as possible new inhibitors of the Hsp90 chaperone machine. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21650,""
"Developing and evaluating a machine learning based algorithm to predict the need of pediatric intensive care unit transfer for newly hospitalized children","Zhai, Brady, Li, Lingren, Ni, Wheeler, Solti","https://doi.org/10.1016/j.resuscitation.2014.04.009","20150401","PubMed","Clinical care; Clinical status deterioration; EHR; Machine learning; PEWS; PICU; Algorithms; Artificial Intelligence; Child; Child, Hospitalized; Female; Follow-Up Studies; Health Services Needs and Demand; Humans; Infant; Intensive Care Units, Pediatric; Male; Patient Transfer; ROC Curve; Retrospective Studies; Severity of Illness Index","Early warning scores (EWS) are designed to identify early clinical deterioration by combining physiologic and/or laboratory measures to generate a quantified score. Current EWS leverage only a small fraction of Electronic Health Record (EHR) content. The planned widespread implementation of EHRs brings the promise of abundant data resources for prediction purposes. The three specific aims of our research are: (1) to develop an EHR-based automated algorithm to predict the need for Pediatric Intensive Care Unit (PICU) transfer in the first 24h of admission; (2) to evaluate the performance of the new algorithm on a held-out test data set; and (3) to compare the effectiveness of the new algorithm's with those of two published Pediatric Early Warning Scores (PEWS). The cases were comprised of 526 encounters with 24-h Pediatric Intensive Care Unit (PICU) transfer. In addition to the cases, we randomly selected 6772 control encounters from 62516 inpatient admissions that were never transferred to the PICU. We used 29 variables in a logistic regression and compared our algorithm against two published PEWS on a held-out test data set. The logistic regression algorithm achieved 0.849 (95% CI 0.753-0.945) sensitivity, 0.859 (95% CI 0.850-0.868) specificity and 0.912 (95% CI 0.905-0.919) area under the curve (AUC) in the test set. Our algorithm's AUC was significantly higher, by 11.8 and 22.6% in the test set, than two published PEWS. The novel algorithm achieved higher sensitivity, specificity, and AUC than the two PEWS reported in the literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21651,""
"OncoSearch: cancer gene search engine with literature evidence","Lee, Dang, Lee, Park","https://doi.org/10.1093/nar/gku368","20140918","PubMed","Data Mining; Gene Expression Regulation, Neoplastic; Genes, Neoplasm; Internet; Search Engine","In order to identify genes that are involved in oncogenesis and to understand how such genes affect cancers, abnormal gene expressions in cancers are actively studied. For an efficient access to the results of such studies that are reported in biomedical literature, the relevant information is accumulated via text-mining tools and made available through the Web. However, current Web tools are not yet tailored enough to allow queries that specify how a cancer changes along with the change in gene expression level, which is an important piece of information to understand an involved gene's role in cancer progression or regression. OncoSearch is a Web-based engine that searches Medline abstracts for sentences that mention gene expression changes in cancers, with queries that specify (i) whether a gene expression level is up-regulated or down-regulated, (ii) whether a certain type of cancer progresses or regresses along with such gene expression change and (iii) the expected role of the gene in the cancer. OncoSearch is available through http://oncosearch.biopathway.org. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21652,""
"Piloting an approach to rapid and automated assessment of a new research initiative: Application to the National Cancer Institute's Provocative Questions initiative","Hsu, Williams, Dijoseph, Schnell, Finstad, Lee, Greenspan, Corrigan","https://doi.org/10.1093/reseval/rvt024","20211021","PubMed","","Funders of biomedical research are often challenged to understand how a new funding initiative fits within the agency's portfolio and the larger research community. While traditional assessment relies on retrospective review by subject matter experts, it is now feasible to design portfolio assessment and gap analysis tools leveraging administrative and grant application data that can be used for early and continued analysis. We piloted such methods on the National Cancer Institute's Provocative Questions (PQ) initiative to address key questions regarding diversity of applicants; whether applicants were proposing new avenues of research; and whether grant applications were filling portfolio gaps. For the latter two questions, we defined measurements called focus shift and relevance, respectively, based on text similarity scoring. We demonstrate that two types of applicants were attracted by the PQs at rates greater than or on par with the general National Cancer Institute applicant pool: those with clinical degrees and new investigators. Focus shift scores tended to be relatively low, with applicants not straying far from previous research, but the majority of applications were found to be relevant to the PQ the application was addressing. Sensitivity to comparison text and inability to distinguish subtle scientific nuances are the primary limitations of our automated approaches based on text similarity, potentially biasing relevance and focus shift measurements. We also discuss potential uses of the relevance and focus shift measures including the design of outcome evaluations, though further experimentation and refinement are needed for a fuller understanding of these measures before broad application.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21653,""
"Trends in demographics and management of obstructing colorectal cancer","Moolla, Madiba","https://doi.org/10.1007/s00268-014-2595-y","20150722","PubMed","Acute Disease; Adult; African Continental Ancestry Group; Age Factors; Aged; Colorectal Neoplasms; Colostomy; Demography; European Continental Ancestry Group; Female; Humans; India; Intestinal Obstruction; Male; Middle Aged; Retrospective Studies; Sex Factors; South Africa; Stents","Obstructing colorectal cancer (CRC) has an aggressive clinical course and poorer prognosis. With the increasing incidence and differing clinical and pathologic spectrum of CRC among Black patients, as well as a paucity of African studies, regional analysis is required. Our aim was to describe the demographics and management of obstructing CRC among the different racial groups in South Africa and to compare these parameters with international standards. Patients referred to Inkosi Albert Luthuli Central Hospital, Durban, South Africa, with CRC between 2000 and 2012 were followed prospectively. Demographic information, site of obstruction, and management of patients who underwent emergency surgery for malignant large bowel obstruction were analyzed separately. CRC was diagnosed in 1,425 patients. A total of 203 three patients (14.3 %) required emergent treatment for acute large bowel obstruction. The mean age at presentation with obstructing CRC was 59 years. Black patients presented significantly younger (50 years) than White (64), Indian (60), or Colored (61) patients (p &lt; 0.001). The most common sites of obstruction were the sigmoid colon and rectum. A total of 58 patients (29 %) had concomitant metastatic disease. No difference was found between race, sex, and sex per race in patients with concurrent metastatic disease (p = 0.227, p = 0.415, p = 0.798, respectively). Of the 203 patients, 128 (63 %) were managed by resection, 37 (18 %) by colonic stenting, 35 (17 %) by colostomy, and 3 (2 %) by colonic bypass. Stenting was unsuccessful in six patients. Tumor location of patients presenting with obstruction is comparable to that cited in international literature; however, the age of presentation among Black patients is more than a decade earlier than in other ethnic groups. Surgical management should be individualized. Stenting remains a reliable alternative in select cases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21654,""
"The comparison between robotic and manual ablations in the treatment of atrial fibrillation: a systematic review and meta-analysis","Zhang, Jia, Su, Lin, Peng, Niu","https://doi.org/10.1371/journal.pone.0096331","20150112","PubMed","Atrial Fibrillation; Catheter Ablation; Clinical Trials as Topic; Cross-Over Studies; Female; Fluoroscopy; Humans; Male; Middle Aged; Randomized Controlled Trials as Topic; Robotics; Treatment Outcome","To examine in what aspects and to what extent robotic ablation is superior over manual ablation, we sought to design a meta-analysis to compare clinical outcomes between the two ablations in the treatment of atrial fibrillation. A literature search was conducted of PubMed and EMBASE databases before December 1, 2013. Data were extracted independently and in duplicate from 8 clinical articles and 792 patients. Effect estimates were expressed as weighted mean difference (WMD) or odds ratio (OR) and the accompanied 95% confidence interval (95% CI). Pooling the results of all qualified trials found significant reductions in fluoroscopic time (minutes) (WMD; 95% CI; P: -8.9; -12.54 to -5.26; &lt;0.0005) and dose-area product (GyÃƒâ€”cm2) (WMD; 95% CI; P: -1065.66; -1714.36 to -416.96; 0.001) for robotic ablation relative to manual ablation, with evident heterogeneity (P&lt;0.0005) and a low probability of publication bias. In subgroup analysis, great improvement of fluoroscopic time in patients with robotic ablation was consistently presented in both randomized and nonrandomized clinical trials, particularly in the former (WMD; 95% CI; P: -12.61; -15.13 to -10.09; &lt;0.0005). Success rate of catheter ablation was relatively higher in patients with robotic ablation than with manual ablation (OR; 95% CI; P: 3.45; 0.24 to 49.0; 0.36), the difference yet exhibiting no statistical significance. This study confirmed and extended previous observations by quantifying great reductions of fluoroscopic time and dose-area product in patients referred for robotic ablation than for manual ablation in the treatment of atrial fibrillation, especially in randomized clinical trials.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21655,""
"A review of the available urology skills training curricula and their validation","Shepherd, Arora, Abboudi, Shamim Khan, Dasgupta, Ahmed","https://doi.org/10.1016/j.jsurg.2013.09.005","20150105","PubMed","Interpersonal and Communication Skills; Medical Knowledge; Practice-Based Learning and Improvement; curriculum; education; simulation; surgery; training; urology; Clinical Competence; Curriculum; Education, Medical; Endoscopy; Laparoscopy; Robotics; Urology; Validation Studies as Topic","The transforming field of urological surgery continues to demand development of novel training devices and curricula for its trainees. Contemporary trainees have to balance workplace demands while overcoming the cognitive barriers of acquiring skills in rapidly multiplying and advancing surgical techniques. This article provides a brief review of the process involved in developing a surgical curriculum and the current status of real and simulation-based curricula in the 4 subgroups of urological surgical practice: open, laparoscopic, endoscopic, and robotic. An informal literature review was conducted to provide a snapshot into the variety of simulation training tools available for technical and nontechnical urological surgical skills within all subgroups of urological surgery using the following keywords: ""urology, surgery, training, curriculum, validation, non-technical skills, technical skills, LESS, robotic, laparoscopy, animal models."" Validated training tools explored in research were tabulated and summarized. A total of 20 studies exploring validated training tools were identified. Huge variation was noticed in the types of validity sought by researchers and suboptimal incorporation of these tools into curricula was noted across the subgroups of urological surgery. The following key recommendations emerge from the review: adoption of simulation-based curricula in training; better integration of dedicated training time in simulated environments within a trainee's working hours; better incentivization for educators and assessors to improvise, research, and deliver teaching using the technologies available; and continued emphasis on developing nontechnical skills in tandem with technical operative skills.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21656,""
"Integrating neuroinformatics tools in TheVirtualBrain","Woodman, Pezard, Domide, Knock, Sanz-Leon, Mersmann, McIntosh, Jirsa","https://doi.org/10.3389/fninf.2014.00036","20140505","PubMed","Python; brain networks; connectivity; electroencephalography; functional MRI; magnetoencephalography; neural mass; time delays","TheVirtualBrain (TVB) is a neuroinformatics Python package representing the convergence of clinical, systems, and theoretical neuroscience in the analysis, visualization and modeling of neural and neuroimaging dynamics. TVB is composed of a flexible simulator for neural dynamics measured across scales from local populations to large-scale dynamics measured by electroencephalography (EEG), magnetoencephalography (MEG) and functional magnetic resonance imaging (fMRI), and core analytic and visualization functions, all accessible through a web browser user interface. A datatype system modeling neuroscientific data ties together these pieces with persistent data storage, based on a combination of SQL and HDF5. These datatypes combine with adapters allowing TVB to integrate other algorithms or computational systems. TVB provides infrastructure for multiple projects and multiple users, possibly participating under multiple roles. For example, a clinician might import patient data to identify several potential lesion points in the patient's connectome. A modeler, working on the same project, tests these points for viability through whole brain simulation, based on the patient's connectome, and subsequent analysis of dynamical features. TVB also drives research forward: the simulator itself represents the culmination of several simulation frameworks in the modeling literature. The availability of the numerical methods, set of neural mass models and forward solutions allows for the construction of a wide range of brain-scale simulation scenarios. This paper briefly outlines the history and motivation for TVB, describing the framework and simulator, giving usage examples in the web UI and Python scripting. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21657,""
"Searching for religion and mental health studies required health, social science, and grey literature databases","Wright, Cottrell, Mir","https://doi.org/10.1016/j.jclinepi.2014.02.017","20140829","PubMed","Bibliographic databases; Depression; Information retrieval; Literature searching; Qualitative research; Religion; Databases, Factual; Depression; Humans; Information Storage and Retrieval; Mental Health; Religion and Psychology; Social Sciences","To determine the optimal databases to search for studies of faith-sensitive interventions for treating depression. We examined 23 health, social science, religious, and grey literature databases searched for an evidence synthesis. Databases were prioritized by yield of (1) search results, (2) potentially relevant references identified during screening, (3) included references contained in the synthesis, and (4) included references that were available in the database. We assessed the impact of databases beyond MEDLINE, EMBASE, and PsycINFO by their ability to supply studies identifying new themes and issues. We identified pragmatic workload factors that influence database selection. PsycINFO was the best performing database within all priority lists. ArabPsyNet, CINAHL, Dissertations and Theses, EMBASE, Global Health, Health Management Information Consortium, MEDLINE, PsycINFO, and Sociological Abstracts were essential for our searches to retrieve the included references. Citation tracking activities and the personal library of one of the research teams made significant contributions of unique, relevant references. Religion studies databases (Am Theo Lib Assoc, FRANCIS) did not provide unique, relevant references. Literature searches for reviews and evidence syntheses of religion and health studies should include social science, grey literature, non-Western databases, personal libraries, and citation tracking activities.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21658,""
"N-gram support vector machines for scalable procedure and diagnosis classification, with applications to clinical free text data from the intensive care unit","Marafino, Davies, Bardach, Dean, Dudley","https://doi.org/10.1136/amiajnl-2014-002694","20141013","PubMed","ICU; Risk adjustment; SVM; classification; n-gram; Adult; Classification; Electronic Health Records; Humans; Infant, Newborn; Information Storage and Retrieval; Intensive Care Units; Jaundice, Neonatal; Phototherapy; Respiration, Artificial; Support Vector Machine","Existing risk adjustment models for intensive care unit (ICU) outcomes rely on manual abstraction of patient-level predictors from medical charts. Developing an automated method for abstracting these data from free text might reduce cost and data collection times. To develop a support vector machine (SVM) classifier capable of identifying a range of procedures and diagnoses in ICU clinical notes for use in risk adjustment. We selected notes from 2001-2008 for 4191 neonatal ICU (NICU) and 2198 adult ICU patients from the MIMIC-II database from the Beth Israel Deaconess Medical Center. Using these notes, we developed an implementation of the SVM classifier to identify procedures (mechanical ventilation and phototherapy in NICU notes) and diagnoses (jaundice in NICU and intracranial hemorrhage (ICH) in adult ICU). On the jaundice classification task, we also compared classifier performance using n-gram features to unigrams with application of a negation algorithm (NegEx). Our classifier accurately identified mechanical ventilation (accuracy=0.982, F1=0.954) and phototherapy use (accuracy=0.940, F1=0.912), as well as jaundice (accuracy=0.898, F1=0.884) and ICH diagnoses (accuracy=0.938, F1=0.943). Including bigram features improved performance on the jaundice (accuracy=0.898 vs 0.865) and ICH (0.938 vs 0.927) tasks, and outperformed NegEx-derived unigram features (accuracy=0.898 vs 0.863) on the jaundice task. Overall, a classifier using n-gram support vectors displayed excellent performance characteristics. The classifier generalizes to diverse patient populations, diagnoses, and procedures. SVM-based classifiers can accurately identify procedure status and diagnoses among ICU patients, and including n-gram features improves performance, compared to existing methods.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21659,""
"Robotic-assisted versus laparoscopic colorectal surgery: a meta-analysis of four randomized controlled trials","Liao, Zhao, Lin, Li, Yuan, Du, Chen, Deng","https://doi.org/10.1186/1477-7819-12-122","20140911","PubMed","Colorectal Neoplasms; Colorectal Surgery; Humans; Laparoscopy; Prognosis; Randomized Controlled Trials as Topic; Robotics","Robotic-assisted laparoscopy is popularly performed for colorectal disease. The objective of this meta-analysis was to compare the safety and efficacy of robotic-assisted colorectal surgery (RCS) and laparoscopic colorectal surgery (LCS) for colorectal disease based on randomized controlled trial studies. Literature searches of electronic databases (Pubmed, Web of Science, and Cochrane Library) were performed to identify randomized controlled trial studies that compared the clinical or oncologic outcomes of RCS and LCS. This meta-analysis was performed using the Review Manager (RevMan) software (version 5.2) that is provided by the Cochrane Collaboration. The data used were mean differences and odds ratios for continuous and dichotomous variables, respectively. Fixed-effects or random-effects models were adopted according to heterogeneity. Four randomized controlled trial studies were identified for this meta-analysis. In total, 110 patients underwent RCS, and 116 patients underwent LCS. The results revealed that estimated blood losses (EBLs), conversion rates and times to the recovery of bowel function were significantly reduced following RCS compared with LCS. There were no significant differences in complication rates, lengths of hospital stays, proximal margins, distal margins or harvested lymph nodes between the two techniques. RCS is a promising technique and is a safe and effective alternative to LCS for colorectal surgery. The advantages of RCS include reduced EBLs, lower conversion rates and shorter times to the recovery of bowel function. Further studies are required to define the financial effects of RCS and the effects of RCS on long-term oncologic outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21660,""
"GenCLiP 20: a web server for functional clustering of genes and construction of molecular networks based on free terms","Wang, Zhao, Lin, Su, Chen, Huang, Wang, Zhang, Hu, Yao, Huang","https://doi.org/10.1093/bioinformatics/btu241","20150115","PubMed","Cluster Analysis; Data Mining; Gene Regulatory Networks; Genes; Humans; Internet; MEDLINE; Software","Identifying biological functions and molecular networks in a gene list and how the genes may relate to various topics is of considerable value to biomedical researchers. Here, we present a web-based text-mining server, GenCLiP 2.0, which can analyze human genes with enriched keywords and molecular interactions. Compared with other similar tools, GenCLiP 2.0 offers two unique features: (i) analysis of gene functions with free terms (i.e. any terms in the literature) generated by literature mining or provided by the user and (ii) accurate identification and integration of comprehensive molecular interactions from Medline abstracts, to construct molecular networks and subnetworks related to the free terms. http://ci.smu.edu.cn. Supplementary data are available at Bioinformatics online.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21661,""
"Environmental factors in an Ontario community with disparities in colorectal cancer incidence","Sritharan, Kamaleswaran, McFarlan, Lemonde, George, Sanchez","https://doi.org/10.5539/gjhs.v6n3p175","20140729","PubMed","Adolescent; Adult; Aged; Alcoholism; Colorectal Neoplasms; Environmental Exposure; Female; Health Status; Health Status Disparities; Humans; Incidence; Male; Middle Aged; Mining; Ontario; Pesticides; Risk Factors; Smoking; Socioeconomic Factors; Young Adult","In Ontario, there are significant geographical disparities in colorectal cancer incidence. In particular, the northern region of Timiskaming has the highest incidence of colorectal cancer in Ontario while the southern region of Peel displays the lowest. We aimed to identify non-nutritional modifiable environmental factors in Timiskaming that may be associated with its diverging colorectal cancer incidence rates when compared to Peel. We performed a systematic review to identify established and proposed environmental factors associated with colorectal cancer incidence, created an assessment questionnaire tool regarding these environmental exposures, and applied this questionnaire among 114 participants from the communities of Timiskaming and Peel. We found that tobacco smoking, alcohol consumption, residential use of organochlorine pesticides, and potential exposure to toxic metals were dominant factors among Timiskaming respondents. We found significant differences regarding active smoking, chronic alcohol use, reported indoor and outdoor household pesticide use, and gold and silver mining in the Timiskaming region. This study, the first to assess environmental factors in the Timiskaming community, identified higher reported exposures to tobacco, alcohol, pesticides, and mining in Timiskaming when compared with Peel. These significant findings highlight the need for specific public health assessments and interventions regarding community environmental exposures.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21662,""
"Comparison of search strategies in systematic reviews of adverse effects to other systematic reviews","Golder, Loke, Zorzela","https://doi.org/10.1111/hir.12041","20151005","PubMed","MEDLINE; bibliographic databases; database searching; information retrieval; meta analysis; review, literature; review, systematic; search strategies; searching; Databases, Bibliographic; Databases, Factual; Drug-Related Side Effects and Adverse Reactions; Humans; Information Storage and Retrieval; MEDLINE; Research Design; Review Literature as Topic","Research indicates that the methods used to identify data for systematic reviews of adverse effects may need to differ from other systematic reviews. To compare search methods in systematic reviews of adverse effects with other reviews. The search methodologies in 849 systematic reviews of adverse effects were compared with other reviews. Poor reporting of search strategies is apparent in both systematic reviews of adverse effects and other types of systematic reviews. Systematic reviews of adverse effects are less likely to restrict their searches to MEDLINE or include only randomised controlled trials (RCTs). The use of other databases is largely dependent on the topic area and the year the review was conducted, with more databases searched in more recent reviews. Adverse effects search terms are used by 72% of reviews and despite recommendations only two reviews report using floating subheadings. The poor reporting of search strategies in systematic reviews is universal, as is the dominance of searching MEDLINE. However, reviews of adverse effects are more likely to include a range of study designs (not just RCTs) and search beyond MEDLINE.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21663,""
"Endovascular neurointervention success and complication rates in the first year of independent practice in a suburban hospital setup","Kumar","https://doi.org/10.4103/0976-3147.127864","20140417","PubMed","Acute stroke; aneurysm coiling; cerebral angiography; combined lysis of thrombus in brain ischemia using transcranial ultrasound and systemic tissue plasminogen activator; embolization; endovascular neurointervention; sonothrombolysis","Endovascular neurointervention (interventional neuroradiology) is a highly demanding science requiring deep understanding of disease, anatomy, clinical skills and manual dexterity, consequently with a long learning curve and thus posing significant challenges to a physician entering new into the competitive arena. To evaluate the procedural success, complications and outcome in the first year of independent endovascular neurointervention practice in a suburban hospital. Retrospective analysis of prospectively maintained data of all diagnostic and therapeutic neurointerventional cases performed by the author between the period of January 02, 2012 and December 31, 2012. A total of 61 procedures were performed. The performance success rate of the diagnostic procedures was 100% (38/38) and that of therapeutic procedures was 82.6% (19/23). The periprocedural complication rates were nil and 13%, respectively, for diagnostic and therapeutic procedures. The 3-month patient outcome for therapeutic procedures was good outcome (Modified Rankin Scale &lt;2) in 87% cases (20/23), and poor outcome in 13% (2 dead and 1 debilitated with Modified Rankin Scale of 3). For a well-trained endovascular neurointerventionalist, the first year of practice had high procedural success rate and acceptable complication with patient outcome rates comparable to the existing literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21664,""
"Robotic versus open partial nephrectomy: a systematic review and meta-analysis","Wu, Li, Liu, Cai, Ye, Lv, Yang, Sheng, Song, Qu, Xiao, Sun, Wang","https://doi.org/10.1371/journal.pone.0094878","20150207","PubMed","Blood Loss, Surgical; Cost-Benefit Analysis; Humans; Length of Stay; Nephrectomy; Operative Time; Robotics; Treatment Outcome","To critically review the currently available evidence of studies comparing robotic partial nephrectomy (RPN) and open partial nephrectomy (OPN). A comprehensive review of the literature from Pubmed, Web of Science and Scopus was performed in October 2013. All relevant studies comparing RPN with OPN were included for further screening. A cumulative meta-analysis of all comparative studies was performed and publication bias was assessed by a funnel plot. Eight studies were included for the analysis, including a total of 3418 patients (757 patients in the robotic group and 2661 patients in the open group). Although RPN procedures had a longer operative time (weighted mean difference [WMD]: 40.89; 95% confidence interval [CI], 14.39-67.40; pÃ¢â‚¬Å =Ã¢â‚¬Å 0.002), patients in this group benefited from a lower perioperative complication rate (19.3% for RPN and 29.5% for OPN; odds ratio [OR]: 0.53; 95%CI, 0.42-0.67; p&lt;0.00001), shorter hospital stay (WMD: -2.78; 95%CI, -3.36 to -1.92; p&lt;0.00001), less estimated blood loss(WMD: -106.83; 95%CI, -176.4 to -37.27; pÃ¢â‚¬Å =Ã¢â‚¬Å 0.003). Transfusions, conversion to radical nephrectomy, ischemia time and estimated GFR change, margin status, and overall cost were comparable between the two techniques. The main limitation of the present meta-analysis is the non-randomization of all included studies. RPN appears to be an efficient alternative to OPN with the advantages of a lower rate of perioperative complications, shorter length of hospital stay and less blood loss. Nevertheless, high quality prospective randomized studies with longer follow-up period are needed to confirm these findings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21665,""
"An information retrieval system for computerized patient records in the context of a daily hospital practice: the example of the LÃƒÂ©on BÃƒÂ©rard Cancer Center (France)","Biron, Metzger, Pezet, Sebban, Barthuet, Durand","https://doi.org/10.4338/ACI-2013-08-CR-0065","20150515","PubMed","Electronic health records; data mining; information storage and retrieval; user-computer interface; Biomedical Research; France; Health Records, Personal; Hospitals; Humans; Information Storage and Retrieval; Internet; Medical Records Systems, Computerized; Qualitative Research; Search Engine; User-Computer Interface","A full-text search tool was introduced into the daily practice of LÃƒÂ©on BÃƒÂ©rard Center (France), a health care facility devoted to treatment of cancer. This tool was integrated into the hospital information system by the IT department having been granted full autonomy to improve the system. To describe the development and various uses of a tool for full-text search of computerized patient records. The technology is based on Solr, an open-source search engine. It is a web-based application that processes HTTP requests and returns HTTP responses. A data processing pipeline that retrieves data from different repositories, normalizes, cleans and publishes it to Solr, was integrated in the information system of the Leon BÃƒÂ©rard center. The IT department developed also user interfaces to allow users to access the search engine within the computerized medical record of the patient. From January to May 2013, 500 queries were launched per month by an average of 140 different users. Several usages of the tool were described, as follows: medical management of patients, medical research, and improving the traceability of medical care in medical records. The sensitivity of the tool for detecting the medical records of patients diagnosed with both breast cancer and diabetes was 83.0%, and its positive predictive value was 48.7% (gold standard: manual screening by a clinical research assistant). The project demonstrates that the introduction of full-text-search tools allowed practitioners to use unstructured medical information for various purposes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21666,""
"Disrupted structural and functional brain connectomes in mild cognitive impairment and Alzheimer's disease","Dai, He","https://doi.org/10.1007/s12264-013-1421-0","20141203","PubMed","Alzheimer Disease; Cognitive Dysfunction; Connectome; Humans; Neural Pathways","Alzheimer's disease (AD) is the most common type of dementia, comprising an estimated 60-80% of all dementia cases. It is clinically characterized by impairments of memory and other cognitive functions. Previous studies have demonstrated that these impairments are associated with abnormal structural and functional connections among brain regions, leading to a disconnection concept of AD. With the advent of a combination of non-invasive neuroimaging (structural magnetic resonance imaging (MRI), diffusion MRI, and functional MRI) and neurophysiological techniques (electroencephalography and magnetoencephalography) with graph theoretical analysis, recent studies have shown that patients with AD and mild cognitive impairment (MCI), the prodromal stage of AD, exhibit disrupted topological organization in large-scale brain networks (i.e., connectomics) and that this disruption is significantly correlated with the decline of cognitive functions. In this review, we summarize the recent progress of brain connectomics in AD and MCI, focusing on the changes in the topological organization of large-scale structural and functional brain networks using graph theoretical approaches. Based on the two different perspectives of information segregation and integration, the literature reviewed here suggests that AD and MCI are associated with disrupted segregation and integration in brain networks. Thus, these connectomics studies open up a new window for understanding the pathophysiological mechanisms of AD and demonstrate the potential to uncover imaging biomarkers for clinical diagnosis and treatment evaluation for this disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21667,""
"Treatment of Laryngoceles: what is the progress over the last two decades?","Zelenik, Stanikova, Smatanova, Cerny, Kominek","https://doi.org/10.1155/2014/819453","20141209","PubMed","History, 20th Century; History, 21st Century; Humans; Laryngocele; Laryngoscopy; Laser Therapy; PubMed; Robotic Surgical Procedures","To review surgical techniques used in the treatment of laryngoceles over the last two decades and point out developments and trends. PubMed, the Cochrane Library, and the JBI Library of Systematic Reviews were searched using the term ""laryngocele."" Demographic data, type of laryngocele, presence of a laryngopyocele, type of treatment and need for a tracheotomy were assessed. Overall, data on 86 patients were analyzed, culled from 50 articles, of which 41 were case reports and 9 were case series. No single systematic review or meta-analysis or randomized controlled trial has been published on the topic. Altogether, 71 laryngoceles in 63 patients met the criteria for further analysis focusing on surgical treatment. An external approach was selected in 25/29 (86.2%) cases of combined laryngoceles. Microlaryngoscopic resection using a CO2 laser was performed in three cases and endoscopic robotic surgery in one case. The majority of patients with an internal laryngocele, 31/42 (73.8%), were treated using the microlaryngoscopy approach. Microlaryngoscopy involving the use of a CO2 laser has become the main therapeutic procedure for the treatment of internal laryngoceles during the past 20 years. An external approach still remains the main therapeutic approach for the treatment of combined laryngoceles.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21668,""
"Texture analysis of T1 - and T2 -weighted MR images and use of probabilistic neural network to discriminate posterior fossa tumours in children","Orphanidou-Vlachou, Vlachos, Davies, Arvanitis, Grundy, Peet","https://doi.org/10.1002/nbm.3099","20150204","PubMed","MRI; paediatric posterior fossa tumours; texture analysis; Child; Humans; Infratentorial Neoplasms; Magnetic Resonance Imaging; Neural Networks, Computer; Principal Component Analysis; Probability","Brain tumours are the most common solid tumours in children, representing 20% of all cancers. The most frequent posterior fossa tumours are medulloblastomas, pilocytic astrocytomas and ependymomas. Texture analysis (TA) of MR images can be used to support the diagnosis of these tumours by providing additional quantitative information. MaZda software was used to perform TA on T1 - and T2 -weighted images of children with pilocytic astrocytomas, medulloblastomas and ependymomas of the posterior fossa, who had MRI at Birmingham Children's Hospital prior to treatment. The region of interest was selected on three slices per patient in Image J, using thresholding and manual outlining. TA produced 279 features, which were reduced using principal component analysis (PCA). The principal components (PCs) explaining 95% of the variance were used in a linear discriminant analysis (LDA) and a probabilistic neural network (PNN) to classify the cases, using DTREG statistics software. PCA of texture features from both T1 - and T2 -weighted images yielded 13 PCs to explain &gt;95% of the variance. The PNN classifier for T1 -weighted images achieved 100% accuracy on training the data and 90% on leave-one-out cross-validation (LOOCV); for T2 -weighted images, the accuracy was 100% on training the data and 93.3% on LOOCV. A PNN classifier with T1 and T2 PCs achieved 100% accuracy on training the data and 85.8% on LOOCV. LDA classification accuracies were noticeably poorer. The features found to hold the highest discriminating potential were all co-occurrence matrix derived, where adjacent pixels had highly correlated intensities. This study shows that TA can be performed on standard T1 - and T2 -weighted images of childhood posterior fossa tumours using readily available software to provide high diagnostic accuracy. Discriminatory features do not correspond to those used in the clinical interpretation of the images and therefore provide novel tumour information.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21669,""
"Feasibility and outcomes regarding open and laparoscopic radical prostatectomy in patients with previous synthetic mesh inguinal hernia repair: meta-analysis and systematic review of 7,497 patients","Picozzi, Ricci, Bonavina, Bona, Stubinski, Macchi, Ratti, Finkelberg, Carmignani","https://doi.org/10.1007/s00345-014-1282-9","20160108","PubMed","Feasibility Studies; Hernia, Inguinal; Herniorrhaphy; Humans; Laparoscopy; Male; Prostatectomy; Prostatic Neoplasms; Robotic Surgical Procedures; Surgical Mesh; Treatment Outcome","The purpose of this article is to contribute information to the interpretation of the feasibility and outcomes regarding open, laparoscopic and robotic strategies of radical prostatectomy in patients with previous synthetic mesh inguinal hernia repair. A bibliographic search covering the period from January 1980 to September 2012 was conducted in PubMed, MEDLINE and EMBASE. Database searches yielded 28 references. This analysis is based on the eleven studies that fulfilled the predefined criteria. A total of 7,497 patients were included. In the study group, there were 462 patients. The surgical prostatectomy techniques were open in five studies, laparoscopic in three and robotic in the remaining three. The control group consisted in 7,035 patients. The comparison of the open procedure performed in patients with a previous mesh herniorrhaphy and controls shows that the number of lymph nodes removed resulted significantly lower and hospital stay with catheterization time results statistically longer. The comparison of the laparoscopic procedure does not evidence a statistically significant difference in terms of blood loss, operative time and catheterization time, while the comparison with the robotic group could not be performed for the lack of data. All patients need an adequate informed consent regarding the multitude of aspects which may be influenced by the mesh such as the possibility of hernia recurrence, mesh infection, need for mesh explantation, possibility of mesh erosion into the bowel or bladder, bladder neck contractures or postoperative urinary incontinence and a compromised nodal staging.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21670,""
"Computer-aided detection system for lung cancer in computed tomography scans: review and future prospects","Firmino, Morais, MendoÃƒÂ§a, Dantas, Hekis, Valentim","https://doi.org/10.1186/1475-925X-13-41","20140911","PubMed","Diagnosis, Computer-Assisted; False Positive Reactions; Humans; Image Processing, Computer-Assisted; Lung Neoplasms; Tomography, X-Ray Computed","The goal of this paper is to present a critical review of major Computer-Aided Detection systems (CADe) for lung cancer in order to identify challenges for future research. CADe systems must meet the following requirements: improve the performance of radiologists providing high sensitivity in the diagnosis, a low number of false positives (FP), have high processing speed, present high level of automation, low cost (of implementation, training, support and maintenance), the ability to detect different types and shapes of nodules, and software security assurance. The relevant literature related to ""CADe for lung cancer"" was obtained from PubMed, IEEEXplore and Science Direct database. Articles published from 2009 to 2013, and some articles previously published, were used. A systemic analysis was made on these articles and the results were summarized. Based on literature search, it was observed that many if not all systems described in this survey have the potential to be important in clinical practice. However, no significant improvement was observed in sensitivity, number of false positives, level of automation and ability to detect different types and shapes of nodules in the studied period. Challenges were presented for future research. Further research is needed to improve existing systems and propose new solutions. For this, we believe that collaborative efforts through the creation of open source software communities are necessary to develop a CADe system with all the requirements mentioned and with a short development cycle. In addition, future CADe systems should improve the level of automation, through integration with picture archiving and communication systems (PACS) and the electronic record of the patient, decrease the number of false positives, measure the evolution of tumors, evaluate the evolution of the oncological treatment, and its possible prognosis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21671,""
"Impact of neurologic deficits on motor imagery: a systematic review of clinical evaluations","Di Rienzo, Collet, Hoyek, Guillot","https://doi.org/10.1007/s11065-014-9257-6","20140912","PubMed","Amputees; Brain; Humans; Imagination; Motor Activity; Nervous System Diseases; Parkinson Disease; Spinal Cord Injuries; Stroke","Motor imagery (MI, the mental representation of an action without engaging in its actual execution) is a therapeutically relevant technique to promote motor recovery after neurologic disorders. MI shares common neural and psychological bases with physical practice. Interestingly, both acute and progressive neurologic disorders impact brain motor networks, hence potentially eliciting changes in MI capacities. How experimental neuroscientists and medical practitioners should assess and take into account these changes in order to design fruitful interventions is largely unresolved. Understanding how the psychometric, behavioral and neurophysiological correlates of MI are impacted by neurologic disorders is required. To address this brain-behavior issue, we conducted a systematic review of MI data in stroke, Parkinson's disease, spinal cord injury, and amputee participants. MI evaluation methods are presented. Redundant MI profiles, primarily based on psychometric and behavioral evaluations, emerged in each clinical population. When present, changes in the psychometric and behavioral correlates of MI were highly congruent with the corresponding motor impairments. Neurophysiological recordings yielded specific changes in cerebral activations during MI, which mirrored structural and functional reorganizations due to neuroplasticity. In this view, MI capacities may not be deteriorated per se by neurologic diseases resulting in chronic motor incapacities, but adjusted to the current state of the motor system. Literature-driven orientations for future clinical research are provided. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21672,""
"Assessing the similarity of surface linguistic features related to epilepsy across pediatric hospitals","Connolly, Matykiewicz, Bretonnel Cohen, Standridge, Glauser, Dlugos, Koh, Tham, Pestian","https://doi.org/10.1136/amiajnl-2013-002601","20141013","PubMed","Epilepsy; Linguistics; Multicenter; Support vector machines; Text classification; Electronic Health Records; Epilepsy; Hospitals, Pediatric; Humans; Linguistics; Natural Language Processing; Support Vector Machine; Terminology as Topic","The constant progress in computational linguistic methods provides amazing opportunities for discovering information in clinical text and enables the clinical scientist to explore novel approaches to care. However, these new approaches need evaluation. We describe an automated system to compare descriptions of epilepsy patients at three different organizations: Cincinnati Children's Hospital, the Children's Hospital Colorado, and the Children's Hospital of Philadelphia. To our knowledge, there have been no similar previous studies. In this work, a support vector machine (SVM)-based natural language processing (NLP) algorithm is trained to classify epilepsy progress notes as belonging to a patient with a specific type of epilepsy from a particular hospital. The same SVM is then used to classify notes from another hospital. Our null hypothesis is that an NLP algorithm cannot be trained using epilepsy-specific notes from one hospital and subsequently used to classify notes from another hospital better than a random baseline classifier. The hypothesis is tested using epilepsy progress notes from the three hospitals. We are able to reject the null hypothesis at the 95% level. It is also found that classification was improved by including notes from a second hospital in the SVM training sample. With a reasonably uniform epilepsy vocabulary and an NLP-based algorithm able to use this uniformity to classify epilepsy progress notes across different hospitals, we can pursue automated comparisons of patient conditions, treatments, and diagnoses across different healthcare settings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21673,""
"Profiling of drugs and environmental chemicals for functional impairment of neural crest migration in a novel stem cell-based test battery","Zimmer, Pallocca, Dreser, Foerster, Waldmann, Westerhout, Julien, Krause, van Thriel, Hengstler, Sachinidis, Bosgra, Leist","https://doi.org/10.1007/s00204-014-1231-9","20150512","PubMed","Animals; Cell Differentiation; Cell Movement; Dose-Response Relationship, Drug; Embryonic Stem Cells; HEK293 Cells; Humans; Mice; Models, Theoretical; Neural Crest; Toxicity Tests","Developmental toxicity in vitro assays have hitherto been established as stand-alone systems, based on a limited number of toxicants. Within the embryonic stem cell-based novel alternative tests project, we developed a test battery framework that allows inclusion of any developmental toxicity assay and that explores the responses of such test systems to a wide range of drug-like compounds. We selected 28 compounds, including several biologics (e.g., erythropoietin), classical pharmaceuticals (e.g., roflumilast) and also six environmental toxicants. The chemical, toxicological and clinical data of this screen library were compiled. In order to determine a non-cytotoxic concentration range, cytotoxicity data were obtained for all compounds from HEK293 cells and from murine embryonic stem cells. Moreover, an estimate of relevant exposures was provided by literature data mining. To evaluate feasibility of the suggested test framework, we selected a well-characterized assay that evaluates 'migration inhibition of neural crest cells.' Screening at the highest non-cytotoxic concentration resulted in 11 hits (e.g., geldanamycin, abiraterone, gefitinib, chlorpromazine, cyproconazole, arsenite). These were confirmed in concentration-response studies. Subsequent pharmacokinetic modeling indicated that triadimefon exerted its effects at concentrations relevant to the in vivo situation, and also interferon-ÃŽÂ² and polybrominated diphenyl ether showed effects within the same order of magnitude of concentrations that may be reached in humans. In conclusion, the test battery framework can identify compounds that disturb processes relevant for human development and therefore may represent developmental toxicants. The open structure of the strategy allows rich information to be generated on both the underlying library, and on any contributing assay. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21674,""
"Detection of lungs status using morphological complexities of respiratory sounds","Mondal, Bhattacharya, Saha","https://doi.org/10.1155/2014/182938","20141218","PubMed","Artificial Intelligence; Auscultation; Diagnosis, Computer-Assisted; Female; Humans; Lung Diseases; Male; Pattern Recognition, Automated; Reproducibility of Results; Respiratory Sounds; Sensitivity and Specificity; Sound Spectrography","Traditionally, the clinical diagnosis of a respiratory disease is made from a careful clinical examination including chest auscultation. Objective analysis and automatic interpretation of the lung sound based on its physical characters are strongly warranted to assist clinical practice. In this paper, a new method is proposed to distinguish between the normal and the abnormal subjects using the morphological complexities of the lung sound signals. The morphological embedded complexities used in these experiments have been calculated in terms of texture information (lacunarity), irregularity index (sample entropy), third order moment (skewness), and fourth order moment (Kurtosis). These features are extracted from a mixed data set of 10 normal and 20 abnormal subjects and are analyzed using two different classifiers: extreme learning machine (ELM) and support vector machine (SVM) network. The results are obtained using 5-fold cross-validation. The performance of the proposed method is compared with a wavelet analysis based method. The developed algorithm gives a better accuracy of 92.86% and sensitivity of 86.30% and specificity of 86.90% for a composite feature vector of four morphological indices. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21675,""
"Systematic changes in position sense accompany normal aging across adulthood","Herter, Scott, Dukelow","https://doi.org/10.1186/1743-0003-11-43","20140822","PubMed","Adolescent; Adult; Aged; Aged, 80 and over; Aging; Female; Humans; Male; Middle Aged; Proprioception; Robotics; Upper Extremity; Young Adult","Development of clinical neurological assessments aimed at separating normal from abnormal capabilities requires a comprehensive understanding of how basic neurological functions change (or do not change) with increasing age across adulthood. In the case of proprioception, the research literature has failed to conclusively determine whether or not position sense in the upper limb deteriorates in elderly individuals. The present study was conducted a) to quantify whether upper limb position sense deteriorates with increasing age, and b) to generate a set of normative data that can be used for future comparisons with clinical populations. We examined position sense in 209 healthy males and females between the ages of 18 and 90 using a robotic arm position-matching task that is both objective and reliable. In this task, the robot moved an arm to one of nine positions and subjects attempted to mirror-match that position with the opposite limb. Measures of position sense were recorded by the robotic apparatus in hand-and joint-based coordinates, and linear regressions were used to quantify age-related changes and percentile boundaries of normal behaviour. For clinical comparisons, we also examined influences of sex (male versus female) and test-hand (dominant versus non-dominant) on all measures of position sense. Analyses of hand-based parameters identified several measures of position sense (Variability, Shift, Spatial Contraction, Absolute Error) with significant effects of age, sex, and test-hand. Joint-based parameters at the shoulder (Absolute Error) and elbow (Variability, Shift, Absolute Error) also exhibited significant effects of age and test-hand. The present study provides strong evidence that several measures of upper extremity position sense exhibit declines with age. Furthermore, this data provides a basis for quantifying when changes in position sense are related to normal aging or alternatively, pathology.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21676,""
"Optimization of breast mass classification using sequential forward floating selection (SFFS) and a support vector machine (SVM) model","Tan, Pu, Zheng","https://doi.org/10.1007/s11548-014-0992-1","20161101","PubMed","Breast cancer; Computer-aided diagnosis of mammograms; Feature selection; Pattern classification; Algorithms; Breast Neoplasms; Diagnosis, Computer-Assisted; Female; Humans; Mammography; Neoplasm Staging; Pattern Recognition, Automated; ROC Curve; Radiographic Image Interpretation, Computer-Assisted; Support Vector Machine","Improving radiologists' performance in classification between malignant and benign breast lesions is important to increase cancer detection sensitivity and reduce false-positive recalls. For this purpose, developing computer-aided diagnosis schemes has been attracting research interest in recent years. In this study, we investigated a new feature selection method for the task of breast mass classification. We initially computed 181 image features based on mass shape, spiculation, contrast, presence of fat or calcifications, texture, isodensity, and other morphological features. From this large image feature pool, we used a sequential forward floating selection (SFFS)-based feature selection method to select relevant features and analyzed their performance using a support vector machine (SVM) model trained for the classification task. On a database of 600 benign and 600 malignant mass regions of interest, we performed the study using a tenfold cross-validation method. Feature selection and optimization of the SVM parameters were conducted on the training subsets only. The area under the receiver operating characteristic curve [Formula: see text] was obtained for the classification task. The results also showed that the most frequently selected features by the SFFS-based algorithm in tenfold iterations were those related to mass shape, isodensity, and presence of fat, which are consistent with the image features frequently used by radiologists in the clinical environment for mass classification. The study also indicated that accurately computing mass spiculation features from the projection mammograms was difficult, and failed to perform well for the mass classification task due to tissue overlap within the benign mass regions. In conclusion, this comprehensive feature analysis study provided new and valuable information for optimizing computerized mass classification schemes that may have potential to be useful as a ""second reader"" in future clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21677,""
"Does temporal discounting explain unhealthy behavior? A systematic review and reinforcement learning perspective","Story, Vlaev, Seymour, Darzi, Dolan","https://doi.org/10.3389/fnbeh.2014.00076","20140421","PubMed","addiction; discounting; habit; health; hyperbolic; model-based; model-free; preference reversal","The tendency to make unhealthy choices is hypothesized to be related to an individual's temporal discount rate, the theoretical rate at which they devalue delayed rewards. Furthermore, a particular form of temporal discounting, hyperbolic discounting, has been proposed to explain why unhealthy behavior can occur despite healthy intentions. We examine these two hypotheses in turn. We first systematically review studies which investigate whether discount rates can predict unhealthy behavior. These studies reveal that high discount rates for money (and in some instances food or drug rewards) are associated with several unhealthy behaviors and markers of health status, establishing discounting as a promising predictive measure. We secondly examine whether intention-incongruent unhealthy actions are consistent with hyperbolic discounting. We conclude that intention-incongruent actions are often triggered by environmental cues or changes in motivational state, whose effects are not parameterized by hyperbolic discounting. We propose a framework for understanding these state-based effects in terms of the interplay of two distinct reinforcement learning mechanisms: a ""model-based"" (or goal-directed) system and a ""model-free"" (or habitual) system. Under this framework, while discounting of delayed health may contribute to the initiation of unhealthy behavior, with repetition, many unhealthy behaviors become habitual; if health goals then change, habitual behavior can still arise in response to environmental cues. We propose that the burgeoning development of computational models of these processes will permit further identification of health decision-making phenotypes. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21678,""
"Machine learning-based prediction of drug-drug interactions by integrating drug phenotypic, therapeutic, chemical, and genomic properties","Cheng, Zhao","https://doi.org/10.1136/amiajnl-2013-002512","20141028","PubMed","Artificial Intelligence; Bayes Theorem; Decision Trees; Drug Interactions; Humans; Logistic Models; Models, Theoretical; Molecular Structure; Pharmaceutical Preparations; Pharmacokinetics; ROC Curve; Support Vector Machine","Drug-drug interactions (DDIs) are an important consideration in both drug development and clinical application, especially for co-administered medications. While it is necessary to identify all possible DDIs during clinical trials, DDIs are frequently reported after the drugs are approved for clinical use, and they are a common cause of adverse drug reactions (ADR) and increasing healthcare costs. Computational prediction may assist in identifying potential DDIs during clinical trials. Here we propose a heterogeneous network-assisted inference (HNAI) framework to assist with the prediction of DDIs. First, we constructed a comprehensive DDI network that contained 6946 unique DDI pairs connecting 721 approved drugs based on DrugBank data. Next, we calculated drug-drug pair similarities using four features: phenotypic similarity based on a comprehensive drug-ADR network, therapeutic similarity based on the drug Anatomical Therapeutic Chemical classification system, chemical structural similarity from SMILES data, and genomic similarity based on a large drug-target interaction network built using the DrugBank and Therapeutic Target Database. Finally, we applied five predictive models in the HNAI framework: naive Bayes, decision tree, k-nearest neighbor, logistic regression, and support vector machine, respectively. The area under the receiver operating characteristic curve of the HNAI models is 0.67 as evaluated using fivefold cross-validation. Using antipsychotic drugs as an example, several HNAI-predicted DDIs that involve weight gain and cytochrome P450 inhibition were supported by literature resources. Through machine learning-based integration of drug phenotypic, therapeutic, structural, and genomic similarities, we demonstrated that HNAI is promising for uncovering DDIs in drug development and postmarketing surveillance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21679,""
"Functional outcomes after TORS for oropharyngeal cancer: a systematic review","Hutcheson, Holsinger, Kupferman, Lewin","https://doi.org/10.1007/s00405-014-2985-7","20150825","PubMed","Deglutition; Humans; Natural Orifice Endoscopic Surgery; Oropharyngeal Neoplasms; Otorhinolaryngologic Surgical Procedures; Recovery of Function; Robotics; Treatment Outcome","Summarize functional outcomes after transoral robotic surgery (TORS) Ã‚Â± adjuvant therapy for oropharyngeal cancer (OPC). A systematic review was conducted. The MEDLINE database was searched (MeSH terms: TORS, pharyngeal neoplasms, oropharyngeal neoplasms). Peer-reviewed human subject papers published through December 2013 were included. Exclusion criteria were as follows: (1) case report design (n &lt; 10), (2) review article, or (3) technical, animal, or cadaver studies. Functional outcomes extracted included feeding tube dependence, swallow examination findings, speech ratings, velopharyngeal insufficiency, pneumonia, and oral intake measures. Twelve papers comprising 441 patients with OPC treated with TORS Ã‚Â± adjuvant therapy were included. Feeding tube rates were the most commonly reported functional outcome. Excluding prophylactic placement, 18-39% of patients required gastrostomy placement, typically during adjuvant therapy. Chronic gastrostomy dependence ranged from 0 to 7% (mean follow-up 11-26 months), regardless of disease stage. Composite MD Anderson Dysphagia Inventory (MDADI) scores ranged from 65.2 to 78 (89 patients, 3 series, mean follow-up 12-13 months). Videofluoroscopic swallowing studies were not systematically reported. Incidence of postoperative pneumonia was 0-7%. Predictors of swallowing function included baseline function, T-stage, N-stage, tongue base primary tumors, and adjuvant chemoradiation. Rates of transient hypernasality were 4-9%. A single study suggested dose-dependent effects of adjuvant therapy (none, radiation alone, chemoradiation) on diet scores at 6 and 12 months. Crude end points of functional recovery after TORS Ã‚Â± adjuvant therapy suggest promising swallowing outcomes, depending on the functional measure reported.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21680,""
"MedXN: an open source medication extraction and normalization tool for clinical text","Sohn, Clark, Halgrim, Murphy, Chute, Liu","https://doi.org/10.1136/amiajnl-2013-002190","20141013","PubMed","Electronic Medical Records; Medication Extraction; Medication Normalization; Natural Language Processing; RxNorm; Data Mining; Drug Therapy; Electronic Health Records; Humans; Natural Language Processing; Pharmaceutical Preparations; RxNorm","We developed the Medication Extraction and Normalization (MedXN) system to extract comprehensive medication information and normalize it to the most appropriate RxNorm concept unique identifier (RxCUI) as specifically as possible. Medication descriptions in clinical notes were decomposed into medication name and attributes, which were separately extracted using RxNorm dictionary lookup and regular expression. Then, each medication name and its attributes were combined together according to RxNorm convention to find the most appropriate RxNorm representation. To do this, we employed serialized hierarchical steps implemented in Apache's Unstructured Information Management Architecture. We also performed synonym expansion, removed false medications, and employed inference rules to improve the medication extraction and normalization performance. An evaluation on test data of 397 medication mentions showed F-measures of 0.975 for medication name and over 0.90 for most attributes. The RxCUI assignment produced F-measures of 0.932 for medication name and 0.864 for full medication information. Most false negative RxCUI assignments in full medication information are due to human assumption of missing attributes and medication names in the gold standard. The MedXN system (http://sourceforge.net/projects/ohnlp/files/MedXN/) was able to extract comprehensive medication information with high accuracy and demonstrated good normalization capability to RxCUI as long as explicit evidence existed. More sophisticated inference rules might result in further improvements to specific RxCUI assignments for incomplete medication descriptions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21681,""
"Dose-specific adverse drug reaction identification in electronic patient records: temporal data mining in an inpatient psychiatric population","Eriksson, Werge, Jensen, Brunak","https://doi.org/10.1007/s40264-014-0145-z","20150309","PubMed","Adolescent; Adverse Drug Reaction Reporting Systems; Aged; Aged, 80 and over; Antipsychotic Agents; Data Collection; Data Mining; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Female; Humans; Inpatients; Male; Mental Disorders; Middle Aged; Young Adult","Data collected for medical, filing and administrative purposes in electronic patient records (EPRs) represent a rich source of individualised clinical data, which has great potential for improved detection of patients experiencing adverse drug reactions (ADRs), across all approved drugs and across all indication areas. The aim of this study was to take advantage of techniques for temporal data mining of EPRs in order to detect ADRs in a patient- and dose-specific manner. We used a psychiatric hospital's EPR system to investigate undesired drug effects. Within one workflow the method identified patient-specific adverse events (AEs) and links these to specific drugs and dosages in a temporal manner, based on integration of text mining results and structured data. The structured data contained precise information on drug identity, dosage and strength. When applying the method to the 3,394 patients in the cohort, we identified AEs linked with a drug in 2,402 patients (70.8 %). Of the 43,528 patient-specific drug substances prescribed, 14,736 (33.9 %) were linked with AEs. From these links we identified multiple ADRs (p &lt; 0.05) and found them to occur at similar frequencies, as stated by the manufacturer and in the literature. We showed that drugs displaying similar ADR profiles share targets, and we compared submitted spontaneous AE reports with our findings. For nine of the ten most prescribed antipsychotics in the patient population, larger doses were prescribed to sedated patients than non-sedated patients; five antipsychotics [corrected] exhibited a significant difference (p&lt;0.05). Finally, we present two cases (p &lt; 0.05) identified by the workflow. The method identified the potentially fatal AE QT prolongation caused by methadone, and a non-described likely ADR between levomepromazine and nightmares found among the hundreds of identified novel links between drugs and AEs (p &lt; 0.05). The developed method can be used to extract dose-dependent ADR information from already collected EPR data. Large-scale AE extraction from EPRs may complement or even replace current drug safety monitoring methods in the future, reducing or eliminating manual reporting and enabling much faster ADR detection.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21682,""
"A review of EEG and MEG for brainnetome research","Zhang, Lei, Wu, Jiang","https://doi.org/10.1007/s11571-013-9274-9","20140624","PubMed","Brain network; Brainnetome; EEG; MEG","The majority of brain activities are performed by functionally integrating separate regions of the brain. Therefore, the synchronous operation of the brain's multiple regions or neuronal assemblies can be represented as a network with nodes that are interconnected by links. Because of the complexity of brain interactions and their varying effects at different levels of complexity, one of the corresponding authors of this paper recently proposed the brainnetome as a new -ome to explore and integrate the brain network at different scales. Because electroencephalography (EEG) and magnetoencephalography (MEG) are noninvasive and have outstanding temporal resolution and because they are the primary clinical techniques used to capture the dynamics of neuronal connections, they lend themselves to the analysis of the neural networks comprising the brainnetome. Because of EEG/MEG's applicability to brainnetome analyses, the aim of this review is to identify the procedures that can be used to form a network using EEG/MEG data in sensor or source space and to promote EEG/MEG network analysis for either neuroscience or clinical applications. To accomplish this aim, we show the relationship of the brainnetome to brain networks at the macroscale and provide a systematic review of network construction using EEG and MEG. Some potential applications of the EEG/MEG brainnetome are to use newly developed methods to associate the properties of a brainnetome with indices of cognition or disease conditions. Associations based on EEG/MEG brainnetome analysis may improve the comprehension of the functioning of the brain in neuroscience research or the recognition of abnormal patterns in neurological disease. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21683,""
"Neural correlates of cognitive and affective processing in maltreated youth with posttraumatic stress symptoms: does gender matter?","Crozier, Wang, Huettel, De Bellis","https://doi.org/10.1017/S095457941400008X","20141219","PubMed","Adolescent; Affect; Brain; Case-Control Studies; Cerebellum; Child; Child Abuse; Cognition; Executive Function; Female; Gyrus Cinguli; Humans; Magnetic Resonance Imaging; Male; Neuroimaging; Prefrontal Cortex; Sex Factors; Stress Disorders, Post-Traumatic; Visual Cortex","We investigated the relationship of gender to cognitive and affective processing in maltreated youth with posttraumatic stress disorder symptoms using functional magnetic resonance imaging. Maltreated (N = 29, 13 females, 16 males) and nonmaltreated participants (N = 45, 26 females, 19 males) performed an emotional oddball task that involved detection of targets with fear or scrambled face distractors. Results were moderated by gender. During the executive component of this task, left precuneus/posterior middle cingulate hypoactivation to fear versus calm or scrambled face targets were seen in maltreated versus control males and may represent dysfunction and less resilience in attentional networks. Maltreated males also showed decreased activation in the inferior frontal gyrus compared to control males. No differences were found in females. Posterior cingulate activations positively correlated with posttraumatic stress disorder symptoms. While viewing fear faces, maltreated females exhibited decreased activity in the dorsomedial prefrontal cortex and cerebellum I-VI, whereas maltreated males exhibited increased activity in the left hippocampus, fusiform cortex, right cerebellar crus I, and visual cortex compared to their same-gender controls. Gender by maltreatment effects were not attributable to demographic, clinical, or maltreatment parameters. Maltreated girls and boys exhibited distinct patterns of neural activations during executive and affective processing, a new finding in the maltreatment literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21684,""
"Evaluating alignment quality between iconic language and reference terminologies using similarity metrics","Griffon, KerdelhuÃƒÂ©, Soualmia, Merabti, Grosjean, Lamy, Venot, Duclos, Darmoni","https://doi.org/10.1186/1472-6947-14-17","20141021","PubMed","Electronic Health Records; Humans; Information Storage and Retrieval; International Classification of Diseases; Medical Subject Headings; Terminology as Topic; Unified Medical Language System; Vocabulary, Controlled","Visualization of Concepts in Medicine (VCM) is a compositional iconic language that aims to ease information retrieval in Electronic Health Records (EHR), clinical guidelines or other medical documents. Using VCM language in medical applications requires alignment with medical reference terminologies. Alignment from Medical Subject Headings (MeSH) thesaurus and International Classification of Diseases - tenth revision (ICD10) to VCM are presented here. This study aim was to evaluate alignment quality between VCM and other terminologies using different measures of inter-alignment agreement before integration in EHR. For medical literature retrieval purposes and EHR browsing, the MeSH thesaurus and the ICD10, both organized hierarchically, were aligned to VCM language. Some MeSH to VCM alignments were performed automatically but others were performed manually and validated. ICD10 to VCM alignment was entirely manually performed. Inter-alignment agreement was assessed on ICD10 codes and MeSH descriptors, sharing the same Concept Unique Identifiers in the Unified Medical Language System (UMLS). Three metrics were used to compare two VCM icons: binary comparison, crude Dice Similarity Coefficient (DSCcrude), and semantic Dice Similarity Coefficient (DSCsemantic), based on Lin similarity. An analysis of discrepancies was performed. MeSH to VCM alignment resulted in 10,783 relations: 1,830 of which were manually performed and 8,953 were automatically inherited. ICD10 to VCM alignment led to 19,852 relations. UMLS gathered 1,887 alignments between ICD10 and MeSH. Only 1,606 of them were used for this study. Inter-alignment agreement using only validated MeSH to VCM alignment was 74.2% [70.5-78.0]CI95%, DSCcrude was 0.93 [0.91-0.94]CI95%, and DSCsemantic was 0.96 [0.95-0.96]CI95%. Discrepancy analysis revealed that even if two thirds of errors came from the reviewers, UMLS was nevertheless responsible for one third. This study has shown strong overall inter-alignment agreement between MeSH to VCM and ICD10 to VCM manual alignments. VCM icons have now been integrated into a guideline search engine (http://www.cismef.org) and a health terminologies portal (http://www.hetop.eu).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21685,""
"Pareto design of state feedback tracking control of a biped robot via multiobjective PSO in comparison with sigma method and genetic algorithms: modified NSGAII and MATLAB's toolbox","Mahmoodabadi, Taherkhorsandi, Bagheri","https://doi.org/10.1155/2014/303101","20141229","PubMed","Algorithms; Equipment Design; Genetics; Robotics","An optimal robust state feedback tracking controller is introduced to control a biped robot. In the literature, the parameters of the controller are usually determined by a tedious trial and error process. To eliminate this process and design the parameters of the proposed controller, the multiobjective evolutionary algorithms, that is, the proposed method, modified NSGAII, Sigma method, and MATLAB's Toolbox MOGA, are employed in this study. Among the used evolutionary optimization algorithms to design the controller for biped robots, the proposed method operates better in the aspect of designing the controller since it provides ample opportunities for designers to choose the most appropriate point based upon the design criteria. Three points are chosen from the nondominated solutions of the obtained Pareto front based on two conflicting objective functions, that is, the normalized summation of angle errors and normalized summation of control effort. Obtained results elucidate the efficiency of the proposed controller in order to control a biped robot. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21686,""
"Robot-assisted laparoscopy for deep infiltrating endometriosis: international multicentric retrospective study","Collinet, Leguevaque, Neme, Cela, Barton-Smith, HÃƒÂ©bert, Hanssens, Nishi, Nisolle","https://doi.org/10.1007/s00464-014-3480-3","20141204","PubMed","Adult; Endometriosis; Female; Humans; Hysterectomy; Infertility, Female; Laparoscopy; Middle Aged; Operative Time; Postoperative Complications; Pregnancy; Pregnancy Rate; Rectal Diseases; Retrospective Studies; Robotic Surgical Procedures; Ureteral Diseases; Urinary Bladder Diseases; Young Adult","This study aimed to assess the interest in robot-assisted laparoscopy for deep infiltrating endometriosis and to investigate the perioperative results. From November 2008 to April 2012, 164 women with stage 4 endometriosis who underwent robot-assisted laparoscopy (da Vinci Intuitive Surgical System) were included by to eight international participating clinical centers. This study evaluated the procedures performed, the duration of the intervention, the complications, the recurrence, and the impact on fertility. The average operative time was 180 min. The main complications were laparotomy (n = 1, 0.6%), sutured bowel injury (n = 2, 1.2%), transfusion for a 2,300-ml bleed (n = 1), prolonged urinary catheterization (n = 1, 0.6%), ureter-bladder anastomotic leak (n = 1, 0.6%), and ureteral fistula after ureterolysis (n = 2, 1.2%). The reoperation rate was 1.8% (n = 3). The mean follow-up period was 10.2 months. A full recovery was experienced by 86.7% (98/113) of the patients. After surgery, 41.2% (42/102) of the patients had a desire for pregnancy, and 28.2% (11/39) of them became pregnant. This study analyzed the largest series of robot-assisted laparoscopies for deep infiltrating endometriosis published in the literature. No increase in surgical time, blood loss, or intra- or postoperative complications was observed. The interest in robot-assisted laparoscopy for deep infiltrating endometriosis seems to be promising.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21687,""
"A new device to automate the monitoring of critical patients' urine output","Otero, Apalkov, FernÃƒÂ¡ndez, Armada","https://doi.org/10.1155/2014/587593","20141015","PubMed","Humans; Urine Specimen Collection","Urine output (UO) is usually measured manually each hour in acutely ill patients. This task consumes a substantial amount of time. Furthermore, in the literature there is evidence that more frequent (minute-by-minute) UO measurement could impact clinical decision making and improve patient outcomes. However, it is not feasible to manually take minute-by-minute UO measurements. A device capable of automatically monitoring UO could save precious time of the healthcare staff and improve patient outcomes through a more precise and continuous monitoring of this parameter. This paper presents a device capable of automatically monitoring UO. It provides minute by minute measures and it can generate alarms that warn of deviations from therapeutic goals. It uses a capacitive sensor for the measurement of the UO collected within a rigid container. When the container is full, it automatically empties without requiring any internal or external power supply or any intervention by the nursing staff. In vitro tests have been conducted to verify the proper operation and accuracy in the measures of the device. These tests confirm the viability of the device to automate the monitoring of UO. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21688,""
"Clinical, cognitive, and behavioural correlates of white matter damage in progressive supranuclear palsy","Agosta, Galantucci, Svetel, LukiÃ„â€¡, Copetti, Davidovic, TomiÃ„â€¡, Spinelli, KostiÃ„â€¡, Filippi","https://doi.org/10.1007/s00415-014-7301-3","20150126","PubMed","Aged; Apathy; Brief Psychiatric Rating Scale; Cognition Disorders; Cross-Sectional Studies; Diffusion Tensor Imaging; Female; Humans; Male; Middle Aged; Supranuclear Palsy, Progressive; White Matter","White matter (WM) tract alterations were assessed in patients with progressive supranuclear palsy (PSP) relative to healthy controls and patients with idiopathic Parkinson's disease (PD) to explore the relationship of WM tract damage with clinical disease severity, performance on cognitive tests, and apathy. 37 PSP patients, 41 PD patients, and 34 healthy controls underwent an MRI scan and clinical testing to evaluate physical disability, cognitive impairment, and apathy. In PSP, the contribution of WM tract damage to global disease severity and cognitive and behavioural disturbances was assessed using Random Forest analysis. Relative to controls, PSP patients showed diffusion tensor (DT) MRI abnormalities of the corpus callosum, superior cerebellar peduncle (SCP), cingulum and uncinate fasciculus bilaterally, and right inferior longitudinal fasciculus. Corpus callosum and SCP DT MRI measures distinguished PSP from PD patients with high accuracy (area under the curve ranging from 0.89 to 0.72). In PSP, DT MRI metrics of the corpus callosum and superior cerebellar peduncles were the best predictors of global disease severity scale scores. DT MRI metrics of the corpus callosum, right superior longitudinal and inferior longitudinal fasciculus, and left uncinate were the best predictors of executive dysfunction. In PSP, apathy severity was related to the damage to the corpus callosum, right superior longitudinal, and uncinate fasciculi. In conclusion, WM tract damage contributes to the motor, cognitive, and behavioural deficits in PSP. DT MRI offers markers for PSP diagnosis, assessment, and monitoring.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21689,""
"Effectiveness of treatment approaches for children and adolescents with reading disabilities: a meta-analysis of randomized controlled trials","Galuschka, Ise, Krick, Schulte-KÃƒÂ¶rne","https://doi.org/10.1371/journal.pone.0089900","20150122","PubMed","Adolescent; Child; Dyslexia; Exercise; Eyeglasses; Helianthus; Humans; Plant Extracts; Randomized Controlled Trials as Topic; Reading; Remedial Teaching","Children and adolescents with reading disabilities experience a significant impairment in the acquisition of reading and spelling skills. Given the emotional and academic consequences for children with persistent reading disorders, evidence-based interventions are critically needed. The present meta-analysis extracts the results of all available randomized controlled trials. The aims were to determine the effectiveness of different treatment approaches and the impact of various factors on the efficacy of interventions. The literature search for published randomized-controlled trials comprised an electronic search in the databases ERIC, PsycINFO, PubMed, and Cochrane, and an examination of bibliographical references. To check for unpublished trials, we searched the websites clinicaltrials.com and ProQuest, and contacted experts in the field. Twenty-two randomized controlled trials with a total of 49 comparisons of experimental and control groups could be included. The comparisons evaluated five reading fluency trainings, three phonemic awareness instructions, three reading comprehension trainings, 29 phonics instructions, three auditory trainings, two medical treatments, and four interventions with coloured overlays or lenses. One trial evaluated the effectiveness of sunflower therapy and another investigated the effectiveness of motor exercises. The results revealed that phonics instruction is not only the most frequently investigated treatment approach, but also the only approach whose efficacy on reading and spelling performance in children and adolescents with reading disabilities is statistically confirmed. The mean effect sizes of the remaining treatment approaches did not reach statistical significance. The present meta-analysis demonstrates that severe reading and spelling difficulties can be ameliorated with appropriate treatment. In order to be better able to provide evidence-based interventions to children and adolescent with reading disabilities, research should intensify the application of blinded randomized controlled trials. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21690,""
"Automated detection of off-label drug use","Jung, LePendu, Chen, Iyer, Readhead, Dudley, Shah","https://doi.org/10.1371/journal.pone.0089324","20141014","PubMed","Algorithms; Data Mining; Databases, Factual; Models, Theoretical; Off-Label Use; Pattern Recognition, Automated","Off-label drug use, defined as use of a drug in a manner that deviates from its approved use defined by the drug's FDA label, is problematic because such uses have not been evaluated for safety and efficacy. Studies estimate that 21% of prescriptions are off-label, and only 27% of those have evidence of safety and efficacy. We describe a data-mining approach for systematically identifying off-label usages using features derived from free text clinical notes and features extracted from two databases on known usage (Medi-Span and DrugBank). We trained a highly accurate predictive model that detects novel off-label uses among 1,602 unique drugs and 1,472 unique indications. We validated 403 predicted uses across independent data sources. Finally, we prioritize well-supported novel usages for further investigation on the basis of drug safety and cost. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21691,""
"Choose and Book: a sociological analysis of 'resistance' to an expert system","Greenhalgh, Stones, Swinglehurst","https://doi.org/10.1016/j.socscimed.2013.12.014","20140805","PubMed","Electronic patent records; Expert systems; Referral; Resistance; Structuration theory; United Kingdom; e-Health; Appointments and Schedules; Choice Behavior; Expert Systems; General Practice; General Practitioners; Health Policy; Humans; Medical Records Systems, Computerized; Qualitative Research; Sociology; State Medicine; United Kingdom","In 2004, the English Department of Health introduced a technology (Choose and Book) designed to help general practitioners and patients book hospital outpatient appointments. It was anticipated that remote booking would become standard practice once technical challenges were overcome. But despite political pressure and financial incentives, Choose and Book remained unpopular and was generally used reluctantly if at all. Policymakers framed this as a problem of 'clinician resistance'. We considered Choose and Book from a sociological perspective. Our dataset, drawn from a qualitative study of computer use in general practice, comprised background documents, field notes, interviews, clinical consultations (directly observed and videotaped) and naturally occurring talk relating to referral to hospital in four general practices. We used strong structuration theory, Giddens' conceptualisation of expert systems, and sensitivity to other sociological perspectives on technology, institutions and professional values to examine the relationship between the external environment, the evolving technology and actions of human agents (GPs, administrators, managers and patients). Choose and Book had the characteristics of an expert system. It served to 'empty out' the content of the consultation as the abstract knowledge it contained was assumed to have universal validity and to over-ride the clinician's application of local knowledge and practical wisdom. Sick patients were incorrectly assumed to behave as rational choosers, able and willing to decide between potential options using abstracted codified information. Our analysis revealed four foci of resistance: to the policy of choice that Choose and Book symbolised and purported to deliver; to accommodating the technology's socio-material constraints; to interference with doctors' contextual judgements; and to adjusting to the altered social relations consequent on its use. We conclude that 'resistance' is a complex phenomenon with socio-material and normative components; it is unlikely to be overcome using the behaviourist techniques recommended in some health informatics and policy literature. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21692,""
"Learning regular expressions for clinical text classification","Bui, Zeng-Treitler","https://doi.org/10.1136/amiajnl-2013-002411","20141013","PubMed","Machine Learning; Natural Language Processing; Regular Expressions; Support Vector Machines; Text Classification; Algorithms; Artificial Intelligence; Electronic Data Processing; Humans; Medical Records Systems, Computerized; Natural Language Processing; Pain; Smoking; Support Vector Machine","Natural language processing (NLP) applications typically use regular expressions that have been developed manually by human experts. Our goal is to automate both the creation and utilization of regular expressions in text classification. We designed a novel regular expression discovery (RED) algorithm and implemented two text classifiers based on RED. The RED+ALIGN classifier combines RED with an alignment algorithm, and RED+SVM combines RED with a support vector machine (SVM) classifier. Two clinical datasets were used for testing and evaluation: the SMOKE dataset, containing 1091 text snippets describing smoking status; and the PAIN dataset, containing 702 snippets describing pain status. We performed 10-fold cross-validation to calculate accuracy, precision, recall, and F-measure metrics. In the evaluation, an SVM classifier was trained as the control. The two RED classifiers achieved 80.9-83.0% in overall accuracy on the two datasets, which is 1.3-3% higher than SVM's accuracy (p&lt;0.001). Similarly, small but consistent improvements have been observed in precision, recall, and F-measure when RED classifiers are compared with SVM alone. More significantly, RED+ALIGN correctly classified many instances that were misclassified by the SVM classifier (8.1-10.3% of the total instances and 43.8-53.0% of SVM's misclassifications). Machine-generated regular expressions can be effectively used in clinical text classification. The regular expression-based classifier can be combined with other classifiers, like SVM, to improve classification performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21693,""
"A data-driven acute inflammation therapy","Radosavljevic, Ristovski, Obradovic","https://doi.org/10.1186/1755-8794-6-S3-S7","20141020","PubMed","Acute Disease; Algorithms; Anti-Inflammatory Agents; Artificial Intelligence; Computer Simulation; Dose-Response Relationship, Drug; Humans; Inflammation; Models, Biological; Outcome Assessment, Health Care","Acute inflammation is a severe medical condition defined as an inflammatory response of the body to an infection. Its rapid progression requires quick and accurate decisions from clinicians. Inadequate and delayed decisions makes acute inflammation the 10th leading cause of death overall in United States with the estimated cost of treatment about $17 billion annually. However, despite the need, there are limited number of methods that could assist clinicians to determine optimal therapies for acute inflammation. We developed a data-driven method for suggesting optimal therapy by using machine learning model that is learned on historical patients' behaviors. To reduce both the risk of failure and the expense for clinical trials, our method is evaluated on a virtual patients generated by a mathematical model that emulates inflammatory response. In conducted experiments, acute inflammation was handled with two complimentary pro- and anti-inflammatory medications which adequate timing and doses are crucial for the successful outcome. Our experiments show that the dosage regimen assigned with our data-driven method significantly improves the percentage of healthy patients when compared to results by other methods used in clinical practice and found in literature. Our method saved 88% of patients that would otherwise die within a week, while the best method found in literature saved only 73% of patients. At the same time, our method used lower doses of medications than alternatives. In addition, our method achieved better results than alternatives when only incomplete or noisy measurements were available over time as well as it was less affected by therapy delay. The presented results provide strong evidence that models from the artificial intelligence community have a potential for development of personalized treatment strategies for acute inflammation. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21694,""
"Pathway-based drug repositioning using causal inference","Li, Lu","https://doi.org/10.1186/1471-2105-14-S16-S3","20140429","PubMed","Artificial Intelligence; Computational Biology; Computer Simulation; Crohn Disease; Drug Repositioning; Gene Regulatory Networks; Humans; Likelihood Functions; Reproducibility of Results","Recent in vivo studies showed new hopes of drug repositioning through causality inference from drugs to disease. Inspired by their success, here we present an in silico method for building a causal network (CauseNet) between drugs and diseases, in an attempt to systematically identify new therapeutic uses of existing drugs. Unlike the traditional 'one drug-one target-one disease' causal model, we simultaneously consider all possible causal chains connecting drugs to diseases via target- and gene-involved pathways based on rich information in several expert-curated knowledge-bases. With statistical learning, our method estimates transition likelihood of each causal chain in the network based on known drug-disease treatment associations (e.g. bexarotene treats skin cancer). To demonstrate its validity, our method showed high performance (AUC = 0.859) in cross validation. Moreover, our top scored prediction results are highly enriched in literature and clinical trials. As a showcase of its utility, we show several drugs for potential re-use in Crohn's Disease. We successfully developed a computational method for discovering new uses of existing drugs based on casual inference in a layered drug-target-pathway-gene- disease network. The results showed that our proposed method enables hypothesis generation from public accessible biological data for drug repositioning.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21695,""
"A pipeline to extract drug-adverse event pairs from multiple data sources","Yeleswarapu, Rao, Joseph, Saipradeep, Srinivasan","https://doi.org/10.1186/1472-6947-14-13","20141021","PubMed","Adverse Drug Reaction Reporting Systems; Algorithms; Data Mining; Drug-Related Side Effects and Adverse Reactions; Humans; Natural Language Processing","Pharmacovigilance aims to uncover and understand harmful side-effects of drugs, termed adverse events (AEs). Although the current process of pharmacovigilance is very systematic, the increasing amount of information available in specialized health-related websites as well as the exponential growth in medical literature presents a unique opportunity to supplement traditional adverse event gathering mechanisms with new-age ones. We present a semi-automated pipeline to extract associations between drugs and side effects from traditional structured adverse event databases, enhanced by potential drug-adverse event pairs mined from user-comments from health-related websites and MEDLINE abstracts. The pipeline was tested using a set of 12 drugs representative of two previous studies of adverse event extraction from health-related websites and MEDLINE abstracts. Testing the pipeline shows that mining non-traditional sources helps substantiate the adverse event databases. The non-traditional sources not only contain the known AEs, but also suggest some unreported AEs for drugs which can then be analyzed further. A semi-automated pipeline to extract the AE pairs from adverse event databases as well as potential AE pairs from non-traditional sources such as text from MEDLINE abstracts and user-comments from health-related websites is presented.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21696,""
"Cue-based assertion classification for Swedish clinical text--developing a lexicon for pyConTextSwe","Velupillai, Skeppstedt, Kvist, Mowery, Chapman, Dalianis, Chapman","https://doi.org/10.1016/j.artmed.2014.01.001","20150330","PubMed","Assertion classification; Clinical text mining; Dictionaries; Electronic health records; Information extraction; Medical Language Processing; Artificial Intelligence; Cues; Electronic Health Records; Humans; Language; Natural Language Processing; Semantics; Sweden; Translations; Uncertainty; Vocabulary, Controlled","The ability of a cue-based system to accurately assert whether a disorder is affirmed, negated, or uncertain is dependent, in part, on its cue lexicon. In this paper, we continue our study of porting an assertion system (pyConTextNLP) from English to Swedish (pyConTextSwe) by creating an optimized assertion lexicon for clinical Swedish. We integrated cues from four external lexicons, along with generated inflections and combinations. We used subsets of a clinical corpus in Swedish. We applied four assertion classes (definite existence, probable existence, probable negated existence and definite negated existence) and two binary classes (existence yes/no and uncertainty yes/no) to pyConTextSwe. We compared pyConTextSwe's performance with and without the added cues on a development set, and improved the lexicon further after an error analysis. On a separate evaluation set, we calculated the system's final performance. Following integration steps, we added 454 cues to pyConTextSwe. The optimized lexicon developed after an error analysis resulted in statistically significant improvements on the development set (83% F-score, overall). The system's final F-scores on an evaluation set were 81% (overall). For the individual assertion classes, F-score results were 88% (definite existence), 81% (probable existence), 55% (probable negated existence), and 63% (definite negated existence). For the binary classifications existence yes/no and uncertainty yes/no, final system performance was 97%/87% and 78%/86% F-score, respectively. We have successfully ported pyConTextNLP to Swedish (pyConTextSwe). We have created an extensive and useful assertion lexicon for Swedish clinical text, which could form a valuable resource for similar studies, and which is publicly available.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21697,""
"Latent information in fluency lists predicts functional decline in persons at risk for Alzheimer disease","Clark, Kapur, Geldmacher, Brockington, Harrell, DeRamus, Blanton, Lokken, Nicholas, Marson","https://doi.org/10.1016/j.cortex.2013.12.013","20150115","PubMed","Alzheimer's disease; Cognitive neuropsychology; Dementia; MCI (mild cognitive impairment); Machine learning; Random forests; Aged; Alzheimer Disease; Area Under Curve; Artificial Intelligence; Case-Control Studies; Cognitive Dysfunction; Female; Humans; Male; Middle Aged; ROC Curve; Reproducibility of Results; Risk; Semantics; Speech; Speech Disorders","We constructed random forest classifiers employing either the traditional method of scoring semantic fluency word lists or new methods. These classifiers were then compared in terms of their ability to diagnose Alzheimer disease (AD) or to prognosticate among individuals along the continuum from cognitively normal (CN) through mild cognitive impairment (MCI) to AD. Semantic fluency lists from 44 cognitively normal elderly individuals, 80 MCI patients, and 41 AD patients were transcribed into electronic text files and scored by four methods: traditional raw scores, clustering and switching scores, ""generalized"" versions of clustering and switching, and a method based on independent components analysis (ICA). Random forest classifiers based on raw scores were compared to ""augmented"" classifiers that incorporated newer scoring methods. Outcome variables included AD diagnosis at baseline, MCI conversion, increase in Clinical Dementia Rating-Sum of Boxes (CDR-SOB) score, or decrease in Financial Capacity Instrument (FCI) score. Receiver operating characteristic (ROC) curves were constructed for each classifier and the area under the curve (AUC) was calculated. We compared AUC between raw and augmented classifiers using Delong's test and assessed validity and reliability of the augmented classifier. Augmented classifiers outperformed classifiers based on raw scores for the outcome measures AD diagnosis (AUC .97 vs. .95), MCI conversion (AUC .91 vs. .77), CDR-SOB increase (AUC .90 vs. .79), and FCI decrease (AUC .89 vs. .72). Measures of validity and stability over time support the use of the method. Latent information in semantic fluency word lists is useful for predicting cognitive and functional decline among elderly individuals at increased risk for developing AD. Modern machine learning methods may incorporate latent information to enhance the diagnostic value of semantic fluency raw scores. These methods could yield information valuable for patient care and clinical trial design with a relatively small investment of time and money.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21698,""
"Preparing an annotated gold standard corpus to share with extramural investigators for de-identification research","Deleger, Lingren, Ni, Kaiser, Stoutenborough, Marsolo, Kouril, Molnar, Solti","https://doi.org/10.1016/j.jbi.2014.01.014","20150330","PubMed","Automated de-identification; De-identification gold standard; Health insurance portability and accountability act; Natural Language Processing; Privacy of patient data; Protected Health Information; Computer Security; Electronic Health Records; Health Insurance Portability and Accountability Act; Medical Informatics; United States","The current study aims to fill the gap in available healthcare de-identification resources by creating a new sharable dataset with realistic Protected Health Information (PHI) without reducing the value of the data for de-identification research. By releasing the annotated gold standard corpus with Data Use Agreement we would like to encourage other Computational Linguists to experiment with our data and develop new machine learning models for de-identification. This paper describes: (1) the modifications required by the Institutional Review Board before sharing the de-identification gold standard corpus; (2) our efforts to keep the PHI as realistic as possible; (3) and the tests to show the effectiveness of these efforts in preserving the value of the modified data set for machine learning model development. In a previous study we built an original de-identification gold standard corpus annotated with true Protected Health Information (PHI) from 3503 randomly selected clinical notes for the 22 most frequent clinical note types of our institution. In the current study we modified the original gold standard corpus to make it suitable for external sharing by replacing HIPAA-specified PHI with newly generated realistic PHI. Finally, we evaluated the research value of this new dataset by comparing the performance of an existing published in-house de-identification system, when trained on the new de-identification gold standard corpus, with the performance of the same system, when trained on the original corpus. We assessed the potential benefits of using the new de-identification gold standard corpus to identify PHI in the i2b2 and PhysioNet datasets that were released by other groups for de-identification research. We also measured the effectiveness of the i2b2 and PhysioNet de-identification gold standard corpora in identifying PHI in our original clinical notes. Performance of the de-identification system using the new gold standard corpus as a training set was very close to training on the original corpus (92.56 vs. 93.48 overall F-measures). Best i2b2/PhysioNet/CCHMC cross-training performances were obtained when training on the new shared CCHMC gold standard corpus, although performances were still lower than corpus-specific trainings. We successfully modified a de-identification dataset for external sharing while preserving the de-identification research value of the modified gold standard corpus with limited drop in machine learning de-identification performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21699,""
"Cost-effectiveness analysis of pharmaceutical treatment options in the first-line management of major depressive disorder in Belgium","Annemans, Brignone, Druais, De Pauw, Gauthier, Demyttenaere","https://doi.org/10.1007/s40273-014-0138-x","20150408","PubMed","Antidepressive Agents; Belgium; Cost-Benefit Analysis; Decision Making; Decision Trees; Depressive Disorder, Major; Drug Costs; Humans; Longitudinal Studies; Models, Economic; Probability; Quality-Adjusted Life Years","The objective of this study was to assess the cost effectiveness of commonly used antidepressants as first-line treatment of major depressive disorder (MDD) in Belgium. The model structure was based on a decision tree developed by the Swedish TLV (TandvÃƒÂ¥rds- och lÃƒÂ¤kemedelsfÃƒÂ¶rmÃƒÂ¥nsverket) and adapted to the Belgium healthcare setting, using primary local data on the patterns of treatment and following KCE [Federal Knowledge Center (Federaal Kenniscentrum voor de Gezondheidszorg)] recommendations. Comparators were escitalopram, citalopram, fluoxetine, paroxetine, sertraline, duloxetine, venlafaxine, and mirtazapine. In the model, patients not achieving remission or relapsing after remission on the assessed treatment moved to a second therapeutic step (titration, switch, add-on, or transfer to a specialist). In case of failure in the second step or following a suicide attempt, patients were assumed to be referred to secondary care. The time horizon was 1 year and the analysis was conducted from the National Institute for Health and Disability Insurance (NIHDI; national health insurance) and societal perspectives. Remission rates were obtained from the TLV network meta-analysis and risk of relapse, efficacy following therapeutic change, risk of suicide attempts and related death, utilities, costs (2012), and resources were derived from the published literature and expert opinion. The effect of uncertainty in model parameters was estimated through scenario analyses and a probabilistic sensitivity analysis (PSA). In the base-case analysis, escitalopram was identified as the optimal strategy: it dominated all other treatments except venlafaxine from the NIHDI perspective, against which it was cost effective with an incremental cost-effectiveness ratio of &lt;euro&gt;6,352 per quality-adjusted life-year (QALY). Escitalopram also dominated all other treatments from the societal perspective. At a threshold of &lt;euro&gt;30,000 per QALY and from the NIHDI perspective, the PSA showed that the probability of escitalopram being identified as the optimal strategy ranged from 61 % (vs. venlafaxine) to 100 % (vs. fluoxetine). Escitalopram was associated with the highest probability of being the optimal treatment from the NIHDI and societal perspectives. This analysis, based on new Belgian clinical practice data and following KCE requirements, provides additional information that may be used to guide the choice of treatments in the management of MDD in Belgium.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21700,""
"Implementation of Emergency Medical Text Classifier for syndromic surveillance","Travers, Haas, Waller, Schwartz, Mostafa, Best, Crouch","https://www.google.com/search?q=Implementation+of+Emergency+Medical+Text+Classifier+for+syndromic+surveillance.","20140526","PubMed","Disease Outbreaks; Electronic Health Records; Emergency Service, Hospital; Humans; Natural Language Processing; Public Health Informatics; Public Health Surveillance","Public health officials use syndromic surveillance systems to facilitate early detection and response to infectious disease outbreaks. Emergency department clinical notes are becoming more available for surveillance but present the challenge of accurately extracting concepts from these text data. The purpose of this study was to implement a new system, Emergency Medical Text Classifier (EMT-C), into daily production for syndromic surveillance and evaluate system performance and user satisfaction. The system was designed to meet user preferences for a syndromic classifier that maximized positive predictive value and minimized false positives in order to provide a manageable workload. EMT-C performed better than the baseline system on all metrics and users were slightly more satisfied with it. It is vital to obtain user input and test new systems in the production environment. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21701,""
"Automatically pairing measured findings across narrative abdomen CT reports","Sevenster, Bozeman, Cowhy, Trost","https://www.google.com/search?q=Automatically+pairing+measured+findings+across+narrative+abdomen+CT+reports.","20140526","PubMed","Data Mining; Humans; Narration; Natural Language Processing; Radiography, Abdominal; Radiology Information Systems; Tomography, X-Ray Computed","Radiological measurements are one of the key variables in widely adopted guidelines (WHO, RECIST) that standardize and objectivize response assessment in oncology care. Measurements are typically described in free-text, narrative radiology reports. We present a natural language processing pipeline that extracts measurements from radiology reports and pairs them with extracted measurements from prior reports of the same clinical finding, e.g., lymph node or mass. A ground truth was created by manually pairing measurements in the abdomen CT reports of 50 patients. A Random Forest classifier trained on 15 features achieved superior results in an end-to-end evaluation of the pipeline on the extraction and pairing task: precision 0.910, recall 0.878, F-measure 0.894, AUC 0.988. Representing the narrative content in terms of UMLS concepts did not improve results. Applications of the proposed technology include data mining, advanced search and workflow support for healthcare professionals managing radiological measurements. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21702,""
"Developing predictive models using electronic medical records: challenges and pitfalls","Paxton, Niculescu-Mizil, Saria","https://www.google.com/search?q=Developing+predictive+models+using+electronic+medical+records:+challenges+and+pitfalls.","20140526","PubMed","Area Under Curve; Artificial Intelligence; Electronic Health Records; Humans; Models, Biological; Patient Care; Prognosis; Shock, Septic","While Electronic Medical Records (EMR) contain detailed records of the patient-clinician encounter - vital signs, laboratory tests, symptoms, caregivers' notes, interventions prescribed and outcomes - developing predictive models from this data is not straightforward. These data contain systematic biases that violate assumptions made by off-the-shelf machine learning algorithms, commonly used in the literature to train predictive models. In this paper, we discuss key issues and subtle pitfalls specific to building predictive models from EMR. We highlight the importance of carefully considering both the special characteristics of EMR as well as the intended clinical use of the predictive model and show that failure to do so could lead to developing models that are less useful in practice. Finally, we describe approaches for training and evaluating models on EMR using early prediction of septic shock as our example application. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21703,""
"Identifying synonymy between SNOMED clinical terms of varying length using distributional analysis of electronic health records","Henriksson, Conway, Duneld, Chapman","https://www.google.com/search?q=Identifying+synonymy+between+SNOMED+clinical+terms+of+varying+length+using+distributional+analysis+of+electronic+health+records.","20140526","PubMed","Electronic Health Records; Models, Theoretical; Natural Language Processing; Semantics; Subject Headings; Systematized Nomenclature of Medicine","Medical terminologies and ontologies are important tools for natural language processing of health record narratives. To account for the variability of language use, synonyms need to be stored in a semantic resource as textual instantiations of a concept. Developing such resources manually is, however, prohibitively expensive and likely to result in low coverage. To facilitate and expedite the process of lexical resource development, distributional analysis of large corpora provides a powerful data-driven means of (semi-)automatically identifying semantic relations, including synonymy, between terms. In this paper, we demonstrate how distributional analysis of a large corpus of electronic health records - the MIMIC-II database - can be employed to extract synonyms of SNOMED CT preferred terms. A distinctive feature of our method is its ability to identify synonymous relations between terms of varying length. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21704,""
"Automated extraction of the Barthel Index from clinical texts","Giang, Williams, Argyros","https://www.google.com/search?q=Automated+extraction+of+the+Barthel+Index+from+clinical+texts.","20140526","PubMed","Activities of Daily Living; Algorithms; Data Mining; Electronic Health Records; Humans; Natural Language Processing; Semantics","This paper describes a text mining program that computes the Barthel score of functional status by analyzing clinical notes stored in Electronic Health Record systems(EHR) and comparing them to textual evidence provided by clinical experts. The program demonstrates high accuracy and overall reliability based on a relatively small number of expert-abstracted charts. It offers an efficient and affordable method for estimating functional status using clinical notes. An important feature is an architecture that facilitates interaction between users and the program, allowing the program to improve its performance based on user feedback . ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21705,""
"Development and content validation of the information assessment method for patients and consumers","Pluye, Granikov, Bartlett, Grad, Tang, Johnson-Lafleur, Shulha, Barbosa GalvÃƒÂ£o, Ricarte, Stephenson, Shohet, Hutsul, Repchinsky, Rosenberg, Burnand, LÃƒÂ©garÃƒÂ©, Dunikowski, Murray, Boruff, Frati, Kloda, Macaulay, Lagarde, Doray","https://doi.org/10.2196/resprot.2908","20140219","PubMed","consumer health information; consumer-centered outcomes; content validity; information retrieval; information use; push technology","Online consumer health information addresses health problems, self-care, disease prevention, and health care services and is intended for the general public. Using this information, people can improve their knowledge, participation in health decision-making, and health. However, there are no comprehensive instruments to evaluate the value of health information from a consumer perspective. We collaborated with information providers to develop and validate the Information Assessment Method for all (IAM4all) that can be used to collect feedback from information consumers (including patients), and to enable a two-way knowledge translation between information providers and consumers. Content validation steps were followed to develop the IAM4all questionnaire. The first version was based on a theoretical framework from information science, a critical literature review and prior work. Then, 16 laypersons were interviewed on their experience with online health information and specifically their impression of the IAM4all questionnaire. Based on the summaries and interpretations of interviews, questionnaire items were revised, added, and excluded, thus creating the second version of the questionnaire. Subsequently, a panel of 12 information specialists and 8 health researchers participated in an online survey to rate each questionnaire item for relevance, clarity, representativeness, and specificity. The result of this expert panel contributed to the third, current, version of the questionnaire. The current version of the IAM4all questionnaire is structured by four levels of outcomes of information seeking/receiving: situational relevance, cognitive impact, information use, and health benefits. Following the interviews and the expert panel survey, 9 questionnaire items were confirmed as relevant, clear, representative, and specific. To improve readability and accessibility for users with a lower level of literacy, 19 items were reworded and all inconsistencies in using a passive or active voice have been solved. One item was removed due to redundancy. The current version of the IAM4all questionnaire contains 28 items. We developed and content validated the IAM4all in partnership with information providers, information specialists, researchers and representatives of information consumers. This questionnaire can be integrated within electronic knowledge resources to stimulate users' reflection (eg, their intention to use information). We claim that any organization (eg, publishers, community organizations, or patient associations), can evaluate and improve their online consumer health information from a consumers' perspective using this method.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21706,""
"ÃŽÂ³ -H2AX: A Novel Prognostic Marker in a Prognosis Prediction Model of Patients with Early Operable Non-Small Cell Lung Cancer","Chatzimichail, Matthaios, Bouros, Karakitsos, Romanidis, Kakolyris, Papashinopoulos, Rigas","https://doi.org/10.1155/2014/160236","20140214","PubMed","","Cancer is a leading cause of death worldwide and the prognostic evaluation of cancer patients is of great importance in medical care. The use of artificial neural networks in prediction problems is well established in human medical literature. The aim of the current study was to assess the prognostic value of a series of clinical and molecular variables with the addition of ÃŽÂ³ -H2AX-a new DNA damage response marker-for the prediction of prognosis in patients with early operable non-small cell lung cancer by comparing the ÃŽÂ³ -H2AX-based artificial network prediction model with the corresponding LR one. Two prognostic models of 96 patients with 27 input variables were constructed by using the parameter-increasing method in order to compare the predictive accuracy of neural network and logistic regression models. The quality of the models was evaluated by an independent validation data set of 11 patients. Neural networks outperformed logistic regression in predicting the patient's outcome according to the experimental results. To assess the importance of the two factors p53 and ÃŽÂ³ -H2AX, models without these two variables were also constructed. JR and accuracy of these models were lower than those of the models using all input variables, suggesting that these biological markers are very important for optimal performance of the models. This study indicates that neural networks may represent a potentially more useful decision support tool than conventional statistical methods for predicting the outcome of patients with non-small cell lung cancer and that some molecular markers, such as ÃŽÂ³ -H2AX, enhance their predictive ability. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21707,""
"A Network Approach to Wound Healing","Arodz, Bonchev, Diegelmann","https://doi.org/10.1089/wound.2012.0386","20211021","PubMed","","The wound healing process is well-understood on the cellular and tissue level; however, its complex molecular mechanisms are not yet uncovered in their entirety. Viewing wounds as perturbed molecular networks provides the tools for analyzing and optimizing the healing process. It helps to answer specific questions that lead to better understanding of the complexity of the process. What are the molecular pathways involved in wound healing? How do these pathways interact with each other during the different stages of wound healing? Is it possible to grasp the entire mechanism of regulatory interactions in the healing of a wound? Networks are structures composed of nodes connected by links. A network describing the state of a cell taking part in the healing process may contain nodes representing genes, proteins, microRNAs, metabolites, and drug molecules. The links connecting nodes represent interactions such as binding, regulation, co-expression, chemical reaction, and others. Both nodes and links can be weighted by numbers related to molecular concentration and the intensity of intermolecular interactions. Proceeding from data and from molecular profiling experiments, different types of networks are built to characterize the stages of the healing process. Network nodes having a higher degree of connectivity and centrality usually play more important roles for the functioning of the system they describe. We describe here the algorithms and software packages for building, manipulating and analyzing networks proceeding from information available from a literature or database search or directly extracted from experimental gene expression, metabolic, and proteomic data. Network analysis identifies genes/proteins most differentiated during the healing process, and their organization in functional pathways or modules, and their distribution into gene ontology categories of biological processes, molecular functions, and cellular localization. We provide an example of how network analysis can be used to reach better understanding of regulation of key wound healing mediators and microRNAs that regulate them. Univariate statistical tests widely used in clinical studies are not enough to improve understanding and optimize the processes of wound healing. Network methods of analysis of patients ""omics"" data, such as transcriptoms, proteomes, and others can provide a better insight into the healing processes and help in development of better treatment practices. We review several articles that are examples of this emergent approach to the study of wound healing. Network analysis has the potential to considerably contribute to the better understanding of the molecular mechanisms of wound healing and to the discovery of means to control and optimize that process.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21708,""
"Short communication: cheminformatics analysis to identify predictors of antiviral drug penetration into the female genital tract","Thompson, Sedykh, Nicol, Muratov, Fourches, Tropsha, Kashuba","https://doi.org/10.1089/AID.2013.0254","20150622","PubMed","Administration, Oral; Anti-Retroviral Agents; Artificial Intelligence; Bodily Secretions; Female; Genitalia, Female; Humans; Models, Statistical; Quantitative Structure-Activity Relationship","The exposure of oral antiretroviral (ARV) drugs in the female genital tract (FGT) is variable and almost unpredictable. Identifying an efficient method to find compounds with high tissue penetration would streamline the development of regimens for both HIV preexposure prophylaxis and viral reservoir targeting. Here we describe the cheminformatics investigation of diverse drugs with known FGT penetration using cluster analysis and quantitative structure-activity relationships (QSAR) modeling. A literature search over the 1950-2012 period identified 58 compounds (including 21 ARVs and representing 13 drug classes) associated with their actual concentration data for cervical or vaginal tissue, or cervicovaginal fluid. Cluster analysis revealed significant trends in the penetrative ability for certain chemotypes. QSAR models to predict genital tract concentrations normalized to blood plasma concentrations were developed with two machine learning techniques utilizing drugs' molecular descriptors and pharmacokinetic parameters as inputs. The QSAR model with the highest predictive accuracy had R(2)test=0.47. High volume of distribution, high MRP1 substrate probability, and low MRP4 substrate probability were associated with FGT concentrations Ã¢â€°Â¥1.5-fold plasma concentrations. However, due to the limited FGT data available, prediction performances of all models were low. Despite this limitation, we were able to support our findings by correctly predicting the penetration class of rilpivirine and dolutegravir. With more data to enrich the models, we believe these methods could potentially enhance the current approach of clinical testing.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21709,""
"DFLAT: functional annotation for human development","Wick, Drabkin, Ngu, Sackman, Fournier, Haggett, Blake, Bianchi, Slonim","https://doi.org/10.1186/1471-2105-15-45","20140615","PubMed","Amniotic Fluid; Databases, Genetic; Fetal Development; Fetal Diseases; Genes; Genomics; Human Development; Humans; Infant, Newborn; Molecular Sequence Annotation; Vocabulary, Controlled","Recent increases in genomic studies of the developing human fetus and neonate have led to a need for widespread characterization of the functional roles of genes at different developmental stages. The Gene Ontology (GO), a valuable and widely-used resource for characterizing gene function, offers perhaps the most suitable functional annotation system for this purpose. However, due in part to the difficulty of studying molecular genetic effects in humans, even the current collection of comprehensive GO annotations for human genes and gene products often lacks adequate developmental context for scientists wishing to study gene function in the human fetus. The Developmental FunctionaL Annotation at Tufts (DFLAT) project aims to improve the quality of analyses of fetal gene expression and regulation by curating human fetal gene functions using both manual and semi-automated GO procedures. Eligible annotations are then contributed to the GO database and included in GO releases of human data. DFLAT has produced a considerable body of functional annotation that we demonstrate provides valuable information about developmental genomics. A collection of gene sets (genes implicated in the same function or biological process), made by combining existing GO annotations with the 13,344 new DFLAT annotations, is available for use in novel analyses. Gene set analyses of expression in several data sets, including amniotic fluid RNA from fetuses with trisomies 21 and 18, umbilical cord blood, and blood from newborns with bronchopulmonary dysplasia, were conducted both with and without the DFLAT annotation. Functional analysis of expression data using the DFLAT annotation increases the number of implicated gene sets, reflecting the DFLAT's improved representation of current knowledge. Blinded literature review supports the validity of newly significant findings obtained with the DFLAT annotations. Newly implicated significant gene sets also suggest specific hypotheses for future research. Overall, the DFLAT project contributes new functional annotation and gene sets likely to enhance our ability to interpret genomic studies of human fetal and neonatal development.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21710,""
"Synonym extraction and abbreviation expansion with ensembles of semantic spaces","Henriksson, Moen, Skeppstedt, DaudaraviÃ„Âius, Duneld","https://doi.org/10.1186/2041-1480-5-6","20140227","PubMed","","Terminologies that account for variation in language use by linking synonyms and abbreviations to their corresponding concept are important enablers of high-quality information extraction from medical texts. Due to the use of specialized sub-languages in the medical domain, manual construction of semantic resources that accurately reflect language use is both costly and challenging, often resulting in low coverage. Although models of distributional semantics applied to large corpora provide a potential means of supporting development of such resources, their ability to isolate synonymy from other semantic relations is limited. Their application in the clinical domain has also only recently begun to be explored. Combining distributional models and applying them to different types of corpora may lead to enhanced performance on the tasks of automatically extracting synonyms and abbreviation-expansion pairs. A combination of two distributional models - Random Indexing and Random Permutation - employed in conjunction with a single corpus outperforms using either of the models in isolation. Furthermore, combining semantic spaces induced from different types of corpora - a corpus of clinical text and a corpus of medical journal articles - further improves results, outperforming a combination of semantic spaces induced from a single source, as well as a single semantic space induced from the conjoint corpus. A combination strategy that simply sums the cosine similarity scores of candidate terms is generally the most profitable out of the ones explored. Finally, applying simple post-processing filtering rules yields substantial performance gains on the tasks of extracting abbreviation-expansion pairs, but not synonyms. The best results, measured as recall in a list of ten candidate terms, for the three tasks are: 0.39 for abbreviations to long forms, 0.33 for long forms to abbreviations, and 0.47 for synonyms. This study demonstrates that ensembles of semantic spaces can yield improved performance on the tasks of automatically extracting synonyms and abbreviation-expansion pairs. This notion, which merits further exploration, allows different distributional models - with different model parameters - and different types of corpora to be combined, potentially allowing enhanced performance to be obtained on a wide range of natural language processing tasks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21711,""
"Outcomes of robotic-assisted colorectal surgery compared with laparoscopic and open surgery: a systematic review","Kim, Kim, Baik","https://doi.org/10.1007/s11605-014-2469-5","20141118","PubMed","Blood Loss, Surgical; Colectomy; Colonic Neoplasms; Conversion to Open Surgery; Humans; Laparoscopy; Length of Stay; Lymph Node Excision; Neoplasm, Residual; Operative Time; Rectal Neoplasms; Robotics; Treatment Outcome","Robotic technology has been applied to colorectal surgery over the last decade. The aim of this review is to analyze the outcomes of robotic colorectal surgery systematically and to provide objective information to surgeons. Studies were searched and identified using PubMed and Google Scholar from Jan 2001 to Feb 2013 with the search terms ""robot,"" ""robotic,"" ""colon,"" ""rectum,"" ""colorectal,"" and ""colectomy."" Appropriate data in the studies about the outcomes of robotic colorectal surgery were analyzed. Sixty-nine publications were included in this review and composed of 39 case series, 29 comparative studies, and 1 randomized controlled trial. Most of the studies reported that robotic surgery showed a longer operation time, less estimated blood loss, shorter length of hospital stay, lower complication and conversion rates, and comparable oncologic outcomes compared to laparoscopic or open surgery. Robotic colorectal surgery is a safe and feasible option. Robotic surgery showed comparable short-term outcomes compared to laparoscopic surgery or open surgery. However, the long operation time and high cost are the limitations of robotic surgery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21712,""
"Multidimensional texture characterization: on analysis for brain tumor tissues using MRS and MRI","Nachimuthu, Baladhandapani","https://doi.org/10.1007/s10278-013-9669-5","20150414","PubMed","Artificial Intelligence; Brain; Brain Neoplasms; Diagnosis, Differential; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Magnetic Resonance Spectroscopy; Pattern Recognition, Automated; Reproducibility of Results","This paper investigates the efficacy of automated pattern recognition methods on magnetic resonance data with the objective of assisting radiologists in the clinical diagnosis of brain tissue tumors. In this paper, the sciences of magnetic resonance imaging (MRI) and magnetic resonance spectroscopy (MRS) are combined to improve the accuracy of the classifier, based on the multidimensional co-occurrence matrices to assess the detection of pathological tissues (tumor and edema), normal tissues (white matter - WM and gray matter - GM), and fluid (cerebrospinal fluid - CSF). The results show the ability of the classifier with iterative training to automatically and simultaneously recover tissue-specific spectral and structural patterns and achieve segmentation of tumor and edema and grading of high and low glioma tumor. Here, extreme learning machine - improved particle swarm optimization (ELM-IPSO) neural network classifier is trained with the feature descriptions in brain magnetic resonance (MR) spectra. This has the characteristics of varying the normal spectral pattern associated with tumor patterns along with imaging features. Validation was performed considering 35 clinical studies. The volumetric features extracted from the vectors of this matrix articulate some important elementary structures, which along with spectroscopic metabolite ratios discriminate the tumor grades and tissue classes. The quantitative 3D analysis reveals significant improvement in terms of global accuracy rate for automatic classification in brain tissues and discriminating pathological tumor tissue from structural healthy brain tissue. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21713,""
"Influence of exposure assessment and parameterization on exposure response Aspects of epidemiologic cohort analysis using the Libby Amphibole asbestos worker cohort","Bateson, Kopylev","https://doi.org/10.1038/jes.2014.3","20160408","PubMed","Adult; Asbestos, Amphibole; Cohort Studies; Female; Humans; Lung Neoplasms; Male; Mining; Montana; Occupational Exposure; Smoking","Recent meta-analyses of occupational epidemiology studies identified two important exposure data quality factors in predicting summary effect measures for asbestos-associated lung cancer mortality risk: sufficiency of job history data and percent coverage of work history by measured exposures. The objective was to evaluate different exposure parameterizations suggested in the asbestos literature using the Libby, MT asbestos worker cohort and to evaluate influences of exposure measurement error caused by historically estimated exposure data on lung cancer risks. Focusing on workers hired after 1959, when job histories were well-known and occupational exposures were predominantly based on measured exposures (85% coverage), we found that cumulative exposure alone, and with allowance of exponential decay, fit lung cancer mortality data similarly. Residence-time-weighted metrics did not fit well. Compared with previous analyses based on the whole cohort of Libby workers hired after 1935, when job histories were less well-known and exposures less frequently measured (47% coverage), our analyses based on higher quality exposure data yielded an effect size as much as 3.6 times higher. Future occupational cohort studies should continue to refine retrospective exposure assessment methods, consider multiple exposure metrics, and explore new methods of maintaining statistical power while minimizing exposure measurement error. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21714,""
"Clustering clinical trials with similar eligibility criteria features","Hao, Rusanov, Boland, Weng","https://doi.org/10.1016/j.jbi.2014.01.009","20150826","PubMed","Clinical trial; Cluster analysis; Medical informatics; Clinical Trials as Topic; Cluster Analysis; Data Mining; Humans; Medical Informatics; Semantics","To automatically identify and cluster clinical trials with similar eligibility features. Using the public repository ClinicalTrials.gov as the data source, we extracted semantic features from the eligibility criteria text of all clinical trials and constructed a trial-feature matrix. We calculated the pairwise similarities for all clinical trials based on their eligibility features. For all trials, by selecting one trial as the center each time, we identified trials whose similarities to the central trial were greater than or equal to a predefined threshold and constructed center-based clusters. Then we identified unique trial sets with distinctive trial membership compositions from center-based clusters by disregarding their structural information. From the 145,745 clinical trials on ClinicalTrials.gov, we extracted 5,508,491 semantic features. Of these, 459,936 were unique and 160,951 were shared by at least one pair of trials. Crowdsourcing the cluster evaluation using Amazon Mechanical Turk (MTurk), we identified the optimal similarity threshold, 0.9. Using this threshold, we generated 8806 center-based clusters. Evaluation of a sample of the clusters by MTurk resulted in a mean score 4.331Ã‚Â±0.796 on a scale of 1-5 (5 indicating ""strongly agree that the trials in the cluster are similar""). We contribute an automated approach to clustering clinical trials with similar eligibility features. This approach can be potentially useful for investigating knowledge reuse patterns in clinical trial eligibility criteria designs and for improving clinical trial recruitment. We also contribute an effective crowdsourcing method for evaluating informatics interventions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21715,""
"Glutamatergic candidate genes in autism spectrum disorder: an overview","Chiocchetti, Bour, Freitag","https://doi.org/10.1007/s00702-014-1161-y","20150511","PubMed","Animals; Child Development Disorders, Pervasive; Glutamic Acid; Humans","Autism spectrum disorders (ASD) are neurodevelopmental disorders with early onset in childhood. Most of the risk for ASD can be explained by genetic variants that act in interaction with biological environmental risk factors. However, the architecture of the genetic components is still unclear. Genetic studies and subsequent systems biological approaches described converging functional effects of identified genes towards pathways relevant for neuronal signalling. Mouse models suggest an aberrant synaptic plasticity at the neuropathological level, which is believed to be conferred by dysregulation of long-term potentiation or depression of neuronal connections. A central pathway regulating these mechanisms is glutamatergic signalling. Here, we hypothesized that susceptibility genes for ASD are enriched for components of this pathway. To further understand the impact of ASD risk genes on the glutamatergic pathway, we performed a systematic review using the literature database ""pubmed"" and the ""AutismKB"" knowledgebase. We provide an overview of the glutamatergic system in typical brain function and development, and summarize findings from linkage, association, copy number variants, and sequencing studies in ASD to provide a comprehensive picture of the glutamatergic landscape of ASD genetics. Genetic variants associated with ASD were enriched in glutamatergic pathways, affecting receptor signalling, metabolism and transport. Furthermore, in genetically modified mouse models for ASD, pharmacological compounds acting on ionotropic or metabotropic receptor activity are able to rescue ASD reminscent phenotypes. We conclude that glutamatergic genetic risk factors for ASD show a complex pattern and further studies are needed to fully understand its mechanisms, before translation of findings into clinical applications and individualized treatment approaches will be possible.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21716,""
"Predicting the risk of suicide by analyzing the text of clinical notes","Poulin, Shiner, Thompson, Vepstas, Young-Xu, Goertzel, Watts, Flashman, McAllister","https://doi.org/10.1371/journal.pone.0085733","20141218","PubMed","Humans; Medical Records; Mental Health Services; Risk Factors; Suicide; United States; United States Department of Veterans Affairs; Veterans","We developed linguistics-driven prediction models to estimate the risk of suicide. These models were generated from unstructured clinical notes taken from a national sample of U.S. Veterans Administration (VA) medical records. We created three matched cohorts: veterans who committed suicide, veterans who used mental health services and did not commit suicide, and veterans who did not use mental health services and did not commit suicide during the observation period (n = 70 in each group). From the clinical notes, we generated datasets of single keywords and multi-word phrases, and constructed prediction models using a machine-learning algorithm based on a genetic programming framework. The resulting inference accuracy was consistently 65% or more. Our data therefore suggests that computerized text analytics can be applied to unstructured medical records to estimate the risk of suicide. The resulting system could allow clinicians to potentially screen seemingly healthy patients at the primary care level, and to continuously evaluate the suicide risk among psychiatric patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21717,""
"Using natural language processing to improve efficiency of manual chart abstraction in research: the case of breast cancer recurrence","Carrell, Halgrim, Tran, Buist, Chubak, Chapman, Savova","https://doi.org/10.1093/aje/kwt441","20140429","PubMed","breast cancer recurrence; chart abstraction; natural language processing; Age Factors; Aged; Breast Neoplasms; Electronic Health Records; Female; Humans; Middle Aged; Natural Language Processing; Neoplasm Grading; Neoplasm Recurrence, Local; Reference Standards; Reproducibility of Results","The increasing availability of electronic health records (EHRs) creates opportunities for automated extraction of information from clinical text. We hypothesized that natural language processing (NLP) could substantially reduce the burden of manual abstraction in studies examining outcomes, like cancer recurrence, that are documented in unstructured clinical text, such as progress notes, radiology reports, and pathology reports. We developed an NLP-based system using open-source software to process electronic clinical notes from 1995 to 2012 for women with early-stage incident breast cancers to identify whether and when recurrences were diagnosed. We developed and evaluated the system using clinical notes from 1,472 patients receiving EHR-documented care in an integrated health care system in the Pacific Northwest. A separate study provided the patient-level reference standard for recurrence status and date. The NLP-based system correctly identified 92% of recurrences and estimated diagnosis dates within 30 days for 88% of these. Specificity was 96%. The NLP-based system overlooked 5 of 65 recurrences, 4 because electronic documents were unavailable. The NLP-based system identified 5 other recurrences incorrectly classified as nonrecurrent in the reference standard. If used in similar cohorts, NLP could reduce by 90% the number of EHR charts abstracted to identify confirmed breast cancer recurrence cases at a rate comparable to traditional abstraction. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21718,""
"An evidence-based knowledgebase of pulmonary arterial hypertension to identify genes and pathways relevant to pathogenesis","Zhao, Austin, Hemnes, Loyd, Zhao","https://doi.org/10.1039/c3mb70496c","20141203","PubMed","Chromosome Mapping; Data Collection; Databases, Genetic; Familial Primary Pulmonary Hypertension; Focal Adhesions; Humans; Internet; MAP Kinase Signaling System; Neoplasms; Receptors, Cytokine; Transforming Growth Factor beta","Pulmonary arterial hypertension (PAH) is a major progressive form of pulmonary hypertension (PH) with more than 4800 patients in the United States. In the last two decades, many studies have identified numerous genes associated with this disease. However, there is no comprehensive research resource for PAH or other PH types that integrates various genetic studies and their related biological information. Thus, the number of associated genes, and their strength of evidence, is unclear. In this study, we tested the hypothesis that a web-based knowledgebase could be used to develop a biological map of highly interrelated, functionally important genes in PAH. We developed the pulmonary arterial hypertension knowledgebase (PAHKB, ), a comprehensive database with a user-friendly web interface. PAHKB extracts genetic data from all available sources, including those from association studies, genetic mutation, gene expression, animal model, supporting literature, various genomic annotations, gene networks, cellular and regulatory pathways, as well as microRNAs. Moreover, PAHKB provides online tools for data browsing and searching, data integration, pathway graphical presentation, and gene ranking. In the current release, PAHKB contains 341 human PH-related genes (293 protein coding and 48 non-coding genes) curated from over 1000 PubMed abstracts. Based on the top 39 ranked PAH-related genes in PAHKB, we constructed a core biological map. This core map was enriched with the TGF-beta signaling pathway, focal adhesion, cytokine-cytokine receptor interaction, and MAPK signaling. In addition, the reconstructed map elucidates several novel cancer signaling pathways, which may provide clues to support the application of anti-cancer therapeutics to PAH. In summary, we have developed a system for the identification of core PH-related genes and identified critical signaling pathways that may be relevant to PAH pathogenesis. This system can be easily applied to other pulmonary diseases. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21719,""
"Signal detection of potentially drug-induced acute liver injury in children using a multi-country healthcare database network","Ferrajolo, Coloma, Verhamme, Schuemie, de Bie, Gini, Herings, Mazzaglia, Picelli, Giaquinto, Scotti, Avillach, Pedersen, Rossi, Capuano, van der Lei, TrifirÃƒÂ³, Sturkenboom","https://doi.org/10.1007/s40264-013-0132-9","20140908","PubMed","Adolescent; Adverse Drug Reaction Reporting Systems; Chemical and Drug Induced Liver Injury; Child; Child Welfare; Child, Preschool; Data Mining; Databases, Factual; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; European Union; Humans; Infant; Infant, Newborn; International Cooperation; Liver Failure, Acute","Data mining in spontaneous reporting databases has shown that drug-induced liver injury is infrequently reported in children. Our objectives were to (i) identify drugs potentially associated with acute liver injury (ALI) in children and adolescents using electronic healthcare record (EHR) data; and (ii) to evaluate the significance and novelty of these associations. We identified potential cases of ALI during exposure to any prescribed/dispensed drug for individuals &lt;18 years old from the EU-ADR network, which includes seven databases from three countries, covering the years 1996-2010. Several new methods for signal detection were applied to identify all statistically significant associations between drugs and ALI. A drug was considered statistically significantly associated with ALI, using all other time as a reference category, if the 95% CI lower band of the relative risk was &gt;1 and in the presence of at least three exposed cases of ALI. Potentially new signals were distinguished from already known associations concerning ALI (whether in adults and/or in the paediatric population) through manual review of published literature and drug product labels. The study population comprised 4,838,146 individuals aged &lt;18 years, who contributed an overall 25,575,132 person-years of follow-up. Within this population, we identified 1,015 potential cases of ALI. Overall, 20 positive drug-ALI associations were detected. The associations between ALI and domperidone, flunisolide and human insulin were considered as potentially new signals. Citalopram and cetirizine have been previously described as hepatotoxic in adults but not in children, while all remaining associations were already known in both adults and children. Data mining of multiple EHR databases for signal detection confirmed known associations between ALI and several drugs, and identified some potentially new signals in children that require further investigation through formal epidemiologic studies. This study shows that EHRs may complement traditional spontaneous reporting systems for signal detection and strengthening.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21720,""
"Detecting concept mentions in biomedical text using hidden Markov model: multiple concept types at once or one at a time?","Torii, Wagholikar, Liu","https://doi.org/10.1186/2041-1480-5-3","20140203","PubMed","","Identifying phrases that refer to particular concept types is a critical step in extracting information from documents. Provided with annotated documents as training data, supervised machine learning can automate this process. When building a machine learning model for this task, the model may be built to detect all types simultaneously (all-types-at-once) or it may be built for one or a few selected types at a time (one-type- or a-few-types-at-a-time). It is of interest to investigate which strategy yields better detection performance. Hidden Markov models using the different strategies were evaluated on a clinical corpus annotated with three concept types (i2b2/VA corpus) and a biology literature corpus annotated with five concept types (JNLPBA corpus). Ten-fold cross-validation tests were conducted and the experimental results showed that models trained for multiple concept types consistently yielded better performance than those trained for a single concept type. F-scores observed for the former strategies were higher than those observed for the latter by 0.9 to 2.6% on the i2b2/VA corpus and 1.4 to 10.1% on the JNLPBA corpus, depending on the target concept types. Improved boundary detection and reduced type confusion were observed for the all-types-at-once strategy. The current results suggest that detection of concept phrases could be improved by simultaneously tackling multiple concept types. This also suggests that we should annotate multiple concept types in developing a new corpus for machine learning models. Further investigation is expected to gain insights in the underlying mechanism to achieve good performance when multiple concept types are considered.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21721,""
"Assisted annotation of medical free text using RapTAT","Gobbel, Garvin, Reeves, Cronin, Heavirland, Williams, Weaver, Jayaramaraja, Giuse, Speroff, Brown, Xu, Matheny","https://doi.org/10.1136/amiajnl-2013-002255","20141013","PubMed","Clinical Informatics; Guideline Adherence; Heart Failure; Medical Informatics Computing; Natural Language Processing; Artificial Intelligence; Electronic Health Records; Heart Failure; Humans; Natural Language Processing","To determine whether assisted annotation using interactive training can reduce the time required to annotate a clinical document corpus without introducing bias. A tool, RapTAT, was designed to assist annotation by iteratively pre-annotating probable phrases of interest within a document, presenting the annotations to a reviewer for correction, and then using the corrected annotations for further machine learning-based training before pre-annotating subsequent documents. Annotators reviewed 404 clinical notes either manually or using RapTAT assistance for concepts related to quality of care during heart failure treatment. Notes were divided into 20 batches of 19-21 documents for iterative annotation and training. The number of correct RapTAT pre-annotations increased significantly and annotation time per batch decreased by ~50% over the course of annotation. Annotation rate increased from batch to batch for assisted but not manual reviewers. Pre-annotation F-measure increased from 0.5 to 0.6 to &gt;0.80 (relative to both assisted reviewer and reference annotations) over the first three batches and more slowly thereafter. Overall inter-annotator agreement was significantly higher between RapTAT-assisted reviewers (0.89) than between manual reviewers (0.85). The tool reduced workload by decreasing the number of annotations needing to be added and helping reviewers to annotate at an increased rate. Agreement between the pre-annotations and reference standard, and agreement between the pre-annotations and assisted annotations, were similar throughout the annotation process, which suggests that pre-annotation did not introduce bias. Pre-annotations generated by a tool capable of interactive training can reduce the time required to create an annotated document corpus by up to 50%.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21722,""
"Cardiorespiratory fitness in breast cancer patients: a call for normative values","Peel, Thomas, Dittus, Jones, Lakoski","https://doi.org/10.1161/JAHA.113.000432","20140825","PubMed","breast cancer; cardiorespiratory fitness; women; Breast Neoplasms; Cardiovascular Diseases; Chemotherapy, Adjuvant; Exercise Test; Exercise Therapy; Female; Health Status; Humans; Myocardium; Oxygen Consumption; Physical Fitness; Predictive Value of Tests; Radiotherapy, Adjuvant; Reference Values; Risk Factors; Survivors; Time Factors; Treatment Outcome","There is emerging evidence that adjuvant treatments for breast cancer negatively impact cardiorespiratory fitness (CRF) or Vo2max, a key predictor of cardiovascular risk. Although a number of studies have measured CRF in breast cancer patients, there is currently limited data regarding expected CRF values in this patient population. Given that CRF is a poor prognostic sign and recently highlighted as a key measure to standardize by the American Heart Association, we sought to review the available literature on CRF among breast cancer patients. We identified 27 clinical trials and observational studies measuring Vo2max in the pre- and post-adjuvant treatment setting for breast cancer. We compared Vo2max before to Vo2max after adjuvant therapy and compared Vo2max in female breast cancer patients with Vo2max in healthy controls. We found that CRF was substantially lower in women with a history of breast cancer compared with healthy women and this was most pronounced among breast cancer patients in the post-adjuvant setting. We conclude that knowledge of normative CRF values is critical to tailor appropriately timed exercise interventions in breast cancer patients susceptible to low CRF and subsequent cardiovascular risk.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21723,""
"[Current reporting in radiology : what will happen tomorrow?]","Baumann, HacklÃƒÂ¤nder, Kotter","https://doi.org/10.1007/s00117-013-2540-3","20141010","PubMed","Documentation; Forecasting; Germany; Health Records, Personal; Information Storage and Retrieval; Medical Records Systems, Computerized; Radiology; Radiology Information Systems","Reporting in radiology faces considerable changes in the near future that will be influenced by a broader understanding of the task and increasing technological possibilities. Until now a radiological report could be regarded as a text phrased by a radiologist after viewing imaging data. New solutions will be accessed by advances in visualization of large datasets, in extracting, analyzing, and communicating metadata as well as by improved integration and interpretation of clinical information. Virtual reality, texture analysis, growing networks, semantic annotation, data mining and context based presentation have the potential to extensively change the everyday working routine. Although many of these developments are still in a laboratory phase, the impact on the process of reporting can already be predicted. As the leading community in information analysis and technology, radiology as a subject should strive to lead and shape these impending changes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21724,""
"Recruitment of veterans from primary care into a physical activity randomized controlled trial: the experience of the VA-STRIDE study","Hawkins, Hough, Berger, Mor, Steenkiste, Gao, Stone, Burkitt, Marcus, Ciccolo, Kriska, Klinvex, Sevick","https://doi.org/10.1186/1745-6215-15-11","20140915","PubMed","Automation; Electronic Health Records; Humans; Motor Activity; Overweight; Patient Selection; Pennsylvania; Primary Health Care; Randomized Controlled Trials as Topic; Sample Size; Sedentary Behavior; Veterans","Much of the existing literature on physical activity (PA) interventions involves physically inactive individuals recruited from community settings rather than clinical practice settings. Recruitment of patients into interventions in clinical practice settings is difficult due to limited time available in the clinic, identification of appropriate personnel to efficiently conduct the process, and time-consuming methods of recruitment. The purpose of this report is to describe the approach used to identify and recruit veterans from the Veterans Affairs (VA) Pittsburgh Healthcare System Primary Care Clinic into a randomized controlled PA study. A sampling frame of veterans was developed using the VA electronic medical record. During regularly scheduled clinic appointments, primary care providers (PCPs) screened identified patients for safety to engage in moderate-intensity PA and willingness to discuss the study with research staff members. Research staff determined eligibility with a subsequent telephone screening call and scheduled a research study appointment, at which time signed informed consent and baseline measurements were obtained. Of the 3,482 veterans in the sampling frame who were scheduled for a primary care appointment during the study period, 1,990 (57.2%) were seen in the clinic and screened by the PCP; moderate-intensity PA was deemed safe for 1,293 (37.1%), 871 (25.0%) agreed to be contacted for further screening, 334 (9.6%) were eligible for the study, and 232 (6.7%) enrolled. Using a semiautomated screening approach that combined an electronically-derived sampling frame with paper and pencil prescreening by PCPs and research staff, VA-STRIDE was able to recruit 1 in 15 veterans in the sampling frame. Using this approach, a high proportion of potentially eligible veterans were screened by their PCPs. Clinical trials.gov identifier: NCT00731094.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21725,""
"Discovering implicit entity relation with the gene-citation-gene network","Song, Han, Kim, Ding, Chambers","https://doi.org/10.1371/journal.pone.0084639","20140916","PubMed","Computational Biology; Data Mining; Databases, Genetic; Gene Regulatory Networks; Humans; Protein Interaction Mapping","In this paper, we apply the entitymetrics model to our constructed Gene-Citation-Gene (GCG) network. Based on the premise there is a hidden, but plausible, relationship between an entity in one article and an entity in its citing article, we constructed a GCG network of gene pairs implicitly connected through citation. We compare the performance of this GCG network to a gene-gene (GG) network constructed over the same corpus but which uses gene pairs explicitly connected through traditional co-occurrence. Using 331,411 MEDLINE abstracts collected from 18,323 seed articles and their references, we identify 25 gene pairs. A comparison of these pairs with interactions found in BioGRID reveal that 96% of the gene pairs in the GCG network have known interactions. We measure network performance using degree, weighted degree, closeness, betweenness centrality and PageRank. Combining all measures, we find the GCG network has more gene pairs, but a lower matching rate than the GG network. However, combining top ranked genes in both networks produces a matching rate of 35.53%. By visualizing both the GG and GCG networks, we find that cancer is the most dominant disease associated with the genes in both networks. Overall, the study indicates that the GCG network can be useful for detecting gene interaction in an implicit manner. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21726,""
"A Multi-Core Parallelization Strategy for Statistical Significance Testing in Learning Classifier Systems","Rudd, Moore, Urbanowicz","https://doi.org/10.1007/s12065-013-0092-0","20211021","PubMed","Algorithms; Design; LCS; Performance; multi-core processors; parallelization; scalability; significance testing","Permutation-based statistics for evaluating the significance of class prediction, predictive attributes, and patterns of association have only appeared within the learning classifier system (LCS) literature since 2012. While still not widely utilized by the LCS research community, formal evaluations of test statistic confidence are imperative to large and complex real world applications such as genetic epidemiology where it is standard practice to quantify the likelihood that a seemingly meaningful statistic could have been obtained purely by chance. LCS algorithms are relatively computationally expensive on their own. The compounding requirements for generating permutation-based statistics may be a limiting factor for some researchers interested in applying LCS algorithms to real world problems. Technology has made LCS parallelization strategies more accessible and thus more popular in recent years. In the present study we examine the benefits of externally parallelizing a series of independent LCS runs such that permutation testing with cross validation becomes more feasible to complete on a single multi-core workstation. We test our python implementation of this strategy in the context of a simulated complex genetic epidemiological data mining problem. Our evaluations indicate that as long as the number of concurrent processes does not exceed the number of CPU cores, the speedup achieved is approximately linear.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21727,""
"Sexuality and physical intimacy in long-term care","Lichtenberg","https://doi.org/10.3109/07380577.2013.865858","20140828","PubMed","Aged; Cognition Disorders; Decision Making; Decision Trees; Dementia; Frail Elderly; Humans; Interviews as Topic; Long-Term Care; Male; Sexual Behavior; Sexuality","Sexuality and sexual needs in older adults remains a neglected area of clinical intervention, particularly so in long-term care settings. Because older adults in medical rehabilitation and long-term care beds present with significant frailties, and often significant neurocognitive disorders, it makes it difficult for occupational therapists and other staff to evaluate the capacity of an older adult resident to participate in sexual relationships. The current paper reviews the current literature on sexuality and aging, examines some of the clinical practices and guidelines regarding sexual expression in long-term care, and presents two case examples. A semistructured interview and decision tree is presented to assist therapists in making careful and informed decisions and thereby balancing the needs for protection with the needs for autonomy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21728,""
"Treatment of median arcuate ligament syndrome via traditional and robotic techniques","You, Cooper, Nishida, Matsuda, Murariu","https://www.google.com/search?q=Treatment+of+median+arcuate+ligament+syndrome+via+traditional+and+robotic+techniques.","20141112","PubMed","Dunbar syndrome; celiac artery compression syndrome; celiac axis syndrome; median arcuate ligament syndrome; Celiac Artery; Constriction, Pathologic; Female; Humans; Laparoscopy; Median Arcuate Ligament Syndrome; Middle Aged; Radiography; Robotics","Median arcuate ligament syndrome (MALS) is a rare entity characterized by extrinsic compression of the celiac artery and symptoms of postprandial epigastric pain, nausea, vomiting, and weight loss mimicking mesenteric ischemia. We present two patients diagnosed with MALS, the first treated with an open laparotomy by a vascular surgeon and the second using a robot assisted laparoscopic approach by a general surgeon with a vascular surgeon on standby. This is the second ever report of this approach. Both patients recovered without complications and experienced resolution of their symptoms. A discussion of the pathophysiology, literature review, and multispecialty treatment approach are presented. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21729,""
"Appraisal tools for clinical practice guidelines: a systematic review","Siering, Eikermann, Hausner, Hoffmann-EÃƒÅ¸er, Neugebauer","https://doi.org/10.1371/journal.pone.0082915","20150330","PubMed","Delivery of Health Care; Evaluation Studies as Topic; Humans; MEDLINE; Practice Guidelines as Topic","Clinical practice guidelines can improve healthcare processes and patient outcomes, but are often of low quality. Guideline appraisal tools aim to help potential guideline users in assessing guideline quality. We conducted a systematic review of publications describing guideline appraisal tools in order to identify and compare existing tools. Among others we searched MEDLINE, EMBASE and the Cochrane Database of Systematic Reviews from 1995 to May 2011 for relevant primary and secondary publications. We also handsearched the reference lists of relevant publications. On the basis of the available literature we firstly generated 34 items to be used in the comparison of appraisal tools and grouped them into thirteen quality dimensions. We then extracted formal characteristics as well as questions and statements of the appraisal tools and assigned them to the items. We identified 40 different appraisal tools. They covered between three and thirteen of the thirteen possible quality dimensions and between three and 29 of the possible 34 items. The main focus of the appraisal tools were the quality dimensions ""evaluation of evidence"" (mentioned in 35 tools; 88%), ""presentation of guideline content"" (34 tools; 85%), ""transferability"" (33 tools; 83%), ""independence"" (32 tools; 80%), ""scope"" (30 tools; 75%), and ""information retrieval"" (29 tools; 73%). The quality dimensions ""consideration of different perspectives"" and ""dissemination, implementation and evaluation of the guideline"" were covered by only twenty (50%) and eighteen tools (45%) respectively. Most guideline appraisal tools assess whether the literature search and the evaluation, synthesis and presentation of the evidence in guidelines follow the principles of evidence-based medicine. Although conflicts of interest and norms and values of guideline developers, as well as patient involvement, affect the trustworthiness of guidelines, they are currently insufficiently considered. Greater focus should be placed on these issues in the further development of guideline appraisal tools.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21730,""
"A comprehensive study of named entity recognition in Chinese clinical text","Lei, Tang, Lu, Gao, Jiang, Xu","https://doi.org/10.1136/amiajnl-2013-002381","20141013","PubMed","Chinese clinic notes; Machine learning algorithm; Medical concept recognition; Natural language processing; Algorithms; Artificial Intelligence; China; Electronic Health Records; Humans; Natural Language Processing; Patient Admission; Support Vector Machine","Named entity recognition (NER) is one of the fundamental tasks in natural language processing. In the medical domain, there have been a number of studies on NER in English clinical notes; however, very limited NER research has been carried out on clinical notes written in Chinese. The goal of this study was to systematically investigate features and machine learning algorithms for NER in Chinese clinical text. We randomly selected 400 admission notes and 400 discharge summaries from Peking Union Medical College Hospital in China. For each note, four types of entity-clinical problems, procedures, laboratory test, and medications-were annotated according to a predefined guideline. Two-thirds of the 400 notes were used to train the NER systems and one-third for testing. We investigated the effects of different types of feature including bag-of-characters, word segmentation, part-of-speech, and section information, and different machine learning algorithms including conditional random fields (CRF), support vector machines (SVM), maximum entropy (ME), and structural SVM (SSVM) on the Chinese clinical NER task. All classifiers were trained on the training dataset and evaluated on the test set, and micro-averaged precision, recall, and F-measure were reported. Our evaluation on the independent test set showed that most types of feature were beneficial to Chinese NER systems, although the improvements were limited. The system achieved the highest performance by combining word segmentation and section information, indicating that these two types of feature complement each other. When the same types of optimized feature were used, CRF and SSVM outperformed SVM and ME. More specifically, SSVM achieved the highest performance of the four algorithms, with F-measures of 93.51% and 90.01% for admission notes and discharge summaries, respectively.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21731,""
"Evaluating predictive modeling algorithms to assess patient eligibility for clinical trials from routine data","KÃƒÂ¶pcke, Lubgan, Fietkau, Scholler, Nau, StÃƒÂ¼rzl, Croner, Prokosch, Toddenroth","https://doi.org/10.1186/1472-6947-13-134","20140714","PubMed","Algorithms; Clinical Trials as Topic; Electronic Health Records; Eligibility Determination; Feasibility Studies; Humans; Models, Theoretical; Patient Selection; Predictive Value of Tests","The necessity to translate eligibility criteria from free text into decision rules that are compatible with data from the electronic health record (EHR) constitutes the main challenge when developing and deploying clinical trial recruitment support systems. Recruitment decisions based on case-based reasoning, i.e. using past cases rather than explicit rules, could dispense with the need for translating eligibility criteria and could also be implemented largely independently from the terminology of the EHR's database. We evaluated the feasibility of predictive modeling to assess the eligibility of patients for clinical trials and report on a prototype's performance for different system configurations. The prototype worked by using existing basic patient data of manually assessed eligible and ineligible patients to induce prediction models. Performance was measured retrospectively for three clinical trials by plotting receiver operating characteristic curves and comparing the area under the curve (ROC-AUC) for different prediction algorithms, different sizes of the learning set and different numbers and aggregation levels of the patient attributes. Random forests were generally among the best performing models with a maximum ROC-AUC of 0.81 (CI: 0.72-0.88) for trial A, 0.96 (CI: 0.95-0.97) for trial B and 0.99 (CI: 0.98-0.99) for trial C. The full potential of this algorithm was reached after learning from approximately 200 manually screened patients (eligible and ineligible). Neither block- nor category-level aggregation of diagnosis and procedure codes influenced the algorithms' performance substantially. Our results indicate that predictive modeling is a feasible approach to support patient recruitment into clinical trials. Its major advantages over the commonly applied rule-based systems are its independency from the concrete representation of eligibility criteria and EHR data and its potential for automation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21732,""
"Automated workflow-based exploitation of pathway databases provides new insights into genetic associations of metabolite profiles","Dharuri, Henneman, Demirkan, van Klinken, Mook-Kanamori, Wang-Sattler, Gieger, Adamski, Hettne, Roos, Suhre, Van Duijn, van Dijk, 't Hoen, Demirkan, van Duijn, Ugocsai, Isaacs, Pramstaller, Liebisch, Wilson, Johansson, Rudan, Aulchenko, Kirichenko, Janssens, Jansen, Gnewuch, Domingues, Pattaro, Wild, Jonasson, Polasek, Zorkoltseva, Hofman, Karssen, Struchalin, Floyd, Igl, Biloglav, Broer, Pfeufer, Pichler, Campbell, Zaboli, Kolcic, Rivadeneira, Huffman, Hastie, Uitterlinden, Franke, Franklin, Vitart, Witteman, Axenovich, Oostra, Meitinger, Hicks, Hayward, Wright, Gyllensten, Campbell, Schmitz","https://doi.org/10.1186/1471-2164-14-865","20140721","PubMed","Computational Biology; Databases, Genetic; Electronic Data Processing; Genome-Wide Association Study; Humans; Linear Models; Metabolic Networks and Pathways; Metabolome; Polymorphism, Single Nucleotide; Software; Workflow","Genome-wide association studies (GWAS) have identified many common single nucleotide polymorphisms (SNPs) that associate with clinical phenotypes, but these SNPs usually explain just a small part of the heritability and have relatively modest effect sizes. In contrast, SNPs that associate with metabolite levels generally explain a higher percentage of the genetic variation and demonstrate larger effect sizes. Still, the discovery of SNPs associated with metabolite levels is challenging since testing all metabolites measured in typical metabolomics studies with all SNPs comes with a severe multiple testing penalty. We have developed an automated workflow approach that utilizes prior knowledge of biochemical pathways present in databases like KEGG and BioCyc to generate a smaller SNP set relevant to the metabolite. This paper explores the opportunities and challenges in the analysis of GWAS of metabolomic phenotypes and provides novel insights into the genetic basis of metabolic variation through the re-analysis of published GWAS datasets. Re-analysis of the published GWAS dataset from Illig et al. (Nature Genetics, 2010) using a pathway-based workflow (http://www.myexperiment.org/packs/319.html), confirmed previously identified hits and identified a new locus of human metabolic individuality, associating Aldehyde dehydrogenase family1 L1 (ALDH1L1) with serine/glycine ratios in blood. Replication in an independent GWAS dataset of phospholipids (Demirkan et al., PLoS Genetics, 2012) identified two novel loci supported by additional literature evidence: GPAM (Glycerol-3 phosphate acyltransferase) and CBS (Cystathionine beta-synthase). In addition, the workflow approach provided novel insight into the affected pathways and relevance of some of these gene-metabolite pairs in disease development and progression. We demonstrate the utility of automated exploitation of background knowledge present in pathway databases for the analysis of GWAS datasets of metabolomic phenotypes. We report novel loci and potential biochemical mechanisms that contribute to our understanding of the genetic basis of metabolic variation and its relationship to disease development and progression.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21733,""
"Bayesian network models in brain functional connectivity analysis","Ide, Zhang, Li","https://doi.org/10.1016/j.ijar.2013.03.013","20211021","PubMed","Bayesian networks; cognitive control; fMRI; functional connectivity; response inhibition","Much effort has been made to better understand the complex integration of distinct parts of the human brain using functional magnetic resonance imaging (fMRI). Altered functional connectivity between brain regions is associated with many neurological and mental illnesses, such as Alzheimer and Parkinson diseases, addiction, and depression. In computational science, Bayesian networks (BN) have been used in a broad range of studies to model complex data set in the presence of uncertainty and when expert prior knowledge is needed. However, little is done to explore the use of BN in connectivity analysis of fMRI data. In this paper, we present an up-to-date literature review and methodological details of connectivity analyses using BN, while highlighting caveats in a real-world application. We present a BN model of fMRI dataset obtained from sixty healthy subjects performing the <i>stop-signal task</i> (SST), a paradigm widely used to investigate response inhibition. Connectivity results are validated with the extant literature including our previous studies. By exploring the <i>link strength</i> of the learned BN's and correlating them to behavioral performance measures, this novel use of BN in connectivity analysis provides new insights to the functional neural pathways underlying response inhibition.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21734,""
"Robotic versus open gastrectomy for gastric cancer: a meta-analysis","Liao, Chen, Ren, Li, Du, Xie, Deng, Yang, Yuan","https://doi.org/10.1371/journal.pone.0081946","20140927","PubMed","Gastrectomy; Humans; Length of Stay; Postoperative Complications; Robotics; Stomach Neoplasms; Time Factors","To evaluate the safety and efficacy of robotic gastrectomy versus open gastrectomy for gastric cancer. A comprehensive search of PubMed, EMBASE, Cochrane Library, and Web of Knowledge was performed. Systematic review was carried out to identify studies comparing robotic gastrectomy and open gastrectomy in gastric cancer. Intraoperative and postoperative outcomes were also analyzed to evaluate the safety and efficacy of the surgery. A fixed effects model or a random effects model was utilized according to the heterogeneity. Four studies involving 5780 patients with 520 (9.00%) cases of robotic gastrectomy and 5260 (91.00%) cases of open gastrectomy were included in this meta-analysis. Compared to open gastrectomy, robotic gastrectomy has a significantly longer operation time (weighted mean differences (WMD) =92.37, 95% confidence interval (CI): 55.63 to 129.12, P&lt;0.00001), lower blood loss (WMD: -126.08, 95% CI: -189.02 to -63.13, P&lt;0.0001), and shorter hospital stay (WMD = -2.87; 95% CI: -4.17 to -1.56; P&lt;0.0001). No statistical difference was noted based on the rate of overall postoperative complication, wound infection, bleeding, number of harvested lymph nodes, anastomotic leakage and postoperative mortality rate. The results of this meta-analysis suggest that robotic gastrectomy is a better alternative technique to open gastrectomy for gastric cancer. However, more prospective, well-designed, multicenter, randomized controlled trials are necessary to further evaluate the safety and efficacy as well as the long-term outcome.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21735,""
"Exploring drug-target interaction networks of illicit drugs","Atreya, Sun, Zhao","https://doi.org/10.1186/1471-2164-14-S4-S1","20140708","PubMed","Analgesics; Central Nervous System Depressants; Central Nervous System Stimulants; Computational Biology; Databases, Pharmaceutical; Gene Ontology; Genes; Humans; Illicit Drugs; Proteins; Steroids; Substance-Related Disorders; United States","Drug addiction is a complex and chronic mental disease, which places a large burden on the American healthcare system due to its negative effects on patients and their families. Recently, network pharmacology is emerging as a promising approach to drug discovery by integrating network biology and polypharmacology, allowing for a deeper understanding of molecular mechanisms of drug actions at the systems level. This study seeks to apply this approach for investigation of illicit drugs and their targets in order to elucidate their interaction patterns and potential secondary drugs that can aid future research and clinical care. In this study, we extracted 188 illicit substances and their related information from the DrugBank database. The data process revealed 86 illicit drugs targeting a total of 73 unique human genes, which forms an illicit drug-target network. Compared to the full drug-target network from DrugBank, illicit drugs and their target genes tend to cluster together and form four subnetworks, corresponding to four major medication categories: depressants, stimulants, analgesics, and steroids. External analysis of Anatomical Therapeutic Chemical (ATC) second sublevel classifications confirmed that the illicit drugs have neurological functions or act via mechanisms of stimulants, opioids, and steroids. To further explore other drugs potentially having associations with illicit drugs, we constructed an illicit-extended drug-target network by adding the drugs that have the same target(s) as illicit drugs to the illicit drug-target network. After analyzing the degree and betweenness of the network, we identified hubs and bridge nodes, which might play important roles in the development and treatment of drug addiction. Among them, 49 non-illicit drugs might have potential to be used to treat addiction or have addictive effects, including some results that are supported by previous studies. This study presents the first systematic review of the network characteristics of illicit drugs, their targets, and other drugs that share the targets of these illicit drugs. The results, though preliminary, provide some novel insights into the molecular mechanisms of drug addiction. The observation of illicit-related drugs, with partial verification from previous studies, demonstrated that the network-assisted approach is promising for the identification of drug repositioning.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21736,""
"An efficient method for mining cross-timepoint gene regulation sequential patterns from time course gene expression datasets","Cheng, Liu, Tsai, Tseng","https://doi.org/10.1186/1471-2105-14-S12-S3","20140224","PubMed","Algorithms; Cluster Analysis; Data Mining; Gene Expression Regulation; Humans; Oligonucleotide Array Sequence Analysis","Observation of gene expression changes implying gene regulations using a repetitive experiment in time course has become more and more important. However, there is no effective method which can handle such kind of data. For instance, in a clinical/biological progression like inflammatory response or cancer formation, a great number of differentially expressed genes at different time points could be identified through a large-scale microarray approach. For each repetitive experiment with different samples, converting the microarray datasets into transactional databases with significant singleton genes at each time point would allow sequential patterns implying gene regulations to be identified. Although traditional sequential pattern mining methods have been successfully proposed and widely used in different interesting topics, like mining customer purchasing sequences from a transactional database, to our knowledge, the methods are not suitable for such biological dataset because every transaction in the converted database may contain too many items/genes. In this paper, we propose a new algorithm called CTGR-Span (Cross-Timepoint Gene Regulation Sequential pattern) to efficiently mine CTGR-SPs (Cross-Timepoint Gene Regulation Sequential Patterns) even on larger datasets where traditional algorithms are infeasible. The CTGR-Span includes several biologically designed parameters based on the characteristics of gene regulation. We perform an optimal parameter tuning process using a GO enrichment analysis to yield CTGR-SPs more meaningful biologically. The proposed method was evaluated with two publicly available human time course microarray datasets and it was shown that it outperformed the traditional methods in terms of execution efficiency. After evaluating with previous literature, the resulting patterns also strongly correlated with the experimental backgrounds of the datasets used in this study. We propose an efficient CTGR-Span to mine several biologically meaningful CTGR-SPs. We postulate that the biologist can benefit from our new algorithm since the patterns implying gene regulations could provide further insights into the mechanisms of novel gene regulations during a biological or clinical progression. The Java source code, program tutorial and other related materials used in this program are available at http://websystem.csie.ncku.edu.tw/CTGR-Span.rar.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21737,""
"Pharmacovigilance using Clinical Text","Lependu, Iyer, Bauer-Mehren, Harpaz, Ghebremariam, Cooke, Shah","https://www.google.com/search?q=Pharmacovigilance+using+Clinical+Text.","20131204","PubMed","","The current state of the art in post-marketing drug surveillance utilizes voluntarily submitted reports of suspected adverse drug reactions. We present data mining methods that transform unstructured patient notes taken by doctors, nurses and other clinicians into a de-identified, temporally ordered, patient-feature matrix using standardized medical terminologies. We demonstrate how to use the resulting high-throughput data to monitor for adverse drug events based on the clinical notes in the EHR. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21738,""
"Automated Detection of Systematic Off-label Drug Use in Free Text of Electronic Medical Records","Jung, Lependu, Shah","https://www.google.com/search?q=Automated+Detection+of+Systematic+Off-label+Drug+Use+in+Free+Text+of+Electronic+Medical+Records.","20131204","PubMed","","Off-label use of a drug occurs when it is used in a manner that deviates from its FDA label. Studies estimate that 21% of prescriptions are off-label, with only 27% of those uses supported by evidence of safety and efficacy. We have developed methods to detect population level off-label usage using computationally efficient annotation of free text from clinical notes to generate features encoding empirical information about drug-disease mentions. By including additional features encoding prior knowledge about drugs, diseases, and known usage, we trained a highly accurate predictive model that was used to detect novel candidate off-label usages in a very large clinical corpus. We show that the candidate uses are plausible and can be prioritized for further analysis in terms of safety and efficacy. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21739,""
"An information extraction framework for cohort identification using electronic health records","Liu, Bielinski, Sohn, Murphy, Wagholikar, Jonnalagadda, Ravikumar, Wu, Kullo, Chute","https://www.google.com/search?q=An+information+extraction+framework+for+cohort+identification+using+electronic+health+records.","20131204","PubMed","","Information extraction (IE), a natural language processing (NLP) task that automatically extracts structured or semi-structured information from free text, has become popular in the clinical domain for supporting automated systems at point-of-care and enabling secondary use of electronic health records (EHRs) for clinical and translational research. However, a high performance IE system can be very challenging to construct due to the complexity and dynamic nature of human language. In this paper, we report an IE framework for cohort identification using EHRs that is a knowledge-driven framework developed under the Unstructured Information Management Architecture (UIMA). A system to extract specific information can be developed by subject matter experts through expert knowledge engineering of the externalized knowledge resources used in the framework. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21740,""
"Mining and analysis of audiology data to find significant factors associated with tinnitus masker","Anwar","https://doi.org/10.1186/2193-1801-2-595","20131122","PubMed","Age; Audiogram; Gender; ITE (in the ear)/BTE (behind the ear) hearing aids; Masker; Mould; Tinnitus","The objective of this research is to find the factors associated with tinnitus masker from the literature, and by using the large amount of audiology data available from a large NHS (National Health Services, UK) hearing aid clinic. The factors evaluated were hearing impairment, age, gender, hearing aid type, mould and clinical comments. The research includes literature survey for factors associated with tinnitus masker, and performs the analysis of audiology data using statistical and data mining techniques. This research uses a large audiology data but it also faced the problem of limited data for tinnitus. It uses 1,316 records for tinnitus and other diagnoses, and 10,437 records of clinical comments from a hearing aid clinic. The research is looking for variables associated with tinnitus masker, and in future, these variables can be combined into a single model to develop a decision support system to predict about tinnitus masker for a patient. The results demonstrated that tinnitus maskers are more likely to be fit to individuals with milder forms of hearing loss, and the factors age, gender, type of hearing aid and mould were all found significantly associated with tinnitus masker. In particular, those patients having AgeÃ¢â‚¬â€°&lt;Ã¢â‚¬â€°=55 years were more likely to wear a tinnitus masker, as well as those with milder forms of hearing loss. ITE (in the ear) hearing aids were also found associated with tinnitus masker. A feedback on the results of association of mould with tinnitus masker from a professional audiologist of a large NHS (National Health Services, UK) was also taken to better understand them. The results were obtained with different accuracy for different techniques. For example, the chi-squared test results were obtained with 95% accuracy, for Support and Confidence only those results were retained which had more than 1% Support and 80% Confidence. The variables audiograms, age, gender, hearing aid type and mould were found associated with the choice of tinnitus masker in the literature and by using statistical and data mining techniques. The further work in this research would lead to the development of a decision support system for tinnitus masker with an explanation that how that decision was obtained.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21741,""
"The end of robot-assisted laparoscopy? A critical appraisal of scientific evidence on the use of robot-assisted laparoscopic surgery","Heemskerk, Bouvy, Baeten","https://doi.org/10.1007/s00464-013-3306-8","20141021","PubMed","Costs and Cost Analysis; Humans; Laparoscopy; Robotics","Robot-assisted laparoscopy has been used in a wide variety of surgical fields; however, the financial costs involved are high and convincing proof of superiority in terms of quality of life, cost effectiveness and survival is often lacking. Possibly, there might be small benefits for the patient or for the surgeon's health that might warrant the use of robotics in limited fields of surgery. We performed a critical appraisal of the literature, searching for scientific evidence supporting the use of robotics in daily laparoscopic surgery. Convincing evidence supporting the use of robotics is lacking. In an era of worldwide economic crisis, it is about time to start a critical discussion as to whether we should drastically limit, or even abandon, the use of robot-assisted laparoscopic surgery and focus on more cost-effective strategies of healthcare improvement. We suggest the use of robotics should be limited to well-powered, randomized clinical trials in a limited field of research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21742,""
"Automatic analysis of selected choroidal diseases in OCT images of the eye fundus","Koprowski, Teper, WrÃƒÂ³bel, Wylegala","https://doi.org/10.1186/1475-925X-12-117","20140630","PubMed","Adolescent; Adult; Aged; Algorithms; Automation; Child; Choroid Diseases; Fundus Oculi; Humans; Image Processing, Computer-Assisted; Middle Aged; Tomography, Optical Coherence; Young Adult","This paper describes a method for automatic analysis of the choroid in OCT images of the eye fundus in ophthalmology. The problem of vascular lesions occurs e.g. in a large population of patients having diabetes or macular degeneration. Their correct diagnosis and quantitative assessment of the treatment progress are a critical part of the eye fundus diagnosis. The study analysed about 1'000 OCT images acquired using SOCT Copernicus (Optopol Tech. SA, Zawiercie, Poland). The proposed algorithm for image analysis enabled to analyse the texture of the choroid portion located beneath the RPE (Retinal Pigment Epithelium) layer. The analysis was performed using the profiled algorithm based on morphological analysis and texture analysis and a classifier in the form of decision trees. The location of the centres of gravity of individual objects present in the image beneath the RPE layer proved to be important in the evaluation of different types of images. In addition, the value of the standard deviation and the number of objects in a scene were equally important. These features enabled classification of three different forms of the choroid that were related to retinal pathology: diabetic edema (the classification gave accuracy ACC1Ã¢â‚¬â€°=Ã¢â‚¬â€°0.73), ischemia of the inner retinal layers (ACC2Ã¢â‚¬â€°=Ã¢â‚¬â€°0.83) and scarring fibro vascular tissue (ACC3Ã¢â‚¬â€°=Ã¢â‚¬â€°0.69). For the cut decision tree the results were as follows: ACC1Ã¢â‚¬â€°=Ã¢â‚¬â€°0.76, ACC2Ã¢â‚¬â€°=Ã¢â‚¬â€°0.81, ACC3Ã¢â‚¬â€°=Ã¢â‚¬â€°0.68. The created decision tree enabled to obtain satisfactory results of the classification of three types of choroidal imaging. In addition, it was shown that for the assumed characteristics and the developed classifier, the location of B-scan does not significantly affect the results. The image analysis method for texture analysis presented in the paper confirmed its usefulness in choroid imaging. Currently the application is further studied in the Clinical Department of Ophthalmology in the District Railway Hospital in Katowice, Medical University of Silesia, Poland.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21743,""
"White matter microstructure changes induced by motor skill learning utilizing a body machine interface","Wang, Casadio, Weber, Mussa-Ivaldi, Parrish","https://doi.org/10.1016/j.neuroimage.2013.10.066","20180119","PubMed","Diffusion tensor imaging; Fractional anisotropy; Motor skill learning; White matter plasticity; Adult; Corpus Callosum; Diffusion Tensor Imaging; Female; Humans; Internal Capsule; Learning; Male; Motor Activity; Motor Skills; Neuronal Plasticity; Space Perception; Visual Perception; White Matter; Young Adult","The purpose of this study is to identify white matter microstructure changes following bilateral upper extremity motor skill training to increase our understanding of learning-induced structural plasticity and enhance clinical strategies in physical rehabilitation. Eleven healthy subjects performed two visuo-spatial motor training tasks over 9 sessions (2-3 sessions per week). Subjects controlled a cursor with bilateral simultaneous movements of the shoulders and upper arms using a body machine interface. Before the start and within 2days of the completion of training, whole brain diffusion tensor MR imaging data were acquired. Motor training increased fractional anisotropy (FA) values in the posterior and anterior limbs of the internal capsule, the corona radiata, and the body of the corpus callosum by 4.19% on average indicating white matter microstructure changes induced by activity-dependent modulation of axon number, axon diameter, or myelin thickness. These changes may underlie the functional reorganization associated with motor skill learning.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21744,""
"Vitamin B12: one carbon metabolism, fetal growth and programming for chronic disease","Rush, Katre, Yajnik","https://doi.org/10.1038/ejcn.2013.232","20140821","PubMed","Animals; Biomarkers; Chronic Disease; DNA Methylation; Diet, Vegetarian; Female; Fetal Development; Humans; Insulin Resistance; Lipogenesis; Maternal Nutritional Physiological Phenomena; Metabolic Networks and Pathways; Pregnancy; Vitamin B 12; Vitamin B 12 Deficiency","This review brings together human and animal studies and reviews that examine the possible role of maternal vitamin B12 (B12) on fetal growth and its programming for susceptibility to chronic disease. A selective literature review was undertaken to identify studies and reviews that investigate these issues, particularly in the context of a vegetarian diet that may be low in B12 and protein and high in carbohydrate. Evidence is accumulating that maternal B12 status influences fetal growth and development. Low maternal vitamin B12 status and protein intake are associated with increased risk of neural tube defect, low lean mass and excess adiposity, increased insulin resistance, impaired neurodevelopment and altered risk of cancer in the offspring. Vitamin B12 is a key nutrient associated with one carbon metabolic pathways related to substrate metabolism, synthesis and stability of nucleic acids and methylation of DNA which regulates gene expression. Understanding of factors regulating maternal-fetal one carbon metabolism and its role in fetal programming of non communicable diseases could help design effective interventions, starting with maternal nutrition before conception. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21745,""
"Attaining surgical competency and its implications in surgical clinical trial design: a systematic review of the learning curve in laparoscopic and robot-assisted laparoscopic colorectal cancer surgery","Barrie, Jayne, Wright, Murray, Collinson, Pavitt","https://doi.org/10.1245/s10434-013-3348-0","20141113","PubMed","Clinical Competence; Clinical Trials as Topic; Colorectal Neoplasms; Colorectal Surgery; Humans; Laparoscopy; Prognosis; Research Design; Robotics","Laparoscopic surgery is increasingly used in the treatment of colorectal cancer and more recently robotic assistance has been advocated. However, the learning curve to achieve surgical proficiency in laparoscopic surgery is ill-defined and subject to many influences. The aim of this review was to comprehensively appraise the literature on the learning curve for laparoscopic and robotic colorectal cancer surgery, and to quantify attainment of surgical proficiency and its implications in surgical clinical trial design. A systematic review using a defined search strategy was performed. Included studies had to state an explicit numerical value of the learning curve evaluated by a single parameter or multiple parameters. Thirty-four studies were included, 28 laparoscopic and 6 robot assisted. Of the laparoscopic studies, nine defined the learning curve on the basis of a single parameter. Nine studies used more than one parameter to define learning, and 11 used a cumulative sum (CUSUM) analysis. One study used both a multiparameter and CUSUM analysis. The definition of proficiency was subjective, and the number of operations to achieve it ranged from 5 to 310 cases for laparoscopic and 15-30 cases for robotic surgery. The learning curve in laparoscopic colorectal surgery is multifaceted and often ill-defined, with poor descriptions of mentorship/supervision. Further, the quantification to attain proficiency is variable. The use of a single parameter to quantify this is simplistic. Multidimensional assessment is recommended; as part of this, the CUSUM model, which assesses trends in multiple surgical outcomes, is useful and appropriate when assessing the learning curve in a clinical setting.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21746,""
"A review of approaches to identifying patient phenotype cohorts using electronic health records","Shivade, Raghavan, Fosler-Lussier, Embi, Elhadad, Johnson, Lai","https://doi.org/10.1136/amiajnl-2013-001935","20140529","PubMed","Cohort Identification; Electronic Health Records; Phenotyping; Review; Artificial Intelligence; Data Mining; Diagnosis; Electronic Health Records; Humans; Natural Language Processing; Phenotype; Statistics as Topic; Vocabulary, Controlled","To summarize literature describing approaches aimed at automatically identifying patients with a common phenotype. We performed a review of studies describing systems or reporting techniques developed for identifying cohorts of patients with specific phenotypes. Every full text article published in (1) Journal of American Medical Informatics Association, (2) Journal of Biomedical Informatics, (3) Proceedings of the Annual American Medical Informatics Association Symposium, and (4) Proceedings of Clinical Research Informatics Conference within the past 3 years was assessed for inclusion in the review. Only articles using automated techniques were included. Ninety-seven articles met our inclusion criteria. Forty-six used natural language processing (NLP)-based techniques, 24 described rule-based systems, 41 used statistical analyses, data mining, or machine learning techniques, while 22 described hybrid systems. Nine articles described the architecture of large-scale systems developed for determining cohort eligibility of patients. We observe that there is a rise in the number of studies associated with cohort identification using electronic medical records. Statistical analyses or machine learning, followed by NLP techniques, are gaining popularity over the years in comparison with rule-based systems. There are a variety of approaches for classifying patients into a particular phenotype. Different techniques and data sources are used, and good performance is reported on datasets at respective institutions. However, no system makes comprehensive use of electronic medical records addressing all of their known weaknesses.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21747,""
"Feasibility and effectiveness of an automated bilingual text message intervention for weight loss: pilot study","Kolodziejczyk, Norman, Barrera-Ng, Dillon, Marshall, Arredondo, Rock, Raab, Griswold, Sullivan, Patrick","https://doi.org/10.2196/resprot.2789","20131108","PubMed","Hispanic Americans; cellular phone; diet; health behavior; obesity; physical activity; text messaging; weight loss","Little is known about the feasibility and acceptability of tailored text message based weight loss programs for English and Spanish-language speakers. This pilot study evaluated the feasibility, acceptability, and estimated impact of a tailored text message based weight loss program for English and Spanish-language speakers. The purpose of this pilot study was to inform the development of a full-scale randomized trial. There were 20 overweight or obese participants (mean age 40.10, SD 8.05; 8/20, 40% male; 9/20, 45% Spanish-speakers) that were recruited in San Diego, California, from March to May 2011 and evaluated in a one-group pre/post clinical trial. For 8 weeks, participants received and responded to 3-5 text messages daily sent from a fully automated text messaging system. They also received printed weight loss materials and brief 10-15 minute weekly counseling calls. To estimate the impact of the program, the primary outcome was weight (kg) measured during face-to-face measurement visits by trained research staff. Pre and post differences in weight were analyzed with a one-way repeated measures analysis of variance. Differences by language preference at both time points were analyzed with t tests. Body mass index and weight management behaviors also were examined. Feasibility and acceptability were determined by recruitment success, adherence (ie, percentage of replies to interactive text messages and attrition), and participant satisfaction. Participants who completed the final assessment (N=18) decreased body weight by 1.85 kg (F1,17=10.80, P=.004, CIÃ¢Ë†â€  0.66-3.03, ÃŽÂ·(2)=0.39). At both time points, there were no differences in weight by language preference. Participants responded to 88.04% (986/1120) of interactive text messages, attrition rate was 10% (2/20), and 94% (19/20) of participants reported satisfaction with the program. This fully automated text message based weight program was feasible with English and Spanish-speakers and may have promoted modest weight loss over an 8-week period. Clinicaltrials.gov NCT01171586; http://clinicaltrials.gov/ct2/show/NCT01171586 (Archived by WebCite at http://www.webcitation.org/6Ksr6dl7n).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21748,""
"Current status of robotic bariatric surgery: a systematic review","Cirocchi, Boselli, Santoro, Guarino, Covarelli, Renzi, Listorti, Trastulli, Desiderio, Coratti, Noya, Redler, Parisi","https://doi.org/10.1186/1471-2482-13-53","20140421","PubMed","Bariatric Surgery; Humans; Laparoscopy; Length of Stay; Obesity, Morbid; Postoperative Complications; Robotics; Treatment Outcome","Bariatric surgery is an effective treatment to obtain weight loss in severely obese patients. The feasibility and safety of bariatric robotic surgery is the topic of this review. A search was performed on PubMed, Cochrane Central Register of Controlled Trials, BioMed Central, and Web of Science. Twenty-two studies were included. Anastomotic leak rate was 8.51% in biliopancreatic diversion. 30-day reoperation rate was 1.14% in Roux-en-Y gastric bypass and 1.16% in sleeve gastrectomy. Major complication rate in Roux-en-Y gastric bypass resulted higher than in sleeve gastrectomy ( 4,26% vs. 1,2%). The mean hospital stay was longer in Roux-en-Y gastric bypass (range 2.6-7.4 days). The major limitation of our analysis is due to the small number and the low quality of the studies, the small sample size, heterogeneity of the enrolled patients and the lack of data from metabolic and bariatric outcomes. Despite the use of the robot, the majority of these cases are completed with stapled anastomosis. The assumption that robotic surgery is superior in complex cases is not supported by the available present evidence. The major strength of the robotic surgery is strongly facilitating some of the surgical steps (gastro-jejunostomy and jejunojejunostomy anastomosis in the robotic Roux-en-Y gastric bypass or the vertical gastric resection in the robotic sleeve gastrectomy).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21749,""
"Electronic tools for health information exchange: an evidence-based analysis","","https://www.google.com/search?q=Electronic+tools+for+health+information+exchange:+an+evidence-based+analysis.","20140619","PubMed","Ambulatory Care; Chronic Disease; Emergency Service, Hospital; Evidence-Based Practice; Health Information Systems; Health Services; Hospitalization; Humans; Information Dissemination; Length of Stay; Medical Records Systems, Computerized; Quality of Health Care","As patients experience transitions in care, there is a need to share information between care providers in an accurate and timely manner. With the push towards electronic medical records and other electronic tools (eTools) (and away from paper-based health records) for health information exchange, there remains uncertainty around the impact of eTools as a form of communication. To examine the impact of eTools for health information exchange in the context of care coordination for individuals with chronic disease in the community. A literature search was performed on April 26, 2012, using OVID MEDLINE, OVID MEDLINE In-Process and Other Non-Indexed Citations, OVID EMBASE, EBSCO Cumulative Index to Nursing &amp; Allied Health Literature (CINAHL), the Wiley Cochrane Library, and the Centre for Reviews and Dissemination database, for studies published until April 26, 2012 (no start date limit was applied). A systematic literature search was conducted, and meta-analysis conducted where appropriate. Outcomes of interest fell into 4 categories: health services utilization, disease-specific clinical outcomes, process-of-care indicators, and measures of efficiency. The quality of the evidence was assessed individually for each outcome. Expert panels were assembled for stakeholder engagement and contextualization. Eleven articles were identified (4 randomized controlled trials and 7 observational studies). There was moderate quality evidence of a reduction in hospitalizations, hospital length of stay, and emergency department visits following the implementation of an electronically generated laboratory report with recommendations based on clinical guidelines. The evidence showed no difference in disease-specific outcomes; there was no evidence of a positive impact on process-of-care indicators or measures of efficiency. A limited body of research specifically examined eTools for health information exchange in the population and setting of interest. This evidence included a combination of study designs and was further limited by heterogeneity in individual technologies and settings in which they were implemented. There is evidence that the right eTools in the right environment and context can significantly impact health services utilization. However, the findings from this evidence-based analysis raise doubts about the ability of eTools with care-coordination capabilities to independently improve the quality of outpatient care. While eTools may be able to support and sustain processes, inefficiencies embedded in the health care system may require more than automation alone to resolve. Patients with chronic diseases often work with many different health care providers. To ensure smooth transitions from one setting to the next, health care providers must share information and coordinate care effectively. Electronic medical records (eTools) are being used more and more to coordinate patient care, but it is not yet known whether they are more effective than paper-based health records. In this analysis, we reviewed the evidence for the use of eTools to exchange information and coordinate care for people with chronic diseases in the community. There was some evidence that eTools reduced the number of hospital and emergency department visits, as well as patients' length of stay in the hospital, but there was no evidence that eTools improved the overall quality of patient care.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21750,""
"Normalization and standardization of electronic health records for high-throughput phenotyping: the SHARPn consortium","Pathak, Bailey, Beebe, Bethard, Carrell, Chen, Dligach, Endle, Hart, Haug, Huff, Kaggal, Li, Liu, Marchant, Masanz, Miller, Oniki, Palmer, Peterson, Rea, Savova, Stancl, Sohn, Solbrig, Suesse, Tao, Taylor, Westberg, Wu, Zhuo, Chute","https://doi.org/10.1136/amiajnl-2013-001939","20140124","PubMed","Electronic health record; Meaningful Use; Natural Language Processing; Normalization; Phenotype Extraction; Algorithms; Biomedical Research; Computer Security; Data Mining; Electronic Health Records; Humans; Medical Informatics Applications; Natural Language Processing; Phenotype; Software; Vocabulary, Controlled","To develop scalable informatics infrastructure for normalization of both structured and unstructured electronic health record (EHR) data into a unified, concept-based model for high-throughput phenotype extraction. Software tools and applications were developed to extract information from EHRs. Representative and convenience samples of both structured and unstructured data from two EHR systems-Mayo Clinic and Intermountain Healthcare-were used for development and validation. Extracted information was standardized and normalized to meaningful use (MU) conformant terminology and value set standards using Clinical Element Models (CEMs). These resources were used to demonstrate semi-automatic execution of MU clinical-quality measures modeled using the Quality Data Model (QDM) and an open-source rules engine. Using CEMs and open-source natural language processing and terminology services engines-namely, Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) and Common Terminology Services (CTS2)-we developed a data-normalization platform that ensures data security, end-to-end connectivity, and reliable data flow within and across institutions. We demonstrated the applicability of this platform by executing a QDM-based MU quality measure that determines the percentage of patients between 18 and 75 years with diabetes whose most recent low-density lipoprotein cholesterol test result during the measurement year was &lt;100 mg/dL on a randomly selected cohort of 273 Mayo Clinic patients. The platform identified 21 and 18 patients for the denominator and numerator of the quality measure, respectively. Validation results indicate that all identified patients meet the QDM-based criteria. End-to-end automated systems for extracting clinical information from diverse EHR systems require extensive use of standardized vocabularies and terminologies, as well as robust information models for storing, discovering, and processing that information. This study demonstrates the application of modular and open-source resources for enabling secondary use of EHR data through normalization into standards-based, comparable, and consistent format for high-throughput phenotyping to identify patient cohorts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21751,""
"The biology of Nociceptin/Orphanin FQ (N/OFQ) related to obesity, stress, anxiety, mood, and drug dependence","Witkin, Statnick, Rorick-Kehn, Pintar, Ansonoff, Chen, Tucker, Ciccocioppo","https://doi.org/10.1016/j.pharmthera.2013.10.011","20140915","PubMed","(1S,3aS)-8- (2,3,3a,4,5,6-hexahydro-1H-phenalen-1-yl)-1-phenyl-1,3,8-triaza-spiro[4.5]decan-4-one, a NOP receptor agonist; (Ã‚Â±)trans-1-[1-cyclooctylmethyl-3-hydroxymethyl-4-piperidyl]-3-ethyl-1,3-dihydro-2H-benzimidazol-2-one, a NOP receptor antagonist; 2-{3-[1-((1R)-acenaphthen-1-yl)piperidin-4-yl]-2,3-dihydro-2-oxo-benzimidazol-1-yl}-N-methylacetamide, a NOP receptor agonist; 5-HT; 5-hydroxytryptamine or serotonin; 8-[bis(2-methylphenyl)-methyl]-3-phenyl-8-azabicyclo[3.2.1]octan-3-ol; ACTH; Alcohol-preferring rats; Anxiety; BED; BNST; CGRP; CPP; CRF; CTA; Calcitonin gene related peptide; CeA; DA; Depression; Drug dependence; EPSC; FST; G-protein activated, inwardly rectifying K(+) channel; G-protein-coupled receptor; GIRK; GPCR; HPA; J-113397; JTC-801; KO; MDD; Marchigian Sardinian Alcohol-Preferring; N-(4-amino-2-methylquinolin-6-yl)-2-(4-ethylphenoxymethyl)benzamide hydrochloride, a NOP receptor antagonist; N/OFQ; NAcc; NE; NOP; NPY; Nociceptin opioid peptide or Nociceptin opioid peptide receptor; Nociceptin/Orphanin FQ; Nociceptin/Orphanin FQ (F: phenylalanine, Q: glutamine, the amino acids that begin and end the peptide sequence); ORL; Obesity; P rats; POMC; Pro-opiomelanocortin; Ro 64-6198; SB-612111; SCH 221510; SCH 655842; Stress; TST; UFP-101; VTA; W212393; [(Ã¢â‚¬â€œ)-cis-1-methyl-7-[[4-(2,6-dichlorophenyl)piperidin-1-yl]methyl]-6,7,8,9-tetrahydro-5H-benzocyclohepten-5-ol, a NOP receptor antagonist; [Nphe(1),Arg(14),Lys(15)]N/OFQ-NH(2), a NOP receptor antagonist; adrenocorticotropic hormone; bed nucleus of stria terminalis; binge eating disorder; central nucleus of the amygdala; conditioned place preference; conditioned taste aversion; corticotrophin-releasing factor; dopamine; endo-8-[bis(2-chlorophenyl)methyl]-3-phenyl-8-azabicyclo[3.2.1]octane-3-carboxamide, a NOP receptor agonist; excitatory post-synaptic current; forced-swim test; hypothalamicÃ¢â‚¬â€œpituitary axis; knockout; mPFC; major depressive disorder; medial prefrontal cortex; msP; neuropeptide Y; norepinephrine; nucleus accumbens; opioid-receptor-like; tail-suspension test; ventral tegmental area; Animals; Anxiety; Drug Design; Humans; Mice; Mood Disorders; Narcotic Antagonists; Obesity; Opioid Peptides; Rats; Receptors, Opioid; Stress, Psychological; Substance-Related Disorders","Nociceptin/Orphanin FQ (N/OFQ) is a 17 amino acid peptide that was deorphanized in 1995. The generation of specific agonists, antagonists and receptor deficient mice and rats has enabled progress in elucidating the biological functions of N/OFQ. Additionally, radio-imaging technologies have been advanced for investigation of this system in animals and humans. Together with traditional neurobehavioral techniques, these tools have been utilized to identify the biological significance of the N/OFQ system and its interacting partners. The present review focuses on the role of N/OFQ in the regulation of feeding, body weight homeostasis, stress, the stress-related psychiatric disorders of depression and anxiety, and in drug and alcohol dependence. Critical evaluation of the current scientific preclinical literature suggests that small molecule modulators of nociceptin opioid peptide receptors (NOP) might be useful in the treatment of diseases related to these biological functions. In particular, the literature data suggest that antagonism of NOP receptors will produce anti-obesity and antidepressant activities in humans. However, there are also contradictory data discussed. The current literature on the role of N/OFQ in anxiety and addiction, on the other hand points primarily to a role of agonist modulation being potentially therapeutic. Some drug-like molecules that function either as agonists or antagonists of NOP receptors have been optimized for human clinical study to test some of these hypotheses. The discovery of PET ligands for NOP receptors, combined with the pharmacological tools and burgeoning preclinical data set discussed here bodes well for a rapid advancement of clinical understanding and potential therapeutic benefit. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21752,""
"Use of data from multiple registries in studying biologic discontinuation: challenges and opportunities","Yoshida, Radner, Kavanaugh, Sung, Bae, Kishimoto, Matsui, Okada, Tohma, Weinblatt, Solomon","https://www.google.com/search?q=Use+of+data+from+multiple+registries+in+studying+biologic+discontinuation:+challenges+and+opportunities.","20131203","PubMed","Antirheumatic Agents; Arthritis, Rheumatoid; Biological Products; Data Mining; Drug Administration Schedule; Drug Therapy, Combination; Evidence-Based Medicine; Humans; Recurrence; Registries; Remission Induction; Severity of Illness Index; Time Factors; Treatment Outcome","Many studies have been conducted concerning discontinuation of biologic disease-modifying anti-rheumatic drugs (DMARD), but mainly in trial settings which result in limited generalisability. Registry studies can complement the current literature of biologic DMARD discontinuation by providing more generalisable information. However, it may be necessary to combine registries to increase power and provide more diverse patient populations. This increased power could provide us information about risk and benefits of discontinuing biologic DMARD in typical clinical practice. However, use of multiple registries is not without challenges. In this review, we discuss the challenges to combining data across multiple registries, focusing on biologic discontinuation as an example. Challenges include: 1) generalizability of each registry; 2) new versus prevalent users designs; 3) outcome definitions; 4) different health care systems; 5) different follow up intervals; and 6) data harmonisation. The first three apply to each registry, and the last three apply to combining multiple registries. This review describes these challenges, corresponding solutions, and potential future opportunities. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21753,""
"Automatic signal extraction, prioritizing and filtering approaches in detecting post-marketing cardiovascular events associated with targeted cancer drugs from the FDA Adverse Event Reporting System (FAERS)","Xu, Wang","https://doi.org/10.1016/j.jbi.2013.10.008","20141104","PubMed","Cardiotoxicity; Data mining; Personalized medicine; Post-market drug safety surveillance; Targeted cancer therapy; Adverse Drug Reaction Reporting Systems; Algorithms; Antineoplastic Agents; Cardiovascular Diseases; Data Mining; Databases, Factual; Drug-Related Side Effects and Adverse Reactions; Electronic Data Processing; Humans; Neoplasms; United States; United States Food and Drug Administration","Targeted drugs dramatically improve the treatment outcomes in cancer patients; however, these innovative drugs are often associated with unexpectedly high cardiovascular toxicity. Currently, cardiovascular safety represents both a challenging issue for drug developers, regulators, researchers, and clinicians and a concern for patients. While FDA drug labels have captured many of these events, spontaneous reporting systems are a main source for post-marketing drug safety surveillance in 'real-world' (outside of clinical trials) cancer patients. In this study, we present approaches to extracting, prioritizing, filtering, and confirming cardiovascular events associated with targeted cancer drugs from the FDA Adverse Event Reporting System (FAERS). The dataset includes records of 4,285,097 patients from FAERS. We first extracted drug-cardiovascular event (drug-CV) pairs from FAERS through named entity recognition and mapping processes. We then compared six ranking algorithms in prioritizing true positive signals among extracted pairs using known drug-CV pairs derived from FDA drug labels. We also developed three filtering algorithms to further improve precision. Finally, we manually validated extracted drug-CV pairs using 21 million published MEDLINE records. We extracted a total of 11,173 drug-CV pairs from FAERS. We showed that ranking by frequency is significantly more effective than by the five standard signal detection methods (246% improvement in precision for top-ranked pairs). The filtering algorithm we developed further improved overall precision by 91.3%. By manual curation using literature evidence, we show that about 51.9% of the 617 drug-CV pairs that appeared in both FAERS and MEDLINE sentences are true positives. In addition, 80.6% of these positive pairs have not been captured by FDA drug labeling. The unique drug-CV association dataset that we created based on FAERS could facilitate our understanding and prediction of cardiotoxic events associated with targeted cancer drugs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21754,""
"Skin parameter map retrieval from a dedicated multispectral imaging system applied to dermatology/cosmetology","Jolivot, Benezeth, Marzani","https://doi.org/10.1155/2013/978289","20131025","PubMed","","In vivo quantitative assessment of skin lesions is an important step in the evaluation of skin condition. An objective measurement device can help as a valuable tool for skin analysis. We propose an explorative new multispectral camera specifically developed for dermatology/cosmetology applications. The multispectral imaging system provides images of skin reflectance at different wavebands covering visible and near-infrared domain. It is coupled with a neural network-based algorithm for the reconstruction of reflectance cube of cutaneous data. This cube contains only skin optical reflectance spectrum in each pixel of the bidimensional spatial information. The reflectance cube is analyzed by an algorithm based on a Kubelka-Munk model combined with evolutionary algorithm. The technique allows quantitative measure of cutaneous tissue and retrieves five skin parameter maps: melanin concentration, epidermis/dermis thickness, haemoglobin concentration, and the oxygenated hemoglobin. The results retrieved on healthy participants by the algorithm are in good accordance with the data from the literature. The usefulness of the developed technique was proved during two experiments: a clinical study based on vitiligo and melasma skin lesions and a skin oxygenation experiment (induced ischemia) with healthy participant where normal tissues are recorded at normal state and when temporary ischemia is induced. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21755,""
"Mining clinical text for signals of adverse drug-drug interactions","Iyer, Harpaz, LePendu, Bauer-Mehren, Shah","https://doi.org/10.1136/amiajnl-2013-001612","20140529","PubMed","Adverse Reactions; Data Mining; Drug Interaction; Electronic Health Records; Ontology; Pharmacovigilance; Data Mining; Drug Interactions; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Humans","Electronic health records (EHRs) are increasingly being used to complement the FDA Adverse Event Reporting System (FAERS) and to enable active pharmacovigilance. Over 30% of all adverse drug reactions are caused by drug-drug interactions (DDIs) and result in significant morbidity every year, making their early identification vital. We present an approach for identifying DDI signals directly from the textual portion of EHRs. We recognize mentions of drug and event concepts from over 50 million clinical notes from two sites to create a timeline of concept mentions for each patient. We then use adjusted disproportionality ratios to identify significant drug-drug-event associations among 1165 drugs and 14 adverse events. To validate our results, we evaluate our performance on a gold standard of 1698 DDIs curated from existing knowledge bases, as well as with signaling DDI associations directly from FAERS using established methods. Our method achieves good performance, as measured by our gold standard (area under the receiver operator characteristic (ROC) curve &gt;80%), on two independent EHR datasets and the performance is comparable to that of signaling DDIs from FAERS. We demonstrate the utility of our method for early detection of DDIs and for identifying alternatives for risky drug combinations. Finally, we publish a first of its kind database of population event rates among patients on drug combinations based on an EHR corpus. It is feasible to identify DDI signals and estimate the rate of adverse events among patients on drug combinations, directly from clinical text; this could have utility in prioritizing drug interaction surveillance as well as in clinical decision support.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21756,""
"Learning to recognize phenotype candidates in the auto-immune literature using SVM re-ranking","Collier, Tran, Le, Ha, Oellrich, Rebholz-Schuhmann","https://doi.org/10.1371/journal.pone.0072965","20140617","PubMed","Animals; Artificial Intelligence; Autoimmune Diseases; Data Mining; Entropy; Humans; Male; Mice; Models, Theoretical; Phenotype; Semantics; Support Vector Machine; Vocabulary, Controlled","The identification of phenotype descriptions in the scientific literature, case reports and patient records is a rewarding task for bio-medical text mining. Any progress will support knowledge discovery and linkage to other resources. However because of their wide variation a number of challenges still remain in terms of their identification and semantic normalisation before they can be fully exploited for research purposes. This paper presents novel techniques for identifying potential complex phenotype mentions by exploiting a hybrid model based on machine learning, rules and dictionary matching. A systematic study is made of how to combine sequence labels from these modules as well as the merits of various ontological resources. We evaluated our approach on a subset of Medline abstracts cited by the Online Mendelian Inheritance of Man database related to auto-immune diseases. Using partial matching the best micro-averaged F-score for phenotypes and five other entity classes was 79.9%. A best performance of 75.3% was achieved for phenotype candidates using all semantics resources. We observed the advantage of using SVM-based learn-to-rank for sequence label combination over maximum entropy and a priority list approach. The results indicate that the identification of simple entity types such as chemicals and genes are robustly supported by single semantic resources, whereas phenotypes require combinations. Altogether we conclude that our approach coped well with the compositional structure of phenotypes in the auto-immune domain. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21757,""
"Automated extraction of clinical traits of multiple sclerosis in electronic medical records","Davis, Sriram, Bush, Denny, Haines","https://doi.org/10.1136/amiajnl-2013-001999","20140124","PubMed","Multiple sclerosis; electronic health records; Adolescent; Adult; Aged; Aged, 80 and over; Algorithms; Child; Data Mining; Disease Progression; Electronic Health Records; Female; Humans; Male; Middle Aged; Multiple Sclerosis; Natural Language Processing","The clinical course of multiple sclerosis (MS) is highly variable, and research data collection is costly and time consuming. We evaluated natural language processing techniques applied to electronic medical records (EMR) to identify MS patients and the key clinical traits of their disease course. We used four algorithms based on ICD-9 codes, text keywords, and medications to identify individuals with MS from a de-identified, research version of the EMR at Vanderbilt University. Using a training dataset of the records of 899 individuals, algorithms were constructed to identify and extract detailed information regarding the clinical course of MS from the text of the medical records, including clinical subtype, presence of oligoclonal bands, year of diagnosis, year and origin of first symptom, Expanded Disability Status Scale (EDSS) scores, timed 25-foot walk scores, and MS medications. Algorithms were evaluated on a test set validated by two independent reviewers. We identified 5789 individuals with MS. For all clinical traits extracted, precision was at least 87% and specificity was greater than 80%. Recall values for clinical subtype, EDSS scores, and timed 25-foot walk scores were greater than 80%. This collection of clinical data represents one of the largest databases of detailed, clinical traits available for research on MS. This work demonstrates that detailed clinical information is recorded in the EMR and can be extracted for research purposes with high reliability.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21758,""
"An automated algorithm for online detection of fragmented QRS and identification of its various morphologies","Maheshwari, Acharyya, Puddu, Mazomenos, Leekha, Maharatna, Schiariti","https://doi.org/10.1098/rsif.2013.0761","20140508","PubMed","electrocardiography; fragmented QRS; wavelet transform; Algorithms; Biomarkers; Biomedical Engineering; Cardiovascular Diseases; Electrocardiography; Humans; Sensitivity and Specificity; Signal Processing, Computer-Assisted; Wavelet Analysis","Fragmented QRS (f-QRS) has been proven to be an efficient biomarker for several diseases, including remote and acute myocardial infarction, cardiac sarcoidosis, non-ischaemic cardiomyopathy, etc. It has also been shown to have higher sensitivity and/or specificity values than the conventional markers (e.g. Q-wave, ST-elevation, etc.) which may even regress or disappear with time. Patients with such diseases have to undergo expensive and sometimes invasive tests for diagnosis. Automated detection of f-QRS followed by identification of its various morphologies in addition to the conventional ECG feature (e.g. P, QRS, T amplitude and duration, etc.) extraction will lead to a more reliable diagnosis, therapy and disease prognosis than the state-of-the-art approaches and thereby will be of significant clinical importance for both hospital-based and emerging remote health monitoring environments as well as for implanted ICD devices. An automated algorithm for detection of f-QRS from the ECG and identification of its various morphologies is proposed in this work which, to the best of our knowledge, is the first work of its kind. Using our recently proposed time-domain morphology and gradient-based ECG feature extraction algorithm, the QRS complex is extracted and discrete wavelet transform (DWT) with one level of decomposition, using the 'Haar' wavelet, is applied on it to detect the presence of fragmentation. Detailed DWT coefficients were observed to hypothesize the postulates of detection of all types of morphologies as reported in the literature. To model and verify the algorithm, PhysioNet's PTB database was used. Forty patients were randomly selected from the database and their ECG were examined by two experienced cardiologists and the results were compared with those obtained from the algorithm. Out of 40 patients, 31 were considered appropriate for comparison by two cardiologists, and it is shown that 334 out of 372 (89.8%) leads from the chosen 31 patients complied favourably with our proposed algorithm. The sensitivity and specificity values obtained for the detection of f-QRS were 0.897 and 0.899, respectively. Automation will speed up the detection of fragmentation, reducing the human error involved and will allow it to be implemented for hospital-based remote monitoring and ICD devices. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21759,""
"Automated chart review for asthma cohort identification using natural language processing: an exploratory study","Wu, Sohn, Ravikumar, Wagholikar, Jonnalagadda, Liu, Juhn","https://doi.org/10.1016/j.anai.2013.07.022","20131211","PubMed","Asthma; Child, Preschool; Cohort Studies; Electronic Data Processing; Female; Humans; Male; Medical Records Systems, Computerized; Natural Language Processing","A significant proportion of children with asthma have delayed diagnosis of asthma by health care providers. Manual chart review according to established criteria is more accurate than directly using diagnosis codes, which tend to under-identify asthmatics, but chart reviews are more costly and less timely. To evaluate the accuracy of a computational approach to asthma ascertainment, characterizing its utility and feasibility toward large-scale deployment in electronic medical records. A natural language processing (NLP) system was developed for extracting predetermined criteria for asthma from unstructured text in electronic medical records and then inferring asthma status based on these criteria. Using manual chart reviews as a gold standard, asthma status (yes vs no) and identification date (first date of a ""yes"" asthma status) were determined by the NLP system. Patients were a group of children (n = 112, 84% Caucasian, 49% girls) younger than 4 years (mean 2.0 years, standard deviation 1.03 years) who participated in previous studies. The NLP approach to asthma ascertainment showed sensitivity, specificity, positive predictive value, negative predictive value, and median delay in diagnosis of 84.6%, 96.5%, 88.0%, 95.4%, and 0 months, respectively; this compared favorably with diagnosis codes, at 30.8%, 93.2%, 57.1%, 82.2%, and 2.3 months, respectively. Automated asthma ascertainment from electronic medical records using NLP is feasible and more accurate than traditional approaches such as diagnosis codes. Considering the difficulty of labor-intensive manual record review, NLP approaches for asthma ascertainment should be considered for improving clinical care and research, especially in large-scale efforts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21760,""
"Computer-aided assessment of regional abdominal fat with food residue removal in CT","Makrogiannis, Caturegli, Davatzikos, Ferrucci","https://doi.org/10.1016/j.acra.2013.08.007","20140605","PubMed","Body composition assessment; false positive reduction; Abdominal Fat; Algorithms; Body Composition; Food; Humans; Longitudinal Studies; Phantoms, Imaging; Radiographic Image Interpretation, Computer-Assisted; Radiography, Abdominal; Subtraction Technique; Support Vector Machine; Tomography, X-Ray Computed","Separate quantification of abdominal subcutaneous and visceral fat regions is essential to understand the role of regional adiposity as risk factor in epidemiological studies. Fat quantification is often based on computed tomography (CT) because fat density is distinct from other tissue densities in the abdomen. However, the presence of intestinal food residues with densities similar to fat may reduce fat quantification accuracy. We introduce an abdominal fat quantification method in CT with interest in food residue removal. Total fat was identified in the feature space of Hounsfield units and divided into subcutaneous and visceral components using model-based segmentation. Regions of food residues were identified and removed from visceral fat using a machine learning method integrating intensity, texture, and spatial information. Cost-weighting and bagging techniques were investigated to address class imbalance. We validated our automated food residue removal technique against semimanual quantifications. Our feature selection experiments indicated that joint intensity and texture features produce the highest classification accuracy at 95%. We explored generalization capability using k-fold cross-validation and receiver operating characteristic (ROC) analysis with variable k. Losses in accuracy and area under ROC curve between maximum and minimum k were limited to 0.1% and 0.3%. We validated tissue segmentation against reference semimanual delineations. The Dice similarity scores were as high as 93.1 for subcutaneous fat and 85.6 for visceral fat. Computer-aided regional abdominal fat quantification is a reliable computational tool for large-scale epidemiological studies. Our proposed intestinal food residue reduction scheme is an original contribution of this work. Validation experiments indicate very good accuracy and generalization capability.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21761,""
"Robotic partial nephrectomy for renal tumors larger than 4 cm: a systematic review and meta-analysis","Bi, Zhang, Li, Fan, Xu, Han, Huang, Liu, Dong, Yang, Huang, Lin","https://doi.org/10.1371/journal.pone.0075050","20140609","PubMed","Humans; Kidney Neoplasms; Nephrectomy; Robotics; Surgery, Computer-Assisted; Treatment Outcome","With the establishment of minimally invasive surgery in society, the robot has been increasingly widely used in the urologic field, including in partial nephrectomy. This study aimed to comprehensively summarize the currently available evidence on the feasibility and safety of robotic partial nephrectomy for renal tumors of &gt;4 cm. An electronic database search of PubMed, Scopus, Web of Science, and the Cochrane Library was performed. This systematic review and meta-analysis was based on all relevant studies that assessed robotic partial nephrectomy for renal tumors of &gt;4 cm. Five studies were included. The meta-analysis involved 3 studies from 11 institutions including 154 patients, while the narrative review involved the remaining 2 studies from 5 institutions including 64 patients. In the meta-analysis, the mean ischemic time, operation time, and console time was 28, 319, and 189 minutes, respectively. The estimated blood loss and length of stay was 317 ml and 3.8 days, respectively. The rates of conversion, positive margins, intraoperative complications, postoperative complications, hilar clamping, and collecting system repair were 7.0%, 3.5%, 7.0%, 9.8%, 93.9%, and 47.5%, respectively. The narrative review showed results similar to those of the meta-analysis. Robotic partial nephrectomy is feasible and safe for renal tumors of &gt;4 cm with an acceptable warm ischemic time, positive margin rate, conversion rate, complication rate, operation time, estimated blood loss, and length of stay.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21762,""
"FlexiTerm: a flexible term recognition method","SpasiÃ„â€¡, Greenwood, Preece, Francis, Elwyn","https://doi.org/10.1186/2041-1480-4-27","20131115","PubMed","","The increasing amount of textual information in biomedicine requires effective term recognition methods to identify textual representations of domain-specific concepts as the first step toward automating its semantic interpretation. The dictionary look-up approaches may not always be suitable for dynamic domains such as biomedicine or the newly emerging types of media such as patient blogs, the main obstacles being the use of non-standardised terminology and high degree of term variation. In this paper, we describe FlexiTerm, a method for automatic term recognition from a domain-specific corpus, and evaluate its performance against five manually annotated corpora. FlexiTerm performs term recognition in two steps: linguistic filtering is used to select term candidates followed by calculation of termhood, a frequency-based measure used as evidence to qualify a candidate as a term. In order to improve the quality of termhood calculation, which may be affected by the term variation phenomena, FlexiTerm uses a range of methods to neutralise the main sources of variation in biomedical terms. It manages syntactic variation by processing candidates using a bag-of-words approach. Orthographic and morphological variations are dealt with using stemming in combination with lexical and phonetic similarity measures. The method was evaluated on five biomedical corpora. The highest values for precision (94.56%), recall (71.31%) and F-measure (81.31%) were achieved on a corpus of clinical notes. FlexiTerm is an open-source software tool for automatic term recognition. It incorporates a simple term variant normalisation method. The method proved to be more robust than the baseline against less formally structured texts, such as those found in patient blogs or medical notes. The software can be downloaded freely at http://www.cs.cf.ac.uk/flexiterm.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21763,""
"The clinical measurement, measurement method and experimental condition ontologies: expansion, improvements and new applications","Smith, Park, Nigam, Laulederkind, Hayman, Wang, Lowry, Petri, Pons, Tutaj, Liu, Worthey, Shimoyama, Dwinell","https://doi.org/10.1186/2041-1480-4-26","20131115","PubMed","","The Clinical Measurement Ontology (CMO), Measurement Method Ontology (MMO), and Experimental Condition Ontology (XCO) were originally developed at the Rat Genome Database (RGD) to standardize quantitative rat phenotype data in order to integrate results from multiple studies into the PhenoMiner database and data mining tool. These ontologies provide the framework for presenting what was measured, how it was measured, and under what conditions it was measured. There has been a continuing expansion of subdomains in each ontology with a parallel 2-3 fold increase in the total number of terms, substantially increasing the size and improving the scope of the ontologies. The proportion of terms with textual definitions has increased from ~60% to over 80% with greater synchronization of format and content throughout the three ontologies. Representation of definition source Uniform Resource Identifiers (URI) has been standardized, including the removal of all non-URI characters, and systematic versioning of all ontology files has been implemented. The continued expansion and success of these ontologies has facilitated the integration of more than 60,000 records into the RGD PhenoMiner database. In addition, new applications of these ontologies, such as annotation of Quantitative Trait Loci (QTL), have been added at the sites actively using them, including RGD and the Animal QTL Database. The improvements to these three ontologies have been substantial, and development is ongoing. New terms and expansions to the ontologies continue to be added as a result of active curation efforts at RGD and the Animal QTL database. Use of these vocabularies to standardize data representation for quantitative phenotypes and quantitative trait loci across databases for multiple species has demonstrated their utility for integrating diverse data types from multiple sources. These ontologies are freely available for download and use from the NCBO BioPortal website at http://bioportal.bioontology.org/ontologies/1583 (CMO), http://bioportal.bioontology.org/ontologies/1584 (MMO), and http://bioportal.bioontology.org/ontologies/1585 (XCO), or from the RGD ftp site at ftp://rgd.mcw.edu/pub/ontology/.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21764,""
"Effects of early and intensive neuro-rehabilitative treatment on muscle synergies in acute post-stroke patients: a pilot study","Tropea, Monaco, Coscia, Posteraro, Micera","https://doi.org/10.1186/1743-0003-10-103","20140728","PubMed","Aged; Aged, 80 and over; Arm; Biomechanical Phenomena; Female; Humans; Male; Muscle, Skeletal; Pilot Projects; Psychomotor Performance; Recovery of Function; Robotics; Stroke; Stroke Rehabilitation","After a stroke, patients show significant modifications of neural control of movement, such as abnormal muscle co-activation, and reduced selectivity and modulation of muscle activity. Nonetheless, results reported in literature do not allow to unequivocally explain whether and, in case, how a cerebrovascular accident affects muscle synergies underlying the control of the upper limb. These discrepancies suggest that a complete understanding of the modular re-organization of muscle activity due to a stroke is still lacking. This pilot study aimed at investigating the effects of the conjunction between the natural ongoing of the pathology and the intense robot-mediated treatment on muscle synergies of the paretic upper limb of subacute post-stroke patients. Six subacute patients, homogenous with respect to the age and the time elapsed from the trauma, and ten healthy age-matched subjects were enrolled. The protocol consisted in achieving planar movement of the upper limb while handling the end-effector of a robotic platform. Patients underwent 6 weeks long treatment while clinical scores, kinematics of the end-effector and muscle activity were recorded. Then we verified whether muscle coordination underlying the motor task was significantly affected by the cerebrovascular accident and how muscle synergies were modified along the treatment. Results show that although muscle synergies in subacute stroke patients were qualitatively comparable to those of healthy subjects, those underlying the movement of the shoulder can reflect the functional deficit induced by the pathology. Moreover, the improvement of motor performance due to the treatment was achieved in conjunction with slight modifications of muscle synergies. In this regard, modifications of muscle synergies appeared to be influenced by the different recovering mechanisms across patients presumably due to the heterogeneity of lesions, sides and location of the accident. The results support the hypothesis that muscle synergies reflect the injury of the cerebrovascular accident and could document the effects of the functional recovery due to a suitable and customized treatment. Therefore, they open up new possibilities for the development of more effective neuro-rehabilitation protocols.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21765,""
"Discovering body site and severity modifiers in clinical texts","Dligach, Bethard, Becker, Miller, Savova","https://doi.org/10.1136/amiajnl-2013-001766","20140605","PubMed","biomedical informatics; information extraction; natural language processing; relation extraction; Anatomy; Electronic Health Records; Humans; Natural Language Processing; Severity of Illness Index; Support Vector Machine","To research computational methods for discovering body site and severity modifiers in clinical texts. We cast the task of discovering body site and severity modifiers as a relation extraction problem in the context of a supervised machine learning framework. We utilize rich linguistic features to represent the pairs of relation arguments and delegate the decision about the nature of the relationship between them to a support vector machine model. We evaluate our models using two corpora that annotate body site and severity modifiers. We also compare the model performance to a number of rule-based baselines. We conduct cross-domain portability experiments. In addition, we carry out feature ablation experiments to determine the contribution of various feature groups. Finally, we perform error analysis and report the sources of errors. The performance of our method for discovering body site modifiers achieves F1 of 0.740-0.908 and our method for discovering severity modifiers achieves F1 of 0.905-0.929. Results indicate that both methods perform well on both in-domain and out-domain data, approaching the performance of human annotators. The most salient features are token and named entity features, although syntactic dependency features also contribute to the overall performance. The dominant sources of errors are infrequent patterns in the data and inability of the system to discern deeper semantic structures. We investigated computational methods for discovering body site and severity modifiers in clinical texts. Our best system is released open source as part of the clinical Text Analysis and Knowledge Extraction System (cTAKES).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21766,""
"Improved de-identification of physician notes through integrative modeling of both public and private medical text","McMurry, Fitch, Savova, Kohane, Reis","https://doi.org/10.1186/1472-6947-13-112","20140714","PubMed","Algorithms; Computer Simulation; Confidentiality; Electronic Health Records; Humans; Natural Language Processing; Physicians; Reproducibility of Results","Physician notes routinely recorded during patient care represent a vast and underutilized resource for human disease studies on a population scale. Their use in research is primarily limited by the need to separate confidential patient information from clinical annotations, a process that is resource-intensive when performed manually. This study seeks to create an automated method for de-identifying physician notes that does not require large amounts of private information: in addition to training a model to recognize Protected Health Information (PHI) within private physician notes, we reverse the problem and train a model to recognize non-PHI words and phrases that appear in public medical texts. Public and private medical text sources were analyzed to distinguish common medical words and phrases from Protected Health Information. Patient identifiers are generally nouns and numbers that appear infrequently in medical literature. To quantify this relationship, term frequencies and part of speech tags were compared between journal publications and physician notes. Standard medical concepts and phrases were then examined across ten medical dictionaries. Lists and rules were included from the US census database and previously published studies. In total, 28 features were used to train decision tree classifiers. The model successfully recalled 98% of PHI tokens from 220 discharge summaries. Cost sensitive classification was used to weight recall over precision (98%Ã‚Â F10 score, 76%Ã‚Â F1 score). More than half of the false negatives were the word ""of"" appearing in a hospital name. All patient names, phone numbers, and home addresses were at least partially redacted. Medical concepts such as ""elevated white blood cell count"" were informative for de-identification. The results exceed the previously approved criteria established by four Institutional Review Boards. The results indicate that distributional differences between private and public medical text can be used to accurately classify PHI. The data and algorithms reported here are made freely available for evaluation and improvement.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21767,""
"Supervised embedding of textual predictors with applications in clinical diagnostics for pediatric cardiology","Perry, Zha, Zhou, Frias, Zeng, Braunstein","https://doi.org/10.1136/amiajnl-2013-001792","20140313","PubMed","Clinical Diagnostics; Eigenmaps; Embedding; Supervised Learning; Algorithms; Area Under Curve; Artificial Intelligence; Cardiology; Diagnosis; Discriminant Analysis; Humans; Pattern Recognition, Automated; Pediatrics; ROC Curve; Sensitivity and Specificity","Electronic health records possess critical predictive information for machine-learning-based diagnostic aids. However, many traditional machine learning methods fail to simultaneously integrate textual data into the prediction process because of its high dimensionality. In this paper, we present a supervised method using Laplacian Eigenmaps to enable existing machine learning methods to estimate both low-dimensional representations of textual data and accurate predictors based on these low-dimensional representations at the same time. We present a supervised Laplacian Eigenmap method to enhance predictive models by embedding textual predictors into a low-dimensional latent space, which preserves the local similarities among textual data in high-dimensional space. The proposed implementation performs alternating optimization using gradient descent. For the evaluation, we applied our method to over 2000 patient records from a large single-center pediatric cardiology practice to predict if patients were diagnosed with cardiac disease. In our experiments, we consider relatively short textual descriptions because of data availability. We compared our method with latent semantic indexing, latent Dirichlet allocation, and local Fisher discriminant analysis. The results were assessed using four metrics: the area under the receiver operating characteristic curve (AUC), Matthews correlation coefficient (MCC), specificity, and sensitivity. The results indicate that supervised Laplacian Eigenmaps was the highest performing method in our study, achieving 0.782 and 0.374 for AUC and MCC, respectively. Supervised Laplacian Eigenmaps showed an increase of 8.16% in AUC and 20.6% in MCC over the baseline that excluded textual data and a 2.69% and 5.35% increase in AUC and MCC, respectively, over unsupervised Laplacian Eigenmaps. As a solution, we present a supervised Laplacian Eigenmap method to embed textual predictors into a low-dimensional Euclidean space. This method allows many existing machine learning predictors to effectively and efficiently capture the potential of textual predictors, especially those based on short texts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21768,""
"Survey of keyword adjustment of published articles medical subject headings in journal of mazandaran university of medical sciences (2009-2010)","Kabirzadeh, Siamian, Abadi, Saravi","https://doi.org/10.5455/aim.2013.21.98-102","20130923","PubMed","Abstracting and Indexing as Topic; Information Services; Information Storage and Retrieval; Iran; MEDLINE; Medical Subject Headings; PubMed","NONE DECLARED. Keywords are the most important tools for Information retrieval. They are usually used for retrieval of articles based on contents of information reserved from printed and electronic resources. Retrieval of appropriate keywords from Medical Subject Headings (MeSH) can impact with exact, correctness and short time on information retrieval. Regarding the above mentioned matters, this study was done to compare the Latin keywords was in the articles published in the Journal of Mazandaran University of Medical Sciences. This is a descriptive study. The data were extracted from the key words of Englsih abstracts of articles published in the years 2009-2010 in the Journal of Mazandaran University of Medical Sciences by census method. Checklist of data collection is designed, based on research objectives and literature review which has face validity. Compliance rate in this study was to determine if the keywords cited in this article as a full subject of the main subject headings in a MeSH (Bold and the selected word) is a perfect adjustment. If keywords were cited in the article but the main heading is not discussed in the following main topics to be discussed with reference to See and See related it has considered has partial adjustment. Out of 148 articles published in 12 issues in proposed time of studying, 72 research papers were analyzed. The average numbers of authors in each article were 4 Ã‚Â± 1. Results showed that most of specialty papers 42 (58. 4%), belonging to the (Department of Clinical Sciences) School of Medicine, 11 (15.3%) Basic Science, 6(8.4%) Pharmacy, Nursing and Midwifery 5(6.9%), 4(5.5%) Health, paramedical Sciences 3(4.2%), and non medical article 1(1.3%) school of medicine. In general, results showed that 80 (30%) of key words have been used to complete the adjustment. Also, only 1(1.4%) had complete adjustment with all the MeSH key words and in 8 articles(11.4%) key words of had no adjustment with MeSH. The results showed that only 17 articles could be retrieved if the search words are selected from the MeSH. In this case the expected 100% of published articles titles at this university the validity of exchange of research projects which is something noteworthy. The lack of correlation between number of authors and matching of Keywords with MeSH, may mean all of the papers' authors did not take part in writing and it is understanding that only one author wrote the paper.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21769,""
"Multivariate pattern analysis of DTI reveals differential white matter in individuals with obsessive-compulsive disorder","Li, Huang, Tang, Yang, Li, Kemp, Mechelli, Gong","https://doi.org/10.1002/hbm.22357","20141209","PubMed","diffusion tensor imaging; fractional anisotropy; multivariate pattern analysis; obsessive-compulsive disorder; support vector machine; Adolescent; Adult; Anisotropy; Brain; Diffusion Magnetic Resonance Imaging; Diffusion Tensor Imaging; Female; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Multivariate Analysis; Nerve Fibers, Myelinated; Obsessive-Compulsive Disorder; ROC Curve; Sensitivity and Specificity; Severity of Illness Index; Support Vector Machine; White Matter; Young Adult","Diffusion tensor imaging (DTI) studies have revealed group differences in white matter between patients with obsessive-compulsive disorder (OCD) and healthy controls. However, the results of these studies were based on average differences between the two groups, and therefore had limited clinical applicability. The objective of this study was to investigate whether fractional anisotropy (FA) of white matter can be used to discriminate between patients with OCD and healthy controls at the level of the individual. DTI data were acquired from 28 OCD patients and 28 demographically matched healthy controls, scanned using a 3T MRI system. Differences in FA values of white matter between OCD and healthy controls were examined using a multivariate pattern classification technique known as support vector machine (SVM). SVM applied to FA images correctly identified OCD patients with a sensitivity of 86% and a specificity of 82% resulting in a statistically significant accuracy of 84% (P Ã¢â€°Â¤ 0.001). This discrimination was based on a distributed network including bilateral prefrontal and temporal regions, inferior fronto-occipital fasciculus, superior fronto-parietal fasciculus, splenium of corpus callosum and left middle cingulum bundle. The present study demonstrates subtle and spatially distributed white matter abnormalities in individuals with OCD, and provides preliminary support for the suggestion that that these could be used to aid the identification of individuals with OCD in clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21770,""
"Grammatical comprehension deficits in non-fluent/agrammatic primary progressive aphasia","Charles, Olm, Powers, Ash, Irwin, McMillan, Rascovsky, Grossman","https://doi.org/10.1136/jnnp-2013-305749","20140403","PubMed","Aphasia; Behavioural Disorder; Brain Mapping; Dementia; Aged; Anisotropy; Aphasia, Broca; Aphasia, Wernicke; Brain; Case-Control Studies; Comprehension; Diffusion Tensor Imaging; Humans; Middle Aged; Neuroimaging; Neuropsychological Tests; Parietal Lobe; Primary Progressive Nonfluent Aphasia; Temporal Lobe","Grammatical comprehension difficulty is an essential supporting feature of the non-fluent/agrammatic variant of primary progressive aphasia (naPPA), but well-controlled clinical measures of grammatical comprehension are unavailable. To develop a measure of grammatical comprehension and examine this comparatively in PPA variants and behavioural-variant frontotemporal degeneration (bvFTD) and to assess the neuroanatomic basis for these deficits with volumetric grey matter atrophy and whole-brain fractional anisotropy (FA) in white matter tracts. Case-control study. Academic medical centre. 39 patients with variants of PPA (naPPA=12, lvPPA=15 and svPPA=12), 27 bvFTD patients without aphasia and 12 healthy controls. Grammatical comprehension accuracy. Patients with naPPA had selective difficulty understanding cleft sentence structures, while all PPA variants and patients with bvFTD were impaired with sentences containing a centre-embedded subordinate clause. Patients with bvFTD were also impaired understanding sentences involving short-term memory. Linear regressions related grammatical comprehension difficulty in naPPA to left anterior-superior temporal atrophy and reduced FA in corpus callosum and inferior frontal-occipital fasciculus. Difficulty with centre-embedded sentences in other PPA variants was related to other brain regions. These findings emphasise a distinct grammatical comprehension deficit in naPPA and associate this with interruption of a frontal-temporal neural network.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21771,""
"Discovering combinatorial interactions in survival data","Duverle, Takeuchi, Murakami-Tonami, Kadomatsu, Tsuda","https://doi.org/10.1093/bioinformatics/btt532","20140508","PubMed","Algorithms; Breast Neoplasms; Computational Biology; Female; Gene Expression Profiling; Gene Regulatory Networks; Humans; Likelihood Functions; Logistic Models; Models, Biological; Neoplasm Proteins; Neuroblastoma; Proportional Hazards Models; Risk Factors; Survival Rate","Although several methods exist to relate high-dimensional gene expression data to various clinical phenotypes, finding combinations of features in such input remains a challenge, particularly when fitting complex statistical models such as those used for survival studies. Our proposed method builds on existing 'regularization path-following' techniques to produce regression models that can extract arbitrarily complex patterns of input features (such as gene combinations) from large-scale data that relate to a known clinical outcome. Through the use of the data's structure and itemset mining techniques, we are able to avoid combinatorial complexity issues typically encountered with such methods, and our algorithm performs in similar orders of duration as single-variable versions. Applied to data from various clinical studies of cancer patient survival time, our method was able to produce a number of promising gene-interaction candidates whose tumour-related roles appear confirmed by literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21772,""
"Unsupervised mining of frequent tags for clinical eligibility text indexing","Miotto, Weng","https://doi.org/10.1016/j.jbi.2013.08.012","20140716","PubMed","Clinical trials; Controlled vocabulary; Eligibility criteria; Information filtering; Information storage and retrieval; Tags; Clinical Trials as Topic; Data Mining; Eligibility Determination; Humans","Clinical text, such as clinical trial eligibility criteria, is largely underused in state-of-the-art medical search engines due to difficulties of accurate parsing. This paper proposes a novel methodology to derive a semantic index for clinical eligibility documents based on a controlled vocabulary of frequent tags, which are automatically mined from the text. We applied this method to eligibility criteria on ClinicalTrials.gov and report that frequent tags (1) define an effective and efficient index of clinical trials and (2) are unlikely to grow radically when the repository increases. We proposed to apply the semantic index to filter clinical trial search results and we concluded that frequent tags reduce the result space more efficiently than an uncontrolled set of UMLS concepts. Overall, unsupervised mining of frequent tags from clinical text leads to an effective semantic index for the clinical eligibility documents and promotes their computational reuse. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21773,""
"Automated outcome classification of emergency department computed tomography imaging reports","Yadav, Sarioglu, Smith, Choi","https://doi.org/10.1111/acem.12174","20140424","PubMed","Artificial Intelligence; Cohort Studies; Electronic Health Records; Emergency Medical Services; Emergency Service, Hospital; Humans; Natural Language Processing; Retrospective Studies; Sensitivity and Specificity; Tomography, X-Ray Computed","Reliably abstracting outcomes from free-text electronic health records remains a challenge. While automated classification of free text has been a popular medical informatics topic, performance validation using real-world clinical data has been limited. The two main approaches are linguistic (natural language processing [NLP]) and statistical (machine learning). The authors have developed a hybrid system for abstracting computed tomography (CT) reports for specified outcomes. The objective was to measure performance of a hybrid NLP and machine learning system for automated outcome classification of emergency department (ED) CT imaging reports. The hypothesis was that such a system is comparable to medical personnel doing the data abstraction. A secondary analysis was performed on a prior diagnostic imaging study on 3,710 blunt facial trauma victims. Staff radiologists dictated CT reports as free text, which were then deidentified. A trained data abstractor manually coded the reference standard outcome of acute orbital fracture, with a random subset double-coded for reliability. The data set was randomly split evenly into training and testing sets. Training patient reports were used as input to the Medical Language Extraction and Encoding (MedLEE) NLP tool to create structured output containing standardized medical terms and modifiers for certainty and temporal status. Findings were filtered for low certainty and past/future modifiers and then combined with the manual reference standard to generate decision tree classifiers using data mining tools Waikato Environment for Knowledge Analysis (WEKA) 3.7.5 and Salford Predictive Miner 6.6. Performance of decision tree classifiers was evaluated on the testing set with or without NLP processing. The performance of machine learning alone was comparable to prior NLP studies (sensitivity = 0.92, specificity = 0.93, precision = 0.95, recall = 0.93, f-score = 0.94), and the combined use of NLP and machine learning showed further improvement (sensitivity = 0.93, specificity = 0.97, precision = 0.97, recall = 0.96, f-score = 0.97). This performance is similar to, or better than, that of medical personnel in previous studies. A hybrid NLP and machine learning automated classification system shows promise in coding free-text electronic clinical data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21774,""
"Automating annotation of information-giving for analysis of clinical conversation","Mayfield, Laws, Wilson, Penstein RosÃƒÂ©","https://doi.org/10.1136/amiajnl-2013-001898","20140313","PubMed","Automated Annotation; Computational Linguistics; Machine Learning; Patient-provider Communication; Artificial Intelligence; Clinical Coding; Communication; Electronic Data Processing; HIV Infections; Humans; Medical Records; Speech","Coding of clinical communication for fine-grained features such as speech acts has produced a substantial literature. However, annotation by humans is laborious and expensive, limiting application of these methods. We aimed to show that through machine learning, computers could code certain categories of speech acts with sufficient reliability to make useful distinctions among clinical encounters. The data were transcripts of 415 routine outpatient visits of HIV patients which had previously been coded for speech acts using the Generalized Medical Interaction Analysis System (GMIAS); 50 had also been coded for larger scale features using the Comprehensive Analysis of the Structure of Encounters System (CASES). We aggregated selected speech acts into information-giving and requesting, then trained the machine to automatically annotate using logistic regression classification. We evaluated reliability by per-speech act accuracy. We used multiple regression to predict patient reports of communication quality from post-visit surveys using the patient and provider information-giving to information-requesting ratio (briefly, information-giving ratio) and patient gender. Automated coding produces moderate reliability with human coding (accuracy 71.2%, ÃŽÂº=0.57), with high correlation between machine and human prediction of the information-giving ratio (r=0.96). The regression significantly predicted four of five patient-reported measures of communication quality (r=0.263-0.344). The information-giving ratio is a useful and intuitive measure for predicting patient perception of provider-patient communication quality. These predictions can be made with automated annotation, which is a practical option for studying large collections of clinical encounters with objectivity, consistency, and low cost, providing greater opportunity for training and reflection for care providers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21775,""
"The pattern of name tokens in narrative clinical text and a comparison of five systems for redacting them","Kayaalp, Browne, Callaghan, Dodd, Divita, Ozturk, McDonald","https://doi.org/10.1136/amiajnl-2013-001689","20140605","PubMed","Chart Research; De-Identification; Electronic Medical Records; PHI; Confidentiality; Electronic Health Records; Humans; Names; National Library of Medicine (U.S.); Natural Language Processing; United States","To understand the factors that influence success in scrubbing personal names from narrative text. We developed a scrubber, the NLM Name Scrubber (NLM-NS), to redact personal names from narrative clinical reports, hand tagged words in a set of gold standard narrative reports as personal names or not, and measured the scrubbing success of NLM-NS and that of four other scrubbing/name recognition tools (MIST, MITdeid, LingPipe, and ANNIE/GATE) against the gold standard reports. We ran three comparisons which used increasingly larger name lists. The test reports contained more than 1 million words, of which 2388 were patient and 20,160 were provider name tokens. NLM-NS failed to scrub only 2 of the 2388 instances of patient name tokens. Its sensitivity was 0.999 on both patient and provider name tokens and missed fewer instances of patient name tokens in all comparisons with other scrubbers. MIST produced the best all token specificity and F-measure for name instances in our most relevant study (study 2), with values of 0.997 and 0.938, respectively. In that same comparison, NLM-NS was second best, with values of 0.986 and 0.748, respectively, and MITdeid was a close third, with values of 0.985 and 0.796 respectively. With the addition of the Clinical Center name list to their native name lists, Ling Pipe, MITdeid, MIST, and ANNIE/GATE all improved substantially. MITdeid and Ling Pipe gained the most--reaching patient name sensitivity of 0.995 (F-measure=0.705) and 0.989 (F-measure=0.386), respectively. The privacy risk due to two name tokens missed by NLM-NS was statistically negligible, since neither individual could be distinguished among more than 150,000 people listed in the US Social Security Registry. The nature and size of name lists have substantial influences on scrubbing success. The use of very large name lists with frequency statistics accounts for much of NLM-NS scrubbing success.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21776,""
"Improvement research priorities: USA survey and expert consensus","Stevens, Ovretveit","https://doi.org/10.1155/2013/695729","20130911","PubMed","","The purpose of this study was to identify stakeholder views about national priorities for improvement science and build agreement for action in a national improvement and implementation research network in the USA. This was accomplished using three stages of identification and consensus. (1) Topics were identified through a multipronged environmental scan of the literature and initiatives. (2) Based on this scan, a survey was developed, and stakeholders (n = 2,777) were invited to rate the resulting 33-topic, 9-category list, via an online survey. Data from 560 respondents (20% response) were analyzed. (3) An expert panel used survey results to further refine the research priorities through a Rand Delphi process. Priorities identified were within four categories: care coordination and transitions, high-performing clinical systems and microsystems improvement approaches, implementation of evidence-based improvements and best practices, and culture of quality and safety. The priorities identified were adopted by the improvement science research network as the research agenda to guide strategy. The process and conclusions may be of value to quality improvement research funding agencies, governments, and research units seeking to concentrate their resources on improvement topics where research is capable of yielding timely and actionable answers as well as contributing to the knowledge base for improvement. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21777,""
"A study of brain networks associated with swallowing using graph-theoretical approaches","Luan, SÃƒÂ¶rÃƒÂ¶s, SejdiÃ„â€¡","https://doi.org/10.1371/journal.pone.0073577","20140416","PubMed","Adult; Algorithms; Brain; Brain Mapping; Deglutition; Female; Humans; Magnetic Resonance Imaging; Models, Neurological; Psychomotor Performance; Young Adult","Functional connectivity between brain regions during swallowing tasks is still not well understood. Understanding these complex interactions is of great interest from both a scientific and a clinical perspective. In this study, functional magnetic resonance imaging (fMRI) was utilized to study brain functional networks during voluntary saliva swallowing in twenty-two adult healthy subjects (all females, [Formula: see text] years of age). To construct these functional connections, we computed mean partial correlation matrices over ninety brain regions for each participant. Two regions were determined to be functionally connected if their correlation was above a certain threshold. These correlation matrices were then analyzed using graph-theoretical approaches. In particular, we considered several network measures for the whole brain and for swallowing-related brain regions. The results have shown that significant pairwise functional connections were, mostly, either local and intra-hemispheric or symmetrically inter-hemispheric. Furthermore, we showed that all human brain functional network, although varying in some degree, had typical small-world properties as compared to regular networks and random networks. These properties allow information transfer within the network at a relatively high efficiency. Swallowing-related brain regions also had higher values for some of the network measures in comparison to when these measures were calculated for the whole brain. The current results warrant further investigation of graph-theoretical approaches as a potential tool for understanding the neural basis of dysphagia. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21778,""
"Clinical utility of machine-learning approaches in schizophrenia: improving diagnostic confidence for translational neuroimaging","Iwabuchi, Liddle, Palaniyappan","https://doi.org/10.3389/fpsyt.2013.00095","20130906","PubMed","diagnosis; gray matter; machine learning; schizophrenia; structural MRI; support vector machine; white matter","Machine-learning approaches are becoming commonplace in the neuroimaging literature as potential diagnostic and prognostic tools for the study of clinical populations. However, very few studies provide clinically informative measures to aid in decision-making and resource allocation. Head-to-head comparison of neuroimaging-based multivariate classifiers is an essential first step to promote translation of these tools to clinical practice. We systematically evaluated the classifier performance using back-to-back structural MRI in two field strengths (3- and 7-T) to discriminate patients with schizophrenia (nÃ¢â‚¬â€°=Ã¢â‚¬â€°19) from healthy controls (nÃ¢â‚¬â€°=Ã¢â‚¬â€°20). Gray matter (GM) and white matter images were used as inputs into a support vector machine to classify patients and control subjects. Seven Tesla classifiers outperformed the 3-T classifiers with accuracy reaching as high as 77% for the 7-T GM classifier compared to 66.6% for the 3-T GM classifier. Furthermore, diagnostic odds ratio (a measure that is not affected by variations in sample characteristics) and number needed to predict (a measure based on Bayesian certainty of a test result) indicated superior performance of the 7-T classifiers, whereby for each correct diagnosis made, the number of patients that need to be examined using the 7-T GM classifier was one less than the number that need to be examined if a different classifier was used. Using a hypothetical example, we highlight how these findings could have significant implications for clinical decision-making. We encourage the reporting of measures proposed here in future studies utilizing machine-learning approaches. This will not only promote the search for an optimum diagnostic tool but also aid in the translation of neuroimaging to clinical use. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21779,""
"Evaluating the impact of pre-annotation on annotation speed and potential bias: natural language processing gold standard development for clinical named entity recognition in clinical trial announcements","Lingren, Deleger, Molnar, Zhai, Meinzen-Derr, Kaiser, Stoutenborough, Li, Solti","https://doi.org/10.1136/amiajnl-2013-001837","20140605","PubMed","Information Extraction; Natural Language Processing; Pre-annotation; clinical trial announcements; named entity recognition; umls; Analysis of Variance; Clinical Trials as Topic; Humans; Information Storage and Retrieval; Natural Language Processing; Time and Motion Studies","To present a series of experiments: (1) to evaluate the impact of pre-annotation on the speed of manual annotation of clinical trial announcements; and (2) to test for potential bias, if pre-annotation is utilized. To build the gold standard, 1400 clinical trial announcements from the clinicaltrials.gov website were randomly selected and double annotated for diagnoses, signs, symptoms, Unified Medical Language System (UMLS) Concept Unique Identifiers, and SNOMED CT codes. We used two dictionary-based methods to pre-annotate the text. We evaluated the annotation time and potential bias through F-measures and ANOVA tests and implemented Bonferroni correction. Time savings ranged from 13.85% to 21.5% per entity. Inter-annotator agreement (IAA) ranged from 93.4% to 95.5%. There was no statistically significant difference for IAA and annotator performance in pre-annotations. On every experiment pair, the annotator with the pre-annotated text needed less time to annotate than the annotator with non-labeled text. The time savings were statistically significant. Moreover, the pre-annotation did not reduce the IAA or annotator performance. Dictionary-based pre-annotation is a feasible and practical method to reduce the cost of annotation of clinical named entity recognition in the eligibility sections of clinical trial announcements without introducing bias in the annotation process.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21780,""
"Low cardiorespiratory fitness in African Americans: a health disparity risk factor?","Swift, Staiano, Johannsen, Lavie, Earnest, Katzmarzyk, Blair, Newton, Church","https://doi.org/10.1007/s40279-013-0092-3","20140717","PubMed","African Americans; Cardiovascular Diseases; Health Status Disparities; Humans; Physical Fitness; Risk Factors","Low cardiorespiratory fitness (CRF) is a well-established risk factor for all-cause and cardiovascular disease mortality. African Americans have higher rates of cardiovascular disease compared with their Caucasian counterparts. However, the extent to which lower CRF levels contribute to the excess risk in African Americans has not been fully explored. The purpose of this review is to: (i) explore the literature evaluating the relationship between CRF and mortality specifically in African American populations; and (ii) critically evaluate the studies which have compared CRF between African American and Caucasians in epidemiological studies and clinical trials. We have further discussed several potential mechanisms that may contribute to the observation of lower CRF levels in African American compared with Caucasian adults, including potential racial differences in physical activity levels, muscle fiber type distribution, and hemoglobin levels. If lower CRF is generally present in African Americans compared with Caucasians, and is of a clinically meaningful difference, this may represent an important public health concern. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21781,""
"Population cancer risks associated with coal mining: a systematic review","Jenkins, Christian, Mueller, Robbins","https://doi.org/10.1371/journal.pone.0071312","20140408","PubMed","Coal Mining; Databases, Bibliographic; Environmental Exposure; Female; Humans; Incidence; Lung Neoplasms; Male; Occupational Exposure; Risk; Stomach Neoplasms; United States","Coal is produced across 25 states and provides 42% of US energy. With production expected to increase 7.6% by 2035, proximate populations remain at risk of exposure to carcinogenic coal products such as silica dust and organic compounds. It is unclear if population exposure is associated with increased risk, or even which cancers have been studied in this regard. We performed a systematic review of English-language manuscripts published since 1980 to determine if coal mining exposure was associated with increased cancer risk (incidence and mortality). Of 34 studies identified, 27 studied coal mining as an occupational exposure (coal miner cohort or as a retrospective risk factor) but only seven explored health effects in surrounding populations. Overall, risk assessments were reported for 20 cancer site categories, but their results and frequency varied considerably. Incidence and mortality risk assessments were: negative (no increase) for 12 sites; positive for 1 site; and discordant for 7 sites (e.g. lung, gastric). However, 10 sites had only a single study reporting incidence risk (4 sites had none), and 11 sites had only a single study reporting mortality risk (2 sites had none). The ecological study data were particularly meager, reporting assessments for only 9 sites. While mortality assessments were reported for each, 6 had only a single report and only 2 sites had reported incidence assessments. The reported assessments are too meager, and at times contradictory, to make definitive conclusions about population cancer risk due to coal mining. However, the preponderance of this and other data support many of Hill's criteria for causation. The paucity of data regarding population exposure and risk, the widespread geographical extent of coal mining activity, and the continuing importance of coal for US energy, warrant further studies of population exposure and risk.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21782,""
"Automatic prediction of rheumatoid arthritis disease activity from the electronic medical records","Lin, Karlson, Canhao, Miller, Dligach, Chen, Perez, Shen, Weinblatt, Shadick, Plenge, Savova","https://doi.org/10.1371/journal.pone.0069932","20140408","PubMed","Antirheumatic Agents; Arthritis, Rheumatoid; Artificial Intelligence; Data Mining; Disease Progression; Electronic Health Records; Humans; ROC Curve; Support Vector Machine","We aimed to mine the data in the Electronic Medical Record to automatically discover patients' Rheumatoid Arthritis disease activity at discrete rheumatology clinic visits. We cast the problem as a document classification task where the feature space includes concepts from the clinical narrative and lab values as stored in the Electronic Medical Record. The Training Set consisted of 2792 clinical notes and associated lab values. Test Set 1 included 1749 clinical notes and associated lab values. Test Set 2 included 344 clinical notes for which there were no associated lab values. The Apache clinical Text Analysis and Knowledge Extraction System was used to analyze the text and transform it into informative features to be combined with relevant lab values. Experiments over a range of machine learning algorithms and features were conducted. The best performing combination was linear kernel Support Vector Machines with Unified Medical Language System Concept Unique Identifier features with feature selection and lab values. The Area Under the Receiver Operating Characteristic Curve (AUC) is 0.831 (ÃÆ’Ã¢â‚¬Å =Ã¢â‚¬Å 0.0317), statistically significant as compared to two baselines (AUCÃ¢â‚¬Å =Ã¢â‚¬Å 0.758, ÃÆ’Ã¢â‚¬Å =Ã¢â‚¬Å 0.0291). Algorithms demonstrated superior performance on cases clinically defined as extreme categories of disease activity (Remission and High) compared to those defined as intermediate categories (Moderate and Low) and included laboratory data on inflammatory markers. Automatic Rheumatoid Arthritis disease activity discovery from Electronic Medical Record data is a learnable task approximating human performance. As a result, this approach might have several research applications, such as the identification of patients for genome-wide pharmacogenetic studies that require large sample sizes with precise definitions of disease activity and response to therapies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21783,""
"Identifying phenotypic signatures of neuropsychiatric disorders from electronic medical records","Lyalina, Percha, LePendu, Iyer, Altman, Shah","https://doi.org/10.1136/amiajnl-2013-001933","20140124","PubMed","Autism; Bipolar Disorder; Data Mining; Electronic Medical Records; Network Analysis; Schizophrenia; Adolescent; Adult; Aged; Aged, 80 and over; Autistic Disorder; Bipolar Disorder; Child; Child, Preschool; Data Mining; Diagnosis, Differential; Electronic Health Records; Female; Humans; Male; Middle Aged; Phenotype; Psychotropic Drugs; Schizophrenia; Unified Medical Language System; Young Adult","Mental illness is the leading cause of disability in the USA, but boundaries between different mental illnesses are notoriously difficult to define. Electronic medical records (EMRs) have recently emerged as a powerful new source of information for defining the phenotypic signatures of specific diseases. We investigated how EMR-based text mining and statistical analysis could elucidate the phenotypic boundaries of three important neuropsychiatric illnesses-autism, bipolar disorder, and schizophrenia. We analyzed the medical records of over 7000 patients at two facilities using an automated text-processing pipeline to annotate the clinical notes with Unified Medical Language System codes and then searching for enriched codes, and associations among codes, that were representative of the three disorders. We used dimensionality-reduction techniques on individual patient records to understand individual-level phenotypic variation within each disorder, as well as the degree of overlap among disorders. We demonstrate that automated EMR mining can be used to extract relevant drugs and phenotypes associated with neuropsychiatric disorders and characteristic patterns of associations among them. Patient-level analyses suggest a clear separation between autism and the other disorders, while revealing significant overlap between schizophrenia and bipolar disorder. They also enable localization of individual patients within the phenotypic 'landscape' of each disorder. Because EMRs reflect the realities of patient care rather than idealized conceptualizations of disease states, we argue that automated EMR mining can help define the boundaries between different mental illnesses, facilitate cohort building for clinical and genomic studies, and reveal how clear expert-defined disease boundaries are in practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21784,""
"Use of computerized algorithm to identify individuals in need of testing for celiac disease","Ludvigsson, Pathak, Murphy, Durski, Kirsch, Chute, Ryu, Murray","https://doi.org/10.1136/amiajnl-2013-001924","20140124","PubMed","algorithm; artificial intelligence; celiac; decision support system, clinical; inflammation; Adult; Age Distribution; Algorithms; Celiac Disease; Child; Electronic Health Records; Female; Humans; International Classification of Diseases; Male; Natural Language Processing; Phenotype; Risk; Sex Distribution","Celiac disease (CD) is a lifelong immune-mediated disease with excess mortality. Early diagnosis is important to minimize disease symptoms, complications, and consumption of healthcare resources. Most patients remain undiagnosed. We developed two electronic medical record (EMR)-based algorithms to identify patients at high risk of CD and in need of CD screening. (I) Using natural language processing (NLP), we searched EMRs for 16 free text (and related) terms in 216 CD patients and 280 controls. (II) EMRs were also searched for ICD9 (International Classification of Disease) codes suggesting an increased risk of CD in 202 patients with CD and 524 controls. For each approach, we determined the optimal number of hits to be assigned as CD cases. To assess performance of these algorithms, sensitivity and specificity were calculated. Using two hits as the cut-off, the NLP algorithm identified 72.9% of all celiac patients (sensitivity), and ruled out CD in 89.9% of the controls (specificity). In a representative US population of individuals without a prior celiac diagnosis (assuming that 0.6% had undiagnosed CD), this NLP algorithm could identify a group of individuals where 4.2% would have CD (positive predictive value). ICD9 code search using three hits as the cut-off had a sensitivity of 17.1% and a specificity of 88.5% (positive predictive value was 0.9%). This study shows that computerized EMR-based algorithms can help identify patients at high risk of CD. NLP-based techniques demonstrate higher sensitivity and positive predictive values than algorithms based on ICD9 code searches.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21785,""
"Unsupervised biomedical named entity recognition: experiments with clinical and biological texts","Zhang, Elhadad","https://doi.org/10.1016/j.jbi.2013.08.004","20140716","PubMed","Chunking; Distributional semantics; Named entity recognition; Natural language processing; UMLS; Biomedical Research; Natural Language Processing; Vocabulary, Controlled","Named entity recognition is a crucial component of biomedical natural language processing, enabling information extraction and ultimately reasoning over and knowledge discovery from text. Much progress has been made in the design of rule-based and supervised tools, but they are often genre and task dependent. As such, adapting them to different genres of text or identifying new types of entities requires major effort in re-annotation or rule development. In this paper, we propose an unsupervised approach to extracting named entities from biomedical text. We describe a stepwise solution to tackle the challenges of entity boundary detection and entity type classification without relying on any handcrafted rules, heuristics, or annotated data. A noun phrase chunker followed by a filter based on inverse document frequency extracts candidate entities from free text. Classification of candidate entities into categories of interest is carried out by leveraging principles from distributional semantics. Experiments show that our system, especially the entity classification step, yields competitive results on two popular biomedical datasets of clinical notes and biological literature, and outperforms a baseline dictionary match approach. Detailed error analysis provides a road map for future work. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21786,""
"The Vertebrate Trait Ontology: a controlled vocabulary for the annotation of trait data across species","Park, Bello, Smith, Hu, Munzenmaier, Nigam, Smith, Shimoyama, Eppig, Reecy","https://doi.org/10.1186/2041-1480-4-13","20131115","PubMed","","The use of ontologies to standardize biological data and facilitate comparisons among datasets has steadily grown as the complexity and amount of available data have increased. Despite the numerous ontologies available, one area currently lacking a robust ontology is the description of vertebrate traits. A trait is defined as any measurable or observable characteristic pertaining to an organism or any of its substructures. While there are several ontologies to describe entities and processes in phenotypes, diseases, and clinical measurements, one has not been developed for vertebrate traits; the Vertebrate Trait Ontology (VT) was created to fill this void. Significant inconsistencies in trait nomenclature exist in the literature, and additional difficulties arise when trait data are compared across species. The VT is a unified trait vocabulary created to aid in the transfer of data within and between species and to facilitate investigation of the genetic basis of traits. Trait information provides a valuable link between the measurements that are used to assess the trait, the phenotypes related to the traits, and the diseases associated with one or more phenotypes. Because multiple clinical and morphological measurements are often used to assess a single trait, and a single measurement can be used to assess multiple physiological processes, providing investigators with standardized annotations for trait data will allow them to investigate connections among these data types. The annotation of genomic data with ontology terms provides unique opportunities for data mining and analysis. Links between data in disparate databases can be identified and explored, a strategy that is particularly useful for cross-species comparisons or in situations involving inconsistent terminology. The VT provides a common basis for the description of traits in multiple vertebrate species. It is being used in the Rat Genome Database and Animal QTL Database for annotation of QTL data for rat, cattle, chicken, swine, sheep, and rainbow trout, and in the Mouse Phenome Database to annotate strain characterization data. In these databases, data are also cross-referenced to applicable terms from other ontologies, providing additional avenues for data mining and analysis. The ontology is available at http://bioportal.bioontology.org/ontologies/50138.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21787,""
"Optimal oxygen titration in patients with chronic obstructive pulmonary disease: a role for automated oxygen delivery?","Lellouche, Lipes, L'Her","https://doi.org/10.1155/2013/376545","20140130","PubMed","Automation; Humans; Hyperoxia; Hypoxia; Oxygen Inhalation Therapy; Pulmonary Disease, Chronic Obstructive; Titrimetry","Oxygen therapy can be life-saving for patients with chronic obstructive pulmonary disease (COPD) and is the backbone of any acute COPD treatment strategy. Although largely considered to be a benign drug, many publications have highlighted the need to accurately adjust oxygen delivery to avoid both hypoxemia and the problem of hyperoxia-induced hypercapnia. Recent clinical data have shown that the deleterious effects of excess oxygen treatment can not only alter carbon dioxide levels (which has been known for more than 60 years) but can also lead to an increase in mortality. Nevertheless, despite the extensive literature, the risks associated with hyperoxia are often overlooked and published clinical recommendations are largely ignored. This failure in knowledge translation has become increasingly important not only because of the desire to reduce medical error, but in a society with limited health care resources, the economic burden of COPD is such that it cannot afford to make preventable medical mistakes. Recently, novel devices have been developed to automatically adjust oxygen flow rates to maintain stable oxygen saturations. These closed-loop oxygen delivery systems have the potential to reduce medical error, improve morbidity and mortality, and reduce health care costs. Preliminary data in this field are promising and will require a significant amount of research in the coming years to determine the precise indications for these systems. The importance of appropriate oxygen dosing and the current literature regarding novel oxygen delivery systems are reviewed. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21788,""
"A review of recent literature employing electroencephalographic techniques to study the pathophysiology, phenomenology, and treatment response of schizophrenia","Hasey, Kiang","https://doi.org/10.1007/s11920-013-0388-x","20140317","PubMed","Cognition; Electroencephalography; Evoked Potentials; Humans; Schizophrenia; Severity of Illness Index","Clinical experience and research findings suggest that schizophrenia is a disorder comprised of multiple genetic and neurophysiological subtypes with differential response to treatment. Electroencephalography (EEG) is a non-invasive, inexpensive and useful tool for investigating the neurobiology of schizophrenia and its subtypes. EEG studies elucidate the neurophysiological mechanisms potentially underlying clinical symptomatology. In this review article recent advances in applying EEG to study pathophysiology, phenomenology, and treatment response in schizophrenia are discussed. Investigative strategies employed include: analyzing quantitative EEG (QEEG) spectral power during the resting state and cognitive tasks; applying machine learning methods to identify QEEG indicators of diagnosis and treatment response; and using the event-related brain potential (ERP) technique to characterize the neurocognitive processes underlying clinical symptoms. Studies attempting to validate potential EEG biomarkers of schizophrenia and its symptoms, which could be useful in assessing familial risk and treatment response, are also reviewed. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21789,""
"Synergistic combination of clinical and imaging features predicts abnormal imaging patterns of pulmonary infections","Bagci, Jaster-Miller, Olivier, Yao, Mollura","https://doi.org/10.1016/j.compbiomed.2013.06.008","20140325","PubMed","AmRMR; Biomarker; Feature extraction; Infectious diseases; Lung CT; NTM; Parainfluenza; Pneumonias; Texture analysis; Adult; Aged; Biomarkers; Female; Humans; Image Processing, Computer-Assisted; Lung; Male; Middle Aged; Pneumonia, Bacterial; Pneumonia, Viral; Tomography, X-Ray Computed","We designed and tested a novel hybrid statistical model that accepts radiologic image features and clinical variables, and integrates this information in order to automatically predict abnormalities in chest computed-tomography (CT) scans and identify potentially important infectious disease biomarkers. In 200 patients, 160 with various pulmonary infections and 40 healthy controls, we extracted 34 clinical variables from laboratory tests and 25 textural features from CT images. From the CT scans, pleural effusion (PE), linear opacity (or thickening) (LT), tree-in-bud (TIB), pulmonary nodules, ground glass opacity (GGO), and consolidation abnormality patterns were analyzed and predicted through clinical, textural (imaging), or combined attributes. The presence and severity of each abnormality pattern was validated by visual analysis of the CT scans. The proposed biomarker identification system included two important steps: (i) a coarse identification of an abnormal imaging pattern by adaptively selected features (AmRMR), and (ii) a fine selection of the most important features from the previous step, and assigning them as biomarkers, depending on the prediction accuracy. Selected biomarkers were used to classify normal and abnormal patterns by using a boosted decision tree (BDT) classifier. For all abnormal imaging patterns, an average prediction accuracy of 76.15% was obtained. Experimental results demonstrated that our proposed biomarker identification approach is promising and may advance the data processing in clinical pulmonary infection research and diagnostic techniques. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21790,""
"Google Scholar is not enough to be used alone for systematic reviews","Giustini, Boulos","https://doi.org/10.5210/ojphi.v5i2.4623","20130807","PubMed","MeSH Keywords: Google Scholar; PubMed; information retrieval; searching; systematic reviews","Google Scholar (GS) has been noted for its ability to search broadly for important references in the literature. Gehanno et al. recently examined GS in their study: 'Is Google scholar enough to be used alone for systematic reviews?' In this paper, we revisit this important question, and some of Gehanno et al.'s other findings in evaluating the academic search engine. The authors searched for a recent systematic review (SR) of comparable size to run search tests similar to those in Gehanno et al. We selected Chou et al. (2013) contacting the authors for a list of publications they found in their SR on social media in health. We queried GS for each of those 506 titles (in quotes """"), one by one. When GS failed to retrieve a paper, or produced too many results, we used the allintitle: command to find papers with the same title. Google Scholar produced records for ~95% of the papers cited by Chou et al. (n=476/506). A few of the 30 papers that were not in GS were later retrieved via PubMed and even regular Google Search. But due to its different structure, we could not run searches in GS that were originally performed by Chou et al. in PubMed, Web of Science, Scopus and PsycINFOÃ‚Â®. Identifying 506 papers in GS was an inefficient process, especially for papers using similar search terms. Has Google Scholar improved enough to be used alone in searching for systematic reviews? No. GS' constantly-changing content, algorithms and database structure make it a poor choice for systematic reviews. Looking for papers when you know their titles is a far different issue from discovering them initially. Further research is needed to determine when and how (and for what purposes) GS can be used alone. Google should provide details about GS' database coverage and improve its interface (e.g., with semantic search filters, stored searching, etc.). Perhaps then it will be an appropriate choice for systematic reviews.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21791,""
"Workshop on using natural language processing applications for enhancing clinical decision making: an executive summary","Pai, Rodgers, Conroy, Luo, Zhou, Seto","https://doi.org/10.1136/amiajnl-2013-001896","20140313","PubMed","clinical decision-making; medical knowledge base; medical reasoning; natural language processing; personalized longitudinal healthcare; unstructured clinical notes; Artificial Intelligence; Decision Support Systems, Clinical; Electronic Health Records; Humans; Natural Language Processing","In April 2012, the National Institutes of Health organized a two-day workshop entitled 'Natural Language Processing: State of the Art, Future Directions and Applications for Enhancing Clinical Decision-Making' (NLP-CDS). This report is a summary of the discussions during the second day of the workshop. Collectively, the workshop presenters and participants emphasized the need for unstructured clinical notes to be included in the decision making workflow and the need for individualized longitudinal data tracking. The workshop also discussed the need to: (1) combine evidence-based literature and patient records with machine-learning and prediction models; (2) provide trusted and reproducible clinical advice; (3) prioritize evidence and test results; and (4) engage healthcare professionals, caregivers, and patients. The overall consensus of the NLP-CDS workshop was that there are promising opportunities for NLP and CDS to deliver cognitive support for healthcare professionals, caregivers, and patients. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21792,""
"Practical implementation of an existing smoking detection pipeline and reduced support vector machine training corpus requirements","Khor, Yip, Bressel, Rose, Duchesne, Foroudi","https://doi.org/10.1136/amiajnl-2013-002090","20140206","PubMed","</Abstract><AuthorList CompleteYN=""Y""><Author ValidYN=""Y""><LastName>Khor</LastName><ForeName>Richard</ForeName><Initials>R</Initials><AffiliationInfo><Affiliation>Department of Radiation Oncology, Peter MacCallum Cancer Centre, Melbourne, Victoria, Australia.</Affiliation></AffiliationInfo></Author><Author ValidYN=""Y""><LastName>Yip</LastName><ForeName>Wai-Kuan</ForeName><Initials>WK</Initials></Author><Author ValidYN=""Y""><LastName>Bressel</LastName><ForeName>Mathias</ForeName><Initials>M</Initials></Author><Author ValidYN=""Y""><LastName>Rose</LastName><ForeName>William</ForeName><Initials>W</Initials></Author><Author ValidYN=""Y""><LastName>Duchesne</LastName><ForeName>Gillian</ForeName><Initials>G</Initials></Author><Author ValidYN=""Y""><LastName>Foroudi</LastName><ForeName>Farshad</ForeName><Initials>F</Initials></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI=""D016428"">Journal Article</PublicationType></PublicationTypeList><ArticleDate DateType=""Electronic""><Year>2013</Year><Month>08</Month><Day>06</Day></ArticleDate></Article><MedlineJournalInfo><Country>England</Country><MedlineTA>J Am Med Inform Assoc</MedlineTA><NlmUniqueID>9430800</NlmUniqueID><ISSNLinking>1067-5027</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI=""D057225"" MajorTopicYN=""N"">Data Mining</DescriptorName><QualifierName UI=""Q000379"" MajorTopicYN=""Y"">methods</QualifierName></MeshHeading><MeshHeading><DescriptorName UI=""D006801"" MajorTopicYN=""N"">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=""D012907"" MajorTopicYN=""Y"">Smoking</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=""D013358"" MajorTopicYN=""N"">Subject Headings</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=""D060388"" MajorTopicYN=""Y"">Support Vector Machine</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=""D014825"" MajorTopicYN=""N"">Vocabulary</DescriptorName></MeshHeading></MeshHeadingList><KeywordList Owner=""NOTNLM""><Keyword MajorTopicYN=""N"">Classification/methods; Medical Records Systems, Computerized; Natural Language Processing; Smoking; Data Mining; Humans; Smoking; Subject Headings; Support Vector Machine; Vocabulary","This study aimed to reduce reliance on large training datasets in support vector machine (SVM)-based clinical text analysis by categorizing keyword features. An enhanced Mayo smoking status detection pipeline was deployed. We used a corpus of 709 annotated patient narratives. The pipeline was optimized for local data entry practice and lexicon. SVM classifier retraining used a grouped keyword approach for better efficiency. Accuracy, precision, and F-measure of the unaltered and optimized pipelines were evaluated using k-fold cross-validation. Initial accuracy of the clinical Text Analysis and Knowledge Extraction System (cTAKES) package was 0.69. Localization and keyword grouping improved system accuracy to 0.9 and 0.92, respectively. F-measures for current and past smoker classes improved from 0.43 to 0.81 and 0.71 to 0.91, respectively. Non-smoker and unknown-class F-measures were 0.96 and 0.98, respectively. Keyword grouping had no negative effect on performance, and decreased training time. Grouping keywords is a practical method to reduce training corpus size. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21793,""
"Analyzing differences between chinese and english clinical text: a cross-institution comparison of discharge summaries in two languages","Wu, Lei, Wei, Tang, Denny, Rosenbloom, Miller, Giuse, Zheng, Xu","https://www.google.com/search?q=Analyzing+differences+between+chinese+and+english+clinical+text:+a+cross-institution+comparison+of+discharge+summaries+in+two+languages.","20150406","PubMed","China; Documentation; Electronic Health Records; Medical Record Linkage; Natural Language Processing; Patient Discharge Summaries; Semantics; Translating; United States; Vocabulary, Controlled","Worldwide adoption of Electronic Medical Records (EMRs) databases in health care have generated an unprecedented amount of clinical data available electronically. There has been an increasing trend in US and western institutions towards collaborating with China on medical research using EMR data. However, few studies have investigated characteristics of EMR data in China and their differences with the data in US hospitals. As an initial step towards differentiating EMR data in Chinese and US systems, this study attempts to understand system and cultural differences that may exist between Chinese and English clinical documents. We collected inpatient discharge summaries from one Chinese and from three US institutions and manually analyzed three major clinical components in text: medical problems, tests, and treatments. We reported comparison results at the document level and section level and discussed potential reasons for observed differences. Documenting and understanding differences in clinical reports from the US and China EMRs are important for cross-country collaborations. Our study also provided valuable insights for developing natural language processing tools for Chinese clinical text. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21794,""
"Applying multiple methods to assess the readability of a large corpus of medical documents","Wu, Hanauer, Mei, Clark, An, Lei, Proulx, Zeng-Treitler, Zheng","https://www.google.com/search?q=Applying+multiple+methods+to+assess+the+readability+of+a+large+corpus+of+medical+documents.","20150406","PubMed","Artificial Intelligence; Comprehension; Documentation; Humans; MEDLINE; MedlinePlus; Natural Language Processing; Reading; Vocabulary, Controlled","Medical documents provided to patients at the end of an episode of care, such as discharge summaries and referral letters, serve as an important vehicle to convey critical information to patients and families. Increasingly, healthcare institutions are also experimenting with granting patients direct electronic access to other types of clinical narratives that are not typically shared unless explicitly requested, such as progress notes. While these efforts have great potential to improve information transparency, their value can be severely diminished if patients are unable to read and thus unable to properly interpret the medical documents shared to them. In this study, we approached the problem by contrasting the 'readability' of two types of medical documents: referral letters vs. other genres of narrative clinician notes not explicitly intended for direct viewing by patients. To establish a baseline for comparison, we also computed readability scores of MedlinePlus articles - exemplars of fine patient education materials carefully crafted for lay audiences. We quantified document readability using four different measures. Differences in the results obtained through these measures are also discussed. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21795,""
"eTACTS: a method for dynamically filtering clinical trial search results","Miotto, Jiang, Weng","https://doi.org/10.1016/j.jbi.2013.07.014","20140716","PubMed","Association rules; Clinical trials; Dynamic information filtering; Information storage and retrieval; Interactive information retrieval; Tag cloud; Clinical Trials as Topic; Humans; Treatment Outcome","Information overload is a significant problem facing online clinical trial searchers. We present eTACTS, a novel interactive retrieval framework using common eligibility tags to dynamically filter clinical trial search results. eTACTS mines frequent eligibility tags from free-text clinical trial eligibility criteria and uses these tags for trial indexing. After an initial search, eTACTS presents to the user a tag cloud representing the current results. When the user selects a tag, eTACTS retains only those trials containing that tag in their eligibility criteria and generates a new cloud based on tag frequency and co-occurrences in the remaining trials. The user can then select a new tag or unselect a previous tag. The process iterates until a manageable number of trials is returned. We evaluated eTACTS in terms of filtering efficiency, diversity of the search results, and user eligibility to the filtered trials using both qualitative and quantitative methods. eTACTS (1) rapidly reduced search results from over a thousand trials to ten; (2) highlighted trials that are generally not top-ranked by conventional search engines; and (3) retrieved a greater number of suitable trials than existing search engines. eTACTS enables intuitive clinical trial searches by indexing eligibility criteria with effective tags. User evaluation was limited to one case study and a small group of evaluators due to the long duration of the experiment. Although a larger-scale evaluation could be conducted, this feasibility study demonstrated significant advantages of eTACTS over existing clinical trial search engines. A dynamic eligibility tag cloud can potentially enhance state-of-the-art clinical trial search engines by allowing intuitive and efficient filtering of the search result space.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21796,""
"The use of laser therapy for dental implant surface decontamination: a narrative review of in vitro studies","Kamel, Khosa, Tawse-Smith, Leichter","https://doi.org/10.1007/s10103-013-1396-0","20160104","PubMed","Decontamination; Dental Implants; Humans; Inflammation; Laser Therapy; Lasers; Lasers, Semiconductor; Lasers, Solid-State; Low-Level Light Therapy; Prostheses and Implants; Titanium","The aim of this narrative review was to critically evaluate in vitro studies assessing the efficacy of lasers in the bacterial decontamination of titanium implant surfaces. The MEDLINE, Web of Knowledge and Embase electronic databases were used to search for articles relating to the use of lasers in the bacterial decontamination of titanium specimen surfaces using predetermined search statements. Clinical studies, case reports, case series, review articles and animal models were excluded. Study selection was carried out independently and then cross-checked by two authors through abstract viewing. Eighteen articles were selected for full-text analysis. Erbium-doped yttrium-aluminium-garnet lasers had a wide range of powers capable of inducing bacterial decontamination. While carbon dioxide and gallium-aluminium-arsenide diode lasers demonstrated the ability to produce bacterial decontamination, the bacterial sensitivity to each varied depending on the species involved. There is no concensus on the laser type or settings that are optimal for bacterial decontamination of titanium implant surfaces as studies employ various test specimens, contamination methodologies, irradiation settings and protocols, and outcome measures resulting in limited study comparability. More investigations are required to provide guidelines for the use of laser therapy in the decontamination of implant surfaces. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21797,""
"Syntactic parsing of clinical text: guideline and corpus development with handling ill-formed sentences","Fan, Yang, Jiang, Prasad, Loomis, Zisook, Denny, Xu, Huang","https://doi.org/10.1136/amiajnl-2013-001810","20131217","PubMed","annotation guidelines; corpus development; natural language processing; syntactic parsing; Electronic Health Records; Guidelines as Topic; Linguistics; Natural Language Processing","To develop, evaluate, and share: (1) syntactic parsing guidelines for clinical text, with a new approach to handling ill-formed sentences; and (2) a clinical Treebank annotated according to the guidelines. To document the process and findings for readers with similar interest. Using random samples from a shared natural language processing challenge dataset, we developed a handbook of domain-customized syntactic parsing guidelines based on iterative annotation and adjudication between two institutions. Special considerations were incorporated into the guidelines for handling ill-formed sentences, which are common in clinical text. Intra- and inter-annotator agreement rates were used to evaluate consistency in following the guidelines. Quantitative and qualitative properties of the annotated Treebank, as well as its use to retrain a statistical parser, were reported. A supplement to the Penn Treebank II guidelines was developed for annotating clinical sentences. After three iterations of annotation and adjudication on 450 sentences, the annotators reached an F-measure agreement rate of 0.930 (while intra-annotator rate was 0.948) on a final independent set. A total of 1100 sentences from progress notes were annotated that demonstrated domain-specific linguistic features. A statistical parser retrained with combined general English (mainly news text) annotations and our annotations achieved an accuracy of 0.811 (higher than models trained purely with either general or clinical sentences alone). Both the guidelines and syntactic annotations are made available at https://sourceforge.net/projects/medicaltreebank. We developed guidelines for parsing clinical text and annotated a corpus accordingly. The high intra- and inter-annotator agreement rates showed decent consistency in following the guidelines. The corpus was shown to be useful in retraining a statistical parser that achieved moderate accuracy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21798,""
"Effects of Tier 3 Intervention for Students With Persistent Reading Difficulties and Characteristics of Inadequate Responders","Denton, Tolar, Fletcher, Barth, Vaughn, Francis","https://doi.org/10.1037/a0032581","20211021","PubMed","Grade 2; reading difficulties; reading intervention; response to intervention","This article describes a randomized controlled trial conducted to evaluate the effects of an intensive, individualized, Tier 3 reading intervention for second grade students who had previously experienced inadequate response to quality first grade classroom reading instruction (Tier 1) and supplemental small-group intervention (Tier 2). Also evaluated were cognitive characteristics of students with inadequate response to intensive Tier 3 intervention. Students were randomized to receive the research intervention (<i>N</i> = 47) or the instruction and intervention typically provided in their schools (<i>N</i> = 25). Results indicated that students who received the research intervention made significantly better growth than those who received typical school instruction on measures of word identification, phonemic decoding, and word reading fluency and on a measure of sentence- and paragraph-level reading comprehension. Treatment effects were smaller and not statistically significant on phonemic decoding efficiency, text reading fluency, and reading comprehension in extended text. Effect sizes for all outcomes except oral reading fluency met criteria for substantive importance; however, many of the students in the intervention continued to struggle. An evaluation of cognitive profiles of adequate and inadequate responders was consistent with a continuum of severity (as opposed to qualitative differences), showing greater language and reading impairment prior to the intervention in students who were inadequate responders.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21799,""
"PREDOSE: a semantic web platform for drug abuse epidemiology using social media","Cameron, Smith, Daniulaityte, Sheth, Dave, Chen, Anand, Carlson, Watkins, Falck","https://doi.org/10.1016/j.jbi.2013.07.007","20140716","PubMed","Drug Abuse Ontology; Entity identification; Opiod abuse; Prescription drug abuse; Relationship extraction; Semantic web; Sentiment extraction; Social media; Triple extraction; Humans; Internet; Social Media; Substance-Related Disorders","The role of social media in biomedical knowledge mining, including clinical, medical and healthcare informatics, prescription drug abuse epidemiology and drug pharmacology, has become increasingly significant in recent years. Social media offers opportunities for people to share opinions and experiences freely in online communities, which may contribute information beyond the knowledge of domain professionals. This paper describes the development of a novel semantic web platform called PREDOSE (PREscription Drug abuse Online Surveillance and Epidemiology), which is designed to facilitate the epidemiologic study of prescription (and related) drug abuse practices using social media. PREDOSE uses web forum posts and domain knowledge, modeled in a manually created Drug Abuse Ontology (DAO--pronounced dow), to facilitate the extraction of semantic information from User Generated Content (UGC), through combination of lexical, pattern-based and semantics-based techniques. In a previous study, PREDOSE was used to obtain the datasets from which new knowledge in drug abuse research was derived. Here, we report on various platform enhancements, including an updated DAO, new components for relationship and triple extraction, and tools for content analysis, trend detection and emerging patterns exploration, which enhance the capabilities of the PREDOSE platform. Given these enhancements, PREDOSE is now more equipped to impact drug abuse research by alleviating traditional labor-intensive content analysis tasks. Using custom web crawlers that scrape UGC from publicly available web forums, PREDOSE first automates the collection of web-based social media content for subsequent semantic annotation. The annotation scheme is modeled in the DAO, and includes domain specific knowledge such as prescription (and related) drugs, methods of preparation, side effects, and routes of administration. The DAO is also used to help recognize three types of data, namely: (1) entities, (2) relationships and (3) triples. PREDOSE then uses a combination of lexical and semantic-based techniques to extract entities and relationships from the scraped content, and a top-down approach for triple extraction that uses patterns expressed in the DAO. In addition, PREDOSE uses publicly available lexicons to identify initial sentiment expressions in text, and then a probabilistic optimization algorithm (from related research) to extract the final sentiment expressions. Together, these techniques enable the capture of fine-grained semantic information, which facilitate search, trend analysis and overall content analysis using social media on prescription drug abuse. Moreover, extracted data are also made available to domain experts for the creation of training and test sets for use in evaluation and refinements in information extraction techniques. A recent evaluation of the information extraction techniques applied in the PREDOSE platform indicates 85% precision and 72% recall in entity identification, on a manually created gold standard dataset. In another study, PREDOSE achieved 36% precision in relationship identification and 33% precision in triple extraction, through manual evaluation by domain experts. Given the complexity of the relationship and triple extraction tasks and the abstruse nature of social media texts, we interpret these as favorable initial results. Extracted semantic information is currently in use in an online discovery support system, by prescription drug abuse researchers at the Center for Interventions, Treatment and Addictions Research (CITAR) at Wright State University. A comprehensive platform for entity, relationship, triple and sentiment extraction from such abstruse texts has never been developed for drug abuse research. PREDOSE has already demonstrated the importance of mining social media by providing data from which new findings in drug abuse research were uncovered. Given the recent platform enhancements, including the refined DAO, components for relationship and triple extraction, and tools for content, trend and emerging pattern analysis, it is expected that PREDOSE will play a significant role in advancing drug abuse epidemiology in future.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21800,""
"Automated selected reaction monitoring data analysis workflow for large-scale targeted proteomic studies","Surinova, HÃƒÂ¼ttenhain, Chang, Espona, Vitek, Aebersold","https://doi.org/10.1038/nprot.2013.091","20140224","PubMed","Biomarkers; Data Interpretation, Statistical; Electronic Data Processing; Female; Humans; Mass Spectrometry; Ovarian Neoplasms; Plasma; Proteomics; Software","Targeted proteomics based on selected reaction monitoring (SRM) mass spectrometry is commonly used for accurate and reproducible quantification of protein analytes in complex biological mixtures. Strictly hypothesis-driven, SRM assays quantify each targeted protein by collecting measurements on its peptide fragment ions, called transitions. To achieve sensitive and accurate quantitative results, experimental design and data analysis must consistently account for the variability of the quantified transitions. This consistency is especially important in large experiments, which increasingly require profiling up to hundreds of proteins over hundreds of samples. Here we describe a robust and automated workflow for the analysis of large quantitative SRM data sets that integrates data processing, statistical protein identification and quantification, and dissemination of the results. The integrated workflow combines three software tools: mProphet for peptide identification via probabilistic scoring; SRMstats for protein significance analysis with linear mixed-effect models; and PASSEL, a public repository for storage, retrieval and query of SRM data. The input requirements for the protocol are files with SRM traces in mzXML format, and a file with a list of transitions in a text tab-separated format. The protocol is especially suited for data with heavy isotope-labeled peptide internal standards. We demonstrate the protocol on a clinical data set in which the abundances of 35 biomarker candidates were profiled in 83 blood plasma samples of subjects with ovarian cancer or benign ovarian tumors. The time frame to realize the protocol is 1-2 weeks, depending on the number of replicates used in the experiment. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21801,""
"The therapeutic potential of small-conductance KCa2 channels in neurodegenerative and psychiatric diseases","Lam, Coleman, Garing, Wulff","https://doi.org/10.1517/14728222.2013.823161","20140407","PubMed","Animals; Humans; Membrane Transport Modulators; Mental Disorders; Neurodegenerative Diseases; Small-Conductance Calcium-Activated Potassium Channels","KCa2 or small-conductance Ca(2+)-activated K(+) channels (SK) are expressed in many areas of the central nervous system where they participate in the regulation of neuronal afterhyperpolarization and excitability, and also serve as negative feedback regulators on the glutamate-NMDA pathway. This review focuses on the role of KCa2 channels in learning and memory and their potential as therapeutic targets for Alzheimer's and Parkinson's disease, ataxia, schizophrenia and alcohol dependence. There currently exists relatively solid evidence supporting the use of KCa2 activators for ataxia. Genetic KCa2 channel suppression in deep cerebellar neurons induces ataxia, while KCa2 activators like 1-EBIO, SKA-31 and NS13001 improve motor deficits in mouse models of episodic ataxia (EA) and spinal cerebellar ataxia (SCA). Use of KCa2 activators for ataxia is further supported by a report that riluzole improves ataxia in a small clinical trial. Based on accumulating literature evidence, KCa2 activators further appear attractive for the treatment of alcohol dependence and withdrawal. Regarding Alzheimer's disease, Parkinson's disease and schizophrenia, further research, including long-term studies in disease relevant animal models, will be needed to determine whether KCa2 channels constitute valid targets and whether activators or inhibitors would be needed to positively affect disease outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21802,""
"Machine learning approaches to diagnosis and laterality effects in semantic dementia discourse","Garrard, Rentoumi, Gesierich, Miller, Gorno-Tempini","https://doi.org/10.1016/j.cortex.2013.05.008","20150115","PubMed","Discourse; Information gain; Laterality; Machine learning; Semantic dementia; Aged; Artificial Intelligence; Atrophy; Bayes Theorem; Case-Control Studies; Female; Frontotemporal Dementia; Functional Laterality; Humans; Magnetic Resonance Imaging; Male; Middle Aged; Speech Disorders; Statistics as Topic; Temporal Lobe; Vocabulary","Advances in automatic text classification have been necessitated by the rapid increase in the availability of digital documents. Machine learning (ML) algorithms can 'learn' from data: for instance a ML system can be trained on a set of features derived from written texts belonging to known categories, and learn to distinguish between them. Such a trained system can then be used to classify unseen texts. In this paper, we explore the potential of the technique to classify transcribed speech samples along clinical dimensions, using vocabulary data alone. We report the accuracy with which two related ML algorithms [naive Bayes Gaussian (NBG) and naive Bayes multinomial (NBM)] categorized picture descriptions produced by: 32 semantic dementia (SD) patients versus 10 healthy, age-matched controls; and SD patients with left- (nÃ‚Â =Ã‚Â 21) versus right-predominant (nÃ‚Â =Ã‚Â 11) patterns of temporal lobe atrophy. We used information gain (IG) to identify the vocabulary features that were most informative to each of these two distinctions. In the SD versus control classification task, both algorithms achieved accuracies of greater than 90%. In the right- versus left-temporal lobe predominant classification, NBM achieved a high level of accuracy (88%), but this was achieved by both NBM and NBG when the features used in the training set were restricted to those with high values of IG. The most informative features for the patient versus control task were low frequency content words, generic terms and components of metanarrative statements. For the right versus left task the number of informative lexical features was too small to support any specific inferences. An enriched feature set, including values derived from Quantitative Production Analysis (QPA) may shed further light on this little understood distinction. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21803,""
"Robotic pancreatic surgery is no substitute for experience and clinical judgment: an initial experience and literature review","Wayne, Steele, Iskandar, Cooperman","https://doi.org/10.1186/1477-7819-11-160","20150414","PubMed","Adult; Aged; Female; Humans; Judgment; Laparoscopy; Length of Stay; Male; Middle Aged; Pancreatectomy; Pancreatic Neoplasms; Robotics; Treatment Outcome","Robotic pancreatic surgery offers technical advantages, and has been applied across many surgical specialties. We report an initial experience of 12 distal pancreatic resections for benign tumors from an established pancreatic center with previous general and biliary laparoscopic experience. Of a total of 12 patients, 7 were women; the mean age was 55.5 years, and the lesions included 8 distal intraductal papillary mucinous tumors, 1 insulinoma and in 3 a non-functioning neuroendocrine tumor. All operations were performed in between 90 and 180 minutes, and blood loss and hospital stay were minimal.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21804,""
"Simultaneous EEG monitoring during transcranial direct current stimulation","Schestatsky, Morales-Quezada, Fregni","https://doi.org/10.3791/50426","20140326","PubMed","Electric Stimulation; Electroencephalography; Humans; Motor Cortex","Transcranial direct current stimulation (tDCS) is a technique that delivers weak electric currents through the scalp. This constant electric current induces shifts in neuronal membrane excitability, resulting in secondary changes in cortical activity. Although tDCS has most of its neuromodulatory effects on the underlying cortex, tDCS effects can also be observed in distant neural networks. Therefore, concomitant EEG monitoring of the effects of tDCS can provide valuable information on the mechanisms of tDCS. In addition, EEG findings can be an important surrogate marker for the effects of tDCS and thus can be used to optimize its parameters. This combined EEG-tDCS system can also be used for preventive treatment of neurological conditions characterized by abnormal peaks of cortical excitability, such as seizures. Such a system would be the basis of a non-invasive closed-loop device. In this article, we present a novel device that is capable of utilizing tDCS and EEG simultaneously. For that, we describe in a step-by-step fashion the main procedures of the application of this device using schematic figures, tables and video demonstrations. Additionally, we provide a literature review on clinical uses of tDCS and its cortical effects measured by EEG techniques. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21805,""
"Automated tissue characterization of in vivo atherosclerotic plaques by intravascular optical coherence tomography images","Ughi, Adriaenssens, Sinnaeve, Desmet, D'hooge","https://doi.org/10.1364/BOE.4.001014","20130712","PubMed","(100.0100) Image processing; (100.2960) Image analysis; (100.4995) Pattern recognition, metrics; (170.0170) Medical optics and biotechnology; (170.6935) Tissue characterization","Intravascular optical coherence tomography (IVOCT) is rapidly becoming the method of choice for the in vivo investigation of coronary artery disease. While IVOCT visualizes atherosclerotic plaques with a resolution &lt;20Ã‚Âµm, image analysis in terms of tissue composition is currently performed by a time-consuming manual procedure based on the qualitative interpretation of image features. We illustrate an algorithm for the automated and systematic characterization of IVOCT atherosclerotic tissue. The proposed method consists in a supervised classification of image pixels according to textural features combined with the estimated value of the optical attenuation coefficient. IVOCT images of 64 plaques, from 49 in vivo IVOCT data sets, constituted the algorithm's training and testing data sets. Validation was obtained by comparing automated analysis results to the manual assessment of atherosclerotic plaques. An overall pixel-wise accuracy of 81.5% with a classification feasibility of 76.5% and per-class accuracy of 89.5%, 72.1% and 79.5% for fibrotic, calcified and lipid-rich tissue respectively, was found. Moreover, measured optical properties were in agreement with previous results reported in literature. As such, an algorithm for automated tissue characterization was developed and validated using in vivo human data, suggesting that it can be applied to clinical IVOCT data. This might be an important step towards the integration of IVOCT in cardiovascular research and routine clinical practice. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21806,""
"Towards Converting Clinical Phrases into SNOMED CT Expressions","Kate","https://doi.org/10.4137/BII.S11645","20130712","PubMed","SNOMED CT; clinical phrases; natural language processing; relation identification","Converting information contained in natural language clinical text into computer-amenable structured representations can automate many clinical applications. As a step towards that goal, we present a method which could help in converting novel clinical phrases into new expressions in SNOMED CT, a standard clinical terminology. Since expressions in SNOMED CT are written in terms of their relations with other SNOMED CT concepts, we formulate the important task of identifying relations between clinical phrases and SNOMED CT concepts. We present a machine learning approach for this task and using the dataset of existing SNOMED CT relations we show that it performs well. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21807,""
"Analysis of cross-institutional medication description patterns in clinical narratives","Sohn, Clark, Halgrim, Murphy, Jonnalagadda, Wagholikar, Wu, Chute, Liu","https://doi.org/10.4137/BII.S11634","20130712","PubMed","electronic medical record; medication extraction; natural language processing","A large amount of medication information resides in the unstructured text found in electronic medical records, which requires advanced techniques to be properly mined. In clinical notes, medication information follows certain semantic patterns (eg, medication, dosage, frequency, and mode). Some medication descriptions contain additional word(s) between medication attributes. Therefore, it is essential to understand the semantic patterns as well as the patterns of the context interspersed among them (ie, context patterns) to effectively extract comprehensive medication information. In this paper we examined both semantic and context patterns, and compared those found in Mayo Clinic and i2b2 challenge data. We found that some variations exist between the institutions but the dominant patterns are common. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21808,""
"Semi-supervised clinical text classification with Laplacian SVMs: an application to cancer case management","Garla, Taylor, Brandt","https://doi.org/10.1016/j.jbi.2013.06.014","20140414","PubMed","Graph Laplacian; Natural language processing; Semi-supervised learning; Support vector machine; Algorithms; Case Management; Humans; Neoplasms; Support Vector Machine","To compare linear and Laplacian SVMs on a clinical text classification task; to evaluate the effect of unlabeled training data on Laplacian SVM performance. The development of machine-learning based clinical text classifiers requires the creation of labeled training data, obtained via manual review by clinicians. Due to the effort and expense involved in labeling data, training data sets in the clinical domain are of limited size. In contrast, electronic medical record (EMR) systems contain hundreds of thousands of unlabeled notes that are not used by supervised machine learning approaches. Semi-supervised learning algorithms use both labeled and unlabeled data to train classifiers, and can outperform their supervised counterparts. We trained support vector machines (SVMs) and Laplacian SVMs on a training reference standard of 820 abdominal CT, MRI, and ultrasound reports labeled for the presence of potentially malignant liver lesions that require follow up (positive class prevalence 77%). The Laplacian SVM used 19,845 randomly sampled unlabeled notes in addition to the training reference standard. We evaluated SVMs and Laplacian SVMs on a test set of 520 labeled reports. The Laplacian SVM trained on labeled and unlabeled radiology reports significantly outperformed supervised SVMs (Macro-F1 0.773 vs. 0.741, Sensitivity 0.943 vs. 0.911, Positive Predictive value 0.877 vs. 0.883). Performance improved with the number of labeled and unlabeled notes used to train the Laplacian SVM (pearson's ÃÂ=0.529 for correlation between number of unlabeled notes and macro-F1 score). These results suggest that practical semi-supervised methods such as the Laplacian SVM can leverage the large, unlabeled corpora that reside within EMRs to improve clinical text classification.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21809,""
"Development and evaluation of a de-identification procedure for a case register sourced from mental health electronic records","Fernandes, Cloete, Broadbent, Hayes, Chang, Jackson, Roberts, Tsang, Soncul, Liebscher, Stewart, Callard","https://doi.org/10.1186/1472-6947-13-71","20140317","PubMed","Algorithms; Computer Security; Electronic Data Processing; Electronic Health Records; Health Services Research; Humans; London; Mental Health Services; Program Development; Registries; Reproducibility of Results; Systems Integration","Electronic health records (EHRs) provide enormous potential for health research but also present data governance challenges. Ensuring de-identification is a pre-requisite for use of EHR data without prior consent. The South London and Maudsley NHS Trust (SLaM), one of the largest secondary mental healthcare providers in Europe, has developed, from its EHRs, a de-identified psychiatric case register, the Clinical Record Interactive Search (CRIS), for secondary research. We describe development, implementation and evaluation of a bespoke de-identification algorithm used to create the register. It is designed to create dictionaries using patient identifiers (PIs) entered into dedicated source fields and then identify, match and mask them (with ZZZZZ) when they appear in medical texts. We deemed this approach would be effective, given high coverage of PI in the dedicated fields and the effectiveness of the masking combined with elements of a security model. We conducted two separate performance tests i) to test performance of the algorithm in masking individual true PIs entered in dedicated fields and then found in text (using 500 patient notes) and ii) to compare the performance of the CRIS pattern matching algorithm with a machine learning algorithm, called the MITRE Identification Scrubber Toolkit - MIST (using 70 patient notes - 50 notes to train, 20 notes to test on). We also report any incidences of potential breaches, defined by occurrences of 3 or more true or apparent PIs in the same patient's notes (and in an additional set of longitudinal notes for 50 patients); and we consider the possibility of inferring information despite de-identification. True PIs were masked with 98.8% precision and 97.6% recall. As anticipated, potential PIs did appear, owing to misspellings entered within the EHRs. We found one potential breach. In a separate performance test, with a different set of notes, CRIS yielded 100% precision and 88.5% recall, while MIST yielded a 95.1% and 78.1%, respectively. We discuss how we overcome the realistic possibility - albeit of low probability - of potential breaches through implementation of the security model. CRIS is a de-identified psychiatric database sourced from EHRs, which protects patient anonymity and maximises data available for research. CRIS demonstrates the advantage of combining an effective de-identification algorithm with a carefully designed security model. The paper advances much needed discussion of EHR de-identification - particularly in relation to criteria to assess de-identification, and considering the contexts of de-identified research databases when assessing the risk of breaches of confidential patient information.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21810,""
"Managing the data deluge: data-driven GO category assignment improves while complexity of functional annotation increases","Gobeill, Pasche, Vishnyakova, Ruch","https://doi.org/10.1093/database/bat041","20131021","PubMed","Algorithms; Data Mining; Databases, Genetic; Knowledge Bases; Molecular Sequence Annotation","The available curated data lag behind current biological knowledge contained in the literature. Text mining can assist biologists and curators to locate and access this knowledge, for instance by characterizing the functional profile of publications. Gene Ontology (GO) category assignment in free text already supports various applications, such as powering ontology-based search engines, finding curation-relevant articles (triage) or helping the curator to identify and encode functions. Popular text mining tools for GO classification are based on so called thesaurus-based--or dictionary-based--approaches, which exploit similarities between the input text and GO terms themselves. But their effectiveness remains limited owing to the complex nature of GO terms, which rarely occur in text. In contrast, machine learning approaches exploit similarities between the input text and already curated instances contained in a knowledge base to infer a functional profile. GO Annotations (GOA) and MEDLINE make possible to exploit a growing amount of curated abstracts (97 000 in November 2012) for populating this knowledge base. Our study compares a state-of-the-art thesaurus-based system with a machine learning system (based on a k-Nearest Neighbours algorithm) for the task of proposing a functional profile for unseen MEDLINE abstracts, and shows how resources and performances have evolved. Systems are evaluated on their ability to propose for a given abstract the GO terms (2.8 on average) used for curation in GOA. We show that since 2006, although a massive effort was put into adding synonyms in GO (+300%), our thesaurus-based system effectiveness is rather constant, reaching from 0.28 to 0.31 for Recall at 20 (R20). In contrast, thanks to its knowledge base growth, our machine learning system has steadily improved, reaching from 0.38 in 2006 to 0.56 for R20 in 2012. Integrated in semi-automatic workflows or in fully automatic pipelines, such systems are more and more efficient to provide assistance to biologists. DATABASE URL: http://eagl.unige.ch/GOCat/","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21811,""
"Immediate loading of overdentures: systematic review","Goiato, Bannwart, Pesqueira, Santos, Haddad, Santos, Castilho","https://doi.org/10.1007/s10006-013-0421-6","20160831","PubMed","Bone-Implant Interface; Dental Prosthesis, Implant-Supported; Denture, Overlay; Humans; Immediate Dental Implant Loading; Jaw, Edentulous; Osseointegration; Survival Analysis","The goal of implant treatment is the formation of a direct bone-implant interface contact. This study aimed to evaluate the possibilities of immediate loading treatment for edentulous patients rehabilitated with mandibular and maxillary overdentures. A literature review using the PubMed and BIREME databases between the periods of 1977 and 2011 was performed. From an initial yield of 218 titles, 78 articles were selected for text analysis, finally resulting in 23 studies (16 prospective, 6 prospective randomized, and 1 prospective multicenter) that met the inclusion criteria. The immediate loading protocol through which the implants are subjected to occlusal function immediately after their placement was introduced to overcome this limitation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21812,""
"Functional assessment and performance evaluation for assistive robotic manipulators: Literature review","Chung, Wang, Cooper","https://doi.org/10.1179/2045772313Y.0000000132","20130917","PubMed","Activities of Daily Living; Clinical Trials as Topic; Databases, Factual; Disabled Persons; Humans; Outcome Assessment, Health Care; Robotics","The user interface development of assistive robotic manipulators can be traced back to the 1960s. Studies include kinematic designs, cost-efficiency, user experience involvements, and performance evaluation. This paper is to review studies conducted with clinical trials using activities of daily living (ADLs) tasks to evaluate performance categorized using the International Classification of Functioning, Disability, and Health (ICF) frameworks, in order to give the scope of current research and provide suggestions for future studies. We conducted a literature search of assistive robotic manipulators from 1970 to 2012 in PubMed, Google Scholar, and University of Pittsburgh Library System - PITTCat. Twenty relevant studies were identified. Studies were separated into two broad categories: user task preferences and user-interface performance measurements of commercialized and developing assistive robotic manipulators. The outcome measures and ICF codes associated with the performance evaluations are reported. Suggestions for the future studies include (1) standardized ADL tasks for the quantitative and qualitative evaluation of task efficiency and performance to build comparable measures between research groups, (2) studies relevant to the tasks from user priority lists and ICF codes, and (3) appropriate clinical functional assessment tests with consideration of constraints in assistive robotic manipulator user interfaces. In addition, these outcome measures will help physicians and therapists build standardized tools while prescribing and assessing assistive robotic manipulators.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21813,""
"Prediction of the origin of French Legionella pneumophila strains using a mixed-genome microarray","Den Boer, Euser, Nagelkerke, Schuren, Jarraud, Etienne","https://doi.org/10.1186/1471-2164-14-435","20131030","PubMed","Environment; France; Genetic Markers; Genome, Bacterial; Genomics; Humans; Legionella pneumophila; Oligonucleotide Array Sequence Analysis","Legionella is a water and soil bacterium that can infect humans, causing a pneumonia known as Legionnaires' disease. The pneumonia is almost exclusively caused by the species L. pneumophila, of which serogroup 1 is responsible for 90% of patients. Within serogroup 1, large differences in prevalence in clinical isolates have been described. A recent study, using a Dutch Legionella strain collection, identified five virulence associated markers. In our study, we verify whether these five Dutch markers can predict the patient or environmental origin of a French Legionella strain collection. In addition, we identify new potential virulence markers and verify whether these can predict better. A total of 219 French patient isolates and environmental strains were compared using a mixed-genome micro-array. The micro-array data were analysed to identify predictive markers, using a Random Forest algorithm combined with a logistic regression model. The sequences of the identified markers were compared with eleven known Legionella genomes, using BlastN and BlastX; the functionality for each of the predictive markers was checked in the literature. The five Dutch markers insufficiently predicted the patient or environmental origin of the French Legionella strains. Subsequent analyses identified four predictive markers for the French collection that were used for the logistic regression model. This model showed a negative predictive value of 91%. Three of the French markers differed from the Dutch markers, one showed considerable overlap and was found in one of the Legionella genomes (Lorraine strain). This marker encodes for a structural toxin protein RtxA, described for L. pneumophila as a factor involved in virulence and entry in both human cells and amoebae. The combination of a mixed-genome micro-array and statistical analysis using a Random Forest algorithm has identified virulence markers in a consistent way. The Lorraine strain and related Dutch and French Legionella strains contain a marker that encodes a RtxA protein which probably is involved in the increased prevalence in clinical isolates. The current set of predictive markers is insufficient to justify its use as a reliable test in the public health field in France. Our results suggest that genetic differences in Legionella strains exist between geographically distinct entities. It may be necessary to develop region-specific mixed-genome microarrays that are constantly adapted and updated.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21814,""
"Automated grading system for evaluation of ocular redness associated with dry eye","Rodriguez, Johnston, Ousler, Smith, Abelson","https://doi.org/10.2147/OPTH.S39703","20130702","PubMed","classification; computer-assisted; conjunctival diseases; diagnosis; humans; hyperemia; image processing; keratoconjunctivitis sicca; observer variation","We have observed that dry eye redness is characterized by a prominence of fine horizontal conjunctival vessels in the exposed ocular surface of the interpalpebral fissure, and have incorporated this feature into the grading of redness in clinical studies of dry eye. To develop an automated method of grading dry eye-associated ocular redness in order to expand on the clinical grading system currently used. Ninety nine images from 26 dry eye subjects were evaluated by five graders using a 0-4 (in 0.5 increments) dry eye redness (Ora CalibraÃ¢â€žÂ¢ Dry Eye Redness Scale [OCDER]) scale. For the automated method, the Opencv computer vision library was used to develop software for calculating redness and horizontal conjunctival vessels (noted as ""horizontality""). From original photograph, the region of interest (ROI) was selected manually using the open source ImageJ software. Total average redness intensity (Com-Red) was calculated as a single channel 8-bit image as R - 0.83G - 0.17B, where R, G and B were the respective intensities of the red, green and blue channels. The location of vessels was detected by normalizing the blue channel and selecting pixels with an intensity of less than 97% of the mean. The horizontal component (Com-Hor) was calculated by the first order Sobel derivative in the vertical direction and the score was calculated as the average blue channel image intensity of this vertical derivative. Pearson correlation coefficients, accuracy and concordance correlation coefficients (CCC) were calculated after regression and standardized regression of the dataset. The agreement (both Pearson's and CCC) among investigators using the OCDER scale was 0.67, while the agreement of investigator to computer was 0.76. A multiple regression using both redness and horizontality improved the agreement CCC from 0.66 and 0.69 to 0.76, demonstrating the contribution of vessel geometry to the overall grade. Computer analysis of a given image has 100% repeatability and zero variability from session to session. This objective means of grading ocular redness in a unified fashion has potential significance as a new clinical endpoint. In comparisons between computer and investigator, computer grading proved to be more reliable than another investigator using the OCDER scale. The best fitting model based on the present sample, and usable for future studies, was [Formula: see text] is the predicted investigator grade, and [Formula: see text] and [Formula: see text] are logarithmic transformations of the computer calculated parameters COM-Hor and COM-Red. Considering the superior repeatability, computer automated grading might be preferable to investigator grading in multicentered dry eye studies in which the subtle differences in redness incurred by treatment have been historically difficult to define.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21815,""
"A sense inventory for clinical abbreviations and acronyms created using clinical notes and medical dictionary resources","Moon, Pakhomov, Liu, Ryan, Melton","https://doi.org/10.1136/amiajnl-2012-001506","20140529","PubMed","Abbreviations as Topic*; Clinical sense inventory; Medical Records*; Natural Language Processing*; Word sense disambiguation; Abbreviations as Topic; Adolescent; Adult; Aged; Aged, 80 and over; Child; Dictionaries, Medical as Topic; Female; Humans; MEDLINE; Male; Medical Records; Middle Aged; Natural Language Processing; Unified Medical Language System; Young Adult","To create a sense inventory of abbreviations and acronyms from clinical texts. The most frequently occurring abbreviations and acronyms from 352,267 dictated clinical notes were used to create a clinical sense inventory. Senses of each abbreviation and acronym were manually annotated from 500 random instances and lexically matched with long forms within the Unified Medical Language System (UMLS V.2011AB), Another Database of Abbreviations in Medline (ADAM), and Stedman's Dictionary, Medical Abbreviations, Acronyms &amp; Symbols, 4th edition (Stedman's). Redundant long forms were merged after they were lexically normalized using Lexical Variant Generation (LVG). The clinical sense inventory was found to have skewed sense distributions, practice-specific senses, and incorrect uses. Of 440 abbreviations and acronyms analyzed in this study, 949 long forms were identified in clinical notes. This set was mapped to 17,359, 5233, and 4879 long forms in UMLS, ADAM, and Stedman's, respectively. After merging long forms, only 2.3% matched across all medical resources. The UMLS, ADAM, and Stedman's covered 5.7%, 8.4%, and 11% of the merged clinical long forms, respectively. The sense inventory of clinical abbreviations and acronyms and anonymized datasets generated from this study are available for public use at http://www.bmhi.umn.edu/ihi/research/nlpie/resources/index.htm ('Sense Inventories', website). Clinical sense inventories of abbreviations and acronyms created using clinical notes and medical dictionary resources demonstrate challenges with term coverage and resource integration. Further work is needed to help with standardizing abbreviations and acronyms in clinical care and biomedicine to facilitate automated processes such as text-mining and information extraction.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21816,""
"Robot-assisted and fluoroscopy-guided pedicle screw placement: a systematic review","Marcus, Cundy, Nandi, Yang, Darzi","https://doi.org/10.1007/s00586-013-2879-1","20150127","PubMed","Fluoroscopy; Humans; Pedicle Screws; Robotic Surgical Procedures; Spinal Fusion","At present, most spinal surgeons undertake pedicle screw implantation using either anatomical landmarks or C-arm fluoroscopy. Reported rates of screw malposition using these techniques vary considerably, though the evidence generally favors the use of image-guidance systems. A miniature spine-mounted robot has recently been developed to further improve the accuracy of pedicle screw placement. In this systematic review, we critically appraise the perceived benefits of robot-assisted pedicle screw placement compared to conventional fluoroscopy-guided technique. The Cochrane Central Register of Controlled Trials, PubMed, and EMBASE databases were searched between January 2006 and January 2013 to identify relevant publications that (1) featured placement of pedicle screws, (2) compared robot-assisted and fluoroscopy-guided surgery, (3) assessed outcome in terms of pedicle screw position, and (4) present sufficient data in each arm to enable meaningful comparison (&gt;10 pedicle screws in each study group). A total of 246 articles were retrieved, of which 5 articles met inclusion criteria, collectively reporting placement of 1,308 pedicle screws (729 robot-assisted, 579 fluoroscopy-guided). The findings of these studies are mixed, with limited higher level of evidence data favoring fluoroscopy-guided procedures, and remaining comparative studies supporting robot-assisted pedicle screw placement. There is insufficient evidence to unequivocally recommend one surgical technique over the other. Given the high cost of robotic systems, and the high risk of spinal surgery, further high quality studies are required to address unresolved clinical equipoise in this field.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21817,""
"Understanding the acceptability of a computer decision support system in pediatric primary care","Bauer, Carroll, Downs","https://doi.org/10.1136/amiajnl-2013-001851","20140206","PubMed","Clinical guidelines; Computer-based decision support; Pediatrics; Primary care; Attitude of Health Personnel; Attitude to Computers; Data Collection; Decision Support Systems, Clinical; Electronic Health Records; Humans; Pediatrics; Primary Health Care; User-Computer Interface","Individual users' attitudes and opinions help predict successful adoption of health information technology (HIT) into practice; however, little is known about pediatric users' acceptance of HIT for medical decision-making at the point of care. We wished to examine the attitudes and opinions of pediatric users' toward the Child Health Improvement through Computer Automation (CHICA) system, a computer decision support system linked to an electronic health record in four community pediatric clinics. Surveys were administered in 2011 and 2012 to all users to measure CHICA's acceptability and users' satisfaction with it. Free text comments were analyzed for themes to understand areas of potential technical refinement. 70 participants completed the survey in 2011 (100% response rate) and 64 of 66 (97% response rate) in 2012. Initially, satisfaction with CHICA was mixed. In general, users felt the system held promise; however various critiques reflected difficulties understanding integrated technical aspects of how CHICA worked, as well as concern with the format and wording on generated forms for families and users. In the subsequent year, users' ratings reflected improved satisfaction and acceptance. Comments also reflected a deeper understanding of the system's logic, often accompanied by suggestions on potential refinements to make CHICA more useful at the point of care. Pediatric users appreciate the system's automation and enhancements that allow relevant and meaningful clinical data to be accessible at point of care. Understanding users' acceptability and satisfaction is critical for ongoing refinement of HIT to ensure successful adoption into practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21818,""
"Systematic identification of DNA variants associated with ultraviolet radiation using a novel Geographic-Wide Association Study (GeoWAS)","Hsu, Chen, Ramesh, Corona, Kang, Ruau, Butte","https://doi.org/10.1186/1471-2350-14-62","20130722","PubMed","Antigens, Neoplasm; Continental Population Groups; Databases, Genetic; Early Detection of Cancer; Gene Frequency; Genetic Association Studies; Genetics, Population; Genome, Human; Geography; Humans; Melanoma; Membrane Transport Proteins; Phenotype; Polymorphism, Single Nucleotide; Risk Factors; Selection, Genetic; Ultraviolet Rays; Vitamin D","Long-term environmental variables are widely understood to play important roles in DNA variation. Previously, clinical studies examining the impacts of these variables on the human genome were localized to a single country, and used preselected DNA variants. Furthermore, clinical studies or surveys are either not available or difficult to carry out for developing countries. A systematic approach utilizing bioinformatics to identify associations among environmental variables, genetic variation, and diseases across various geographical locations is needed but has been lacking. Using a novel Geographic-Wide Association Study (GeoWAS) methodology, we identified Single Nucleotide Polymorphisms (SNPs) in the Human Genome Diversity Project (HGDP) with population allele frequencies associated geographical ultraviolet radiation exposure, and then assessed the diseases known to be assigned with these SNPs. 2,857 radiation SNPs were identified from over 650,000 SNPs in 52 indigenous populations across the world. Using a quantitative disease-SNP database curated from 5,065 human genetic papers, we identified disease associations with those radiation SNPs. The correlation of the rs16891982 SNP in the SLC45A2 gene with melanoma was used as a case study for analysis of disease risk, and the results were consistent with the incidence and mortality rates of melanoma in published scientific literature. Finally, by analyzing the ontology of genes in which the radiation SNPs were significantly enriched, potential associations between SNPs and neurological disorders such as Alzheimer's disease were hypothesized. A systematic approach using GeoWAS has enabled us to identify DNA variation associated with ultraviolet radiation and their connections to diseases such as skin cancers. Our analyses have led to a better understating at the genetic level of why certain diseases are more predominant in specific geographical locations, due to the interactions between environmental variables such as ultraviolet radiation and the population types in those regions. The hypotheses proposed in GeoWAS can lead to future testing and interdisciplinary research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21819,""
"Corneal biomechanics in iatrogenic ectasia and keratoconus: A review of the literature","Moshirfar, Edmonds, Behunin, Christiansen","https://doi.org/10.4103/0974-620X.111895","20130618","PubMed","Corneal hysteresis; corneal deformation signal waveform analysis; corneal resistance factor; keratoconus; keratoectasia; ocular response analyzer","The Ocular Response Analyzer (ORA) (Reichert Ophthalmic Instruments, Buffalo, NY) allows direct measurement of corneal biomechanical properties. Since its introduction, many studies have sought to elucidate the clinical applications of corneal hysteresis (CH) and corneal resistance factor (CRF). More recently, detailed corneal deformation signal waveform analysis (WA) has potentially expanded the diagnostic capabilities of the ORA. In this review, the role of CH, CRF, and WA are examined in keratoconus (KC) and iatrogenic ectasia (IE). The PubMed database was searched electronically for peer-reviewed literature in July 2012 and August 2012 without date restrictions. The search strategy included medical subject heading (MeSH) and natural language terms to retrieve references on corneal biomechanics, CH, CRF, corneal deformation signal WA, IE, and KC. The evidence suggests that while CH and CRF are poor screening tools when used alone, increased sensitivity and specificity of KC and IE screening result when these parameters are combined with tomography and topography. Recent advances in WA are promising, but little is currently understood about its biomechanical and clinical relevance. Future studies should seek to refine the screening protocols for KC and IE as well as define the clinical applicability of WA parameters.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21820,""
"Automatic hippocampus segmentation of 70 Tesla MR images by combining multiple atlases and auto-context models","Kim, Wu, Li, Wang, Son, Cho, Shen","https://doi.org/10.1016/j.neuroimage.2013.06.006","20141218","PubMed","7.0T MRI; Auto-context model; Automatic hippocampus segmentation; Label fusion; Multiple atlases based segmentation; Adult; Algorithms; Artificial Intelligence; Computer Simulation; Female; Hippocampus; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Male; Models, Anatomic; Models, Neurological; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique","In many neuroscience and clinical studies, accurate measurement of hippocampus is very important to reveal the inter-subject anatomical differences or the subtle intra-subject longitudinal changes due to aging or dementia. Although many automatic segmentation methods have been developed, their performances are still challenged by the poor image contrast of hippocampus in the MR images acquired especially from 1.5 or 3.0 Tesla (T) scanners. With the recent advance of imaging technology, 7.0 T scanner provides much higher image contrast and resolution for hippocampus study. However, the previous methods developed for segmentation of hippocampus from 1.5 T or 3.0 T images do not work for the 7.0 T images, due to different levels of imaging contrast and texture information. In this paper, we present a learning-based algorithm for automatic segmentation of hippocampi from 7.0 T images, by taking advantages of the state-of-the-art multi-atlas framework and also the auto-context model (ACM). Specifically, ACM is performed in each atlas domain to iteratively construct sequences of location-adaptive classifiers by integrating both image appearance and local context features. Due to the plenty texture information in 7.0 T images, more advanced texture features are also extracted and incorporated into the ACM during the training stage. Then, under the multi-atlas segmentation framework, multiple sequences of ACM-based classifiers are trained for all atlases to incorporate the anatomical variability. In the application stage, for a new image, its hippocampus segmentation can be achieved by fusing the labeling results from all atlases, each of which is obtained by applying the atlas-specific ACM-based classifiers. Experimental results on twenty 7.0 T images with the voxel size of 0.35Ãƒâ€”0.35Ãƒâ€”0.35 mm3 show very promising hippocampus segmentations (in terms of Dice overlap ratio 89.1Ã‚Â±0.020), indicating high applicability for the future clinical and neuroscience studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21821,""
"Automated classification of limb fractures from free-text radiology reports using a clinician-informed gazetteer methodology","Wagholikar, Zuccon, Nguyen, Chu, Martin, Lai, Greenslade","https://doi.org/10.4066/AMJ.2013.1651","20130610","PubMed","Limb fractures; classification; emergency department; machine learning; radiology reports; rule-based method","Timely diagnosis and reporting of patient symptoms in hospital emergency departments (ED) is a critical component of health services delivery. However, due to dispersed information resources and a vast amount of manual processing of unstructured information, accurate point-of-care diagnosis is often difficult. The aim of this research is to report initial experimental evaluation of a clinician-informed automated method for the issue of initial misdiagnoses associated with delayed receipt of unstructured radiology reports. A method was developed that resembles clinical reasoning for identifying limb abnormalities. The method consists of a gazetteer of keywords related to radiological findings; the method classifies an X-ray report as abnormal if it contains evidence contained in the gazetteer. A set of 99 narrative reports of radiological findings was sourced from a tertiary hospital. Reports were manually assessed by two clinicians and discrepancies were validated by a third expert ED clinician; the final manual classification generated by the expert ED clinician was used as ground truth to empirically evaluate the approach. The automated method that attempts to individuate limb abnormalities by searching for keywords expressed by clinicians achieved an F-measure of 0.80 and an accuracy of 0.80. While the automated clinician-driven method achieved promising performances, a number of avenues for improvement were identified using advanced natural language processing (NLP) and machine learning techniques.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21822,""
"Laparoendoscopic single-site surgery in kidney surgery: clinical experience and future perspectives","Kallidonis, Kontogiannis, Kyriazis, Georgiopoulos, Al-Aown, Stolzenburg, Liatsikos","https://doi.org/10.1007/s11934-013-0346-5","20140612","PubMed","Equipment Design; Forecasting; Humans; Kidney Diseases; Laparoscopes; Laparoscopy; Nephrectomy; Reproducibility of Results; Robotics","Laparoscopic surgery of the upper urinary tract has reduced the morbidity related to large abdominal incisions and has resulted in significant advantages over open surgery. Nevertheless, the pursuit for even more minimally invasive alternatives to laparoscopy has led to the concept of scarless surgery and the approach of laparoendoscopic single-site surgery (LESS). LESS is currently a feasible approach for the majority of kidney surgical procedures, and there is intense debate regarding its efficiency and advantages. In the present review of the literature, the current status of upper urinary LESS and its advantages and disadvantages, as well the technological and technical evolution, are presented. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21823,""
"[Prevention and management of complications in Descemet membrane endothelial keratoplasty (DMEK) and Descemet stripping automated endothelial keratoplasty (DSAEK)]","Cursiefen, Steven, Roters, Heindl","https://doi.org/10.1007/s00347-012-2679-8","20140310","PubMed","Corneal Diseases; Descemet Stripping Endothelial Keratoplasty; Humans; Postoperative Complications","Posterior lamellar keratoplasty, in the form of Descemet membrane endothelial keratoplasty (DMEK) and Descemet stripping automated endothelial keratoplasty (DSAEK), has become a standard procedure for therapy of endothelial diseases of the cornea. The aim of this article is to describe strategies to prevent and manage complications in DMEK and DSAEK surgery. The article is based on a PubMed literature search and own clinical data. Key words used were ""DMEK"", ""DSAEK"", ""Descemet membrane endothelial keratoplasty"" and ""Descemet stripping automated endothelial keratoplasty"". The DMEK and DSAEK procedures are safe surgical strategies for treating endothelial corneal diseases if the indications are made correctly. The DMEK procedure is the standard procedure for improvement of visual acuity especially for younger patients with Fuchs' dystrophy and DSAEK is particularly suitable for eyes with complicated anterior chamber situations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21824,""
"NCBO Technology: Powering semantically aware applications","Whetzel","https://doi.org/10.1186/2041-1480-4-S1-S8","20130606","PubMed","","As new biomedical technologies are developed, the amount of publically available biomedical data continues to increase. To help manage these vast and disparate data sources, researchers have turned to the Semantic Web. Specifically, ontologies are used in data annotation, natural language processing, information retrieval, clinical decision support, and data integration tasks. The development of software applications to perform these tasks requires the integration of Web services to incorporate the wide variety of ontologies used in the health care and life sciences. The National Center for Biomedical Ontology, a National Center for Biomedical Computing created under the NIH Roadmap, developed BioPortal, which provides access to one of the largest repositories of biomedical ontologies. The NCBO Web services provide programmtic access to these ontologies and can be grouped into four categories; Ontology, Mapping, Annotation, and Data Access. The Ontology Web services provide access to ontologies, their metadata, ontology versions, downloads, navigation of the class hierarchy (parents, children, siblings) and details of each term. The Mapping Web services provide access to the millions of ontology mappings published in BioPortal. The NCBO Annotator Web service ""tags"" text automatically with terms from ontologies in BioPortal, and the NCBO Resource Index Web services provides access to an ontology-based index of public, online data resources. The NCBO Widgets package the Ontology Web services for use directly in Web sites. The functionality of the NCBO Web services and widgets are incorporated into semantically aware applications for ontology development and visualization, data annotation, and data integration. This overview will describe these classes of applications, discuss a few examples of each type, and which NCBO Web services are used by these applications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21825,""
"Open-source surface mesh-based ultrasound-guided spinal intervention simulator","Bartha, Lasso, Pinter, Ungi, Keri, Fichtinger","https://doi.org/10.1007/s11548-013-0901-z","20141029","PubMed","Computer Simulation; Humans; Models, Anatomic; Spine; Surgery, Computer-Assisted; Ultrasonography, Interventional","Ã‚Â Ã‚Â Ã‚Â Ultrasound is prevalent in image-guided therapy as a safe, inexpensive, and widely available imaging modality. However, extensive training in interpreting ultrasound images is essential for successful procedures. An open-source ultrasound image simulator was developed to facilitate the training of ultrasound-guided spinal intervention procedures, thereby eliminating the need for an ultrasound machine from the phantom-based training environment. Ã‚Â Ã‚Â Ã‚Â Anatomical structures and surgical tools are converted to surface meshes for data compression. Anatomical data are converted from segmented volumetric images, while the geometry of surgical tools is available as a surface mesh. The pose of the objects are either constants or coming from a pose-tracking device. Intersection points between the surface models and the ultrasound scan lines are determined with a binary space partitioning tree. The scan lines are divided into segments and filled with gray values determined by an intensity calculation accounting for material properties, reflection, and attenuation parameters defined in a configuration file. The scan lines are finally converted to a regular brightness-mode ultrasound image. Ã‚Â Ã‚Â Ã‚Â The simulator was tested in a tracked ultrasound imaging system, with a mock transducer tracked with an Ascension trakSTAR electromagnetic tracker, on a spine phantom. A mesh model of the spine was created from CT data. The simulated ultrasound images were generated at a speed of 50 frames per second, and a resolution of [Formula: see text] pixels, with 256 scan lines per frame, on a PC with a 3.4Ã‚Â GHz processor. A human subject trial was conducted to compare the learning performance of novice trainees, with real and simulated ultrasound, in the localization of facet joints of a spine phantom. With 22 participants split into two equal groups, and each participant localizing 6 facet joints, there was no statistical difference in the performance of the two groups, indicating that simulated ultrasound could indeed replace the real ultrasound in phantom-based ultrasonography training for spinal interventions. Ã‚Â Ã‚Â Ã‚Â The ultrasound simulator was implemented and integrated into the open-source Public Library for Ultrasound (PLUS) toolkit.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21826,""
"Occupational injury among migrant workers in China: a systematic review","Fitzgerald, Chen, Qu, Sheff","https://doi.org/10.1136/injuryprev-2012-040578","20140318","PubMed","China; Emigrants and Immigrants; Humans; Occupational Health; Occupational Injuries; Preventive Health Services; Public Health Surveillance","This review considers the state of occupational injury surveillance and prevention among migrant workers in China and suggests areas of focus for future research on the topic. Bibliographic databases were searched for qualitative and quantitative studies on surveillance of and interventions to prevent occupational injury among migrant workers in mainland China. Additional abstracts were identified from the citations of relevant articles from the database search. Studies fitting the inclusion criteria were evaluated, and findings were extracted and summarised. The search uncovered 726 studies in the English-language databases searched, and 3109 in the Chinese database. This article analyses a total of 19 research articles that fit the inclusion criteria with qualitative or quantitative data on occupational injury surveillance and prevention of migrant workers in China. Despite evidence of the vulnerability of migrant workers in the workplace, there is little systematic surveillance of occupational injury and few evaluated interventions. Migrant workers account for a disproportionate burden of occupational injury morbidity and mortality in China. However, data are inconsistent and inadequate to detail injury incidence or to evaluate interventions. The following are suggestions to decrease injury incidence among migrants: strengthen the national system of occupational injury surveillance; focus surveillance and interventions on high-risk occupations employing migrants such as construction, manufacturing and small mining operations; improve occupational safety training and access to appropriate safety equipment; evaluate recent changes in occupational health and safety and evaluate outcome of multi-party interventions to reduce occupational injury among migrant workers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21827,""
"Differentiation of pancreatic cancer and chronic pancreatitis using computer-aided diagnosis of endoscopic ultrasound (EUS) images: a diagnostic test","Zhu, Xu, Yu, Wu, Li, Zhang, Jin, Li","https://doi.org/10.1371/journal.pone.0063820","20131230","PubMed","Algorithms; Diagnosis, Computer-Assisted; Diagnosis, Differential; Diagnostic Tests, Routine; Endosonography; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Pancreatic Neoplasms; Pancreatitis, Chronic","Differentiating pancreatic cancer (PC) from normal tissue by computer-aided diagnosis of EUS images were quite useful. The current study was designed to investigate the feasibility of using computer-aided diagnostic (CAD) techniques to extract EUS image parameters for the differential diagnosis of PC and chronic pancreatitis (CP). This study recruited 262 patients with PC and 126 patients with CP. Typical EUS images were selected from the sample sets. Texture features were extracted from the region of interest using computer-based techniques. Then the distance between class algorithm and sequential forward selection (SFS) algorithm were used for a better combination of features; and, later, a support vector machine (SVM) predictive model was built, trained, and validated. Overall, 105 features of 9 categories were extracted from the EUS images for pattern classification. Of these features, the 16 were selected as a better combination of features. Then, SVM predictive model was built and trained. The total cases were randomly divided into a training set and a testing set. The training set was used to train the SVM, and the testing set was used to evaluate the performance of the SVM. After 200 trials of randomised experiments, the average accuracy, sensitivity, specificity, the positive and negative predictive values of pancreatic cancer were 94.2Ã‚Â±0.1749%,96.25Ã‚Â±0.4460%, 93.38Ã‚Â±0.2076%, 92.21Ã‚Â±0.4249% and 96.68Ã‚Â±0.1471%, respectively. Digital image processing and computer-aided EUS image differentiation technologies are highly accurate and non-invasive. This technology provides a kind of new and valuable diagnostic tool for the clinical determination of PC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21828,""
"Dictionary construction and identification of possible adverse drug events in Danish clinical narrative text","Eriksson, Jensen, Frankild, Jensen, Brunak","https://doi.org/10.1136/amiajnl-2013-001708","20131217","PubMed","Adverse Drug Event; Adverse Drug Reaction Reporting Systems; Data Mining; Dictionary; Electronic Health Records; Data Mining; Denmark; Dictionaries, Medical as Topic; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Humans; Narration","Drugs have tremendous potential to cure and relieve disease, but the risk of unintended effects is always present. Healthcare providers increasingly record data in electronic patient records (EPRs), in which we aim to identify possible adverse events (AEs) and, specifically, possible adverse drug events (ADEs). Based on the undesirable effects section from the summary of product characteristics (SPC) of 7446 drugs, we have built a Danish ADE dictionary. Starting from this dictionary we have developed a pipeline for identifying possible ADEs in unstructured clinical narrative text. We use a named entity recognition (NER) tagger to identify dictionary matches in the text and post-coordination rules to construct ADE compound terms. Finally, we apply post-processing rules and filters to handle, for example, negations and sentences about subjects other than the patient. Moreover, this method allows synonyms to be identified and anatomical location descriptions can be merged to allow appropriate grouping of effects in the same location. The method identified 1 970 731 (35 477 unique) possible ADEs in a large corpus of 6011 psychiatric hospital patient records. Validation was performed through manual inspection of possible ADEs, resulting in precision of 89% and recall of 75%. The presented dictionary-building method could be used to construct other ADE dictionaries. The complication of compound words in Germanic languages was addressed. Additionally, the synonym and anatomical location collapse improve the method. The developed dictionary and method can be used to identify possible ADEs in Danish clinical narratives.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21829,""
"A texture based pattern recognition approach to distinguish melanoma from non-melanoma cells in histopathological tissue microarray sections","Rexhepaj, AgnarsdÃƒÂ³ttir, Bergman, Edqvist, Bergqvist, UhlÃƒÂ©n, Gallagher, Lundberg, Ponten","https://doi.org/10.1371/journal.pone.0062070","20131216","PubMed","Humans; Image Processing, Computer-Assisted; Immunohistochemistry; MART-1 Antigen; Melanocytes; Melanoma; Pattern Recognition, Automated; Surface Properties; Tissue Array Analysis","Immunohistochemistry is a routine practice in clinical cancer diagnostics and also an established technology for tissue-based research regarding biomarker discovery efforts. Tedious manual assessment of immunohistochemically stained tissue needs to be fully automated to take full advantage of the potential for high throughput analyses enabled by tissue microarrays and digital pathology. Such automated tools also need to be reproducible for different experimental conditions and biomarker targets. In this study we present a novel supervised melanoma specific pattern recognition approach that is fully automated and quantitative. Melanoma samples were immunostained for the melanocyte specific target, Melan-A. Images representing immunostained melanoma tissue were then digitally processed to segment regions of interest, highlighting Melan-A positive and negative areas. Color deconvolution was applied to each region of interest to separate the channel containing the immunohistochemistry signal from the hematoxylin counterstaining channel. A support vector machine melanoma classification model was learned from a discovery melanoma patient cohort (n = 264) and subsequently validated on an independent cohort of melanoma patient tissue sample images (n = 157). Here we propose a novel method that takes advantage of utilizing an immuhistochemical marker highlighting melanocytes to fully automate the learning of a general melanoma cell classification model. The presented method can be applied on any protein of interest and thus provides a tool for quantification of immunohistochemistry-based protein expression in melanoma.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21830,""
"A flexible framework for recognizing events, temporal expressions, and temporal relations in clinical text","Roberts, Rink, Harabagiu","https://doi.org/10.1136/amiajnl-2013-001619","20131217","PubMed","Clinical Informatics; Medical Records Systems, Computerized; Natural Language Processing; Artificial Intelligence; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Time; Translational Medical Research","To provide a natural language processing method for the automatic recognition of events, temporal expressions, and temporal relations in clinical records. A combination of supervised, unsupervised, and rule-based methods were used. Supervised methods include conditional random fields and support vector machines. A flexible automated feature selection technique was used to select the best subset of features for each supervised task. Unsupervised methods include Brown clustering on several corpora, which result in our method being considered semisupervised. On the 2012 Informatics for Integrating Biology and the Bedside (i2b2) shared task data, we achieved an overall event F1-measure of 0.8045, an overall temporal expression F1-measure of 0.6154, an overall temporal link detection F1-measure of 0.5594, and an end-to-end temporal link detection F1-measure of 0.5258. The most competitive system was our event recognition method, which ranked third out of the 14 participants in the event task. Analysis reveals the event recognition method has difficulty determining which modifiers to include/exclude in the event span. The temporal expression recognition method requires significantly more normalization rules, although many of these rules apply only to a small number of cases. Finally, the temporal relation recognition method requires more advanced medical knowledge and could be improved by separating the single discourse relation classifier into multiple, more targeted component classifiers. Recognizing events and temporal expressions can be achieved accurately by combining supervised and unsupervised methods, even when only minimal medical knowledge is available. Temporal normalization and temporal relation recognition, however, are far more dependent on the modeling of medical knowledge.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21831,""
"Temporal reasoning over clinical text: the state of the art","Sun, Rumshisky, Uzuner","https://doi.org/10.1136/amiajnl-2013-001760","20131217","PubMed","Medical language processing; Natural language processing; Temporal reasoning; Artificial Intelligence; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Software; Time","To provide an overview of the problem of temporal reasoning over clinical text and to summarize the state of the art in clinical natural language processing for this task. This overview targets medical informatics researchers who are unfamiliar with the problems and applications of temporal reasoning over clinical text. We review the major applications of text-based temporal reasoning, describe the challenges for software systems handling temporal information in clinical text, and give an overview of the state of the art. Finally, we present some perspectives on future research directions that emerged during the recent community-wide challenge on text-based temporal reasoning in the clinical domain.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21832,""
"Minimally invasive surgery: national trends in adoption and future directions for hospital strategy","Tsui, Klein, Garabrant","https://doi.org/10.1007/s00464-013-2973-9","20140220","PubMed","Clinical Competence; Forecasting; General Surgery; Hospital Administration; Humans; Laparoscopy; Minimally Invasive Surgical Procedures; Robotics; United States","Surgeons have rapidly adopted minimally invasive surgical (MIS) techniques for a wide range of applications since the first laparoscopic appendectomy was performed in 1983. At the helm of this MIS shift has been laparoscopy, with robotic surgery also gaining ground in a number of areas. Researchers estimated national volumes, growth forecasts, and MIS adoption rates for the following procedures: cholecystectomy, appendectomy, gastric bypass, ventral hernia repair, colectomy, prostatectomy, tubal ligation, hysterectomy, and myomectomy. MIS adoption rates are based on secondary research, interviews with clinicians and administrators involved in MIS, and a review of clinical literature, where available. Overall volume estimates and growth forecasts are sourced from The Advisory Board Company's national demand model which provides current and future utilization rate projections for inpatient and outpatient services. The model takes into account demographics (growth and aging of the population) as well as non demographic factors such as inpatient to outpatient shift, increase in disease prevalence, technological advancements, coverage expansion, and changing payment models. Surgeons perform cholecystectomy, a relatively simple procedure, laparoscopically in 96 % of the cases. Use of the robot as a tool in laparoscopy is gaining traction in general surgery and seeing particular growth within colorectal surgery. Surgeons use robotic surgery in 15 % of colectomy cases, far behind that of prostatectomy but similar to that of hysterectomy, which have robotic adoption rates of 90 and 20 %, respectively. Surgeons are using minimally invasive surgical techniques, primarily laparoscopy and robotic surgery, to perform procedures that were previously done as open surgery. As risk-based pressures mount, hospital executives will increasingly scrutinize the cost of new technology and the impact it has on patient outcomes. These changing market dynamics may thwart the expansion of new surgical techniques and heighten emphasis on competency standards.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21833,""
"The contribution of the vaccine adverse event text mining system to the classification of possible Guillain-BarrÃƒÂ© syndrome reports","Botsis, Woo, Ball","https://doi.org/10.4338/ACI-2012-11-RA-0049","20140911","PubMed","Biosurveillance and case reporting; and analysis; data access; data mining; data repositories; integration; natural language processing; Data Mining; Guillain-Barre Syndrome; Humans; Research Report; Vaccines","We previously demonstrated that a general purpose text mining system, the Vaccine adverse event Text Mining (VaeTM) system, could be used to automatically classify reports of an-aphylaxis for post-marketing safety surveillance of vaccines. To evaluate the ability of VaeTM to classify reports to the Vaccine Adverse Event Reporting System (VAERS) of possible Guillain-BarrÃƒÂ© Syndrome (GBS). We used VaeTM to extract the key diagnostic features from the text of reports in VAERS. Then, we applied the Brighton Collaboration (BC) case definition for GBS, and an information retrieval strategy (i.e. the vector space model) to quantify the specific information that is included in the key features extracted by VaeTM and compared it with the encoded information that is already stored in VAERS as Medical Dictionary for Regulatory Activities (MedDRA) Preferred Terms (PTs). We also evaluated the contribution of the primary (diagnosis and cause of death) and secondary (second level diagnosis and symptoms) diagnostic VaeTM-based features to the total VaeTM-based information. MedDRA captured more information and better supported the classification of reports for GBS than VaeTM (AUC: 0.904 vs. 0.777); the lower performance of VaeTM is likely due to the lack of extraction by VaeTM of specific laboratory results that are included in the BC criteria for GBS. On the other hand, the VaeTM-based classification exhibited greater specificity than the MedDRA-based approach (94.96% vs. 87.65%). Most of the VaeTM-based information was contained in the secondary diagnostic features. For GBS, clinical signs and symptoms alone are not sufficient to match MedDRA coding for purposes of case classification, but are preferred if specificity is the priority.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21834,""
"Assisted knowledge discovery for the maintenance of clinical guidelines","Pasche, Ruch, Teodoro, Huttner, Harbarth, Gobeill, Wipfli, Lovis","https://doi.org/10.1371/journal.pone.0062874","20131126","PubMed","Anti-Bacterial Agents; Drug Prescriptions; Evidence-Based Medicine; Humans; Internet; Practice Guidelines as Topic; Search Engine; Software","Improving antibiotic prescribing practices is an important public-health priority given the widespread antimicrobial resistance. Establishing clinical practice guidelines is crucial to this effort, but their development is a complex task and their quality is directly related to the methodology and source of knowledge used. We present the design and the evaluation of a tool (KART) that aims to facilitate the creation and maintenance of clinical practice guidelines based on information retrieval techniques. KART consists of three main modules 1) a literature-based medical knowledge extraction module, which is built upon a specialized question-answering engine; 2) a module to normalize clinical recommendations based on automatic text categorizers; and 3) a module to manage clinical knowledge, which formalizes and stores clinical recommendations for further use. The evaluation of the usability and utility of KART followed the methodology of the cognitive walkthrough. KART was designed and implemented as a standalone web application. The quantitative evaluation of the medical knowledge extraction module showed that 53% of the clinical recommendations generated by KART are consistent with existing clinical guidelines. The user-based evaluation confirmed this result by showing that KART was able to find a relevant antibiotic for half of the clinical scenarios tested. The automatic normalization of the recommendation produced mixed results among end-users. We have developed an innovative approach for the process of clinical guidelines development and maintenance in a context where available knowledge is increasing at a rate that cannot be sustained by humans. In contrast to existing knowledge authoring tools, KART not only provides assistance to normalize, formalize and store clinical recommendations, but also aims to facilitate knowledge building.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21835,""
"Textrous!: extracting semantic textual meaning from gene sets","Chen, Martin, Daimon, Siddiqui, Luttrell, Maudsley","https://doi.org/10.1371/journal.pone.0062665","20131126","PubMed","Animals; Computational Biology; Genomics; Humans; Internet; Semantics; Software; User-Computer Interface","The un-biased and reproducible interpretation of high-content gene sets from large-scale genomic experiments is crucial to the understanding of biological themes, validation of experimental data, and the eventual development of plans for future experimentation. To derive biomedically-relevant information from simple gene lists, a mathematical association to scientific language and meaningful words or sentences is crucial. Unfortunately, existing software for deriving meaningful and easily-appreciable scientific textual 'tokens' from large gene sets either rely on controlled vocabularies (Medical Subject Headings, Gene Ontology, BioCarta) or employ Boolean text searching and co-occurrence models that are incapable of detecting indirect links in the literature. As an improvement to existing web-based informatic tools, we have developed Textrous!, a web-based framework for the extraction of biomedical semantic meaning from a given input gene set of arbitrary length. Textrous! employs natural language processing techniques, including latent semantic indexing (LSI), sentence splitting, word tokenization, parts-of-speech tagging, and noun-phrase chunking, to mine MEDLINE abstracts, PubMed Central articles, articles from the Online Mendelian Inheritance in Man (OMIM), and Mammalian Phenotype annotation obtained from Jackson Laboratories. Textrous! has the ability to generate meaningful output data with even very small input datasets, using two different text extraction methodologies (collective and individual) for the selecting, ranking, clustering, and visualization of English words obtained from the user data. Textrous!, therefore, is able to facilitate the output of quantitatively significant and easily appreciable semantic words and phrases linked to both individual gene and batch genomic data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21836,""
"Expanding utilization of robotic partial nephrectomy for clinical T1b and complex T1a renal masses","Borghesi, Schiavina, Gan, Novara, Mottrie, Ficarra","https://doi.org/10.1007/s00345-013-1095-2","20140220","PubMed","Blood Loss, Surgical; Carcinoma, Renal Cell; Humans; Kidney Neoplasms; Laparoscopy; Minimally Invasive Surgical Procedures; Nephrectomy; Operative Time; Robotics; Treatment Outcome; Tumor Burden; Warm Ischemia","Partial nephrectomy is the standard of care for cT1a renal masses, offering equivalent oncologic outcomes and lower renal function impairment when compared to radical nephrectomy, with excellent overall survival results. Robot-assisted partial nephrectomy (RAPN) allows to perform a precise tumor excision, simplifying the reconstruction steps of the procedure, especially in the treatment of complex or large renal tumors. Aim of this study was to summarize the available perioperative, functional, and oncological outcomes of RAPN performed for complex and/or large (cT1b) renal cell carcinoma (RCC). We performed a nonsystematic review of the literature using a free-text protocol in the Medline database, using the terms ""robot-assisted partial nephrectomy"" and ""robotic partial nephrectomy."" Two Authors reviewed separately to select RAPN series reporting data about complex and cT1b RCC. Other significant studies cited in the reference lists of the selected papers were also evaluated. According to the currently available evidences, RAPN offers promising results in terms of perioperative, functional, and oncological outcomes for the conservative management of complex or large renal tumors, even when compared with open and laparoscopic partial nephrectomy. Robot-assisted procedure allows surgeons to treat large and challenging renal masses, even if with higher warm ischemia time, operating time, and estimated blood loss in comparison with those obtained for the treatment of smaller lesions. In the hands of experienced surgeons, RAPN is a safe and reproducible approach for the treatment of cT1b and more challenging renal tumors, and could represent the way to expand the indications for minimally invasive conservative approach to RCC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21837,""
"A plea for neutral comparison studies in computational sciences","Boulesteix, Lauer, Eugster","https://doi.org/10.1371/journal.pone.0061562","20131209","PubMed","Artificial Intelligence; Computational Biology; Humans","In computational science literature including, e.g., bioinformatics, computational statistics or machine learning, most published articles are devoted to the development of ""new methods"", while comparison studies are generally appreciated by readers but surprisingly given poor consideration by many journals. This paper stresses the importance of neutral comparison studies for the objective evaluation of existing methods and the establishment of standards by drawing parallels with clinical research. The goal of the paper is twofold. Firstly, we present a survey of recent computational papers on supervised classification published in seven high-ranking computational science journals. The aim is to provide an up-to-date picture of current scientific practice with respect to the comparison of methods in both articles presenting new methods and articles focusing on the comparison study itself. Secondly, based on the results of our survey we critically discuss the necessity, impact and limitations of neutral comparison studies in computational sciences. We define three reasonable criteria a comparison study has to fulfill in order to be considered as neutral, and explicate general considerations on the individual components of a ""tidy neutral comparison study"". R codes for completely replicating our statistical analyses and figures are available from the companion website http://www.ibe.med.uni-muenchen.de/organisation/mitarbeiter/020_professuren/boulesteix/plea2013.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21838,""
"Working memory and corpus callosum microstructural integrity after pediatric traumatic brain injury: a diffusion tensor tractography study","Treble, Hasan, Iftikhar, Stuebing, Kramer, Cox, Swank, Ewing-Cobbs","https://doi.org/10.1089/neu.2013.2934","20140502","PubMed","Adolescent; Brain Injuries; Cerebral Cortex; Child; Consciousness Disorders; Corpus Callosum; Diffuse Axonal Injury; Diffusion Tensor Imaging; Ethnic Groups; Female; Glasgow Coma Scale; Humans; Image Processing, Computer-Assisted; Injury Severity Score; Male; Memory, Short-Term; Neuropsychological Tests; Psychomotor Performance; Regression Analysis; Space Perception; Visual Perception","Deficits in working memory (WM) are a common consequence of pediatric traumatic brain injury (TBI) and are believed to contribute to difficulties in a range of cognitive and academic domains. Reduced integrity of the corpus callosum (CC) after TBI may disrupt the connectivity between bilateral frontoparietal neural networks underlying WM. In the present investigation, diffusion tensor imaging (DTI) tractography of eight callosal subregions (CC1-CC8) was examined in relation to measures of verbal and visuospatial WM in 74 children sustaining TBI and 49 typically developing comparison children. Relative to the comparison group, children with TBI demonstrated poorer visuospatial WM, but comparable verbal WM. Microstructure of the CC was significantly compromised in brain-injured children, with lower fractional anisotropy (FA) and higher axial and radial diffusivity metrics in all callosal subregions. In both groups of children, lower FA and/or higher radial diffusivity in callosal subregions connecting anterior and posterior parietal cortical regions predicted poorer verbal WM, whereas higher radial diffusivity in callosal subregions connecting anterior and posterior parietal, as well as temporal, cortical regions predicted poorer visuospatial WM. DTI metrics, especially radial diffusivity, in predictive callosal subregions accounted for significant variance in WM over and above remaining callosal subregions. Reduced microstructural integrity of the CC, particularly in subregions connecting parietal and temporal cortices, may act as a neuropathological mechanism contributing to long-term WM deficits. The future clinical use of neuroanatomical biomarkers may allow for the early identification of children at highest risk for WM deficits and earlier provision of interventions for these children.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21839,""
"Comparison of machine learning algorithms for classification of the sentences in three clinical practice guidelines","Song, Lee, Kang","https://doi.org/10.4258/hir.2013.19.1.16","20130430","PubMed","Data Mining; Information Storage and Retrieval; Knowledge Bases","Clinical Practice Guidelines (CPGs) are an effective tool for minimizing the gap between a physician's clinical decision and medical evidence and for modeling the systematic and standardized pathway used to provide better medical treatment to patients. In this study, sentences within the clinical guidelines are categorized according to a classification system. We used three clinical guidelines that incorporated knowledge from medical experts in the field of family medicine. These were the seventh report of the Joint National Committee (JNC7) on Prevention, Detection, Evaluation, and Treatment of High Blood Pressure from the National Heart, Lung, and Blood Institute; the third report of the National Cholesterol Education Program (NCEP) Expert Panel on Detection, Evaluation, and Treatment of High Blood Cholesterol in Adults from the same institution; and the Standards of Medical Care in Diabetes 2010 report from the American Diabetes Association. Three annotators each tagged 346 sentences hand-chosen from these three clinical guidelines. The three annotators then carried out cross-validations of the tagged corpus. We also used various machine learning-based classifiers for sentence classification. We conducted experiments using real-valued features and token units, as well as a Boolean feature. The results showed that the combination of maximum entropy-based learning and information gain-based feature extraction gave the best classification performance (over 98% f-measure) in four sentence categories. This result confirmed the contribution of the feature reduction algorithm and optimal technique for very sparse feature spaces, such as the sentence classification problem in the clinical guideline document.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21840,""
"Cannabinoid and opioid interactions: implications for opiate dependence and withdrawal","Scavone, Sterling, Van Bockstaele","https://doi.org/10.1016/j.neuroscience.2013.04.034","20131231","PubMed","2-AG; 2-arachidonoylglycerol; AC; CB1r; CREB; CRF; EC; HPA; LC; MMT; MOR; NAc; NTS; PGi; PKA; UDS; adenylyl cyclase; cAMP response element binding protein; cannabinoid type 1 receptors; clinical; corticotropin releasing factor; endocannabinoid; hypothalamicÃ¢â‚¬â€œpituitaryÃ¢â‚¬â€œadrenal; locus coeruleus; marijuana; methadone maintenance treatment; mu-opioid receptor; norepinephrine; nucleus accumbens; nucleus of the solitary tract; paragigantocellularis; protein kinase-A; stress; urinary drug screen; Analgesics, Opioid; Animals; Cannabinoids; Drug Interactions; Endocannabinoids; Humans; Locus Coeruleus; Norepinephrine; Opioid-Related Disorders; Signal Transduction; Substance Withdrawal Syndrome; Synapses","Withdrawal from opiates, such as heroin or oral narcotics, is characterized by a host of aversive physical and emotional symptoms. High rates of relapse and limited treatment success rates for opiate addiction have prompted a search for new approaches. For many opiate addicts, achieving abstinence may be further complicated by poly-drug use and co-morbid mental disorders. Research over the past decade has shed light on the influence of endocannabinoids (ECs) on the opioid system. Evidence from both animal and clinical studies point toward an interaction between these two systems, and suggest that targeting the EC system may provide novel interventions for managing opiate dependence and withdrawal. This review will summarize the literature surrounding the molecular effects of cannabinoids and opioids on the locus coeruleus-norepinephrine system, a key circuit implicated in the negative sequelae of opiate addiction. A consideration of the trends and effects of marijuana use in those seeking treatment to abstain from opiates in the clinical setting will also be presented. In summary, the present review details how cannabinoid-opioid interactions may inform novel interventions in the management of opiate dependence and withdrawal. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21841,""
"Mining social media and web searches for disease detection","Yang, Horneffer, DiLisio","https://doi.org/10.4081/jphr.2013.e4","20140829","PubMed","epidemiological intelligence; flu; infectious disease.; informatics; social media","Web-based social media is increasingly being used across different settings in the health care industry. The increased frequency in the use of the Internet via computer or mobile devices provides an opportunity for social media to be the medium through which people can be provided with valuable health information quickly and directly. While traditional methods of detection relied predominately on hierarchical or bureaucratic lines of communication, these often failed to yield timely and accurate epidemiological intelligence. New web-based platforms promise increased opportunities for a more timely and accurate spreading of information and analysis. This article aims to provide an overview and discussion of the availability of timely and accurate information. It is especially useful for the rapid identification of an outbreak of an infectious disease that is necessary to promptly and effectively develop public health responses. These web-based platforms include search queries, data mining of web and social media, process and analysis of blogs containing epidemic key words, text mining, and geographical information system data analyses. These new sources of analysis and information are intended to complement traditional sources of epidemic intelligence. Despite the attractiveness of these new approaches, further study is needed to determine the accuracy of blogger statements, as increases in public participation may not necessarily mean the information provided is more accurate. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21842,""
"Large-scale event extraction from literature with multi-level gene normalization","Van Landeghem, BjÃƒÂ¶rne, Wei, Hakala, Pyysalo, Ananiadou, Kao, Lu, Salakoski, Van de Peer, Ginter","https://doi.org/10.1371/journal.pone.0055814","20131111","PubMed","Algorithms; Data Mining; Genes; Multigene Family; Publications; Reference Standards; Signal Transduction; Statistics as Topic","Text mining for the life sciences aims to aid database curation, knowledge summarization and information retrieval through the automated processing of biomedical texts. To provide comprehensive coverage and enable full integration with existing biomolecular database records, it is crucial that text mining tools scale up to millions of articles and that their analyses can be unambiguously linked to information recorded in resources such as UniProt, KEGG, BioGRID and NCBI databases. In this study, we investigate how fully automated text mining of complex biomolecular events can be augmented with a normalization strategy that identifies biological concepts in text, mapping them to identifiers at varying levels of granularity, ranging from canonicalized symbols to unique gene and proteins and broad gene families. To this end, we have combined two state-of-the-art text mining components, previously evaluated on two community-wide challenges, and have extended and improved upon these methods by exploiting their complementary nature. Using these systems, we perform normalization and event extraction to create a large-scale resource that is publicly available, unique in semantic scope, and covers all 21.9 million PubMed abstracts and 460 thousand PubMed Central open access full-text articles. This dataset contains 40 million biomolecular events involving 76 million gene/protein mentions, linked to 122 thousand distinct genes from 5032 species across the full taxonomic tree. Detailed evaluations and analyses reveal promising results for application of this data in database and pathway curation efforts. The main software components used in this study are released under an open-source license. Further, the resulting dataset is freely accessible through a novel API, providing programmatic and customized access (http://www.evexdb.org/api/v001/). Finally, to allow for large-scale bioinformatic analyses, the entire resource is available for bulk download from http://evexdb.org/download/, under the Creative Commons - Attribution - Share Alike (CC BY-SA) license.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21843,""
"The SADI Personal Health Lens: A Web Browser-Based System for Identifying Personally Relevant Drug Interactions","Vandervalk, McCarthy, Cruz-Toledo, Klein, Baker, Dumontier, Wilkinson","https://doi.org/10.2196/resprot.2315","20130425","PubMed","SADI; SHARE; Web-based interaction; Web-based services; drug interactions; semantic Web; telemedicine","The Web provides widespread access to vast quantities of health-related information that can improve quality-of-life through better understanding of personal symptoms, medical conditions, and available treatments. Unfortunately, identifying a credible and personally relevant subset of information can be a time-consuming and challenging task for users without a medical background. The objective of the Personal Health Lens system is to aid users when reading health-related webpages by providing warnings about personally relevant drug interactions. More broadly, we wish to present a prototype for a novel, generalizable approach to facilitating interactions between a patient, their practitioner(s), and the Web. We utilized a distributed, Semantic Web-based architecture for recognizing personally dangerous drugs consisting of: (1) a private, local triple store of personal health information, (2) Semantic Web services, following the Semantic Automated Discovery and Integration (SADI) design pattern, for text mining and identifying substance interactions, (3) a bookmarklet to trigger analysis of a webpage and annotate it with personalized warnings, and (4) a semantic query that acts as an abstract template of the analytical workflow to be enacted by the system. A prototype implementation of the system is provided in the form of a Java standalone executable JAR file. The JAR file bundles all components of the system: the personal health database, locally-running versions of the SADI services, and a javascript bookmarklet that triggers analysis of a webpage. In addition, the demonstration includes a hypothetical personal health profile, allowing the system to be used immediately without configuration. Usage instructions are provided. The main strength of the Personal Health Lens system is its ability to organize medical information and to present it to the user in a personalized and contextually relevant manner. While this prototype was limited to a single knowledge domain (drug/drug interactions), the proposed architecture is generalizable, and could act as the foundation for much richer personalized-health-Web clients, while importantly providing a novel and personalizable mechanism for clinical experts to inject their expertise into the browsing experience of their patients in the form of customized semantic queries and ontologies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21844,""
"Accuracy and response-time distributions for decision-making: linear perfect integrators versus nonlinear attractor-based neural circuits","Miller, Katz","https://doi.org/10.1007/s10827-013-0452-x","20140528","PubMed","Algorithms; Computer Simulation; Decision Making; Electrophysiological Phenomena; Humans; Hydrogen-Ion Concentration; Linear Models; Neural Networks, Computer; Neurons; Nonlinear Dynamics; Probability; Psychomotor Performance; Reaction Time; Reward; Sensory Gating","Animals choose actions based on imperfect, ambiguous data. ""Noise"" inherent in neural processing adds further variability to this already-noisy input signal. Mathematical analysis has suggested that the optimal apparatus (in terms of the speed/accuracy trade-off) for reaching decisions about such noisy inputs is perfect accumulation of the inputs by a temporal integrator. Thus, most highly cited models of neural circuitry underlying decision-making have been instantiations of a perfect integrator. Here, in accordance with a growing mathematical and empirical literature, we describe circumstances in which perfect integration is rendered suboptimal. In particular we highlight the impact of three biological constraints: (1) significant noise arising within the decision-making circuitry itself; (2) bounding of integration by maximal neural firing rates; and (3) time limitations on making a decision. Under conditions (1) and (2), an attractor system with stable attractor states can easily best an integrator when accuracy is more important than speed. Moreover, under conditions in which such stable attractor networks do not best the perfect integrator, a system with unstable initial states can do so if readout of the system's final state is imperfect. Ubiquitously, an attractor system with a nonselective time-dependent input current is both more accurate and more robust to imprecise tuning of parameters than an integrator with such input. Given that neural responses that switch stochastically between discrete states can ""masquerade"" as integration in single-neuron and trial-averaged data, our results suggest that such networks should be considered as plausible alternatives to the integrator model. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21845,""
"Combining rules and machine learning for extraction of temporal expressions and events from clinical narratives","Kovacevic, Dehghan, Filannino, Keane, Nenadic","https://doi.org/10.1136/amiajnl-2013-001625","20131217","PubMed","clinical NLP; clinical text mining; event extraction; termporal expression extraction; termporal expression normalization; Artificial Intelligence; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Time; Translational Medical Research","Identification of clinical events (eg, problems, tests, treatments) and associated temporal expressions (eg, dates and times) are key tasks in extracting and managing data from electronic health records. As part of the i2b2 2012 Natural Language Processing for Clinical Data challenge, we developed and evaluated a system to automatically extract temporal expressions and events from clinical narratives. The extracted temporal expressions were additionally normalized by assigning type, value, and modifier. The system combines rule-based and machine learning approaches that rely on morphological, lexical, syntactic, semantic, and domain-specific features. Rule-based components were designed to handle the recognition and normalization of temporal expressions, while conditional random fields models were trained for event and temporal recognition. The system achieved micro F scores of 90% for the extraction of temporal expressions and 87% for clinical event extraction. The normalization component for temporal expressions achieved accuracies of 84.73% (expression's type), 70.44% (value), and 82.75% (modifier). Compared to the initial agreement between human annotators (87-89%), the system provided comparable performance for both event and temporal expression mining. While (lenient) identification of such mentions is achievable, finding the exact boundaries proved challenging. The system provides a state-of-the-art method that can be used to support automated identification of mentions of clinical events and temporal expressions in narratives either to support the manual review process or as a part of a large-scale processing of electronic health databases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21846,""
"Recognizing clinical entities in hospital discharge summaries using Structural Support Vector Machines with word representation features","Tang, Cao, Wu, Jiang, Xu","https://doi.org/10.1186/1472-6947-13-S1-S1","20130701","PubMed","Algorithms; Artificial Intelligence; Cluster Analysis; Critical Pathways; Humans; Markov Chains; Medical Records Systems, Computerized; Natural Language Processing; Patient Discharge; Pattern Recognition, Automated; Pennsylvania; Reproducibility of Results; Semantics","Named entity recognition (NER) is an important task in clinical natural language processing (NLP) research. Machine learning (ML) based NER methods have shown good performance in recognizing entities in clinical text. Algorithms and features are two important factors that largely affect the performance of ML-based NER systems. Conditional Random Fields (CRFs), a sequential labelling algorithm, and Support Vector Machines (SVMs), which is based on large margin theory, are two typical machine learning algorithms that have been widely applied to clinical NER tasks. For features, syntactic and semantic information of context words has often been used in clinical NER systems. However, Structural Support Vector Machines (SSVMs), an algorithm that combines the advantages of both CRFs and SVMs, and word representation features, which contain word-level back-off information over large unlabelled corpus by unsupervised algorithms, have not been extensively investigated for clinical text processing. Therefore, the primary goal of this study is to evaluate the use of SSVMs and word representation features in clinical NER tasks. In this study, we developed SSVMs-based NER systems to recognize clinical entities in hospital discharge summaries, using the data set from the concept extration task in the 2010 i2b2 NLP challenge. We compared the performance of CRFs and SSVMs-based NER classifiers with the same feature sets. Furthermore, we extracted two different types of word representation features (clustering-based representation features and distributional representation features) and integrated them with the SSVMs-based clinical NER system. We then reported the performance of SSVM-based NER systems with different types of word representation features. Using the same training (N = 27,837) and test (N = 45,009) sets in the challenge, our evaluation showed that the SSVMs-based NER systems achieved better performance than the CRFs-based systems for clinical entity recognition, when same features were used. Both types of word representation features (clustering-based and distributional representations) improved the performance of ML-based NER systems. By combining two different types of word representation features together with SSVMs, our system achieved a highest F-measure of 85.82%, which outperformed the best system reported in the challenge by 0.6%. Our results show that SSVMs is a great potential algorithm for clinical NLP research, and both types of unsupervised word representation features are beneficial to clinical NER tasks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21847,""
"Web information retrieval for health professionals","Ting, See-To, Tse","https://doi.org/10.1007/s10916-013-9946-3","20160422","PubMed","Hong Kong; Humans; Information Storage and Retrieval; Information Systems; Internet","This paper presents a Web Information Retrieval System (WebIRS), which is designed to assist the healthcare professionals to obtain up-to-date medical knowledge and information via the World Wide Web (WWW). The system leverages the document classification and text summarization techniques to deliver the highly correlated medical information to the physicians. The system architecture of the proposed WebIRS is first discussed, and then a case study on an application of the proposed system in a Hong Kong medical organization is presented to illustrate the adoption process and a questionnaire is administrated to collect feedback on the operation and performance of WebIRS in comparison with conventional information retrieval in the WWW. A prototype system has been constructed and implemented on a trial basis in a medical organization. It has proven to be of benefit to healthcare professionals through its automatic functions in classification and summarizing the medical information that the physicians needed and interested. The results of the case study show that with the use of the proposed WebIRS, significant reduction of searching time and effort, with retrieval of highly relevant materials can be attained.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21848,""
"Eventual situations for timeline extraction from clinical reports","Grouin, Grabar, Hamon, Rosset, Tannier, Zweigenbaum","https://doi.org/10.1136/amiajnl-2013-001627","20131217","PubMed","Chronology as Topic; Information Extraction; Medical Records; Natural Language Processing; Text Mining; Artificial Intelligence; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Time","To identify the temporal relations between clinical events and temporal expressions in clinical reports, as defined in the i2b2/VA 2012 challenge. To detect clinical events, we used rules and Conditional Random Fields. We built Random Forest models to identify event modality and polarity. To identify temporal expressions we built on the HeidelTime system. To detect temporal relations, we systematically studied their breakdown into distinct situations; we designed an oracle method to determine the most prominent situations and the most suitable associated classifiers, and combined their results. We achieved F-measures of 0.8307 for event identification, based on rules, and 0.8385 for temporal expression identification. In the temporal relation task, we identified nine main situations in three groups, experimentally confirming shared intuitions: within-sentence relations, section-related time, and across-sentence relations. Logistic regression and NaÃƒÂ¯ve Bayes performed best on the first and third groups, and decision trees on the second. We reached a 0.6231 global F-measure, improving by 7.5 points our official submission. Carefully hand-crafted rules obtained good results for the detection of events and temporal expressions, while a combination of classifiers improved temporal link prediction. The characterization of the oracle recall of situations allowed us to point at directions where further work would be most useful for temporal relation detection: within-sentence relations and linking History of Present Illness events to the admission date. We suggest that the systematic situation breakdown proposed in this paper could also help improve other systems addressing this task.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21849,""
"A unified structural/terminological interoperability framework based on LexEVS: application to TRANSFoRm","Ethier, Dameron, Curcin, McGilchrist, Verheij, Arvanitis, Taweel, Delaney, Burgun","https://doi.org/10.1136/amiajnl-2012-001312","20131217","PubMed","Interoperability; LexEVS; Ontology; Semantics; Terminology; Translational Medical Research; Biomedical Research; Databases as Topic; Software; Systems Integration; Terminology as Topic","Biomedical research increasingly relies on the integration of information from multiple heterogeneous data sources. Despite the fact that structural and terminological aspects of interoperability are interdependent and rely on a common set of requirements, current efforts typically address them in isolation. We propose a unified ontology-based knowledge framework to facilitate interoperability between heterogeneous sources, and investigate if using the LexEVS terminology server is a viable implementation method. We developed a framework based on an ontology, the general information model (GIM), to unify structural models and terminologies, together with relevant mapping sets. This allowed a uniform access to these resources within LexEVS to facilitate interoperability by various components and data sources from implementing architectures. Our unified framework has been tested in the context of the EU Framework Program 7 TRANSFoRm project, where it was used to achieve data integration in a retrospective diabetes cohort study. The GIM was successfully instantiated in TRANSFoRm as the clinical data integration model, and necessary mappings were created to support effective information retrieval for software tools in the project. We present a novel, unifying approach to address interoperability challenges in heterogeneous data sources, by representing structural and semantic models in one framework. Systems using this architecture can rely solely on the GIM that abstracts over both the structure and coding. Information models, terminologies and mappings are all stored in LexEVS and can be accessed in a uniform manner (implementing the HL7 CTS2 service functional model). The system is flexible and should reduce the effort needed from data sources personnel for implementing and managing the integration.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21850,""
"A hybrid system for temporal information extraction from clinical text","Tang, Wu, Jiang, Chen, Denny, Xu","https://doi.org/10.1136/amiajnl-2013-001635","20131217","PubMed","Clinic event extraction; Machine learning; Natural language processing; Temporal expression extraction; Temporal information extraction; Temporal relation extraction; Artificial Intelligence; Electronic Health Records; Humans; Natural Language Processing; Patient Discharge Summaries; Time; Translational Medical Research","To develop a comprehensive temporal information extraction system that can identify events, temporal expressions, and their temporal relations in clinical text. This project was part of the 2012 i2b2 clinical natural language processing (NLP) challenge on temporal information extraction. The 2012 i2b2 NLP challenge organizers manually annotated 310 clinic notes according to a defined annotation guideline: a training set of 190 notes and a test set of 120 notes. All participating systems were developed on the training set and evaluated on the test set. Our system consists of three modules: event extraction, temporal expression extraction, and temporal relation (also called Temporal Link, or 'TLink') extraction. The TLink extraction module contains three individual classifiers for TLinks: (1) between events and section times, (2) within a sentence, and (3) across different sentences. The performance of our system was evaluated using scripts provided by the i2b2 organizers. Primary measures were micro-averaged Precision, Recall, and F-measure. Our system was among the top ranked. It achieved F-measures of 0.8659 for temporal expression extraction (ranked fourth), 0.6278 for end-to-end TLink track (ranked first), and 0.6932 for TLink-only track (ranked first) in the challenge. We subsequently investigated different strategies for TLink extraction, and were able to marginally improve performance with an F-measure of 0.6943 for TLink-only track.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21851,""
"Pharmacovigilance using clinical notes","LePendu, Iyer, Bauer-Mehren, Harpaz, Mortensen, Podchiyska, Ferris, Shah","https://doi.org/10.1038/clpt.2013.47","20130723","PubMed","Adverse Drug Reaction Reporting Systems; Data Mining; Drug Interactions; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Humans; Pharmacovigilance; Prevalence; United States","With increasing adoption of electronic health records (EHRs), there is an opportunity to use the free-text portion of EHRs for pharmacovigilance. We present novel methods that annotate the unstructured clinical notes and transform them into a deidentified patient-feature matrix encoded using medical terminologies. We demonstrate the use of the resulting high-throughput data for detecting drug-adverse event associations and adverse events associated with drug-drug interactions. We show that these methods flag adverse events early (in most cases before an official alert), allow filtering of spurious signals by adjusting for potential confounding, and compile prevalence information. We argue that analyzing large volumes of free-text clinical notes enables drug safety surveillance using a yet untapped data source. Such data mining can be used for hypothesis generation and for rapid analysis of suspected adverse event risk.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21852,""
"A semi-supervised approach to extract pharmacogenomics-specific drug-gene pairs from biomedical literature for personalized medicine","Xu, Wang","https://doi.org/10.1016/j.jbi.2013.04.001","20140218","PubMed","Information extraction; Personalized medicine; Pharmacogenomics; Text mining; Algorithms; Data Mining; Pharmacogenetics; Precision Medicine","Personalized medicine is to deliver the right drug to the right patient in the right dose. Pharmacogenomics (PGx) is to identify genetic variants that may affect drug efficacy and toxicity. The availability of a comprehensive and accurate PGx-specific drug-gene relationship knowledge base is important for personalized medicine. However, building a large-scale PGx-specific drug-gene knowledge base is a difficult task. In this study, we developed a bootstrapping, semi-supervised learning approach to iteratively extract and rank drug-gene pairs according to their relevance to drug pharmacogenomics. Starting with a single PGx-specific seed pair and 20 million MEDLINE abstracts, the extraction algorithm achieved a precision of 0.219, recall of 0.368 and F1 of 0.274 after two iterations, a significant improvement over the results of using non-PGx-specific seeds (precision: 0.011, recall: 0.018, and F1: 0.014) or co-occurrence (precision: 0.015, recall: 1.000, and F1: 0.030). After the extraction step, the ranking algorithm further improved the precision from 0.219 to 0.561 for top ranked pairs. By comparing to a dictionary-based approach with PGx-specific gene lexicon as input, we showed that the bootstrapping approach has better performance in terms of both precision and F1 (precision: 0.251 vs. 0.152, recall: 0.396 vs. 0.856 and F1: 0.292 vs. 0.254). By integrative analysis using a large drug adverse event database, we have shown that the extracted drug-gene pairs strongly correlate with drug adverse events. In conclusion, we developed a novel semi-supervised bootstrapping approach for effective PGx-specific drug-gene pair extraction from large number of MEDLINE articles with minimal human input. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21853,""
"Improving case definition of Crohn's disease and ulcerative colitis in electronic medical records using natural language processing: a novel informatics approach","Ananthakrishnan, Cai, Savova, Cheng, Chen, Perez, Gainer, Murphy, Szolovits, Xia, Shaw, Churchill, Karlson, Kohane, Plenge, Liao","https://doi.org/10.1097/MIB.0b013e31828133fd","20140122","PubMed","Adult; Algorithms; Colitis, Ulcerative; Crohn Disease; Electronic Health Records; Female; Follow-Up Studies; Humans; Male; Medical Informatics; Natural Language Processing; Prognosis; Tertiary Care Centers","Previous studies identifying patients with inflammatory bowel disease using administrative codes have yielded inconsistent results. Our objective was to develop a robust electronic medical record-based model for classification of inflammatory bowel disease leveraging the combination of codified data and information from clinical text notes using natural language processing. Using the electronic medical records of 2 large academic centers, we created data marts for Crohn's disease (CD) and ulcerative colitis (UC) comprising patients with Ã¢â€°Â¥1 International Classification of Diseases, 9th edition, code for each disease. We used codified (i.e., International Classification of Diseases, 9th edition codes, electronic prescriptions) and narrative data from clinical notes to develop our classification model. Model development and validation was performed in a training set of 600 randomly selected patients for each disease with medical record review as the gold standard. Logistic regression with the adaptive LASSO penalty was used to select informative variables. We confirmed 399 CD cases (67%) in the CD training set and 378 UC cases (63%) in the UC training set. For both, a combined model including narrative and codified data had better accuracy (area under the curve for CD 0.95; UC 0.94) than models using only disease International Classification of Diseases, 9th edition codes (area under the curve 0.89 for CD; 0.86 for UC). Addition of natural language processing narrative terms to our final model resulted in classification of 6% to 12% more subjects with the same accuracy. Inclusion of narrative concepts identified using natural language processing improves the accuracy of electronic medical records case definition for CD and UC while simultaneously identifying more subjects compared with models using codified data alone.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21854,""
"Formative evaluation of the accuracy of a clinical decision support system for cervical cancer screening","Wagholikar, MacLaughlin, Kastner, Casey, Henry, Greenes, Liu, Chaudhry","https://doi.org/10.1136/amiajnl-2013-001613","20130903","PubMed","Crowdsourcing; Decision Support Systems, Clinical; Guideline Adherence; Uterine Cervical Neoplasms; Vaginal Smears; Validation Studies as Topic; Data Mining; Decision Support Systems, Clinical; Early Detection of Cancer; Electronic Health Records; Female; Humans; Natural Language Processing; Practice Guidelines as Topic; Uterine Cervical Neoplasms","We previously developed and reported on a prototype clinical decision support system (CDSS) for cervical cancer screening. However, the system is complex as it is based on multiple guidelines and free-text processing. Therefore, the system is susceptible to failures. This report describes a formative evaluation of the system, which is a necessary step to ensure deployment readiness of the system. Care providers who are potential end-users of the CDSS were invited to provide their recommendations for a random set of patients that represented diverse decision scenarios. The recommendations of the care providers and those generated by the CDSS were compared. Mismatched recommendations were reviewed by two independent experts. A total of 25 users participated in this study and provided recommendations for 175 cases. The CDSS had an accuracy of 87% and 12 types of CDSS errors were identified, which were mainly due to deficiencies in the system's guideline rules. When the deficiencies were rectified, the CDSS generated optimal recommendations for all failure cases, except one with incomplete documentation. The crowd-sourcing approach for construction of the reference set, coupled with the expert review of mismatched recommendations, facilitated an effective evaluation and enhancement of the system, by identifying decision scenarios that were missed by the system's developers. The described methodology will be useful for other researchers who seek rapidly to evaluate and enhance the deployment readiness of complex decision support systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21855,""
"Comprehensive temporal information detection from clinical text: medical events, time, and TLINK identification","Sohn, Wagholikar, Li, Jonnalagadda, Tao, Komandur Elayavilli, Liu","https://doi.org/10.1136/amiajnl-2013-001622","20131217","PubMed","Artificial Intelligence; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Patient Discharge Summaries; Time","Temporal information detection systems have been developed by the Mayo Clinic for the 2012 i2b2 Natural Language Processing Challenge. To construct automated systems for EVENT/TIMEX3 extraction and temporal link (TLINK) identification from clinical text. The i2b2 organizers provided 190 annotated discharge summaries as the training set and 120 discharge summaries as the test set. Our Event system used a conditional random field classifier with a variety of features including lexical information, natural language elements, and medical ontology. The TIMEX3 system employed a rule-based method using regular expression pattern match and systematic reasoning to determine normalized values. The TLINK system employed both rule-based reasoning and machine learning. All three systems were built in an Apache Unstructured Information Management Architecture framework. Our TIMEX3 system performed the best (F-measure of 0.900, value accuracy 0.731) among the challenge teams. The Event system produced an F-measure of 0.870, and the TLINK system an F-measure of 0.537. Our TIMEX3 system demonstrated good capability of regular expression rules to extract and normalize time information. Event and TLINK machine learning systems required well-defined feature sets to perform well. We could also leverage expert knowledge as part of the machine learning features to further improve TLINK identification performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21856,""
"Web 20-based crowdsourcing for high-quality gold standard development in clinical natural language processing","Zhai, Lingren, Deleger, Li, Kaiser, Stoutenborough, Solti","https://doi.org/10.2196/jmir.2426","20131113","PubMed","Clinical Trials as Topic; Crowdsourcing; Humans; Internet; Natural Language Processing; Pilot Projects; Quality Control; Social Media; Telemedicine","A high-quality gold standard is vital for supervised, machine learning-based, clinical natural language processing (NLP) systems. In clinical NLP projects, expert annotators traditionally create the gold standard. However, traditional annotation is expensive and time-consuming. To reduce the cost of annotation, general NLP projects have turned to crowdsourcing based on Web 2.0 technology, which involves submitting smaller subtasks to a coordinated marketplace of workers on the Internet. Many studies have been conducted in the area of crowdsourcing, but only a few have focused on tasks in the general NLP field and only a handful in the biomedical domain, usually based upon very small pilot sample sizes. In addition, the quality of the crowdsourced biomedical NLP corpora were never exceptional when compared to traditionally-developed gold standards. The previously reported results on medical named entity annotation task showed a 0.68 F-measure based agreement between crowdsourced and traditionally-developed corpora. Building upon previous work from the general crowdsourcing research, this study investigated the usability of crowdsourcing in the clinical NLP domain with special emphasis on achieving high agreement between crowdsourced and traditionally-developed corpora. To build the gold standard for evaluating the crowdsourcing workers' performance, 1042 clinical trial announcements (CTAs) from the ClinicalTrials.gov website were randomly selected and double annotated for medication names, medication types, and linked attributes. For the experiments, we used CrowdFlower, an Amazon Mechanical Turk-based crowdsourcing platform. We calculated sensitivity, precision, and F-measure to evaluate the quality of the crowd's work and tested the statistical significance (P&lt;.001, chi-square test) to detect differences between the crowdsourced and traditionally-developed annotations. The agreement between the crowd's annotations and the traditionally-generated corpora was high for: (1) annotations (0.87, F-measure for medication names; 0.73, medication types), (2) correction of previous annotations (0.90, medication names; 0.76, medication types), and excellent for (3) linking medications with their attributes (0.96). Simple voting provided the best judgment aggregation approach. There was no statistically significant difference between the crowd and traditionally-generated corpora. Our results showed a 27.9% improvement over previously reported results on medication named entity annotation task. This study offers three contributions. First, we proved that crowdsourcing is a feasible, inexpensive, fast, and practical approach to collect high-quality annotations for clinical text (when protected health information was excluded). We believe that well-designed user interfaces and rigorous quality control strategy for entity annotation and linking were critical to the success of this work. Second, as a further contribution to the Internet-based crowdsourcing field, we will publicly release the JavaScript and CrowdFlower Markup Language infrastructure code that is necessary to utilize CrowdFlower's quality control and crowdsourcing interfaces for named entity annotations. Finally, to spur future research, we will release the CTA annotations that were generated by traditional and crowdsourced approaches.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21857,""
"Expression levels of obesity-related genes are associated with weight change in kidney transplant recipients","Cashion, Stanfill, Thomas, Xu, Sutter, Eason, Ensell, Homayouni","https://doi.org/10.1371/journal.pone.0059962","20130917","PubMed","Adult; Aged; Cluster Analysis; Gene Expression Regulation; Gene Regulatory Networks; Genetic Predisposition to Disease; Humans; Kidney Transplantation; Male; Middle Aged; Molecular Sequence Annotation; Obesity; Principal Component Analysis; Transcriptome; Weight Gain; Young Adult","The aim of this study was to investigate the association of gene expression profiles in subcutaneous adipose tissue with weight change in kidney transplant recipients and to gain insights into the underlying mechanisms of weight gain. A secondary data analysis was done on a subgroup (nÃ¢â‚¬Å =Ã¢â‚¬Å 26) of existing clinical and gene expression data from a larger prospective longitudinal study examining factors contributing to weight gain in transplant recipients. Measurements taken included adipose tissue gene expression profiles at time of transplant, baseline and six-month weight, and demographic data. Using multivariate linear regression analysis controlled for race and gender, expression levels of 1553 genes were significantly (p&lt;0.05) associated with weight change. Functional analysis using Gene Ontology and Kyoto Encyclopedia of Genes and Genomes classifications identified metabolic pathways that were enriched in this dataset. Furthermore, GeneIndexer literature mining analysis identified a subset of genes that are highly associated with obesity in the literature and Ingenuity pathway analysis revealed several significant gene networks associated with metabolism and endocrine function. Polymorphisms in several of these genes have previously been linked to obesity. We have successfully identified a set of molecular pathways that taken together may provide insights into the mechanisms of weight gain in kidney transplant recipients. Future work will be done to determine how these pathways may contribute to weight gain.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21858,""
"Use of a support vector machine for categorizing free-text notes: assessment of accuracy across two institutions","Wright, McCoy, Henkin, Kale, Sittig","https://doi.org/10.1136/amiajnl-2012-001576","20131217","PubMed","electronic health record; natural language processing; search; support vector machine; Diabetes Mellitus; Electronic Health Records; Humans; ROC Curve; Search Engine; Support Vector Machine","Electronic health record (EHR) users must regularly review large amounts of data in order to make informed clinical decisions, and such review is time-consuming and often overwhelming. Technologies like automated summarization tools, EHR search engines and natural language processing have been shown to help clinicians manage this information. To develop a support vector machine (SVM)-based system for identifying EHR progress notes pertaining to diabetes, and to validate it at two institutions. We retrieved 2000 EHR progress notes from patients with diabetes at the Brigham and Women's Hospital (1000 for training and 1000 for testing) and another 1000 notes from the University of Texas Physicians (for validation). We manually annotated all notes and trained a SVM using a bag of words approach. We then used the SVM on the testing and validation sets and evaluated its performance with the area under the curve (AUC) and F statistics. The model accurately identified diabetes-related notes in both the Brigham and Women's Hospital testing set (AUC=0.956, F=0.934) and the external University of Texas Faculty Physicians validation set (AUC=0.947, F=0.935). Overall, the model we developed was quite accurate. Furthermore, it generalized, without loss of accuracy, to another institution with a different EHR and a distinct patient and provider population. It is possible to use a SVM-based classifier to identify EHR progress notes pertaining to diabetes, and the model generalizes well.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21859,""
"Magnetic resonance imaging evidence for presymptomatic change in thalamus and caudate in familial Alzheimer's disease","Ryan, Keihaninejad, Shakespeare, Lehmann, Crutch, Malone, Thornton, Mancini, Hyare, Yousry, Ridgway, Zhang, Modat, Alexander, Rossor, Ourselin, Fox","https://doi.org/10.1093/brain/awt065","20130624","PubMed","Adult; Alzheimer Disease; Asymptomatic Diseases; Caudate Nucleus; Cohort Studies; Diffusion Magnetic Resonance Imaging; Female; Humans; Male; Middle Aged; Mutation; Thalamus","Amyloid imaging studies of presymptomatic familial Alzheimer's disease have revealed the striatum and thalamus to be the earliest sites of amyloid deposition. This study aimed to investigate whether there are associated volume and diffusivity changes in these subcortical structures during the presymptomatic and symptomatic stages of familial Alzheimer's disease. As the thalamus and striatum are involved in neural networks subserving complex cognitive and behavioural functions, we also examined the diffusion characteristics in connecting white matter tracts. A cohort of 20 presenilin 1 mutation carriers underwent volumetric and diffusion tensor magnetic resonance imaging, neuropsychological and clinical assessments; 10 were symptomatic, 10 were presymptomatic and on average 5.6 years younger than their expected age at onset; 20 healthy control subjects were also studied. We conducted region of interest analyses of volume and diffusivity changes in the thalamus, caudate, putamen and hippocampus and examined diffusion behaviour in the white matter tracts of interest (fornix, cingulum and corpus callosum). Voxel-based morphometry and tract-based spatial statistics were also used to provide unbiased whole-brain analyses of group differences in volume and diffusion indices, respectively. We found that reduced volumes of the left thalamus and bilateral caudate were evident at a presymptomatic stage, together with increased fractional anisotropy of bilateral thalamus and left caudate. Although no significant hippocampal volume loss was evident presymptomatically, reduced mean diffusivity was observed in the right hippocampus and reduced mean and axial diffusivity in the right cingulum. In contrast, symptomatic mutation carriers showed increased mean, axial and in particular radial diffusivity, with reduced fractional anisotropy, in all of the white matter tracts of interest. The symptomatic group also showed atrophy and increased mean diffusivity in all of the subcortical grey matter regions of interest, with increased fractional anisotropy in bilateral putamen. We propose that axonal injury may be an early event in presymptomatic Alzheimer's disease, causing an initial fall in axial and mean diffusivity, which then increases with loss of axonal density. The selective degeneration of long-coursing white matter tracts, with relative preservation of short interneurons, may account for the increase in fractional anisotropy that is seen in the thalamus and caudate presymptomatically. It may be owing to their dense connectivity that imaging changes are seen first in the thalamus and striatum, which then progress to involve other regions in a vulnerable neuronal network.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21860,""
"Discovery-2: an interactive resource for the rational selection and comparison of putative drug target proteins in malaria","Mpangase, Szolkiewicz, le Grange, Smit, Burger, Joubert","https://doi.org/10.1186/1475-2875-12-116","20130909","PubMed","Antimalarials; Computational Biology; Data Mining; Drug Discovery; Humans; Plasmodium falciparum","Drug resistance to anti-malarial compounds remains a serious problem, with resistance to newer pharmaceuticals developing at an alarming rate. The development of new anti-malarials remains a priority, and the rational selection of putative targets is a key element of this process. Discovery-2 is an update of the original Discovery in silico resource for the rational selection of putative drug target proteins, enabling researchers to obtain information for a protein which may be useful for the selection of putative drug targets, and to perform advanced filtering of proteins encoded by the malaria genome based on a series of molecular properties. An updated in silico resource has been developed where researchers are able to mine information on malaria proteins and predicted ligands, as well as perform comparisons to the human and mosquito host characteristics. Protein properties used include: domains, motifs, EC numbers, GO terms, orthologs, protein-protein interactions, protein-ligand interactions. Newly added features include drugability measures from ChEMBL, automated literature relations and links to clinical trial information. Searching by chemical structure is also available. The updated functionality of the Discovery-2 resource is presented, together with a detailed case study of the Plasmodium falciparum S-adenosyl-L-homocysteine hydrolase (PfSAHH) protein. A short example of a chemical search with pyrimethamine is also illustrated. The updated Discovery-2 resource allows researchers to obtain detailed properties of proteins from the malaria genome, which may be of interest in the target selection process, and to perform advanced filtering and selection of proteins based on a relevant range of molecular characteristics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21861,""
"Gastrointestinal adverse effects of short-term aspirin use: a meta-analysis of published randomized controlled trials","Baron, Senn, Voelker, Lanas, Laurora, Thielemann, BrÃƒÂ¼ckner, McCarthy","https://doi.org/10.1007/s40268-013-0011-y","20140120","PubMed","Abdominal Pain; Aspirin; Gastrointestinal Diseases; Humans; Randomized Controlled Trials as Topic; Time Factors; Treatment Outcome","Aspirin is widely used for short-term treatment of pain, fever or colds, but there are only limited data regarding the safety of this use. To summarize the available data on this topic, we conducted a meta-analysis of the published clinical trial literature regarding the gastrointestinal adverse effects of short-term use of aspirin in comparison with placebo and other medications commonly used for the same purpose. An extensive literature search identified 119,310 articles regarding possible adverse effects of aspirin, among which 23,131 appeared to possibly include relevant data. An automated text-mining procedure was used to score the references for potential relevance for the meta-analysis. The 3,983 highest-scoring articles were reviewed individually to identify those with data that could be included in this analysis. Ultimately, 78 relevant articles were identified that contained gastrointestinal adverse event data from clinical trials of aspirin versus placebo or an active comparator. Odds ratios (ORs) computed using a Mantel-Haenszel estimator were used to summarize the comparative effects on dyspepsia, nausea/vomiting, and abdominal pain, considered separately and also aggregated as 'minor gastrointestinal events'. Gastrointestinal bleeds, ulcers, and perforations were also investigated. Data were obtained regarding 19,829 subjects (34 % treated with aspirin, 17 % placebo, and 49 % an active comparator). About half of the aspirin subjects took a single dose. Aspirin was associated with a higher risk of minor gastrointestinal events than placebo or active comparators: the summary ORs were 1.46 (95 % confidence interval [CI] 1.15-1.86) and 1.81 (95 % CI 1.61-2.04), respectively. Ulcers, perforation, and serious bleeding were not seen after use of aspirin or any of the other interventions. During short-term use, aspirin is associated with a higher frequency of gastrointestinal complaints than other medications commonly used for treatment of pain, colds, and fever. Serious adverse events were not observed with aspirin or any of the comparators.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21862,""
"Vaginal repair of ureterovaginal fistula may be suitable for selected cases","Boateng, Eltahawy, Mahdy","https://doi.org/10.1007/s00192-013-2070-6","20140217","PubMed","Adult; Female; Gynecologic Surgical Procedures; Humans; Hysterectomy; Middle Aged; Robotics; Treatment Outcome; Ureter; Ureteral Diseases; Vagina; Vaginal Fistula","Ureterovaginal fistula (UVF) is an uncommon but devastating complication of gynecologic surgery. Management includes ureteral stenting for 6-8 weeks. For stent failure, ureteroneocystostomy (UNC) through an open, laparoscopic, or robotic abdominal approach is the classic alternative. Originally pioneered for repair of vesicovaginal fistulas (VVF), the use of the vaginal approach in UVF is scarcely reported in the literature. We report the successful repair of UVF performed exclusively through the vaginal approach in two women after robotic hysterectomy. In select clinical scenarios, this approach may be applied, as it provides a minimally invasive option for managing UVF after failure of ureteral stenting.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21863,""
"A la Recherche du Temps Perdu: extracting temporal relations from medical text in the 2012 i2b2 NLP challenge","Cherry, Zhu, Martin, de Bruijn","https://doi.org/10.1136/amiajnl-2013-001624","20131217","PubMed","clinical text; information extraction; natural language processing; relation extraction; temporal reasoning; Artificial Intelligence; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Patient Discharge Summaries; Time; Translational Medical Research","An analysis of the timing of events is critical for a deeper understanding of the course of events within a patient record. The 2012 i2b2 NLP challenge focused on the extraction of temporal relationships between concepts within textual hospital discharge summaries. The team from the National Research Council Canada (NRC) submitted three system runs to the second track of the challenge: typifying the time-relationship between pre-annotated entities. The NRC system was designed around four specialist modules containing statistical machine learning classifiers. Each specialist targeted distinct sets of relationships: local relationships, 'sectime'-type relationships, non-local overlap-type relationships, and non-local causal relationships. The best NRC submission achieved a precision of 0.7499, a recall of 0.6431, and an F1 score of 0.6924, resulting in a statistical tie for first place. Post hoc improvements led to a precision of 0.7537, a recall of 0.6455, and an F1 score of 0.6954, giving the highest scores reported on this task to date. Methods for general relation extraction extended well to temporal relations, and gave top-ranked state-of-the-art results. Careful ordering of predictions within result sets proved critical to this success.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21864,""
"Effectiveness of robot-assisted therapy on ankle rehabilitation--a systematic review","Zhang, Davies, Xie","https://doi.org/10.1186/1743-0003-10-30","20130718","PubMed","Adolescent; Adult; Aged; Aged, 80 and over; Ankle; Ankle Injuries; Child; Gait; Humans; Middle Aged; Muscle, Skeletal; Peripheral Nerve Injuries; Rehabilitation; Research Design; Robotics; Treatment Outcome; Young Adult","The aim of this study was to provide a systematic review of studies that investigated the effectiveness of robot-assisted therapy on ankle motor and function recovery from musculoskeletal or neurologic ankle injuries. Thirteen electronic databases of articles published from January, 1980 to June, 2012 were searched using keywords 'ankle*', 'robot*', 'rehabilitat*' or 'treat*' and a free search in Google Scholar based on effects of ankle rehabilitation robots was also conducted. References listed in relevant publications were further screened. Eventually, twenty-nine articles were selected for review and they focused on effects of robot-assisted ankle rehabilitation. Twenty-nine studies met the inclusion criteria and a total of 164 patients and 24 healthy subjects participated in these trials. Ankle performance and gait function were the main outcome measures used to assess the therapeutic effects of robot-assisted ankle rehabilitation. The protocols and therapy treatments were varied, which made comparison among different studies difficult or impossible. Few comparative trials were conducted among different devices or control strategies. Moreover, the majority of study designs met levels of evidence that were no higher than American Academy for Cerebral Palsy (CP) and Developmental Medicine (AACPDM) level IV. Only one study used a Randomized Control Trial (RCT) approach with the evidence level being II. All the selected studies showed improvements in terms of ankle performance or gait function after a period of robot-assisted ankle rehabilitation training. The most effective robot-assisted intervention cannot be determined due to the lack of universal evaluation criteria for various devices and control strategies. Future research into the effects of robot-assisted ankle rehabilitation should be carried out based on universal evaluation criteria, which could determine the most effective method of intervention. It is also essential to conduct trials to analyse the differences among different devices or control strategies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21865,""
"Robotic-assisted laparoscopic radical cystectomy: history, techniques and outcomes","Liss, Kader","https://doi.org/10.1007/s00345-013-1053-z","20140220","PubMed","Blood Loss, Surgical; Cystectomy; History, 21st Century; Humans; Incidence; Laparoscopy; Learning Curve; Lymph Node Excision; Lymph Nodes; Postoperative Complications; Robotics; Treatment Outcome; Urinary Bladder Neoplasms","Robotic-assisted radical cystectomy (RARC) is a less invasive means of performing the radical cystectomy operation, which holds promise for improved patient morbidity. We review the history, technique and current literature pertaining to RARC and place the current results in context with the open procedure. All articles regarding RARC found in PubMed after January 2000 were examined. We selected articles that appeared in high-impact journals, had large patient population size (&gt;80 patients), or were novel in technique or findings. We chose key laparoscopic articles to give reference to the history in transition to robotic radical cystectomy. In addition, we chose classic articles from open radical cystectomy to give reference regarding the newer robotic perioperative outcomes. Studies suggest that a 20-patient learning curve is needed to reach an operative time of 6.5 h, with 30 surgeries performed to reach lymph node counts in excess of 20 (International Robotic Cystectomy Consortium). The only randomized surgical trial comparing open and robotic techniques showed equivalent lymph node yield, which may be surgeon and volume dependent. Literature demonstrates lower estimated blood loss, transfusion rates, early return of bowel function and decreased complications in early small series. RARC and urinary diversion are still early in development and limited to centers with extensive robotic experience and volume, although adoption of the robotic approach is becoming more common. Early studies have shown promise to reduce complications with equivalent oncologic results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21866,""
"Helping oxytocin deliver: considerations in the development of oxytocin-based therapeutics for brain disorders","Macdonald, Feifel","https://doi.org/10.3389/fnins.2013.00035","20130320","PubMed","drug development; humans; intranasal administration; oxytocin; pharmacology; psychiatry","Concerns regarding a drought in psychopharmacology have risen from many quarters. From one perspective, the wellspring of bedrock medications for anxiety disorders, depression, and schizophrenia was serendipitously discovered over 30 year ago, the swell of pharmaceutical investment in drug discovery has receded, and the pipeline's flow of medications with unique mechanisms of action (i.e., glutamatergic agents, CRF antagonists) has slowed to a trickle. Might oxytocin (OT)-based therapeutics be an oasis? Though a large basic science literature and a slowly increasing number of studies in human diseases support this hope, the bulk of extant OT studies in humans are single-dose studies on normals, and do not directly relate to improvements in human brain-based diseases. Instead, these studies have left us with a field pregnant with therapeutic possibilities, but barren of definitive treatments. In this clinically oriented review, we discuss the extant OT literature with an eye toward helping OT deliver on its promise as a therapeutic agent. To this end, we identify 10 key questions that we believe future OT research should address. From this overview, several conclusions are clear: (1) the OT system represents an extremely promising target for novel CNS drug development; (2) there is a pressing need for rigorous, randomized controlled clinical trials targeting actual patients; and (3) in order to inform the design and execution of these vital trials, we need further translational studies addressing the questions posed in this review. Looking forward, we extend a cautious hope that the next decade of OT research will birth OT-targeted treatments that can truly deliver on this system's therapeutic potential.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21867,""
"[Use of PubMed to improve evidence-based medicine in routine urological practice]","Rink, Kluth, Shariat, Chun, Fisch, Dahm","https://doi.org/10.1007/s00120-013-3147-z","20130916","PubMed","Data Mining; Evidence-Based Medicine; Germany; Practice Patterns, Physicians'; PubMed; Urology","Applying evidence-based medicine in daily clinical practice is the basis of patient-centered medicine and knowledge of accurate literature acquisition skills is necessary for informed clinical decision-making. PubMed is an easy accessible, free bibliographic database comprising over 21 million citations from the medical field, life-science journals and online books. The article summarizes the effective use of PubMed in routine urological clinical practice based on a common case scenario. This article explains the simple use of PubMed to obtain the best search results with the highest evidence. Accurate knowledge about the use of PubMed in routine clinical practice can improve evidence-based medicine and also patient treatment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21868,""
"Histological image classification using biologically interpretable shape-based features","Kothari, Phan, Young, Wang","https://doi.org/10.1186/1471-2342-13-9","20130813","PubMed","Algorithms; Artificial Intelligence; Biopsy; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Neoplasms; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity","Automatic cancer diagnostic systems based on histological image classification are important for improving therapeutic decisions. Previous studies propose textural and morphological features for such systems. These features capture patterns in histological images that are useful for both cancer grading and subtyping. However, because many of these features lack a clear biological interpretation, pathologists may be reluctant to adopt these features for clinical diagnosis. We examine the utility of biologically interpretable shape-based features for classification of histological renal tumor images. Using Fourier shape descriptors, we extract shape-based features that capture the distribution of stain-enhanced cellular and tissue structures in each image and evaluate these features using a multi-class prediction model. We compare the predictive performance of the shape-based diagnostic model to that of traditional models, i.e., using textural, morphological and topological features. The shape-based model, with an average accuracy of 77%, outperforms or complements traditional models. We identify the most informative shapes for each renal tumor subtype from the top-selected features. Results suggest that these shapes are not only accurate diagnostic features, but also correlate with known biological characteristics of renal tumors. Shape-based analysis of histological renal tumor images accurately classifies disease subtypes and reveals biologically insightful discriminatory features. This method for shape-based analysis can be extended to other histological datasets to aid pathologists in diagnostic and therapeutic decisions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21869,""
"Improving performance of natural language processing part-of-speech tagging on clinical narratives through domain adaptation","Ferraro, DaumÃƒÂ©, Duvall, Chapman, Harkema, Haug","https://doi.org/10.1136/amiajnl-2012-001453","20131217","PubMed","Clinical Narratives; Domain Adaptation; NLP; Natural Language Processing; POS Tagging; Linguistics; Medical Records Systems, Computerized; Narration; Natural Language Processing","Natural language processing (NLP) tasks are commonly decomposed into subtasks, chained together to form processing pipelines. The residual error produced in these subtasks propagates, adversely affecting the end objectives. Limited availability of annotated clinical data remains a barrier to reaching state-of-the-art operating characteristics using statistically based NLP tools in the clinical domain. Here we explore the unique linguistic constructions of clinical texts and demonstrate the loss in operating characteristics when out-of-the-box part-of-speech (POS) tagging tools are applied to the clinical domain. We test a domain adaptation approach integrating a novel lexical-generation probability rule used in a transformation-based learner to boost POS performance on clinical narratives. Two target corpora from independent healthcare institutions were constructed from high frequency clinical narratives. Four leading POS taggers with their out-of-the-box models trained from general English and biomedical abstracts were evaluated against these clinical corpora. A high performing domain adaptation method, Easy Adapt, was compared to our newly proposed method ClinAdapt. The evaluated POS taggers drop in accuracy by 8.5-15% when tested on clinical narratives. The highest performing tagger reports an accuracy of 88.6%. Domain adaptation with Easy Adapt reports accuracies of 88.3-91.0% on clinical texts. ClinAdapt reports 93.2-93.9%. ClinAdapt successfully boosts POS tagging performance through domain adaptation requiring a modest amount of annotated clinical data. Improving the performance of critical NLP subtasks is expected to reduce pipeline error propagation leading to better overall results on complex processing tasks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21870,""
"Evaluation of robotic and laparoscopic partial nephrectomy for small renal tumours (T1a)","Froghi, Ahmed, Khan, Dasgupta, Challacombe","https://doi.org/10.1111/bju.12053","20131113","PubMed","partial nephrectomy; renal cell cancer; robot-assisted laparoscopic surgery; robotic surgery; Humans; Kidney Neoplasms; Laparoscopy; Neoplasm Staging; Nephrectomy; Robotics","To compare laparoscopic partial nephrectomy (LPN) with robotic PN (RPN) using meta-analytical techniques, since there has been a rise in the incidence of small renal masses (SRM; &lt;4 cm) minimally invasive approaches are becoming more popular in dealing with such pathologies. A systematic review of the literature was performed to identify studies comparing LPN and RPN. Comparative studies evaluating RPN and LPN that fulfilled the inclusion criteria were selected. Data on preoperative, operative (operative time, estimated blood loss [EBL], and warm ischaemia time [WIT]), postoperative (length of stay [LOS]) variables and complications were collected. A meta-analysis using random effect model was performed. A further Bland-Altman analysis of some of the operative variables was done to compare their reproducibility and mean difference in techniques. Six studies matched the selection criteria. In all, 256 patients were analysed (40% RPN and 60% LPN). There was no significant different in EBL (P = 0.12, 95% confidence interval [CI] -12.01 to 104.26). Similarly, there was no significant different in WIT between the groups (P = 0.23, 95% CI -15.22 to 3.70). Also, LOS (P = 0.22, 95% CI -0.38 to 0.09) and overall postoperative complication rates were not significantly different between the groups (P = 0.84, 95% CI -0.05 to 0.06). Despite multiple studies reporting better perioperative variables for RPN, the present study found no significant differences between RPN and LPN. This has implications for both the surgeon and the patient. Lack of randomised controlled trials in addition to a lack of long-term oncological data for RPN are current limitations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21871,""
"Model-based pancreas segmentation in portal venous phase contrast-enhanced CT images","Hammon, Cavallaro, Erdt, Dankerl, Kirschner, Drechsler, Wesarg, Uder, Janka","https://doi.org/10.1007/s10278-013-9586-7","20140717","PubMed","Algorithms; Artificial Intelligence; Contrast Media; Female; Germany; Humans; Image Interpretation, Computer-Assisted; Male; Models, Theoretical; Pancreas; Pattern Recognition, Automated; Portal Vein; Radiographic Image Enhancement; Sensitivity and Specificity; Tomography, X-Ray Computed","This study aims to automatically detect and segment the pancreas in portal venous phase contrast-enhanced computed tomography (CT) images. The institutional review board of the University of Erlangen-Nuremberg approved this study and waived the need for informed consent. Discriminative learning is used to build a pancreas tissue classifier incorporating spatial relationships between the pancreas and surrounding organs and vessels. Furthermore, discrete cosine and wavelet transforms are used to build texture features to describe local tissue appearance. Classification is used to guide a constrained statistical shape model to fit the data. The algorithm to detect and segment the pancreas was evaluated on 40 consecutive CT data that were acquired in the portal venous contrast agent phase. Manual segmentation of the pancreas was carried out by experienced radiologists and served as reference standard. Threefold cross validation was performed. The algorithm-based detection and segmentation yielded an average surface distance of 1.7Ã‚Â mm and an average overlap of 61.2Ã‚Â % compared with the reference standard. The overall runtime of the system was 20.4Ã‚Â min. The presented novel approach enables automatic pancreas segmentation in portal venous phase contrast-enhanced CT images which are included in almost every clinical routine abdominal CT examination. Reliable pancreatic segmentation is crucial for computer-aided detection systems and an organ-specific decision support. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21872,""
"Improving sensitivity of machine learning methods for automated case identification from free-text electronic medical records","Afzal, Schuemie, van Blijderveen, Sen, Sturkenboom, Kors","https://doi.org/10.1186/1472-6947-13-30","20130827","PubMed","Acute Kidney Injury; Algorithms; Artificial Intelligence; Biliary Tract Diseases; Data Collection; Electronic Health Records; Humans; Liver Diseases","Distinguishing cases from non-cases in free-text electronic medical records is an important initial step in observational epidemiological studies, but manual record validation is time-consuming and cumbersome. We compared different approaches to develop an automatic case identification system with high sensitivity to assist manual annotators. We used four different machine-learning algorithms to build case identification systems for two data sets, one comprising hepatobiliary disease patients, the other acute renal failure patients. To improve the sensitivity of the systems, we varied the imbalance ratio between positive cases and negative cases using under- and over-sampling techniques, and applied cost-sensitive learning with various misclassification costs. For the hepatobiliary data set, we obtained a high sensitivity of 0.95 (on a par with manual annotators, as compared to 0.91 for a baseline classifier) with specificity 0.56. For the acute renal failure data set, sensitivity increased from 0.69 to 0.89, with specificity 0.59. Performance differences between the various machine-learning algorithms were not large. Classifiers performed best when trained on data sets with imbalance ratio below 10. We were able to achieve high sensitivity with moderate specificity for automatic case identification on two data sets of electronic medical records. Such a high-sensitive case identification system can be used as a pre-filter to significantly reduce the burden of manual record validation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21873,""
"Genetic analysis of the Trichuris muris-induced model of colitis reveals QTL overlap and a novel gene cluster for establishing colonic inflammation","Levison, Fisher, Hankinson, Zeef, Eyre, Ollier, McLaughlin, Brass, Grencis, Pennock","https://doi.org/10.1186/1471-2164-14-127","20131021","PubMed","Animals; Chromosome Mapping; Chromosomes; Colitis; Genes, Helminth; Genetic Predisposition to Disease; Genome-Wide Association Study; Genotype; Male; Mice; Mice, Inbred AKR; Mice, Inbred BALB C; Microsatellite Repeats; Multigene Family; Phenotype; Polymorphism, Single Nucleotide; Quantitative Trait Loci; Trichuriasis; Trichuris","Genetic susceptibility to colonic inflammation is poorly defined at the gene level. Although Genome Wide Association studies (GWAS) have identified loci in the human genome which confer susceptibility to Inflammatory Bowel Disease (Crohn's and Ulcerative Colitis), it is not clear if precise loci exist which confer susceptibility to inflammation at specific locations within the gut e.g. small versus large intestine. Susceptibility loci for colitis in particular have been defined in the mouse, although specific candidate genes have not been identified to date. We have previously shown that infection with Trichuris muris (T. muris) induces chronic colitis in susceptible mouse strains with clinical, histological, and immunological homology to human colonic Crohn's disease. We performed an integrative analysis of colitis susceptibility, using an F2 inter-cross of resistant (BALB/c) and susceptible (AKR) mice following T. muris infection. Quantitative Trait Loci (QTL), polymorphic and expression data were analysed alongside in silico workflow analyses to discover novel candidate genes central to the development and biology of chronic colitis. 7 autosomal QTL regions were associated with the establishment of chronic colitis following infection. 144 QTL genes had parental strain SNPs and significant gene expression changes in chronic colitis (expression fold-change Ã¢â€°Â¥ +/-1.4). The T. muris QTL on chromosome 3 (Tm3) mapped to published QTL in 3 unrelated experimental models of colitis and contained 33 significantly transcribed polymorphic genes. Phenotypic pathway analysis, text mining and time-course qPCR replication highlighted several potential cis-QTL candidate genes in colitis susceptibility, including FcgR1, Ptpn22, RORc, and Vav3. Genetic susceptibility to induced colonic mucosal inflammation in the mouse is conserved at Tm3 and overlays Cdcs1.1. Genes central to the maintenance of intestinal homeostasis reside within this locus, implicating several candidates in susceptibility to colonic inflammation. Combined methodology incorporating genetic, transcriptional and pathway data allowed identification of biologically relevant candidate genes, with Vav3 newly implicated as a colitis susceptibility gene of functional relevance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21874,""
"An iterative searching and ranking algorithm for prioritising pharmacogenomics genes","Xu, Wang","https://doi.org/10.1504/IJCBDD.2013.052199","20130702","PubMed","Algorithms; Data Mining; Drug Design; Genomics; Humans; Natural Language Processing; Pharmacogenetics; Pharmacological Phenomena; Precision Medicine","Pharmacogenomics (PGx) studies are to identify genetic variants that may affect drug efficacy and toxicity. A machine understandable drug-gene relationship knowledge is important for many computational PGx studies and for personalised medicine. A comprehensive and accurate PGx-specific gene lexicon is important for automatic drug-gene relationship extraction from the scientific literature, rich knowledge source for PGx studies. In this study, we present a bootstrapping learning technique to rank 33,310 human genes with respect to their relevance to drug response. The algorithm uses only one seed PGx gene to iteratively extract and rank co-occurred genes using 20 million MEDLINE abstracts. Our ranking method is able to accurately rank PGx-specific genes highly among all human genes. Compared to randomly ranked genes (precision: 0.032, recall: 0.013, F1: 0.018), the algorithm has achieved significantly better performance (precision: 0.861, recall: 0.548, F1: 0.662) in ranking the top 2.5% of genes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21875,""
"Extracting data from electronic medical records: validation of a natural language processing program to assess prostate biopsy results","Thomas, Zheng, Jung, Chang, Kim, Gelfond, Slezak, Porter, Jacobsen, Chien","https://doi.org/10.1007/s00345-013-1040-4","20141006","PubMed","Adenocarcinoma; Biopsy; California; Cross-Sectional Studies; Electronic Health Records; Humans; Information Storage and Retrieval; Male; Natural Language Processing; Prostate; Prostatic Neoplasms; Reproducibility of Results; Retrospective Studies; Sensitivity and Specificity","The extraction of specific data from electronic medical records (EMR) remains tedious and is often performed manually. Natural language processing (NLP) programs have been developed to identify and extract information within clinical narrative text. We performed a study to assess the validity of an NLP program to accurately identify patients with prostate cancer and to retrieve pertinent pathologic information from their EMR. A retrospective review was performed of a prospectively collected database including patients from the Southern California Kaiser Permanente Medical Region that underwent prostate biopsies during a 2-week period. A NLP program was used to identify patients with prostate biopsies that were positive for prostatic adenocarcinoma from all pathology reports within this period. The application then processed 100 consecutive patients with prostate adenocarcinoma to extract 10 variables from their pathology reports. The extraction and retrieval of information by NLP was then compared to a blinded manual review. A consecutive series of 18,453 pathology reports were evaluated. NLP correctly detected 117 out of 118 patients (99.1%) with prostatic adenocarcinoma after TRUS-guided prostate biopsy. NLP had a positive predictive value of 99.1% with a 99.1% sensitivity and a 99.9% specificity to correctly identify patients with prostatic adenocarcinoma after biopsy. The overall ability of the NLP application to accurately extract variables from the pathology reports was 97.6%. Natural language processing is a reliable and accurate method to identify select patients and to extract relevant data from an existing EMR in order to establish a prospective clinical database.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21876,""
"Recent finding and new technologies in nephrolitiasis: a review of the recent literature","Rosa, Usai, Miano, Kim, Finazzi AgrÃƒÂ², Bove, Micali","https://doi.org/10.1186/1471-2490-13-10","20130711","PubMed","Allopurinol; Citrates; Humans; Lithotripsy; Nephrolithiasis; Robotics; Thiazides; Ureterolithiasis; Ureteroscopy; Xanthine Oxidase","This review summarizes recent literature on advances regarding renal and ureteral calculi, with particular focus in areas of recent advances in the overall field of urolithiasis. Clinical management in everyday practice requires a complete understanding of the issues regarding metabolic evaluation and subgrouping of stone-forming patients, diagnostic procedures, effective treatment regime in acute stone colic, medical expulsive therapy, and active stone removal. In this review we focus on new perspectives in managing nephrolitihiasis and discuss recentadvances, including medical expulsive therapy, new technologies, and refinements of classical therapy such as shock wave lithotripsy, give a fundamental modification of nephrolithiasis management. Overall, this field appears to be the most promising, capable of new developments in ureterorenoscopy and percutaneous approaches. Further improvements are expected from robotic-assisted procedures, such as flexible robotics in ureterorenoscopy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21877,""
"Pivotal role of the muscle-contraction pathway in cryptorchidism and evidence for genomic connections with cardiomyopathy pathways in RASopathies","Cannistraci, Ogorevc, Zorc, Ravasi, Dovc, Kunej","https://doi.org/10.1186/1755-8794-6-5","20130819","PubMed","Animals; Cardiomyopathies; Cluster Analysis; Computational Biology; Cryptorchidism; Data Mining; Databases, Genetic; Genetic Loci; Humans; Internet; Male; Metabolic Networks and Pathways; Mice; Muscle Contraction; Software; User-Computer Interface","Cryptorchidism is the most frequent congenital disorder in male children; however the genetic causes of cryptorchidism remain poorly investigated. Comparative integratomics combined with systems biology approach was employed to elucidate genetic factors and molecular pathways underlying testis descent. Literature mining was performed to collect genomic loci associated with cryptorchidism in seven mammalian species. Information regarding the collected candidate genes was stored in MySQL relational database. Genomic view of the loci was presented using Flash GViewer web tool (http://gmod.org/wiki/Flashgviewer/). DAVID Bioinformatics Resources 6.7 was used for pathway enrichment analysis. Cytoscape plug-in PiNGO 1.11 was employed for protein-network-based prediction of novel candidate genes. Relevant protein-protein interactions were confirmed and visualized using the STRING database (version 9.0). The developed cryptorchidism gene atlas includes 217 candidate loci (genes, regions involved in chromosomal mutations, and copy number variations) identified at the genomic, transcriptomic, and proteomic level. Human orthologs of the collected candidate loci were presented using a genomic map viewer. The cryptorchidism gene atlas is freely available online: http://www.integratomics-time.com/cryptorchidism/. Pathway analysis suggested the presence of twelve enriched pathways associated with the list of 179 literature-derived candidate genes. Additionally, a list of 43 network-predicted novel candidate genes was significantly associated with four enriched pathways. Joint pathway analysis of the collected and predicted candidate genes revealed the pivotal importance of the muscle-contraction pathway in cryptorchidism and evidence for genomic associations with cardiomyopathy pathways in RASopathies. The developed gene atlas represents an important resource for the scientific community researching genetics of cryptorchidism. The collected data will further facilitate development of novel genetic markers and could be of interest for functional studies in animals and human. The proposed network-based systems biology approach elucidates molecular mechanisms underlying co-presence of cryptorchidism and cardiomyopathy in RASopathies. Such approach could also aid in molecular explanation of co-presence of diverse and apparently unrelated clinical manifestations in other syndromes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21878,""
"Mining skeletal phenotype descriptions from scientific literature","Groza, Hunter, Zankl","https://doi.org/10.1371/journal.pone.0055656","20130906","PubMed","Artificial Intelligence; Humans; Phenotype; Skeleton","Phenotype descriptions are important for our understanding of genetics, as they enable the computation and analysis of a varied range of issues related to the genetic and developmental bases of correlated characters. The literature contains a wealth of such phenotype descriptions, usually reported as free-text entries, similar to typical clinical summaries. In this paper, we focus on creating and making available an annotated corpus of skeletal phenotype descriptions. In addition, we present and evaluate a hybrid Machine Learning approach for mining phenotype descriptions from free text. Our hybrid approach uses an ensemble of four classifiers and experiments with several aggregation techniques. The best scoring technique achieves an F-1 score of 71.52%, which is close to the state-of-the-art in other domains, where training data exists in abundance. Finally, we discuss the influence of the features chosen for the model on the overall performance of the method.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21879,""
"A knowledge-based decision support system in bioinformatics: an application to protein complex extraction","Fiannaca, La Rosa, Urso, Rizzo, Gaglio","https://doi.org/10.1186/1471-2105-14-S1-S5","20130802","PubMed","Algorithms; Computational Biology; Decision Support Techniques; Knowledge Bases; Multiprotein Complexes; Protein Interaction Mapping; Saccharomyces cerevisiae Proteins; Software; Workflow","We introduce a Knowledge-based Decision Support System (KDSS) in order to face the Protein Complex Extraction issue. Using a Knowledge Base (KB) coding the expertise about the proposed scenario, our KDSS is able to suggest both strategies and tools, according to the features of input dataset. Our system provides a navigable workflow for the current experiment and furthermore it offers support in the configuration and running of every processing component of that workflow. This last feature makes our system a crossover between classical DSS and Workflow Management Systems. We briefly present the KDSS' architecture and basic concepts used in the design of the knowledge base and the reasoning component. The system is then tested using a subset of Saccharomyces cerevisiae Protein-Protein interaction dataset. We used this subset because it has been well studied in literature by several research groups in the field of complex extraction: in this way we could easily compare the results obtained through our KDSS with theirs. Our system suggests both a preprocessing and a clustering strategy, and for each of them it proposes and eventually runs suited algorithms. Our system's final results are then composed of a workflow of tasks, that can be reused for other experiments, and the specific numerical results for that particular trial. The proposed approach, using the KDSS' knowledge base, provides a novel workflow that gives the best results with regard to the other workflows produced by the system. This workflow and its numeric results have been compared with other approaches about PPI network analysis found in literature, offering similar results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21880,""
"Multi-field-of-view framework for distinguishing tumor grade in ER+ breast cancer from entire histopathology slides","Basavanhally, Ganesan, Feldman, Shih, Mies, Tomaszewski, Madabhushi","https://doi.org/10.1109/TBME.2013.2245129","20140312","PubMed","Algorithms; Artificial Intelligence; Breast Neoplasms; Female; Humans; Image Interpretation, Computer-Assisted; Microscopy; Neoplasm Grading; Pattern Recognition, Automated; Receptors, Estrogen; Reproducibility of Results; Sensitivity and Specificity","Modified Bloom-Richardson (mBR) grading is known to have prognostic value in breast cancer (BCa), yet its use in clinical practice has been limited by intra- and interobserver variability. The development of a computerized system to distinguish mBR grade from entire estrogen receptor-positive (ER+) BCa histopathology slides will help clinicians identify grading discrepancies and improve overall confidence in the diagnostic result. In this paper, we isolate salient image features characterizing tumor morphology and texture to differentiate entire hematoxylin and eosin (H and E) stained histopathology slides based on mBR grade. The features are used in conjunction with a novel multi-field-of-view (multi-FOV) classifier--a whole-slide classifier that extracts features from a multitude of FOVs of varying sizes--to identify important image features at different FOV sizes. Image features utilized include those related to the spatial arrangement of cancer nuclei (i.e., nuclear architecture) and the textural patterns within nuclei (i.e., nuclear texture). Using slides from 126 ER+ patients (46 low, 60 intermediate, and 20 high mBR grade), our grading system was able to distinguish low versus high, low versus intermediate, and intermediate versus high grade patients with area under curve values of 0.93, 0.72, and 0.74, respectively. Our results suggest that the multi-FOV classifier is able to 1) successfully discriminate low, medium, and high mBR grade and 2) identify specific image features at different FOV sizes that are important for distinguishing mBR grade in H and E stained ER+ BCa histology slides.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21881,""
"PhenoDB: a new web-based tool for the collection, storage, and analysis of phenotypic features","Hamosh, Sobreira, Hoover-Fong, Sutton, Boehm, Schiettecatte, Valle","https://doi.org/10.1002/humu.22283","20130906","PubMed","Databases, Factual; Genomics; Humans; Internet; Medical Informatics; Phenotype; Software","To interpret whole exome/genome sequence data for clinical and research purposes, comprehensive phenotypic information, knowledge of pedigree structure, and results of previous clinical testing are essential. With these requirements in mind and to meet the needs of the Centers for Mendelian Genomics project, we have developed PhenoDB (http://phenodb.net), a secure, Web-based portal for entry, storage, and analysis of phenotypic and other clinical information. The phenotypic features are organized hierarchically according to the major headings and subheadings of the Online Mendelian Inheritance in Man (OMIMÃ‚Â®) clinical synopses, with further subdivisions according to structure and function. Every string allows for a free-text entry. All of the approximately 2,900 features use the preferred term from Elements of Morphology and are fully searchable and mapped to the Human Phenotype Ontology and Elements of Morphology. The PhenoDB allows for ascertainment of relevant information from a case in a family or cohort, which is then searchable by family, OMIM number, phenotypic feature, mode of inheritance, genes screened, and so on. The database can also be used to format phenotypic data for submission to dbGaP for appropriately consented individuals. PhenoDB was built using Django, an open source Web development tool, and is freely available through the Johns Hopkins McKusick-Nathans Institute of Genetic Medicine (http://phenodb.net).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21882,""
"A predictive signature gene set for discriminating active from latent tuberculosis in Warao Amerindian children","Verhagen, Zomer, Maes, Villalba, Del Nogal, Eleveld, van Hijum, de Waard, Hermans","https://doi.org/10.1186/1471-2164-14-74","20130628","PubMed","Adolescent; Adult; Case-Control Studies; Child; Child, Preschool; Female; Gene Expression Profiling; Genomics; Humans; Indians, North American; Infant; Male; Reproducibility of Results; Tuberculosis","Tuberculosis (TB) continues to cause a high toll of disease and death among children worldwide. The diagnosis of childhood TB is challenged by the paucibacillary nature of the disease and the difficulties in obtaining specimens. Whereas scientific and clinical research efforts to develop novel diagnostic tools have focused on TB in adults, childhood TB has been relatively neglected. Blood transcriptional profiling has improved our understanding of disease pathogenesis of adult TB and may offer future leads for diagnosis and treatment. No studies applying gene expression profiling of children with TB have been published so far. We identified a 116-gene signature set that showed an average prediction error of 11% for TB vs. latent TB infection (LTBI) and for TB vs. LTBI vs. healthy controls (HC) in our dataset. A minimal gene set of only 9 genes showed the same prediction error of 11% for TB vs. LTBI in our dataset. Furthermore, this minimal set showed a significant discriminatory value for TB vs. LTBI for all previously published adult studies using whole blood gene expression, with average prediction errors between 17% and 23%. In order to identify a robust representative gene set that would perform well in populations of different genetic backgrounds, we selected ten genes that were highly discriminative between TB, LTBI and HC in all literature datasets as well as in our dataset. Functional annotation of these genes highlights a possible role for genes involved in calcium signaling and calcium metabolism as biomarkers for active TB. These ten genes were validated by quantitative real-time polymerase chain reaction in an additional cohort of 54 Warao Amerindian children with LTBI, HC and non-TB pneumonia. Decision tree analysis indicated that five of the ten genes were sufficient to classify 78% of the TB cases correctly with no LTBI subjects wrongly classified as TB (100% specificity). Our data justify the further exploration of our signature set as biomarkers for potential childhood TB diagnosis. We show that, as the identification of different biomarkers in ethnically distinct cohorts is apparent, it is important to cross-validate newly identified markers in all available cohorts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21883,""
"Temporal modulation transfer function for efficient assessment of auditory temporal resolution","Shen, Richards","https://doi.org/10.1121/1.4773271","20130719","PubMed","Acoustic Stimulation; Adolescent; Adult; Algorithms; Audiometry; Auditory Perception; Auditory Threshold; Bayes Theorem; Cues; Humans; Psychoacoustics; Signal Detection, Psychological; Time Factors; Time Perception; Young Adult","Two common measures of auditory temporal resolution are the temporal modulation transfer function (TMTF) and the gap detection threshold (GDT). The current study addresses the lack of efficient psychophysical procedures for collecting TMTFs and the lack of literature on the comparisons of TMTF and GDT. Two procedures for efficient measurements of the TMTF are proposed: (1) A Bayesian procedure that adaptively chooses the stimulus modulation rate and depth to maximize the information gain from each trial and (2) a procedure that reduces the data collection to two adaptive staircase tracks. Results from experiments I and II showed that, for broadband carriers, these approaches provided similar results compared to TMTFs measured using traditional methods despite taking less than 10Ã¢â‚¬â€°min for data collection. Using these efficient procedures, TMTFs were measured from a large number of naive listeners and were compared to the gap detection thresholds collected from the same ears in experiment III. Results showed that the sensitivity parameter estimated from the TMTF measurements correlated well with the GDTs, whereas the cutoff rate is either uncorrelated or positively correlated with the gap detection threshold. These results suggest caution in interpreting a lower GDT as evidence for less sluggish temporal processing.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21884,""
"Towards comprehensive syntactic and semantic annotations of the clinical narrative","Albright, Lanfranchi, Fredriksen, Styler, Warner, Hwang, Choi, Dligach, Nielsen, Martin, Ward, Palmer, Savova","https://doi.org/10.1136/amiajnl-2012-001317","20131217","PubMed","Gold Standard Annotations; Natural Language Processing; Propbank; Treebank; UMLS; cTAKES; Electronic Health Records; Humans; Linguistics; Narration; Natural Language Processing; Semantics","To create annotated clinical narratives with layers of syntactic and semantic labels to facilitate advances in clinical natural language processing (NLP). To develop NLP algorithms and open source components. Manual annotation of a clinical narrative corpus of 127 606 tokens following the Treebank schema for syntactic information, PropBank schema for predicate-argument structures, and the Unified Medical Language System (UMLS) schema for semantic information. NLP components were developed. The final corpus consists of 13 091 sentences containing 1772 distinct predicate lemmas. Of the 766 newly created PropBank frames, 74 are verbs. There are 28 539 named entity (NE) annotations spread over 15 UMLS semantic groups, one UMLS semantic type, and the Person semantic category. The most frequent annotations belong to the UMLS semantic groups of Procedures (15.71%), Disorders (14.74%), Concepts and Ideas (15.10%), Anatomy (12.80%), Chemicals and Drugs (7.49%), and the UMLS semantic type of Sign or Symptom (12.46%). Inter-annotator agreement results: Treebank (0.926), PropBank (0.891-0.931), NE (0.697-0.750). The part-of-speech tagger, constituency parser, dependency parser, and semantic role labeler are built from the corpus and released open source. A significant limitation uncovered by this project is the need for the NLP community to develop a widely agreed-upon schema for the annotation of clinical concepts and their relations. This project takes a foundational step towards bringing the field of clinical NLP up to par with NLP in the general domain. The corpus creation and NLP components provide a resource for research and application development that would have been previously impossible.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21885,""
"Multimodality GPU-based computer-assisted diagnosis of breast cancer using ultrasound and digital mammography images","Sidiropoulos, Kostopoulos, Glotsos, Athanasiadis, Dimitropoulos, Stonham, Cavouras","https://doi.org/10.1007/s11548-013-0813-y","20140311","PubMed","Adult; Aged; Algorithms; Breast Neoplasms; Computer Graphics; Diagnosis, Computer-Assisted; Female; Humans; Image Interpretation, Computer-Assisted; Mammography; Middle Aged; Multimodal Imaging; Neural Networks, Computer; Reproducibility of Results; Ultrasonography, Mammary","To improve the computer-aided diagnosis of breast lesions, by designing a pattern recognition system (PR-system) on commercial graphics processing unit (GPU) cards using parallel programming and textural information from multimodality imaging. Patients with histologically verified breast lesions underwent both ultrasound (US) and digital mammography (DM), lesions were outlined on the images by an experienced radiologist, and textural features were calculated. The PR-system was designed to provide highest possible precision by programming in parallel the multiprocessors of the NVIDIA's GPU cards, GeForce 8800GT or 580GTX, and using the CUDA programming framework and C++. The PR-system was built around the probabilistic neural network classifier, and its performance was evaluated by a re-substitution method, for estimating the system's highest accuracy, and by the external cross-validation method, for assessing the PR-system's unbiased accuracy to new, ""unseen"" by the system, data. Classification accuracies for discriminating malignant from benign lesions were as follows: 85.5 % using US-features alone, 82.3 % employing DM features alone, and 93.5 % combining US and DM features. Mean accuracy to new ""unseen"" data for the combined US and DM features was 81 %. Those classification accuracies were about 10 % higher than accuracies achieved on a single CPU, using sequential programming methods, and 150-fold faster. The proposed PR-system improves breast-lesion discrimination accuracy, it may be redesigned on site when new verified data are incorporated in its depository, and it may serve as a second opinion tool in a clinical environment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21886,""
"Some improvements are apparent in identifying adverse effects in systematic reviews from 1994 to 2011","Golder, Loke, Zorzela","https://doi.org/10.1016/j.jclinepi.2012.09.013","20130405","PubMed","Databases, Bibliographic; Drug-Related Side Effects and Adverse Reactions; Evidence-Based Medicine; Humans; Review Literature as Topic; Therapeutics","An increasing amount of research and guidelines has been published on search methodology and the reporting of search strategies in systematic reviews. This research assessed whether this has lead to any improvements in the reporting and quality of searching in systematic reviews of adverse effects. All records within Cochrane Database of Systematic Reviews and Database of Abstracts of Reviews of Effects were scanned for systematic reviews of adverse effects. Data were then extracted on the methods used for information retrieval in these reviews and a descriptive analysis conducted by publication year. A total of 849 reviews published from 1994 to 2011 met the inclusion criteria. There has been a significant increase (P&lt;0.001) in the number of adverse effects reviews per year from 1994 (n=5) to 2010 (n=104). Some improvements were apparent, such as an increase in the number of databases searched and fewer date and language restrictions applied. However, there has been an increase in reviews limited to data from randomized controlled trials, whereas the reporting of search strategies could still be improved further, with only 9% (74/849) of the reviews reporting reproducible searches. Some improvements in searching systematic reviews of adverse effects are apparent; however, poor reporting of search strategies remains a great obstacle to readers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21887,""
"Expert System Shells for Rapid Clinical Decision Support Module Development: An ESTA Demonstration of a Simple Rule-Based System for the Diagnosis of Vaginal Discharge","Kamel Boulos","https://doi.org/10.4258/hir.2012.18.4.252","20130704","PubMed","Clinical Decision Support Systems; Computer-Assisted Decision Making; Expert Systems; Knowledge Bases; Software Design","This study demonstrates the feasibility of using expert system shells for rapid clinical decision support module development. A readily available expert system shell was used to build a simple rule-based system for the crude diagnosis of vaginal discharge. Pictures and 'canned text explanations' are extensively used throughout the program to enhance its intuitiveness and educational dimension. All the steps involved in developing the system are documented. The system runs under Microsoft Windows and is available as a free download at http://healthcybermap.org/vagdisch.zip (the distribution archive includes both the program's executable and the commented knowledge base source as a text document). The limitations of the demonstration system, such as the lack of provisions for assessing uncertainty or various degrees of severity of a sign or symptom, are discussed in detail. Ways of improving the system, such as porting it to the Web and packaging it as an app for smartphones and tablets, are also presented. An easy-to-use expert system shell enables clinicians to rapidly become their own 'knowledge engineers' and develop concise evidence-based decision support modules of simple to moderate complexity, targeting clinical practitioners, medical and nursing students, as well as patients, their lay carers and the general public (where appropriate). In the spirit of the social Web, it is hoped that an online repository can be created to peer review, share and re-use knowledge base modules covering various clinical problems and algorithms, as a service to the clinical community.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21888,""
"Meaningful measurement: developing a measurement system to improve blood pressure control in patients with chronic kidney disease","Greenberg, Vakharia, Szent-Gyorgyi, Desai, Turchin, Forman, Bonventre, Kachalia","https://doi.org/10.1136/amiajnl-2012-001308","20130813","PubMed","chronic disease management; chronic kidney disease; population management; quality improvement; registries; Algorithms; Humans; Hypertension; Information Systems; Registries; Renal Insufficiency, Chronic","To develop an electronic registry of patients with chronic kidney disease (CKD) treated in a nephrology practice in order to provide clinically meaningful measurement and population management to improve rates of blood pressure (BP) control. We combined data from multiple electronic sources: the billing system, structured fields in the electronic health record (EHR), and free text physician notes using natural language processing (NLP). We also used point-of-care worksheets to capture clinical rationale. Nephrologist billing accurately identified patients with CKD. Using an algorithm that incorporated multiple BP readings increased the measured rate of control (130/80 mm Hg) from 37.1% to 42.3%. With the addition of NLP to capture BP readings from free text notes, the rate was 52.6%. Data from point-of-care worksheets indicated that in 52% of visits in which patients were identified as not having controlled BP, patients were actually at goal based on BP readings taken at home or on that day in the office. Building a method for clinically meaningful continuous performance measurement of BP control is possible, but will require data from multiple sources. Electronic measurement systems need to grow to be able to capture and process performance data from patients as well as in real-time from physicians.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21889,""
"Protein network-based Lasso regression model for the construction of disease-miRNA functional interactions","Qabaja, Alshalalfa, Bismar, Alhajj","https://doi.org/10.1186/1687-4153-2013-3","20130326","PubMed","","There is a growing body of evidence associating microRNAs (miRNAs) with human diseases. MiRNAs are new key players in the disease paradigm demonstrating roles in several human diseases. The functional association between miRNAs and diseases remains largely unclear and far from complete. With the advent of high-throughput functional genomics techniques that infer genes and biological pathways dysregulted in diseases, it is now possible to infer functional association between diseases and biological molecules by integrating disparate biological information. Here, we first used Lasso regression model to identify miRNAs associated with disease signature as a proof of concept. Then we proposed an integrated approach that uses disease-gene associations from microarray experiments and text mining, and miRNA-gene association from computational predictions and protein networks to build functional associations network between miRNAs and diseases. The findings of the proposed model were validated against gold standard datasets using ROC analysis and results were promising (AUC=0.81). Our protein network-based approach discovered 19 new functional associations between prostate cancer and miRNAs. The new 19 associations were validated using miRNA expression data and clinical profiles and showed to act as diagnostic and prognostic prostate biomarkers. The proposed integrated approach allowed us to reconstruct functional associations between miRNAs and human diseases and uncovered functional roles of newly discovered miRNAs. Lasso regression was used to find associations between diseases and miRNAs using their gene signature. Defining miRNA gene signature by integrating the downstream effect of miRNAs demonstrated better performance than the miRNA signature alone. Integrating biological networks and multiple data to define miRNA and disease gene signature demonstrated high performance to uncover new functional associations between miRNAs and diseases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21890,""
"Automated differentiation of glioblastomas from intracranial metastases using 3T MR spectroscopic and perfusion data","Tsolaki, Svolos, Kousi, Kapsalaki, Fountas, Theodorou, Tsougos","https://doi.org/10.1007/s11548-012-0808-0","20140916","PubMed","Adult; Aged; Algorithms; Bayes Theorem; Brain Neoplasms; Diagnosis, Differential; Female; Glioblastoma; Humans; Magnetic Resonance Spectroscopy; Male; Middle Aged; Neoplasm Metastasis; Pattern Recognition, Automated; Reproducibility of Results","Differentiation of glioblastomas from metastases is clinical important, but may be difficult even for expert observers. To investigate the contribution of machine learning algorithms in the differentiation of glioblastomas multiforme (GB) from metastases, we developed and tested a pattern recognition system based on 3T magnetic resonance (MR) data. Single and multi-voxel proton magnetic resonance spectroscopy (1H-MRS) and dynamic susceptibility contrast (DSC) MRI scans were performed on 49 patients with solitary brain tumors (35 glioblastoma multiforme and 14 metastases). Metabolic (NAA/Cr, Cho/Cr, (Lip [Formula: see text] Lac)/Cr) and perfusion (rCBV) parameters were measured in both intratumoral and peritumoral regions. The statistical significance of these parameters was evaluated. For the classification procedure, three datasets were created to find the optimum combination of parameters that provides maximum differentiation. Three machine learning methods were utilized: NaÃƒÂ¯ve-Bayes, Support Vector Machine (SVM) and [Formula: see text]-nearest neighbor (KNN). The discrimination ability of each classifier was evaluated with quantitative performance metrics. Glioblastoma and metastases were differentiable only in the peritumoral region of these lesions ([Formula: see text]). SVM achieved the highest overall performance (accuracy 98%) for both the intratumoral and peritumoral areas. NaÃƒÂ¯ve-Bayes and KNN presented greater variations in performance. The proper selection of datasets plays a very significant role as they are closely correlated to the underlying pathophysiology. The application of pattern recognition techniques using 3T MR-based perfusion and metabolic features may provide incremental diagnostic value in the differentiation of common intraaxial brain tumors, such as glioblastoma versus metastasis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21891,""
"Automatic identification of heart failure diagnostic criteria, using text analysis of clinical notes from electronic health records","Byrd, Steinhubl, Sun, Ebadollahi, Stewart","https://doi.org/10.1016/j.ijmedinf.2012.12.005","20150804","PubMed","Diagnostic criteria; Electronic health records; Heart failure; Natural language processing; Text mining; Cohort Studies; Data Mining; Electronic Data Processing; Electronic Health Records; Heart Failure; Humans; Natural Language Processing; Population Surveillance; Primary Health Care","Early detection of Heart Failure (HF) could mitigate the enormous individual and societal burden from this disease. Clinical detection is based, in part, on recognition of the multiple signs and symptoms comprising the Framingham HF diagnostic criteria that are typically documented, but not necessarily synthesized, by primary care physicians well before more specific diagnostic studies are done. We developed a natural language processing (NLP) procedure to identify Framingham HF signs and symptoms among primary care patients, using electronic health record (EHR) clinical notes, as a prelude to pattern analysis and clinical decision support for early detection of HF. We developed a hybrid NLP pipeline that performs two levels of analysis: (1) At the criteria mention level, a rule-based NLP system is constructed to annotate all affirmative and negative mentions of Framingham criteria. (2) At the encounter level, we construct a system to label encounters according to whether any Framingham criterion is asserted, denied, or unknown. Precision, recall, and F-score are used as performance metrics for criteria mention extraction and for encounter labeling. Our criteria mention extractions achieve a precision of 0.925, a recall of 0.896, and an F-score of 0.910. Encounter labeling achieves an F-score of 0.932. Our system accurately identifies and labels affirmations and denials of Framingham diagnostic criteria in primary care clinical notes and may help in the attempt to improve the early detection of HF. With adaptation and tooling, our development methodology can be repeated in new problem settings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21892,""
"The curation of genetic variants: difficulties and possible solutions","Pandey, Maden, Poudel, Pradhananga, Sharma","https://doi.org/10.1016/j.gpb.2012.06.006","20130705","PubMed","Animals; Databases, Genetic; Documentation; Genes; Genetic Variation; Humans; Software; Terminology as Topic","The curation of genetic variants from biomedical articles is required for various clinical and research purposes. Nowadays, establishment of variant databases that include overall information about variants is becoming quite popular. These databases have immense utility, serving as a user-friendly information storehouse of variants for information seekers. While manual curation is the gold standard method for curation of variants, it can turn out to be time-consuming on a large scale thus necessitating the need for automation. Curation of variants described in biomedical literature may not be straightforward mainly due to various nomenclature and expression issues. Though current trends in paper writing on variants is inclined to the standard nomenclature such that variants can easily be retrieved, we have a massive store of variants in the literature that are present as non-standard names and the online search engines that are predominantly used may not be capable of finding them. For effective curation of variants, knowledge about the overall process of curation, nature and types of difficulties in curation, and ways to tackle the difficulties during the task are crucial. Only by effective curation, can variants be correctly interpreted. This paper presents the process and difficulties of curation of genetic variants with possible solutions and suggestions from our work experience in the field including literature support. The paper also highlights aspects of interpretation of genetic variants and the importance of writing papers on variants following standard and retrievable methods.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21893,""
"A reference standard for evaluation of methods for drug safety signal detection using electronic healthcare record databases","Coloma, Avillach, Salvo, Schuemie, Ferrajolo, Pariente, Fourrier-RÃƒÂ©glat, Molokhia, Patadia, van der Lei, Sturkenboom, TrifirÃƒÂ²","https://doi.org/10.1007/s40264-012-0002-x","20130610","PubMed","Adverse Drug Reaction Reporting Systems; Databases, Factual; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Humans; Pharmacovigilance; Product Surveillance, Postmarketing; Reference Standards","The growing interest in using electronic healthcare record (EHR) databases for drug safety surveillance has spurred development of new methodologies for signal detection. Although several drugs have been withdrawn postmarketing by regulatory authorities after scientific evaluation of harms and benefits, there is no definitive list of confirmed signals (i.e. list of all known adverse reactions and which drugs can cause them). As there is no true gold standard, prospective evaluation of signal detection methods remains a challenge. Within the context of methods development and evaluation in the EU-ADR Project (Exploring and Understanding Adverse Drug Reactions by integrative mining of clinical records and biomedical knowledge), we propose a surrogate reference standard of drug-adverse event associations based on existing scientific literature and expert opinion. The reference standard was constructed for ten top-ranked events judged as important in pharmacovigilance. A stepwise approach was employed to identify which, among a list of drug-event associations, are well recognized (known positive associations) or highly unlikely ('negative controls') based on MEDLINE-indexed publications, drug product labels, spontaneous reports made to the WHO's pharmacovigilance database, and expert opinion. Only drugs with adequate exposure in the EU-ADR database network (comprising Ã¢â€°Ë†60 million person-years of healthcare data) to allow detection of an association were considered. Manual verification of positive associations and negative controls was independently performed by two experts proficient in clinical medicine, pharmacoepidemiology and pharmacovigilance. A third expert adjudicated equivocal cases and arbitrated any disagreement between evaluators. Overall, 94 drug-event associations comprised the reference standard, which included 44 positive associations and 50 negative controls for the ten events of interest: bullous eruptions; acute renal failure; anaphylactic shock; acute myocardial infarction; rhabdomyolysis; aplastic anaemia/pancytopenia; neutropenia/agranulocytosis; cardiac valve fibrosis; acute liver injury; and upper gastrointestinal bleeding. For cardiac valve fibrosis, there was no drug with adequate exposure in the database network that satisfied the criteria for a positive association. A strategy for the construction of a reference standard to evaluate signal detection methods that use EHR has been proposed. The resulting reference standard is by no means definitive, however, and should be seen as dynamic. As knowledge on drug safety evolves over time and new issues in drug safety arise, this reference standard can be re-evaluated.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21894,""
"Biomarkers of Alzheimer's disease among Mexican Americans","O'Bryant, Xiao, Edwards, Devous, Gupta, Martins, Zhang, Barber, Doody, Rountree, Pavlik, Chan, Massman, Darby, Evans, Khaleeq, Schrimsher, Dentino, Orozco, Ramirez, Fairchild, Knebl, Hall, Mains, Johnson, Alvarez, Braddock, McCallum, Adams, Rosenberg, Weiner, Quiceno, Reisch, Williams, Huebinger, Svetlik, Werry, Smith, Royall, Palmer, Polk","https://doi.org/10.3233/JAD-122074","20130912","PubMed","Aged; Aged, 80 and over; Alzheimer Disease; Biomarkers; CD40 Antigens; Female; Glucagon-Like Peptide 1; Glucagon-Like Peptides; Humans; Insulin; Male; Mental Status Schedule; Mexican Americans; Middle Aged; Pancreatic Polypeptide; Sensitivity and Specificity; Somatomedins","Mexican Americans are the fastest aging segment of the U.S. population, yet little scientific literature exists regarding the Alzheimer's disease (AD) among this segment of the population. The extant literature suggests that biomarkers of AD will vary according to race/ethnicity though no prior work has explicitly studied this possibility. The aim of this study was to create a serum-based biomarker profile of AD among Mexican American. Data were analyzed from 363 Mexican American participants (49 AD and 314 normal controls) enrolled in the Texas Alzheimer's Research &amp; Care Consortium (TARCC). Non-fasting serum samples were analyzed using a luminex-based multi-plex platform. A biomarker profile was generated using random forest analyses. The biomarker profile of AD among Mexican Americans was different from prior work from non-Hispanic populations with regards to the variable importance plots. In fact, many of the top markers were related to metabolic factors (e.g., FABP, GLP-1, CD40, pancreatic polypeptide, insulin-like-growth factor, and insulin). The biomarker profile was a significant classifier of AD status yielding an area under the receiver operating characteristic curve, sensitivity, and specificity of 0.77, 0.92, and 0.64, respectively. Combining biomarkers with clinical variables yielded a better balance of sensitivity and specificity. The biomarker profile for AD among Mexican American cases is significantly different from that previously identified among non-Hispanic cases from many large-scale studies. This is the first study to explicitly examine and provide support for blood-based biomarkers of AD among Mexican Americans. Areas for future research are highlighted.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21895,""
"Current status of robot assisted laparoscopic radical nephroureterectomy for management of upper tract urothelial carcinoma","Lim, Shin, Rha","https://doi.org/10.1007/s11934-012-0303-8","20130819","PubMed","Carcinoma, Transitional Cell; Humans; Kidney Neoplasms; Kidney Pelvis; Laparoscopy; Nephrectomy; Robotics; Treatment Outcome; Ureter; Ureteral Neoplasms","Upper tract urothelial carcinomas (UUT-UC) are usually aggressive tumours and require radical treatments. The standard of care for localised UUT-UC is radical nephroureterectomy (RNU). Robot-assisted laparoscopic surgeries are currently employed in various urological procedures, including RNU. We conducted a literature search on medical databases (PubMed/ MEDLINE) using free text keywords nephroureterectomy, distal ureter, bladder cuff, urothelial carcinoma and/or robotic. In this review, we aim to provide an up-to-date status on robot-assisted laparoscopic nephroureterectomy (RAL-NU) for the management of UUT-UC. The various surgical techniques and approaches for RAL-NU and retroperitoneal lymph node dissection (RPLND) will be discussed and their perioperative and early oncological outcomes reported. The feasibility and safety of RAL-NU has been demonstrated in a number of studies but intermediate and long term clinical and oncological outcomes are still lacking.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21896,""
"Robotic total mesorectal excision: operative technique and review of the literature","Kim, Kwak","https://doi.org/10.1007/s10151-012-0939-x","20130822","PubMed","Humans; Laparoscopy; Ligation; Minimally Invasive Surgical Procedures; Patient Positioning; Patient Safety; Recovery of Function; Rectal Neoplasms; Robotics","In recent years, an increasing number of reports have been published on robotic colorectal surgery; this modality has also garnered an increasing amount of attention from the colorectal society. Most of the interest has been in robotic total mesorectal excision (TME) for rectal cancer. The purpose of this article is to briefly introduce our technique for total robotic TME and to review the recent literature regarding robotic TME for rectal cancer to summarize the current evidence on clinical and oncologic outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21897,""
"Automated assessment of medical training evaluation text","Zhang, Pakhomov, Gladding, Aylward, Borman-Shoap, Melton","https://www.google.com/search?q=Automated+assessment+of+medical+training+evaluation+text.","20130730","PubMed","Clinical Competence; Data Mining; Educational Measurement; Feasibility Studies; Humans; Internship and Residency; Natural Language Processing; Pilot Projects","Medical post-graduate residency training and medical student training increasingly utilize electronic systems to evaluate trainee performance based on defined training competencies with quantitative and qualitative data, the later of which typically consists of text comments. Medical education is concomitantly becoming a growing area of clinical research. While electronic systems have proliferated in number, little work has been done to help manage and analyze qualitative data from these evaluations. We explored the use of text-mining techniques to assist medical education researchers in sentiment analysis and topic analysis of residency evaluations with a sample of 812 evaluation statements. While comments were predominantly positive, sentiment analysis improved the ability to discriminate statements with 93% accuracy. Similar to other domains, Latent Dirichlet Analysis and Information Gain revealed groups of core subjects and appear to be useful for identifying topics from this data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21898,""
"Automated disambiguation of acronyms and abbreviations in clinical texts: window and training size considerations","Moon, Pakhomov, Melton","https://www.google.com/search?q=Automated+disambiguation+of+acronyms+and+abbreviations+in+clinical+texts:+window+and+training+size+considerations.","20130730","PubMed","Abbreviations as Topic; Artificial Intelligence; Bayes Theorem; Decision Trees; Electronic Health Records; Natural Language Processing; Support Vector Machine","Acronyms and abbreviations within electronic clinical texts are widespread and often associated with multiple senses. Automated acronym sense disambiguation (WSD), a task of assigning the context-appropriate sense to ambiguous clinical acronyms and abbreviations, represents an active problem for medical natural language processing (NLP) systems. In this paper, fifty clinical acronyms and abbreviations with 500 samples each were studied using supervised machine-learning techniques (Support Vector Machines (SVM), NaÃƒÂ¯ve Bayes (NB), and Decision Trees (DT)) to optimize the window size and orientation and determine the minimum training sample size needed for optimal performance. Our analysis of window size and orientation showed best performance using a larger left-sided and smaller right-sided window. To achieve an accuracy of over 90%, the minimum required training sample size was approximately 125 samples for SVM classifiers with inverted cross-validation. These findings support future work in clinical acronym and abbreviation WSD and require validation with other clinical texts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21899,""
"EpiDEA: extracting structured epilepsy and seizure information from patient discharge summaries for cohort identification","Cui, Bozorgi, Lhatoo, Zhang, Sahoo","https://www.google.com/search?q=EpiDEA:+extracting+structured+epilepsy+and+seizure+information+from+patient+discharge+summaries+for+cohort+identification.","20130730","PubMed","Algorithms; Anticonvulsants; Cause of Death; Data Mining; Death, Sudden; Electroencephalography; Epilepsy; Humans; Magnetic Resonance Imaging; Natural Language Processing; Patient Discharge; Seizures; Vocabulary, Controlled","Sudden Unexpected Death in Epilepsy (SUDEP) is a poorly understood phenomenon. Patient cohorts to power statistical studies in SUDEP need to be drawn from multiple centers due to the low rate of reported SUDEP incidences. But the current practice of manual chart review of Epilepsy Monitoring Units (EMU) patient discharge summaries is time-consuming, tedious, and not scalable for large studies. To address this challenge in the multi-center NIH-funded Prevention and Risk Identification of SUDEP Mortality (PRISM) Project, we have developed the Epilepsy Data Extraction and Annotation (EpiDEA) system for effective processing of discharge summaries. EpiDEA uses a novel Epilepsy and Seizure Ontology (EpSO), which has been developed based on the International League Against Epilepsy (ILAE) classification system, as the core knowledge resource. By extending the cTAKES natural language processing tool developed at the Mayo Clinic, EpiDEA implements specialized functions to address the unique challenges of processing epilepsy and seizure-related clinical free text in discharge summaries. The EpiDEA system was evaluated on a corpus of 104 discharge summaries from the University Hospitals Case Medical Center EMU and achieved an overall precision of 93.59% and recall of 84.01% with an F-measure of 88.53%. The results were compared against a gold standard created by two epileptologists. We demonstrate the use of EpiDEA for cohort identification through use of an intuitive visual query interface that can be directly used by clinical researchers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21900,""
"Automatic adverse drug events detection using letters to the editor","Yang, Srinivasan, Polgreen","https://www.google.com/search?q=Automatic+adverse+drug+events+detection+using+letters+to+the+editor.","20130730","PubMed","Adverse Drug Reaction Reporting Systems; Correspondence as Topic; Drug-Related Side Effects and Adverse Reactions; Humans; Natural Language Processing; Product Surveillance, Postmarketing","We present and test the intuition that letters to the editor in journals carry early signals of adverse drug events (ADEs). Surprisingly these letters have not yet been exploited for automatic ADE detection unlike for example, clinical records and PubMed. Part of the challenge is that it is not easy to access the full-text of letters (for the most part these do not appear in PubMed). Also letters are likely underrated in comparison with full articles. Besides demonstrating that this intuition holds we contribute techniques for post market drug surveillance. Specifically, we test an automatic approach for ADE detection from letters using off-the-shelf machine learning tools. We also involve natural language processing for feature definitions. Overall we achieve high accuracy in our experiments and our method also works well on a second new test set. Our results encourage us to further pursue this line of research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21901,""
"Combining corpus-derived sense profiles with estimated frequency information to disambiguate clinical abbreviations","Xu, Stetson, Friedman","https://www.google.com/search?q=Combining+corpus-derived+sense+profiles+with+estimated+frequency+information+to+disambiguate+clinical+abbreviations.","20130730","PubMed","Abbreviations as Topic; Electronic Health Records; Humans; Natural Language Processing; Pattern Recognition, Automated","Abbreviations are widely used in clinical notes and are often ambiguous. Word sense disambiguation (WSD) for clinical abbreviations therefore is a critical task for many clinical natural language processing (NLP) systems. Supervised machine learning based WSD methods are known for their high performance. However, it is time consuming and costly to construct annotated samples for supervised WSD approaches and sense frequency information is often ignored by these methods. In this study, we proposed a profile-based method that used dictated discharge summaries as an external source to automatically build sense profiles and applied them to disambiguate abbreviations in hospital admission notes via the vector space model. Our evaluation using a test set containing 2,386 annotated instances from 13 ambiguous abbreviations in admission notes showed that the profile-based method performed better than two baseline methods and achieved a best average precision of 0.792. Furthermore, we developed a strategy to combine sense frequency information estimated from a clustering analysis with the profile-based method. Our results showed that the combined approach largely improved the performance and achieved a highest precision of 0.875 on the same test set, indicating that integrating sense frequency information with local context is effective for clinical abbreviation disambiguation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21902,""
"A comparative study of current Clinical Natural Language Processing systems on handling abbreviations in discharge summaries","Wu, Denny, Rosenbloom, Miller, Giuse, Xu","https://www.google.com/search?q=A+comparative+study+of+current+Clinical+Natural+Language+Processing+systems+on+handling+abbreviations+in+discharge+summaries.","20130730","PubMed","Abbreviations as Topic; Electronic Health Records; Humans; Natural Language Processing; Patient Discharge; Pattern Recognition, Automated","Clinical Natural Language Processing (NLP) systems extract clinical information from narrative clinical texts in many settings. Previous research mentions the challenges of handling abbreviations in clinical texts, but provides little insight into how well current NLP systems correctly recognize and interpret abbreviations. In this paper, we compared performance of three existing clinical NLP systems in handling abbreviations: MetaMap, MedLEE, and cTAKES. The evaluation used an expert-annotated gold standard set of clinical documents (derived from from 32 de-identified patient discharge summaries) containing 1,112 abbreviations. The existing NLP systems achieved suboptimal performance in abbreviation identification, with F-scores ranging from 0.165 to 0.601. MedLEE achieved the best F-score of 0.601 for all abbreviations and 0.705 for clinically relevant abbreviations. This study suggested that accurate identification of clinical abbreviations is a challenging task and that more advanced abbreviation recognition modules might improve existing clinical NLP systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21903,""
"An evaluation of the NQF Quality Data Model for representing Electronic Health Record driven phenotyping algorithms","Thompson, Rasmussen, Pacheco, Peissig, Denny, Kho, Miller, Pathak","https://www.google.com/search?q=An+evaluation+of+the+NQF+Quality+Data+Model+for+representing+Electronic+Health+Record+driven+phenotyping+algorithms.","20130730","PubMed","Algorithms; Biomedical Research; Electronic Health Records; Humans; Natural Language Processing; Phenotype; Programming Languages; Quality Control","The development of Electronic Health Record (EHR)-based phenotype selection algorithms is a non-trivial and highly iterative process involving domain experts and informaticians. To make it easier to port algorithms across institutions, it is desirable to represent them using an unambiguous formal specification language. For this purpose we evaluated the recently developed National Quality Forum (NQF) information model designed for EHR-based quality measures: the Quality Data Model (QDM). We selected 9 phenotyping algorithms that had been previously developed as part of the eMERGE consortium and translated them into QDM format. Our study concluded that the QDM contains several core elements that make it a promising format for EHR-driven phenotyping algorithms for clinical research. However, we also found areas in which the QDM could be usefully extended, such as representing information extracted from clinical text, and the ability to handle algorithms that do not consist of Boolean combinations of criteria.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21904,""
"OPIC: Ontology-driven Patient Information Capturing system for epilepsy","Sahoo, Zhao, Luo, Bozorgi, Gupta, Lhatoo, Zhang","https://www.google.com/search?q=OPIC:+Ontology-driven+Patient+Information+Capturing+system+for+epilepsy.","20130730","PubMed","Epilepsy; Humans; Information Storage and Retrieval; Internet; Medical Records Systems, Computerized; Seizures; Software; User-Computer Interface; Vocabulary, Controlled","The widespread use of paper or document-based forms for capturing patient information in various clinical settings, for example in epilepsy centers, is a critical barrier for large-scale, multi-center research studies that require interoperable, consistent, and error-free data collection. This challenge can be addressed by a web-accessible and flexible patient data capture system that is supported by a common terminological system to facilitate data re-usability, sharing, and integration. We present OPIC, an Ontology-driven Patient Information Capture (OPIC) system that uses a domain-specific epilepsy and seizure ontology (EpSO) to (1) support structured entry of multi-modal epilepsy data, (2) proactively ensure quality of data through use of ontology terms in drop-down menus, and (3) identify and index clinically relevant ontology terms in free-text fields to improve accuracy of subsequent analytical queries (e.g. cohort identification). EpSO, modeled using the Web Ontology Language (OWL), conforms to the recommendations of the International League Against Epilepsy (ILAE) classification and terminological commission. OPIC has been developed using agile software engineering methodology for rapid development cycles in close collaboration with domain expert and end users. We report the result from the initial deployment of OPIC at the University Hospitals Case Medical Center (UH CMC) epilepsy monitoring unit (EMU) as part of the NIH-funded project on Sudden Unexpected Death in Epilepsy (SUDEP). Preliminary user evaluation shows that OPIC has achieved its design objectives to be an intuitive patient information capturing system that also reduces the potential for data entry errors and variability in use of epilepsy terms.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21905,""
"A study of transportability of an existing smoking status detection module across institutions","Liu, Shah, Jiang, Peterson, Dai, Aldrich, Chen, Bowton, Liu, Denny, Xu","https://www.google.com/search?q=A+study+of+transportability+of+an+existing+smoking+status+detection+module+across+institutions.","20130730","PubMed","Electronic Health Records; Humans; Medical Record Linkage; Natural Language Processing; Smoking","Electronic Medical Records (EMRs) are valuable resources for clinical observational studies. Smoking status of a patient is one of the key factors for many diseases, but it is often embedded in narrative text. Natural language processing (NLP) systems have been developed for this specific task, such as the smoking status detection module in the clinical Text Analysis and Knowledge Extraction System (cTAKES). This study examined transportability of the smoking module in cTAKES on the Vanderbilt University Hospital's EMR data. Our evaluation demonstrated that modest effort of change is necessary to achieve desirable performance. We modified the system by filtering notes, annotating new data for training the machine learning classifier, and adding rules to the rule-based classifiers. Our results showed that the customized module achieved significantly higher F-measures at all levels of classification (i.e., sentence, document, patient) compared to the direct application of the cTAKES module to the Vanderbilt data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21906,""
"Towards a semantic lexicon for clinical natural language processing","Liu, Wu, Li, Jonnalagadda, Sohn, Wagholikar, Haug, Huff, Chute","https://www.google.com/search?q=Towards+a+semantic+lexicon+for+clinical+natural+language+processing.","20130730","PubMed","Dictionaries as Topic; Electronic Health Records; Humans; Natural Language Processing; Semantics; Unified Medical Language System; Vocabulary, Controlled","A semantic lexicon which associates words and phrases in text to concepts is critical for extracting and encoding clinical information in free text and therefore achieving semantic interoperability between structured and unstructured data in Electronic Health Records (EHRs). Directly using existing standard terminologies may have limited coverage with respect to concepts and their corresponding mentions in text. In this paper, we analyze how tokens and phrases in a large corpus distribute and how well the UMLS captures the semantics. A corpus-driven semantic lexicon, MedLex, has been constructed where the semantics is based on the UMLS assisted with variants mined and usage information gathered from clinical text. The detailed corpus analysis of tokens, chunks, and concept mentions shows the UMLS is an invaluable source for natural language processing. Increasing the semantic coverage of tokens provides a good foundation in capturing clinical information comprehensively. The study also yields some insights in developing practical NLP systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21907,""
"Extracting temporal information from electronic patient records","Li, Patrick","https://www.google.com/search?q=Extracting+temporal+information+from+electronic+patient+records.","20130730","PubMed","Bayes Theorem; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Time","A method for automatic extraction of clinical temporal information would be of significant practical importance for deep medical language understanding, and a key to creating many successful applications, such as medical decision making, medical question and answering, etc. This paper proposes a rich statistical model for extracting temporal information from an extremely noisy clinical corpus. Besides the common linguistic, contextual and semantic features, the highly restricted training sample expansion and the structure distance between the temporal expression &amp; related event expressions are also integrated into a supervised machine-learning approach. The learning method produces almost 80% F- score in the extraction of five temporal classes, and nearly 75% F-score in identifying temporally related events. This process has been integrated into the document-processing component of an implemented clinical question answering system that focuses on answering patient-specific questions (See demonstration at http://hitrl.cs.usyd.edu.au/ICNS/).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21908,""
"Risk stratification of ICU patients using topic models inferred from unstructured progress notes","Lehman, Saeed, Long, Lee, Mark","https://www.google.com/search?q=Risk+stratification+of+ICU+patients+using+topic+models+inferred+from+unstructured+progress+notes.","20130730","PubMed","Adult; Algorithms; Area Under Curve; Hospital Mortality; Humans; Intensive Care Units; Models, Theoretical; Natural Language Processing; Nursing Records; Risk Assessment; Severity of Illness Index; Unified Medical Language System","We propose a novel approach for ICU patient risk stratification by combining the learned ""topic"" structure of clinical concepts (represented by UMLS codes) extracted from the unstructured nursing notes with physiologic data (from SAPS-I) for hospital mortality prediction. We used Hierarchical Dirichlet Processes (HDP), a non-parametric topic modeling technique, to automatically discover ""topics"" as shared groups of co-occurring UMLS clinical concepts. We evaluated the potential utility of the inferred topic structure in predicting hospital mortality using the nursing notes of 14,739 adult ICU patients (mortality 14.6%) from the MIMIC II database. Our results indicate that learned topic structure from the first 24-hour ICU nursing notes significantly improved the performance of the SAPS-I algorithm for hospital mortality prediction. The AUC for predicting hospital mortality from the first 24 hours of physiologic data and nursing text notes was 0.82. Using the physiologic data alone with the SAPS-I algorithm, an AUC of 0.72 was achieved. Thus, the clinical topics that were extracted and used to augment the SAPS-I algorithm significantly improved the performance of the baseline algorithm.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21909,""
"Extracting semantic lexicons from discharge summaries using machine learning and the C-Value method","Jiang, Denny, Tang, Cao, Xu","https://www.google.com/search?q=Extracting+semantic+lexicons+from+discharge+summaries+using+machine+learning+and+the+C-Value+method.","20130730","PubMed","Algorithms; Artificial Intelligence; Humans; Natural Language Processing; Patient Discharge; Semantics; Terminology as Topic; Vocabulary, Controlled","Semantic lexicons that link words and phrases to specific semantic types such as diseases are valuable assets for clinical natural language processing (NLP) systems. Although terminological terms with predefined semantic types can be generated easily from existing knowledge bases such as the Unified Medical Language Systems (UMLS), they are often limited and do not have good coverage for narrative clinical text. In this study, we developed a method for building semantic lexicons from clinical corpus. It extracts candidate semantic terms using a conditional random field (CRF) classifier and then selects terms using the C-Value algorithm. We applied the method to a corpus containing 10 years of discharge summaries from Vanderbilt University Hospital (VUH) and extracted 44,957 new terms for three semantic groups: Problem, Treatment, and Test. A manual analysis of 200 randomly selected terms not found in the UMLS demonstrated that 59% of them were meaningful new clinical concepts and 25% were lexical variants of exiting concepts in the UMLS. Furthermore, we compared the effectiveness of corpus-derived and UMLS-derived semantic lexicons in the concept extraction task of the 2010 i2b2 clinical NLP challenge. Our results showed that the classifier with corpus-derived semantic lexicons as features achieved a better performance (F-score 82.52%) than that with UMLS-derived semantic lexicons as features (F-score 82.04%). We conclude that such corpus-based methods are effective for generating semantic lexicons, which may improve named entity recognition tasks and may aid in augmenting synonymy within existing terminologies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21910,""
"Active Learning-based corpus annotation--the PathoJen experience","Hahn, Beisswanger, Buyko, Faessler","https://www.google.com/search?q=Active+Learning-based+corpus+annotation--the+PathoJen+experience.","20130730","PubMed","Algorithms; Artificial Intelligence; Humans; MEDLINE; Pathology; Problem-Based Learning","We report on basic design decisions and novel annotation procedures underlying the development of PathoJen, a corpus of Medline abstracts annotated for pathological phenomena, including diseases as a proper subclass. This named entity type is known to be hard to delineate and capture by annotation guidelines. We here propose a two-category encoding schema where we distinguish short from long mention spans, the first covering standardized terminology (e.g. diseases), the latter accounting for less structured descriptive statements about norm-deviant states, as well as criteria and observations that might signal pathologies. The second design decision relates to the way annotation instances are sampled. Here we subscribe to an Active Learning-based approach which is known to save annotation costs without sacrificing annotation quality by means of a sample bias. By design, Active Learning picks up 'hard' to annotate instances for human annotators, whereas 'easier' ones are passed over to the automatic classifier whose models already incorporate and gradually improve with previous annotation experience.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21911,""
"Interactive intervention analysis","Gotz, Wongsuphasawat","https://www.google.com/search?q=Interactive+intervention+analysis.","20130730","PubMed","Data Mining; Decision Making, Computer-Assisted; Disease Progression; Electronic Health Records; Heart Failure; Humans; Natural Language Processing; User-Computer Interface","Disease progression is often complex and seemingly unpredictable. Moreover, patients often respond in dramatically different ways to various treatments, and determining the appropriate intervention for a patient can sometimes be difficult. In this paper, we describe an interactive visualization-based system for intervention analysis and apply it to patients at risk of developing congestive heart failure (CHF). Text analysis techniques are used to extract Framingham criteria data from clinical notes. We then correlate the progression of these criteria with intervention data. A visualization-based user interface is provided to allow interactive exploration. We present an overview of the system and share clinician feedback regarding the prototype implementation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21912,""
"Generalizability and comparison of automatic clinical text de-identification methods and resources","FerrÃƒÂ¡ndez, South, Shen, Friedlin, Samore, Meystre","https://www.google.com/search?q=Generalizability+and+comparison+of+automatic+clinical+text+de-identification+methods+and+resources.","20130730","PubMed","Artificial Intelligence; Confidentiality; Electronic Health Records; Health Insurance Portability and Accountability Act; Humans; Natural Language Processing; United States; United States Department of Veterans Affairs","In this paper, we present an evaluation of the hybrid best-of-breed automated VHA (Veteran's Health Administration) clinical text de-identification system, nicknamed BoB, developed within the VHA Consortium for Healthcare Informatics Research. We also evaluate two available machine learning-based text de-identifications systems: MIST and HIDE. Two different clinical corpora were used for this evaluation: a manually annotated VHA corpus, and the 2006 i2b2 de-identification challenge corpus. These experiments focus on the generalizability and portability of the classification models across different document sources. BoB demonstrated good recall (92.6%), satisfactorily prioritizing patient privacy, and also achieved competitive precision (83.6%) for preserving subsequent document interpretability. MIST and HIDE reached very competitive results, in most cases with high precision (92.6% and 93.6%), although recall was sometimes lower than desired for the most sensitive PHI categories.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21913,""
"Building gold standard corpora for medical natural language processing tasks","Deleger, Li, Lingren, Kaiser, Molnar, Stoutenborough, Kouril, Marsolo, Solti","https://www.google.com/search?q=Building+gold+standard+corpora+for+medical+natural+language+processing+tasks.","20130730","PubMed","Clinical Trials as Topic; Drug Labeling; Medical Records; Natural Language Processing; Software; United States; United States Food and Drug Administration","We present the construction of three annotated corpora to serve as gold standards for medical natural language processing (NLP) tasks. Clinical notes from the medical record, clinical trial announcements, and FDA drug labels are annotated. We report high inter-annotator agreements (overall F-measures between 0.8467 and 0.9176) for the annotation of Personal Health Information (PHI) elements for a de-identification task and of medications, diseases/disorders, and signs/symptoms for information extraction (IE) task. The annotated corpora of clinical trials and FDA labels will be publicly released and to facilitate translational NLP tasks that require cross-corpora interoperability (e.g. clinical trial eligibility screening) their annotation schemas are aligned with a large scale, NIH-funded clinical text annotation project.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21914,""
"Leveraging derived data elements in data analytic models for understanding and predicting hospital readmissions","Cholleti, Post, Gao, Lin, Bornstein, Cantrell, Saltz","https://www.google.com/search?q=Leveraging+derived+data+elements+in+data+analytic+models+for+understanding+and+predicting+hospital+readmissions.","20130730","PubMed","Algorithms; Artificial Intelligence; Computer Simulation; Data Mining; Electronic Health Records; Female; Humans; Logistic Models; Male; Mathematical Computing; Patient Readmission; Risk Factors","Hospital readmissions depend on numerous factors. Automated risk calculation using electronic health record (EHR) data could allow targeting care to prevent them. EHRs usually are incomplete with respect to data relevant to readmissions prediction. Lack of standard data representations in EHRs restricts generalizability of predictive models. We propose developing such models by first generating derived variables that characterize clinical phenotype. This reduces the number of variables, reduces noise, introduces clinical knowledge into model building, and abstracts away the underlying data representation, thus facilitating use of standard data mining algorithms. We combined this pre-processing step with a random forest algorithm to compute risk for readmission within 30 days for patients in ten disease categories. Results were promising for encounters that our algorithm assigned very high or very low risk. Assigning patients to either of these two risk groups could be of value to patient care teams aiming to prevent readmissions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21915,""
"Lexical concept distribution reflects clinical practice","Breydo, Shubina, Shalaby, Einbinder, Turchin","https://www.google.com/search?q=Lexical+concept+distribution+reflects+clinical+practice.","20130730","PubMed","Algorithms; Antihypertensive Agents; Diabetes Mellitus; Electronic Health Records; Humans; Hypoglycemic Agents; Medical Records; Narration; Natural Language Processing; Practice Patterns, Physicians'; Retrospective Studies","It is not known whether narrative medical text directly reflects clinical reality. We have tested the hypothesis that the pattern of distribution of lexical concept of medication intensification in narrative provider notes correlates with clinical practice as reflected in electronic medication records. Over 29,000 medication intensifications identified in narrative provider notes and 444,000 electronic medication records for 82 anti-hypertensive, anti-hyperlipidemic and anti-hyperglycemic medications were analyzed. Pearson correlation coefficient between the fraction of dose increases among all medication intensifications and therapeutic range calculated from EMR medication records was 0.39 (p = 0.0003). Correlations with therapeutic ranges obtained from two medication dictionaries, used as a negative control, were not significant. These findings provide evidence that narrative medical documents directly reflect clinical practice and constitute a valid source of medical data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21916,""
"Pooling annotated corpora for clinical concept extraction","Wagholikar, Torii, Jonnalagadda, Liu","https://doi.org/10.1186/2041-1480-4-3","20130319","PubMed","","The availability of annotated corpora has facilitated the application of machine learning algorithms to concept extraction from clinical notes. However, high expenditure and labor are required for creating the annotations. A potential alternative is to reuse existing corpora from other institutions by pooling with local corpora, for training machine taggers. In this paper we have investigated the latter approach by pooling corpora from 2010 i2b2/VA NLP challenge and Mayo Clinic Rochester, to evaluate taggers for recognition of medical problems. The corpora were annotated for medical problems, but with different guidelines. The taggers were constructed using an existing tagging system MedTagger that consisted of dictionary lookup, part of speech (POS) tagging and machine learning for named entity prediction and concept extraction. We hope that our current work will be a useful case study for facilitating reuse of annotated corpora across institutions. We found that pooling was effective when the size of the local corpus was small and after some of the guideline differences were reconciled. The benefits of pooling, however, diminished as more locally annotated documents were included in the training data. We examined the annotation guidelines to identify factors that determine the effect of pooling. The effectiveness of pooling corpora, is dependent on several factors, which include compatibility of annotation guidelines, distribution of report types and size of local and foreign corpora. Simple methods to rectify some of the guideline differences can facilitate pooling. Our findings need to be confirmed with further studies on different corpora. To facilitate the pooling and reuse of annotated corpora, we suggest that - i) the NLP community should develop a standard annotation guideline that addresses the potential areas of guideline differences that are partly identified in this paper; ii) corpora should be annotated with a two-pass method that focuses first on concept recognition, followed by normalization to existing ontologies; and iii) metadata such as type of the report should be created during the annotation process.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21917,""
"A common type system for clinical natural language processing","Wu, Kaggal, Dligach, Masanz, Chen, Becker, Chapman, Savova, Liu, Chute","https://doi.org/10.1186/2041-1480-4-1","20130220","PubMed","","<AbstractText Label=""BACKGROUND"" NlmCategory=""BACKGROUND"">One challenge in reusing clinical data stored in electronic medical records is that these data are heterogenous. Clinical Natural Language Processing (NLP) plays an important role in transforming information in clinical text to a standard representation that is comparable and interoperable. Information may be processed and shared when a type system specifies the allowable data structures. Therefore, we aim to define a common type system for clinical NLP that enables interoperability between structured and unstructured data generated in different clinical settings. We describe a common type system for clinical NLP that has an end target of deep semantics based on Clinical Element Models (CEMs), thus interoperating with structured data and accommodating diverse NLP approaches. The type system has been implemented in UIMA (Unstructured Information Management Architecture) and is fully functional in a popular open-source clinical NLP system, cTAKES (clinical Text Analysis and Knowledge Extraction System) versions 2.0 and later. We have created a type system that targets deep semantics, thereby allowing for NLP systems to encapsulate knowledge from text and share it alongside heterogenous clinical data sources. Rather than surface semantics that are typically the end product of NLP algorithms, CEM-based semantics explicitly build in deep clinical semantics as the point of interoperability with more structured data types.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21918,""
"Implementation of provider-based electronic medical records and improvement of the quality of data in a large HIV program in Sub-Saharan Africa","Castelnuovo, Kiragga, Afayo, Ncube, Orama, Magero, Okwi, Manabe, Kambugu","https://doi.org/10.1371/journal.pone.0051631","20130617","PubMed","Adult; Africa South of the Sahara; Decision Support Systems, Clinical; Electronic Health Records; HIV; HIV Infections; Humans; Program Development; Quality Assurance, Health Care; Surveys and Questionnaires","Starting in June 2010 the Infectious Diseases Institute (IDI) clinic (a large urban HIV out-patient facility) switched to provider-based Electronic Medical Records (EMR) from paper EMR entered in the database by data-entry clerks. Standardized clinics forms were eliminated but providers still fill free text clinical notes in physical patients' files. The objective of this study was to compare the rate of errors in the database before and after the introduction of the provider-based EMR. Data in the database pre and post provider-based EMR was compared with the information in the patients' files and classified as correct, incorrect, and missing. We calculated the proportion of incorrect, missing and total error for key variables (toxicities, opportunistic infections, reasons for treatment change and interruption). Proportions of total errors were compared using chi-square test. A survey of the users of the EMR was also conducted. We compared data from 2,382 visits (from 100 individuals) of a retrospective validation conducted in 2007 with 34,957 visits (from 10,920 individuals) of a prospective validation conducted in April-August 2011. The total proportion of errors decreased from 66.5% in 2007 to 2.1% in 2011 for opportunistic infections, from 51.9% to 3.5% for ART toxicity, from 82.8% to 12.5% for reasons for ART interruption and from 94.1% to 0.9% for reasons for ART switch (all P&lt;0.0001). The survey showed that 83% of the providers agreed that provider-based EMR led to improvement of clinical care, 80% reported improved access to patients' records, and 80% appreciated the automation of providers' tasks. The introduction of provider-based EMR improved the quality of data collected with a significant reduction in missing and incorrect information. The majority of providers and clients expressed satisfaction with the new system. We recommend the use of provider-based EMR in large HIV programs in Sub-Saharan Africa.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21919,""
"Examination of the regulatory frameworks applicable to biologic drugs (including stem cells and their progeny) in Europe, the US, and Australia: part II--a method of software documentary analysis","Ilic, Savic, Siegel, Atkinson, Tasic","https://doi.org/10.5966/sctm.2012-0038","20130129","PubMed","Animals; Australia; Biological Products; Documentation; Europe; Humans; Software; Stem Cell Transplantation; Terminology as Topic; United States; United States Food and Drug Administration","A wide range of regulatory standards applicable to production and use of tissues, cells, and other biologics (or biologicals), as advanced therapies, indicates considerable interest in the regulation of these products. The objective of this study was to analyze and compare high-tier documents within the Australian, European, and U.S. biologic drug regulatory environments using qualitative methodology. Eighteen high-tier documents from the European Medicines Agency (EMA), U.S. Food and Drug Administration (FDA), and Therapeutic Goods Administration (TGA) regulatory frameworks were subject to automated text analysis. Selected documents were consistent with the legal requirements for manufacturing and use of biologic drugs in humans and fall into six different categories. Concepts, themes, and their co-occurrence were identified and compared. The most frequent concepts in TGA, FDA, and EMA frameworks were ""biological,"" ""product,"" and ""medicinal,"" respectively. This was consistent with the previous manual terminology search. Good Manufacturing Practice documents, across frameworks, identified ""quality"" and ""appropriate"" as main concepts, whereas in Good Clinical Practice (GCP) documents it was ""clinical,"" followed by ""trial,"" ""subjects,"" ""sponsor,"" and ""data."" GCP documents displayed considerably higher concordance between different regulatory frameworks, as demonstrated by a smaller number of concepts, similar size, and similar distance between them. Although high-tier documents often use different terminology, they share concepts and themes. This paper may be a modest contribution to the recognition of similarities and differences between analyzed regulatory documents. It may also fill the literature gap and provide some foundation for future comparative research of biologic drug regulations on a global level.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21920,""
"Toxic Anterior Segment Syndrome following a Triple Descemet's Stripping Automated Endothelial Keratoplasty Procedure","Sorkin, Varssano","https://doi.org/10.1159/000345531","20130101","PubMed","Descemet's stripping automated endothelial keratoplasty; Toxic anterior segment syndrome; Triple procedure","To present a unique case of a 58-year-old female with toxic anterior segment syndrome (TASS), following a triple procedure: Descemet's stripping automated endothelial keratoplasty (DSAEK), phacoemulsification and posterior chamber intraocular lens implantation. The patient was treated with topical dexamethasone sodium phosphate 0.1% and topical atropine sulfate 1%. Due to a slow improvement in her clinical status, oral prednisone 1 mg/kg/day was added. The anterior chamber reaction improved gradually, with tapering down of topical and oral treatment, until a complete resolution of the anterior chamber reaction was observed. Taking into account the estimated volume of DSAEK triple procedures performed worldwide, we would expect an annual incidence of several TASS cases, following triple DSAEK procedures. However, we were unable to find any such previous reports in the literature. This fact raises questions regarding the cause of reduced TASS incidence following triple DSAEK procedures.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21921,""
"Diffusion of robotics into clinical practice in the United States: process, patient safety, learning curves, and the public health","Mirheydar, Parsons","https://doi.org/10.1007/s00345-012-1015-x","20140220","PubMed","Cystectomy; Evidence-Based Medicine; Health Care Costs; Humans; Learning Curve; Nephrectomy; Patient Safety; Prostatectomy; Public Health; Robotics; Treatment Outcome; United States","Robotic technology disseminated into urological practice without robust comparative effectiveness data. To review the diffusion of robotic surgery into urological practice. We performed a comprehensive literature review focusing on diffusion patterns, patient safety, learning curves, and comparative costs for robotic radical prostatectomy, partial nephrectomy, and radical cystectomy. Robotic urologic surgery diffused in patterns typical of novel technology spreading among practicing surgeons. Robust evidence-based data comparing outcomes of robotic to open surgery were sparse. Although initial Level 3 evidence for robotic prostatectomy observed complication outcomes similar to open prostatectomy, subsequent population-based Level 2 evidence noted an increased prevalence of adverse patient safety events and genitourinary complications among robotic patients during the early years of diffusion. Level 2 evidence indicated comparable to improved patient safety outcomes for robotic compared to open partial nephrectomy and cystectomy. Learning curve recommendations for robotic urologic surgery have drawn exclusively on Level 4 evidence and subjective, non-validated metrics. The minimum number of cases required to achieve competency for robotic prostatectomy has increased to unrealistically high levels. Most comparative cost-analyses have demonstrated that robotic surgery is significantly more expensive than open or laparoscopic surgery. Evidence-based data are limited but suggest an increased prevalence of adverse patient safety events for robotic prostatectomy early in the national diffusion period. Learning curves for robotic urologic surgery are subjective and based on non-validated metrics. The urological community should develop rigorous, evidence-based processes by which future technological innovations may diffuse in an organized and safe manner.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21922,""
"PROBABILISTIC PREDICTION OF NEUROLOGICAL DISORDERS WITH A STATISTICAL ASSESSMENT OF NEUROIMAGING DATA MODALITIES","Filippone, Marquand, Blain, Williams, MourÃƒÂ£o-Miranda, Girolami","https://doi.org/10.1214/12-aoas562","20211021","PubMed","Gaussian process; Markov chain Monte Carlo; Multi-modality multinomial logit model; Parkinsonian diseases; hierarchical model; high-dimensional data; prediction of disease state","For many neurological disorders, prediction of disease state is an important clinical aim. Neuroimaging provides detailed information about brain structure and function from which such predictions may be statistically derived. A multinomial logit model with Gaussian process priors is proposed to: (i) predict disease state based on whole-brain neuroimaging data and (ii) analyze the relative informativeness of different image modalities and brain regions. Advanced Markov chain Monte Carlo methods are employed to perform posterior inference over the model. This paper reports a statistical assessment of multiple neuroimaging modalities applied to the discrimination of three Parkinsonian neurological disorders from one another and healthy controls, showing promising predictive performance of disease states when compared to nonprobabilistic classifiers based on multiple modalities. The statistical analysis also quantifies the relative importance of different neuroimaging measures and brain regions in discriminating between these diseases and suggests that for prediction there is little benefit in acquiring multiple neuroimaging sequences. Finally, the predictive capability of different brain regions is found to be in accordance with the regional pathology of the diseases as reported in the clinical literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21923,""
"Network, anatomical, and non-imaging measures for the prediction of ADHD diagnosis in individual subjects","Bohland, Saperstein, Pereira, Rapin, Grady","https://doi.org/10.3389/fnsys.2012.00078","20121226","PubMed","ADHD; fMRI; functional connectivity; machine learning; network analysis; resting state","Brain imaging methods have long held promise as diagnostic aids for neuropsychiatric conditions with complex behavioral phenotypes such as Attention-Deficit/Hyperactivity Disorder. This promise has largely been unrealized, at least partly due to the heterogeneity of clinical populations and the small sample size of many studies. A large, multi-center dataset provided by the ADHD-200 Consortium affords new opportunities to test methods for individual diagnosis based on MRI-observable structural brain attributes and functional interactions observable from resting-state fMRI. In this study, we systematically calculated a large set of standard and new quantitative markers from individual subject datasets. These features (&gt;12,000 per subject) consisted of local anatomical attributes such as cortical thickness and structure volumes, and both local and global resting-state network measures. Three methods were used to compute graphs representing interdependencies between activations in different brain areas, and a full set of network features was derived from each. Of these, features derived from the inverse of the time series covariance matrix, under an L1-norm regularization penalty, proved most powerful. Anatomical and network feature sets were used individually, and combined with non-imaging phenotypic features from each subject. Machine learning algorithms were used to rank attributes, and performance was assessed under cross-validation and on a separate test set of 168 subjects for a variety of feature set combinations. While non-imaging features gave highest performance in cross-validation, the addition of imaging features in sufficient numbers led to improved generalization to new data. Stratification by gender also proved to be a fruitful strategy to improve classifier performance. We describe the overall approach used, compare the predictive power of different classes of features, and describe the most impactful features in relation to the current literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21924,""
"Identification of fever and vaccine-associated gene interaction networks using ontology-based literature mining","Hur, OzgÃƒÂ¼r, Xiang, He","https://doi.org/10.1186/2041-1480-3-18","20130319","PubMed","","Fever is one of the most common adverse events of vaccines. The detailed mechanisms of fever and vaccine-associated gene interaction networks are not fully understood. In the present study, we employed a genome-wide, Centrality and Ontology-based Network Discovery using Literature data (CONDL) approach to analyse the genes and gene interaction networks associated with fever or vaccine-related fever responses. Over 170,000 fever-related articles from PubMed abstracts and titles were retrieved and analysed at the sentence level using natural language processing techniques to identify genes and vaccines (including 186 Vaccine Ontology terms) as well as their interactions. This resulted in a generic fever network consisting of 403 genes and 577 gene interactions. A vaccine-specific fever sub-network consisting of 29 genes and 28 gene interactions was extracted from articles that are related to both fever and vaccines. In addition, gene-vaccine interactions were identified. Vaccines (including 4 specific vaccine names) were found to directly interact with 26 genes. Gene set enrichment analysis was performed using the genes in the generated interaction networks. Moreover, the genes in these networks were prioritized using network centrality metrics. Making scientific discoveries and generating new hypotheses were possible by using network centrality and gene set enrichment analyses. For example, our study found that the genes in the generic fever network were more enriched in cell death and responses to wounding, and the vaccine sub-network had more gene enrichment in leukocyte activation and phosphorylation regulation. The most central genes in the vaccine-specific fever network are predicted to be highly relevant to vaccine-induced fever, whereas genes that are central only in the generic fever network are likely to be highly relevant to generic fever responses. Interestingly, no Toll-like receptors (TLRs) were found in the gene-vaccine interaction network. Since multiple TLRs were found in the generic fever network, it is reasonable to hypothesize that vaccine-TLR interactions may play an important role in inducing fever response, which deserves a further investigation. This study demonstrated that ontology-based literature mining is a powerful method for analyzing gene interaction networks and generating new scientific hypotheses.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21925,""
"Computer-aided diagnosis of breast microcalcifications based on dual-tree complex wavelet transform","Jian, Sun, Luo","https://doi.org/10.1186/1475-925X-11-96","20130423","PubMed","Breast Neoplasms; Calcinosis; Diagnosis, Computer-Assisted; Mammography; Support Vector Machine; Wavelet Analysis","Digital mammography is the most reliable imaging modality for breast carcinoma diagnosis and breast micro-calcifications is regarded as one of the most important signs on imaging diagnosis. In this paper, a computer-aided diagnosis (CAD) system is presented for breast micro-calcifications based on dual-tree complex wavelet transform (DT-CWT) to facilitate radiologists like double reading. Firstly, 25 abnormal ROIs were extracted according to the center and diameter of the lesions manually and 25 normal ROIs were selected randomly. Then micro-calcifications were segmented by combining space and frequency domain techniques. We extracted three texture features based on wavelet (Haar, DB4, DT-CWT) transform. Totally 14 descriptors were introduced to define the characteristics of the suspicious micro-calcifications. Principal Component Analysis (PCA) was used to transform these descriptors to a compact and efficient vector expression. Support Vector Machine (SVM) classifier was used to classify potential micro-calcifications. Finally, we used the receiver operating characteristic (ROC) curve and free-response operating characteristic (FROC) curve to evaluate the performance of the CAD system. The results of SVM classifications based on different wavelets shows DT-CWT has a better performance. Compared with other results, DT-CWT method achieved an accuracy of 96% and 100% for the classification of normal and abnormal ROIs, and the classification of benign and malignant micro-calcifications respectively. In FROC analysis, our CAD system for clinical dataset detection achieved a sensitivity of 83.5% at a false positive per image of 1.85. Compared with general wavelets, DT-CWT could describe the features more effectively, and our CAD system had a competitive performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21926,""
"A 2012 Workshop: Vaccine and Drug Ontology in the Study of Mechanism and Effect (VDOSME 2012)","He, Toldo, Burns, Tao, Abernethy","https://doi.org/10.1186/2041-1480-3-12","20130128","PubMed",""," Vaccines and drugs have contributed to dramatic improvements in public health worldwide. Over the last decade, there have been efforts in developing biomedical ontologies that represent various areas associated with vaccines and drugs. These ontologies combined with existing health and clinical terminology systems (e.g., SNOMED, RxNorm, NDF-RT, MedDRA, VO, OAE, and AERO) could play significant roles on clinical and translational research. The first ""Vaccine and Drug Ontology in the Study of Mechanism and Effect"" workshop (VDOSME 2012) provided a platform for discussing problems and solutions in the development and application of biomedical ontologies in representing and analyzing vaccines/drugs, vaccine/drug administrations, vaccine/drug-induced immune responses (including positive host responses and adverse events), and similar topics. The workshop covered two main areas: (i) ontologies of vaccines, of drugs, and of studies thereof; and (ii) analysis of administration, mechanism and effect in terms of representations based on such ontologies. Six full-length papers included in this thematic issue focus on ontology representation and time analysis of vaccine/drug administration and host responses (including positive immune responses and adverse events), vaccine and drug adverse event text mining, and ontology-based Semantic Web applications. The workshop, together with the follow-up activities and personal meetings, provided a wonderful platform for the researchers and scientists in the vaccine and drug communities to demonstrate research progresses, share ideas, address questions, and promote collaborations for better representation and analysis of vaccine and drug-related terminologies and clinical and research data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21927,""
"A review of acupoint specificity research in china: status quo and prospects","Zhao, Chen, Liu, Li, Cai, Tang, Yang, Liang","https://doi.org/10.1155/2012/543943","20121218","PubMed","","The theory of acupoint specificity is the basis for elucidating the actions of acupoints as employed in clinical practice. Acupoint specificity has become a focus of attention in international research efforts by scholars in the areas of acupuncture and moxibustion. In 2006, the Chinese Ministry of Science approved and initiated the National Basic Research Program (973 Program), one area of which was entitled Basic Research on Acupoint Specificity Based on Clinical Efficacy. Using such approaches as data mining, evidence-based medicine, clinical epidemiology, neuroimaging, molecular biology, neurophysiology, and metabolomics, fruitful research has been conducted in the form of literature research, clinical assessments, and biological studies. Acupoint specificity has been proved to exist, and it features meridian-propagated, relative, persistent, and conditional effects. Preliminarily investigations have been made into the biological basis for acupoint specificity.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21928,""
"Finding falls in ambulatory care clinical documents using statistical text mining","McCart, Berndt, Jarman, Finch, Luther","https://doi.org/10.1136/amiajnl-2012-001334","20131217","PubMed","Accidental Falls; Ambulatory Care; Electronic Health Records; Text Mining; Accidental Falls; Ambulatory Care; Ambulatory Care Information Systems; Area Under Curve; Data Mining; Electronic Health Records; Humans; Logistic Models; Models, Statistical; Support Vector Machine","To determine how well statistical text mining (STM) models can identify falls within clinical text associated with an ambulatory encounter. 2241 patients were selected with a fall-related ICD-9-CM E-code or matched injury diagnosis code while being treated as an outpatient at one of four sites within the Veterans Health Administration. All clinical documents within a 48-h window of the recorded E-code or injury diagnosis code for each patient were obtained (n=26 010; 611 distinct document titles) and annotated for falls. Logistic regression, support vector machine, and cost-sensitive support vector machine (SVM-cost) models were trained on a stratified sample of 70% of documents from one location (dataset Atrain) and then applied to the remaining unseen documents (datasets Atest-D). All three STM models obtained area under the receiver operating characteristic curve (AUC) scores above 0.950 on the four test datasets (Atest-D). The SVM-cost model obtained the highest AUC scores, ranging from 0.953 to 0.978. The SVM-cost model also achieved F-measure values ranging from 0.745 to 0.853, sensitivity from 0.890 to 0.931, and specificity from 0.877 to 0.944. The STM models performed well across a large heterogeneous collection of document titles. In addition, the models also generalized across other sites, including a traditionally bilingual site that had distinctly different grammatical patterns. The results of this study suggest STM-based models have the potential to improve surveillance of falls. Furthermore, the encouraging evidence shown here that STM is a robust technique for mining clinical documents bodes well for other surveillance-related topics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21929,""
"Cost-effectiveness analysis, prevention of atopic dermatitis by oral application of bacterial lysate in newborns/small children","Kiencke, Viehmann, Rychlik","https://doi.org/10.1007/s10198-012-0448-x","20140701","PubMed","Adjuvants, Immunologic; Cell Extracts; Child; Child, Preschool; Cost-Benefit Analysis; Dermatitis, Atopic; Double-Blind Method; Female; Genetic Predisposition to Disease; Humans; Infant; Infant, Newborn; Male; Models, Economic","The aim of this analysis was to determine the cost-effectiveness compared to placebo of prophylactic treatment with sterile bacterial lysate (Escherichia coli and Enterococcus faecalis) (verum) of newborns/small children with heredity for atopy [atopic dermatitis (AD)]. Infants were followed from the age of 5 weeks until 3 years of age. During this time, the number of children with AD who were treated with verum or placebo was observed at eight visits. Cost-effectiveness analyses were performed at different time points. A randomized, double-blind placebo-controlled clinical trial performed in Germany included 606 newborns. After randomization, n = 303 patients were classified in the placebo group and n = 303 in the verum group. A total of 119 participants left the study, so data from n = 250 patients of the placebo group and n = 237 patients of the verum group were available for analysis. At the beginning of the study, newborns were treated prophylactically with bacterial lysate or placebo for 26 weeks. After this, children were observed until the age of 3 years. A systematic literature research was done to evaluate treatment costs of atopic eczema in newborn/small children. Finally, 17 publications were included and checked for searched treatment costs of AD. A study was then initiated to evaluate the direct costs to statutory health insurance. Based on the described clinical trial, a decision tree model was developed. Using the evaluated direct costs and prevalence according to the clinical trial, the developed model can be used in cost-effectiveness analyses. The focus of the analyses was on the subgroup ""single heredity for atopy"" in clinical trials. Cost-effectiveness analysis showed an advantage for bacterial lysate after 3 years. To further support this result a model extension was executed; the model was expanded from 3 to 6 years. Cost-effectiveness of bacterial lysate was also proven after 6 years. Prophylactic treatment with bacterial lysate of infants with single heredity for atopy for 26 weeks in the 1st year of life is cost-effective at the age of 3 and 6 years, i.e. prophylactic use of bacterial lysate generated lower costs by leading to lower prevalence compared to placebo.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21930,""
"Systematic review of robotic liver resection","Ho, Wakabayashi, Nitta, Ito, Hasegawa, Takahara","https://doi.org/10.1007/s00464-012-2547-2","20130802","PubMed","Adult; Aged; Aged, 80 and over; Conversion to Open Surgery; Female; Hepatectomy; Humans; Laparoscopy; Length of Stay; Liver Diseases; Male; Middle Aged; Operative Time; Postoperative Complications; Robotics; Treatment Outcome; Young Adult","Robotic liver resection has emerged as a new modality in the field of minimally invasive surgery. However, the effectiveness of this approach for liver resection is not yet known. A literature survey was performed using specific search phrases in PubMed. Case series that focused on biliary reconstruction were excluded. Characteristics, such as patient demographics, perioperative outcomes, and oncological results for colorectal liver metastasis and hepatocellular carcinoma were analyzed. Nineteen series that described the cases of 217 eligible patients were reviewed. The most commonly performed procedures were wedge resection and segmentectomy. Right hepatectomy was performed in a few specialized centers. The conversion and complication rates were 4.6 and 20.3 %, respectively. The most common reason for conversion was unclear tumor margin. Intra-abdominal fluid collection was the most frequently occurring morbidity. Mean operation time was 200-507 min. Mean intraoperative blood loss was 50-660 mL, with a tendency toward increased blood loss observed in series that included major hepatectomies. Mean postoperative hospital stay was 5.5-11.7 days. The longest mean follow-up time was 36 months for colorectal liver metastasis and 25.1 months in hepatocellular carcinoma. Disease-free survival for mixed malignancies was comparable to that after laparoscopic procedures. Overall survival was not reported. Robotic liver resection is safe and feasible for experienced surgeons with advanced laparoscopic skills. Long-term oncologic outcomes are unclear, but short-term perioperative results seem comparable to those of conventional laparoscopic liver resection.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21931,""
"Robotic surgery in Italy national survey (2011)","Santoro, Pansadoro","https://doi.org/10.1007/s13304-012-0190-z","20130708","PubMed","Costs and Cost Analysis; Data Collection; Humans; Italy; Robotics; Surgical Procedures, Operative","Robotic surgery in Italy has become a clinical reality that is gaining increasing acceptance. As of 2011 after the United States, Italy together with Germany is the country with the largest number of active Robotic centers, 46, and da Vinci Robots installed, with at least 116 operators already trained. The number of interventions performed in Italy in 2011 exceeded 6,000 and in 2010 were 4,784, with prevalence for urology, general surgery and gynecology, however these interventions have also begun to be applied in other fields such as cervicofacial, cardiothoracic and pediatric surgery. In Italy Robotic centers are mostly located in Northern Italy, while in the South there are only a few centers, and four regions are lacking altogether. Of the 46 centers which were started in 1999, the vast majority is still operational and almost half handle over 200 cases a year. The quality of the work is also especially high with large diffusion of radical prostatectomy in urology and liver resection and colic in general surgery. The method is very well accepted among operators, over 80Ã‚Â %, and among patients, over 95Ã‚Â %. From the analysis of world literature and a survey carried out in Italy, Robotic surgery, which at the moment could be better defined as telesurgery, represents a significant advantage for operators and a consistent gain for the patient. However, it still has important limits such as high cost and non-structured training of operators.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21932,""
"Robot-assisted pancreatic surgery: a systematic review of the literature","Strijker, van Santvoort, Besselink, van Hillegersberg, Borel Rinkes, Vriens, Molenaar","https://doi.org/10.1111/j.1477-2574.2012.00589.x","20130521","PubMed","Adult; Aged; Aged, 80 and over; Female; Humans; Male; Middle Aged; Pancreatectomy; Pancreatic Fistula; Pancreatic Neoplasms; Pancreaticoduodenectomy; Pancreaticojejunostomy; Risk Factors; Robotics; Surgery, Computer-Assisted; Time Factors; Treatment Outcome","To potentially improve outcomes in pancreatic resection, robot-assisted pancreatic surgery has been introduced. This technique has possible advantages over laparoscopic surgery, such as its affordance of three-dimensional vision and increased freedom of movement of instruments. A systematic review was performed to assess the safety and feasibility of robot-assisted pancreatic surgery. The literature published up to 30 September 2011 was systematically reviewed, with no restrictions on publication date. Studies reporting on over five patients were included. Animal studies, studies not reporting morbidity and mortality, review articles and conference abstracts were excluded. Data were extracted and weighted means were calculated. A total of 499 studies were screened, after which eight cohort studies reporting on a total of 251 patients undergoing robot-assisted pancreatic surgery were retained for analysis. Weighted mean operation time was 404 Ã‚Â± 102 min (510 Ã‚Â± 107 min for pancreatoduodenectomy only). The rate of conversion was 11.0% (16.4% for pancreatoduodenectomy only). Overall morbidity was 30.7% (n = 77), most frequently involving pancreatic fistulae (n = 46). Mortality was 1.6%. Negative surgical margins were obtained in 92.9% of patients. The rate of spleen preservation in distal pancreatectomy was 87.1%. Robot-assisted pancreatic surgery seems to be safe and feasible in selected patients and, in left-sided resections, may increase the rate of spleen preservation. Randomized studies should compare the respective outcomes of robot-assisted, laparoscopic and open pancreatic surgery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21933,""
"Navigational bronchoscopy with biopsy versus computed tomography-guided biopsy for the diagnosis of a solitary pulmonary nodule: a cost-consequences analysis","Dale, Madtes, Fan, Gorden, Veenstra","https://doi.org/10.1097/LBR.0b013e318272157d","20130520","PubMed","Biopsy; Bronchoscopy; Costs and Cost Analysis; Decision Trees; Humans; Lung Neoplasms; Radiography, Interventional; Sensitivity and Specificity; Solitary Pulmonary Nodule; Thoracic Surgery, Video-Assisted; Tomography, X-Ray Computed","Solitary pulmonary nodules (SPNs) are frequent and can be malignant. Both computed tomography-guided biopsy and electromagnetic navigational bronchoscopy (ENB) with biopsy can be used to diagnose a SPN. A nondiagnostic computed tomography (CT)-guided or ENB biopsy is often followed by video-assisted thoracoscopic surgery (VATS) biopsy. The relative costs and consequences of these strategies are not known. A decision tree was created with values from the literature to evaluate the clinical consequences and societal costs of a CT-guided biopsy strategy versus an ENB biopsy strategy for the diagnosis of a SPN. The serial use of ENB after nondiagnostic CT-guided biopsy and CT-guided biopsy after nondiagnostic ENB biopsy were tested as alternate strategies. In a hypothetical cohort of 100 patients, use of the ENB biopsy strategy on average results in 13.4 fewer pneumothoraces, 5.9 fewer chest tubes, 0.9 fewer significant hemorrhage episodes, and 0.6 fewer respiratory failure episodes compared with a CT-guided biopsy strategy. ENB biopsy increases average costs by $3719 per case and increases VATS rates by an absolute 20%. The sequential diagnostic strategy that combines CT-guided biopsy after nondiagnostic ENB biopsy and vice versa decreases the rate of VATS procedures to 3%. A sequential approach starting with ENB decreases average per case cost relative to CT-guided biopsy followed by VATS, if needed, by $507; and a sequential approach starting with CT-guided biopsy decreases the cost relative to CT-guided biopsy followed by VATS, if needed, by $979. An ENB with biopsy strategy is associated with decreased pneumothorax rate but increased costs and increased use of VATS. Combining CT-guided biopsy and ENB with biopsy serially can decrease costs and complications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21934,""
"Design and validation of an automated method to detect known adverse drug reactions in MEDLINE: a contribution from the EU-ADR project","Avillach, Dufour, Diallo, Salvo, Joubert, Thiessard, Mougin, TrifirÃƒÂ², Fourrier-RÃƒÂ©glat, Pariente, Fieschi","https://doi.org/10.1136/amiajnl-2012-001083","20130710","PubMed","Drug-Related Side Effects and Adverse Reactions; Europe; Humans; Information Storage and Retrieval; Internet; MEDLINE; Medical Subject Headings","The aim of this research was to automate the search of publications concerning adverse drug reactions (ADR) by defining the queries used to search MEDLINE and by determining the required threshold for the number of extracted publications to confirm the drug/event association in the literature. We defined an approach based on the medical subject headings (MeSH) 'descriptor records' and 'supplementary concept records' thesaurus, using the subheadings 'chemically induced' and 'adverse effects' with the 'pharmacological action' knowledge. An expert-built validation set of true positive and true negative drug/adverse event associations (n=61) was used to validate our method. Using a threshold of three of more extracted publications, the automated search method presented a sensitivity of 90% and a specificity of 100%. For nine different drug/event pairs selected, the recall of the automated search ranged from 24% to 64% and the precision from 93% to 48%. This work presents a method to find previously established relationships between drugs and adverse events in the literature. Using MEDLINE, following a MeSH approach to filter the signals, is a valid option. Our contribution is available as a web service that will be integrated in the final European EU-ADR project (Exploring and Understanding Adverse Drug Reactions by integrative mining of clinical records and biomedical knowledge) automated system.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21935,""
"Accelerating literature curation with text-mining tools: a case study of using PubTator to curate genes in PubMed abstracts","Wei, Harris, Li, Berardini, Huala, Kao, Lu","https://doi.org/10.1093/database/bas041","20130424","PubMed","Abstracting and Indexing; Data Mining; Databases, Factual; Feedback; Genes; Humans; Periodicals as Topic; PubMed; User-Computer Interface","Today's biomedical research has become heavily dependent on access to the biological knowledge encoded in expert curated biological databases. As the volume of biological literature grows rapidly, it becomes increasingly difficult for biocurators to keep up with the literature because manual curation is an expensive and time-consuming endeavour. Past research has suggested that computer-assisted curation can improve efficiency, but few text-mining systems have been formally evaluated in this regard. Through participation in the interactive text-mining track of the BioCreative 2012 workshop, we developed PubTator, a PubMed-like system that assists with two specific human curation tasks: document triage and bioconcept annotation. On the basis of evaluation results from two external user groups, we find that the accuracy of PubTator-assisted curation is comparable with that of manual curation and that PubTator can significantly increase human curatorial speed. These encouraging findings warrant further investigation with a larger number of publications to be annotated. Database URL: http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator/","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21936,""
"Acupuncture induces divergent alterations of functional connectivity within conventional frequency bands: evidence from MEG recordings","You, Bai, Dai, Zhong, Xue, Wang, Liu, Wei, Tian","https://doi.org/10.1371/journal.pone.0049250","20130507","PubMed","Acupuncture Therapy; Adult; Female; Humans; Magnetoencephalography; Male; Meridians; Nerve Net","As an ancient Chinese healing modality which has gained increasing popularity in modern society, acupuncture involves stimulation with fine needles inserted into acupoints. Both traditional literature and clinical data indicated that modulation effects largely depend on specific designated acupoints. However, scientific representations of acupoint specificity remain controversial. In the present study, considering the new findings on the sustained effects of acupuncture and its time-varied temporal characteristics, we employed an electrophysiological imaging modality namely magnetoencephalography with a temporal resolution on the order of milliseconds. Taken into account the differential band-limited signal modulations induced by acupuncture, we sought to explore whether or not stimulation at Stomach Meridian 36 (ST36) and a nearby non-meridian point (NAP) would evoke divergent functional connectivity alterations within delta, theta, alpha, beta and gamma bands. Whole-head scanning was performed on 28 healthy participants during an eyes-closed no-task condition both preceding and following acupuncture. Data analysis involved calculation of band-limited power (BLP) followed by pair-wise BLP correlations. Further averaging was conducted to obtain local and remote connectivity. Statistical analyses revealed the increased connection degree of the left temporal cortex within delta (0.5-4 Hz), beta (13-30 Hz) and gamma (30-48 Hz) bands following verum acupuncture. Moreover, we not only validated the closer linkage of the left temporal cortex with the prefrontal and frontal cortices, but further pinpointed that such patterns were more extensively distributed in the ST36 group in the delta and beta bands compared to the restriction only to the delta band for NAP. Psychophysical results for significant pain threshold elevation further confirmed the analgesic effect of acupuncture at ST36. In conclusion, our findings may provide a new perspective to lend support for the specificity of neural expression underlying acupuncture.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21937,""
"Preliminary study of online machine translation use of nursing literature: quality evaluation and perceived usability","Anazawa, Ishikawa, Park, Kiuchi","https://doi.org/10.1186/1756-0500-5-635","20130621","PubMed","Adult; Comprehension; Education, Nursing; Female; Humans; Japan; Language; Male; Middle Aged; Natural Language Processing; Nurses; Online Systems; Perception; Surveys and Questionnaires; Translations","Japanese nurses are increasingly required to read published international research in clinical, educational, and research settings. Language barriers are a significant obstacle, and online machine translation (MT) is a tool that can be used to address this issue. We examined the quality of Google TranslateÃ‚Â® (English to Japanese and Korean to Japanese), which is a representative online MT, using a previously verified evaluation method. We also examined the perceived usability and current use of online MT among Japanese nurses. Randomly selected nursing abstracts were translated and then evaluated for intelligibility and usability by 28 participants, including assistants and research associates from nursing universities throughout Japan. They answered a questionnaire about their online MT use. From simple comparison of mean scores between two language pairs, translation quality was significantly better, with respect to both intelligibility and usability, for Korean-Japanese than for English-Japanese. Most respondents perceived a language barrier. Online MT had been used by 61% of the respondents and was perceived as not useful enough. Nursing articles translated from Korean into Japanese by an online MT system could be read at an acceptable level of comprehension, but the same could not be said for English-Japanese translations. Respondents with experience using online MT used it largely to grasp the overall meanings of the original text. Enrichment in technical terms appeared to be the key to better usability. Users will be better able to use MT outputs if they improve their foreign language proficiency as much as possible. Further research is being conducted with a larger sample size and detailed analysis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21938,""
"Clinical value of prognosis gene expression signatures in colorectal cancer: a systematic review","Sanz-Pamplona, Berenguer, Cordero, Riccadonna, SolÃƒÂ©, Crous-Bou, GuinÃƒÂ³, Sanjuan, Biondo, Soriano, Jurman, Capella, Furlanello, Moreno","https://doi.org/10.1371/journal.pone.0048877","20130523","PubMed","Colorectal Neoplasms; Humans; Neoplasm Staging; Predictive Value of Tests; Prognosis; Recurrence; Transcriptome","The traditional staging system is inadequate to identify those patients with stage II colorectal cancer (CRC) at high risk of recurrence or with stage III CRC at low risk. A number of gene expression signatures to predict CRC prognosis have been proposed, but none is routinely used in the clinic. The aim of this work was to assess the prediction ability and potential clinical usefulness of these signatures in a series of independent datasets. A literature review identified 31 gene expression signatures that used gene expression data to predict prognosis in CRC tissue. The search was based on the PubMed database and was restricted to papers published from January 2004 to December 2011. Eleven CRC gene expression datasets with outcome information were identified and downloaded from public repositories. Random Forest classifier was used to build predictors from the gene lists. Matthews correlation coefficient was chosen as a measure of classification accuracy and its associated p-value was used to assess association with prognosis. For clinical usefulness evaluation, positive and negative post-tests probabilities were computed in stage II and III samples. Five gene signatures showed significant association with prognosis and provided reasonable prediction accuracy in their own training datasets. Nevertheless, all signatures showed low reproducibility in independent data. Stratified analyses by stage or microsatellite instability status showed significant association but limited discrimination ability, especially in stage II tumors. From a clinical perspective, the most predictive signatures showed a minor but significant improvement over the classical staging system. The published signatures show low prediction accuracy but moderate clinical usefulness. Although gene expression data may inform prognosis, better strategies for signature validation are needed to encourage their widespread use in the clinic.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21939,""
"Longitudinal analysis of pain in patients with metastatic prostate cancer using natural language processing of medical record text","Heintzelman, Taylor, Simonsen, Lustig, Anderko, Haythornthwaite, Childs, Bova","https://doi.org/10.1136/amiajnl-2012-001076","20131217","PubMed","Cancer Pain; Individualized Medicine; Metastatic Prostate Cancer; Natural Language Processing; Pain Management; Personalized Medicine; Adult; Aged; Algorithms; Data Mining; Electronic Health Records; Feasibility Studies; Humans; Longitudinal Studies; Male; Middle Aged; Natural Language Processing; Neoplasm Metastasis; Pain; Prostatic Neoplasms; Unified Medical Language System","To test the feasibility of using text mining to depict meaningfully the experience of pain in patients with metastatic prostate cancer, to identify novel pain phenotypes, and to propose methods for longitudinal visualization of pain status. Text from 4409 clinical encounters for 33 men enrolled in a 15-year longitudinal clinical/molecular autopsy study of metastatic prostate cancer (Project to ELIminate lethal CANcer) was subjected to natural language processing (NLP) using Unified Medical Language System-based terms. A four-tiered pain scale was developed, and logistic regression analysis identified factors that correlated with experience of severe pain during each month. NLP identified 6387 pain and 13 827 drug mentions in the text. Graphical displays revealed the pain 'landscape' described in the textual records and confirmed dramatically increasing levels of pain in the last years of life in all but two patients, all of whom died from metastatic cancer. Severe pain was associated with receipt of opioids (OR=6.6, p&lt;0.0001) and palliative radiation (OR=3.4, p=0.0002). Surprisingly, no severe or controlled pain was detected in two of 33 subjects' clinical records. Additionally, the NLP algorithm proved generalizable in an evaluation using a separate data source (889 Informatics for Integrating Biology and the Bedside (i2b2) discharge summaries). Patterns in the pain experience, undetectable without the use of NLP to mine the longitudinal clinical record, were consistent with clinical expectations, suggesting that meaningful NLP-based pain status monitoring is feasible. Findings in this initial cohort suggest that 'outlier' pain phenotypes useful for probing the molecular basis of cancer pain may exist. The results are limited by a small cohort size and use of proprietary NLP software. We have established the feasibility of tracking longitudinal patterns of pain by text mining of free text clinical records. These methods may be useful for monitoring pain management and identifying novel cancer phenotypes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21940,""
"Creation of a corpus for evidence based medicine summarisation","MollÃƒÂ¡, Santiago-MartÃƒÂ­nez","https://doi.org/10.4066/AMJ.2012.1375","20121102","PubMed","Evidence Based Medicine; corpora; natural language processing.; text summarisation","Automated text summarisers that find the best clinical evidence reported in collections of medical literature are of potential benefit for the practice of Evidence Based Medicine (EBM). Research and development of text summarisers for EBM, however, is impeded by the lack of corpora to train and test such systems. To produce a corpus for research in EBM summarisation. We sourced the ""Clinical Inquiries"" section of the Journal of Family Practice (JFP) and obtained a sizeable sample of questions and evidence based summaries. We further processed the summaries by combining automated techniques, human annotations, and crowdsourcing techniques to identify the PubMed IDs of the references. The corpus has 456 questions, 1,396 answer components, 3,036 answer justifications, and 2,908 references. The corpus is now available for the research community at http://sourceforge.net/projects/ebmsumcorpus.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21941,""
"Alzheimer's disease biomarker discovery using in silico literature mining and clinical validation","Greco, Day, Riddoch-Contreras, Reed, Soininen, KÃ…â€šoszewska, Tsolaki, Vellas, Spenger, Mecocci, Wahlund, Simmons, Barnes, Lovestone","https://doi.org/10.1186/1479-5876-10-217","20130401","PubMed","Alzheimer Disease; Biomarkers; Humans; Information Storage and Retrieval","Alzheimer's Disease (AD) is the most widespread form of dementia in the elderly but despite progress made in recent years towards a mechanistic understanding, there is still an urgent need for disease modification therapy and for early diagnostic tests. Substantial international efforts are being made to discover and validate biomarkers for AD using candidate analytes and various data-driven 'omics' approaches. Cerebrospinal fluid is in many ways the tissue of choice for biomarkers of brain disease but is limited by patient and clinician acceptability, and increasing attention is being paid to the search for blood-based biomarkers. The aim of this study was to use a novel in silico approach to discover a set of candidate biomarkers for AD. We used an in silico literature mining approach to identify potential biomarkers by creating a summarized set of assertional metadata derived from relevant legacy information. We then assessed the validity of this approach using direct assays of the identified biomarkers in plasma by immunodetection methods. Using this in silico approach, we identified 25 biomarker candidates, at least three of which have subsequently been reported to be altered in blood or CSF from AD patients. Two further candidate biomarkers, indicated from the in silico approach, were choline acetyltransferase and urokinase-type plasminogen activator receptor. Using immunodetection, we showed that, in a large sample set, these markers are either altered in disease or correlate with MRI markers of atrophy. These data support as a proof of concept the use of data mining and in silico analyses to derive valid biomarker candidates for AD and, by extension, for other disorders.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21942,""
"Automatically extracting sentences from Medline citations to support clinicians' information needs","Jonnalagadda, Del Fiol, Medlin, Weir, Fiszman, Mostafa, Liu","https://doi.org/10.1136/amiajnl-2012-001347","20131217","PubMed","clinical decision support; information needs; knowledge summary; natural language processing; Algorithms; Alzheimer Disease; Depressive Disorder; Humans; Information Storage and Retrieval; MEDLINE; Natural Language Processing; Semantics; Unified Medical Language System","Online health knowledge resources contain answers to most of the information needs raised by clinicians in the course of care. However, significant barriers limit the use of these resources for decision-making, especially clinicians' lack of time. In this study we assessed the feasibility of automatically generating knowledge summaries for a particular clinical topic composed of relevant sentences extracted from Medline citations. The proposed approach combines information retrieval and semantic information extraction techniques to identify relevant sentences from Medline abstracts. We assessed this approach in two case studies on the treatment alternatives for depression and Alzheimer's disease. A total of 515 of 564 (91.3%) sentences retrieved in the two case studies were relevant to the topic of interest. About one-third of the relevant sentences described factual knowledge or a study conclusion that can be used for supporting information needs at the point of care. The high rate of relevant sentences is desirable, given that clinicians' lack of time is one of the main barriers to using knowledge resources at the point of care. Sentence rank was not significantly associated with relevancy, possibly due to most sentences being highly relevant. Sentences located closer to the end of the abstract and sentences with treatment and comparative predications were likely to be conclusive sentences. Our proposed technical approach to helping clinicians meet their information needs is promising. The approach can be extended for other knowledge resources and information need types.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21943,""
"Brain connectivity abnormalities extend beyond the sensorimotor network in peripheral neuropathy","Rocca, Valsasina, Fazio, Previtali, Messina, Falini, Comi, Filippi","https://doi.org/10.1002/hbm.22198","20140902","PubMed","brain plasticity; fMRI; functional network connectivity; peripheral neuropathy; resting state functional connectivity; Adult; Aged; Analysis of Variance; Brain; Brain Mapping; Case-Control Studies; Female; Gait Disorders, Neurologic; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Nerve Net; Neural Pathways; Oxygen; Peripheral Nervous System Diseases","To investigate, using resting state (RS) functional connectivity (FC), the selectivity of involvement of the sensorimotor network in patients with acquired (A) and with hereditary (H) peripheral neuropathies (PN) and the correlations of RS FC abnormalities with clinical impairment and structural brain damage. Temporal associations among RS networks were also explored. RS fMRI scans were acquired from 13 APN, 12 HPN, and 18 age- and sex-matched healthy controls. Independent component analysis and functional network connectivity were used to investigate RS FC within and among RS networks with potential functional relevance. Compared to controls, patients had a decreased FC of the right precentral gyrus and an increased RS FC of the precuneus within the sensorimotor network. Both decreased and increased RS FC also involved the visual and auditory networks, which additionally had an increased coherence of function with the sensorimotor network (more pronounced in HPN). RS FC modifications in patients extended to several cognitive networks and were correlated with disease duration. In APN, they were also correlated with the severity of clinical impairment and corpus callosum atrophy. In PN, RS FC modifications extend beyond the sensorimotor network and involve other sensory and cognitive networks. The correlations between RS FC patterns and disease duration in patients as well as with clinical impairment in patients with APN suggest that modifications of FC might reflect an adaptive mechanism, which takes time to occur and helps to limit the clinical consequences of peripheral damage.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21944,""
"Matching health information seekers' queries to medical terms","Soualmia, Prieur-Gaston, Moalla, Lecroq, Darmoni","https://doi.org/10.1186/1471-2105-13-S14-S11","20130502","PubMed","Algorithms; Humans; Information Storage and Retrieval; Internet; Language; Medical Informatics; Vocabulary, Controlled","The Internet is a major source of health information but most seekers are not familiar with medical vocabularies. Hence, their searches fail due to bad query formulation. Several methods have been proposed to improve information retrieval: query expansion, syntactic and semantic techniques or knowledge-based methods. However, it would be useful to clean those queries which are misspelled. In this paper, we propose a simple yet efficient method in order to correct misspellings of queries submitted by health information seekers to a medical online search tool. In addition to query normalizations and exact phonetic term matching, we tested two approximate string comparators: the similarity score function of Stoilos and the normalized Levenshtein edit distance. We propose here to combine them to increase the number of matched medical terms in French. We first took a sample of query logs to determine the thresholds and processing times. In the second run, at a greater scale we tested different combinations of query normalizations before or after misspelling correction with the retained thresholds in the first run. According to the total number of suggestions (around 163, the number of the first sample of queries), at a threshold comparator score of 0.3, the normalized Levenshtein edit distance gave the highest F-Measure (88.15%) and at a threshold comparator score of 0.7, the Stoilos function gave the highest F-Measure (84.31%). By combining Levenshtein and Stoilos, the highest F-Measure (80.28%) is obtained with 0.2 and 0.7 thresholds respectively. However, queries are composed by several terms that may be combination of medical terms. The process of query normalization and segmentation is thus required. The highest F-Measure (64.18%) is obtained when this process is realized before spelling-correction. Despite the widely known high performance of the normalized edit distance of Levenshtein, we show in this paper that its combination with the Stoilos algorithm improved the results for misspelling correction of user queries. Accuracy is improved by combining spelling, phoneme-based information and string normalizations and segmentations into medical terms. These encouraging results have enabled the integration of this method into two projects funded by the French National Research Agency-Technologies for Health Care. The first aims to facilitate the coding process of clinical free texts contained in Electronic Health Records and discharge summaries, whereas the second aims at improving information retrieval through Electronic Health Records.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21945,""
"Knowledge-based biomedical word sense disambiguation: an evaluation and application to clinical document classification","Garla, Brandt","https://doi.org/10.1136/amiajnl-2012-001350","20131217","PubMed","Natural Language Processing; Semantic similarity; Word Sense Disambiguation; Artificial Intelligence; Data Mining; Knowledge Bases; Literature; Medical Subject Headings; Natural Language Processing; Semantics; Unified Medical Language System","Word sense disambiguation (WSD) methods automatically assign an unambiguous concept to an ambiguous term based on context, and are important to many text-processing tasks. In this study we developed and evaluated a knowledge-based WSD method that uses semantic similarity measures derived from the Unified Medical Language System (UMLS) and evaluated the contribution of WSD to clinical text classification. We evaluated our system on biomedical WSD datasets and determined the contribution of our WSD system to clinical document classification on the 2007 Computational Medicine Challenge corpus. Our system compared favorably with other knowledge-based methods. Machine learning classifiers trained on disambiguated concepts significantly outperformed those trained using all concepts. We developed a WSD system that achieves high disambiguation accuracy on standard biomedical WSD datasets and showed that our WSD system improves clinical document classification. We integrated our WSD system with MetaMap and the clinical Text Analysis and Knowledge Extraction System, two popular biomedical natural language processing systems. All codes required to reproduce our results and all tools developed as part of this study are released as open source, available under http://code.google.com/p/ytex.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21946,""
"Transcatheter aortic valve implantation (TAVI) for treatment of aortic valve stenosis: an evidence-based Analysis (part B)","Sehatzadeh, Doble, Xie, Blackhouse, Campbell, Kaulback, Chandra, Goeree","https://www.google.com/search?q=Transcatheter+aortic+valve+implantation+(TAVI)+for+treatment+of+aortic+valve+stenosis:+an+evidence-based+Analysis+(part+B).","20130429","PubMed","Aortic Valve; Aortic Valve Stenosis; Cardiac Catheterization; Cost-Benefit Analysis; Heart Valve Prosthesis; Heart Valve Prosthesis Implantation; Humans","Transcatheter aortic valve implantation (TAVI) has become an alternative to surgical aortic valve replacement (sAVR) for patients at high risk for surgery. To evaluate the safety, effectiveness, and cost-effectiveness of TAVI for treatment of aortic valve stenosis in symptomatic older adults. A literature search was performed on September 6, 2011, for studies published from January 1, 2007, to September 6, 2011. A combined decision tree and Markov model was developed to compare costs, life years, and quality-adjusted life-years (QALYs) of all treatment options in their respective patient populations over a 20-year time horizon. Two studies from the PARTNER trial were identified. The first study compared TAVI to sAVR in patients who were candidates for sAVR. The second study compared TAVI to standard treatment in patients who were not eligible for sAVR. The first study showed that TAVI and sAVR had similar mortality rates at 1 year. The second study showed a significant improvement in patient survival in those undergoing TAVI. However, in both studies, the TAVI group had significantly higher rates of stroke/transient ischemic attack, and major vascular complications. Rates of major bleeding were significantly higher in sAVR group in the first study and significantly higher in TAVI group in the second study. The base-case cost-effectiveness of TAVI was $48,912 per QALY, but the incremental cost-effectiveness ratio ranged from $36,000 to $291,000 per QALY depending on the assumptions made in the longer-term prediction portion of the model (i.e., beyond the follow-up period of the PARTNER trial). TAVI improves survival in patients who cannot undergo surgery. For those who are candidates for surgery, TAVI has a mortality rate similar to sAVR, but it is associated with significant adverse effects. TAVI may be cost-effective for patients who cannot undergo surgery, but is not cost-effective for patients who can.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21947,""
"Translational reciprocity: bridging the gap between preclinical studies and clinical treatment of stress effects on the adolescent brain","Neigh, Ritschel, Kilpela, Harrell, Bourke","https://doi.org/10.1016/j.neuroscience.2012.09.075","20140411","PubMed","ACTH; BPD; CRF; DHEA; GR; HPA; LC; MDD; NPY; POMC; PTSD; SUD; adolescent; adrenocorticotropic hormone; animal model; borderline personality disorder; corticotropin-releasing factor; dehydroepiandrosterone; glucocorticoid receptor; hypothalamicÃ¢â‚¬â€œpituitaryÃ¢â‚¬â€œadrenal; locus coeruleus; mPFC; major depressive disorder; medial prefrontal cortex; neuropeptide Y; post-traumatic stress disorder; preclinical; proopiomelanocortin; stress; substance use disorders; trauma; Adolescent; Animals; Brain; Disease Models, Animal; Humans; Stress, Psychological; Translational Medical Research; Treatment Outcome","The genetic, biological, and environmental backgrounds of an organism fundamentally influence the balance between risk and resilience to stress. Sex, age, and environment transact with responses to trauma in ways that can mitigate or exacerbate the likelihood that post-traumatic stress disorder will develop. Translational approaches to modeling affective disorders in animals will ultimately provide novel treatments and a better understanding of the neurobiological underpinnings behind these debilitating disorders. The extant literature on trauma/stress has focused predominately on limbic and cortical structures that innervate the hypothalamic-pituitary-adrenal axis and influence glucocorticoid-mediated negative feedback. It is through these neuroendocrine pathways that a self-perpetuating fear memory can propagate the long-term effects of early life trauma. Recent work incorporating translational approaches has provided novel pathways that can be influenced by early life stress, such as the glucocorticoid receptor chaperones, including FKBP51. Animal models of stress have differing effects on behavior and endocrine pathways; however, complete models replicating clinical characteristics of risk and resilience have not been rigorously studied. This review discusses a four-factor model that considers the importance of studying both risk and resilience in understanding the developmental response to trauma/stress. Consideration of the multifactorial nature of clinical populations in the design of preclinical models and the application of preclinical findings to clinical treatment approaches comprise the core of translational reciprocity, which is discussed in the context of the four-factor model. ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21948,""
"SVM-based characterization of liver ultrasound images using wavelet packet texture descriptors","Virmani, Kumar, Kalra, Khandelwal","https://doi.org/10.1007/s10278-012-9537-8","20140109","PubMed","Algorithms; Carcinoma, Hepatocellular; Diagnosis, Computer-Assisted; Female; Humans; Liver; Liver Cirrhosis; Liver Neoplasms; Male; Sensitivity and Specificity; Support Vector Machine; Ultrasonography; Wavelet Analysis","A system to characterize normal liver, cirrhotic liver and hepatocellular carcinoma (HCC) evolved on cirrhotic liver is proposed in this paper. The study is performed with 56 real ultrasound images (15 normal, 16 cirrhotic and 25 HCC liver images) taken from 56 subjects. A total of 180 nonoverlapping regions of interest (ROIs), i.e. 60 from each image class, are extracted by an experienced participating radiologist. The multiresolution wavelet packet texture descriptors, i.e. mean, standard deviation and energy features, are computed from all 180 ROIs by using various compact support wavelet filters including Haar, Daubechies (db4 and db6), biorthogonal (bior3.1,bior3.3 and bior4.4), symlets (sym3 and sym5) and coiflets (coif1 and coif2). It is observed that a combined texture descriptor feature vector of length 48 consisting of 16 mean, 16 standard deviation and 16 energy features estimated from all 16 subband feature images (wavelet packets) obtained by second-level decomposition with two-dimensional wavelet packet transform by using Haar wavelet filter gives the best characterization performance of 86.6Ã‚Â %. Feature selection by genetic algorithm-support vector machine method increased the classification accuracy to 88.8Ã‚Â % with sensitivity of 90Ã‚Â % for detecting normal and cirrhotic cases and sensitivity of 86.6Ã‚Â % for HCC cases. Considering limited sensitivity of B-mode ultrasound for detecting HCCs evolved on cirrhotic liver, the sensitivity of 86.6Ã‚Â % for HCC lesions obtained by the proposed computer-aided diagnostic system is quite promising and suggests that the proposed system can be used in a clinical environment to support radiologists in lesion interpretation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21949,""
"A rule based solution to co-reference resolution in clinical text","Chen, Hinote, Chen","https://doi.org/10.1136/amiajnl-2011-000770","20131217","PubMed","Co-reference Resolution; Computational Linguistics; Natural Language Processing; Rule-based system; Algorithms; Artificial Intelligence; Data Mining; Electronic Health Records; Female; Humans; Male; Natural Language Processing","To build an effective co-reference resolution system tailored to the biomedical domain. Experimental materials used in this study were provided by the 2011 i2b2 Natural Language Processing Challenge. The 2011 i2b2 challenge involves co-reference resolution in medical documents. Concept mentions have been annotated in clinical texts, and the mentions that co-refer in each document are linked by co-reference chains. Normally, there are two ways of constructing a system to automatically discoverco-referent links. One is to manually build rules forco-reference resolution; the other is to use machine learning systems to learn automatically from training datasets and then perform the resolution task on testing datasets. The existing co-reference resolution systems are able to find some of the co-referent links; our rule based system performs well, finding the majority of the co-referent links. Our system achieved 89.6% overall performance on multiple medical datasets. Manually crafted rules based on observation of training data is a valid way to accomplish high performance in this co-reference resolution task for the critical biomedical domain.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21950,""
"Integrating constitutive gene expression and chemoactivity: mining the NCI60 anticancer screen","Covell","https://doi.org/10.1371/journal.pone.0044631","20130402","PubMed","Algorithms; Antineoplastic Agents; Camptothecin; Cell Line, Tumor; Cell Proliferation; Cell Survival; Cluster Analysis; Colchicine; Computational Biology; Cyclin-Dependent Kinases; Dasatinib; Databases, Genetic; Fluorouracil; Gene Expression Profiling; Gene Expression Regulation, Neoplastic; Humans; Inhibitory Concentration 50; Neoplasms; Oligonucleotide Array Sequence Analysis; Paclitaxel; Pimozide; Purines; Pyrimidines; Terfenadine; Thiazoles; Tubulin Modulators; Verapamil","Studies into the genetic origins of tumor cell chemoactivity pose significant challenges to bioinformatic mining efforts. Connections between measures of gene expression and chemoactivity have the potential to identify clinical biomarkers of compound response, cellular pathways important to efficacy and potential toxicities; all vital to anticancer drug development. An investigation has been conducted that jointly explores tumor-cell constitutive NCI60 gene expression profiles and small-molecule NCI60 growth inhibition chemoactivity profiles, viewed from novel applications of self-organizing maps (SOMs) and pathway-centric analyses of gene expressions, to identify subsets of over- and under-expressed pathway genes that discriminate chemo-sensitive and chemo-insensitive tumor cell types. Linear Discriminant Analysis (LDA) is used to quantify the accuracy of discriminating genes to predict tumor cell chemoactivity. LDA results find 15% higher prediction accuracies, using Ã¢Ë†Â¼30% fewer genes, for pathway-derived discriminating genes when compared to genes derived using conventional gene expression-chemoactivity correlations. The proposed pathway-centric data mining procedure was used to derive discriminating genes for ten well-known compounds. Discriminating genes were further evaluated using gene set enrichment analysis (GSEA) to reveal a cellular genetic landscape, comprised of small numbers of key over and under expressed on- and off-target pathway genes, as important for a compound's tumor cell chemoactivity. Literature-based validations are provided as support for chemo-important pathways derived from this procedure. Qualitatively similar results are found when using gene expression measurements derived from different microarray platforms. The data used in this analysis is available at http://pubchem.ncbi.nlm.nih.gov/andhttp://www.ncbi.nlm.nih.gov/projects/geo (GPL96, GSE32474).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21951,""
"Robot-assisted surgery: improved tool for major liver resections?","Abood, Tsung","https://doi.org/10.1007/s00534-012-0560-4","20130806","PubMed","Hepatectomy; Humans; Laparoscopy; Liver Diseases; Robotics; Treatment Outcome","Minimally invasive liver surgery has recently undergone an explosion in reported worldwide experience. Given its comparable outcomes to its open counterpart, high-volume centers are utilizing minimal access liver surgery more frequently under well-defined criteria. The recent introduction of robot-assisted surgery has further revolutionized the field of minimally invasive surgery and has expanded the reach of feasibility. Robot-assisted surgery was developed to help overcome the disadvantages of conventional laparoscopic surgery. As a result, there has been an increase in the reporting of advanced robot-assisted liver resections. A literature review was performed to identify the current manuscripts describing robot-assisted liver surgery. Nine case series were identified, yielding 144 unique patient characteristics. Outcomes indicate that robot-assisted liver resection is feasible and safe for both minor and major liver resections with regard to estimated blood loss, length of stay, and complications. Early data also suggest that robot-assisted liver surgery is efficacious with regard to short-term oncologic outcomes. Future studies will be needed to better evaluate advantages and disadvantages compared to laparoscopic liver resections.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21952,""
"SemMedDB: a PubMed-scale repository of biomedical semantic predications","Kilicoglu, Shin, Fiszman, Rosemblat, Rindflesch","https://doi.org/10.1093/bioinformatics/bts591","20130805","PubMed","Algorithms; Data Mining; Databases, Factual; Humans; PubMed; Semantics; Unified Medical Language System","Effective access to the vast biomedical knowledge present in the scientific literature is challenging. Semantic relations are increasingly used in knowledge management applications supporting biomedical research to help address this challenge. We describe SemMedDB, a repository of semantic predications (subject-predicate-object triples) extracted from the entire set of PubMed citations. We propose the repository as a knowledge resource that can assist in hypothesis generation and literature-based discovery in biomedicine as well as in clinical decision-making support. The SemMedDB repository is available as a MySQL database for non-commercial use at http://skr3.nlm.nih.gov/SemMedDB. An UMLS Metathesaurus license is required. kilicogluh@mail.nih.gov.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21953,""
"An automatic refolding apparatus for preparative-scale protein production","Feng, Zhang, Zhang, Zhang, Ding, Zhuang, Wang, Yang","https://doi.org/10.1371/journal.pone.0045891","20130228","PubMed","Algorithms; Animals; Automation, Laboratory; Cattle; Chromatography, Gel; Chromatography, Ion Exchange; Humans; Inclusion Bodies; Oxidation-Reduction; Protein Denaturation; Protein Refolding; Recombinant Proteins; Ultrafiltration; Urea","Protein refolding is an important process to recover active recombinant proteins from inclusion bodies. Refolding by simple dilution, dialysis and on-column refolding methods are the most common techniques reported in the literature. However, the refolding process is time-consuming and laborious due to the variability of the behavior of each protein and requires a great deal of trial-and-error to achieve success. Hence, there is a need for automation to make the whole process as convenient as possible. In this study, we invented an automatic apparatus that integrated three refolding techniques: varying dilution, dialysis and on-column refolding. We demonstrated the effectiveness of this technology by varying the flow rates of the dilution buffer into the denatured protein and testing different refolding methods. We carried out different refolding methods on this apparatus: a combination of dilution and dialysis for human stromal cell-derived factor 1 (SDF-1/CXCL12) and thioredoxin fused-human artemin protein (Trx-ARTN); dilution refolding for thioredoxin fused-human insulin-like growth factor I protein (Trx-IGF1) and enhanced fluorescent protein (EGFP); and on-column refolding for bovine serum albumin (BSA). The protein refolding processes of these five proteins were preliminarily optimized using the slowly descending denaturants (or additives) method. Using this strategy of decreasing denaturants concentration, the efficiency of protein refolding was found to produce higher quantities of native protein. The standard refolding apparatus configuration can support different operations for different applications; it is not limited to simple dilution, dialysis and on-column refolding techniques. Refolding by slowly decreasing denaturants concentration, followed by concentration or purification on-column, may be a useful strategy for rapid and efficient recovery of active proteins from inclusion bodies. An automatic refolding apparatus employing this flexible strategy may provide a powerful tool for preparative scale protein production.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21954,""
"ADHD classification by a texture analysis of anatomical brain MRI data","Chang, Ho, Chen","https://doi.org/10.3389/fnsys.2012.00066","20121002","PubMed","ADHD; ADHD200 global competition; LBP; MRI; brain anatomical MRI; isotropic local binary patterns on three orthogona; local binary patterns; texture analysis","The ADHD-200 Global Competition provides an excellent opportunity for building diagnostic classifiers of Attention-Deficit/Hyperactivity Disorder (ADHD) based on resting-state functional MRI (rs-fMRI) and structural MRI data. Here, we introduce a simple method to classify ADHD based on morphological information without using functional data. Our test results show that the accuracy of this approach is competitive with methods based on rs-fMRI data. We used isotropic local binary patterns on three orthogonal planes (LBP-TOP) to extract features from MR brain images. Subsequently, support vector machines (SVM) were used to develop classification models based on the extracted features. In this study, a total of 436 male subjects (210 with ADHD and 226 controls) were analyzed to show the discriminative power of the method. To analyze the properties of this approach, we tested disparate LBP-TOP features from various parcellations and different image resolutions. Additionally, morphological information using a single brain tissue type (i.e., gray matter (GM), white matter (WM), and CSF) was tested. The highest accuracy we achieved was 0.6995. The LBP-TOP was found to provide better discriminative power using whole-brain data as the input. Datasets with higher resolution can train models with increased accuracy. The information from GM plays a more important role than that of other tissue types. These results and the properties of LBP-TOP suggest that most of the disparate feature distribution comes from different patterns of cortical folding. Using LBP-TOP, we provide an ADHD classification model based only on anatomical information, which is easier to obtain in the clinical environment and which is simpler to preprocess compared with rs-fMRI data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21955,""
"Timing deficits in attention-deficit/hyperactivity disorder (ADHD): evidence from neurocognitive and neuroimaging studies","Noreika, Falter, Rubia","https://doi.org/10.1016/j.neuropsychologia.2012.09.036","20130809","PubMed","Attention Deficit Disorder with Hyperactivity; Female; Humans; Male; Neuroimaging; Neuropsychological Tests; Perceptual Disorders; Time Perception","Relatively recently, neurocognitive and neuroimaging studies have indicated that individuals with attention-deficit/hyperactivity disorder (ADHD) may have deficits in a range of timing functions and their underlying neural networks. Despite this evidence, timing deficits in ADHD are still somewhat neglected in the literature and mostly omitted from reviews on ADHD. There is therefore a lack of integrative reviews on the up-to-date evidence on neurocognitive and neurofunctional deficits of timing in ADHD and their significance with respect to other behavioural and cognitive deficits. The present review provides a synthetic overview of the evidence for neurocognitive and neurofunctional deficits in ADHD in timing functions, and integrates this evidence with the cognitive neuroscience literature of the neural substrates of timing. The review demonstrates that ADHD patients are consistently impaired in three major timing domains, in motor timing, perceptual timing and temporal foresight, comprising several timeframes spanning milliseconds, seconds, minutes and longer intervals up to years. The most consistent impairments in ADHD are found in sensorimotor synchronisation, duration discrimination, reproduction and delay discounting. These neurocognitive findings of timing deficits in ADHD are furthermore supported by functional neuroimaging studies that show dysfunctions in the key inferior fronto-striato-cerebellar and fronto-parietal networks that mediate the timing functions. Although there is evidence that these timing functions are inter-correlated with other executive functions that are well established to be impaired in the disorder, in particular working memory, attention, and to a lesser degree inhibitory control, the key timing deficits appear to survive when these functions are controlled for, suggesting independent cognitive deficits in the temporal domain. There is furthermore strong evidence for an association between timing deficits and behavioural measures of impulsiveness and inattention, suggesting that timing problems are key to the clinical behavioural profile of ADHD. Emerging evidence shows that the most common treatment of ADHD with the dopamine agonist and psychostimulant Methylphenidate attenuates most timing deficits in ADHD and normalises the abnormally blunted recruitment of the underlying fronto-striato-cerebellar networks. Timing function deficits in ADHD, therefore, next to executive function deficits, form an independent impairment domain, and should receive more attention in neuropsychological, neuroimaging, and pharmacological basic research as well as in translational research aimed to develop pharmacological or non-pharmacological treatment of abnormal timing behaviour and cognition in ADHD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21956,""
"Modeling temporal relationships in large scale clinical associations","Hanauer, Ramakrishnan","https://doi.org/10.1136/amiajnl-2012-001117","20130812","PubMed","Computer Graphics; Data Mining; Electronic Health Records; Epidemiologic Methods; Feasibility Studies; Humans; International Classification of Diseases; Michigan; Space-Time Clustering","We describe an approach for modeling temporal relationships in a large scale association analysis of electronic health record data. The addition of temporal information can inform hypothesis generation and help to explain the relationships. We applied this approach on a dataset containing 41.2 million time-stamped International Classification of Diseases, Ninth Revision (ICD-9) codes from 1.6 million patients. We performed two independent analyses including a pairwise association analysis using a Ãâ€¡(2) test and a temporal analysis using a binomial test. Data were visualized using network diagrams and reviewed for clinical significance. We found nearly 400 000 highly associated pairs of ICD-9 codes with varying numbers of strong temporal associations ranging from Ã¢â€°Â¥1 day to Ã¢â€°Â¥10 years apart. Most of the findings were not considered clinically novel, although some, such as an association between Helicobacter pylori infection and diabetes, have recently been reported in the literature. The temporal analysis in our large cohort, however, revealed that diabetes usually preceded the diagnoses of H pylori, raising questions about possible cause and effect. Such analyses have significant limitations, some of which are due to known problems with ICD-9 codes and others to potentially incomplete data even at a health system level. Nevertheless, large scale association analyses with temporal modeling can help provide a mechanism for novel discovery in support of hypothesis generation. Temporal relationships can provide an additional layer of meaning in identifying and interpreting clinical associations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21957,""
"Drugs and Birth Defects: a knowledge database providing risk assessments based on national health registers","NÃƒÂ¶rby, KÃƒÂ¤llÃƒÂ©n, Eiermann, Korkmaz, Winbladh, Gustafsson","https://doi.org/10.1007/s00228-012-1399-y","20130927","PubMed","Abnormalities, Drug-Induced; Adverse Drug Reaction Reporting Systems; Databases, Factual; Drug-Related Side Effects and Adverse Reactions; Female; Humans; Pregnancy; Registries; Risk Assessment; Sweden","To present concept, methods and use of a knowledge database providing assessments of potential fetal risks for all drugs on the Swedish market. Assessments of fetal risks are made primarily by analyzing prospective epidemiological data from the Swedish Medical Birth Register on drug intake in relation to birth outcome. This is complemented by evaluation of the scientific literature. Following standardized working procedures, a statement is compiled for each substance, which is also classified into one of three categories depending on the estimated risk level. The final documents include drug product names on the market, via linkage to a medicinal products register. The information is free and published on the website www.janusinfo.se . It can also be used as an integrated part of electronic health records. The database covers assessments of fetal risks for close to 1,250 medicinal drug substances on the Swedish market. Each year, 96,000 searches are made, which might be compared to the around 100,000 children born in Sweden yearly. Apart from the Swedish Physicians' Desk Reference (Fass), the database is the most commonly used resource among specialists within gynaecology and perinatal medicine for information on drugs during pregnancy. A non-commercial knowledge base with assessments of fetal risk of different drugs is valued by health care professionals and is used extensively in Sweden. Based on analyses of national health registers, the database provides unique information on teratogenic drug risks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21958,""
"Characteristics of mentoring relationships formed by medical students and faculty","Dimitriadis, von der Borch, StÃƒÂ¶rmann, Meinel, Moder, Reincke, Fischer","https://doi.org/10.3402/meo.v17i0.17242","20130116","PubMed","faculty; medical students; mentee; mentor; mentoring; one-on-one mentoring; Education, Medical, Graduate; Educational Measurement; Faculty, Medical; Female; Humans; Interpersonal Relations; Male; Mentors; Professional Role; Sex Factors; Students, Medical","Little is known about the characteristics of mentoring relationships formed between faculty and medical students. Individual mentoring relationships of clinical medical students at Munich Medical School were characterized quantitatively and qualitatively. All students signing up for the mentoring program responded to a questionnaire on their expectations (n = 534). Mentees were asked to give feedback after each of their one-on-one meetings (n = 203). A detailed analysis of the overall mentoring process and its characteristics was performed. For qualitative text analysis, free-text items were analyzed and categorized by two investigators. Quantitative analysis was performed using descriptive statistics and Wilcoxon-test to assess differences in grades between students with and without mentors. High-performing students were significantly more likely to participate in the mentoring program (p&lt;0.001). Topics primarily discussed include the mentee's personal goals (65.5%), career planning (59.6%), and experiences abroad (57.6%). Mentees mostly perceived their mentors as counselors (88.9%), providers of ideas (85.0%), and role models (73.3%). Mentees emphasized the positive impact of the mentoring relationship on career planning (77.2%) and research (75.0%). Medical students with strong academic performance as defined by their grades are more likely to participate in formal mentoring programs. Mentoring relationships between faculty and medical students are perceived as a mutually satisfying and effective instrument for key issues in medical students' professional development. Mentoring relationships are a highly effective means of enhancing the bidirectional flow of information between faculty and medical students. A mentoring program can thus establish a feedback loop enabling the educational institution to swiftly identify and address issues of medical students.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21959,""
"Integrating various resources for gene name normalization","Hu, Li, Lin, Yang, Cheng","https://doi.org/10.1371/journal.pone.0043558","20130312","PubMed","Databases as Topic; Dictionaries as Topic; Genes; Molecular Sequence Annotation; Reference Standards; Terminology as Topic","The recognition and normalization of gene mentions in biomedical literature are crucial steps in biomedical text mining. We present a system for extracting gene names from biomedical literature and normalizing them to gene identifiers in databases. The system consists of four major components: gene name recognition, entity mapping, disambiguation and filtering. The first component is a gene name recognizer based on dictionary matching and semi-supervised learning, which utilizes the co-occurrence information of a large amount of unlabeled MEDLINE abstracts to enhance feature representation of gene named entities. In the stage of entity mapping, we combine the strategies of exact match and approximate match to establish linkage between gene names in the context and the EntrezGene database. For the gene names that map to more than one database identifiers, we develop a disambiguation method based on semantic similarity derived from the Gene Ontology and MEDLINE abstracts. To remove the noise produced in the previous steps, we design a filtering method based on the confidence scores in the dictionary used for NER. The system is able to adjust the trade-off between precision and recall based on the result of filtering. It achieves an F-measure of 83% (precision: 82.5% recall: 83.5%) on BioCreative II Gene Normalization (GN) dataset, which is comparable to the current state-of-the-art.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21960,""
"Toward systems neuroscience of ADHD: a meta-analysis of 55 fMRI studies","Cortese, Kelly, Chabernaud, Proal, Di Martino, Milham, Castellanos","https://doi.org/10.1176/appi.ajp.2012.11101521","20130312","PubMed","Attention Deficit Disorder with Hyperactivity; Brain; Case-Control Studies; Functional Neuroimaging; Humans; Magnetic Resonance Imaging; Neural Pathways; Neuropsychological Tests","The authors performed a comprehensive meta-analysis of task-based functional MRI studies of attention deficit hyperactivity disorder (ADHD). The authors searched PubMed, Ovid, EMBASE, Web of Science, ERIC, CINAHAL, and NeuroSynth for studies published through June 30, 2011. Significant differences in brain region activation between individuals with ADHD and comparison subjects were detected using activation likelihood estimation meta-analysis. Dysfunctional regions in ADHD were related to seven reference neuronal systems. The authors performed a set of meta-analyses focused on age groups (children and adults), clinical characteristics (history of stimulant treatment and presence of psychiatric comorbidities), and specific neuropsychological tasks (inhibition, working memory, and vigilance/attention). Fifty-five studies were included (39 for children and 16 for adults). In children, hypoactivation in ADHD relative to comparison subjects was observed mostly in systems involved in executive function (frontoparietal network) and attention (ventral attentional network). Significant hyperactivation in ADHD relative to comparison subjects was observed predominantly in the default, ventral attention, and somatomotor networks. In adults, ADHD-related hypoactivation was predominant in the frontoparietal system, while ADHD-related hyperactivation was present in the visual, dorsal attention, and default networks. Significant ADHD-related dysfunction largely reflected task features and was detected even in the absence of comorbid mental disorders or a history of stimulant treatment. A growing literature provides evidence of ADHD-related dysfunction in multiple neuronal systems involved in higher-level cognitive functions but also in sensorimotor processes, including the visual system, and in the default network. This meta-analytic evidence extends early models of ADHD pathophysiology that were focused on prefrontal-striatal circuits.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21961,""
"The cost effectiveness of genetic testing for CYP2C19 variants to guide thienopyridine treatment in patients with acute coronary syndromes: a New Zealand evaluation","Panattoni, Brown, Te Ao, Webster, Gladding","https://doi.org/10.2165/11595080-000000000-00000","20130308","PubMed","Acute Coronary Syndrome; Aged; Aged, 80 and over; Alleles; Aryl Hydrocarbon Hydroxylases; Clopidogrel; Cost-Benefit Analysis; Cytochrome P-450 CYP2C19; Decision Trees; Diagnosis-Related Groups; Drugs, Generic; Female; Genetic Testing; Hospital Costs; Hospitalization; Humans; Male; Middle Aged; Monte Carlo Method; New Zealand; Oceanic Ancestry Group; Piperazines; Platelet Aggregation Inhibitors; Prasugrel Hydrochloride; Quality-Adjusted Life Years; Thiophenes; Ticlopidine","A recent clinical trial has demonstrated that patients with acute coronary syndromes (ACS) and the reduced function allele CYP2C19*2 (*2 allele), who are treated with thienopyridines, have an increased risk of adverse cardiac events with clopidogrel, but not with prasugrel. The frequency of the *2 allele varies by ethnicity and the Maoris, Asians and Pacific Islanders of New Zealand have a relatively high incidence. Our objective was to evaluate, from a New Zealand health system perspective, the cost effectiveness of treating all ACS patients with generic clopidogrel compared with prasugrel, and also compared with the genetically guided strategy that *2 allele carriers receive prasugrel and non-carriers receive clopidogrel. A decision-tree model consisting of five health states (myocardial infarction, stroke, bleeding, stent thrombosis and cardiovascular death) was developed. Clinical outcome data (two TRITON-TIMI 38 genetic sub-studies) comparing clopidogrel and prasugrel for both *2 allele carriers and non-carriers were combined with the prevalence of the heterozygosity for the *2 allele in New Zealand Europeans (15%), Maoris (24%), Asians (29%) and Pacific Islanders (45%) to determine the predicted adverse event rate for the New Zealand population. National hospital diagnosis-related group (DRG) discharge codes were used to determine alternative adverse event rates, along with the costs of hospitalizations during the 15 months after patients presented with an ACS. The primary outcome measure was the incremental cost per QALY (calculated using literature-reported weights). Monte Carlo simulations and alternative scenario analysis based on both clinical trial and national hospital incidence were used. Additional analysis considered the overall TRITON-TIMI 38 rates. Costs (in New Zealand dollars [$NZ], year 2009 values) and benefits were discounted at 3% per annum. Actual hospital-based adverse event rates were higher than those reported in the TRITON-TIMI 38 randomized controlled trial and the genetic sub-studies, especially for myocardial infarction and cardiovascular death, and for Maoris and Pacific Islanders. For both sources of adverse event rates, treating the population with prasugrel was associated with worse outcomes (QALYs) than clopidogrel. However, prasugrel became cost effective ($NZ31Ã¢â‚¬â€°751/QALY) when the overall TRITON-TIMI 38 rates were used. A genetic test to guide the selected use of prasugrel was cost effective ($NZ8702/QALY versus $NZ24Ã¢â‚¬â€°617/QALY) for hospital and clinical trial incidence, respectively. Based on the hospital rates, the genetically guided strategy was especially cost effective for Maoris ($NZ7312/QALY) and Pacific Islanders ($NZ7041/QALY). These results were robust to the sensitivity analysis, except the genetically guided strategy under the 15-month clinical trial event rate scenario ($NZ168Ã¢â‚¬â€°748/QALY) did not remain cost effective under a $NZ50Ã¢â‚¬â€°000 threshold. Use of a genetic test to guide thienopyridine treatment in patients with ACS is a potentially cost-effective treatment strategy, especially for Maoris and Pacific Islanders. This treatment strategy also has the potential to reduce ethnic health disparities that exist in New Zealand. However, the results comparing clopidogrel and prasugrel are sensitive to whether the genetic sub-studies or the overall TRITON-TIMI 38 rates are used. While the national hospital event rates may be more appropriate for the New Zealand population, many assumptions are required when they are used to adjust the genetic sub-studies rates.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21962,""
"Imagining is Not Doing but Involves Specific Motor Commands: A Review of Experimental Data Related to Motor Inhibition","Guillot, Di Rienzo, Macintyre, Moran, Collet","https://doi.org/10.3389/fnhum.2012.00247","20121002","PubMed","electromyography; mental processes; motor command inhibition; motor imagery; motor performance; sensorimotor control","There is now compelling evidence that motor imagery (MI) and actual movement share common neural substrate. However, the question of how MI inhibits the transmission of motor commands into the efferent pathways in order to prevent any movement is largely unresolved. Similarly, little is known about the nature of the electromyographic activity that is apparent during MI. In addressing these gaps in the literature, the present paper argues that MI includes motor execution commands for muscle contractions which are blocked at some level of the motor system by inhibitory mechanisms. We first assemble data from neuroimaging studies that demonstrate that the neural networks mediating MI and motor performance are not totally overlapping, thereby highlighting potential differences between MI and actual motor execution. We then review MI data indicating the presence of subliminal muscular activity reflecting the intrinsic characteristics of the motor command as well as increased corticomotor excitability. The third section not only considers the inhibitory mechanisms involved during MI but also examines how the brain resolves the problem of issuing the motor command for action while supervising motor inhibition when people engage in voluntary movement during MI. The last part of the paper draws on imagery research in clinical contexts to suggest that some patients move while imagining an action, although they are not aware of such movements. In particular, experimental data from amputees as well as from patients with Parkinson's disease are discussed. We also review recent studies based on comparing brain activity in tetraplegic patients with that from healthy matched controls that provide insights into inhibitory processes during MI. We conclude by arguing that based on available evidence, a multifactorial explanation of motor inhibition during MI is warranted.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21963,""
"Text data extraction for a prospective, research-focused data mart: implementation and validation","Hinchcliff, Just, Podlusky, Varga, Chang, Kibbe","https://doi.org/10.1186/1472-6947-12-106","20130524","PubMed","Data Mining; Electronic Data Processing; Electronic Health Records; Humans; Medical Informatics; Respiratory Function Tests; Scleroderma, Systemic; Sclerosis; Software; Translational Medical Research; United States","Translational research typically requires data abstracted from medical records as well as data collected specifically for research. Unfortunately, many data within electronic health records are represented as text that is not amenable to aggregation for analyses. We present a scalable open source SQL Server Integration Services package, called Regextractor, for including regular expression parsers into a classic extract, transform, and load workflow. We have used Regextractor to abstract discrete data from textual reports from a number of 'machine generated' sources. To validate this package, we created a pulmonary function test data mart and analyzed the quality of the data mart versus manual chart review. Eleven variables from pulmonary function tests performed closest to the initial clinical evaluation date were studied for 100 randomly selected subjects with scleroderma. One research assistant manually reviewed, abstracted, and entered relevant data into a database. Correlation with data obtained from the automated pulmonary function test data mart within the Northwestern Medical Enterprise Data Warehouse was determined. There was a near perfect (99.5%) agreement between results generated from the Regextractor package and those obtained via manual chart abstraction. The pulmonary function test data mart has been used subsequently to monitor disease progression of patients in the Northwestern Scleroderma Registry. In addition to the pulmonary function test example presented in this manuscript, the Regextractor package has been used to create cardiac catheterization and echocardiography data marts. The Regextractor package was released as open source software in October 2009 and has been downloaded 552 times as of 6/1/2012. Collaboration between clinical researchers and biomedical informatics experts enabled the development and validation of a tool (Regextractor) to parse, abstract and assemble structured data from text data contained in the electronic health record. Regextractor has been successfully used to create additional data marts in other medical domains and is available to the public.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21964,""
"Towards more effective robotic gait training for stroke rehabilitation: a review","Pennycott, Wyss, Vallery, Klamroth-Marganska, Riener","https://doi.org/10.1186/1743-0003-9-65","20130220","PubMed","Exercise Therapy; Gait; Gait Disorders, Neurologic; Humans; Physical Education and Training; Quality Improvement; Robotics; Stroke; Stroke Rehabilitation; Treatment Outcome","Stroke is the most common cause of disability in the developed world and can severely degrade walking function. Robot-driven gait therapy can provide assistance to patients during training and offers a number of advantages over other forms of therapy. These potential benefits do not, however, seem to have been fully realised as of yet in clinical practice. This review determines ways in which robot-driven gait technology could be improved in order to achieve better outcomes in gait rehabilitation. The literature on gait impairments caused by stroke is reviewed, followed by research detailing the different pathways to recovery. The outcomes of clinical trials investigating robot-driven gait therapy are then examined. Finally, an analysis of the literature focused on the technical features of the robot-based devices is presented. This review thus combines both clinical and technical aspects in order to determine the routes by which robot-driven gait therapy could be further developed. Active subject participation in robot-driven gait therapy is vital to many of the potential recovery pathways and is therefore an important feature of gait training. Higher levels of subject participation and challenge could be promoted through designs with a high emphasis on robotic transparency and sufficient degrees of freedom to allow other aspects of gait such as balance to be incorporated.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21965,""
"Exocrine pancreatic carcinogenesis and autotaxin expression","Kadekar, Silins, Korhonen, Dreij, Al-Anati, HÃƒÂ¶gberg, Stenius","https://doi.org/10.1371/journal.pone.0043209","20130219","PubMed","Acinar Cells; Adenoma; Animals; Biological Assay; Calcium; Carcinoma; Cell Line, Tumor; Cell Transformation, Neoplastic; Data Mining; Gene Expression Regulation, Neoplastic; Humans; Male; Models, Genetic; Pancreatic Neoplasms; Phosphoric Diester Hydrolases; Rats; Testosterone","Exocrine pancreatic cancer is an aggressive disease with an exceptionally high mortality rate. Genetic analysis suggests a causative role for environmental factors, but consistent epidemiological support is scarce and no biomarkers for monitoring the effects of chemical pancreatic carcinogens are available. With the objective to identify common traits for chemicals inducing pancreatic tumors we studied the National Toxicology Program (NTP) bioassay database. We found that male rats were affected more often than female rats and identified eight chemicals that induced exocrine pancreatic tumors in males only. For a hypothesis generating process we used a text mining tool to analyse published literature for suggested mode of actions (MOA). The resulting MOA analysis suggested inflammatory responses as common feature. In cell studies we found that all the chemicals increased protein levels of the inflammatory protein autotaxin (ATX) in Panc-1, MIA PaCa-2 or Capan-2 cells. Induction of MMP-9 and increased invasive migration were also frequent effects, consistent with ATX activation. Testosterone has previously been implicated in pancreatic carcinogenesis and we found that it increased ATX levels. Our data show that ATX is a target for chemicals inducing pancreatic tumors in rats. Several lines of evidence implicate ATX and its product lysophosphatidic acid in human pancreatic cancer. Mechanisms of action may include stimulated invasive growth and metastasis. ATX may interact with hormones or onco- or suppressor-genes often deregulated in exocrine pancreatic cancer. Our data suggest that ATX is a target for chemicals promoting pancreatic tumor development.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21966,""
"Computerized segmentation and characterization of breast lesions in dynamic contrast-enhanced MR images using fuzzy c-means clustering and snake algorithm","Pang, Li, Hu, Peng, Liu, Shao","https://doi.org/10.1155/2012/634907","20130110","PubMed","Adult; Aged; Algorithms; Area Under Curve; Breast Neoplasms; Cluster Analysis; Computer Simulation; Contrast Media; Early Detection of Cancer; Female; Fuzzy Logic; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Middle Aged; Pattern Recognition, Automated; Software","This paper presents a novel two-step approach that incorporates fuzzy c-means (FCMs) clustering and gradient vector flow (GVF) snake algorithm for lesions contour segmentation on breast magnetic resonance imaging (BMRI). Manual delineation of the lesions by expert MR radiologists was taken as a reference standard in evaluating the computerized segmentation approach. The proposed algorithm was also compared with the FCMs clustering based method. With a database of 60 mass-like lesions (22 benign and 38 malignant cases), the proposed method demonstrated sufficiently good segmentation performance. The morphological and texture features were extracted and used to classify the benign and malignant lesions based on the proposed computerized segmentation contour and radiologists' delineation, respectively. Features extracted by the computerized characterization method were employed to differentiate the lesions with an area under the receiver-operating characteristic curve (AUC) of 0.968, in comparison with an AUC of 0.914 based on the features extracted from radiologists' delineation. The proposed method in current study can assist radiologists to delineate and characterize BMRI lesion, such as quantifying morphological and texture features and improving the objectivity and efficiency of BMRI interpretation with a certain clinical value.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21967,""
"The feasibility of using natural language processing to extract clinical information from breast pathology reports","Buckley, Coopey, Sharko, Polubriaginof, Drohan, Belli, Kim, Garber, Smith, Gadd, Specht, Roche, Gudewicz, Hughes","https://doi.org/10.4103/2153-3539.97788","20121002","PubMed","Breast pathology reports; clinical decision support; natural language processing","The opportunity to integrate clinical decision support systems into clinical practice is limited due to the lack of structured, machine readable data in the current format of the electronic health record. Natural language processing has been designed to convert free text into machine readable data. The aim of the current study was to ascertain the feasibility of using natural language processing to extract clinical information from &gt;76,000 breast pathology reports. APPROACH AND PROCEDURE: Breast pathology reports from three institutions were analyzed using natural language processing software (Clearforest, Waltham, MA) to extract information on a variety of pathologic diagnoses of interest. Data tables were created from the extracted information according to date of surgery, side of surgery, and medical record number. The variety of ways in which each diagnosis could be represented was recorded, as a means of demonstrating the complexity of machine interpretation of free text. There was widespread variation in how pathologists reported common pathologic diagnoses. We report, for example, 124 ways of saying invasive ductal carcinoma and 95 ways of saying invasive lobular carcinoma. There were &gt;4000 ways of saying invasive ductal carcinoma was not present. Natural language processor sensitivity and specificity were 99.1% and 96.5% when compared to expert human coders. We have demonstrated how a large body of free text medical information such as seen in breast pathology reports, can be converted to a machine readable format using natural language processing, and described the inherent complexities of the task.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21968,""
"Benefits of off-campus education for students in the health sciences: a text-mining analysis","Nakagawa, Asakawa, Yamada, Ushikubo, Yoshida, Yamaguchi","https://doi.org/10.1186/1472-6920-12-84","20130502","PubMed","Adult; Aged; Attitude of Health Personnel; Community Medicine; Community-Institutional Relations; Curriculum; Data Mining; Disabled Persons; Health Education; Health Personnel; Health Promotion; Humans; Japan; Middle Aged; Models, Educational; Professional-Patient Relations; Program Evaluation; Self-Assessment; Social Environment","In Japan, few community-based approaches have been adopted in health-care professional education, and the appropriate content for such approaches has not been clarified. In establishing community-based education for health-care professionals, clarification of its learning effects is required. A community-based educational program was started in 2009 in the health sciences course at Gunma University, and one of the main elements in this program is conducting classes outside school. The purpose of this study was to investigate using text-analysis methods how the off-campus program affects students. In all, 116 self-assessment worksheets submitted by students after participating in the off-campus classes were decomposed into words. The extracted words were carefully selected from the perspective of contained meaning or content. With the selected terms, the relations to each word were analyzed by means of cluster analysis. Cluster analysis was used to select and divide 32 extracted words into four clusters: cluster 1-""actually/direct,"" ""learn/watch/hear,"" ""how,"" ""experience/participation,"" ""local residents,"" ""atmosphere in community-based clinical care settings,"" ""favorable,"" ""communication/conversation,"" and ""study""; cluster 2-""work of staff member"" and ""role""; cluster 3-""interaction/communication,"" ""understanding,"" ""feel,"" ""significant/important/necessity,"" and ""think""; and cluster 4-""community,"" ""confusing,"" ""enjoyable,"" ""proactive,"" ""knowledge,"" ""academic knowledge,"" and ""class."" The students who participated in the program achieved different types of learning through the off-campus classes. They also had a positive impression of the community-based experience and interaction with the local residents, which is considered a favorable outcome. Off-campus programs could be a useful educational approach for students in health sciences.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21969,""
"Vaccine adverse event text mining system for extracting features from vaccine safety reports","Botsis, Buttolph, Nguyen, Winiecki, Woo, Ball","https://doi.org/10.1136/amiajnl-2012-000881","20130425","PubMed","Adverse Drug Reaction Reporting Systems; Data Mining; Humans; Natural Language Processing; Semantics; United States; Vaccines","To develop and evaluate a text mining system for extracting key clinical features from vaccine adverse event reporting system (VAERS) narratives to aid in the automated review of adverse event reports. Based upon clinical significance to VAERS reviewing physicians, we defined the primary (diagnosis and cause of death) and secondary features (eg, symptoms) for extraction. We built a novel vaccine adverse event text mining (VaeTM) system based on a semantic text mining strategy. The performance of VaeTM was evaluated using a total of 300 VAERS reports in three sequential evaluations of 100 reports each. Moreover, we evaluated the VaeTM contribution to case classification; an information retrieval-based approach was used for the identification of anaphylaxis cases in a set of reports and was compared with two other methods: a dedicated text classifier and an online tool. The performance metrics of VaeTM were text mining metrics: recall, precision and F-measure. We also conducted a qualitative difference analysis and calculated sensitivity and specificity for classification of anaphylaxis cases based on the above three approaches. VaeTM performed best in extracting diagnosis, second level diagnosis, drug, vaccine, and lot number features (lenient F-measure in the third evaluation: 0.897, 0.817, 0.858, 0.874, and 0.914, respectively). In terms of case classification, high sensitivity was achieved (83.1%); this was equal and better compared to the text classifier (83.1%) and the online tool (40.7%), respectively. Our VaeTM implementation of a semantic text mining strategy shows promise in providing accurate and efficient extraction of key features from VAERS narratives.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21970,""
"Identifying novel drug indications through automated reasoning","Tari, Vo, Liang, Patel, Baral, Cai","https://doi.org/10.1371/journal.pone.0040946","20130419","PubMed","Artificial Intelligence; Computational Biology; Computer Simulation; Databases, Factual; Drug Discovery; Genetic Association Studies; Humans; Protein Binding","With the large amount of pharmacological and biological knowledge available in literature, finding novel drug indications for existing drugs using in silico approaches has become increasingly feasible. Typical literature-based approaches generate new hypotheses in the form of protein-protein interactions networks by means of linking concepts based on their cooccurrences within abstracts. However, this kind of approaches tends to generate too many hypotheses, and identifying new drug indications from large networks can be a time-consuming process. In this work, we developed a method that acquires the necessary facts from literature and knowledge bases, and identifies new drug indications through automated reasoning. This is achieved by encoding the molecular effects caused by drug-target interactions and links to various diseases and drug mechanism as domain knowledge in AnsProlog, a declarative language that is useful for automated reasoning, including reasoning with incomplete information. Unlike other literature-based approaches, our approach is more fine-grained, especially in identifying indirect relationships for drug indications. To evaluate the capability of our approach in inferring novel drug indications, we applied our method to 943 drugs from DrugBank and asked if any of these drugs have potential anti-cancer activities based on information on their targets and molecular interaction types alone. A total of 507 drugs were found to have the potential to be used for cancer treatments. Among the potential anti-cancer drugs, 67 out of 81 drugs (a recall of 82.7%) are indeed known cancer drugs. In addition, 144 out of 289 drugs (a recall of 49.8%) are non-cancer drugs that are currently tested in clinical trials for cancer treatments. These results suggest that our method is able to infer drug indications (original or alternative) based on their molecular targets and interactions alone and has the potential to discover novel drug indications for existing drugs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21971,""
"Economic evaluation of alternative assisted reproduction techniques in management of infertility in Greece","Fragoulakis, Kourlaba, Tarlatzis, Mastrominas, Maniadakis","https://doi.org/10.2147/CEOR.S31972","20121002","PubMed","Gonal-FÃ‚Â®; MenopurÃ‚Â®; cost-effectiveness; highly purified human menopausal gonatotrophin","The purpose of this study was to compare Gonal-F(Ã‚Â®), a recombinant follicle-stimulating hormone, with Menopur(Ã‚Â®), a highly purified human menopausal gonadotrophin (hpHMG) in assisted reproduction in Greece. A decision tree in combination with a Markov model was used to assess the clinical and economical impact of comparators for up to three consecutive cycles. Transition probabilities were derived from the literature and validated by clinical experts. Cost components were derived from the electronic databases of selected private and public clinics. A probabilistic sensitivity analysis was performed to deal with uncertainty and to construct a cost-effectiveness acceptability curve. There was a statistically significant difference in favor of the recombinant follicle-stimulating hormone arm compared with hpHMG, which was associated with 52 more births (95% uncertainty interval 26-78, P = 0.001) per 1000 patients. The cost per birth was estimated at Ã¢â€šÂ¬16,906 and Ã¢â€šÂ¬17,286 in the recombinant follicle-stimulating hormone and hpHMG arms, respectively. The cost per in vitro fertilization was estimated at Ã¢â€šÂ¬4365 in the recombinant follicle-stimulating hormone arm and Ã¢â€šÂ¬3815 in the hpHMG arm, indicating a difference of Ã¢â€šÂ¬550. The incremental cost per birth for recombinant follicle-stimulating hormone versus hpHMG was estimated at Ã¢â€šÂ¬14,540, while the incremental cost per life-year was estimated at Ã¢â€šÂ¬175.41. Recombinant follicle-stimulating hormone may represent a cost-effective choice compared with hpHMG when used for ovarian stimulation for a pharmacoeconomic point of view in the Greek public health care setting. However, it must be noted that in clinical practice both agents may be used together to increase the number of follicles, oocytes, embryos, and/or pregnancies in treated patients, an approach which has not been evaluated in Greece or reported in the literature due to obvious limitations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21972,""
"Intelligent image retrieval based on radiology reports","Gerstmair, Daumke, Simon, Langer, Kotter","https://doi.org/10.1007/s00330-012-2608-x","20130524","PubMed","Algorithms; Data Mining; Humans; Information Storage and Retrieval; Natural Language Processing; Radiology Information Systems; Search Engine; Semantics; Software; User-Computer Interface","To create an advanced image retrieval and data-mining system based on in-house radiology reports. Radiology reports are semantically analysed using natural language processing (NLP) techniques and stored in a state-of-the-art search engine. Images referenced by sequence and image number in the reports are retrieved from the picture archiving and communication system (PACS) and stored for later viewing. A web-based front end is used as an interface to query for images and show the results with the retrieved images and report text. Using a comprehensive radiological lexicon for the underlying terminology, the search algorithm also finds results for synonyms, abbreviations and related topics. The test set was 108 manually annotated reports analysed by different system configurations. Best results were achieved using full syntactic and semantic analysis with a precision of 0.929 and recall of 0.952. Operating successfully since October 2010, 258,824 reports have been indexed and a total of 405,146 preview images are stored in the database. Data-mining and NLP techniques provide quick access to a vast repository of images and radiology reports with both high precision and recall values. Consequently, the system has become a valuable tool in daily clinical routine, education and research. Radiology reports can now be analysed using sophisticated natural language-processing techniques. Semantic text analysis is backed by terminology of a radiological lexicon. The search engine includes results for synonyms, abbreviations and compositions. Key images are automatically extracted from radiology reports and fetched from PACS. Such systems help to find diagnoses, improve report quality and save time.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21973,""
"Evaluation of hepatic tumor response to yttrium-90 radioembolization therapy using texture signatures generated from contrast-enhanced CT images","Gensure, Foran, Lee, Gendel, Jabbour, Carpizo, Nosher, Yang","https://doi.org/10.1016/j.acra.2012.04.015","20130206","PubMed","Aged; Aged, 80 and over; Algorithms; Artificial Intelligence; Female; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Liver Neoplasms; Male; Middle Aged; Pattern Recognition, Automated; Radiopharmaceuticals; Reproducibility of Results; Sensitivity and Specificity; Tomography, X-Ray Computed; Treatment Outcome; Yttrium Radioisotopes","The aim of this study was to explore the use of texture features generated from liver computed tomographic (CT) datasets as potential image-based indicators of patient response to radioembolization (RE) with yttrium-90 ((90)Y) resin microspheres, an emerging locoregional therapy for advanced-stage liver cancer. Overall posttherapy survival and percent change in serologic tumor marker at 3 months posttherapy represent the primary clinical outcomes in this study. Thirty advanced-stage liver cancer cases (primary and metastatic) treated with RE over a 3-year period were included. Texture signatures for tumor regions, which were delineated to reveal boundaries with normal regions, were computed from pretreatment contrast-enhanced liver CT studies and evaluated for their ability to classify patient serologic response and survival. A series of systematic leave-one-out cross-validation studies using soft-margin support vector machine (SVM) classifiers showed hepatic tumor texton and local binary pattern (LBP) signatures both achieve high accuracy (96%) in discriminating subjects in terms of their serologic response. The image-based indicators were also accurate in classifying subjects by survival status (80% and 93% accuracy for texton and LBP signatures, respectively). Hepatic texture signatures generated from tumor regions on pretreatment triphasic CT studies were highly accurate in differentiating among subjects in terms of serologic response and survival. These image-based computational markers show promise as potential predictive tools in candidate evaluation for locoregional therapy such as RE.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21974,""
"The ""tele"" factor in surgery today and tomorrow: implications for surgical training and education","Gambadauro, TorrejÃƒÂ³n","https://doi.org/10.1007/s00595-012-0267-9","20130621","PubMed","Bibliometrics; General Surgery; Internet; Mentors; Periodicals as Topic; Referral and Consultation; Robotics; Telemedicine; Videoconferencing","New technological developments in the field of telecommunications have allowed a wide range of potentially novel surgical applications. The introduction of the World Wide Web in 1991 has been followed by a steep rise of the relevance of telemedicine, as it is witnessed in the latest scientific literature. There has been a consistent, positive trend in publications dealing, respectively, with telemedicine and the Internet. This article reviews telemedicine and other surgery-related innovations that benefit from telecommunication advances, and presents data from a quantitative bibliographic analysis. A number of applications, such as telementoring, teleproctoring and robotic telesurgery are described and their huge potentials are discussed. The integration between surgery and telecommunications could constitute one of the major achievements of modern medicine, and its safe integration into clinical practice should be a priority for modern surgeons.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21975,""
"Mining the pharmacogenomics literature--a survey of the state of the art","Hahn, Cohen, Garten, Shah","https://doi.org/10.1093/bib/bbs018","20121204","PubMed","Data Collection; Data Mining; Information Storage and Retrieval; Natural Language Processing; Pharmacogenetics; Publications; Semantics","This article surveys efforts on text mining of the pharmacogenomics literature, mainly from the period 2008 to 2011. Pharmacogenomics (or pharmacogenetics) is the field that studies how human genetic variation impacts drug response. Therefore, publications span the intersection of research in genotypes, phenotypes and pharmacology, a topic that has increasingly become a focus of active research in recent years. This survey covers efforts dealing with the automatic recognition of relevant named entities (e.g. genes, gene variants and proteins, diseases and other pathological phenomena, drugs and other chemicals relevant for medical treatment), as well as various forms of relations between them. A wide range of text genres is considered, such as scientific publications (abstracts, as well as full texts), patent texts and clinical narratives. We also discuss infrastructure and resources needed for advanced text analytics, e.g. document corpora annotated with corresponding semantic metadata (gold standards and training data), biomedical terminologies and ontologies providing domain-specific background knowledge at different levels of formality and specificity, software architectures for building complex and scalable text analytics pipelines and Web services grounded to them, as well as comprehensive ways to disseminate and interact with the typically huge amounts of semiformal knowledge structures extracted by text mining tools. Finally, we consider some of the novel applications that have already been developed in the field of pharmacogenomic text mining and point out perspectives for future research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21976,""
"Feature selection in computer-aided breast cancer diagnosis via dynamic contrast-enhanced magnetic resonance images","Rakoczy, McGaughey, Korenberg, Levman, Martel","https://doi.org/10.1007/s10278-012-9506-2","20130919","PubMed","Algorithms; Area Under Curve; Breast Neoplasms; Diagnosis, Computer-Assisted; Early Detection of Cancer; Female; Gadolinium DTPA; Humans; Magnetic Resonance Imaging; Pattern Recognition, Automated; Radiographic Image Enhancement; Reproducibility of Results; Sensitivity and Specificity","The accuracy of computer-aided diagnosis (CAD) for early detection and classification of breast cancer in dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) is dependent upon the features used by the CAD classifier. Here, we show that fast orthogonal search (FOS), which provides a more efficient iterative manner of computing stepwise regression feature selection, can select features with predictive value from a set of kinetic and texture candidate features computed from dynamic contrast-enhanced magnetic resonance images. FOS can in minutes search candidate feature sets of millions of terms, which may include cross-products of features up to second-, third- or fourth-order. This method is tested on a set of 83 DCE-MRI images, of which 20 are for cancerous and 63 for benign cases, using a leave-one-out trial. The features selected by FOS were used in a FOS predictor and nearest-neighbour predictor and had an area under the receiver operating curve (AUC) of 0.889 and 0.791 respectively. The FOS predictor AUC is significantly improved over the signal enhancement ratio predictor with an AUC of 0.706 (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.0035 for the difference in the AUCs). Moreover, using FOS-selected features in a support vector machine increased the AUC over that resulting when the features were manually selected.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21977,""
"Identifying primary and recurrent cancers using a SAS-based natural language processing algorithm","Strauss, Chao, Kwan, Ahmed, Schottinger, Quinn","https://doi.org/10.1136/amiajnl-2012-000928","20130812","PubMed","Algorithms; Biomedical Research; Breast Neoplasms; California; Data Mining; Electronic Health Records; Female; Humans; Information Dissemination; Male; Natural Language Processing; Neoplasms; Prostatic Neoplasms; Recurrence; Reproducibility of Results; Sensitivity and Specificity; Systematized Nomenclature of Medicine","Significant limitations exist in the timely and complete identification of primary and recurrent cancers for clinical and epidemiologic research. A SAS-based coding, extraction, and nomenclature tool (SCENT) was developed to address this problem. SCENT employs hierarchical classification rules to identify and extract information from electronic pathology reports. Reports are analyzed and coded using a dictionary of clinical concepts and associated SNOMED codes. To assess the accuracy of SCENT, validation was conducted using manual review of pathology reports from a random sample of 400 breast and 400 prostate cancer patients diagnosed at Kaiser Permanente Southern California. Trained abstractors classified the malignancy status of each report. Classifications of SCENT were highly concordant with those of abstractors, achieving ÃŽÂº of 0.96 and 0.95 in the breast and prostate cancer groups, respectively. SCENT identified 51 of 54 new primary and 60 of 61 recurrent cancer cases across both groups, with only three false positives in 792 true benign cases. Measures of sensitivity, specificity, positive predictive value, and negative predictive value exceeded 94% in both cancer groups. Favorable validation results suggest that SCENT can be used to identify, extract, and code information from pathology report text. Consequently, SCENT has wide applicability in research and clinical care. Further assessment will be needed to validate performance with other clinical text sources, particularly those with greater linguistic variability. SCENT is proof of concept for SAS-based natural language processing applications that can be easily shared between institutions and used to support clinical and epidemiologic research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21978,""
"Using rule-based machine learning for candidate disease gene prioritization and sample classification of cancer gene expression data","Glaab, Bacardit, Garibaldi, Krasnogor","https://doi.org/10.1371/journal.pone.0039932","20130326","PubMed","Algorithms; Artificial Intelligence; Breast Neoplasms; Databases, Genetic; Female; Gene Expression Profiling; Gene Expression Regulation, Neoplastic; Humans; Lymphoma; Male; Neoplasm Proteins; Oligonucleotide Array Sequence Analysis; Prostatic Neoplasms","Microarray data analysis has been shown to provide an effective tool for studying cancer and genetic diseases. Although classical machine learning techniques have successfully been applied to find informative genes and to predict class labels for new samples, common restrictions of microarray analysis such as small sample sizes, a large attribute space and high noise levels still limit its scientific and clinical applications. Increasing the interpretability of prediction models while retaining a high accuracy would help to exploit the information content in microarray data more effectively. For this purpose, we evaluate our rule-based evolutionary machine learning systems, BioHEL and GAssist, on three public microarray cancer datasets, obtaining simple rule-based models for sample classification. A comparison with other benchmark microarray sample classifiers based on three diverse feature selection algorithms suggests that these evolutionary learning techniques can compete with state-of-the-art methods like support vector machines. The obtained models reach accuracies above 90% in two-level external cross-validation, with the added value of facilitating interpretation by using only combinations of simple if-then-else rules. As a further benefit, a literature mining analysis reveals that prioritizations of informative genes extracted from BioHEL's classification rule sets can outperform gene rankings obtained from a conventional ensemble feature selection in terms of the pointwise mutual information between relevant disease terms and the standardized names of top-ranked genes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21979,""
"Prospective study of toric IOL outcomes based on the Lenstar LS 900Ã‚Â® dual zone automated keratometer","Gundersen, Potvin","https://doi.org/10.1186/1471-2415-12-21","20121016","PubMed","Aged; Aged, 80 and over; Astigmatism; Biometry; Cataract Extraction; Corneal Topography; Female; Humans; Lens Implantation, Intraocular; Lenses, Intraocular; Male; Middle Aged; Preoperative Period; Prospective Studies","To establish clinical expectations when using the Lenstar LS 900Ã‚Â® dual-zone automated keratometer for surgery planning of toric intraocular lenses. Fifty eyes were measured with the Lenstar LS 900Ã‚Â® dual-zone automated keratometer . Surgical planning was performed with the data from this device and the known surgically induced astigmatism of the surgeon. Post-operative refractions and visual acuity were measured at 1 month and 3 months. Clinical outcomes from 43 uncomplicated surgeries showed an average post-operative refractive astigmatism of 0.44D Ã‚Â±0.25D. Over 70% of eyes had 0.50D or less of refractive astigmatism and no eye had more than 1.0D of refractive astigmatism. Uncorrected visual acuity was 20/32 or better in all eyes at 3 months, with 70% of eyes 20/20 or better. A significantly higher number of eyes had 0.75D or more of post-operative refractive astigmatism when the standard deviation of the pre-operative calculated corneal astigmatism angle, reported by the keratometer, was &gt; 5 degrees. In this single-site study investigating the use of the keratometry from the Lenstar LS 900Ã‚Â® for toric IOL surgical planning, clinical outcomes appear equivalent to those reported in the literature for manual keratometry and somewhat better than has been reported for some previous automated instruments. A high standard deviation in the pre-operative calculated astigmatism angle, as reported by the keratometer, appears to increase the likelihood of higher post-operative refractive astigmatism.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21980,""
"Environmental exposure to xenoestrogens and oestrogen related cancers: reproductive system, breast, lung, kidney, pancreas, and brain","Fucic, Gamulin, Ferencic, Katic, Krayer von Krauss, Bartonova, Merlo","https://doi.org/10.1186/1476-069X-11-S1-S8","20121106","PubMed","Endocrine Disruptors; Environmental Exposure; Estrogens; Female; Humans; Male; Neoplasms; Receptors, Estrogen; Sex Factors","The role of steroids in carcinogenesis has become a major concern in environmental protection, biomonitoring, and clinical research. Although historically oestrogen has been related to development of reproductive system, research over the last decade has confirmed its crucial role in the development and homeostasis of other organ systems. As a number of anthropogenic agents are xenoestrogens, environmental health research has focused on oestrogen receptor level disturbances and of aromatase polymorphisms. Oestrogen and xenoestrogens mediate critical points in carcinogenesis by binding to oestrogen receptors, whose distribution is age-, gender-, and tissue-specific. This review brings data about cancer types whose eatiology may be found in environmental exposure to xenoestrogens. Cancer types that have been well documented in literature to be related with environmental exposure include the reproductive system, breast, lung, kidney, pancreas, and brain. The results of our data mining show (a) a significant correlation between exposure to xenoestrogens and increased, gender-related, cancer risk and (b) a need to re-evaluate agents so far defined as endocrine disruptors, as they are also key molecules in carcinogenesis. This revision may be used to further research of cancer aetiology and to improvement of related legislation. Investigation of cancers caused by xenoestrogens may elucidate yet unknown mechanisms also valuable for oncology and the development of new therapies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21981,""
"Biological event composition","Kilicoglu, Bergler","https://doi.org/10.1186/1471-2105-13-S11-S7","20130422","PubMed","Algorithms; Blood Cells; Data Mining; Gene Expression Regulation; Humans; MEDLINE; Natural Language Processing; Transcription Factors","In recent years, biological event extraction has emerged as a key natural language processing task, aiming to address the information overload problem in accessing the molecular biology literature. The BioNLP shared task competitions have contributed to this recent interest considerably. The first competition (BioNLP'09) focused on extracting biological events from Medline abstracts from a narrow domain, while the theme of the latest competition (BioNLP-ST'11) was generalization and a wider range of text types, event types, and subject domains were considered. We view event extraction as a building block in larger discourse interpretation and propose a two-phase, linguistically-grounded, rule-based methodology. In the first phase, a general, underspecified semantic interpretation is composed from syntactic dependency relations in a bottom-up manner. The notion of embedding underpins this phase and it is informed by a trigger dictionary and argument identification rules. Coreference resolution is also performed at this step, allowing extraction of inter-sentential relations. The second phase is concerned with constraining the resulting semantic interpretation by shared task specifications. We evaluated our general methodology on core biological event extraction and speculation/negation tasks in three main tracks of BioNLP-ST'11 (GENIA, EPI, and ID). We achieved competitive results in GENIA and ID tracks, while our results in the EPI track leave room for improvement. One notable feature of our system is that its performance across abstracts and articles bodies is stable. Coreference resolution results in minor improvement in system performance. Due to our interest in discourse-level elements, such as speculation/negation and coreference, we provide a more detailed analysis of our system performance in these subtasks. The results demonstrate the viability of a robust, linguistically-oriented methodology, which clearly distinguishes general semantic interpretation from shared task specific aspects, for biological event extraction. Our error analysis pinpoints some shortcomings, which we plan to address in future work within our incremental system development methodology.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21982,""
"Using domain knowledge and domain-inspired discourse model for coreference resolution for clinical narratives","Jindal, Roth","https://doi.org/10.1136/amiajnl-2011-000767","20130812","PubMed","Data Mining; Electronic Health Records; Humans; Illinois; Narration; Natural Language Processing; Pattern Recognition, Automated; Semantics","This paper presents a coreference resolution system for clinical narratives. Coreference resolution aims at clustering all mentions in a single document to coherent entities. A knowledge-intensive approach for coreference resolution is employed. The domain knowledge used includes several domain-specific lists, a knowledge intensive mention parsing, and task informed discourse model. Mention parsing allows us to abstract over the surface form of the mention and represent each mention using a higher-level representation, which we call the mention's semantic representation (SR). SR reduces the mention to a standard form and hence provides better support for comparing and matching. Existing coreference resolution systems tend to ignore discourse aspects and rely heavily on lexical and structural cues in the text. The authors break from this tradition and present a discourse model for ""person"" type mentions in clinical narratives, which greatly simplifies the coreference resolution. This system was evaluated on four different datasets which were made available in the 2011 i2b2/VA coreference challenge. The unweighted average of F1 scores (over B-cubed, MUC and CEAF) varied from 84.2% to 88.1%. These experiments show that domain knowledge is effective for different mention types for all the datasets. Error analysis shows that most of the recall errors made by the system can be handled by further addition of domain knowledge. The precision errors, on the other hand, are more subtle and indicate the need to understand the relations in which mentions participate for building a robust coreference system. This paper presents an approach that makes an extensive use of domain knowledge to significantly improve coreference resolution. The authors state that their system and the knowledge sources developed will be made publicly available.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21983,""
"Dependency Parser-based Negation Detection in Clinical Narratives","Sohn, Wu, Chute","https://www.google.com/search?q=Dependency+Parser-based+Negation+Detection+in+Clinical+Narratives.","20120824","PubMed","","Negation of clinical named entities is common in clinical documents and is a crucial factor to accurately compile patients' clinical conditions and to further support complex phenotype detection. In 2009, Mayo Clinic released the clinical Text Analysis and Knowledge Extraction System (cTAKES), which includes a negation annotator that identifies negation status of a named entity by searching for negation words within a fixed word distance. However, this negation strategy is not sophisticated enough to correctly identify complicated patterns of negation. This paper aims to investigate whether the dependency structure from the cTAKES dependency parser can improve the negation detection performance. Manually compiled negation rules, derived from dependency paths were tested. Dependency negation rules do not limit the negation scope to word distance; instead, they are based on syntactic context. We found that using a dependency-based negation proved a superior alternative to the current cTAKES negation annotator.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21984,""
"Regression trees for predicting mortality in patients with cardiovascular disease: what improvement is achieved by using ensemble-based methods?","Austin, Lee, Steyerberg, Tu","https://doi.org/10.1002/bimj.201100251","20130404","PubMed","Aged; Biometry; Cardiovascular Diseases; Decision Trees; Female; Heart Failure; Hospitalization; Humans; Logistic Models; Male; Middle Aged; Myocardial Infarction; Risk","In biomedical research, the logistic regression model is the most commonly used method for predicting the probability of a binary outcome. While many clinical researchers have expressed an enthusiasm for regression trees, this method may have limited accuracy for predicting health outcomes. We aimed to evaluate the improvement that is achieved by using ensemble-based methods, including bootstrap aggregation (bagging) of regression trees, random forests, and boosted regression trees. We analyzed 30-day mortality in two large cohorts of patients hospitalized with either acute myocardial infarction (N = 16,230) or congestive heart failure (N = 15,848) in two distinct eras (1999-2001 and 2004-2005). We found that both the in-sample and out-of-sample prediction of ensemble methods offered substantial improvement in predicting cardiovascular mortality compared to conventional regression trees. However, conventional logistic regression models that incorporated restricted cubic smoothing splines had even better performance. We conclude that ensemble methods from the data mining and machine learning literature increase the predictive performance of regression trees, but may not lead to clear advantages over conventional logistic regression models for predicting short-term mortality in population-based samples of subjects with cardiovascular disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21985,""
"Hiding in plain sight: use of realistic surrogates to reduce exposure of protected health information in clinical text","Carrell, Malin, Aberdeen, Bayer, Clark, Wellner, Hirschman","https://doi.org/10.1136/amiajnl-2012-001034","20130812","PubMed","Biomedical Research; Computer Security; Confidentiality; Data Collection; Electronic Health Records; Humans; Information Dissemination; Natural Language Processing; Pilot Projects; United States","Secondary use of clinical text is impeded by a lack of highly effective, low-cost de-identification methods. Both, manual and automated methods for removing protected health information, are known to leave behind residual identifiers. The authors propose a novel approach for addressing the residual identifier problem based on the theory of Hiding In Plain Sight (HIPS). HIPS relies on obfuscation to conceal residual identifiers. According to this theory, replacing the detected identifiers with realistic but synthetic surrogates should collectively render the few 'leaked' identifiers difficult to distinguish from the synthetic surrogates. The authors conducted a pilot study to test this theory on clinical narrative, de-identified by an automated system. Test corpora included 31 oncology and 50 family practice progress notes read by two trained chart abstractors and an informaticist. Experimental results suggest approximately 90% of residual identifiers can be effectively concealed by the HIPS approach in text containing average and high densities of personal identifying information. This pilot test suggests HIPS is feasible, but requires further evaluation. The results need to be replicated on larger corpora of diverse origin under a range of detection scenarios. Error analyses also suggest areas where surrogate generation techniques can be refined to improve efficacy. If these results generalize to existing high-performing de-identification systems with recall rates of 94-98%, HIPS could increase the effective de-identification rates of these systems to levels above 99% without further advancements in system recall. Additional and more rigorous assessment of the HIPS approach is warranted.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21986,""
"Best practices in robot-assisted radical prostatectomy: recommendations of the Pasadena Consensus Panel","Montorsi, Wilson, Rosen, Ahlering, Artibani, Carroll, Costello, Eastham, Ficarra, Guazzoni, Menon, Novara, Patel, Stolzenburg, Van der Poel, Van Poppel, Mottrie","https://doi.org/10.1016/j.eururo.2012.05.057","20130107","PubMed","Benchmarking; Consensus; Delphi Technique; Evidence-Based Medicine; Humans; Laparoscopy; Male; Postoperative Complications; Prostatectomy; Prostatic Neoplasms; Risk Assessment; Risk Factors; Robotics; Surgery, Computer-Assisted; Treatment Outcome","Radical retropubic prostatectomy (RRP) has long been the most common surgical technique used to treat clinically localized prostate cancer (PCa). More recently, robot-assisted radical prostatectomy (RARP) has been gaining increasing acceptance among patients and urologists, and it has become the dominant technique in the United States despite a paucity of prospective studies or randomized trials supporting its superiority over RRP. A 2-d consensus conference of 17 world leaders in prostate cancer and radical prostatectomy was organized in Pasadena, California, and at the City of Hope Cancer Center, Duarte, California, under the auspices of the European Association of Urology Robotic Urology Section to systematically review the currently available data on RARP, to critically assess current surgical techniques, and to generate best practice recommendations to guide clinicians and related medical personnel. No commercial support was obtained for the conference. A systematic review of the literature was performed in agreement with the Preferred Reporting Items for Systematic Reviews and Meta-analysis statement. The results of the systematic literature review were reviewed, discussed, and refined over the 2-d conference. Key recommendations were generated using a Delphi consensus approach. RARP is associated with less blood loss and transfusion rates compared with RRP, and there appear to be minimal differences between the two approaches in terms of overall postoperative complications. Positive surgical margin rates are at least equivalent with RARP, but firm conclusions about biochemical recurrence and other oncologic end points are difficult to draw because the follow-up in existing studies is relatively short and the overall experience with RARP in locally advanced PCa is still limited. RARP may offer advantages in postoperative recovery of urinary continence and erectile function, although there are methodological limitations in most studies to date and a need for well-controlled comparative outcomes studies of radical prostatectomy surgery following best practice guidelines. Surgeon experience and institutional volume of procedures strongly predict better outcomes in all relevant domains. Available evidence suggests that RARP is a valuable therapeutic option for clinically localized PCa. Further research is needed to clarify the actual role of RARP in patients with locally advanced disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21987,""
"Active-learning implementation in an advanced elective course on infectious diseases","Hidayat, Patel, Veltri","https://doi.org/10.5688/ajpe76587","20121119","PubMed","active learning; curriculum; elective course; infectious disease; pharmacy education; Anti-Infective Agents; Communicable Diseases; Curriculum; Drug Resistance, Microbial; Education, Pharmacy; Educational Measurement; Health Knowledge, Attitudes, Practice; Humans; Problem-Based Learning; Students, Pharmacy; Teaching","To describe the development, implementation, and assessment of an advanced elective course on infectious diseases using active-learning strategies. Pedagogy for active learning was incorporated by means of mini-lecture, journal club, and debate with follow-up discussion. Forty-eight students were enrolled in this 4-week elective course, in which 30% of course time was allocated for active-learning exercises. All activities were fundamentally designed as a stepwise approach in complementing each active-learning exercise. Achievement of the course learning objectives was assessed using a 5-point Likert scale survey instrument. Students' awareness of the significance of antimicrobial resistance was improved (p Ã¢â€°Â¤ 0.05). Students' ability to critically evaluate the infectious-disease literature and its application in informed clinical judgments was also enhanced through these active-learning exercises (p Ã¢â€°Â¤ 0.05). Students agreed that active learning should be part of the pharmacy curriculum and that active-learning exercises improved their critical-thinking, literature-evaluation, and self-learning skills. An elective course using active-learning strategies allowed students to combine information gained from the evaluation of infectious-disease literature, critical thinking, and informed clinical judgment. This blended approach ultimately resulted in an increased knowledge and awareness of infectious diseases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21988,""
"Systematic review and meta-analysis of studies reporting oncologic outcome after robot-assisted radical prostatectomy","Novara, Ficarra, Mocellin, Ahlering, Carroll, Graefen, Guazzoni, Menon, Patel, Shariat, Tewari, Van Poppel, Zattoni, Montorsi, Mottrie, Rosen, Wilson","https://doi.org/10.1016/j.eururo.2012.05.047","20130107","PubMed","Chemotherapy, Adjuvant; Chi-Square Distribution; Disease-Free Survival; Evidence-Based Medicine; Humans; Laparoscopy; Lymph Node Excision; Male; Multivariate Analysis; Odds Ratio; Proportional Hazards Models; Prostate-Specific Antigen; Prostatectomy; Prostatic Neoplasms; Radiotherapy, Adjuvant; Risk Assessment; Risk Factors; Robotics; Surgery, Computer-Assisted; Survival Analysis; Time Factors; Treatment Outcome","Despite the large diffusion of robot-assisted radical prostatectomy (RARP), literature and data on the oncologic outcome of RARP are limited. Evaluate lymph node yield, positive surgical margins (PSMs), use of adjuvant therapy, and biochemical recurrence (BCR)-free survival following RARP and perform a cumulative analysis of all studies comparing the oncologic outcomes of RARP and retropubic radical prostatectomy (RRP) or laparoscopic radical prostatectomy (LRP). A systematic review of the literature was performed in August 2011, searching Medline, Embase, and Web of Science databases. A free-text protocol using the term radical prostatectomy was applied. The following limits were used: humans; gender (male); and publications dating from January 1, 2008. A cumulative analysis was conducted using Review Manager software v.4.2 (Cochrane Collaboration, Oxford, UK) and Stata 11.0 SE software (StataCorp, College Station, TX, USA). We retrieved 79 papers evaluating oncologic outcomes following RARP. The mean PSM rate was 15% in all comers and 9% in pathologically localized cancers, with some tumor characteristics being the most relevant predictors of PSMs. Several surgeon-related characteristics or procedure-related issues may play a major role in PSM rates. With regard to BCR, the very few papers with a follow-up duration &gt;5 yr demonstrated 7-yr BCR-free survival estimates of approximately 80%. Finally, all the cumulative analyses comparing RARP with RRP and comparing RARP with LRP demonstrated similar overall PSM rates (RARP vs RRP: odds ratio [OR]: 1.21; p=0.19; RARP vs LRP: OR: 1.12; p=0.47), pT2 PSM rates (RARP vs RRP: OR: 1.25; p=0.31; RARP vs LRP: OR: 0.99; p=0.97), and BCR-free survival estimates (RARP vs RRP: hazard ratio [HR]: 0.9; p=0.526; RARP vs LRP: HR: 0.5; p=0.141), regardless of the surgical approach. PSM rates are similar following RARP, RRP, and LRP. The few data available on BCR from high-volume centers are promising, but definitive comparisons with RRP or LRP are not currently possible. Finally, significant data on cancer-specific mortality are not currently available.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21989,""
"Systematic review and meta-analysis of studies reporting potency rates after robot-assisted radical prostatectomy","Ficarra, Novara, Ahlering, Costello, Eastham, Graefen, Guazzoni, Menon, Mottrie, Patel, Van der Poel, Rosen, Tewari, Wilson, Zattoni, Montorsi","https://doi.org/10.1016/j.eururo.2012.05.046","20130107","PubMed","Erectile Dysfunction; Evidence-Based Medicine; Humans; Laparoscopy; Male; Odds Ratio; Penile Erection; Prostatectomy; Prostatic Neoplasms; Recovery of Function; Risk Assessment; Risk Factors; Robotics; Surgery, Computer-Assisted; Time Factors; Treatment Outcome","Although the initial robot-assisted radical prostatectomy (RARP) series showed 12-mo potency rates ranging from 70% to 80%, the few available comparative studies did not permit any definitive conclusion about the superiority of this technique when compared with retropubic radical prostatectomy (RRP) and laparoscopic radical prostatectomy (LRP). The aims of this systematic review were (1) to evaluate the current prevalence and the potential risk factors of erectile dysfunction after RARP, (2) to identify surgical techniques able to improve the rate of potency recovery after RARP, and (3) to perform a cumulative analysis of all available studies comparing RARP versus RRP or LRP. A literature search was performed in August 2011 using the Medline, Embase, and Web of Science databases. Only comparative studies or clinical series including &gt;100 cases reporting potency recovery outcomes were included in this review. Cumulative analysis was conducted using Review Manager v.4.2 software designed for composing Cochrane Reviews (Cochrane Collaboration, Oxford, UK). We analyzed 15 case series, 6 studies comparing different techniques in the context of RARP, 6 studies comparing RARP with RRP, and 4 studies comparing RARP with LRP. The 12- and 24-mo potency rates ranged from 54% to 90% and from 63% to 94%, respectively. Age, baseline potency status, comorbidities index, and extension of the nerve-sparing procedure represent the most relevant preoperative and intraoperative predictors of potency recovery after RARP. Available data seem to support the use of cautery-free dissection or the use of pinpointed low-energy cauterization. Cumulative analyses showed better 12-mo potency rates after RARP in comparison with RRP (odds ratio [OR]: 2.84; 95% confidence interval [CI]: 1.46-5.43; p=0.002). Only a nonstatistically significant trend in favor of RARP was reported after comparison with LRP (OR: 1.89; p=0.21). The incidence of potency recovery after RARP is influenced by numerous factors. Data coming from the present systematic review support the use of a cautery-free technique. This update of previous systematic reviews of the literature showed, for the first time, a significant advantage in favor of RARP in comparison with RRP in terms of 12-mo potency rates.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21990,""
"Pharmacoeconomic analysis of paliperidone palmitate for treating schizophrenia in Greece","Einarson, Geitona, Chaidemenos, Karpouza, Mougiakos, Paterakis, Ploumpidis, Potamitis-Komis, Zilbershtein, Vicente, Piwko, Kakkavas, Paparouni, Jensen, Hemels","https://doi.org/10.1186/1744-859X-11-18","20121002","PubMed","","Patients having chronic schizophrenia with frequent relapses and hospitalizations represent a great challenge, both clinically and financially. Risperidone long-acting injection (RIS-LAI) has been the main LAI atypical antipsychotic treatment in Greece. Paliperidone palmitate (PP-LAI) has recently been approved. It is dosed monthly, as opposed to biweekly for RIS-LAI, but such advantages have not yet been analysed in terms of economic evaluation. To compare costs and outcomes of PP-LAI versus RIS-LAI in Greece. A cost-utility analysis was performed using a previously validated decision tree to model clinical pathways and costs over 1Ã¢â‚¬â€°year for stable patients started on either medication. Rates were taken from the literature. A local expert panel provided feedback on treatment patterns. All direct costs incurred by the national healthcare system were obtained from the literature and standard price lists; all were inflated to 2011 costs. Patient outcomes analyzed included average days with stable disease, numbers of hospitalizations, emergency room visits, and quality-adjusted life-years (QALYs). The total annual healthcare cost with PP-LAI was Ã¢â€šÂ¬3529; patients experienced 325Ã¢â‚¬â€°days in remission and 0.840 QALY; 28% were hospitalized and 15% received emergency room treatment. With RIS-LAI, the cost was Ã¢â€šÂ¬3695, patients experienced 318.6Ã¢â‚¬â€°days in remission and 0.815 QALY; 33% were hospitalized and 17% received emergency room treatment. Thus, PP-LAI dominated RIS-LAI. Results were generally robust in sensitivity analyses with PP-LAI dominating in 74.6% of simulations. Results were sensitive to the price of PP-LAI. PP-LAI appears to be a cost-effective option for treating chronic schizophrenia in Greece compared with RIS-LAI since it results in savings to the health care system along with better patient outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21991,""
"A new clustering method for detecting rare senses of abbreviations in clinical notes","Xu, Wu, Elhadad, Stetson, Friedman","https://doi.org/10.1016/j.jbi.2012.06.003","20130329","PubMed","Abbreviations as Topic; Algorithms; Cluster Analysis; Medical Records; Natural Language Processing; Unified Medical Language System","Abbreviations are widely used in clinical documents and they are often ambiguous. Building a list of possible senses (also called sense inventory) for each ambiguous abbreviation is the first step to automatically identify correct meanings of abbreviations in given contexts. Clustering based methods have been used to detect senses of abbreviations from a clinical corpus [1]. However, rare senses remain challenging and existing algorithms are not good enough to detect them. In this study, we developed a new two-phase clustering algorithm called Tight Clustering for Rare Senses (TCRS) and applied it to sense generation of abbreviations in clinical text. Using manually annotated sense inventories from a set of 13 ambiguous clinical abbreviations, we evaluated and compared TCRS with the existing Expectation Maximization (EM) clustering algorithm for sense generation, at two different levels of annotation cost (10 vs. 20 instances for each abbreviation). Our results showed that the TCRS-based method could detect 85% senses on average; while the EM-based method found only 75% senses, when similar annotation effort (about 20 instances) was used. Further analysis demonstrated that the improvement by the TCRS method was mainly from additionally detected rare senses, thus indicating its usefulness for building more complete sense inventories of clinical abbreviations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21992,""
"Huntington's disease and its therapeutic target genes: a global functional profile based on the HD Research Crossroads database","Kalathur, HernÃƒÂ¡ndez-Prieto, Futschik","https://doi.org/10.1186/1471-2377-12-47","20130517","PubMed","Chromosome Mapping; Databases, Protein; Gene Targeting; Genetic Predisposition to Disease; Humans; Huntington Disease; Internationality; Polymorphism, Single Nucleotide; Proteome","Huntington's disease (HD) is a fatal progressive neurodegenerative disorder caused by the expansion of the polyglutamine repeat region in the huntingtin gene. Although the disease is triggered by the mutation of a single gene, intensive research has linked numerous other genes to its pathogenesis. To obtain a systematic overview of these genes, which may serve as therapeutic targets, CHDI Foundation has recently established the HD Research Crossroads database. With currently over 800 cataloged genes, this web-based resource constitutes the most extensive curation of genes relevant to HD. It provides us with an unprecedented opportunity to survey molecular mechanisms involved in HD in a holistic manner. To gain a synoptic view of therapeutic targets for HD, we have carried out a variety of bioinformatical and statistical analyses to scrutinize the functional association of genes curated in the HD Research Crossroads database. In particular, enrichment analyses were performed with respect to Gene Ontology categories, KEGG signaling pathways, and Pfam protein families. For selected processes, we also analyzed differential expression, using published microarray data. Additionally, we generated a candidate set of novel genetic modifiers of HD by combining information from the HD Research Crossroads database with previous genome-wide linkage studies. Our analyses led to a comprehensive identification of molecular mechanisms associated with HD. Remarkably, we not only recovered processes and pathways, which have frequently been linked to HD (such as cytotoxicity, apoptosis, and calcium signaling), but also found strong indications for other potentially disease-relevant mechanisms that have been less intensively studied in the context of HD (such as the cell cycle and RNA splicing, as well as Wnt and ErbB signaling). For follow-up studies, we provide a regularly updated compendium of molecular mechanism, that are associated with HD, at http://hdtt.sysbiolab.eu Additionally, we derived a candidate set of 24 novel genetic modifiers, including histone deacetylase 3 (HDAC3), metabotropic glutamate receptor 1 (GRM1), CDK5 regulatory subunit 2 (CDK5R2), and coactivator 1ÃƒÅ¸ of the peroxisome proliferator-activated receptor gamma (PPARGC1B). The results of our study give us an intriguing picture of the molecular complexity of HD. Our analyses can be seen as a first step towards a comprehensive list of biological processes, molecular functions, and pathways involved in HD, and may provide a basis for the development of more holistic disease models and new therapeutics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21993,""
"Multi-Sectional Views Textural Based SVM for MS Lesion Segmentation in Multi-Channels MRIs","Abdullah, Younis, John","https://doi.org/10.2174/1874230001206010056","20120823","PubMed","Brain Segmentation; MRI; Multi-Channels.; Multiple Sclerosis; ROI; SVM; Sectional View; Texture Analysis","In this paper, a new technique is proposed for automatic segmentation of multiple sclerosis (MS) lesions from brain magnetic resonance imaging (MRI) data. The technique uses a trained support vector machine (SVM) to discriminate between the blocks in regions of MS lesions and the blocks in non-MS lesion regions mainly based on the textural features with aid of the other features. The classification is done on each of the axial, sagittal and coronal sectional brain view independently and the resultant segmentations are aggregated to provide more accurate output segmentation. The main contribution of the proposed technique described in this paper is the use of textural features to detect MS lesions in a fully automated approach that does not rely on manually delineating the MS lesions. In addition, the technique introduces the concept of the multi-sectional view segmentation to produce verified segmentation. The proposed textural-based SVM technique was evaluated using three simulated datasets and more than fifty real MRI datasets. The results were compared with state of the art methods. The obtained results indicate that the proposed method would be viable for use in clinical practice for the detection of MS lesions in MRI.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21994,""
"Semiparametric Bayesian local functional models for diffusion tensor tract statistics","Hua, Dunson, Gilmore, Styner, Zhu","https://doi.org/10.1016/j.neuroimage.2012.06.027","20130129","PubMed","Algorithms; Artificial Intelligence; Bayes Theorem; Brain; Data Interpretation, Statistical; Diffusion Tensor Imaging; Female; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Infant; Infant, Newborn; Male; Nerve Fibers, Myelinated; Pattern Recognition, Automated","We propose a semiparametric Bayesian local functional model (BFM) for the analysis of multiple diffusion properties (e.g., fractional anisotropy) along white matter fiber bundles with a set of covariates of interest, such as age and gender. BFM accounts for heterogeneity in the shape of the fiber bundle diffusion properties among subjects, while allowing the impact of the covariates to vary across subjects. A nonparametric Bayesian LPP2 prior facilitates global and local borrowings of information among subjects, while an infinite factor model flexibly represents low-dimensional structure. Local hypothesis testing and credible bands are developed to identify fiber segments, along which multiple diffusion properties are significantly associated with covariates of interest, while controlling for multiple comparisons. Moreover, BFM naturally group subjects into more homogeneous clusters. Posterior computation proceeds via an efficient Markov chain Monte Carlo algorithm. A simulation study is performed to evaluate the finite sample performance of BFM. We apply BFM to investigate the development of white matter diffusivities along the splenium of the corpus callosum tract and the right internal capsule tract in a clinical study of neurodevelopment in new born infants.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21995,""
"Traditional chinese medicine zheng in the era of evidence-based medicine: a literature analysis","Jiang, Zhang, Zheng, Guo, Li, Yang, Lu, Jia, Lu","https://doi.org/10.1155/2012/409568","20120823","PubMed","","Zheng, which is also called a syndrome or pattern, is the basic unit and a key concept of traditional Chinese medicine (TCM) theory. Zheng can be considered a further stratification of patients when it is integrated with biomedical diagnoses in clinical practice to achieve higher efficacies. In an era of evidence-based medicine, confronted with the vast and increasing volume of TCM data, there is an urgent need to explore these resources effectively using techniques of knowledge discovery in databases. The application of effective data mining in the analysis of multiple extensively integrated databases can supply new information about TCM Zheng research. In this paper, we screened the published literature on TCM Zheng-related studies in the SinoMed and PubMed databases with a novel data mining approach to obtain an overview of the Zheng research landscape in the hope of contributing to a better understanding of TCM Zheng in the era of evidence-based medicine. In our results, contrast was found in Zheng in different studies, and several determinants of Zheng were identified. The data described in this paper can be used to assess Zheng research studies based on the title and certain characteristics of the abstract. These findings will benefit modern TCM Zheng-related studies and guide future Zheng study efforts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21996,""
"Exploring Biomolecular Literature with EVEX: Connecting Genes through Events, Homology, and Indirect Associations","Van Landeghem, Hakala, RÃƒÂ¶nnqvist, Salakoski, Van de Peer, Ginter","https://doi.org/10.1155/2012/582765","20120823","PubMed","","Technological advancements in the field of genetics have led not only to an abundance of experimental data, but also caused an exponential increase of the number of published biomolecular studies. Text mining is widely accepted as a promising technique to help researchers in the life sciences deal with the amount of available literature. This paper presents a freely available web application built on top of 21.3 million detailed biomolecular events extracted from all PubMed abstracts. These text mining results were generated by a state-of-the-art event extraction system and enriched with gene family associations and abstract generalizations, accounting for lexical variants and synonymy. The EVEX resource locates relevant literature on phosphorylation, regulation targets, binding partners, and several other biomolecular events and assigns confidence values to these events. The search function accepts official gene/protein symbols as well as common names from all species. Finally, the web application is a powerful tool for generating homology-based hypotheses as well as novel, indirect associations between genes and proteins such as coregulators.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21997,""
"BioContext: an integrated text mining system for large-scale extraction and contextualization of biomolecular events","Gerner, Sarafraz, Bergman, Nenadic","https://doi.org/10.1093/bioinformatics/bts332","20130422","PubMed","Biochemical Phenomena; Computational Biology; Data Mining; MEDLINE; PubMed; Software","Although the amount of data in biology is rapidly increasing, critical information for understanding biological events like phosphorylation or gene expression remains locked in the biomedical literature. Most current text mining (TM) approaches to extract information about biological events are focused on either limited-scale studies and/or abstracts, with data extracted lacking context and rarely available to support further research. Here we present BioContext, an integrated TM system which extracts, extends and integrates results from a number of tools performing entity recognition, biomolecular event extraction and contextualization. Application of our system to 10.9 million MEDLINE abstracts and 234 000 open-access full-text articles from PubMed Central yielded over 36 million mentions representing 11.4 million distinct events. Event participants included over 290 000 distinct genes/proteins that are mentioned more than 80 million times and linked where possible to Entrez Gene identifiers. Over a third of events contain contextual information such as the anatomical location of the event occurrence or whether the event is reported as negated or speculative. The BioContext pipeline is available for download (under the BSD license) at http://www.biocontext.org, along with the extracted data which is also available for online browsing.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21998,""
"Active learning for clinical text classification: is it better than random sampling?","Figueroa, Zeng-Treitler, Ngo, Goryachev, Wiechmann","https://doi.org/10.1136/amiajnl-2011-000648","20130116","PubMed","Algorithms; Artificial Intelligence; Data Mining; Humans; Natural Language Processing; ROC Curve","This study explores active learning algorithms as a way to reduce the requirements for large training sets in medical text classification tasks. Three existing active learning algorithms (distance-based (DIST), diversity-based (DIV), and a combination of both (CMB)) were used to classify text from five datasets. The performance of these algorithms was compared to that of passive learning on the five datasets. We then conducted a novel investigation of the interaction between dataset characteristics and the performance results. Classification accuracy and area under receiver operating characteristics (ROC) curves for each algorithm at different sample sizes were generated. The performance of active learning algorithms was compared with that of passive learning using a weighted mean of paired differences. To determine why the performance varies on different datasets, we measured the diversity and uncertainty of each dataset using relative entropy and correlated the results with the performance differences. The DIST and CMB algorithms performed better than passive learning. With a statistical significance level set at 0.05, DIST outperformed passive learning in all five datasets, while CMB was found to be better than passive learning in four datasets. We found strong correlations between the dataset diversity and the DIV performance, as well as the dataset uncertainty and the performance of the DIST algorithm. For medical text classification, appropriate active learning algorithms can yield performance comparable to that of passive learning with considerably smaller training sets. In particular, our results suggest that DIV performs better on data with higher diversity and DIST on data with lower uncertainty.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",21999,""
"Effects of a Tier 2 Supplemental Reading Intervention for At-Risk Fourth Grade Students","Ritchey, Silverman, Montanaro, Speece, Schatschneider","https://doi.org/10.1177/001440291207800304","20211021","PubMed","","This study investigated a Tier 2 intervention in the context of a Response to Intervention (RTI) model for 123 fourth grade students who were identified as having a high probability of reading failure. A randomized control trial was used to evaluate the effects of a 24 session multi-component supplemental intervention targeting fluency and expository comprehension of science texts. Intervention students performed significantly higher on comprehension strategy knowledge and use and science knowledge, but not on word reading, fluency, or other measures of reading comprehension. Moderators of intervention effects were also examined; children at higher risk in the intervention condition appeared to benefit more in comparison to lower probability children in intervention and compared to higher probability children in the control condition.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22000,""
"A mutation-centric approach to identifying pharmacogenomic relations in text","Rance, Doughty, Demner-Fushman, Kann, Bodenreider","https://doi.org/10.1016/j.jbi.2012.05.003","20130321","PubMed","Data Mining; Databases, Genetic; Humans; Knowledge Bases; MEDLINE; Mutation; Pharmacogenetics","To explore the notion of mutation-centric pharmacogenomic relation extraction and to evaluate our approach against reference pharmacogenomic relations. From a corpus of MEDLINE abstracts relevant to genetic variation, we identify co-occurrences between drug mentions extracted using MetaMap and RxNorm, and genetic variants extracted by EMU. The recall of our approach is evaluated against reference relations curated manually in PharmGKB. We also reviewed a random sample of 180 relations in order to evaluate its precision. One crucial aspect of our strategy is the use of biological knowledge for identifying specific genetic variants in text, not simply gene mentions. On the 104 reference abstracts from PharmGKB, the recall of our mutation-centric approach is 33-46%. Applied to 282,000 abstracts from MEDLINE, our approach identifies pharmacogenomic relations in 4534 abstracts, with a precision of 65%. Compared to a relation-centric approach, our mutation-centric approach shows similar recall, but slightly lower precision. We show that both approaches have limited overlap in their results, but are complementary and can be used in combination. Rather than a solution for the automatic curation of pharmacogenomic knowledge, we see these high-throughput approaches as tools to assist biocurators in the identification of pharmacogenomic relations of interest from the published literature. This investigation also identified three challenging aspects of the extraction of pharmacogenomic relations, namely processing full-text articles, sequence validation of DNA variants and resolution of genetic variants to reference databases, such as dbSNP.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22001,""
"Common brain activations for painful and non-painful aversive stimuli","Hayes, Northoff","https://doi.org/10.1186/1471-2202-13-60","20121214","PubMed","Animals; Brain; Brain Mapping; Databases, Bibliographic; Humans; Neural Pathways; Pain; Physical Stimulation","Identification of potentially harmful stimuli is necessary for the well-being and self-preservation of all organisms. However, the neural substrates involved in the processing of aversive stimuli are not well understood. For instance, painful and non-painful aversive stimuli are largely thought to activate different neural networks. However, it is presently unclear whether there is a common aversion-related network of brain regions responsible for the basic processing of aversive stimuli. To help clarify this issue, this report used a cross-species translational approach in humans (i.e. meta-analysis) and rodents (i.e. systematic review of functional neuroanatomy). Animal and human data combined to show a core aversion-related network, consisting of similar cortical (i.e. MCC, PCC, AI, DMPFC, RTG, SMA, VLOFC; see results section or abbreviation section for full names) and subcortical (i.e. Amyg, BNST, DS, Hab, Hipp/Parahipp, Hyp, NAc, NTS, PAG, PBN, raphe, septal nuclei, Thal, LC, midbrain) regions. In addition, a number of regions appeared to be more involved in pain-related (e.g. sensory cortex) or non-pain-related (e.g. amygdala) aversive processing. This investigation suggests that aversive processing, at the most basic level, relies on similar neural substrates, and that differential responses may be due, in part, to the recruitment of additional structures as well as the spatio-temporal dynamic activity of the network. This network perspective may provide a clearer understanding of why components of this circuit appear dysfunctional in some psychiatric and pain-related disorders.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22002,""
"Current status of validation for robotic surgery simulators - a systematic review","Abboudi, Khan, Aboumarzouk, Guru, Challacombe, Dasgupta, Ahmed","https://doi.org/10.1111/j.1464-410X.2012.11270.x","20130320","PubMed","Clinical Competence; Computer Simulation; Cost-Benefit Analysis; Education, Medical, Graduate; Feasibility Studies; General Surgery; Humans; Laparoscopy; Robotics; Teaching; User-Computer Interface; Validation Studies as Topic","To analyse studies validating the effectiveness of robotic surgery simulators. The MEDLINE(Ã‚Â®), EMBASE(Ã‚Â®) and PsycINFO(Ã‚Â®) databases were systematically searched until September 2011. References from retrieved articles were reviewed to broaden the search. The simulator name, training tasks, participant level, training duration and evaluation scoring were extracted from each study. We also extracted data on feasibility, validity, cost-effectiveness, reliability and educational impact. We identified 19 studies investigating simulation options in robotic surgery. There are five different robotic surgery simulation platforms available on the market. In all, 11 studies sought opinion and compared performance between two different groups; 'expert' and 'novice'. Experts ranged in experience from 21-2200 robotic cases. The novice groups consisted of participants with no prior experience on a robotic platform and were often medical students or junior doctors. The Mimic dV-Trainer(Ã‚Â®), ProMIS(Ã‚Â®), SimSurgery Educational Platform(Ã‚Â®) (SEP) and Intuitive systems have shown face, content and construct validity. The Robotic Surgical SimulatorTM system has only been face and content validated. All of the simulators except SEP have shown educational impact. Feasibility and cost-effectiveness of simulation systems was not evaluated in any trial. Virtual reality simulators were shown to be effective training tools for junior trainees. Simulation training holds the greatest potential to be used as an adjunct to traditional training methods to equip the next generation of robotic surgeons with the skills required to operate safely. However, current simulation models have only been validated in small studies. There is no evidence to suggest one type of simulator provides more effective training than any other. More research is needed to validate simulated environments further and investigate the effectiveness of animal and cadaveric training in robotic surgery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22003,""
"Electronic reminders for cancer prevention: factors associated with preference for automated voice reminders or text messages","Greaney, Puleo, Sprunck-Harrild, Bennett, Cunningham, Gillman, Coeling, Emmons","https://doi.org/10.1016/j.ypmed.2012.05.014","20121113","PubMed","Adolescent; Adult; Attitude to Computers; Body Mass Index; Boston; Cluster Analysis; Female; Health Behavior; Health Status; Humans; Male; Middle Aged; Neoplasms; Patient Preference; Preventive Health Services; Reminder Systems; Risk Factors; Socioeconomic Factors; Speech Recognition Software; Surveys and Questionnaires; Text Messaging; User-Computer Interface","Prompting may promote engagement with behavior change interventions. Prompts can be delivered inexpensively via automated voice response (AVR) reminders or short message service (SMS) text messages. We examined the association between participants' characteristics and preferred reminder modality. Healthy Directions 2 is a cluster randomized controlled trial implemented in Boston, Massachusetts to promote change in multiple behavioral cancer risk factors. At baseline (2009), participants completed a survey assessing socio-demographics, health status, height/weight, and factors associated with technology. One-third of participants randomized to receive the intervention (n=598) were randomized to receive automated reminders, with participants selecting modality. 28% (167/598) of participants selected SMS reminders. Controlling for clustering by primary care provider, younger participants (OR=0.97, 95% CI=(0.95, 0.99), p&lt;0.01), those most comfortable with computers (very uncomfortable OR=0.54, 95% CI=(0.29, 1.01), pÃ¢â€°Â¤0.05: referent group = very comfortable), and those who frequently sent/received text messages (never OR=0.09 CI=(0.04, 0.16) p&lt;0.01; 1-3 times/month OR=0.38, 95% CI=(0.15, 0.93) p=0.04: referent group=1-5 times/week) were more likely to choose SMS. Interventions should make both modalities available to ensure that more participants can benefit from prompting. Studies examining the effect of automated reminders may have reduced effectiveness or generalizability if they employ only one modality.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22004,""
"Automated semantic indices related to cognitive function and rate of cognitive decline","Pakhomov, Hemmy, Lim","https://doi.org/10.1016/j.neuropsychologia.2012.05.016","20121121","PubMed","Aged; Alzheimer Disease; Analysis of Variance; Cognition; Cognition Disorders; Cognitive Dysfunction; Disease Progression; Executive Function; Female; Humans; Male; Neuropsychological Tests; Psycholinguistics; Psychomotor Performance; Semantics; Verbal Behavior","The objective of our study is to introduce a fully automated, computational linguistic technique to quantify semantic relations between words generated on a standard semantic verbal fluency test and to determine its cognitive and clinical correlates. Cognitive differences between patients with Alzheimer's disease and mild cognitive impairment are evident in their performance on the semantic verbal fluency test. In addition to the semantic verbal fluency test score, several other performance characteristics sensitive to disease status and predictive of future cognitive decline have been defined in terms of words generated from semantically related categories (clustering) and shifting between categories (switching). However, the traditional assessment of clustering and switching has been performed manually in a qualitative fashion resulting in subjective scoring with limited reproducibility and scalability. Our approach uses word definitions and hierarchical relations between the words in WordNet(Ã‚Â®), a large electronic lexical database, to quantify the degree of semantic similarity and relatedness between words. We investigated the novel semantic fluency indices of mean cumulative similarity and relatedness between all pairs of words regardless of their order, and mean sequential similarity and relatedness between pairs of adjacent words in a sample of patients with clinically diagnosed probable (n=55) or possible (n=27) Alzheimer's disease or mild cognitive impairment (n=31). The semantic fluency indices differed significantly between the diagnostic groups, and were strongly associated with neuropsychological tests of executive function, as well as the rate of global cognitive decline. Our results suggest that word meanings and relations between words shared across individuals and computationally modeled via WordNet and large text corpora provide the necessary context to account for the variability in language-based behavior and relate it to cognitive dysfunction observed in mild cognitive impairment and Alzheimer's disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22005,""
"Algorithms and results of eye tissues differentiation based on RF ultrasound","Jurkonis, JanuÃ…Â¡auskas, Marozas, JegeleviÃ„Âius, Daukantas, PataÃ…Â¡ius, Paunksnis, LukoÃ…Â¡eviÃ„Âius","https://doi.org/10.1100/2012/870869","20120927","PubMed","Algorithms; Eye; Humans; Orbit; Ultrasonics; Ultrasonography","Algorithms and software were developed for analysis of B-scan ultrasonic signals acquired from commercial diagnostic ultrasound system. The algorithms process raw ultrasonic signals in backscattered spectrum domain, which is obtained using two time-frequency methods: short-time Fourier and Hilbert-Huang transformations. The signals from selected regions of eye tissues are characterized by parameters: B-scan envelope amplitude, approximated spectral slope, approximated spectral intercept, mean instantaneous frequency, mean instantaneous bandwidth, and parameters of Nakagami distribution characterizing Hilbert-Huang transformation output. The backscattered ultrasound signal parameters characterizing intraocular and orbit tissues were processed by decision tree data mining algorithm. The pilot trial proved that applied methods are able to correctly classify signals from corpus vitreum blood, extraocular muscle, and orbit tissues. In 26 cases of ocular tissues classification, one error occurred, when tissues were classified into classes of corpus vitreum blood, extraocular muscle, and orbit tissue. In this pilot classification parameters of spectral intercept and Nakagami parameter for instantaneous frequencies distribution of the 1st intrinsic mode function were found specific for corpus vitreum blood, orbit and extraocular muscle tissues. We conclude that ultrasound data should be further collected in clinical database to establish background for decision support system for ocular tissue noninvasive differentiation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22006,""
"Towards automatic diabetes case detection and ABCS protocol compliance assessment","Mishra, Son, Arnzen","https://doi.org/10.3121/cmr.2012.1047","20121227","PubMed","Algorithms; Data Mining; Diabetes Mellitus; Diagnosis, Computer-Assisted; Female; Guideline Adherence; Humans; Male; Medical Records Systems, Computerized; Risk Factors","According to the American Diabetes Association, the implementation of the standards of care for diabetes has been suboptimal in most clinical settings. Diabetes is a disease that had a total estimated cost of $174 billion in 2007 for an estimated diabetes-affected population of 17.5 million in the United States. With the advent of electronic medical records (EMR), tools to analyze data residing in the EMR for healthcare surveillance can help reduce the burdens experienced today. This study was primarily designed to evaluate the efficacy of employing clinical natural language processing to analyze discharge summaries for evidence indicating a presence of diabetes, as well as to assess diabetes protocol compliance and high risk factors. Three sets of algorithms were developed to analyze discharge summaries for: (1) identification of diabetes, (2) protocol compliance, and (3) identification of high risk factors. The algorithms utilize a common natural language processing framework that extracts relevant discourse evidence from the medical text. Evidence utilized in one or more of the algorithms include assertion of the disease and associated findings in medical text, as well as numerical clinical measurements and prescribed medications. The diabetes classifier was successful at classifying reports for the presence and absence of diabetes. Evaluated against 444 discharge summaries, the classifier's performance included macro and micro F-scores of 0.9698 and 0.9865, respectively. Furthermore, the protocol compliance and high risk factor classifiers showed promising results, with most F-measures exceeding 0.9. The presented approach accurately identified diabetes in medical discharge summaries and showed promise with regards to assessment of protocol compliance and high risk factors. Utilizing free-text analytic techniques on medical text can complement clinical-public health decision support by identifying cases and high risk factors.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22007,""
"Automated identification of patients with pulmonary nodules in an integrated health system using administrative health plan data, radiology reports, and natural language processing","Danforth, Early, Ngan, Kosco, Zheng, Gould","https://doi.org/10.1097/JTO.0b013e31825bd9f5","20121214","PubMed","Aged; Algorithms; Female; Humans; Lung Neoplasms; Male; Middle Aged; Natural Language Processing; Neoplasm Staging; Pattern Recognition, Automated; Prognosis; Radiographic Image Interpretation, Computer-Assisted; Research Report; Solitary Pulmonary Nodule; Tomography, X-Ray Computed","Lung nodules are commonly encountered in clinical practice, yet little is known about their management in community settings. An automated method for identifying patients with lung nodules would greatly facilitate research in this area. Using members of a large, community-based health plan from 2006 to 2010, we developed a method to identify patients with lung nodules, by combining five diagnostic codes, four procedural codes, and a natural language processing algorithm that performed free text searches of radiology transcripts. An experienced pulmonologist reviewed a random sample of 116 radiology transcripts, providing a reference standard for the natural language processing algorithm. With the use of an automated method, we identified 7112 unique members as having one or more incident lung nodules. The mean age of the patients was 65 years (standard deviation 14 years). There were slightly more women (54%) than men, and Hispanics and non-whites comprised 45% of the lung nodule cohort. Thirty-six percent were never smokers whereas 11% were current smokers. Fourteen percent of the patients were subsequently diagnosed with lung cancer. The sensitivity and specificity of the natural language processing algorithm for identifying the presence of lung nodules were 96% and 86%, respectively, compared with clinician review. Among the true positive transcripts in the validation sample, only 35% were solitary and unaccompanied by one or more associated findings, and 56% measured 8 to 30 mm in diameter. A combination of diagnostic codes, procedural codes, and a natural language processing algorithm for free text searching of radiology reports can accurately and efficiently identify patients with incident lung nodules, many of whom are subsequently diagnosed with lung cancer.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22008,""
"RCDB: Renal Cancer Gene Database","Ramana","https://doi.org/10.1186/1756-0500-5-246","20130131","PubMed","Access to Information; Biomarkers, Tumor; Carcinoma, Renal Cell; Databases, Genetic; Genetic Predisposition to Disease; Humans; Internet; Kidney Neoplasms; MicroRNAs; Phenotype; Prognosis","Renal cell carcinoma or RCC is one of the common and most lethal urological cancers, with 40% of the patients succumbing to death because of metastatic progression of the disease. Treatment of metastatic RCC remains highly challenging because of its resistance to chemotherapy as well as radiotherapy, besides surgical resection. Whereas RCC comprises tumors with differing histological types, clear cell RCC remains the most common. A major problem in the clinical management of patients presenting with localized ccRCC is the inability to determine tumor aggressiveness and accurately predict the risk of metastasis following surgery. As a measure to improve the diagnosis and prognosis of RCC, researchers have identified several molecular markers through a number of techniques. However the wealth of information available is scattered in literature and not easily amenable to data-mining. To reduce this gap, this work describes a comprehensive repository called Renal Cancer Gene Database, as an integrated gateway to study renal cancer related data. Renal Cancer Gene Database is a manually curated compendium of 240 protein-coding and 269 miRNA genes contributing to the etiology and pathogenesis of various forms of renal cell carcinomas. The protein coding genes have been classified according to the kind of gene alteration observed in RCC. RCDB also includes the miRNAsdysregulated in RCC, along with the corresponding information regarding the type of RCC and/or metastatic or prognostic significance. While some of the miRNA genes showed an association with other types of cancers few were unique to RCC. Users can query the database using keywords, category and chromosomal location of the genes. The knowledgebase can be freely accessed via a user-friendly web interface at http://www.juit.ac.in/attachments/jsr/rcdb/homenew.html. It is hoped that this database would serve as a useful complement to the existing public resources and as a good starting point for researchers and physicians interested in RCC genetics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22009,""
"ASCOT: a text mining-based web-service for efficient search and assisted creation of clinical trials","Korkontzelos, Mu, Ananiadou","https://doi.org/10.1186/1472-6947-12-S1-S3","20130307","PubMed","Algorithms; Clinical Trials as Topic; Cluster Analysis; Data Display; Data Mining; Databases, Factual; Decision Making, Computer-Assisted; Humans; Information Storage and Retrieval; Internet; Natural Language Processing; Systematized Nomenclature of Medicine; Unified Medical Language System; United Kingdom; User-Computer Interface","Clinical trials are mandatory protocols describing medical research on humans and among the most valuable sources of medical practice evidence. Searching for trials relevant to some query is laborious due to the immense number of existing protocols. Apart from search, writing new trials includes composing detailed eligibility criteria, which might be time-consuming, especially for new researchers. In this paper we present ASCOT, an efficient search application customised for clinical trials. ASCOT uses text mining and data mining methods to enrich clinical trials with metadata, that in turn serve as effective tools to narrow down search. In addition, ASCOT integrates a component for recommending eligibility criteria based on a set of selected protocols.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22010,""
"Routine development of objectively derived search strategies","Hausner, Waffenschmidt, Kaiser, Simon","https://doi.org/10.1186/2046-4053-1-19","20130527","PubMed","Brachytherapy; Databases, Bibliographic; Germany; Humans; Information Storage and Retrieval; Male; Prostatic Neoplasms; Reproducibility of Results; Review Literature as Topic","Over the past few years, information retrieval has become more and more professionalized, and information specialists are considered full members of a research team conducting systematic reviews. Research groups preparing systematic reviews and clinical practice guidelines have been the driving force in the development of search strategies, but open questions remain regarding the transparency of the development process and the available resources. An empirically guided approach to the development of a search strategy provides a way to increase transparency and efficiency. Our aim in this paper is to describe the empirically guided development process for search strategies as applied by the German Institute for Quality and Efficiency in Health Care (Institut fÃƒÂ¼r QualitÃƒÂ¤t und Wirtschaftlichkeit im Gesundheitswesen, or ""IQWiG""). This strategy consists of the following steps: generation of a test set, as well as the development, validation and standardized documentation of the search strategy. We illustrate our approach by means of an example, that is, a search for literature on brachytherapy in patients with prostate cancer. For this purpose, a test set was generated, including a total of 38 references from 3 systematic reviews. The development set for the generation of the strategy included 25 references. After application of textual analytic procedures, a strategy was developed that included all references in the development set. To test the search strategy on an independent set of references, the remaining 13 references in the test set (the validation set) were used. The validation set was also completely identified. Our conclusion is that an objectively derived approach similar to that used in search filter development is a feasible way to develop and validate reliable search strategies. Besides creating high-quality strategies, the widespread application of this approach will result in a substantial increase in the transparency of the development process of search strategies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22011,""
"Feature engineering combined with machine learning and rule-based methods for structured information extraction from narrative clinical discharge summaries","Xu, Hong, Tsujii, Chang","https://doi.org/10.1136/amiajnl-2011-000776","20130116","PubMed","Artificial Intelligence; Data Mining; Electronic Health Records; Humans; Natural Language Processing; Patient Discharge; Vocabulary, Controlled","A system that translates narrative text in the medical domain into structured representation is in great demand. The system performs three sub-tasks: concept extraction, assertion classification, and relation identification. The overall system consists of five steps: (1) pre-processing sentences, (2) marking noun phrases (NPs) and adjective phrases (APs), (3) extracting concepts that use a dosage-unit dictionary to dynamically switch two models based on Conditional Random Fields (CRF), (4) classifying assertions based on voting of five classifiers, and (5) identifying relations using normalized sentences with a set of effective discriminating features. Macro-averaged and micro-averaged precision, recall and F-measure were used to evaluate results. The performance is competitive with the state-of-the-art systems with micro-averaged F-measure of 0.8489 for concept extraction, 0.9392 for assertion classification and 0.7326 for relation identification. The system exploits an array of common features and achieves state-of-the-art performance. Prudent feature engineering sets the foundation of our systems. In concept extraction, we demonstrated that switching models, one of which is especially designed for telegraphic sentences, improved extraction of the treatment concept significantly. In assertion classification, a set of features derived from a rule-based classifier were proven to be effective for the classes such as conditional and possible. These classes would suffer from data scarcity in conventional machine-learning methods. In relation identification, we use two-staged architecture, the second of which applies pairwise classifiers to possible candidate classes. This architecture significantly improves performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22012,""
"Machine learning-based coreference resolution of concepts in clinical documents","Ware, Mullett, Jagannathan, El-Rawas","https://doi.org/10.1136/amiajnl-2011-000774","20130116","PubMed","Artificial Intelligence; Data Mining; Electronic Health Records; Humans; Natural Language Processing; Pattern Recognition, Automated; Semantics","Coreference resolution of concepts, although a very active area in the natural language processing community, has not yet been widely applied to clinical documents. Accordingly, the 2011 i2b2 competition focusing on this area is a timely and useful challenge. The objective of this research was to collate coreferent chains of concepts from a corpus of clinical documents. These concepts are in the categories of person, problems, treatments, and tests. A machine learning approach based on graphical models was employed to cluster coreferent concepts. Features selected were divided into domain independent and domain specific sets. Training was done with the i2b2 provided training set of 489 documents with 6949 chains. Testing was done on 322 documents. The learning engine, using the un-weighted average of three different measurement schemes, resulted in an F measure of 0.8423 where no domain specific features were included and 0.8483 where the feature set included both domain independent and domain specific features. Our machine learning approach is a promising solution for recognizing coreferent concepts, which in turn is useful for practical applications such as the assembly of problem and medication lists from clinical documents.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22013,""
"Ontology-guided feature engineering for clinical text classification","Garla, Brandt","https://doi.org/10.1016/j.jbi.2012.04.010","20130321","PubMed","Algorithms; Cardiovascular Diseases; Data Mining; Databases as Topic; Humans; Medical Informatics Applications; Models, Theoretical; Natural Language Processing; Obesity; Semantics; Unified Medical Language System","In this study we present novel feature engineering techniques that leverage the biomedical domain knowledge encoded in the Unified Medical Language System (UMLS) to improve machine-learning based clinical text classification. Critical steps in clinical text classification include identification of features and passages relevant to the classification task, and representation of clinical text to enable discrimination between documents of different classes. We developed novel information-theoretic techniques that utilize the taxonomical structure of the Unified Medical Language System (UMLS) to improve feature ranking, and we developed a semantic similarity measure that projects clinical text into a feature space that improves classification. We evaluated these methods on the 2008 Integrating Informatics with Biology and the Bedside (I2B2) obesity challenge. The methods we developed improve upon the results of this challenge's top machine-learning based system, and may improve the performance of other machine-learning based clinical text classification systems. We have released all tools developed as part of this study as open source, available at http://code.google.com/p/ytex.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22014,""
"Disturbance of emotion processing in frontotemporal dementia: a synthesis of cognitive and neuroimaging findings","Kumfor, Piguet","https://doi.org/10.1007/s11065-012-9201-6","20130114","PubMed","Brain; Cognition Disorders; Emotions; Facial Expression; Frontal Lobe; Frontotemporal Dementia; Frontotemporal Lobar Degeneration; Humans; Interpersonal Relations; Limbic System; Neuroimaging; Neuropsychological Tests; Primary Progressive Nonfluent Aphasia; Recognition, Psychology; Temporal Lobe","Accurate processing of emotional information is a critical component of appropriate social interactions and interpersonal relationships. Disturbance of emotion processing is present in frontotemporal dementia (FTD) and is a clinical feature in two of the three subtypes: behavioural-variant FTD and semantic dementia. Emotion processing in progressive nonfluent aphasia, the third FTD subtype, is thought to be mostly preserved, although current evidence is scant. This paper reviews the literature on emotion recognition, reactivity and expression in FTD subtypes, although most studies focus on emotion recognition. The relationship between patterns of emotion processing deficits and patterns of neural atrophy are considered, by integrating evidence from recent neuroimaging studies. The review findings are discussed in the context of three contemporary theories of emotion processing: the limbic system model, the right hemisphere model and a multimodal system of emotion. Results across subtypes of FTD are most consistent with the multimodal system model, and support the presence of somewhat dissociable neural correlates for basic emotions, with strongest evidence for the emotions anger and sadness. Poor emotion processing is evident in all three subtypes, although deficits are more widespread than what would be predicted based on studies in healthy cohorts. Studies that include behavioural and imaging data are limited. Future investigations combining these approaches will help improve the understanding of the neural network underlying emotion processing. Presently, longitudinal investigations of emotion processing in FTD are lacking, and studies investigating emotion processing over time are critical to understand the clinical manifestations of disease progression in FTD.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22015,""
"Identification of pneumonia and influenza deaths using the Death Certificate Pipeline","Davis, Staes, Duncan, Igo, Facelli","https://doi.org/10.1186/1472-6947-12-37","20130110","PubMed","Cause of Death; Clinical Coding; Death Certificates; Decision Support Systems, Clinical; Humans; Influenza, Human; Medical Records; Natural Language Processing; Pneumonia; Population Surveillance; United States","Death records are a rich source of data, which can be used to assist with public surveillance and/or decision support. However, to use this type of data for such purposes it has to be transformed into a coded format to make it computable. Because the cause of death in the certificates is reported as free text, encoding the data is currently the single largest barrier of using death certificates for surveillance. Therefore, the purpose of this study was to demonstrate the feasibility of using a pipeline, composed of a detection rule and a natural language processor, for the real time encoding of death certificates using the identification of pneumonia and influenza cases as an example and demonstrating that its accuracy is comparable to existing methods. A Death Certificates Pipeline (DCP) was developed to automatically code death certificates and identify pneumonia and influenza cases. The pipeline used MetaMap to code death certificates from the Utah Department of Health for the year 2008. The output of MetaMap was then accessed by detection rules which flagged pneumonia and influenza cases based on the Centers of Disease and Control and Prevention (CDC) case definition. The output from the DCP was compared with the current method used by the CDC and with a keyword search. Recall, precision, positive predictive value and F-measure with respect to the CDC method were calculated for the two other methods considered here. The two different techniques compared here with the CDC method showed the following recall/ precision results: DCP: 0.998/0.98 and keyword searching: 0.96/0.96. The F-measure were 0.99 and 0.96 respectively (DCP and keyword searching). Both the keyword and the DCP can run in interactive form with modest computer resources, but DCP showed superior performance. The pipeline proposed here for coding death certificates and the detection of cases is feasible and can be extended to other conditions. This method provides an alternative that allows for coding free-text death certificates in real time that may increase its utilization not only in the public health domain but also for biomedical researchers and developers. This study did not involved any clinical trials.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22016,""
"Using PharmGKB to train text mining approaches for identifying potential gene targets for pharmacogenomic studies","Pakhomov, McInnes, Lamba, Liu, Melton, Ghodke, Bhise, Lamba, Birnbaum","https://doi.org/10.1016/j.jbi.2012.04.007","20130321","PubMed","Computational Biology; Data Mining; Databases, Genetic; Drug Discovery; Genes; Humans; Knowledge Bases; MEDLINE; Pharmacogenetics; Support Vector Machine","The main objective of this study was to investigate the feasibility of using PharmGKB, a pharmacogenomic database, as a source of training data in combination with text of MEDLINE abstracts for a text mining approach to identification of potential gene targets for pathway-driven pharmacogenomics research. We used the manually curated relations between drugs and genes in PharmGKB database to train a support vector machine predictive model and applied this model prospectively to MEDLINE abstracts. The gene targets suggested by this approach were subsequently manually reviewed. Our quantitative analysis showed that a support vector machine classifiers trained on MEDLINE abstracts with single words (unigrams) used as features and PharmGKB relations used for supervision, achieve an overall sensitivity of 85% and specificity of 69%. The subsequent qualitative analysis showed that gene targets ""suggested"" by the automatic classifier were not anticipated by expert reviewers but were subsequently found to be relevant to the three drugs that were investigated: carbamazepine, lamivudine and zidovudine. Our results show that this approach is not only feasible but may also find new gene targets not identifiable by other methods thus making it a valuable tool for pathway-driven pharmacogenomics research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22017,""
"Recognition of medication information from discharge summaries using ensembles of classifiers","Doan, Collier, Xu, Pham, Tu","https://doi.org/10.1186/1472-6947-12-36","20130522","PubMed","Algorithms; Artificial Intelligence; Decision Support Techniques; Female; Humans; Information Storage and Retrieval; Institutional Management Teams; Male; Medication Systems; Natural Language Processing; Patient Discharge; Pattern Recognition, Automated; Pharmaceutical Preparations; Reproducibility of Results; Semantics; Software Design; Support Vector Machine","Extraction of clinical information such as medications or problems from clinical text is an important task of clinical natural language processing (NLP). Rule-based methods are often used in clinical NLP systems because they are easy to adapt and customize. Recently, supervised machine learning methods have proven to be effective in clinical NLP as well. However, combining different classifiers to further improve the performance of clinical entity recognition systems has not been investigated extensively. Combining classifiers into an ensemble classifier presents both challenges and opportunities to improve performance in such NLP tasks. We investigated ensemble classifiers that used different voting strategies to combine outputs from three individual classifiers: a rule-based system, a support vector machine (SVM) based system, and a conditional random field (CRF) based system. Three voting methods were proposed and evaluated using the annotated data sets from the 2009 i2b2 NLP challenge: simple majority, local SVM-based voting, and local CRF-based voting. Evaluation on 268 manually annotated discharge summaries from the i2b2 challenge showed that the local CRF-based voting method achieved the best F-score of 90.84% (94.11% Precision, 87.81% Recall) for 10-fold cross-validation. We then compared our systems with the first-ranked system in the challenge by using the same training and test sets. Our system based on majority voting achieved a better F-score of 89.65% (93.91% Precision, 85.76% Recall) than the previously reported F-score of 89.19% (93.78% Precision, 85.03% Recall) by the first-ranked system in the challenge. Our experimental results using the 2009 i2b2 challenge datasets showed that ensemble classifiers that combine individual classifiers into a voting system could achieve better performance than a single classifier in recognizing medication information from clinical text. It suggests that simple strategies that can be easily implemented such as majority voting could have the potential to significantly improve clinical entity recognition.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22018,""
"A knowledge-driven conditional approach to extract pharmacogenomics specific drug-gene relationships from free text","Xu, Wang","https://doi.org/10.1016/j.jbi.2012.04.011","20130321","PubMed","Computational Biology; Data Mining; Drug Discovery; Humans; MEDLINE; Pharmacogenetics","An important task in pharmacogenomics (PGx) studies is to identify genetic variants that may impact drug response. The success of many systematic and integrative computational approaches for PGx studies depends on the availability of accurate, comprehensive and machine understandable drug-gene relationship knowledge bases. Scientific literature is one of the most comprehensive knowledge sources for PGx-specific drug-gene relationships. However, the major barrier in accessing this information is that the knowledge is buried in a large amount of free text with limited machine understandability. Therefore there is a need to develop automatic approaches to extract structured PGx-specific drug-gene relationships from unstructured free text literature. In this study, we have developed a conditional relationship extraction approach to extract PGx-specific drug-gene pairs from 20 million MEDLINE abstracts using known drug-gene pairs as prior knowledge. We have demonstrated that the conditional drug-gene relationship extraction approach significantly improves the precision and F1 measure compared to the unconditioned approach (precision: 0.345 vs. 0.11; recall: 0.481 vs. 1.00; F1: 0.402 vs. 0.201). In this study, a method based on co-occurrence is used as the underlying relationship extraction method for its simplicity. It can be replaced by or combined with more advanced methods such as machine learning or natural language processing approaches to further improve the performance of the drug-gene relationship extraction from free text. Our method is not limited to extracting a drug-gene relationship; it can be generalized to extract other types of relationships when related background knowledge bases exist.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22019,""
"Coreference resolution of medical concepts in discharge summaries by exploiting contextual information","Dai, Chen, Wu, Lai, Tsai, Hsu","https://doi.org/10.1136/amiajnl-2012-000808","20130116","PubMed","Artificial Intelligence; Computer Simulation; Data Mining; Electronic Health Records; Humans; Natural Language Processing; Patient Discharge; Pattern Recognition, Automated; Semantics; United States","Patient discharge summaries provide detailed medical information about hospitalized patients and are a rich resource of data for clinical record text mining. The textual expressions of this information are highly variable. In order to acquire a precise understanding of the patient, it is important to uncover the relationship between all instances in the text. In natural language processing (NLP), this task falls under the category of coreference resolution. A key contribution of this paper is the application of contextual-dependent rules that describe relationships between coreference pairs. To resolve phrases that refer to the same entity, the authors use these rules in three representative NLP systems: one rule-based, another based on the maximum entropy model, and the last a system built on the Markov logic network (MLN) model. The experimental results show that the proposed MLN-based system outperforms the baseline system (exact match) by average F-scores of 4.3% and 5.7% on the Beth and Partners datasets, respectively. Finally, the three systems were integrated into an ensemble system, further improving performance to 87.21%, which is 4.5% more than the official i2b2 Track 1C average (82.7%). In this paper, the main challenges in the resolution of coreference relations in patient discharge summaries are described. Several rules are proposed to exploit contextual information, and three approaches presented. While single systems provided promising results, an ensemble approach combining the three systems produced a better performance than even the best single system.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22020,""
"Systematic identification of pharmacogenomics information from clinical trials","Li, Lu","https://doi.org/10.1016/j.jbi.2012.04.005","20130321","PubMed","Clinical Trials as Topic; Data Mining; Databases, Factual; Genomics; Humans; Knowledge Bases; Pharmacogenetics; PubMed; Treatment Outcome","Recent progress in high-throughput genomic technologies has shifted pharmacogenomic research from candidate gene pharmacogenetics to clinical pharmacogenomics (PGx). Many clinical related questions may be asked such as 'what drug should be prescribed for a patient with mutant alleles?' Typically, answers to such questions can be found in publications mentioning the relationships of the gene-drug-disease of interest. In this work, we hypothesize that ClinicalTrials.gov is a comparable source rich in PGx related information. In this regard, we developed a systematic approach to automatically identify PGx relationships between genes, drugs and diseases from trial records in ClinicalTrials.gov. In our evaluation, we found that our extracted relationships overlap significantly with the curated factual knowledge through the literature in a PGx database and that most relationships appear on average 5 years earlier in clinical trials than in their corresponding publications, suggesting that clinical trials may be valuable for both validating known and capturing new PGx related information in a more timely manner. Furthermore, two human reviewers judged a portion of computer-generated relationships and found an overall accuracy of 74% for our text-mining approach. This work has practical implications in enriching our existing knowledge on PGx gene-drug-disease relationships as well as suggesting crosslinks between ClinicalTrials.gov and other PGx knowledge bases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22021,""
"Clinical decision support with automated text processing for cervical cancer screening","Wagholikar, MacLaughlin, Henry, Greenes, Hankey, Liu, Chaudhry","https://doi.org/10.1136/amiajnl-2012-000820","20130116","PubMed","Aged; Data Mining; Decision Support Systems, Clinical; Electronic Health Records; Female; Humans; Mass Screening; Natural Language Processing; Papanicolaou Test; Sensitivity and Specificity; Uterine Cervical Neoplasms; Vaginal Smears","To develop a computerized clinical decision support system (CDSS) for cervical cancer screening that can interpret free-text Papanicolaou (Pap) reports. The CDSS was constituted by two rulebases: the free-text rulebase for interpreting Pap reports and a guideline rulebase. The free-text rulebase was developed by analyzing a corpus of 49Ã¢â‚¬Ë†293 Pap reports. The guideline rulebase was constructed using national cervical cancer screening guidelines. The CDSS accesses the electronic medical record (EMR) system to generate patient-specific recommendations. For evaluation, the screening recommendations made by the CDSS for 74 patients were reviewed by a physician. Evaluation revealed that the CDSS outputs the optimal screening recommendations for 73 out of 74 test patients and it identified two cases for gynecology referral that were missed by the physician. The CDSS aided the physician to amend recommendations in six cases. The failure case was because human papillomavirus (HPV) testing was sometimes performed separately from the Pap test and these results were reported by a laboratory system that was not queried by the CDSS. Subsequently, the CDSS was upgraded to look up the HPV results missed earlier and it generated the optimal recommendations for all 74 test cases. Single institution and single expert study. An accurate CDSS system could be constructed for cervical cancer screening given the standardized reporting of Pap tests and the availability of explicit guidelines. Overall, the study demonstrates that free text in the EMR can be effectively utilized through natural language processing to develop clinical decision support tools.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22022,""
"Annotation Analysis for Testing Drug Safety Signals using Unstructured Clinical Notes","Lependu, Iyer, Fairon, Shah","https://doi.org/10.1186/2041-1480-3-S1-S5","20121002","PubMed","","The electronic surveillance for adverse drug events is largely based upon the analysis of coded data from reporting systems. Yet, the vast majority of electronic health data lies embedded within the free text of clinical notes and is not gathered into centralized repositories. With the increasing access to large volumes of electronic medical data-in particular the clinical notes-it may be possible to computationally encode and to test drug safety signals in an active manner. We describe the application of simple annotation tools on clinical text and the mining of the resulting annotations to compute the risk of getting a myocardial infarction for patients with rheumatoid arthritis that take Vioxx. Our analysis clearly reveals elevated risks for myocardial infarction in rheumatoid arthritis patients taking Vioxx (odds ratio 2.06) before 2005. Our results show that it is possible to apply annotation analysis methods for testing hypotheses about drug safety using electronic medical records.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22023,""
"[Comments on retroperitoneal lymphadenectomy - laparoscopic versus robotic]","Heidenreich","https://doi.org/10.1007/s00120-012-2889-3","20121019","PubMed","Humans; Laparoscopy; Lymph Node Excision; Lymphatic Metastasis; Male; Minimally Invasive Surgical Procedures; Reconstructive Surgical Procedures; Retroperitoneal Neoplasms; Robotics; Surgery, Computer-Assisted; Testicular Neoplasms","Retroperitoneal lymph node dissection (RPLND) in high risk clinical stage I nonseminomatous germ cell tumors (NSGCT) plays a limited role in modern uro-oncology due to the superior therapeutic efficacy of even one cycle of PEB (cysplatin, etoposide, bleomycin) chemotherapy. There might be an indication for the rare case of pure mature teratoma with unfavorable prognostic risk factors. If RPLND is performed for clinical stage I NSGCT it always has to be performed in a nerve-sparing technique and within the well-defined boundaries of an anatomically adequate template in order to avoid unnecessary adjuvant systemic chemotherapy. In this aspect, laparoscopic RPLND is inferior to open RPLND as basically all patients with lymph node positive disease receive adjuvant chemotherapy. The evidence for robotic-assisted RPLND is too weak to draw any clinically useful conclusions. Currently, it is an experimental procedure.Postchemotherapy RPLND (PC-RPLND) remains a surgery for tertiary referral centres due to the complexity of the surgical intervention and the high probability of adjunctive visceral and/or vascular surgery. In accordance with international guidelines it remains a domain for an open surgical approach. Laparoscopic PC-RPLND is reserved for small residual masses with the option of a unilateral modified template resection in very experienced laparoscopic centres. With regard to robotic-assisted PC-RPLND there is no evidence in the literature with regard to morbidity and complications, short-term and long-term oncological results being in favor of this experimental approach.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22024,""
"A fast, automatic segmentation algorithm for locating and delineating touching cell boundaries in imaged histopathology","Qi, Xing, Foran, Yang","https://doi.org/10.3414/ME11-02-0015","20120912","PubMed","Algorithms; Artificial Intelligence; Breast Neoplasms; Female; Humans; Image Interpretation, Computer-Assisted; Medical Informatics; Normal Distribution; Pattern Recognition, Automated; United States","Automated analysis of imaged histopathology specimens could potentially provide support for improved reliability in detection and classification in a range of investigative and clinical cancer applications. Automated segmentation of cells in the digitized tissue microarray (TMA) is often the prerequisite for quantitative analysis. However overlapping cells usually bring significant challenges for traditional segmentation algorithms. In this paper, we propose a novel, automatic algorithm to separate overlapping cells in stained histology specimens acquired using bright-field RGB imaging. It starts by systematically identifying salient regions of interest throughout the image based upon their underlying visual content. The segmentation algorithm subsequently performs a quick, voting based seed detection. Finally, the contour of each cell is obtained using a repulsive level set deformable model using the seeds generated in the previous step. We compared the experimental results with the most current literature, and the pixel wise accuracy between human experts' annotation and those generated using the automatic segmentation algorithm. The method is tested with 100 image patches which contain more than 1000 overlapping cells. The overall precision and recall of the developed algorithm is 90% and 78%, respectively. We also implement the algorithm on GPU. The parallel implementation is 22 times faster than its C/C++ sequential implementation. The proposed segmentation algorithm can accurately detect and effectively separate each of the overlapping cells. GPU is proven to be an efficient parallel platform for overlapping cell segmentation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22025,""
"Artificial neural networks to predict activity type and energy expenditure in youth","Trost, Wong, Pfeiffer, Zheng","https://doi.org/10.1249/MSS.0b013e318258ac11","20130611","PubMed","Activities of Daily Living; Adolescent; Calorimetry, Indirect; Child; Child, Preschool; Energy Metabolism; Exercise; Female; Humans; Male; Monitoring, Ambulatory; Motor Activity; Neural Networks, Computer; Regression Analysis; Sports","Previous studies have demonstrated that pattern recognition approaches to accelerometer data reduction are feasible and moderately accurate in classifying activity type in children. Whether pattern recognition techniques can be used to provide valid estimates of physical activity (PA) energy expenditure in youth remains unexplored in the research literature. The objective of this study is to develop and test artificial neural networks (ANNs) to predict PA type and energy expenditure (PAEE) from processed accelerometer data collected in children and adolescents. One hundred participants between the ages of 5 and 15 yr completed 12 activity trials that were categorized into five PA types: sedentary, walking, running, light-intensity household activities or games, and moderate-to-vigorous-intensity games or sports. During each trial, participants wore an ActiGraph GT1M on the right hip, and VO2 was measured using the Oxycon Mobile (Viasys Healthcare, Yorba Linda, CA) portable metabolic system. ANNs to predict PA type and PAEE (METs) were developed using the following features: 10th, 25th, 50th, 75th, and 90th percentiles and the lag one autocorrelation. To determine the highest time resolution achievable, we extracted features from 10-, 15-, 20-, 30-, and 60-s windows. Accuracy was assessed by calculating the percentage of windows correctly classified and root mean square error (RMSE). As window size increased from 10 to 60 s, accuracy for the PA-type ANN increased from 81.3% to 88.4%. RMSE for the MET prediction ANN decreased from 1.1 METs to 0.9 METs. At any given window size, RMSE values for the MET prediction ANN were 30-40% lower than the conventional regression-based approaches. ANNs can be used to predict both PA type and PAEE in children and adolescents using count data from a single waist mounted accelerometer.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22026,""
"Non-financial conflicts of interest in academic grant evaluation: a qualitative study of multiple stakeholders in France","Abdoul, Perrey, Tubach, Amiel, Durand-Zaleski, Alberti","https://doi.org/10.1371/journal.pone.0035247","20120823","PubMed","Biomedical Research; Conflict of Interest; Financing, Organized; France; Organizations; Peer Review, Research; Qualitative Research","Peer review is the most widely used method for evaluating grant applications in clinical research. Criticisms of peer review include lack of equity, suspicion of biases, and conflicts of interest (CoI). CoIs raise questions of fairness, transparency, and trust in grant allocation. Few observational studies have assessed these issues. We report the results of a qualitative study on reviewers' and applicants' perceptions and experiences of CoIs in reviews of French academic grant applications. We designed a qualitative study using semi-structured interviews and direct observation. We asked members of assessment panels, external reviewers, and applicants to participate in semi-structured interviews. Two independent researchers conducted in-depth reviews and line-by-line coding of all transcribed interviews, which were also subjected to TropesÃ‚Â® software text analysis, to detect and qualify themes associated with CoIs. Most participants (73/98) spontaneously reported that non-financial CoIs predominated over financial CoIs. Non-financial CoIs mainly involved rivalry among disciplines, cronyism, and geographic and academic biases. However, none of the participants challenged the validity of peer review. Reviewers who felt they might be affected by CoIs said they reacted in a variety of ways: routine refusal to review, routine attempt to conduct an impartial review, or decision on a case-by-case basis. Multiple means of managing non-financial CoIs were suggested, including increased transparency throughout the review process, with public disclosure of non-financial CoIs, and careful selection of independent reviewers, including foreign experts and methodologists. Our study underscores the importance of considering non-financial CoIs when reviewing research grant applications, in addition to financial CoIs. Specific measures are needed to prevent a negative impact of non-financial CoIs on the fairness of resource allocation. Whether and how public disclosure of non-financial CoIs should be accomplished remains debatable.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22027,""
"CDAPubMed: a browser extension to retrieve EHR-based biomedical literature","Perez-Rey, Jimenez-Castellanos, Garcia-Remesal, Crespo, Maojo","https://doi.org/10.1186/1472-6947-12-29","20120806","PubMed","Documentation; Electronic Health Records; Information Storage and Retrieval; Internet; Medical Subject Headings; Periodicals as Topic; PubMed; Software Design; Systems Integration","Over the last few decades, the ever-increasing output of scientific publications has led to new challenges to keep up to date with the literature. In the biomedical area, this growth has introduced new requirements for professionals, e.g., physicians, who have to locate the exact papers that they need for their clinical and research work amongst a huge number of publications. Against this backdrop, novel information retrieval methods are even more necessary. While web search engines are widespread in many areas, facilitating access to all kinds of information, additional tools are required to automatically link information retrieved from these engines to specific biomedical applications. In the case of clinical environments, this also means considering aspects such as patient data security and confidentiality or structured contents, e.g., electronic health records (EHRs). In this scenario, we have developed a new tool to facilitate query building to retrieve scientific literature related to EHRs. We have developed CDAPubMed, an open-source web browser extension to integrate EHR features in biomedical literature retrieval approaches. Clinical users can use CDAPubMed to: (i) load patient clinical documents, i.e., EHRs based on the Health Level 7-Clinical Document Architecture Standard (HL7-CDA), (ii) identify relevant terms for scientific literature search in these documents, i.e., Medical Subject Headings (MeSH), automatically driven by the CDAPubMed configuration, which advanced users can optimize to adapt to each specific situation, and (iii) generate and launch literature search queries to a major search engine, i.e., PubMed, to retrieve citations related to the EHR under examination. CDAPubMed is a platform-independent tool designed to facilitate literature searching using keywords contained in specific EHRs. CDAPubMed is visually integrated, as an extension of a widespread web browser, within the standard PubMed interface. It has been tested on a public dataset of HL7-CDA documents, returning significantly fewer citations since queries are focused on characteristics identified within the EHR. For instance, compared with more than 200,000 citations retrieved by breast neoplasm, fewer than ten citations were retrieved when ten patient features were added using CDAPubMed. This is an open source tool that can be freely used for non-profit purposes and integrated with other existing systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22028,""
"A mathematical model for interpretable clinical decision support with applications in gynecology","Van Belle, Van Calster, Timmerman, Bourne, Bottomley, Valentin, Neven, Van Huffel, Suykens, Boyd","https://doi.org/10.1371/journal.pone.0034312","20121105","PubMed","Adnexal Diseases; Algorithms; Communication; Computer Simulation; Decision Support Systems, Clinical; Decision Support Techniques; Expert Systems; Female; Gynecology; Humans; Models, Theoretical; Obstetrics; Physician-Patient Relations; Pregnancy; Pregnancy Outcome; Prognosis; Reproducibility of Results; Risk","Over time, methods for the development of clinical decision support (CDS) systems have evolved from interpretable and easy-to-use scoring systems to very complex and non-interpretable mathematical models. In order to accomplish effective decision support, CDS systems should provide information on how the model arrives at a certain decision. To address the issue of incompatibility between performance, interpretability and applicability of CDS systems, this paper proposes an innovative model structure, automatically leading to interpretable and easily applicable models. The resulting models can be used to guide clinicians when deciding upon the appropriate treatment, estimating patient-specific risks and to improve communication with patients. We propose the interval coded scoring (ICS) system, which imposes that the effect of each variable on the estimated risk is constant within consecutive intervals. The number and position of the intervals are automatically obtained by solving an optimization problem, which additionally performs variable selection. The resulting model can be visualised by means of appealing scoring tables and color bars. ICS models can be used within software packages, in smartphone applications, or on paper, which is particularly useful for bedside medicine and home-monitoring. The ICS approach is illustrated on two gynecological problems: diagnosis of malignancy of ovarian tumors using a dataset containing 3,511 patients, and prediction of first trimester viability of pregnancies using a dataset of 1,435 women. Comparison of the performance of the ICS approach with a range of prediction models proposed in the literature illustrates the ability of ICS to combine optimal performance with the interpretability of simple scoring systems. The ICS approach can improve patient-clinician communication and will provide additional insights in the importance and influence of available variables. Future challenges include extensions of the proposed methodology towards automated detection of interaction effects, multi-class decision support systems, prognosis and high-dimensional data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22029,""
"A cost-effectiveness analysis of ""test"" versus ""treat"" patients hospitalized with suspected influenza in Hong Kong","You, Chan, Leung, Ip, Lee","https://doi.org/10.1371/journal.pone.0033123","20120828","PubMed","Adult; Aged; Antiviral Agents; Cost-Benefit Analysis; Fluorescent Antibody Technique; Hong Kong; Hospitalization; Humans; Influenza A Virus, H1N1 Subtype; Influenza, Human; Models, Economic; Monte Carlo Method; Oseltamivir; Outcome Assessment, Health Care; Polymerase Chain Reaction; Prevalence; Quality-Adjusted Life Years; Respiratory Tract Infections","Seasonal and 2009 H1N1 influenza viruses may cause severe diseases and result in excess hospitalization and mortality in the older and younger adults, respectively. Early antiviral treatment may improve clinical outcomes. We examined potential outcomes and costs of test-guided versus empirical treatment in patients hospitalized for suspected influenza in Hong Kong. We designed a decision tree to simulate potential outcomes of four management strategies in adults hospitalized for severe respiratory infection suspected of influenza: ""immunofluorescence-assay"" (IFA) or ""polymerase-chain-reaction"" (PCR)-guided oseltamivir treatment, ""empirical treatment plus PCR"" and ""empirical treatment alone"". Model inputs were derived from literature. The average prevalence (11%) of influenza in 2010-2011 (58% being 2009 H1N1) among cases of respiratory infections was used in the base-case analysis. Primary outcome simulated was cost per quality-adjusted life-year (QALY) expected (ICER) from the Hong Kong healthcare providers' perspective. In base-case analysis, ""empirical treatment alone"" was shown to be the most cost-effective strategy and dominated the other three options. Sensitivity analyses showed that ""PCR-guided treatment"" would dominate ""empirical treatment alone"" when the daily cost of oseltamivir exceeded USD18, or when influenza prevalence was &lt;2.5% and the predominant circulating viruses were not 2009 H1N1. Using USD50,000 as the threshold of willingness-to-pay, ""empirical treatment alone"" and ""PCR-guided treatment"" were cost-effective 97% and 3% of time, respectively, in 10,000 Monte-Carlo simulations. During influenza epidemics, empirical antiviral treatment appears to be a cost-effective strategy in managing patients hospitalized with severe respiratory infection suspected of influenza, from the perspective of healthcare providers in Hong Kong.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22030,""
"Functional repertoire, molecular pathways and diseases associated with 3D domain swapping in the human proteome","Shameer, Sowdhamini","https://doi.org/10.1186/2043-9113-2-8","20121123","PubMed","","<AbstractText Label=""BACKGROUND"" NlmCategory=""BACKGROUND"">3D domain swapping is a novel structural phenomenon observed in diverse set of protein structures in oligomeric conformations. A distinct structural feature, where structural segments in a protein dimer or higher oligomer were shared between two or more chains of a protein structure, characterizes 3D domain swapping. 3D domain swapping was observed as a key mediator of numerous functional mechanisms and play pathogenic role in various diseases including conformational diseases like amyloidosis, Alzheimer's disease, Parkinson's disease and prion diseases. We report the first study with a focus on identifying functional classes, pathways and diseases mediated by 3D domain swapping in the human proteome. We used a panel of four enrichment tools with two different ontologies and two annotations database to derive biological and clinical relevant information associated with 3D domain swapping. Protein domain enrichment analysis followed by Gene Ontology (GO) term enrichment analysis revealed the functional repertoire of proteins involved in swapping. Pathway analysis using KEGG annotations revealed diverse pathway associations of human proteins involved in 3D domain swapping. Disease Ontology was used to find statistically significant associations with proteins in swapped conformation and various disease categories (P-value &lt; 0.05). We report meta-analysis results of a literature-curated dataset of human gene products involved in 3D domain swapping and discuss new insights about the functional repertoire, pathway associations and disease implications of proteins involved in 3D domain swapping. Our integrated bioinformatics pipeline comprising of four different enrichment tools, two ontologies and two annotations revealed new insights into the functional and disease correlations with 3D domain swapping. GO term enrichment were used to infer terms associated with three different GO categories. Protein domain enrichment was used to identify conserved domains enriched in swapped proteins. Pathway enrichment analysis using KEGG annotations revealed that proteins with swapped conformations are present in all six classes of KEGG BRITE hierarchy and significantly enriched KEGG pathways were observed in five classes. Five major classes of disease were found to be associated with 3D domain swapping using functional disease ontology based enrichment analysis. Five classes of human diseases: cancer, diseases of the respiratory or pulmonary system, degenerative diseases of the central nervous system, vascular disease and encephalitis were found to be significant. In conclusion, our study shows that bioinformatics based analytical approaches using curated data can enhance the understanding of functional and disease implications of 3D domain swapping.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22031,""
"Machine learning and radiology","Wang, Summers","https://doi.org/10.1016/j.media.2012.02.005","20121107","PubMed","Algorithms; Artificial Intelligence; Image Enhancement; Image Interpretation, Computer-Assisted; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique","In this paper, we give a short introduction to machine learning and survey its applications in radiology. We focused on six categories of applications in radiology: medical image segmentation, registration, computer aided detection and diagnosis, brain function or activity analysis and neurological disease diagnosis from fMR images, content-based image retrieval systems for CT or MRI images, and text analysis of radiology reports using natural language processing (NLP) and natural language understanding (NLU). This survey shows that machine learning plays a key role in many radiology applications. Machine learning identifies complex patterns automatically and helps radiologists make intelligent decisions on radiology data such as conventional radiographs, CT, MRI, and PET images and radiology reports. In many applications, the performance of machine learning-based automatic detection and diagnosis systems has shown to be comparable to that of a well-trained and experienced radiologist. Technology development in machine learning and radiology will benefit from each other in the long run. Key contributions and common characteristics of machine learning techniques in radiology are discussed. We also discuss the problem of translating machine learning applications to the radiology clinical setting, including advantages and potential barriers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22032,""
"Cancer-related fatigue: epidemiology, pathogenesis, diagnosis, and treatment","Horneber, Fischer, Dimeo, RÃƒÂ¼ffer, Weis","https://doi.org/10.3238/arztebl.2012.0161","20120726","PubMed","Causality; Comorbidity; Fatigue; Germany; Humans; Neoplasms; Prevalence; Risk Assessment; Risk Factors; Survival Analysis; Survival Rate","Many cancer patients suffer from cancer-related fatigue (CRF) both during and after their treatment. CRF can arise at any point in the course of the disease and can be either self-limited or persistent, sometimes for years. It gives rise to a vicious circle of impaired physical performance, avoidance of exertion, inactivity, inadequate physical recovery, helplessness, and depressed mood. Its hallmarks are tiredness, exhaustion, and lack of energy; it can impair performance so severely that the patient is unable to work. It is associated with increased mortality. Cancer patients are hardly ever systematically asked about the symptoms and signs of CRF. The stress and impairments that it produces are often inadequately appreciated, and the opportunities for treatment often neglected. Selective review of the pertinent literature, including published guidelines from Germany and abroad. The pathogenesis of CRF is complex, involving an interaction of somatic, emotional, cognitive, and psychosocial factors, with a highly variable pattern of clinical expression. Clinical history-taking plays a key role in diagnostic assessment. Depressive disorders must be considered in the differential diagnosis. Many randomized trials and meta-analyses have documented the efficacy of pharmacological and non-pharmacological treatments for CRF. Cancer-related fatigue is a serious problem that impairs patients physically, mentally, and socially. Physicians need to know how to recognize and treat it.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22033,""
"Absence of low back pain in patients followed weekly over one year with automated text messages","Leboeuf-Yde, Jensen, AxÃƒÂ©n","https://doi.org/10.1186/2045-709X-20-9","20121002","PubMed","","In order to define the onset of a new episode of low back pain (LBP), the definition of a ""non-episode"" must be clear. De Vet et al reviewed the scientific literature but found no evidence-based definitions of episodes or non-episodes of LBP. However, they suggested that pain-based episodes should be preceded and followed by a period of at least one month without LBP. As LBP is an episodic disease, it is not clear whether a sufficient number of patients with LBP will be LBP-free for at least one month (""non-episode"") to justify the use of this duration in the definition of pain free episode. Two clinical populations were followed weekly over one year making it possible 1) to determine the maximum numbers in a row of weeks without LBP, 2) to determine the prevalence of non-episodes throughout a one-year period, and 3) to find the prevalence of patients who reported to be in a non-episode of LBP at the end of the study. Secondary data were used from two recent clinical studies, in which weekly automated text messages (SMSes) had been collected on the number of days with LBP in the preceding week for one year. Weeks with 0 days of LBP were defined as ""zero-weeks"" and four zero-weeks in a row were defined as a period without LBP (a""non-episode"") according to de Vet et al's suggestion. The study participants, all from the secondary care sector, consisted of: study 1) patients with LBP and Magnetic Resonance Imaging-identified Modic changes and study 2) patients without obvious acute disc problems, Modic changes or other pathologies, who therefore were assumed to have non-specific LBP. Both studies were two-armed intervention studies without a significant difference in outcome between intervention groups. The number of zero-weeks was identified in each participant. Thereafter the numbers of participants who reported at least one non-episode during the study period were identified. Finally, the numbers of participants who had a non-episode at the end of the study were counted. Estimates are reported with their 95% confidence intervals. The numbers of participants included in the analyses were 80 and 209. Most commonly, no zero weeks were reported, by 65% (55-75) and 56% (49-63) of patients, respectively. The percentages of study participants with at least one non-episode at some time during the course of the study were 20% (11-29) and 18% (15-21. The percentages of participants who were identified as being in a non-episode at the time of the last week of the study were, 5% (95% CI: 0-10) and 4% (1-7) respectively. The vast majority of these secondary care sector patients had a profile of more or less constant LBP. The estimates for non-episodes during the study period and at the end of the study were very similar for participants with LBP who also had Modic changes and those with non-specific LBP. It is possible that a definition of pain-free periods is pointless in patients seeking care in the secondary care sector.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22034,""
"Assessing the cost effectiveness of robotics in urological surgery - a systematic review","Ahmed, Ibrahim, Wang, Khan, Challacombe, Khan, Dasgupta","https://doi.org/10.1111/j.1464-410X.2012.11015.x","20130110","PubMed","Cost-Benefit Analysis; Costs and Cost Analysis; Cystectomy; Humans; Laparoscopy; Learning Curve; Length of Stay; Prostatectomy; Robotics","Although robotic technology is becoming increasingly popular for urological procedures, barriers to its widespread dissemination include cost and the lack of long term outcomes. This systematic review analyzed studies comparing the use of robotic with laparoscopic and open urological surgery. These three procedures were assessed for cost efficiency in the form of direct as well as indirect costs that could arise from length of surgery, hospital stay, complications, learning curve and postoperative outcomes. A systematic review was performed searching Medline, Embase and Web of Science databases. Two reviewers identified abstracts using online databases and independently reviewed full length papers suitable for inclusion in the study. Laparoscopic and robot assisted radical prostatectomy are superior with respect to reduced hospital stay (range 1-1.76 days and 1-5.5 days, respectively) and blood loss (range 482-780 mL and 227-234 mL, respectively) when compared with the open approach (range 2-8 days and 1015 mL). Robot assisted radical prostatectomy remains more expensive (total cost ranging from US $2000-$39,215) than both laparoscopic (range US $740-$29,771) and open radical prostatectomy (range US $1870-$31,518). This difference is due to the cost of robot purchase, maintenance and instruments. The reduced length of stay in hospital (range 1-1.5 days) and length of surgery (range 102-360 min) are unable to compensate for the excess costs. Robotic surgery may require a smaller learning curve (20-40 cases) although the evidence is inconclusive. Robotic surgery provides similar postoperative outcomes to laparoscopic surgery but a reduced learning curve. Although costs are currently high, increased competition from manufacturers and wider dissemination of the technology could drive down costs. Further trials are needed to evaluate long term outcomes in order to evaluate fully the value of all three procedures in urological surgery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22035,""
"Prediction of promiscuous p-glycoprotein inhibition using a novel machine learning scheme","Leong, Chen, Shih","https://doi.org/10.1371/journal.pone.0033829","20120813","PubMed","ATP Binding Cassette Transporter, Subfamily B; ATP Binding Cassette Transporter, Subfamily B, Member 1; Animals; Computer Simulation; Drug Design; Drug Discovery; Humans; Mice; Models, Molecular; Protein Conformation; Support Vector Machine","P-glycoprotein (P-gp) is an ATP-dependent membrane transporter that plays a pivotal role in eliminating xenobiotics by active extrusion of xenobiotics from the cell. Multidrug resistance (MDR) is highly associated with the over-expression of P-gp by cells, resulting in increased efflux of chemotherapeutical agents and reduction of intracellular drug accumulation. It is of clinical importance to develop a P-gp inhibition predictive model in the process of drug discovery and development. An in silico model was derived to predict the inhibition of P-gp using the newly invented pharmacophore ensemble/support vector machine (PhE/SVM) scheme based on the data compiled from the literature. The predictions by the PhE/SVM model were found to be in good agreement with the observed values for those structurally diverse molecules in the training set (n = 31, r(2) = 0.89, q(2) = 0.86, RMSE = 0.40, s = 0.28), the test set (n = 88, r(2) = 0.87, RMSE = 0.39, s = 0.25) and the outlier set (n = 11, r(2) = 0.96, RMSE = 0.10, s = 0.05). The generated PhE/SVM model also showed high accuracy when subjected to those validation criteria generally adopted to gauge the predictivity of a theoretical model. This accurate, fast and robust PhE/SVM model that can take into account the promiscuous nature of P-gp can be applied to predict the P-gp inhibition of structurally diverse compounds that otherwise cannot be done by any other methods in a high-throughput fashion to facilitate drug discovery and development by designing drug candidates with better metabolism profile.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22036,""
"CvManGO, a method for leveraging computational predictions to improve literature-based Gene Ontology annotations","Park, Costanzo, Balakrishnan, Cherry, Hong","https://doi.org/10.1093/database/bas001","20120612","PubMed","Computational Biology; Databases, Genetic; Genes, Fungal; Genome, Fungal; Molecular Sequence Annotation; Saccharomyces cerevisiae; Saccharomyces cerevisiae Proteins; Software; Vocabulary, Controlled","The set of annotations at the Saccharomyces Genome Database (SGD) that classifies the cellular function of S. cerevisiae gene products using Gene Ontology (GO) terms has become an important resource for facilitating experimental analysis. In addition to capturing and summarizing experimental results, the structured nature of GO annotations allows for functional comparison across organisms as well as propagation of functional predictions between related gene products. Due to their relevance to many areas of research, ensuring the accuracy and quality of these annotations is a priority at SGD. GO annotations are assigned either manually, by biocurators extracting experimental evidence from the scientific literature, or through automated methods that leverage computational algorithms to predict functional information. Here, we discuss the relationship between literature-based and computationally predicted GO annotations in SGD and extend a strategy whereby comparison of these two types of annotation identifies genes whose annotations need review. Our method, CvManGO (Computational versus Manual GO annotations), pairs literature-based GO annotations with computational GO predictions and evaluates the relationship of the two terms within GO, looking for instances of discrepancy. We found that this method will identify genes that require annotation updates, taking an important step towards finding ways to prioritize literature review. Additionally, we explored factors that may influence the effectiveness of CvManGO in identifying relevant gene targets to find in particular those genes that are missing literature-supported annotations, but our survey found that there are no immediately identifiable criteria by which one could enrich for these under-annotated genes. Finally, we discuss possible ways to improve this strategy, and the applicability of this method to other projects that use the GO for curation. DATABASE URL: http://www.yeastgenome.org.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22037,""
"Automatic segmentation of carotid B-mode images using fuzzy classification","Rocha, Silva, Campilho","https://doi.org/10.1007/s11517-012-0883-y","20120626","PubMed","Algorithms; Atherosclerosis; Carotid Artery Diseases; Carotid Artery, Common; Carotid Intima-Media Thickness; Fuzzy Logic; Humans; Image Interpretation, Computer-Assisted","This paper presents a new method for the automatic segmentation of the common carotid artery in B-mode images. This method uses the instantaneous coefficient of variation edge detector, fuzzy classification of edges and dynamic programming. Several discriminating features of the intima and adventitia boundaries are considered, like the edge strength, the intensity gradient orientation, the valley shaped intensity profile and contextual information of the region delimited by those boundaries. The adopted fuzzy classification of edges helps avoiding low-pass filtering. The method is suited to real-time processing and user interaction is not required. Both the near and far wall boundaries can be detected in arteries with plaques of different types and sizes. Both expert manual and automatic tracings are significantly better for the far wall, due to the better visibility of the intima and adventitia boundaries. The automatic detection of the far wall shows an accuracy similar to the manual detections. For this wall, the error coefficient of variation for the mean intima-media thickness is in the range [5.6, 6.6Ã‚Â %] for automatic detections and in [6.7, 7.1Ã‚Â %] for manual ones. In the case of the near wall, the same coefficient of variation is in [11.2, 13.0Ã‚Â %] for automatic detections and in [5.9, 9.0Ã‚Â %] for manual detections. The mean intima-media thickness measurement errors observed for the far wall [Formula: see text] are among the best values reported for other fully automatic approaches. The application of this approach in clinical practice is encouraged by the results for the far wall and the short processing time (mean of 2.1Ã‚Â s per image).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22038,""
"TB-Lineage: an online tool for classification and analysis of strains of Mycobacterium tuberculosis complex","Shabbeer, Cowan, Ozcaglar, Rastogi, Vandenberg, Yener, Bennett","https://doi.org/10.1016/j.meegid.2012.02.010","20120815","PubMed","Bacterial Typing Techniques; Computational Biology; DNA, Bacterial; Genotype; Humans; Internet; Minisatellite Repeats; Mycobacterium tuberculosis; Phylogeny; Software; Tuberculosis","This paper formulates a set of rules to classify genotypes of the Mycobacterium tuberculosis complex (MTBC) into major lineages using spoligotypes and MIRU-VNTR results. The rules synthesize prior literature that characterizes lineages by spacer deletions and variations in the number of repeats seen at locus MIRU24 (alias VNTR2687). A tool that efficiently and accurately implements this rule base is now freely available at http://tbinsight.cs.rpi.edu/run_tb_lineage.html. When MIRU24 data is not available, the system utilizes predictions made by a NaÃƒÂ¯ve Bayes classifier based on spoligotype data. This website also provides a tool to generate spoligoforests in order to visualize the genetic diversity and relatedness of genotypes and their associated lineages. A detailed analysis of the application of these tools on a dataset collected by the CDC consisting of 3198 distinct spoligotypes and 5430 distinct MIRU-VNTR types from 37,066 clinical isolates is presented. The tools were also tested on four other independent datasets. The accuracy of automated classification using both spoligotypes and MIRU24 is &gt;99%, and using spoligotypes alone is &gt;95%. This online rule-based classification technique in conjunction with genotype visualization provides a practical tool that supports surveillance of TB transmission trends and molecular epidemiological studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22039,""
"Thoracoscopic esophagectomy in the prone position","Jarral, Purkayastha, Athanasiou, Darzi, Hanna, Zacharakis","https://doi.org/10.1007/s00464-012-2172-0","20121010","PubMed","Esophagectomy; Humans; Learning Curve; Length of Stay; Lymph Node Excision; Prone Position; Prospective Studies; Respiratory Physiological Phenomena; Retrospective Studies; Robotics; Thoracoscopy; Treatment Outcome","Minimally invasive esophageal surgery has arisen in an attempt to reduce the significant complications associated with esophagectomy. Despite proposed technical and physiological advantages, the prone position technique has not been widely adopted. This article reviews the current status of prone thoracoscopic esophagectomy. A systematic literature search was performed to identify all published clinical studies related to prone esophagectomy. Medline, EMBASE and Google Scholar were searched using the keywords ""prone,"" ""thoracoscopic,"" and ""esophagectomy"" to identify articles published between January 1994 and September 2010. A critical review of these studies is given, and where appropriate the technique is compared to the more traditional minimally invasive technique utilising the left lateral decubitus position. Twelve articles reporting the outcomes following prone thoracoscopic oesophagectomy were tabulated. These studies were all non-randomised single-centre prospective or retrospective studies of which four compared the technique to traditional minimally invasive surgery. Although prone esophagectomy is demonstrated as being both feasible and safe, there is no convincing evidence that it is superior to other forms of esophageal surgery. Most authors comment that the prone position is associated with superior surgical ergonomics and theoretically offers a number of physiological benefits. The ideal approach within minimally invasive esophageal surgery continues to be a subject of debate since no single method has produced outstanding results. Further clinical studies are required to see whether ergonomic advantages of the prone position can be translated into improved patient outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22040,""
"Context-based electronic health record: toward patient specific healthcare","Hsu, Taira, El-Saden, Kangarloo, Bui","https://doi.org/10.1109/TITB.2012.2186149","20120724","PubMed","Database Management Systems; Electronic Health Records; Humans; Models, Theoretical; Natural Language Processing; Precision Medicine; User-Computer Interface","Due to the increasingly data-intensive clinical environment, physicians now have unprecedented access to detailed clinical information from a multitude of sources. However, applying this information to guide medical decisions for a specific patient case remains challenging. One issue is related to presenting information to the practitioner: displaying a large (irrelevant) amount of information often leads to information overload. Next-generation interfaces for the electronic health record (EHR) should not only make patient data easily searchable and accessible, but also synthesize fragments of evidence documented in the entire record to understand the etiology of a disease and its clinical manifestation in individual patients. In this paper, we describe our efforts toward creating a context-based EHR, which employs biomedical ontologies and (graphical) disease models as sources of domain knowledge to identify relevant parts of the record to display. We hypothesize that knowledge (e.g., variables, relationships) from these sources can be used to standardize, annotate, and contextualize information from the patient record, improving access to relevant parts of the record and informing medical decision making. To achieve this goal, we describe a framework that aggregates and extracts findings and attributes from free-text clinical reports, maps findings to concepts in available knowledge sources, and generates a tailored presentation of the record based on the information needs of the user. We have implemented this framework in a system called Adaptive EHR, demonstrating its capabilities to present and synthesize information from neurooncology patients. This paper highlights the challenges and potential applications of leveraging disease models to improve the access, integration, and interpretation of clinical patient data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22041,""
"Building gene expression profile classifiers with a simple and efficient rejection option in R","Benso, Di Carlo, Politano, Savino, Hafeezurrehman","https://doi.org/10.1186/1471-2105-12-S13-S3","20120815","PubMed","Algorithms; Artificial Intelligence; Gene Expression Profiling; Humans; Lymphoma; Oligonucleotide Array Sequence Analysis; Pattern Recognition, Automated; Reproducibility of Results","The collection of gene expression profiles from DNA microarrays and their analysis with pattern recognition algorithms is a powerful technology applied to several biological problems. Common pattern recognition systems classify samples assigning them to a set of known classes. However, in a clinical diagnostics setup, novel and unknown classes (new pathologies) may appear and one must be able to reject those samples that do not fit the trained model. The problem of implementing a rejection option in a multi-class classifier has not been widely addressed in the statistical literature. Gene expression profiles represent a critical case study since they suffer from the curse of dimensionality problem that negatively reflects on the reliability of both traditional rejection models and also more recent approaches such as one-class classifiers. This paper presents a set of empirical decision rules that can be used to implement a rejection option in a set of multi-class classifiers widely used for the analysis of gene expression profiles. In particular, we focus on the classifiers implemented in the R Language and Environment for Statistical Computing (R for short in the remaining of this paper). The main contribution of the proposed rules is their simplicity, which enables an easy integration with available data analysis environments. Since in the definition of a rejection model tuning of the involved parameters is often a complex and delicate task, in this paper we exploit an evolutionary strategy to automate this process. This allows the final user to maximize the rejection accuracy with minimum manual intervention. This paper shows how the use of simple decision rules can be used to help the use of complex machine learning algorithms in real experimental setups. The proposed approach is almost completely automated and therefore a good candidate for being integrated in data analysis flows in labs where the machine learning expertise required to tune traditional classifiers might not be available.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22042,""
"Anaphoric reference in clinical reports: characteristics of an annotated corpus","Chapman, Savova, Zheng, Tharp, Crowley","https://doi.org/10.1016/j.jbi.2012.01.010","20121015","PubMed","Algorithms; Data Mining; Electronic Health Records; Humans; Semantics","Expressions that refer to a real-world entity already mentioned in a narrative are often considered anaphoric. For example, in the sentence ""The pain comes and goes,"" the expression ""the pain"" is probably referring to a previous mention of pain. Interpretation of meaning involves resolving the anaphoric reference: deciding which expression in the text is the correct antecedent of the referring expression, also called an anaphor. We annotated a set of 180 clinical reports (surgical pathology, radiology, discharge summaries, and emergency department) from two institutions to indicate all anaphor-antecedent pairs. The objective of this study is to describe the characteristics of the corpus in terms of the frequency of anaphoric relations, the syntactic and semantic nature of the members of the pairs, and the types of anaphoric relations that occur. Understanding how anaphoric reference is exhibited in clinical reports is critical to developing reference resolution algorithms and to identifying peculiarities of clinical text that may alter the features and methodologies that will be successful for automated anaphora resolution. We found that anaphoric reference is prevalent in all types of clinical reports, that annotations of noun phrases, semantic type, and section headings may be especially important for automated resolution of anaphoric reference, and that separate modules for reference resolution may be required for different report types, different institutions, and different types of anaphors. Accurate resolution will probably require extensive domain knowledge-especially for pathology and radiology reports with more part/whole and set/subset relations. We hope researchers will leverage the annotations in this corpus to develop automated algorithms and will add to the annotations to generate a more extensive corpus.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22043,""
"Predicting sample size required for classification performance","Figueroa, Zeng-Treitler, Kandula, Ngo","https://doi.org/10.1186/1472-6947-12-8","20120629","PubMed","Algorithms; Data Interpretation, Statistical; Diagnosis, Computer-Assisted; Humans; Learning Curve; Models, Statistical; Nonlinear Dynamics; Pattern Recognition, Automated; Predictive Value of Tests; Probability Learning; Problem-Based Learning; Reproducibility of Results; Sample Size; Stochastic Processes","Supervised learning methods need annotated data in order to generate efficient models. Annotated data, however, is a relatively scarce resource and can be expensive to obtain. For both passive and active learning methods, there is a need to estimate the size of the annotated sample required to reach a performance target. We designed and implemented a method that fits an inverse power law model to points of a given learning curve created using a small annotated training set. Fitting is carried out using nonlinear weighted least squares optimization. The fitted model is then used to predict the classifier's performance and confidence interval for larger sample sizes. For evaluation, the nonlinear weighted curve fitting method was applied to a set of learning curves generated using clinical text and waveform classification tasks with active and passive sampling methods, and predictions were validated using standard goodness of fit measures. As control we used an un-weighted fitting method. A total of 568 models were fitted and the model predictions were compared with the observed performances. Depending on the data set and sampling method, it took between 80 to 560 annotated samples to achieve mean average and root mean squared error below 0.01. Results also show that our weighted fitting method outperformed the baseline un-weighted method (p &lt; 0.05). This paper describes a simple and effective sample size prediction algorithm that conducts weighted fitting of learning curves. The algorithm outperformed an un-weighted algorithm described in previous literature. It can help researchers determine annotation sample size for supervised machine learning.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22044,""
"An observational report of intensive robotic and manual gait training in sub-acute stroke","Conesa, Costa, Morales, Edwards, Cortes, LeÃƒÂ³n, Bernabeu, Medina","https://doi.org/10.1186/1743-0003-9-13","20120523","PubMed","Exercise Therapy; Female; Gait; Gait Disorders, Neurologic; Humans; Male; Middle Aged; Recovery of Function; Robotics; Stroke; Stroke Rehabilitation","The use of automated electromechanical devices for gait training in neurological patients is increasing, yet the functional outcomes of well-defined training programs using these devices and the characteristics of patients that would most benefit are seldom reported in the literature. In an observational study of functional outcomes, we aimed to provide a benchmark for expected change in gait function in early stroke patients, from an intensive inpatient rehabilitation program including both robotic and manual gait training. We followed 103 sub-acute stroke patients who met the clinical inclusion criteria for Body Weight Supported Robotic Gait Training (BWSRGT). Patients completed an intensive 8-week gait-training program comprising robotic gait training (weeks 0-4) followed by manual gait training (weeks 4-8). A change in clinical function was determined by the following assessments taken at 0, 4 and 8 weeks (baseline, mid-point and end-point respectively): Functional Ambulatory Categories (FAC), 10 m Walking Test (10 MWT), and Tinetti Gait and Balance Scales. Over half of the patients made a clinically meaningful improvement on the Tinetti Gait Scale (&gt; 3 points) and Tinetti Balance Scale (&gt; 5 points), while over 80% of the patients increased at least 1 point on the FAC scale (0-5) and improved walking speed by more than 0.2 m/s. Patients responded positively in gait function regardless of variables gender, age, aetiology (hemorrhagic/ischemic), and affected hemisphere. The most robust and significant change was observed for patients in the FAC categories two and three. The therapy was well tolerated and no patients withdrew for factors related to the type or intensity of training. Eight-weeks of intensive rehabilitation including robotic and manual gait training was well tolerated by early stroke patients, and was associated with significant gains in function. Patients with mid-level gait dysfunction showed the most robust improvement following robotic training.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22045,""
"A Database of Gene-Environment Interactions Pertaining to Blood Lipid Traits, Cardiovascular Disease and Type 2 Diabetes","Lee, Lai, Ordovas, Parnell","https://doi.org/10.4172/2153-0602.1000106","20211021","PubMed","","As the role of the environment - diet, exercise, alcohol and tobacco use and sleep among others - is accorded a more prominent role in modifying the relationship between genetic variants and clinical measures of disease, consideration of gene-environment (GxE) interactions is a must. To facilitate incorporation of GxE interactions into single-gene and genome-wide association studies, we have compiled from the literature a database of GxE interactions relevant to nutrition, blood lipids, cardiovascular disease and type 2 diabetes. Over 550 such interactions have been incorporated into a single database, along with over 1430 instances where a lack of statistical significance was found. This database will serve as an important resource to researchers in genetics and nutrition in order to gain an understanding of which points in the human genome are sensitive to variations in diet, physical activity and alcohol use, among other lifestyle choices. Furthermore, this GxE database has been designed with future integration into a larger database of nutritional phenotypes in mind.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22046,""
"Building a robust, scalable and standards-driven infrastructure for secondary use of EHR data: the SHARPn project","Rea, Pathak, Savova, Oniki, Westberg, Beebe, Tao, Parker, Haug, Huff, Chute","https://doi.org/10.1016/j.jbi.2012.01.009","20130319","PubMed","Algorithms; Clinical Coding; Database Management Systems; Diabetes Mellitus; Electronic Health Records; Genomics; Humans; Meaningful Use; Medical Informatics Applications; Models, Theoretical; Natural Language Processing; Phenotype","The Strategic Health IT Advanced Research Projects (SHARP) Program, established by the Office of the National Coordinator for Health Information Technology in 2010 supports research findings that remove barriers for increased adoption of health IT. The improvements envisioned by the SHARP Area 4 Consortium (SHARPn) will enable the use of the electronic health record (EHR) for secondary purposes, such as care process and outcomes improvement, biomedical research and epidemiologic monitoring of the nation's health. One of the primary informatics problem areas in this endeavor is the standardization of disparate health data from the nation's many health care organizations and providers. The SHARPn team is developing open source services and components to support the ubiquitous exchange, sharing and reuse or 'liquidity' of operational clinical data stored in electronic health records. One year into the design and development of the SHARPn framework, we demonstrated end to end data flow and a prototype SHARPn platform, using thousands of patient electronic records sourced from two large healthcare organizations: Mayo Clinic and Intermountain Healthcare. The platform was deployed to (1) receive source EHR data in several formats, (2) generate structured data from EHR narrative text, and (3) normalize the EHR data using common detailed clinical models and Consolidated Health Informatics standard terminologies, which were (4) accessed by a phenotyping service using normalized data specifications. The architecture of this prototype SHARPn platform is presented. The EHR data throughput demonstration showed success in normalizing native EHR data, both structured and narrative, from two independent organizations and EHR systems. Based on the demonstration, observed challenges for standardization of EHR data for interoperable secondary use are discussed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22047,""
"Adaptation of a clustered lumpy background model for task-based image quality assessment in x-ray phase-contrast mammography","Zysk, Brankov, Wernick, Anastasio","https://doi.org/10.1118/1.3676183","20120501","PubMed","Algorithms; Artificial Intelligence; Breast Neoplasms; Female; Humans; Mammography; Pattern Recognition, Automated; Radiographic Image Enhancement; Radiographic Image Interpretation, Computer-Assisted; Reproducibility of Results; Sensitivity and Specificity","Since the introduction of clinical x-ray phase-contrast mammography (PCM), a technique that exploits refractive-index variations to create edge enhancement at tissue boundaries, a number of optimization studies employing physical image-quality metrics have been performed. Ideally, task-based assessment of PCM would have been conducted with human readers. These studies have been limited, however, in part due to the large parameter-space of PCM system configurations and the difficulty of employing expert readers for large-scale studies. It has been proposed that numerical observers can be used to approximate the statistical performance of human readers, thus enabling the study of task-based performance over a large parameter-space. Methods are presented for task-based image quality assessment of PCM images with a numerical observer, the most significant of which is an adapted lumpy background from the conventional mammography literature that accounts for the unique wavefield propagation physics of PCM image formation and will be used with a numerical observer to assess image quality. These methods are demonstrated by performing a PCM task-based image quality study using a numerical observer. This study employs a signal-known-exactly, background-known-statistically Bayesian ideal observer method to assess the detectability of a calcification object in PCM images when the anode spot size and calcification diameter are varied. The first realistic model for the structured background in PCM images has been introduced. A numerical study demonstrating the use of this background model has compared PCM and conventional mammography detection of calcification objects. The study data confirm the strong PCM calcification detectability dependence on anode spot size. These data can be used to balance the trade-off between enhanced image quality and the potential for motion artifacts that comes with use of a reduced spot size and increased exposure time. A method has been presented for the incorporation of structured breast background data into task-based numerical observer assessment of PCM images. The method adapts conventional background simulation techniques to the wavefield propagation physics necessary for PCM imaging. This method is demonstrated with a simple detection task.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22048,""
"Importance of multi-modal approaches to effectively identify cataract cases from electronic health records","Peissig, Rasmussen, Berg, Linneman, McCarty, Waudby, Chen, Denny, Wilke, Pathak, Carrell, Kho, Starren","https://doi.org/10.1136/amiajnl-2011-000456","20120511","PubMed","Adult; Cataract; Databases, Factual; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Phenotype","There is increasing interest in using electronic health records (EHRs) to identify subjects for genomic association studies, due in part to the availability of large amounts of clinical data and the expected cost efficiencies of subject identification. We describe the construction and validation of an EHR-based algorithm to identify subjects with age-related cataracts. We used a multi-modal strategy consisting of structured database querying, natural language processing on free-text documents, and optical character recognition on scanned clinical images to identify cataract subjects and related cataract attributes. Extensive validation on 3657 subjects compared the multi-modal results to manual chart review. The algorithm was also implemented at participating electronic MEdical Records and GEnomics (eMERGE) institutions. An EHR-based cataract phenotyping algorithm was successfully developed and validated, resulting in positive predictive values (PPVs) &gt;95%. The multi-modal approach increased the identification of cataract subject attributes by a factor of three compared to single-mode approaches while maintaining high PPV. Components of the cataract algorithm were successfully deployed at three other institutions with similar accuracy. A multi-modal strategy incorporating optical character recognition and natural language processing may increase the number of cases identified while maintaining similar PPVs. Such algorithms, however, require that the needed information be embedded within clinical documents. We have demonstrated that algorithms to identify and characterize cataracts can be developed utilizing data collected via the EHR. These algorithms provide a high level of accuracy even when implemented across multiple EHRs and institutional boundaries.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22049,""
"Validation Study of Automated Dermal/Epidermal Junction Localization Algorithm in Reflectance Confocal Microscopy Images of Skin","Kurugol, Rajadhyaksha, Dy, Brooks","https://doi.org/10.1117/12.909227","20211021","PubMed","classification; confocal reflectance microscopy; image analysis; skin","Reflectance confocal microscopy (RCM) has seen increasing clinical application for noninvasive diagnosis of skin cancer. Identifying the location of the dermal-epidermal junction (DEJ) in the image stacks is key for effective clinical imaging. For example, one clinical imaging procedure acquires a dense stack of 0.5Ãƒâ€”0.5mm FOV images and then, after manual determination of DEJ depth, collects a 5Ãƒâ€”5mm mosaic at that depth for diagnosis. However, especially in lightly pigmented skin, RCM images have low contrast at the DEJ which makes repeatable, objective visual identification challenging. We have previously published proof of concept for an automated algorithm for DEJ detection in both highly- and lightly-pigmented skin types based on sequential feature segmentation and classification. In lightly-pigmented skin the change of skin texture with depth was detected by the algorithm and used to locate the DEJ. Here we report on further validation of our algorithm on a more extensive collection of 24 image stacks (15 fair skin, 9 dark skin). We compare algorithm performance against classification by three clinical experts. We also evaluate inter-expert consistency among the experts. The average correlation across experts was 0.81 for lightly pigmented skin, indicating the difficulty of the problem. The algorithm achieved epidermis/dermis misclassification rates smaller than 10% (based on 25Ãƒâ€”25 mm tiles) and average distance from the expert labeled boundaries of ~6.4 ÃŽÂ¼m for fair skin and ~5.3 ÃŽÂ¼m for dark skin, well within average cell size and less than 2x the instrument resolution in the optical axis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22050,""
"A system for coreference resolution for the clinical narrative","Zheng, Chapman, Miller, Lin, Crowley, Savova","https://doi.org/10.1136/amiajnl-2011-000599","20121220","PubMed","Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Narration; Natural Language Processing; Semantics; Support Vector Machine; United States","To research computational methods for coreference resolution in the clinical narrative and build a system implementing the best methods. The Ontology Development and Information Extraction corpus annotated for coreference relations consists of 7214 coreferential markables, forming 5992 pairs and 1304 chains. We trained classifiers with semantic, syntactic, and surface features pruned by feature selection. For the three system components--for the resolution of relative pronouns, personal pronouns, and noun phrases--we experimented with support vector machines with linear and radial basis function (RBF) kernels, decision trees, and perceptrons. Evaluation of algorithms and varied feature sets was performed using standard metrics. The best performing combination is support vector machines with an RBF kernel and all features (MUC score=0.352, B(3)=0.690, CEAF=0.486, BLANC=0.596) outperforming a traditional decision tree baseline. The application showed good performance similar to performance on general English text. The main error source was sentence distances exceeding a window of 10 sentences between markables. A possible solution to this problem is hinted at by the fact that coreferent markables sometimes occurred in predictable (although distant) note sections. Another system limitation is failure to fully utilize synonymy and ontological knowledge. Future work will investigate additional ways to incorporate syntactic features into the coreference problem. We investigated computational methods for coreference resolution in the clinical narrative. The best methods are released as modules of the open source Clinical Text Analysis and Knowledge Extraction System and Ontology Development and Information Extraction platforms.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22051,""
"Systematic review of the neural basis of social cognition in patients with mood disorders","Cusi, Nazarov, Holshausen, Macqueen, McKinnon","https://doi.org/10.1503/jpn.100179","20120816","PubMed","Affect; Age Factors; Bipolar Disorder; Cognition; Comorbidity; Cost of Illness; Depressive Disorder, Major; Facial Expression; Humans; Magnetic Resonance Imaging; Mood Disorders; Psychotherapy; Social Behavior; Theory of Mind","This review integrates neuroimaging studies of 2 domains of social cognition--emotion comprehension and theory of mind (ToM)--in patients with major depressive disorder and bipolar disorder. The influence of key clinical and method variables on patterns of neural activation during social cognitive processing is also examined. Studies were identified using PsycINFO and PubMed (January 1967 to May 2011). The search terms were ""fMRI,"" ""emotion comprehension,"" ""emotion perception,"" ""affect comprehension,"" ""affect perception,"" ""facial expression,"" ""prosody,"" ""theory of mind,"" ""mentalizing"" and ""empathy"" in combination with ""major depressive disorder,"" ""bipolar disorder,"" ""major depression,"" ""unipolar depression,"" ""clinical depression"" and ""mania."" Taken together, neuroimaging studies of social cognition in patients with mood disorders reveal enhanced activation in limbic and emotion-related structures and attenuated activity within frontal regions associated with emotion regulation and higher cognitive functions. These results reveal an overall lack of inhibition by higher-order cognitive structures on limbic and emotion-related structures during social cognitive processing in patients with mood disorders. Critically, key variables, including illness burden, symptom severity, comorbidity, medication status and cognitive load may moderate this pattern of neural activation. Studies that did not include control tasks or a comparator group were included in this review. Further work is needed to examine the contribution of key moderator variables and to further elucidate the neural networks underlying altered social cognition in patients with mood disorders. The neural networks under lying higher-order social cognitive processes, including empathy, remain unexplored in patients with mood disorders.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22052,""
"Automatic classification of mammography reports by BI-RADS breast tissue composition class","Percha, Nassif, Lipson, Burnside, Rubin","https://doi.org/10.1136/amiajnl-2011-000607","20130116","PubMed","Algorithms; Breast; Data Mining; Female; Humans; Mammography; Natural Language Processing; Radiology Information Systems; Risk Assessment; Sensitivity and Specificity; United States","Because breast tissue composition partially predicts breast cancer risk, classification of mammography reports by breast tissue composition is important from both a scientific and clinical perspective. A method is presented for using the unstructured text of mammography reports to classify them into BI-RADS breast tissue composition categories. An algorithm that uses regular expressions to automatically determine BI-RADS breast tissue composition classes for unstructured mammography reports was developed. The algorithm assigns each report to a single BI-RADS composition class: 'fatty', 'fibroglandular', 'heterogeneously dense', 'dense', or 'unspecified'. We evaluated its performance on mammography reports from two different institutions. The method achieves &gt;99% classification accuracy on a test set of reports from the Marshfield Clinic (Wisconsin) and Stanford University. Since large-scale studies of breast cancer rely heavily on breast tissue composition information, this method could facilitate this research by helping mine large datasets to correlate breast composition with other covariates.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22053,""
"A hybrid knowledge-based and data-driven approach to identifying semantically similar concepts","Pivovarov, Elhadad","https://doi.org/10.1016/j.jbi.2012.01.002","20121015","PubMed","Area Under Curve; Chronic Disease; Data Mining; Humans; Kidney Diseases; Knowledge Bases; Natural Language Processing; Semantics; Systematized Nomenclature of Medicine","An open research question when leveraging ontological knowledge is when to treat different concepts separately from each other and when to aggregate them. For instance, concepts for the terms ""paroxysmal cough"" and ""nocturnal cough"" might be aggregated in a kidney disease study, but should be left separate in a pneumonia study. Determining whether two concepts are similar enough to be aggregated can help build better datasets for data mining purposes and avoid signal dilution. Quantifying the similarity among concepts is a difficult task, however, in part because such similarity is context-dependent. We propose a comprehensive method, which computes a similarity score for a concept pair by combining data-driven and ontology-driven knowledge. We demonstrate our method on concepts from SNOMED-CT and on a corpus of clinical notes of patients with chronic kidney disease. By combining information from usage patterns in clinical notes and from ontological structure, the method can prune out concepts that are simply related from those which are semantically similar. When evaluated against a list of concept pairs annotated for similarity, our method reaches an AUC (area under the curve) of 92%.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22054,""
"Associating Drugs, Targets and Clinical Outcomes into an Integrated Network Affords a New Platform for Computer-Aided Drug Repurposing","Oprea, Nielsen, Ursu, Yang, Taboureau, Mathias, Kouskoumvekaki, Sklar, Bologa","https://doi.org/10.1002/minf.201100023","20211021","PubMed","","Finding new uses for old drugs is a strategy embraced by the pharmaceutical industry, with increasing participation from the academic sector. Drug repurposing efforts focus on identifying novel modes of action, but not in a systematic manner. With intensive data mining and curation, we aim to apply bio- and cheminformatics tools using the DRUGS database, containing 3,837 unique small molecules annotated on 1,750 proteins. These are likely to serve as drug targets and antitargets (i.e., associated with side effects, SE). The academic community, the pharmaceutical sector and clinicians alike could benefit from an integrated, semantic-web compliant computer-aided drug repurposing (CADR) effort, one that would enable deep data mining of associations between approved drugs (D), targets (T), clinical outcomes (CO) and SE. We report preliminary results from text mining and multivariate statistics, based on 7,684 approved drug labels, ADL (Dailymed) via text mining. From the ADL corresponding to 988 unique drugs, the ""adverse reactions"" section was mapped onto 174 SE, then clustered via principal component analysis into a 5x5 self-organizing map that was integrated into a Cytoscape network of SE-D-T-CO. This type of data can be used to streamline drug repurposing and may result in novel insights that can lead to the identification of novel drug actions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22055,""
"Evidence on the human health effects of low-level methylmercury exposure","Karagas, Choi, Oken, Horvat, Schoeny, Kamai, Cowell, Grandjean, Korrick","https://doi.org/10.1289/ehp.1104494","20121001","PubMed","Animals; Biomarkers; Cardiovascular Diseases; Child; Child Development; Environmental Exposure; Epidemiologic Studies; Fetal Development; Fishes; Humans; Immune System; Infant; Methylmercury Compounds; Nervous System","Methylmercury (MeHg) is a known neuro-toxicant. Emerging evidence indicates it may have adverse effects on the neuro-logic and other body systems at common low levels of exposure. Impacts of MeHg exposure could vary by individual susceptibility or be confounded by beneficial nutrients in fish containing MeHg. Despite its global relevance, synthesis of the available literature on low-level MeHg exposure has been limited. We undertook a synthesis of the current knowledge on the human health effects of low-level MeHg exposure to provide a basis for future research efforts, risk assessment, and exposure remediation policies worldwide. We reviewed the published literature for original human epidemiologic research articles that reported a direct biomarker of mercury exposure. To focus on high-quality studies and those specifically on low mercury exposure, we excluded case series, as well as studies of populations with unusually high fish consumption (e.g., the Seychelles), marine mammal consumption (e.g., the Faroe Islands, circumpolar, and other indigenous populations), or consumption of highly contaminated fish (e.g., gold-mining regions in the Amazon). Recent evidence raises the possibility of effects of low-level MeHg exposure on fetal growth among susceptible subgroups and on infant growth in the first 2 years of life. Low-level effects of MeHg on neuro-logic outcomes may differ by age, sex, and timing of exposure. No clear pattern has been observed for cardio-vascular disease (CVD) risk across populations or for specific CVD end points. For the few studies evaluating immunologic effects associated with MeHg, results have been inconsistent. Studies targeted at identifying potential mechanisms of low-level MeHg effects and characterizing individual susceptibility, sexual dimorphism, and non-linearity in dose response would help guide future prevention, policy, and regulatory efforts surrounding MeHg exposure.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22056,""
"A multi-classifier based guideline sentence classification system","Song, Kim, Park, Lee","https://doi.org/10.4258/hir.2011.17.4.224","20120823","PubMed","Data Mining; Knowledge Bases; Natural Language Processing","An efficient clinical process guideline (CPG) modeling service was designed that uses an enhanced intelligent search protocol. The need for a search system arises from the requirement for CPG models to be able to adapt to dynamic patient contexts, allowing them to be updated based on new evidence that arises from medical guidelines and papers. A sentence category classifier combined with the AdaBoost.M1 algorithm was used to evaluate the contribution of the CPG to the quality of the search mechanism. Three annotators each tagged 340 sentences hand-chosen from the Joint National Committee on Prevention, Detection, Evaluation, and Treatment of High Blood Pressure (JNC7) clinical guideline. The three annotators then carried out cross-validations of the tagged corpus. A transformation function is also used that extracts a predefined set of structural feature vectors determined by analyzing the sentential instance in terms of the underlying syntactic structures and phrase-level co-occurrences that lie beneath the surface of the lexical generation event. The additional sub-filtering using a combination of multi-classifiers was found to be more effective than a single conventional Term Frequency-Inverse Document Frequency (TF-IDF)-based search system in pinpointing the page containing or adjacent to the guideline information. We found that transformation has the advantage of exploiting the structural and underlying features which go unseen by the bag-of-words (BOW) model. We also realized that integrating a sentential classifier with a TF-IDF-based search engine enhances the search process by maximizing the probability of the automatically presented relevant information required in the context generated by the guideline authoring environment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22057,""
"Fusion with language models improves spelling accuracy for ERP-based brain computer interface spellers","Orhan, Erdogmus, Roark, Purwar, Hild, Oken, Nezamfar, Fried-Oken","https://doi.org/10.1109/IEMBS.2011.6091429","20120618","PubMed","Brain; Computer Simulation; Electroencephalography; Evoked Potentials, Visual; Humans; Language; Models, Theoretical; Natural Language Processing; Task Performance and Analysis; User-Computer Interface; Writing","Event related potentials (ERP) corresponding to a stimulus in electroencephalography (EEG) can be used to detect the intent of a person for brain computer interfaces (BCI). This paradigm is widely utilized to build letter-by-letter text input systems using BCI. Nevertheless using a BCI-typewriter depending only on EEG responses will not be sufficiently accurate for single-trial operation in general, and existing systems utilize many-trial schemes to achieve accuracy at the cost of speed. Hence incorporation of a language model based prior or additional evidence is vital to improve accuracy and speed. In this paper, we study the effects of Bayesian fusion of an n-gram language model with a regularized discriminant analysis ERP detector for EEG-based BCIs. The letter classification accuracies are rigorously evaluated for varying language model orders as well as number of ERP-inducing trials. The results demonstrate that the language models contribute significantly to letter classification accuracy. Specifically, we find that a BCI-speller supported by a 4-gram language model may achieve the same performance using 3-trial ERP classification for the initial letters of the words and using single trial ERP classification for the subsequent ones. Overall, fusion of evidence from EEG and language models yields a significant opportunity to increase the word rate of a BCI based typing system.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22058,""
"Automated choroidal segmentation of 1060 nm OCT in healthy and pathologic eyes using a statistical model","KajiÃ„â€¡, Esmaeelpour, PovaÃ…Â¾ay, Marshall, Rosin, Drexler","https://doi.org/10.1364/BOE.3.000086","20120313","PubMed","(100.0100) Image processing; (100.3008) Image recognition, algorithms and filters; (170.4500) Optical coherence tomography; (170.4580) Optical diagnostics for medicine","A two stage statistical model based on texture and shape for fully automatic choroidal segmentation of normal and pathologic eyes obtained by a 1060 nm optical coherence tomography (OCT) system is developed. A novel dynamic programming approach is implemented to determine location of the retinal pigment epithelium/ Bruch's membrane /choriocapillaris (RBC) boundary. The choroid-sclera interface (CSI) is segmented using a statistical model. The algorithm is robust even in presence of speckle noise, low signal (thick choroid), retinal pigment epithelium (RPE) detachments and atrophy, drusen, shadowing and other artifacts. Evaluation against a set of 871 manually segmented cross-sectional scans from 12 eyes achieves an average error rate of 13%, computed per tomogram as a ratio of incorrectly classified pixels and the total layer surface. For the first time a fully automatic choroidal segmentation algorithm is successfully applied to a wide range of clinical volumetric OCT data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22059,""
"Computerized analysis of mammographic parenchymal patterns on a large clinical dataset of full-field digital mammograms: robustness study with two high-risk datasets","Li, Giger, Lan, Bancroft Brown, MacMahon, Mussman, Olopade, Sennett","https://doi.org/10.1007/s10278-012-9452-z","20130307","PubMed","Adult; Age Distribution; Aged; Bayes Theorem; Breast Neoplasms; Confidence Intervals; Databases, Factual; Evaluation Studies as Topic; Female; Genes, BRCA2; Genetic Predisposition to Disease; Humans; Incidence; Mammography; Middle Aged; ROC Curve; Radiographic Image Enhancement; Radiographic Image Interpretation, Computer-Assisted; Retrospective Studies; Risk Assessment; Risk Management; Young Adult","The purpose of this study was to demonstrate the robustness of our prior computerized texture analysis method for breast cancer risk assessment, which was developed initially on a limited dataset of screen-film mammograms. This current study investigated the robustness by (1) evaluating on a large clinical dataset, (2) using full-field digital mammograms (FFDM) as opposed to screen-film mammography, and (3) incorporating analyses over two types of high-risk patient sets, as well as patients at low risk for breast cancer. The evaluation included the analyses on the parenchymal patterns of women at high risk of developing of breast cancer, including both BRCA1/2 gene mutation carriers and unilateral cancer patients, and of women at low risk of developing breast cancer. A total of 456 cases, including 53 women with BRCA1/2 gene mutations, 75 women with unilateral cancer, and 328 low-risk women, were retrospectively collected under an institutional review board approved protocol. Regions-of-interest (ROIs), were manually selected from the central breast region immediately behind the nipple. These ROIs were subsequently used in computerized feature extraction to characterize the mammographic parenchymal patterns in the images. Receiver operating characteristic analysis was used to assess the performance of the computerized texture features in the task of distinguishing between high-risk and low-risk subjects. In a round robin evaluation on the FFDM dataset with Bayesian artificial neural network analysis, AUC values of 0.82 (95% confidence interval [0.75, 0.88]) and 0.73 (95% confidence interval [0.67, 0.78]) were obtained between BRCA1/2 gene mutation carriers and low-risk women, and between unilateral cancer and low-risk women, respectively. These results from computerized texture analysis on digital mammograms demonstrated that high-risk and low-risk women have different mammographic parenchymal patterns. On this large clinical dataset, we validated our methods for quantitative analyses of mammographic patterns on FFDM, statistically demonstrating again that women at high risk tend to have dense breasts with coarse and low-contrast texture patterns.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22060,""
"Automated identification of extreme-risk events in clinical incident reports","Ong, Magrabi, Coiera","https://doi.org/10.1136/amiajnl-2011-000562","20130802","PubMed","Artificial Intelligence; Bayes Theorem; Humans; Medical Errors; Risk Management; Support Vector Machine","To explore the feasibility of using statistical text classification to automatically detect extreme-risk events in clinical incident reports. Statistical text classifiers based on NaÃƒÂ¯ve Bayes and Support Vector Machine (SVM) algorithms were trained and tested on clinical incident reports to automatically detect extreme-risk events, defined by incidents that satisfy the criteria of Severity Assessment Code (SAC) level 1. For this purpose, incident reports submitted to the Advanced Incident Management System by public hospitals from one Australian region were used. The classifiers were evaluated on two datasets: (1) a set of reports with diverse incident types (n=120); (2) a set of reports associated with patient misidentification (n=166). Results were assessed using accuracy, precision, recall, F-measure, and area under the curve (AUC) of receiver operating characteristic curves. The classifiers performed well on both datasets. In the multi-type dataset, SVM with a linear kernel performed best, identifying 85.8% of SAC level 1 incidents (precision=0.88, recall=0.83, F-measure=0.86, AUC=0.92). In the patient misidentification dataset, 96.4% of SAC level 1 incidents were detected when SVM with linear, polynomial or radial-basis function kernel was used (precision=0.99, recall=0.94, F-measure=0.96, AUC=0.98). NaÃƒÂ¯ve Bayes showed reasonable performance, detecting 80.8% of SAC level 1 incidents in the multi-type dataset and 89.8% of SAC level 1 patient misidentification incidents. Overall, higher prediction accuracy was attained on the specialized dataset, compared with the multi-type dataset. Text classification techniques can be applied effectively to automate the detection of extreme-risk events in clinical incident reports.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22061,""
"Automatic small bowel tumor diagnosis by using multi-scale wavelet-based analysis in wireless capsule endoscopy images","Barbosa, Roupar, Ramos, Tavares, Lima","https://doi.org/10.1186/1475-925X-11-3","20120523","PubMed","Capsule Endoscopy; Humans; Image Interpretation, Computer-Assisted; Intestinal Neoplasms; Models, Statistical; Neural Networks, Computer; Reproducibility of Results; Sensitivity and Specificity; Video Recording; Wavelet Analysis","Wireless capsule endoscopy has been introduced as an innovative, non-invasive diagnostic technique for evaluation of the gastrointestinal tract, reaching places where conventional endoscopy is unable to. However, the output of this technique is an 8 hours video, whose analysis by the expert physician is very time consuming. Thus, a computer assisted diagnosis tool to help the physicians to evaluate CE exams faster and more accurately is an important technical challenge and an excellent economical opportunity. The set of features proposed in this paper to code textural information is based on statistical modeling of second order textural measures extracted from co-occurrence matrices. To cope with both joint and marginal non-Gaussianity of second order textural measures, higher order moments are used. These statistical moments are taken from the two-dimensional color-scale feature space, where two different scales are considered. Second and higher order moments of textural measures are computed from the co-occurrence matrices computed from images synthesized by the inverse wavelet transform of the wavelet transform containing only the selected scales for the three color channels. The dimensionality of the data is reduced by using Principal Component Analysis. The proposed textural features are then used as the input of a classifier based on artificial neural networks. Classification performances of 93.1% specificity and 93.9% sensitivity are achieved on real data. These promising results open the path towards a deeper study regarding the applicability of this algorithm in computer aided diagnosis systems to assist physicians in their clinical practice.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22062,""
"Mining PeptideAtlas for biomarkers and therapeutics in human disease","Killcoyne, Deutsch, Boyle","https://doi.org/10.2174/138161212799277833","20120727","PubMed","Biomarkers; Data Mining; Databases, Protein; Humans; Mass Spectrometry; Peptides; Proteomics; Software","Mass spectrometry information has long offered the potential of discovering biomarkers that would enable clinicians to diagnose disease, and treat it with targeted therapies. PeptideAtlas currently provides access to large-scale spectra data and identification information. This data, and the generation of targeted peptide information, represents the first step in the process of locating disease biomarkers. Reaching the goal of clinical proteomics requires that this data be integrated with additional information from disease literature and genomic studies. Here we describe PeptideAtlas and associated methods for mining the data, as well as the software tools necessary to support large-scale integration and mining.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22063,""
"Influence of expert-dependent variability over the performance of noninvasive fibrosis assessment in patients with chronic hepatitis C by means of texture analysis","Vicas, Lupsor, Socaciu, Nedevschi, Badea","https://doi.org/10.1155/2012/346713","20120426","PubMed","Adult; Algorithms; Biopsy; Female; Hepacivirus; Hepatitis C, Chronic; Humans; Image Interpretation, Computer-Assisted; Liver Cirrhosis; Male; Middle Aged; Observer Variation; Prospective Studies; Ultrasonography","Texture analysis is viewed as a method to enhance the diagnosis power of classical B-mode ultrasound image. The present paper aims to evaluate and eliminate the dependence between the human expert and the performance of such a texture analysis system in predicting the cirrhosis in chronic hepatitis C patients. 125 consecutive chronic hepatitis C patients were included in this study. Ultrasound images were acquired from each patient and four human experts established regions of interest. Textural analysis tool was evaluated. The performance of this approach depends highly on the human expert that establishes the regions of interest (P &lt; 0.05). The novel algorithm that automatically establishes regions of interest can be compared with a trained radiologist. In classical form met in the literature, the noninvasive diagnosis through texture analysis has limited utility in clinical practice. The automatic ROI establishment tool is very useful in eliminating the expert-dependent variability.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22064,""
"Comparison of natural language processing biosurveillance methods for identifying influenza from encounter notes","Elkin, Froehling, Wahner-Roedler, Brown, Bailey","https://doi.org/10.7326/0003-4819-156-1-201201030-00003","20120213","PubMed","Adult; Analysis of Variance; Biosurveillance; Case-Control Studies; Centers for Disease Control and Prevention, U.S.; Communicable Diseases, Emerging; Disease Outbreaks; Female; Humans; Influenza, Human; Male; Models, Statistical; Natural Language Processing; Retrospective Studies; United States","An effective national biosurveillance system expedites outbreak recognition and facilitates response coordination at the federal, state, and local levels. The BioSense system, used at the Centers for Disease Control and Prevention, incorporates chief complaints but not data from the whole encounter note into its surveillance algorithms. To evaluate whether biosurveillance by using data from the whole encounter note is superior to that using data from the chief complaint field alone. 6-year retrospective case-control cohort study. Mayo Clinic, Rochester, Minnesota. 17,243 persons tested for influenza A or B virus between 1 January 2000 and 31 December 2006. The accuracy of a model based on signs and symptoms to predict influenza virus infection in patients with upper respiratory tract symptoms, and the ability of a natural language processing technique to identify definitional clinical features from free-text encounter notes. Surveillance based on the whole encounter note was superior to the chief complaint field alone. For the case definition used by surveillance of the whole encounter note, the normalized partial area under the receiver-operating characteristic curve (specificity, 0.1 to 0.4) for surveillance using the whole encounter note was 92.9% versus 70.3% for surveillance with the chief complaint field (difference, 22.6%; P &lt; 0.001). Comparison of the 2 models at the fixed specificity of 0.4 resulted in sensitivities of 89.0% and 74.4%, respectively (P &lt; 0.001). The relative risk for missing a true case of influenza was 2.3 by using the chief complaint field model. Participants were seen at 1 tertiary referral center. The cost of comprehensive biosurveillance monitoring was not studied. A biosurveillance model for influenza using the whole encounter note is more accurate than a model that uses only the chief complaint field. Because case-defining signs and symptoms of influenza are commonly available in health records, the investigators believe that the national strategy for biosurveillance should be changed to incorporate data from the whole health record. Centers for Disease Control and Prevention.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22065,""
"A personalized automated messaging system to improve adherence to prostate cancer screening: research protocol","Yuan, HÃƒÂ©bert, Johnson, Long, Vandewater, Vickers","https://doi.org/10.2196/resprot.2398","20130425","PubMed","Early Detection of Cancer; Prostatic Neoplasms; Text Messaging","Public adherence to cancer screening guidelines is poor. Patient confusion over multiple recommendations and modalities for cancer screening has been found to be a major barrier to screening adherence. Such problems will only increase as screening guidelines and timetables become individualized. We propose to increase compliance with cancer screening through two-way rich media mobile messaging based on personalized risk assessment. We propose to develop and test a product that will store algorithms required to personalize cancer screening in a central database managed by a rule-based workflow engine, and implemented via messaging to the patient's mobile phone. We will conduct a randomized controlled trial focusing on prostate cancer screening to study the hypothesis that mobile reminders improve adherence to screening guidelines. We will also explore a secondary hypothesis that patients who reply to the messaging reminders are more engaged and at lower risk of non-adherence. We will conduct a randomized controlled trial in a sample of males between 40 and 75 years (eligible for prostate cancer screening) who are willing to receive text messages, email, or automated voice messages. Participants will be recruited from a primary care clinic and asked to schedule prostate cancer screening at the clinic within the next 3 weeks. The intervention group will receive reminders and confirmation communications for making an appointment, keeping the appointment, and reporting the test results back to the investigators. Three outcomes will be evaluated: (1) the proportion of participants who make an appointment with a physician following a mobile message reminder, (2) the proportion of participants who keep the appointment, and (3) the proportion of participants who report the results of the screening (via text or Web). This is an ongoing project, supported by by a small business commercialization grant from the National Center for Advancing Translational Sciences of the National Institutes of Health. We believe that the use of centralized databases and text messaging could improve adherence with screening guidelines. Furthermore, we anticipate this method of increasing patient engagement could be applied to a broad range of health issues, both inside and outside of the context of cancer. This project will be an important first step in determining the feasibility of personalized text messaging to improve long-term adherence to screening recommendations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22066,""
"E-prescribing: history, issues, and potentials","Salmon, Jiang","https://doi.org/10.5210/ojphi.v4i3.4304","20130410","PubMed","CPOE; E-RX; EMR; Electronic Medical Records; Electronic Prescribing; Medicare incentivizing; Obamacare; PBMs; Pharmacists; Physicians; adverse drug reactions; clinical decision support; e-prescribing; implementation; pharmacy; pharmacy benefits managers; retail chain drugstores","Electronic-Prescribing, Computerized Prescribing, or E-RX has increased dramatically of late in the American health care system, a long overdue alternative to the written form for the almost five billion drug treatments annually. This paper examines the history and selected issues in the rise of E-RX by a review of salient literature, interviews, and field observations in Pharmacy. Pharmacies were early adopters of computerization for a variety of factors. The profession in its new corporate forms of chain drug stores and pharmacy benefits firms has sought efficiencies, profit enhancements, and clinical improvements through managed care strategies that rely upon data automation. E-RX seems to be a leading factor in overall physician acceptance of Electronic Medical Records (EMRs), although the Centers for Medicare and Medicaid (CMS) incentives seem to be the propelling force in acceptance. We conclude that greater research should be conducted by public health professionals to focus on resolutions to pharmaceutical use, safety, and cost escalation, which persist and remain dire following health reform.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22067,""
"Of possible cheminformatics futures","Oprea, Taboureau, Bologa","https://doi.org/10.1007/s10822-011-9535-9","20120723","PubMed","Artificial Intelligence; Chemistry; Drug Discovery; Genomics; Humans; Informatics; Systems Biology","For over a decade, cheminformatics has contributed to a wide array of scientific tasks from analytical chemistry and biochemistry to pharmacology and drug discovery; and although its contributions to decision making are recognized, the challenge is how it would contribute to faster development of novel, better products. Here we address the future of cheminformatics with primary focus on innovation. Cheminformatics developers often need to choose between ""mainstream"" (i.e., accepted, expected) and novel, leading-edge tools, with an increasing trend for open science. Possible futures for cheminformatics include the worst case scenario (lack of funding, no creative usage), as well as the best case scenario (complete integration, from systems biology to virtual physiology). As ""-omics"" technologies advance, and computer hardware improves, compounds will no longer be profiled at the molecular level, but also in terms of genetic and clinical effects. Among potentially novel tools, we anticipate machine learning models based on free text processing, an increased performance in environmental cheminformatics, significant decision-making support, as well as the emergence of robot scientists conducting automated drug discovery research. Furthermore, cheminformatics is anticipated to expand the frontiers of knowledge and evolve in an open-ended, extensible manner, allowing us to explore multiple research scenarios in order to avoid epistemological ""local information minimum trap"".","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22068,""
"Using Medical Text Extraction, Reasoning and Mapping System (MTERMS) to process medication information in outpatient clinical notes","Zhou, Plasek, Mahoney, Karipineni, Chang, Yan, Chang, Dimaggio, Goldman, Rocha","https://www.google.com/search?q=Using+Medical+Text+Extraction,+Reasoning+and+Mapping+System+(MTERMS)+to+process+medication+information+in+outpatient+clinical+notes.","20130225","PubMed","Ambulatory Care Facilities; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; RxNorm; Software; Vocabulary, Controlled","Clinical information is often coded using different terminologies, and therefore is not interoperable. Our goal is to develop a general natural language processing (NLP) system, called Medical Text Extraction, Reasoning and Mapping System (MTERMS), which encodes clinical text using different terminologies and simultaneously establishes dynamic mappings between them. MTERMS applies a modular, pipeline approach flowing from a preprocessor, semantic tagger, terminology mapper, context analyzer, and parser to structure inputted clinical notes. Evaluators manually reviewed 30 free-text and 10 structured outpatient clinical notes compared to MTERMS output. MTERMS achieved an overall F-measure of 90.6 and 94.0 for free-text and structured notes respectively for medication and temporal information. The local medication terminology had 83.0% coverage compared to RxNorm's 98.0% coverage for free-text notes. 61.6% of mappings between the terminologies are exact match. Capture of duration was significantly improved (91.7% vs. 52.5%) from systems in the third i2b2 challenge.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22069,""
"Leveraging rich annotations to improve learning of medical concepts from clinical free text","Yu, Farooq, Krishnapuram, Rao","https://www.google.com/search?q=Leveraging+rich+annotations+to+improve+learning+of+medical+concepts+from+clinical+free+text.","20130225","PubMed","Algorithms; Artificial Intelligence; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing","Information extraction from clinical free text is one of the key elements in medical informatics research. In this paper we propose a general framework to improve learning-based information extraction systems with the help of rich annotations (i.e., annotators provide the medical assertion as well as evidences that support the assertion). A special graphical interface was developed to facilitate the annotation process, and we show how to implement this framework with a state-of-the-art context-based question answering system. Empirical studies demonstrate that with about 10% longer annotation time, we can significantly improve the accuracy of the system. An approach to provide supporting evidence for test documents is also briefly discussed with promising preliminary results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22070,""
"Extracting and integrating data from entire electronic health records for detecting colorectal cancer cases","Xu, Fu, Shah, Chen, Peterson, Chen, Mani, Levy, Dai, Denny","https://www.google.com/search?q=Extracting+and+integrating+data+from+entire+electronic+health+records+for+detecting+colorectal+cancer+cases.","20130225","PubMed","Algorithms; Artificial Intelligence; Colorectal Neoplasms; Data Mining; Electronic Health Records; Humans; Natural Language Processing","Identification of a cohort of patients with specific diseases is an important step for clinical research that is based on electronic health records (EHRs). Informatics approaches combining structured EHR data, such as billing records, with narrative text data have demonstrated utility for such tasks. This paper describes an algorithm combining machine learning and natural language processing to detect patients with colorectal cancer (CRC) from entire EHRs at Vanderbilt University Hospital. We developed a general case detection method that consists of two steps: 1) extraction of positive CRC concepts from all clinical notes (document-level concept identification); and 2) determination of CRC cases using aggregated information from both clinical narratives and structured billing data (patient-level case determination). For each step, we compared performance of rule-based and machine-learning-based approaches. Using a manually reviewed data set containing 300 possible CRC patients (150 for training and 150 for testing), we showed that our method achieved F-measures of 0.996 for document level concept identification, and 0.93 for patient level case detection.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22071,""
"Detecting abbreviations in discharge summaries using machine learning methods","Wu, Rosenbloom, Denny, Miller, Mani, Giuse, Xu","https://www.google.com/search?q=Detecting+abbreviations+in+discharge+summaries+using+machine+learning+methods.","20130225","PubMed","Abbreviations as Topic; Algorithms; Artificial Intelligence; Decision Trees; Electronic Health Records; Humans; Natural Language Processing; Patient Discharge; Pattern Recognition, Automated; Support Vector Machine","Recognition and identification of abbreviations is an important, challenging task in clinical natural language processing (NLP). A comprehensive lexical resource comprised of all common, useful clinical abbreviations would have great applicability. The authors present a corpus-based method to create a lexical resource of clinical abbreviations using machine-learning (ML) methods, and tested its ability to automatically detect abbreviations from hospital discharge summaries. Domain experts manually annotated abbreviations in seventy discharge summaries, which were randomly broken into a training set (40 documents) and a test set (30 documents). We implemented and evaluated several ML algorithms using the training set and a list of pre-defined features. The subsequent evaluation using the test set showed that the Random Forest classifier had the highest F-measure of 94.8% (precision 98.8% and recall of 91.2%). When a voting scheme was used to combine output from various ML classifiers, the system achieved the highest F-measure of 95.7%.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22072,""
"It's about this and that: a description of anaphoric expressions in clinical text","Wang, Melton, Pakhomov","https://www.google.com/search?q=It's+about+this+and+that:+a+description+of+anaphoric+expressions+in+clinical+text.","20130225","PubMed","Electronic Health Records; Linguistics; Natural Language Processing","Although anaphoric expressions are very common in biomedical and clinical documents, little work has been done to systematically characterize their use in clinical text. Samples of 'it', 'this', and 'that' expressions occurring in inpatient clinical notes from four metropolitan hospitals were analyzed using a combination of semi-automated and manual annotation techniques. We developed a rule-based approach to filter potential non-referential expressions. A physician then manually annotated 1000 potential referential instances to determine referent status and the antecedent of each referent expression. A distributional analysis of the three referring expressions in the entire corpus of notes demonstrates a high prevalence of anaphora and large variance in distributions of referential expressions with different notes. Our results confirm that anaphoric expressions are common in clinical texts. Effective co-reference resolution with anaphoric expressions remains an important challenge in medical natural language processing research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22073,""
"Identifying symptom groups from Emergency Department presenting complaint free text using SNOMED CT","Wagholikar, Lawley, Hansen, Chu","https://www.google.com/search?q=Identifying+symptom+groups+from+Emergency+Department+presenting+complaint+free+text+using+SNOMED+CT.","20130225","PubMed","Abdominal Pain; Chest Pain; Diagnosis, Differential; Dyspnea; Emergency Service, Hospital; Humans; Systematized Nomenclature of Medicine; Wounds and Injuries","Patients presenting to Emergency Departments may be categorised into different symptom groups for the purpose of research and quality improvement. The grouping is challenging due to the variability in the way presenting complaints are recorded by clinical staff. This work proposes analysis of the presenting complaint free-text using the semantics encoded in the SNOMED CT ontology. This work demonstrates a validated prototype system that can classify unstructured free-text narratives into patient's symptom group. A rule-based mechanism was developed using variety of keywords to identify the patient's symptom group. The system was validated against the manual identification of the symptom groups by two expert clinical research nurses on 794 patient presentations from six participating hospitals. The comparison of system results with one clinical research nurse showed 99.3% sensitivity; 80.0% specificity and 0.9 F-score for identifying ""chest pain"" symptom group.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22074,""
"Qualitative analysis of workflow modifications used to generate the reference standard for the 2010 i2b2/VA challenge","South, Shen, Barrus, DuVall, Uzuner, Weir","https://www.google.com/search?q=Qualitative+analysis+of+workflow+modifications+used+to+generate+the+reference+standard+for+the+2010+i2b2/VA+challenge.","20130225","PubMed","Humans; Information Storage and Retrieval; Natural Language Processing; Reference Standards; Translational Medical Research; Workflow","The Department of Veterans Affairs (VA) and the Informatics for Integrating Biology and the Bedside (i2b2) team partnered to generate the reference standard for the 2010 i2b2/VA challenge task on concept extraction, assertion classification, and relation classification. The purpose of this paper is to report an in-depth qualitative analysis of the experience and perceptions of human annotators for these tasks. Transcripts of semi-structured interviews were analyzed using qualitative methods to identify key constructs and themes related to these annotation tasks. Interventions were embedded with these tasks using pre-annotation of clinical concepts and a modified annotation workflow. From the human perspective, annotation tasks involve an inherent conflict between bias, accuracy, and efficiency. This analysis deepens understanding of the biases, complexities and impact of variations in the annotation process that may affect annotation task reliability and reference standard validity that are generalizable for other similar large-scale clinical corpus annotation projects.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22075,""
"Automated non-alphanumeric symbol resolution in clinical texts","Moon, Pakhomov, Ryan, Melton","https://www.google.com/search?q=Automated+non-alphanumeric+symbol+resolution+in+clinical+texts.","20130225","PubMed","Artificial Intelligence; Bayes Theorem; Decision Trees; Electronic Health Records; Language; Natural Language Processing; Pilot Projects; Support Vector Machine","Although clinical texts contain many symbols, relatively little attention has been given to symbol resolution by medical natural language processing (NLP) researchers. Interpreting the meaning of symbols may be viewed as a special case of Word Sense Disambiguation (WSD). One thousand instances of four common non-alphanumeric symbols ('+', '-', '/', and '#') were randomly extracted from a clinical document repository and annotated by experts. The symbols and their surrounding context, in addition to bag-of-Words (BoW), and heuristic rules were evaluated as features for the following classifiers: NaÃƒÂ¯ve Bayes, Support Vector Machine, and Decision Tree, using 10-fold cross-validation. Accuracies for '+', '-', '/', and '#' were 80.11%, 80.22%, 90.44%, and 95.00% respectively, with NaÃƒÂ¯ve Bayes. While symbol context contributed the most, BoW was also helpful for disambiguation of some symbols. Symbol disambiguation with supervised techniques can be implemented with reasonable accuracy as a module for medical NLP systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22076,""
"Determining word sequence variation patterns in clinical documents using multiple sequence alignment","Meng, Morioka, El-Saden","https://www.google.com/search?q=Determining+word+sequence+variation+patterns+in+clinical+documents+using+multiple+sequence+alignment.","20130225","PubMed","Algorithms; Language; Natural Language Processing; Pattern Recognition, Automated; Semantics","Sentences and phrases that represent a certain meaning often exhibit patterns of variation where they differ from a basic structural form by one or two words. We present an algorithm that utilizes multiple sequence alignments (MSAs) to generate a representation of groups of phrases that possess the same semantic meaning but also share in common the same basic word sequence structure. The MSA enables the determination not only of the words that compose the basic word sequence, but also of the locations within the structure that exhibit variation. The algorithm can be utilized to generate patterns of text sequences that can be used as the basis for a pattern-based classifier, as a starting point to bootstrap the pattern building process for a regular expression-based classifiers, or serve to reveal the variation characteristics of sentences and phrases within a particular domain.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22077,""
"Using UMLS lexical resources to disambiguate abbreviations in clinical text","Kim, Hurdle, Meystre","https://www.google.com/search?q=Using+UMLS+lexical+resources+to+disambiguate+abbreviations+in+clinical+text.","20130225","PubMed","Abbreviations as Topic; Artificial Intelligence; Medical Records; Natural Language Processing; Unified Medical Language System","Clinical text is rich in acronyms and abbreviations, and they are highly ambiguous. As a pre-processing step before subsequent NLP analysis, we are developing and evaluating clinical abbreviation disambiguation methods. The evaluation of two sequential steps, the detection and the disambiguation of abbreviations, is reported here, for various types of clinical notes. For abbreviations detection, our result indicated the SPECIALIST Lexicon LRABR needed to be revised for better abbreviation detection. Our semi-supervised method using generated training data based on expanded form matching for 12 frequent abbreviations in our clinical notes reached over 90% accuracy in five-fold cross validation and unsupervised approach produced comparable results with the semi-supervised methods.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22078,""
"The Knowledge Program: an innovative, comprehensive electronic data capture system and warehouse","Katzan, Speck, Dopler, Urchek, Bielawski, Dunphy, Jehi, Bae, Parchman","https://www.google.com/search?q=The+Knowledge+Program:+an+innovative,+comprehensive+electronic+data+capture+system+and+warehouse.","20130225","PubMed","Electronic Health Records; Health Status; Humans; Information Storage and Retrieval; Knowledge Bases","Data contained in the electronic health record (EHR) present a tremendous opportunity to improve quality-of-care and enhance research capabilities. However, the EHR is not structured to provide data for such purposes: most clinical information is entered as free text and content varies substantially between providers. Discrete information on patients' functional status is typically not collected. Data extraction tools are often unavailable. We have developed the Knowledge Program (KP), a comprehensive initiative to improve the collection of discrete clinical information into the EHR and the retrievability of data for use in research, quality, and patient care. A distinct feature of the KP is the systematic collection of patient-reported outcomes, which is captured discretely, allowing more refined analyses of care outcomes. The KP capitalizes on features of the Epic EHR and utilizes an external IT infrastructure distinct from Epic for enhanced functionality. Here, we describe the development and implementation of the KP.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22079,""
"Automatic computation of CHA2DS2-VASc score: information extraction from clinical texts for thromboembolism risk assessment","Grouin, DelÃƒÂ©ger, Rosier, Temal, Dameron, Van Hille, Burgun, Zweigenbaum","https://www.google.com/search?q=Automatic+computation+of+CHA2DS2-VASc+score:+information+extraction+from+clinical+texts+for+thromboembolism+risk+assessment.","20130225","PubMed","Atrial Fibrillation; Cardiology; Electronic Health Records; Humans; Language; Natural Language Processing; Risk Assessment; Stroke; Thromboembolism","The CHA2DS2-VASc score is a 10-point scale which allows cardiologists to easily identify potential stroke risk for patients with non-valvular fibrillation. In this article, we present a system based on natural language processing (lexicon and linguistic modules), including negation and speculation handling, which extracts medical concepts from French clinical records and uses them as criteria to compute the CHA2DS2-VASc score. We evaluate this system by comparing its computed criteria with those obtained by human reading of the same clinical texts, and by assessing the impact of the observed differences on the resulting CHA2DS2-VASc scores. Given 21 patient records, 168 instances of criteria were computed, with an accuracy of 97.6%, and the accuracy of the 21 CHA2DS2-VASc scores was 85.7%. All differences in scores trigger the same alert, which means that system performance on this test set yields similar results to human reading of the texts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22080,""
"Part-of-speech tagging for clinical text: wall or bridge between institutions?","Fan, Prasad, Yabut, Loomis, Zisook, Mattison, Huang","https://www.google.com/search?q=Part-of-speech+tagging+for+clinical+text:+wall+or+bridge+between+institutions?","20130225","PubMed","Electronic Health Records; Linguistics; Medical Record Linkage; Medical Records Systems, Computerized; Natural Language Processing","Part-of-speech (POS) tagging is a fundamental step required by various NLP systems. The training of a POS tagger relies on sufficient quality annotations. However, the annotation process is both knowledge-intensive and time-consuming in the clinical domain. A promising solution appears to be for institutions to share their annotation efforts, and yet there is little research on associated issues. We performed experiments to understand how POS tagging performance would be affected by using a pre-trained tagger versus raw training data across different institutions. We manually annotated a set of clinical notes at Kaiser Permanente Southern California (KPSC) and a set from the University of Pittsburg Medical Center (UPMC), and trained/tested POS taggers with intra- and inter-institution settings. The cTAKES POS tagger was also included in the comparison to represent a tagger partially trained from the notes of a third institution, Mayo Clinic at Rochester. Intra-institution 5-fold cross-validation estimated an accuracy of 0.953 and 0.945 on the KPSC and UPMC notes respectively. Trained purely on KPSC notes, the accuracy was 0.897 when tested on UPMC notes. Trained purely on UPMC notes, the accuracy was 0.904 when tested on KPSC notes. Applying the cTAKES tagger pre-trained with Mayo Clinic's notes, the accuracy was 0.881 on KPSC notes and 0.883 on UPMC notes. After adding UPMC annotations to KPSC training data, the average accuracy on tested KPSC notes increased to 0.965. After adding KPSC annotations to UPMC training data, the average accuracy on tested UPMC notes increased to 0.953. The results indicated: first, the performance of pre-trained POS taggers dropped about 5% when applied directly across the institutions; second, mixing annotations from another institution following the same guideline increased tagging accuracy for about 1%. Our findings suggest that institutions can benefit more from sharing raw annotations but less from sharing pre-trained models for the POS tagging task. We believe the study could also provide general insights on cross-institution data sharing for other types of NLP tasks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22081,""
"A cloud-based approach to medical NLP","Chard, Russell, Lussier, MendonÃƒÂ§a, Silverstein","https://www.google.com/search?q=A+cloud-based+approach+to+medical+NLP.","20130225","PubMed","Clinical Coding; Medical Records Systems, Computerized; Natural Language Processing; Software; User-Computer Interface","Natural Language Processing (NLP) enables access to deep content embedded in medical texts. To date, NLP has not fulfilled its promise of enabling robust clinical encoding, clinical use, quality improvement, and research. We submit that this is in part due to poor accessibility, scalability, and flexibility of NLP systems. We describe here an approach and system which leverages cloud-based approaches such as virtual machines and Representational State Transfer (REST) to extract, process, synthesize, mine, compare/contrast, explore, and manage medical text data in a flexibly secure and scalable architecture. Available architectures in which our Smntx (pronounced as semantics) system can be deployed include: virtual machines in a HIPAA-protected hospital environment, brought up to run analysis over bulk data and destroyed in a local cloud; a commercial cloud for a large complex multi-institutional trial; and within other architectures such as caGrid, i2b2, or NHIN.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22082,""
"Latent Semantic Indexing of PubMed abstracts for identification of transcription factor candidates from microarray derived gene sets","Roy, Heinrich, Phan, Berry, Homayouni","https://doi.org/10.1186/1471-2105-12-S10-S19","20120417","PubMed","Algorithms; Amino Acid Motifs; Animals; Data Mining; Gene Regulatory Networks; Humans; Mice; Oligonucleotide Array Sequence Analysis; PubMed; Systems Biology; Transcription Factors","Identification of transcription factors (TFs) responsible for modulation of differentially expressed genes is a key step in deducing gene regulatory pathways. Most current methods identify TFs by searching for presence of DNA binding motifs in the promoter regions of co-regulated genes. However, this strategy may not always be useful as presence of a motif does not necessarily imply a regulatory role. Conversely, motif presence may not be required for a TF to regulate a set of genes. Therefore, it is imperative to include functional (biochemical and molecular) associations, such as those found in the biomedical literature, into algorithms for identification of putative regulatory TFs that might be explicitly or implicitly linked to the genes under investigation. In this study, we present a Latent Semantic Indexing (LSI) based text mining approach for identification and ranking of putative regulatory TFs from microarray derived differentially expressed genes (DEGs). Two LSI models were built using different term weighting schemes to devise pair-wise similarities between 21,027 mouse genes annotated in the Entrez Gene repository. Amongst these genes, 433 were designated TFs in the TRANSFAC database. The LSI derived TF-to-gene similarities were used to calculate TF literature enrichment p-values and rank the TFs for a given set of genes. We evaluated our approach using five different publicly available microarray datasets focusing on TFs Rel, Stat6, Ddit3, Stat5 and Nfic. In addition, for each of the datasets, we constructed gold standard TFs known to be functionally relevant to the study in question. Receiver Operating Characteristics (ROC) curves showed that the log-entropy LSI model outperformed the tf-normal LSI model and a benchmark co-occurrence based method for four out of five datasets, as well as motif searching approaches, in identifying putative TFs. Our results suggest that our LSI based text mining approach can complement existing approaches used in systems biology research to decipher gene regulatory networks by providing putative lists of ranked TFs that might be explicitly or implicitly associated with sets of DEGs derived from microarray experiments. In addition, unlike motif searching approaches, LSI based approaches can reveal TFs that may indirectly regulate genes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22083,""
"Ranking gene-drug relationships in biomedical literature using Latent Dirichlet Allocation","Wu, Liu, Zheng, Zhao, Xu","https://www.google.com/search?q=Ranking+gene-drug+relationships+in+biomedical+literature+using+Latent+Dirichlet+Allocation.","20131210","PubMed","Algorithms; Computational Biology; Data Mining; Databases, Factual; Databases, Genetic; Humans; Knowledge Bases; MEDLINE; Models, Statistical; Natural Language Processing; Pharmacogenetics","Drug responses vary greatly among individuals due to human genetic variations, which is known as pharmacogenomics (PGx). Much of the PGx knowledge has been embedded in biomedical literature and there is a growing interest to develop text mining approaches to extract such knowledge. In this paper, we present a study to rank candidate gene-drug relations using Latent Dirichlet Allocation (LDA) model. Our approach consists of three steps: 1) recognize gene and drug entities in MEDLINE abstracts; 2) extract candidate gene-drug pairs based on different levels of co-occurrence, including abstract level, sentence level, and phrase level; and 3) rank candidate gene-drug pairs using multiple different methods including term frequency, Chi-square test, Mutual Information (MI), a reported Kullback-Leibler (KL) distance based on topics derived from LDA (LDA-KL), and a newly defined probabilistic KL distance based on LDA (LDA-PKL). We systematically evaluated these methods by using a gold standard data set of gene-drug relations derived from PharmGKB. Our results showed that the proposed LDA-PKL method achieved better Mean Average Precision (MAP) than any other methods, suggesting its promising uses for ranking and detecting PGx relations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22084,""
"Assessment of NER solutions against the first and second CALBC Silver Standard Corpus","Rebholz-Schuhmann, Jimeno Yepes, Li, Kafkas, Lewin, Kang, Corbett, Milward, Buyko, Beisswanger, Hornbostel, Kouznetsov, Witte, Laurila, Baker, Kuo, Clematide, Rinaldi, Farkas, MÃƒÂ³ra, Hara, Furlong, Rautschka, Neves, Pascual-Montano, Wei, Collier, Chowdhury, Lavelli, Berlanga, Morante, Van Asch, Daelemans, Marina, van Mulligen, Kors, Hahn","https://doi.org/10.1186/2041-1480-2-S5-S11","20121002","PubMed","","Competitions in text mining have been used to measure the performance of automatic text processing solutions against a manually annotated gold standard corpus (GSC). The preparation of the GSC is time-consuming and costly and the final corpus consists at the most of a few thousand documents annotated with a limited set of semantic groups. To overcome these shortcomings, the CALBC project partners (PPs) have produced a large-scale annotated biomedical corpus with four different semantic groups through the harmonisation of annotations from automatic text mining solutions, the first version of the Silver Standard Corpus (SSC-I). The four semantic groups are chemical entities and drugs (CHED), genes and proteins (PRGE), diseases and disorders (DISO) and species (SPE). This corpus has been used for the First CALBC Challenge asking the participants to annotate the corpus with their text processing solutions. All four PPs from the CALBC project and in addition, 12 challenge participants (CPs) contributed annotated data sets for an evaluation against the SSC-I. CPs could ignore the training data and deliver the annotations from their genuine annotation system, or could train a machine-learning approach on the provided pre-annotated data. In general, the performances of the annotation solutions were lower for entities from the categories CHED and PRGE in comparison to the identification of entities categorized as DISO and SPE. The best performance over all semantic groups were achieved from two annotation solutions that have been trained on the SSC-I.The data sets from participants were used to generate the harmonised Silver Standard Corpus II (SSC-II), if the participant did not make use of the annotated data set from the SSC-I for training purposes. The performances of the participants' solutions were again measured against the SSC-II. The performances of the annotation solutions showed again better results for DISO and SPE in comparison to CHED and PRGE. The SSC-I delivers a large set of annotations (1,121,705) for a large number of documents (100,000 Medline abstracts). The annotations cover four different semantic groups and are sufficiently homogeneous to be reproduced with a trained classifier leading to an average F-measure of 85%. Benchmarking the annotation solutions against the SSC-II leads to better performance for the CPs' annotation solutions in comparison to the SSC-I.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22085,""
"Towards cross-lingual alerting for bursty epidemic events","Collier","https://doi.org/10.1186/2041-1480-2-S5-S10","20121002","PubMed","","Online news reports are increasingly becoming a source for event-based early warning systems that detect natural disasters. Harnessing the massive volume of information available from multilingual newswire presents as many challanges as opportunities due to the patterns of reporting complex spatio-temporal events. In this article we study the problem of utilising correlated event reports across languages. We track the evolution of 16 disease outbreaks using 5 temporal aberration detection algorithms on text-mined events classified according to disease and outbreak country. Using ProMED reports as a silver standard, comparative analysis of news data for 13 languages over a 129 day trial period showed improved sensitivity, F1 and timeliness across most models using cross-lingual events. We report a detailed case study analysis for Cholera in Angola 2010 which highlights the challenges faced in correlating news events with the silver standard. The results show that automated health surveillance using multilingual text mining has the potential to turn low value news into high value alerts if informed choices are used to govern the selection of models and data sources. An implementation of the C2 alerting algorithm using multilingual news is available at the BioCaster portal http://born.nii.ac.jp/?page=globalroundup.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22086,""
"A vision for a biomedical cloud","Grossman, White","https://doi.org/10.1111/j.1365-2796.2011.02491.x","20120228","PubMed","Biomedical Research; Computational Biology; Computer Communication Networks; Computer Security; Data Mining; Electronic Health Records; Genome, Human; Humans; Systems Biology","We present a vision for a Biomedical Cloud that draws on progress in the fields of Genomics, Systems Biology and biomedical data mining. The successful fusion of these areas will combine the use of biomarkers, genetic variants, and environmental variables to build predictive models that will drastically increase the specificity and timeliness of diagnosis for a wide range of common diseases, whilst delivering accurate predictions about the efficacy of treatment options. However, the amount of data being generated by each of these fields is staggering, as is the task of managing and analysing it. Adequate computing infrastructure needs to be developed to assemble, manage and mine the enormous and rapidly growing corpus of 'omics' data along with clinical information. We have now arrived at an intersection point between genome technology, cloud computing and biological data mining. This intersection point provides a launch pad for developing a globally applicable cloud computing platform capable of supporting a new paradigm of data intensive, cloud-enabled predictive medicine.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22087,""
"Automated discovery of drug treatment patterns for endocrine therapy of breast cancer within an electronic medical record","Savova, Olson, Murphy, Cafourek, Couch, Goetz, Ingle, Suman, Chute, Weinshilboum","https://doi.org/10.1136/amiajnl-2011-000295","20130802","PubMed","Algorithms; Antineoplastic Agents, Hormonal; Antineoplastic Combined Chemotherapy Protocols; Aromatase Inhibitors; Breast Neoplasms; Electronic Health Records; Female; Humans; Information Storage and Retrieval; Natural Language Processing; Sensitivity and Specificity; Tamoxifen","To develop an algorithm for the discovery of drug treatment patterns for endocrine breast cancer therapy within an electronic medical record and to test the hypothesis that information extracted using it is comparable to the information found by traditional methods. The electronic medical charts of 1507 patients diagnosed with histologically confirmed primary invasive breast cancer. The automatic drug treatment classification tool consisted of components for: (1) extraction of drug treatment-relevant information from clinical narratives using natural language processing (clinical Text Analysis and Knowledge Extraction System); (2) extraction of drug treatment data from an electronic prescribing system; (3) merging information to create a patient treatment timeline; and (4) final classification logic. Agreement between results from the algorithm and from a nurse abstractor is measured for categories: (0) no tamoxifen or aromatase inhibitor (AI) treatment; (1) tamoxifen only; (2) AI only; (3) tamoxifen before AI; (4) AI before tamoxifen; (5) multiple AIs and tamoxifen cycles in no specific order; and (6) no specific treatment dates. Specificity (all categories): 96.14%-100%; sensitivity (categories (0)-(4)): 90.27%-99.83%; sensitivity (categories (5)-(6)): 0-23.53%; positive predictive values: 80%-97.38%; negative predictive values: 96.91%-99.93%. Our approach illustrates a secondary use of the electronic medical record. The main challenge is event temporality. We present an algorithm for automated treatment classification within an electronic medical record to combine information extracted through natural language processing with that extracted from structured databases. The algorithm has high specificity for all categories, high sensitivity for five categories, and low sensitivity for two categories.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22088,""
"Applying active learning to assertion classification of concepts in clinical text","Chen, Mani, Xu","https://doi.org/10.1016/j.jbi.2011.11.003","20120531","PubMed","Data Mining; Decision Support Systems, Clinical; Humans; Natural Language Processing; Problem-Based Learning; Semantics","Supervised machine learning methods for clinical natural language processing (NLP) research require a large number of annotated samples, which are very expensive to build because of the involvement of physicians. Active learning, an approach that actively samples from a large pool, provides an alternative solution. Its major goal in classification is to reduce the annotation effort while maintaining the quality of the predictive model. However, few studies have investigated its uses in clinical NLP. This paper reports an application of active learning to a clinical text classification task: to determine the assertion status of clinical concepts. The annotated corpus for the assertion classification task in the 2010 i2b2/VA Clinical NLP Challenge was used in this study. We implemented several existing and newly developed active learning algorithms and assessed their uses. The outcome is reported in the global ALC score, based on the Area under the average Learning Curve of the AUC (Area Under the Curve) score. Results showed that when the same number of annotated samples was used, active learning strategies could generate better classification models (best ALC-0.7715) than the passive learning method (random sampling) (ALC-0.7411). Moreover, to achieve the same classification performance, active learning strategies required fewer samples than the random sampling method. For example, to achieve an AUC of 0.79, the random sampling method used 32 samples, while our best active learning algorithm required only 12 samples, a reduction of 62.5% in manual annotation effort.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22089,""
"Automated measurement of local white matter lesion volume","van der Lijn, Verhaaren, Ikram, Klein, de Bruijne, Vrooman, Vernooij, Hammers, Rueckert, van der Lugt, Breteler, Niessen","https://doi.org/10.1016/j.neuroimage.2011.11.021","20120703","PubMed","Aged; Aged, 80 and over; Automation; Brain Diseases; Female; Humans; Magnetic Resonance Imaging; Male; Middle Aged","It has been hypothesized that white matter lesions at different locations may have different etiology and clinical consequences. Several approaches for the quantification of local white matter lesion load have been proposed in the literature, most of which rely on a distinction between lesions in a periventricular region close to the ventricles and a subcortical zone further away. In this work we present a novel automated method for local white matter lesion volume quantification in magnetic resonance images. The method segments and measures the white matter lesion volume in 43 regions defined by orientation and distance to the ventricles, which allows a more spatially detailed study of lesion load. The potential of the method was demonstrated by analyzing the effect of blood pressure on the regional white matter lesion volume in 490 elderly subjects taken from a longitudinal population study. The method was also compared to two commonly used techniques to assess the periventricular and subcortical lesion load. The main finding was that high blood pressure was primarily associated with lesion load in the vascular watershed area that forms the border between the periventricular and subcortical regions. It explains the associations found for both the periventricular and subcortical load computed for the same data, and that were reported in the literature. But the proposed method can localize the region of association with greater precision than techniques that distinguish between periventricular and subcortical lesions only.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22090,""
"Using natural language processing to enable in-depth analysis of clinical messages posted to an Internet mailing list: a feasibility study","Bekhuis, Kreinacke, Spallek, Song, O'Donnell","https://doi.org/10.2196/jmir.1799","20120417","PubMed","Dental Informatics; Electronic Mail; Humans; Internet; Natural Language Processing; North America","An Internet mailing list may be characterized as a virtual community of practice that serves as an information hub with easy access to expert advice and opportunities for social networking. We are interested in mining messages posted to a list for dental practitioners to identify clinical topics. Once we understand the topical domain, we can study dentists' real information needs and the nature of their shared expertise, and can avoid delivering useless content at the point of care in future informatics applications. However, a necessary first step involves developing procedures to identify messages that are worth studying given our resources for planned, labor-intensive research. The primary objective of this study was to develop a workflow for finding a manageable number of clinically relevant messages from a much larger corpus of messages posted to an Internet mailing list, and to demonstrate the potential usefulness of our procedures for investigators by retrieving a set of messages tailored to the research question of a qualitative research team. We mined 14,576 messages posted to an Internet mailing list from April 2008 to May 2009. The list has about 450 subscribers, mostly dentists from North America interested in clinical practice. After extensive preprocessing, we used the Natural Language Toolkit to identify clinical phrases and keywords in the messages. Two academic dentists classified collocated phrases in an iterative, consensus-based process to describe the topics discussed by dental practitioners who subscribe to the list. We then consulted with qualitative researchers regarding their research question to develop a plan for targeted retrieval. We used selected phrases and keywords as search strings to identify clinically relevant messages and delivered the messages in a reusable database. About half of the subscribers (245/450, 54.4%) posted messages. Natural language processing (NLP) yielded 279,193 clinically relevant tokens or processed words (19% of all tokens). Of these, 2.02% (5634 unique tokens) represent the vocabulary for dental practitioners. Based on pointwise mutual information score and clinical relevance, 325 collocated phrases (eg, fistula filled obturation and herpes zoster) with 108 keywords (eg, mercury) were classified into 13 broad categories with subcategories. In the demonstration, we identified 305 relevant messages (2.1% of all messages) over 10 selected categories with instances of collocated phrases, and 299 messages (2.1%) with instances of phrases or keywords for the category systemic disease. A workflow with a sequence of machine-based steps and human classification of NLP-discovered phrases can support researchers who need to identify relevant messages in a much larger corpus. Discovered phrases and keywords are useful search strings to aid targeted retrieval. We demonstrate the potential value of our procedures for qualitative researchers by retrieving a manageable set of messages concerning systemic and oral disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22091,""
"Automated annotation of chemical names in the literature with tunable accuracy","Zhang, Geer, Bolton, Bryant","https://doi.org/10.1186/1758-2946-3-52","20121002","PubMed","","A significant portion of the biomedical and chemical literature refers to small molecules. The accurate identification and annotation of compound name that are relevant to the topic of the given literature can establish links between scientific publications and various chemical and life science databases. Manual annotation is the preferred method for these works because well-trained indexers can understand the paper topics as well as recognize key terms. However, considering the hundreds of thousands of new papers published annually, an automatic annotation system with high precision and relevance can be a useful complement to manual annotation. An automated chemical name annotation system, MeSH Automated Annotations (MAA), was developed to annotate small molecule names in scientific abstracts with tunable accuracy. This system aims to reproduce the MeSH term annotations on biomedical and chemical literature that would be created by indexers. When comparing automated free text matching to those indexed manually of 26 thousand MEDLINE abstracts, more than 40% of the annotations were false-positive (FP) cases. To reduce the FP rate, MAA incorporated several filters to remove ""incorrect"" annotations caused by nonspecific, partial, and low relevance chemical names. In part, relevance was measured by the position of the chemical name in the text. Tunable accuracy was obtained by adding or restricting the sections of the text scanned for chemical names. The best precision obtained was 96% with a 28% recall rate. The best performance of MAA, as measured with the F statistic was 66%, which favorably compares to other chemical name annotation systems. Accurate chemical name annotation can help researchers not only identify important chemical names in abstracts, but also match unindexed and unstructured abstracts to chemical records. The current work is tested against MEDLINE, but the algorithm is not specific to this corpus and it is possible that the algorithm can be applied to papers from chemical physics, material, polymer and environmental science, as well as patents, biological assay descriptions and other textual data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22092,""
"Identifying a network of brain regions involved in aversion-related processing: a cross-species translational investigation","Hayes, Northoff","https://doi.org/10.3389/fnint.2011.00049","20111123","PubMed","animal models; aversion; imaging; meta-analysis; translational","The ability to detect and respond appropriately to aversive stimuli is essential for all organisms, from fruit flies to humans. This suggests the existence of a core neural network which mediates aversion-related processing. Human imaging studies on aversion have highlighted the involvement of various cortical regions, such as the prefrontal cortex, while animal studies have focused largely on subcortical regions like the periaqueductal gray and hypothalamus. However, whether and how these regions form a core neural network of aversion remains unclear. To help determine this, a translational cross-species investigation in humans (i.e., meta-analysis) and other animals (i.e., systematic review of functional neuroanatomy) was performed. Our results highlighted the recruitment of the anterior cingulate cortex, the anterior insula, and the amygdala as well as other subcortical (e.g., thalamus, midbrain) and cortical (e.g., orbitofrontal) regions in both animals and humans. Importantly, involvement of these regions remained independent of sensory modality. This study provides evidence for a core neural network mediating aversion in both animals and humans. This not only contributes to our understanding of the trans-species neural correlates of aversion but may also carry important implications for psychiatric disorders where abnormal aversive behavior can often be observed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22093,""
"Morphological analysis of optical coherence tomography images for automated classification of gastrointestinal tissues","Garcia-Allende, Amygdalos, Dhanapala, Goldin, Hanna, Elson","https://doi.org/10.1364/BOE.2.002821","20111123","PubMed","(110.2960) Image analysis; (110.4500) Optical coherence tomography; (170.3880) Medical and biological imaging","The impact of digestive diseases, which include disorders affecting the oropharynx and alimentary canal, ranges from the inconvenience of a transient diarrhoea to dreaded conditions such as pancreatic cancer, which are usually fatal. Currently, the major limitation for the diagnosis of such diseases is sampling error because, even in the cases of rigorous adherence to biopsy protocols, only a tiny fraction of the surface of the involved gastrointestinal tract is sampled. Optical coherence tomography (OCT), which is an interferometric imaging technique for the minimally invasive measurement of biological samples, could decrease sampling error, increase yield, and even eliminate the need for tissue sampling provided that an automated, quick and reproducible tissue classification system is developed. Segmentation and quantification of ophthalmologic pathologies using OCT traditionally rely on the extraction of thickness and size measures from the OCT images, but layers are often not observed in nonopthalmic OCT imaging. Distinct mathematical methods, namely Principal Component Analysis (PCA) and textural analyses including both spatial textural analysis derived from the two-dimensional discrete Fourier transform (DFT) and statistical texture analysis obtained independently from center-symmetric autocorrelation (CSAC) and spatial grey-level dependency matrices (SGLDM), have been previously reported to overcome this problem. We propose an alternative approach consisting of a region segmentation according to the intensity variation along the vertical axis and a pure statistical technique for feature quantification, i.e. morphological analysis. Qualitative and quantitative comparisons with traditional approaches are accomplished in the discrimination of freshly-excised specimens of gastrointestinal tissues to exhibit the feasibility of the proposed method for computer-aided diagnosis (CAD) in the clinical setting.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22094,""
"Automatic discrimination between safe and unsafe swallowing using a reputation-based classifier","Nikjoo, Steele, SejdiÃ„â€¡, Chau","https://doi.org/10.1186/1475-925X-10-100","20120511","PubMed","Acceleration; Adult; Aged; Automation; Deglutition; Deglutition Disorders; Discriminant Analysis; Female; Humans; Male; Retrospective Studies; Safety; Signal Processing, Computer-Assisted","Swallowing accelerometry has been suggested as a potential non-invasive tool for bedside dysphagia screening. Various vibratory signal features and complementary measurement modalities have been put forth in the literature for the potential discrimination between safe and unsafe swallowing. To date, automatic classification of swallowing accelerometry has exclusively involved a single-axis of vibration although a second axis is known to contain additional information about the nature of the swallow. Furthermore, the only published attempt at automatic classification in adult patients has been based on a small sample of swallowing vibrations. In this paper, a large corpus of dual-axis accelerometric signals were collected from 30 older adults (aged 65.47 Ã‚Â± 13.4 years, 15 male) referred to videofluoroscopic examination on the suspicion of dysphagia. We invoked a reputation-based classifier combination to automatically categorize the dual-axis accelerometric signals into safe and unsafe swallows, as labeled via videofluoroscopic review. From these participants, a total of 224 swallowing samples were obtained, 164 of which were labeled as unsafe swallows (swallows where the bolus entered the airway) and 60 as safe swallows. Three separate support vector machine (SVM) classifiers and eight different features were selected for classification. With selected time, frequency and information theoretic features, the reputation-based algorithm distinguished between safe and unsafe swallowing with promising accuracy (80.48 Ã‚Â± 5.0%), high sensitivity (97.1 Ã‚Â± 2%) and modest specificity (64 Ã‚Â± 8.8%). Interpretation of the most discriminatory features revealed that in general, unsafe swallows had lower mean vibration amplitude and faster autocorrelation decay, suggestive of decreased hyoid excursion and compromised coordination, respectively. Further, owing to its performance-based weighting of component classifiers, the static reputation-based algorithm outperformed the democratic majority voting algorithm on this clinical data set. Given its computational efficiency and high sensitivity, reputation-based classification of dual-axis accelerometry ought to be considered in future developments of a point-of-care swallow assessment where clinical informatics are desired.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22095,""
"Enhancing clinical concept extraction with distributional semantics","Jonnalagadda, Cohen, Wu, Gonzalez","https://doi.org/10.1016/j.jbi.2011.10.007","20120420","PubMed","Data Mining; Decision Support Systems, Clinical; Humans; MEDLINE; Natural Language Processing; Semantics; Unified Medical Language System","Extracting concepts (such as drugs, symptoms, and diagnoses) from clinical narratives constitutes a basic enabling technology to unlock the knowledge within and support more advanced reasoning applications such as diagnosis explanation, disease progression modeling, and intelligent analysis of the effectiveness of treatment. The recent release of annotated training sets of de-identified clinical narratives has contributed to the development and refinement of concept extraction methods. However, as the annotation process is labor-intensive, training data are necessarily limited in the concepts and concept patterns covered, which impacts the performance of supervised machine learning applications trained with these data. This paper proposes an approach to minimize this limitation by combining supervised machine learning with empirical learning of semantic relatedness from the distribution of the relevant words in additional unannotated text. The approach uses a sequential discriminative classifier (Conditional Random Fields) to extract the mentions of medical problems, treatments and tests from clinical narratives. It takes advantage of all Medline abstracts indexed as being of the publication type ""clinical trials"" to estimate the relatedness between words in the i2b2/VA training and testing corpora. In addition to the traditional features such as dictionary matching, pattern matching and part-of-speech tags, we also used as a feature words that appear in similar contexts to the word in question (that is, words that have a similar vector representation measured with the commonly used cosine metric, where vector representations are derived using methods of distributional semantics). To the best of our knowledge, this is the first effort exploring the use of distributional semantics, the semantics derived empirically from unannotated text often using vector space models, for a sequence classification task such as concept extraction. Therefore, we first experimented with different sliding window models and found the model with parameters that led to best performance in a preliminary sequence labeling task. The evaluation of this approach, performed against the i2b2/VA concept extraction corpus, showed that incorporating features based on the distribution of words across a large unannotated corpus significantly aids concept extraction. Compared to a supervised-only approach as a baseline, the micro-averaged F-score for exact match increased from 80.3% to 82.3% and the micro-averaged F-score based on inexact match increased from 89.7% to 91.3%. These improvements are highly significant according to the bootstrap resampling method and also considering the performance of other systems. Thus, distributional semantic features significantly improve the performance of concept extraction from clinical narratives by taking advantage of word distribution information obtained from unannotated data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22096,""
"Recognizing Temporal Information in Korean Clinical Narratives through Text Normalization","Kim, Choi","https://doi.org/10.4258/hir.2011.17.3.150","20111123","PubMed","Automated Pattern Recognition; Information Processing; Medical Informatics; Medical Record; Multilingualism","Acquiring temporal information is important because knowledge in clinical narratives is time-sensitive. In this paper, we describe an approach that can be used to extract the temporal information found in Korean clinical narrative texts. We developed a two-stage system, which employs an exhaustive text analysis phase and a temporal expression recognition phase. Since our target document may include tokens that are made up of both Korean and English text joined together, the minimal semantic units are analyzed and then separated from the concatenated phrases and linguistic derivations within a token using a corpus-based approach to decompose complex tokens. A finite state machine is then used on the minimal semantic units in order to find phrases that possess time-related information. In the experiment, the temporal expressions within Korean clinical narratives were extracted using our system. The system performance was evaluated through the use of 100 discharge summaries from Seoul National University Hospital containing a total of 805 temporal expressions. Our system scored a phrase-level precision and recall of 0.895 and 0.919, respectively. Finding information in Korean clinical narrative is challenging task, since the text is written in both Korean and English and frequently omits syntactic elements and word spacing, which makes it extremely noisy. This study presents an effective method that can be used to aquire the temporal information found in Korean clinical documents.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22097,""
"Structuring and validating a cost-effectiveness model of primary asthma prevention amongst children","Ramos, Kuiper, Dompeling, van Asselt, de Grauw, Knottnerus, van Schayck, Schermer, Severens","https://doi.org/10.1186/1471-2288-11-150","20120328","PubMed","Algorithms; Asthma; Child; Cost-Benefit Analysis; Decision Support Techniques; Health Care Costs; Humans; Models, Economic; Primary Prevention; Reproducibility of Results","Given the rising number of asthma cases and the increasing costs of health care, prevention may be the best cure. Decisions regarding the implementation of prevention programmes in general and choosing between unifaceted and multifaceted strategies in particular are urgently needed. Existing trials on the primary prevention of asthma are, however, insufficient on their own to inform the decision of stakeholders regarding the cost-effectiveness of such prevention strategies. Decision analytic modelling synthesises available data for the cost-effectiveness evaluation of strategies in an explicit manner. Published reports on model development should provide the detail and transparency required to increase the acceptability of cost-effectiveness modelling. But, detail on the explicit steps and the involvement of experts in structuring a model is often unevenly reported. In this paper, we describe a procedure to structure and validate a model for the primary prevention of asthma in children. An expert panel was convened for round-table discussions to frame the cost-effectiveness research question and to select and structure a model. The model's structural validity, which indicates how well a model reflects the reality, was determined through descriptive and parallel validation. Descriptive validation was performed with the experts. Parallel validation qualitatively compared similarity between other published models with different decision problems. The multidisciplinary input of experts helped to develop a decision-tree structure which compares the current situation with screening and prevention. The prevention was further divided between multifaceted and unifaceted approaches to analyse the differences. The clinical outcome was diagnosis of asthma. No similar model was found in the literature discussing the same decision problem. Structural validity in terms of descriptive validity was achieved with the experts and was supported by parallel validation. A decision-tree model developed with experts in round-table discussions benefits from a systematic and transparent approach and the multidisciplinary contributions of the experts. Parallel validation provides a feasible alternative to validating novel models. The process of structuring and validating a model presented in this paper could be a useful guide to increase transparency, credibility, and acceptability of (future, novel) models when experts are involved.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22098,""
"A multi-layered framework for disseminating knowledge for computer-based decision support","Boxwala, Rocha, Maviglia, Kashyap, Meltzer, Kim, Tsurikova, Wright, Paterno, Fairbanks, Middleton","https://doi.org/10.1136/amiajnl-2011-000334","20120824","PubMed","Artificial Intelligence; Decision Making, Computer-Assisted; Decision Support Systems, Clinical; Practice Guidelines as Topic; Software Design","There are several challenges in encoding guideline knowledge in a form that is portable to different clinical sites, including the heterogeneity of clinical decision support (CDS) tools, of patient data representations, and of workflows. We have developed a multi-layered knowledge representation framework for structuring guideline recommendations for implementation in a variety of CDS contexts. In this framework, guideline recommendations are increasingly structured through four layers, successively transforming a narrative text recommendation into input for a CDS system. We have used this framework to implement rules for a CDS service based on three guidelines. We also conducted a preliminary evaluation, where we asked CDS experts at four institutions to rate the implementability of six recommendations from the three guidelines. The experience in using the framework and the preliminary evaluation indicate that this approach has promise in creating structured knowledge, to implement in CDS systems, that is usable across organizations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22099,""
"Natural language processing and the oncologic history: is there a match?","Warner, Anick, Hong, Xue","https://doi.org/10.1200/JOP.2011.000240","20130704","PubMed","","The widespread adoption of electronic health records (EHRs) is creating rich databases documenting the cancer patient's care continuum. However, much of this data, especially narrative ""oncologic histories,"" are ""locked"" within free text (unstructured) portions of notes. Nationwide incentives, ranging from certification (Quality Oncology Practice Initiative) to monetary reimbursement (the Health Information Technology for Economic and Clinical Health Act), increasingly require the translation of these histories into treatment summaries for patient use and into tools to assist in transitions of care. Unfortunately, formulation of treatment summaries from these data is difficult and time-consuming. The rapidly developing field of automated natural language processing may offer a solution to this communication problem. We surveyed a cross section of providers at Beth Israel Deaconess Medical Center regarding the importance of treatment summaries and whether these were being formulated on a regular basis. We also developed a program for the Informatics for Integrating Biology and the Bedside challenge, which was designed to extract meaningful information from EHRs. The program was then applied to a sample of narrative oncologic histories. The majority of providers (86%) felt that treatment summaries were important, but only 11% actually implemented them. The most common obstacles identified were lack of time and lack of EHR tools. We demonstrated that relevant medical concepts can be automatically extracted from oncologic histories with reasonable accuracy and precision. Natural language processing technology offers a promising method for structuring a free-text oncologic history into a compact treatment summary, creating a robust and accurate means of communication between providers and between provider and patient.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22100,""
"Economic evaluation of da Vinci-assisted robotic surgery: a systematic review","Turchetti, Palla, Pierotti, Cuschieri","https://doi.org/10.1007/s00464-011-1936-2","20120416","PubMed","Costs and Cost Analysis; Humans; Laparoscopy; Robotics; Technology Assessment, Biomedical","Health technology assessment (HTA) is frequently used when a new and expensive technology is being introduced into clinical practice. This certainly is the case with the da Vinci surgical robot, with costs ranging from $1 to $2.5 million for each unit. This systematic review documents major variability in the reported cost evaluation studies of da Vinci robot-assisted operations compared with those performed by the direct manual laparoscopic approach. Published studies in the English language related to the period 2000-2010 were searched using economic and clinical electronic databases. All 11 reports included some form of cost analysis, which made it possible for the authors to extract information on certain specific economic outcomes: operating room time, hospital stay, and total costs. With the exception of two studies, the reported operating room time was higher with the robotic approach than with manual laparoscopic surgery, and the hospital stay was the same for the two techniques. Robotic surgery is significantly more expensive if the purchase and maintenance costs of the robot system are included in the total costs. Only 3 of the 11 publications included these costs. The disadvantage of robotic surgery is its higher costs related to purchase and maintenance of technology and its longer operating room time. However, emerging evidence shows that operating room time decreases with experience using the robot. From the HTA viewpoint, the result of this review is that the jury still is out on the HTA of da Vinci-assisted robotic surgery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22101,""
"Characteristics of Finnish and Swedish intensive care nursing narratives: a comparative analysis to support the development of clinical language technologies","Allvin, Carlsson, Dalianis, Danielsson-Ojala, DaudaraviÃ„Âius, Hassel, Kokkinakis, LundgrÃƒÂ©n-Laine, Nilsson, NytrÃƒÂ¸, SalanterÃƒÂ¤, Skeppstedt, Suominen, Velupillai","https://doi.org/10.1186/2041-1480-2-S3-S1","20111110","PubMed","","Free text is helpful for entering information into electronic health records, but reusing it is a challenge. The need for language technology for processing Finnish and Swedish healthcare text is therefore evident; however, Finnish and Swedish are linguistically very dissimilar. In this paper we present a comparison of characteristics in Finnish and Swedish free-text nursing narratives from intensive care. This creates a framework for characterising and comparing clinical text and lays the groundwork for developing clinical language technologies. Our material included daily nursing narratives from one intensive care unit in Finland and one in Sweden. Inclusion criteria for patients were an inpatient period of least five days and an age of at least 16 years. We performed a comparative analysis as part of a collaborative effort between Finnish- and Swedish-speaking healthcare and language technology professionals that included both qualitative and quantitative aspects. The qualitative analysis addressed the content and structure of three average-sized health records from each country. In the quantitative analysis 514 Finnish and 379 Swedish health records were studied using various language technology tools. Although the two languages are not closely related, nursing narratives in Finland and Sweden had many properties in common. Both made use of specialised jargon and their content was very similar. However, many of these characteristics were challenging regarding development of language technology to support producing and using clinical documentation. The way Finnish and Swedish intensive care nursing was documented, was not country or language dependent, but shared a common context, principles and structural features and even similar vocabulary elements. Technology solutions are therefore likely to be applicable to a wider range of natural languages, but they need linguistic tailoring. The Finnish and Swedish data can be found at: http://www.dsv.su.se/hexanord/data/.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22102,""
"Louhi 2010: Special issue on Text and Data Mining of Health Documents","Dalianis, Hassel, Velupillai","https://doi.org/10.1186/2041-1480-2-S3-I1","20111110","PubMed","","The papers presented in this supplement focus and reflect on computer use in every-day clinical work in hospitals and clinics such as electronic health record systems, pre-processing for computer aided summaries, clinical coding, computer decision systems, as well as related ethical concerns and security. Much of this work concerns itself by necessity with incorporation and development of language processing tools and methods, and as such this supplement aims at providing an arena for reporting on development in a diversity of languages. In the supplement we can read about some of the challenges identified above.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22103,""
"PASTE: patient-centered SMS text tagging in a medication management system","Stenner, Johnson, Denny","https://doi.org/10.1136/amiajnl-2011-000484","20120820","PubMed","Drug Therapy, Computer-Assisted; Electronic Health Records; Feasibility Studies; Humans; Information Storage and Retrieval; Medication Systems; Natural Language Processing; Patient-Centered Care; Pilot Projects; Reminder Systems; Text Messaging; User-Computer Interface","To evaluate the performance of a system that extracts medication information and administration-related actions from patient short message service (SMS) messages. Mobile technologies provide a platform for electronic patient-centered medication management. MyMediHealth (MMH) is a medication management system that includes a medication scheduler, a medication administration record, and a reminder engine that sends text messages to cell phones. The object of this work was to extend MMH to allow two-way interaction using mobile phone-based SMS technology. Unprompted text-message communication with patients using natural language could engage patients in their healthcare, but presents unique natural language processing challenges. The authors developed a new functional component of MMH, the Patient-centered Automated SMS Tagging Engine (PASTE). The PASTE web service uses natural language processing methods, custom lexicons, and existing knowledge sources to extract and tag medication information from patient text messages. A pilot evaluation of PASTE was completed using 130 medication messages anonymously submitted by 16 volunteers via a website. System output was compared with manually tagged messages. Verified medication names, medication terms, and action terms reached high F-measures of 91.3%, 94.7%, and 90.4%, respectively. The overall medication name F-measure was 79.8%, and the medication action term F-measure was 90%. Other studies have demonstrated systems that successfully extract medication information from clinical documents using semantic tagging, regular expression-based approaches, or a combination of both approaches. This evaluation demonstrates the feasibility of extracting medication information from patient-generated medication messages.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22104,""
"Active tactile exploration using a brain-machine-brain interface","O'Doherty, Lebedev, Ifft, Zhuang, Shokur, Bleuler, Nicolelis","https://doi.org/10.1038/nature10489","20120125","PubMed","Algorithms; Animals; Artificial Limbs; Brain; Feedback; Macaca mulatta; Man-Machine Systems; Psychometrics; Reward; Somatosensory Cortex; Touch; User-Computer Interface","Brain-machine interfaces use neuronal activity recorded from the brain to establish direct communication with external actuators, such as prosthetic arms. It is hoped that brain-machine interfaces can be used to restore the normal sensorimotor functions of the limbs, but so far they have lacked tactile sensation. Here we report the operation of a brain-machine-brain interface (BMBI) that both controls the exploratory reaching movements of an actuator and allows signalling of artificial tactile feedback through intracortical microstimulation (ICMS) of the primary somatosensory cortex. Monkeys performed an active exploration task in which an actuator (a computer cursor or a virtual-reality arm) was moved using a BMBI that derived motor commands from neuronal ensemble activity recorded in the primary motor cortex. ICMS feedback occurred whenever the actuator touched virtual objects. Temporal patterns of ICMS encoded the artificial tactile properties of each object. Neuronal recordings and ICMS epochs were temporally multiplexed to avoid interference. Two monkeys operated this BMBI to search for and distinguish one of three visually identical objects, using the virtual-reality arm to identify the unique artificial texture associated with each. These results suggest that clinical motor neuroprostheses might benefit from the addition of ICMS feedback to generate artificial somatic perceptions associated with mechanical, robotic or even virtual prostheses.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22105,""
"Rehabilitation after stroke","Knecht, Hesse, Oster","https://doi.org/10.3238/arztebl.2011.0600","20120425","PubMed","Activities of Daily Living; Brain Damage, Chronic; Cerebral Hemorrhage; Cerebral Infarction; Combined Modality Therapy; Cooperative Behavior; Disability Evaluation; Germany; Hospital Units; Humans; Interdisciplinary Communication; Physical Therapy Modalities; Prognosis; Rehabilitation Centers; Robotics; Stroke; Stroke Rehabilitation; Survival Rate","Stroke is becoming more common in Germany as the population ages. Its long-term sequelae can be alleviated by early reperfusion in stroke units and by complication management and functional restoration in early-rehabilitation and rehabilitation centers. Selective review of the literature. Successful rehabilitation depends on systematic treatment by an interdisciplinary team of experienced specialists. In the area of functional restoration, there has been major progress in our understanding of the physiology of learning, relearning, training, and neuroenhancement. There have also been advances in supportive pharmacotherapy and robot technology. Well-organized acute and intermediate rehabilitation after stroke can provide patients with the best functional results attainable on the basis of our current scientific understanding. Further experimental and clinical studies will be needed to expand our knowledge and improve the efficacy of rehabilitation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22106,""
"Modeling paradigms for medical diagnostic decision support: a survey and future directions","Wagholikar, Sundararajan, Deshpande","https://doi.org/10.1007/s10916-011-9780-4","20121010","PubMed","Algorithms; Bayes Theorem; Data Mining; Databases, Factual; Decision Making, Computer-Assisted; Decision Support Techniques; Diagnosis, Computer-Assisted; Diagnosis, Differential; Fuzzy Logic","Use of computer based decision tools to aid clinical decision making, has been a primary goal of research in biomedical informatics. Research in the last five decades has led to the development of Medical Decision Support (MDS) applications using a variety of modeling techniques, for a diverse range of medical decision problems. This paper surveys literature on modeling techniques for diagnostic decision support, with a focus on decision accuracy. Trends and shortcomings of research in this area are discussed and future directions are provided. The authors suggest that-(i) Improvement in the accuracy of MDS application may be possible by modeling of vague and temporal data, research on inference algorithms, integration of patient information from diverse sources and improvement in gene profiling algorithms; (ii) MDS research would be facilitated by public release of de-identified medical datasets, and development of opensource data-mining tool kits; (iii) Comparative evaluations of different modeling techniques are required to understand characteristics of the techniques, which can guide developers in choice of technique for a particular medical decision problem; and (iv) Evaluations of MDS applications in clinical setting are necessary to foster physicians' utilization of these decision aids.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22107,""
"A swarm optimized neural network system for classification of microcalcification in mammograms","Dheeba, Selvi","https://doi.org/10.1007/s10916-011-9781-3","20121010","PubMed","Algorithms; Breast Neoplasms; Calcinosis; Female; Humans; Image Interpretation, Computer-Assisted; Mammography; Neural Networks, Computer; ROC Curve; Sensitivity and Specificity","Early detection of microcalcification clusters in breast tissue will significantly increase the survival rate of the patients. Radiologists use mammography for breast cancer diagnosis at early stage. It is a very challenging and difficult task for radiologists to correctly classify the abnormal regions in the breast tissue, because mammograms are noisy images. To improve the accuracy rate of detection of breast cancer, a novel intelligent computer aided classifier is used, which detects the presence of microcalcification clusters. In this paper, an innovative approach for detection of microcalcification in digital mammograms using Swarm Optimization Neural Network (SONN) is used. Prior to classification Laws texture features are extracted from the image to capture descriptive texture information. These features are used to extract texture energy measures from the Region of Interest (ROI) containing microcalcification (MC). A feedforward neural network is used for detection of abnormal regions in breast tissue is optimally designed using Particle Swarm Optimization algorithm. The proposed intelligent classifier is evaluated based on the MIAS database where 51 malignant, 63 benign and 208 normal images are utilized. The approach has also been tested on 216 real time clinical images having abnormalities which showed that the results are statistically significant. With the proposed methodology, the area under the ROC curve (A ( z )) reached 0.9761 for MIAS database and 0.9138 for real clinical images. The classification results prove that the proposed swarm optimally tuned neural network highly contribute to computer-aided diagnosis of breast cancer.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22108,""
"Drug side effect extraction from clinical narratives of psychiatry and psychology patients","Sohn, Kocher, Chute, Savova","https://doi.org/10.1136/amiajnl-2011-000351","20120824","PubMed","Artificial Intelligence; Data Mining; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Humans; Narration; Natural Language Processing; Pattern Recognition, Automated; Psychiatry; Psychology","To extract physician-asserted drug side effects from electronic medical record clinical narratives. Pattern matching rules were manually developed through examining keywords and expression patterns of side effects to discover an individual side effect and causative drug relationship. A combination of machine learning (C4.5) using side effect keyword features and pattern matching rules was used to extract sentences that contain side effect and causative drug pairs, enabling the system to discover most side effect occurrences. Our system was implemented as a module within the clinical Text Analysis and Knowledge Extraction System. The system was tested in the domain of psychiatry and psychology. The rule-based system extracting side effects and causative drugs produced an F score of 0.80 (0.55 excluding allergy section). The hybrid system identifying side effect sentences had an F score of 0.75 (0.56 excluding allergy section) but covered more side effect and causative drug pairs than individual side effect extraction. The rule-based system was able to identify most side effects expressed by clear indication words. More sophisticated semantic processing is required to handle complex side effect descriptions in the narrative. We demonstrated that our system can be trained to identify sentences with complex side effect descriptions that can be submitted to a human expert for further abstraction. Our system was able to extract most physician-asserted drug side effects. It can be used in either an automated mode for side effect extraction or semi-automated mode to identify side effect sentences that can significantly simplify abstraction by a human expert.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22109,""
"Primary extraskeletal osteosarcoma of the seminal vesicle: a case report and literature review","Choi, La Choi, Kim, Seo, Jeon, Lee, Jeong","https://doi.org/10.1308/003588411X13008879168577","20111110","PubMed","Chemotherapy, Adjuvant; Diagnostic Techniques, Surgical; Genital Neoplasms, Male; Humans; Laparoscopy; Magnetic Resonance Imaging; Male; Middle Aged; Osteosarcoma; Robotics; Seminal Vesicles; Tomography, X-Ray Computed","A primary extraskeletal osteosarcoma (EOS) is a rare tumour. An EOS of the seminal vesicle has not been reported in the literature. We describe a case of a seminal vesicle EOS initially detected as a pre-rectal mass on a routine transrectal ultrasound in a 48-year-old man. A computed tomography (CT) scan confirmed the tumour to be arising from the left seminal vesicle. A robot-assisted laparoscopic seminal vesiculectomy was performed to avoid neurovascular bundle injury. Microscopic examination of the resected specimen showed a poorly differentiated osteosarcoma originating from the seminal vesicle. The patient received adjuvant chemotherapy. He is doing well without voiding or erectile dysfunction and he is tumour-free five months after surgery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22110,""
"Predictive modeling for improved anemia management in dialysis patients","Brier, Gaweda","https://doi.org/10.1097/MNH.0b013e32834bba4e","20120203","PubMed","Anemia; Computer Simulation; Erythropoietin; Expert Systems; Hematinics; Hemoglobins; Humans; Models, Biological; Recombinant Proteins; Renal Dialysis","This review will explore the basic assumptions needed to perform predictive modeling of hemoglobin response to erythropoiesis stimulating agents (ESAs) and summarize the current literature in the area so that the practitioner can incorporate these tools as part of an improved anemia management process. During the last year, several publications have demonstrated some advances in the field that may improve anemia management. The first of these was the publication of a randomized, controlled clinical trial of model predictive control in the dosing of erythropoietin. This work showed that hemoglobin variability can be decreased using predictive models of hemoglobin response. The second publication is potentially more interesting in the long run, as new markers of erythropoietin response were identified in a well-defined population of patients. Predictive models of hemoglobin response improve anemia management by decreasing hemoglobin variability. This will result in more patients within the target range. Coupling these tools with new biomarkers of hemoglobin response has the potential to dramatically improve anemia management.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22111,""
"Cost-effectiveness analysis of pneumococcal polysaccharide vaccination from age 60 in SÃƒÂ£o Paulo State, Brazil","Neto, de Araujo, Gagliardi, Pinho, Durand, Fonseca","https://doi.org/10.4161/hv.7.10.15987","20120321","PubMed","Aged; Aged, 80 and over; Brazil; Cost-Benefit Analysis; Female; Humans; Male; Middle Aged; Models, Statistical; Pneumococcal Infections; Pneumococcal Vaccines","Vaccination of adults aged 60 years and older against Streptococcus pneumonia is not recommended in Brazil. The 23-valent polysaccharide pneumococcal vaccine (PPV23) is only available for institutionalized persons or with underlying diseases despite the substantial medical and economic burden related to pneumococcal infections in adults over than 59 years. The study aimed at evaluating the cost effectiveness of implementing a large PPV program in this population. This analysis was performed using a static decision tree model. Demographic and epidemiological data were obtained from Brazilian official sources and international literature. Economic data were obtained from a study performed in 2007 in a public and a private hospital located in Sao Paulo. Vaccination was assumed to protect for 5 years with 60% effectiveness against bacteremic pneumococcal pneumonia (BPP) and 21% effectiveness against non bacteremic pneumococcal pneumonia (NBPP). Deterministic and sensitivity analyses were performed. The pneumococcal polysaccharide vaccination saved 5,218 life year gained (LYG). The vaccination program was found to be cost effective in the social security and public health care perspectives with a mean incremental cost-effectiveness ratio of R$10,887 and R$8,281 per LYG respectively. Results were sensitive to the vaccine effectiveness against NBPP, the incidence and case-fatality rate of NBPP. From a societal perspective, PPV23 program for adults 60 and older was found to be cost-saving. Pneumococcal polysaccharide vaccination is clinically and economically favored over the present vaccination strategy, in which persons aged over 59 years in Sao Paulo, have not been vaccinated.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22112,""
"Effective diagnosis of coronary artery disease using the rotation forest ensemble method","Karabulut, IbrikÃƒÂ§i","https://doi.org/10.1007/s10916-011-9778-y","20121010","PubMed","Age Factors; Algorithms; Cardiovascular Diseases; Coronary Artery Disease; Diagnosis, Computer-Assisted; Humans; Neural Networks, Computer; Sex Factors","Coronary Artery Disease is a common heart disease related to disorders effecting the heart and blood vessels. Since the disease is one of the leading causes of heart attacks and thus deaths, diagnosis of the disease in its early stages or in cases when patients do not show many of the symptoms yet has considerable importance. In the literature, studies based on computational methods have been proposed to diagnose the disease with readily available and easily collected patient data, and among these studies, the greatest accuracy reached is 89.01%. This paper presents a computational tool based on the Rotation Forest algorithm to effectively diagnose Coronary Artery Disease in order to support clinical decision-making processes. The proposed method utilizes Artificial Neural Networks with the Levenberg-Marquardt back propagation algorithm as base classifiers of the Rotation Forest ensemble method. In this scheme, 91.2% accuracy in diagnosing the disease is accomplished, which is, to the best of our knowledge, the best performance among the computational methods from the literature that use the same data. This paper also presents a comparison of the proposed method with some other classifiers in terms of diagnosis performance of Coronary Artery Disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22113,""
"ELECTRICA: ELEctronic knowledge base for Clinical care, Teaching and Research In Child Abuse","Offiah, Hume, Bamsey, Jenkinson, Lings","https://doi.org/10.1007/s00247-011-2221-1","20120210","PubMed","Child; Child Abuse; Child, Preschool; Humans; Knowledge Bases; Radiology; Research; Retrospective Studies; Teaching","Child abuse is a highly significant public health issue with 4-16% of children being physically abused. The diagnosis is sensitive and challenging, with many radiologists dissatisfied with current levels of training and support. The literature shows a lack of prospective scientific research in this complex field. An ELEctronic knowledge base for Clinical care, Teaching and Research In Child Abuse (ELECTRICA) should solve many current problems. ELECTRICA will be populated with clinical information, radiographs and radiographic findings in children younger than 3 years of age presenting with injury (accidental or suspected abuse), to form a unique resource. This web-based tool will unify the investigative protocol in suspected abuse and support training and allow multicentre national and international collaborative research and provide robust evidence to support the legal process.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22114,""
"Development of an optical character recognition pipeline for handwritten form fields from an electronic health record","Rasmussen, Peissig, McCarty, Starren","https://doi.org/10.1136/amiajnl-2011-000182","20130802","PubMed","Electronic Data Processing; Electronic Health Records; Humans","Although the penetration of electronic health records is increasing rapidly, much of the historical medical record is only available in handwritten notes and forms, which require labor-intensive, human chart abstraction for some clinical research. The few previous studies on automated extraction of data from these handwritten notes have focused on monolithic, custom-developed recognition systems or third-party systems that require proprietary forms. We present an optical character recognition processing pipeline, which leverages the capabilities of existing third-party optical character recognition engines, and provides the flexibility offered by a modular custom-developed system. The system was configured and run on a selected set of form fields extracted from a corpus of handwritten ophthalmology forms. The processing pipeline allowed multiple configurations to be run, with the optimal configuration consisting of the Nuance and LEADTOOLS engines running in parallel with a positive predictive value of 94.6% and a sensitivity of 13.5%. While limitations exist, preliminary experience from this project yielded insights on the generalizability and applicability of integrating multiple, inexpensive general-purpose third-party optical character recognition engines in a modular pipeline.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22115,""
"Data mining of mental health issues of non-bone marrow donor siblings","Takita, Tanaka, Kodama, Murashige, Hatanaka, Kishi, Matsumura, Ohsawa, Kami","https://doi.org/10.1186/2043-9113-1-19","20111110","PubMed","","Allogenic hematopoietic stem cell transplantation is a curative treatment for patients with advanced hematologic malignancies. However, the long-term mental health issues of siblings who were not selected as donors (non-donor siblings, NDS) in the transplantation have not been well assessed. Data mining is useful in discovering new findings from a large, multidisciplinary data set and the Scenario Map analysis is a novel approach which allows extracting keywords linking different conditions/events from text data of interviews even when the keywords appeared infrequently. The aim of this study is to assess mental health issues on NDSs and to find helpful keywords for the clinical follow-up using a Scenario Map analysis. A 47-year-old woman whose younger sister had undergone allogenic hematopoietic stem cell transplantation 20 years earlier was interviewed as a NDS. The text data from the interview transcriptions was analyzed using Scenario Mapping. Four clusters of words and six keywords were identified. Upon review of the word clusters and keywords, both the subject and researchers noticed that the subject has had mental health issues since the disease onset to date with being a NDS. The issues have been alleviated by her family. This single subject study suggested the advantages of data mining in clinical follow-up for mental health issues of patients and/or their families.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22116,""
"Robot-assisted laparoscopic surgery of the colon and rectum","Antoniou, Antoniou, Koch, Pointner, Granderath","https://doi.org/10.1007/s00464-011-1867-y","20120227","PubMed","Blood Loss, Surgical; Colectomy; Colon, Sigmoid; Colorectal Surgery; Humans; Laparoscopy; Length of Stay; Prospective Studies; Rectum; Retrospective Studies; Robotics","Laparoscopic techniques have induced a tremendous revolution in the field of general surgery. Recent multicenter trials have demonstrated similar patient-oriented and oncologic outcomes for laparoscopic colon and rectal resections compared with their open counterparts. Meanwhile, robotic technology has gradually entered the field of general surgery, allowing increased dexterity, improved operative view, and optimal ergonomics. The objective of this study was to review the current status of clinical robotic applications in colorectal surgery. A systematic review of the literature using the PubMed search engine was undertaken to identify relevant articles. The keywords used in all possible combinations were: surgical robotics, robotic surgery, computer-assisted surgery, colectomy, sigmoid resection, sigmoidectomy, and rectal resection. Thirty-nine case series or comparative nonrandomized studies were identified. A specific interest for robot-assisted rectal surgery during the past few years was recorded in the literature. The retrieved articles included 13 ileocecal resections, 220 right colectomies, 190 left colectomies/sigmoid resections, 440 anterior resections, 149 abdominoperineal/intersphincteric resections, and 11 total/subtotal colectomies. The clinical application of the da Vinci robotic system in right and left/sigmoid colectomies yielded satisfactory results in terms of open conversion (1.1 and 3.8%, respectively) and operative morbidity (13.4 and 15.1%, respectively). Robot-assisted anterior resection was accompanied by a considerably low conversion rate (0.4%), morbidity (9.7%), and adequate number of harvested lymph nodes (14.3, mean). Robotic applications in colorectal surgery are feasible with low conversion rates and favorable morbidity. Further studies are required to evaluate its oncologic and patient-oriented outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22117,""
"Coreference resolution: a review of general methodologies and applications in the clinical domain","Zheng, Chapman, Crowley, Savova","https://doi.org/10.1016/j.jbi.2011.08.006","20120405","PubMed","Electronic Health Records; Humans; Information Storage and Retrieval; Linguistics; Medical Informatics; Natural Language Processing","Coreference resolution is the task of determining linguistic expressions that refer to the same real-world entity in natural language. Research on coreference resolution in the general English domain dates back to 1960s and 1970s. However, research on coreference resolution in the clinical free text has not seen major development. The recent US government initiatives that promote the use of electronic health records (EHRs) provide opportunities to mine patient notes as more and more health care institutions adopt EHR. Our goal was to review recent advances in general purpose coreference resolution to lay the foundation for methodologies in the clinical domain, facilitated by the availability of a shared lexical resource of gold standard coreference annotations, the Ontology Development and Information Extraction (ODIE) corpus.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22118,""
"Automatic extraction of relations between medical concepts in clinical texts","Rink, Harabagiu, Roberts","https://doi.org/10.1136/amiajnl-2011-000153","20120120","PubMed","Data Mining; Decision Support Systems, Clinical; Electronic Health Records; Humans; Internet; Natural Language Processing; Support Vector Machine","A supervised machine learning approach to discover relations between medical problems, treatments, and tests mentioned in electronic medical records. A single support vector machine classifier was used to identify relations between concepts and to assign their semantic type. Several resources such as Wikipedia, WordNet, General Inquirer, and a relation similarity metric inform the classifier. The techniques reported in this paper were evaluated in the 2010 i2b2 Challenge and obtained the highest F1 score for the relation extraction task. When gold standard data for concepts and assertions were available, F1 was 73.7, precision was 72.0, and recall was 75.3. F1 is defined as 2*Precision*Recall/(Precision+Recall). Alternatively, when concepts and assertions were discovered automatically, F1 was 48.4, precision was 57.6, and recall was 41.7. Although a rich set of features was developed for the classifiers presented in this paper, little knowledge mining was performed from medical ontologies such as those found in UMLS. Future studies should incorporate features extracted from such knowledge sources, which we expect to further improve the results. Moreover, each relation discovery was treated independently. Joint classification of relations may further improve the quality of results. Also, joint learning of the discovery of concepts, assertions, and relations may also improve the results of automatic relation extraction. Lexical and contextual features proved to be very important in relation extraction from medical texts. When they are not available to the classifier, the F1 score decreases by 3.7%. In addition, features based on similarity contribute to a decrease of 1.1% when they are not available.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22119,""
"Overcoming barriers to NLP for clinical text: the role of shared tasks and the need for additional creative solutions","Chapman, Nadkarni, Hirschman, D'Avolio, Savova, Uzuner","https://doi.org/10.1136/amiajnl-2011-000465","20120120","PubMed","Data Mining; Decision Support Systems, Clinical; Electronic Health Records; Humans; Natural Language Processing","","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22120,""
"Default mode network functional and structural connectivity after traumatic brain injury","Sharp, Beckmann, Greenwood, Kinnunen, Bonnelle, De Boissezon, Powell, Counsell, Patel, Leech","https://doi.org/10.1093/brain/awr175","20111013","PubMed","Adult; Anisotropy; Brain; Brain Injuries; Brain Mapping; Choice Behavior; Cognition Disorders; Female; Humans; Male; Middle Aged; Models, Neurological; Neural Pathways; Neuropsychological Tests; Reaction Time; Statistics as Topic; Tomography, X-Ray Computed","Traumatic brain injury often results in cognitive impairments that limit recovery. The underlying pathophysiology of these impairments is uncertain, which restricts clinical assessment and management. Here, we use magnetic resonance imaging to test the hypotheses that: (i) traumatic brain injury results in abnormalities of functional connectivity within key cognitive networks; (ii) these changes are correlated with cognitive performance; and (iii) functional connectivity within these networks is influenced by underlying changes in structural connectivity produced by diffuse axonal injury. We studied 20 patients in the chronic phase after traumatic brain injury compared with age-matched controls. Network function was investigated in detail using functional magnetic resonance imaging to analyse both regional brain activation, and the interaction of brain regions within a network (functional connectivity). We studied patients during performance of a simple choice-reaction task and at 'rest'. Since functional connectivity reflects underlying structural connectivity, diffusion tensor imaging was used to quantify axonal injury, and test whether structural damage correlated with functional change. The patient group showed typical impairments in information processing and attention, when compared with age-matched controls. Patients were able to perform the task accurately, but showed slow and variable responses. Brain regions activated by the task were similar between the groups, but patients showed greater deactivation within the default mode network, in keeping with an increased cognitive load. A multivariate analysis of 'resting' state functional magnetic resonance imaging was then used to investigate whether changes in network function were present in the absence of explicit task performance. Overall, default mode network functional connectivity was increased in the patient group. Patients with the highest functional connectivity had the least cognitive impairment. In addition, functional connectivity at rest also predicted patterns of brain activation during later performance of the task. As expected, patients showed widespread white matter damage compared with controls. Lower default mode network functional connectivity was seen in those patients with more evidence of diffuse axonal injury within the adjacent corpus callosum. Taken together, our results demonstrate altered patterns of functional connectivity in cognitive networks following injury. The results support a direct relationship between white matter organization within the brain's structural core, functional connectivity within the default mode network and cognitive function following brain injury. They can be explained by two related changes: a compensatory increase in functional connectivity within the default mode network; and a variable degree of structural disconnection that modulates this change in network function.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22121,""
"Bridging the text-image gap: a decision support tool for real-time PACS browsing","Sevenster, van Ommering, Qian","https://doi.org/10.1007/s10278-011-9414-x","20120719","PubMed","Algorithms; Artificial Intelligence; Decision Making, Computer-Assisted; Humans; Magnetic Resonance Imaging; Natural Language Processing; Radiology Information Systems; Systems Integration; User-Computer Interface","In this paper, we introduce an ontology-based technology that bridges the gap between MR images on the one hand and knowledge sources on the other hand. The proposed technology allows the user to express interest in a body region by selecting this region on the MR image he or she is viewing with a mouse device. The proposed technology infers the intended body structure from the manual selection and searches the external knowledge source for pertinent information. This technology can be used to bridge the gap between image data in the clinical workflow and (external) knowledge sources that help to assess the case with increased certainty, accuracy, and efficiency. We evaluate an instance of the proposed technology in the neurodomain by means of a user study in which three neuroradiologists participated. The user study shows that the technology has high recall (&gt;95%) when it comes to inferring the intended brain region from the participant's manual selection. We are confident that this helps to increase the experience of browsing external knowledge sources.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22122,""
"EliXR: an approach to eligibility criteria extraction and representation","Weng, Wu, Luo, Boland, Theodoratos, Johnson","https://doi.org/10.1136/amiajnl-2011-000321","20120824","PubMed","Algorithms; Biomedical Research; Data Mining; Eligibility Determination; Natural Language Processing; Patient Selection; Semantics; Unified Medical Language System","To develop a semantic representation for clinical research eligibility criteria to automate semistructured information extraction from eligibility criteria text. An analysis pipeline called eligibility criteria extraction and representation (EliXR) was developed that integrates syntactic parsing and tree pattern mining to discover common semantic patterns in 1000 eligibility criteria randomly selected from http://ClinicalTrials.gov. The semantic patterns were aggregated and enriched with unified medical language systems semantic knowledge to form a semantic representation for clinical research eligibility criteria. The authors arrived at 175 semantic patterns, which form 12 semantic role labels connected by their frequent semantic relations in a semantic network. Three raters independently annotated all the sentence segments (N=396) for 79 test eligibility criteria using the 12 top-level semantic role labels. Eight-six per cent (339) of the sentence segments were unanimously labelled correctly and 13.8% (55) were correctly labelled by two raters. The Fleiss' ÃŽÂº was 0.88, indicating a nearly perfect interrater agreement. This study present a semi-automated data-driven approach to developing a semantic network that aligns well with the top-level information structure in clinical research eligibility criteria text and demonstrates the feasibility of using the resulting semantic role labels to generate semistructured eligibility criteria with nearly perfect interrater reliability.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22123,""
"e-PKGene: a knowledge-based research tool for analysing the impact of genetics on drug exposure","Hachad, Overby, Argon, Yeung, Ragueneau-Majlessi, Levy","https://doi.org/10.1186/1479-7364-5-5-506","20120123","PubMed","Carrier Proteins; Cytochrome P-450 Enzyme System; Databases, Factual; Drug Interactions; Drug-Related Side Effects and Adverse Reactions; Genetic Variation; Humans; Internet; Knowledge Bases; Pharmaceutical Preparations; Pharmacokinetics; Pharmacology; Software; User-Computer Interface","e-PKGene (www.pharmacogeneticsinfo.org) is a manually curated knowledge product developed in the Department of Pharmaceutics at the University of Washington, USA. The tool integrates information from the literature, public repositories, reference textbooks, product prescribing labels and clinical review sections of new drug approval packages. The database's easy-to-use web portal offers tools for visualisation, reporting and filtering of information. The database helps scientists to mine pharmacokinetic and pharmacodynamic information for drug-metabolising enzymes and transporters, and provides access to available quantitative information on drug exposure contained in the literature. It allows in-depth analysis of the impact of genetic variants of enzymes and transporters on pharmacokinetic responses to drugs and metabolites. This review gives a brief description of the database organisation, its search functionalities and examples of use.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22124,""
"Automatically correlating clinical findings and body locations in radiology reports using MedLEE","Sevenster, van Ommering, Qian","https://doi.org/10.1007/s10278-011-9411-0","20120719","PubMed","Brain Diseases; Breast Diseases; Data Mining; Humans; Natural Language Processing; Radiography; Radiology; Radiology Information Systems; Software","In this paper, we describe and evaluate a system that extracts clinical findings and body locations from radiology reports and correlates them. The system uses Medical Language Extraction and Encoding System (MedLEE) to map the reports' free text to structured semantic representations of their content. A lightweight reasoning engine extracts the clinical findings and body locations from MedLEE's semantic representation and correlates them. Our study is illustrative for research in which existing natural language processing software is embedded in a larger system. We manually created a standard reference based on a corpus of neuro and breast radiology reports. The standard reference was used to evaluate the precision and recall of the proposed system and its modules. Our results indicate that the precision of our system is considerably better than its recall (82.32-91.37% vs. 35.67-45.91%). We conducted an error analysis and discuss here the practical usability of the system given its recall and precision performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22125,""
"Robotic-assisted transoral removal of a bilateral floor of mouth ranulas","Walvekar, Peters, Hardy, Alsfeld, Stromeyer, Anderson, DiLeo","https://doi.org/10.1186/1477-7819-9-78","20120103","PubMed","Biopsy; Diagnosis, Differential; Female; Follow-Up Studies; Humans; Middle Aged; Oral Surgical Procedures; Ranula; Robotics; Sublingual Gland; Sublingual Gland Neoplasms; Tomography, X-Ray Computed","To describe the management of bilateral oral ranulas with the use of the da Vinci Si Surgical System and discuss advantages and disadvantages over traditional transoral resection. Case Report and Review of Literature. A 47 year old woman presented to our service with an obvious right floor of mouth swelling. Clinical evaluation and computerized tomography scan confirmed a large floor of mouth ranula on the right and an incidental asymptomatic early ranula of the left sublingual gland. After obtaining an informed consent, the patient underwent a right transoral robotic-assisted transoral excision of the ranula and sublingual gland with identification and dissection of the submandibular duct and lingual nerve. The patient had an excellent outcome with no evidence of lingual nerve paresis and a return to oral intake on the first postoperative day. Subsequently, the patient underwent an elective transoral robotic-assisted excision of the incidental ranula on the left sublingual gland. We describe the first robotic-assisted excision of bilateral oral ranulas in current literature. The use of the da Vinci system provides excellent visualization, magnification, and dexterity for transoral surgical management of ranulas with preservation of the lingual nerve and Wharton's duct with good functional outcomes. However, the use of the robotic system for anterior floor of mouth surgery in terms of improved surgical outcomes as compared to traditional transoral surgery, long-term recurrence rates, and cost effectiveness needs further validation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22126,""
"Effectiveness of postgraduate training for learning extraperitoneal access for robot-assisted radical prostatectomy","Davis, Achim, Munsell, Matin","https://doi.org/10.1089/end.2011.0052","20111125","PubMed","Aged; Education, Medical, Graduate; Humans; Learning; Male; Middle Aged; Peritoneum; Program Evaluation; Prostatectomy; Robotics","To determine the effectiveness of postgraduate training for learning extraperitoneal robot-assisted radical prostatectomy (EP-RARP) and to identify any unmet training needs. The training resources used were live surgery observations, digital video disc instruction, postgraduate courses, and literature review. Modifications to the transperitoneal (TP) setup in equipment, patient positioning, port placement, and access technique were identified. A surgeon who had previous experience with 898 TP robot-assisted radical prostatectomies (TP-RARPs) performed EP-RARP in 30 patients. We evaluated setup results, emphasizing access-related difficulties, and compared the EP cohort with a nonrandomized, concurrent TP cohort of 62 patients for short-term outcomes. The median setup time for EP was 26 minutes (range 15-65Ã¢â‚¬â€°min) for EP compared with 14 to 17 minutes for the comparable TP setup and dropping the bladder. During EP setup and dissection, peritoneal entry occurred in 37%, incorrect port spacing in 10%, epigastric vessel injury in 10%, and other minor pitfalls in 10%. No significant differences were found between EP and TP in postsetup operative times, hospital stay, complications, surgical margin status with organ-confined disease, or lymph node dissection yield. EP had significantly higher estimated blood loss (300 vs 200Ã¢â‚¬â€°mL, P=0.001) and more symptomatic lymphoceles when extended pelvic lymph node dissection was performed (3/16 vs 0/47, P=0.001). Using postgraduate education resources, an experienced TP-RARP surgeon successfully transitioned to EP-RARP, achieving the major objectives of safety and equivalent outcomes. We identified several minor nuances in the setup that need further refinement in future education models.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22127,""
"A flexible framework for deriving assertions from electronic medical records","Roberts, Harabagiu","https://doi.org/10.1136/amiajnl-2011-000152","20120120","PubMed","Data Mining; Decision Support Systems, Clinical; Electronic Health Records; Humans; Natural Language Processing; Semantics; Support Vector Machine; Uncertainty","This paper describes natural-language-processing techniques for two tasks: identification of medical concepts in clinical text, and classification of assertions, which indicate the existence, absence, or uncertainty of a medical problem. Because so many resources are available for processing clinical texts, there is interest in developing a framework in which features derived from these resources can be optimally selected for the two tasks of interest. The authors used two machine-learning (ML) classifiers: support vector machines (SVMs) and conditional random fields (CRFs). Because SVMs and CRFs can operate on a large set of features extracted from both clinical texts and external resources, the authors address the following research question: Which features need to be selected for obtaining optimal results? To this end, the authors devise feature-selection techniques which greatly reduce the amount of manual experimentation and improve performance. The authors evaluated their approaches on the 2010 i2b2/VA challenge data. Concept extraction achieves 79.59 micro F-measure. Assertion classification achieves 93.94 micro F-measure. Approaching medical concept extraction and assertion classification through ML-based techniques has the advantage of easily adapting to new data sets and new medical informatics tasks. However, ML-based techniques perform best when optimal features are selected. By devising promising feature-selection techniques, the authors obtain results that outperform the current state of the art. This paper presents two ML-based approaches for processing language in the clinical texts evaluated in the 2010 i2b2/VA challenge. By using novel feature-selection methods, the techniques presented in this paper are unique among the i2b2 participants.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22128,""
"Decoding continuous variables from neuroimaging data: basic and clinical applications","Cohen, Asarnow, Sabb, Bilder, Bookheimer, Knowlton, Poldrack","https://doi.org/10.3389/fnins.2011.00075","20110714","PubMed","fMRI; high-dimensional regression; machine learning; multivariate decoding; predictive analysis","The application of statistical machine learning techniques to neuroimaging data has allowed researchers to decode the cognitive and disease states of participants. The majority of studies using these techniques have focused on pattern classification to decode the type of object a participant is viewing, the type of cognitive task a participant is completing, or the disease state of a participant's brain. However, an emerging body of literature is extending these classification studies to the decoding of values of continuous variables (such as age, cognitive characteristics, or neuropsychological state) using high-dimensional regression methods. This review details the methods used in such analyses and describes recent results. We provide specific examples of studies which have used this approach to answer novel questions about age and cognitive and disease states. We conclude that while there is still much to learn about these methods, they provide useful information about the relationship between neural activity and age, cognitive state, and disease state, which could not have been obtained using traditional univariate analytical methods.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22129,""
"Using machine learning for concept extraction on clinical documents from multiple data sources","Torii, Wagholikar, Liu","https://doi.org/10.1136/amiajnl-2011-000155","20120120","PubMed","Data Mining; Decision Support Systems, Clinical; Electronic Health Records; Humans; Information Dissemination; Natural Language Processing; Unified Medical Language System","Concept extraction is a process to identify phrases referring to concepts of interests in unstructured text. It is a critical component in automated text processing. We investigate the performance of machine learning taggers for clinical concept extraction, particularly the portability of taggers across documents from multiple data sources. We used BioTagger-GM to train machine learning taggers, which we originally developed for the detection of gene/protein names in the biology domain. Trained taggers were evaluated using the annotated clinical documents made available in the 2010 i2b2/VA Challenge workshop, consisting of documents from four data sources. As expected, performance of a tagger trained on one data source degraded when evaluated on another source, but the degradation of the performance varied depending on data sources. A tagger trained on multiple data sources was robust, and it achieved an F score as high as 0.890 on one data source. The results also suggest that performance of machine learning taggers is likely to improve if more annotated documents are available for training. Our study shows how the performance of machine learning taggers is degraded when they are ported across clinical documents from different sources. The portability of taggers can be enhanced by training on datasets from multiple sources. The study also shows that BioTagger-GM can be easily extended to detect clinical concept mentions with good performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22130,""
"Dynamic categorization of clinical research eligibility criteria by hierarchical clustering","Luo, Yetisgen-Yildiz, Weng","https://doi.org/10.1016/j.jbi.2011.06.001","20120405","PubMed","Algorithms; Artificial Intelligence; Biomedical Research; Cluster Analysis; Semantics; Unified Medical Language System","To semi-automatically induce semantic categories of eligibility criteria from text and to automatically classify eligibility criteria based on their semantic similarity. The UMLS semantic types and a set of previously developed semantic preference rules were utilized to create an unambiguous semantic feature representation to induce eligibility criteria categories through hierarchical clustering and to train supervised classifiers. We induced 27 categories and measured the prevalence of the categories in 27,278 eligibility criteria from 1578 clinical trials and compared the classification performance (i.e., precision, recall, and F1-score) between the UMLS-based feature representation and the ""bag of words"" feature representation among five common classifiers in Weka, including J48, Bayesian Network, NaÃƒÂ¯ve Bayesian, Nearest Neighbor, and instance-based learning classifier. The UMLS semantic feature representation outperforms the ""bag of words"" feature representation in 89% of the criteria categories. Using the semantically induced categories, machine-learning classifiers required only 2000 instances to stabilize classification performance. The J48 classifier yielded the best F1-score and the Bayesian Network classifier achieved the best learning efficiency. The UMLS is an effective knowledge source and can enable an efficient feature representation for semi-automated semantic category induction and automatic categorization for clinical research eligibility criteria and possibly other clinical text.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22131,""
"2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text","Uzuner, South, Shen, DuVall","https://doi.org/10.1136/amiajnl-2011-000203","20120120","PubMed","Data Mining; Decision Support Systems, Clinical; Electronic Health Records; Humans; Natural Language Processing","The 2010 i2b2/VA Workshop on Natural Language Processing Challenges for Clinical Records presented three tasks: a concept extraction task focused on the extraction of medical concepts from patient reports; an assertion classification task focused on assigning assertion types for medical problem concepts; and a relation classification task focused on assigning relation types that hold between medical problems, tests, and treatments. i2b2 and the VA provided an annotated reference standard corpus for the three tasks. Using this reference standard, 22 systems were developed for concept extraction, 21 for assertion classification, and 16 for relation classification. These systems showed that machine learning approaches could be augmented with rule-based systems to determine concepts, assertions, and relations. Depending on the task, the rule-based systems can either provide input for machine learning or post-process the output of machine learning. Ensembles of classifiers, information from unlabeled data, and external knowledge sources can help when the training data are inadequate.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22132,""
"Discovering and visualizing indirect associations between biomedical concepts","Tsuruoka, Miwa, Hamamoto, Tsujii, Ananiadou","https://doi.org/10.1093/bioinformatics/btr214","20111027","PubMed","Artificial Intelligence; Data Mining; Internet; MEDLINE; Medical Informatics Applications; PubMed; United States","Discovering useful associations between biomedical concepts has been one of the main goals in biomedical text-mining, and understanding their biomedical contexts is crucial in the discovery process. Hence, we need a text-mining system that helps users explore various types of (possibly hidden) associations in an easy and comprehensible manner. This article describes FACTA+, a real-time text-mining system for finding and visualizing indirect associations between biomedical concepts from MEDLINE abstracts. The system can be used as a text search engine like PubMed with additional features to help users discover and visualize indirect associations between important biomedical concepts such as genes, diseases and chemical compounds. FACTA+ inherits all functionality from its predecessor, FACTA, and extends it by incorporating three new features: (i) detecting biomolecular events in text using a machine learning model, (ii) discovering hidden associations using co-occurrence statistics between concepts, and (iii) visualizing associations to improve the interpretability of the output. To the best of our knowledge, FACTA+ is the first real-time web application that offers the functionality of finding concepts involving biomolecular events and visualizing indirect associations of concepts with both their categories and importance. FACTA+ is available as a web application at http://refine1-nactem.mc.man.ac.uk/facta/, and its visualizer is available at http://refine1-nactem.mc.man.ac.uk/facta-visualizer/. tsuruoka@jaist.ac.jp.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22133,""
"Computerized lung sound analysis as diagnostic aid for the detection of abnormal lung sounds: a systematic review and meta-analysis","Gurung, Scrafford, Tielsch, Levine, Checkley","https://doi.org/10.1016/j.rmed.2011.05.007","20111114","PubMed","Auscultation; Diagnosis, Computer-Assisted; Humans; Lung Diseases; Respiratory Sounds; Sensitivity and Specificity; Signal Processing, Computer-Assisted; Stethoscopes","The standardized use of a stethoscope for chest auscultation in clinical research is limited by its inherent inter-listener variability. Electronic auscultation and automated classification of recorded lung sounds may help prevent some of these shortcomings. We sought to perform a systematic review and meta-analysis of studies implementing computerized lung sound analysis (CLSA) to aid in the detection of abnormal lung sounds for specific respiratory disorders. We searched for articles on CLSA in MEDLINE, EMBASE, Cochrane Library and ISI Web of Knowledge through July 31, 2010. Following qualitative review, we conducted a meta-analysis to estimate the sensitivity and specificity of CLSA for the detection of abnormal lung sounds. Of 208 articles identified, we selected eight studies for review. Most studies employed either electret microphones or piezoelectric sensors for auscultation, and Fourier Transform and Neural Network algorithms for analysis and automated classification of lung sounds. Overall sensitivity for the detection of wheezes or crackles using CLSA was 80% (95% CI 72-86%) and specificity was 85% (95% CI 78-91%). While quality data on CLSA are relatively limited, analysis of existing information suggests that CLSA can provide a relatively high specificity for detecting abnormal lung sounds such as crackles and wheezes. Further research and product development could promote the value of CLSA in research studies or its diagnostic utility in clinical settings.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22134,""
"A context-blocks model for identifying clinical relationships in patient records","Islamaj DoÃ„Å¸an, NÃƒÂ©vÃƒÂ©ol, Lu","https://doi.org/10.1186/1471-2105-12-S3-S3","20110803","PubMed","Humans; Medical Records Systems, Computerized; Medical Records, Problem-Oriented; Models, Statistical; Natural Language Processing","Patient records contain valuable information regarding explanation of diagnosis, progression of disease, prescription and/or effectiveness of treatment, and more. Automatic recognition of clinically important concepts and the identification of relationships between those concepts in patient records are preliminary steps for many important applications in medical informatics, ranging from quality of care to hypothesis generation. In this work we describe an approach that facilitates the automatic recognition of eight relationships defined between medical problems, treatments and tests. Unlike the traditional bag-of-words representation, in this work, we represent a relationship with a scheme of five distinct context-blocks determined by the position of concepts in the text. As a preliminary step to relationship recognition, and in order to provide an end-to-end system, we also addressed the automatic extraction of medical problems, treatments and tests. Our approach combined the outcome of a statistical model for concept recognition and simple natural language processing features in a conditional random fields model. A set of 826 patient records from the 4th i2b2 challenge was used for training and evaluating the system. Results show that our concept recognition system achieved an F-measure of 0.870 for exact span concept detection. Moreover the context-block representation of relationships was more successful (F-Measure = 0.775) at identifying relationships than bag-of-words (F-Measure = 0.402). Most importantly, the performance of the end-to-end system of relationship extraction using automatically extracted concepts (F-Measure = 0.704) was comparable to that obtained using manually annotated concepts (F-Measure = 0.711), and their difference was not statistically significant. We extracted important clinical relationships from text in an automated manner, starting with concept recognition, and ending with relationship identification. The advantage of the context-blocks representation scheme was the correct management of word position information, which may be critical in identifying certain relationships. Our results may serve as benchmark for comparison to other systems developed on i2b2 challenge data. Finally, our system may serve as a preliminary step for other discovery tasks in medical informatics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22135,""
"Characterizing mammography reports for health analytics","Rojas, Patton, Beckerman","https://doi.org/10.1007/s10916-011-9685-2","20120430","PubMed","Electronic Data Processing; Electronic Health Records; Female; Humans; Information Management; Mammography; Reproducibility of Results","As massive collections of digital health data are becoming available, the opportunities for large-scale automated analysis increase. In particular, the widespread collection of detailed health information is expected to help realize a vision of evidence-based public health and patient-centric health care. Within such a framework for large scale health analytics we describe the transformation of a large data set of mostly unlabeled and free-text mammography data into a searchable and accessible collection, usable for analytics. We also describe several methods to characterize and analyze the data, including their temporal aspects, using information retrieval, supervised learning, and classical statistical techniques. We present experimental results that demonstrate the validity and usefulness of the approach, since the results are consistent with the known features of the data, provide novel insights about it, and can be used in specific applications. Additionally, based on the process of going from raw data to results from analysis, we present the architecture of a generic system for health analytics from clinical notes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22136,""
"What can we learn from first-year medical students' perceptions of pain in the primary care setting?","Corrigan, Desnick, Marshall, Bentov, Rosenblatt","https://doi.org/10.1111/j.1526-4637.2011.01150.x","20120111","PubMed","Adult; Curriculum; Female; Humans; Male; Pain; Physician-Patient Relations; Primary Health Care; Students, Medical","Pain concerns are one of the leading causes of visits to primary care. However, practicing physicians find managing pain frustrating and complex. There is little information about how undergraduate medical students approach pain and its management. This study aimed to explore first-year medical students' perceptions of pain-related patient encounters in the primary care setting. Qualitative analysis was used to explore first-year students' reflective journals written during an early clinical experience in primary care. Using iterative process for text analysis, entries referencing pain-related encounters were coded by two independent researchers with 94% inter-rater reliability. Themes and categories were sought by immersion crystallization. Three themes emerged from the students' journals: positive, negative, and neutral perceptions of pain-related encounters. With further analysis of the journals, acute, chronic, end-of-life, iatrogenic, and emotional pain categories also emerged. Most journal entries were negative, and chronic pain generated the most negativity. First-year medical students identified pain as a major concern in their early clinical experience. Students' perceptions of pain-related encounters can inform curriculum design and may ultimately benefit both physicians and the patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22137,""
"Towards an Age-Phenome Knowledge-base","Geifman, Rubin","https://doi.org/10.1186/1471-2105-12-229","20110919","PubMed","Age Factors; Data Mining; Humans; Knowledge; Phenotype","Currently, data about age-phenotype associations are not systematically organized and cannot be studied methodically. Searching for scientific articles describing phenotypic changes reported as occurring at a given age is not possible for most ages. Here we present the Age-Phenome Knowledge-base (APK), in which knowledge about age-related phenotypic patterns and events can be modeled and stored for retrieval. The APK contains evidence connecting specific ages or age groups with phenotypes, such as disease and clinical traits. Using a simple text mining tool developed for this purpose, we extracted instances of age-phenotype associations from journal abstracts related to non-insulin-dependent Diabetes Mellitus. In addition, links between age and phenotype were extracted from clinical data obtained from the NHANES III survey. The knowledge stored in the APK is made available for the relevant research community in the form of 'Age-Cards', each card holds the collection of all the information stored in the APK about a particular age. These Age-Cards are presented in a wiki, allowing community review, amendment and contribution of additional information. In addition to the wiki interaction, complex searches can also be conducted which require the user to have some knowledge of database query construction. The combination of a knowledge model based repository with community participation in the evolution and refinement of the knowledge-base makes the APK a useful and valuable environment for collecting and curating existing knowledge of the connections between age and phenotypes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22138,""
"Combined optical tweezers and laser dissector for controlled ablation of functional connections in neural networks","Difato, Dal Maschio, Marconi, Ronzitti, Maccione, Fellin, Berdondini, Chieregatti, Benfenati, Blau","https://doi.org/10.1117/1.3560268","20120228","PubMed","Animals; Cells, Cultured; Dissection; Equipment Design; Equipment Failure Analysis; Laser Therapy; Microsurgery; Nerve Net; Neurites; Optical Tweezers; Rats; Rats, Sprague-Dawley; Robotics; Systems Integration","Regeneration of functional connectivity within a neural network after different degrees of lesion is of utmost clinical importance. To test pharmacological approaches aimed at recovering from a total or partial damage of neuronal connections within a circuit, it is necessary to develop a precise method for controlled ablation of neuronal processes. We combined a UV laser microdissector to ablate neural processes in vitro at single neuron and neural network level with infrared holographic optical tweezers to carry out force spectroscopy measurements. Simultaneous force spectroscopy, down to the sub-pico-Newton range, was performed during laser dissection to quantify the tension release in a partially ablated neurite. Therefore, we could control and measure the damage inflicted to an individual neuronal process. To characterize the effect of the inflicted injury on network level, changes in activity of neural subpopulations were monitored with subcellular resolution and overall network activity with high temporal resolution by concurrent calcium imaging and microelectrode array recording. Neuronal connections have been sequentially ablated and the correlated changes in network activity traced and mapped. With this unique combination of electrophysiological and optical tools, neural activity can be studied and quantified in response to controlled injury at the subcellular, cellular, and network level.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22139,""
"Laparoendoscopic single site (LESS) radical prostatectomy: a review of the initial experience","Silberstein, Power, Touijer","https://www.google.com/search?q=Laparoendoscopic+single+site+(LESS)+radical+prostatectomy:+a+review+of+the+initial+experience.","20111005","PubMed","Forecasting; Humans; Laparoscopy; Male; Prostatectomy; Prostatic Neoplasms; Robotics","Surgical treatment for prostate cancer has changed dramatically in recent years due to the incorporation of minimally invasive techniques in the surgical armamentarium. Open surgical approaches to the prostate have largely given way to laparoscopic and robotic techniques. In order to further reduce incisional morbidity and improve cosmesis, there has been a recent interest in laparoendoscopic single site (LESS) approaches to the prostate. Despite a rising interest, there is little available data on these procedures. We performed a systematic review of the literature using MEDLINE, OVID, and Web of Science to identify all publications including LESS radical prostatectomy to date. Manual bibliographic review of cross-referenced items was also performed. We attempt to identify and summarize existing data on these procedures both with and without robotic assistance. Additionally, we review the emerging devices, instruments, cameras, and ports that have made these procedures possible. Next, we offer insight into how this rapidly moving field may transition in the future. Finally, we provide our commentary on this surgical approach, its impact on urology, and how it may help us evolve in the future.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22140,""
"CoPub update: CoPub 50 a text mining system to answer biological questions","Fleuren, Verhoeven, Frijters, Heupers, Polman, van Schaik, de Vlieg, Alkema","https://doi.org/10.1093/nar/gkr310","20111107","PubMed","Data Mining; Gene Regulatory Networks; Internet; PubMed; Software","In this article, we present CoPub 5.0, a publicly available text mining system, which uses Medline abstracts to calculate robust statistics for keyword co-occurrences. CoPub was initially developed for the analysis of microarray data, but we broadened the scope by implementing new technology and new thesauri. In CoPub 5.0, we integrated existing CoPub technology with new features, and provided a new advanced interface, which can be used to answer a variety of biological questions. CoPub 5.0 allows searching for keywords of interest and its relations to curated thesauri and provides highlighting and sorting mechanisms, using its statistics, to retrieve the most important abstracts in which the terms co-occur. It also provides a way to search for indirect relations between genes, drugs, pathways and diseases, following an ABC principle, in which A and C have no direct connection but are connected via shared B intermediates. With CoPub 5.0, it is possible to create, annotate and analyze networks using the layout and highlight options of Cytoscape web, allowing for literature based systems biology. Finally, operations of the CoPub 5.0 Web service enable to implement the CoPub technology in bioinformatics workflows. CoPub 5.0 can be accessed through the CoPub portal http://www.copub.org.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22141,""
"The Yale cTAKES extensions for document classification: architecture and application","Garla, Lo Re, Dorey-Stein, Kidwai, Scotch, Womack, Justice, Brandt","https://doi.org/10.1136/amiajnl-2011-000093","20120120","PubMed","Connecticut; Data Mining; Decision Support Systems, Clinical; Electronic Health Records; Humans; Liver Failure; Natural Language Processing; Pattern Recognition, Automated; Radiography; Radiology Information Systems","Open-source clinical natural-language-processing (NLP) systems have lowered the barrier to the development of effective clinical document classification systems. Clinical natural-language-processing systems annotate the syntax and semantics of clinical text; however, feature extraction and representation for document classification pose technical challenges. The authors developed extensions to the clinical Text Analysis and Knowledge Extraction System (cTAKES) that simplify feature extraction, experimentation with various feature representations, and the development of both rule and machine-learning based document classifiers. The authors describe and evaluate their system, the Yale cTAKES Extensions (YTEX), on the classification of radiology reports that contain findings suggestive of hepatic decompensation. The F(1)-Score of the system for the retrieval of abdominal radiology reports was 96%, and was 79%, 91%, and 95% for the presence of liver masses, ascites, and varices, respectively. The authors released YTEX as open source, available at http://code.google.com/p/ytex.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22142,""
"Exploring subdomain variation in biomedical language","Lippincott, SÃƒÂ©aghdha, Korhonen","https://doi.org/10.1186/1471-2105-12-212","20110831","PubMed","Artificial Intelligence; Biomedical Research; Child; Data Mining; Humans; Natural Language Processing; Semantics","Applications of Natural Language Processing (NLP) technology to biomedical texts have generated significant interest in recent years. In this paper we identify and investigate the phenomenon of linguistic subdomain variation within the biomedical domain, i.e., the extent to which different subject areas of biomedicine are characterised by different linguistic behaviour. While variation at a coarser domain level such as between newswire and biomedical text is well-studied and known to affect the portability of NLP systems, we are the first to conduct an extensive investigation into more fine-grained levels of variation. Using the large OpenPMC text corpus, which spans the many subdomains of biomedicine, we investigate variation across a number of lexical, syntactic, semantic and discourse-related dimensions. These dimensions are chosen for their relevance to the performance of NLP systems. We use clustering techniques to analyse commonalities and distinctions among the subdomains. We find that while patterns of inter-subdomain variation differ somewhat from one feature set to another, robust clusters can be identified that correspond to intuitive distinctions such as that between clinical and laboratory subjects. In particular, subdomains relating to genetics and molecular biology, which are the most common sources of material for training and evaluating biomedical NLP tools, are not representative of all biomedical subdomains. We conclude that an awareness of subdomain variation is important when considering the practical use of language processing applications by biomedical researchers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22143,""
"Cost-effectiveness analysis of antimuscarinics in the treatment of patients with overactive bladder in Spain: a decision-tree model","Arlandis-Guzman, Errando-Smet, Trocio, Arumi, Rejas","https://doi.org/10.1186/1471-2490-11-9","20111102","PubMed","Adult; Aged; Aged, 80 and over; Cost-Benefit Analysis; Double-Blind Method; Female; Health Care Costs; Humans; Male; Middle Aged; Muscarinic Antagonists; Prevalence; Spain; Urinary Bladder, Overactive; Young Adult","Fesoterodine, a new once daily antimuscarinic, has proven to be an effective, safe, and well-tolerated treatment in patients with overactive bladder (OAB). To date, no analysis has evaluated the economic costs and benefits associated with fesoterodine, compared to antimuscarinics in Spain. The purpose of this analysis was to assess the economic value of OAB treatment with fesoterodine relative to extended release tolterodine and solifenacin, from the societal perspective. The economic model was based on data from two 12-week, randomized, double-blind, and multicenter trials comparing fesoterodine and tolterodine extended released (ER). Treatment response rates for solifenacin were extracted from the published literature. Discontinuation and efficacy were based on the results of a 12-week multinational randomized clinical trial extrapolated to 52 weeks. Changes in health related quality of life were assessed with the King's Health Questionnaire, which was transformed into preference-based utility values. Medical costs included (expressed in Ã¢â€šÂ¬ 2010) were antimuscarinics, physician visits, laboratory tests, incontinence pads and the costs of OAB-related comorbidities, fractures, skin infections, urinary tract infections, depression, and nursing home admissions associated with incontinence. Time lost from work was also considered. Univariate sensitivity analyses were also performed. At week 12, continents accounted for 50.6%, 40.6% and 47.2% of patients in the fesoterodine, tolterodine, and solifenacin groups, respectively. By week 52, the projected proportions of patients remaining on therapy were 33.1%, 26.5% and 30.8%, respectively. The projected quality- adjusted life years (QALY) gain (compared to baseline) over the 52-week simulation period were 0.01014, 0.00846 and 0.00957, respectively. The overall treatment cost was estimated at Ã¢â€šÂ¬1,937, Ã¢â€šÂ¬2,089 and Ã¢â€šÂ¬1,960 for fesoterodine, tolterodine and solifenacin, respectively. Therefore, treatment with fesoterodine resulted in similar overall costs and greater QALY gain than treatment with either tolterodine or solifenacin. Sensitivity analysis showed that these results were robust to all changes performed. The results of this economic analysis suggest that fesoterodine is a cost-effective alternative to tolterodine and solifenacin for the treatment of patients with OAB in Spain. Fesoterodine provides additional health benefits while maintain a similar level of costs being a cost-effective treatment strategy from a societal perspective.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22144,""
"Hybrid methods for improving information access in clinical documents: concept, assertion, and relation identification","Minard, Ligozat, Ben Abacha, Bernhard, Cartoni, DelÃƒÂ©ger, Grau, Rosset, Zweigenbaum, Grouin","https://doi.org/10.1136/amiajnl-2011-000154","20120120","PubMed","Data Mining; Decision Support Systems, Clinical; Electronic Health Records; Expert Systems; Humans; Natural Language Processing; Semantics; Support Vector Machine; Unified Medical Language System","This paper describes the approaches the authors developed while participating in the i2b2/VA 2010 challenge to automatically extract medical concepts and annotate assertions on concepts and relations between concepts. The authors'approaches rely on both rule-based and machine-learning methods. Natural language processing is used to extract features from the input texts; these features are then used in the authors' machine-learning approaches. The authors used Conditional Random Fields for concept extraction, and Support Vector Machines for assertion and relation annotation. Depending on the task, the authors tested various combinations of rule-based and machine-learning methods. The authors'assertion annotation system obtained an F-measure of 0.931, ranking fifth out of 21 participants at the i2b2/VA 2010 challenge. The authors' relation annotation system ranked third out of 16 participants with a 0.709 F-measure. The 0.773 F-measure the authors obtained on concept extraction did not make it to the top 10. On the one hand, the authors confirm that the use of only machine-learning methods is highly dependent on the annotated training data, and thus obtained better results for well-represented classes. On the other hand, the use of only a rule-based method was not sufficient to deal with new types of data. Finally, the use of hybrid approaches combining machine-learning and rule-based approaches yielded higher scores.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22145,""
"Degree centrality for semantic abstraction summarization of therapeutic studies","Zhang, Fiszman, Shin, Miller, Rosemblat, Rindflesch","https://doi.org/10.1016/j.jbi.2011.05.001","20120419","PubMed","Algorithms; Humans; Information Storage and Retrieval; MEDLINE; Natural Language Processing; Semantics; Unified Medical Language System","Automatic summarization has been proposed to help manage the results of biomedical information retrieval systems. Semantic MEDLINE, for example, summarizes semantic predications representing assertions in MEDLINE citations. Results are presented as a graph which maintains links to the original citations. Graphs summarizing more than 500 citations are hard to read and navigate, however. We exploit graph theory for focusing these large graphs. The method is based on degree centrality, which measures connectedness in a graph. Four categories of clinical concepts related to treatment of disease were identified and presented as a summary of input text. A baseline was created using term frequency of occurrence. The system was evaluated on summaries for treatment of five diseases compared to a reference standard produced manually by two physicians. The results showed that recall for system results was 72%, precision was 73%, and F-score was 0.72. The system F-score was considerably higher than that for the baseline (0.47).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22146,""
"Design and development of an international clinical data exchange system: the international layer function of the Dolphin Project","Li, Zhou, Chu, Araki, Yoshihara","https://doi.org/10.1136/amiajnl-2011-000111","20120120","PubMed","China; Computer Security; Electronic Health Records; Humans; Information Dissemination; International Cooperation; Japan; Medical Record Linkage; Natural Language Processing; Programming Languages; Reference Standards; Systems Integration; Translating; User-Computer Interface","At present, most clinical data are exchanged between organizations within a regional system. However, people traveling abroad may need to visit a hospital, which would make international exchange of clinical data very useful. Since 2007, a collaborative effort to achieve clinical data sharing has been carried out at Zhejiang University in China and Kyoto University and Miyazaki University in Japan; each is running a regional clinical information center. Methods An international layer system named Global Dolphin was constructed with several key services, sharing patients' health information between countries using a medical markup language (MML). The system was piloted with 39 test patients. The three regions above have records for 966,000 unique patients, which are available through Global Dolphin. Data exchanged successfully from Japan to China for the 39 study patients include 1001 MML files and 152 images. The MML files contained 197 free text-type paragraphs that needed human translation. Discussion The pilot test in Global Dolphin demonstrates that patient information can be shared across countries through international health data exchange. To achieve cross-border sharing of clinical data, some key issues had to be addressed: establishment of a super directory service across countries; data transformation; and unique one-language translation. Privacy protection was also taken into account. The system is now ready for live use. The project demonstrates a means of achieving worldwide accessibility of medical data, by which the integrity and continuity of patients' health information can be maintained.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22147,""
"[Robot-assisted radical cystectomy Pilot study for the prospective evaluation of perioperative parameters compared to open radical cystectomy]","Niegisch, Rabenalt, Albers","https://doi.org/10.1007/s00120-011-2580-0","20120203","PubMed","Aged; Carcinoma, Transitional Cell; Comorbidity; Convalescence; Cystectomy; Erythrocyte Transfusion; Female; Humans; Length of Stay; Male; Middle Aged; Multicenter Studies as Topic; Pilot Projects; Postoperative Complications; Prospective Studies; Randomized Controlled Trials as Topic; Retrospective Studies; Robotics; Urinary Bladder Neoplasms; Urinary Diversion","For robot-assisted radical cystectomy prospective assembly and evaluation of peri- and postoperative parameters within a national database is planned. This pilot study evaluated which parameters should be assessed and which problems might occur for assembly and interpretation of data. Of 84 patients with radical cystectomy, 14 underwent RARC. Evaluable patients were compared to patients with open radical cystectomy (ORC) regarding perioperative parameters. In addition, a literature review on published single-center RARC series and comparative investigations (RARC vs ORC) was performed. Published data were compared to results of our own series. RARC patients received less packed red blood cells [RARC: 0 (0-2), ORC 2 (0-12), p=0.009] and hospitalization was shorter [RARC: 14 (8-18) days, ORC: 18 (11-97) days, p=0.015]. Comorbidities as assessed by the Charlson Comorbidity Index were less common in RARC patients [RARC: 4 (3-8), ORC: 6 (3-11), p=0.11]. No major differences between our own and published results were observed. The rate of continent urinary diversions in the DÃƒÂ¼sseldorf RARC cohort was, apart from one study, larger. Problems in the assembly and interpretation of operation time, blood loss, transfusion rate, and postoperative recovery were observed. Even in this small cohort results of published studies were confirmed. Potential problems in data assembly were identified. Appropriate solutions will be implemented in the national database.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22148,""
"Machine-learned solutions for three stages of clinical information extraction: the state of the art at i2b2 2010","de Bruijn, Cherry, Kiritchenko, Martin, Zhu","https://doi.org/10.1136/amiajnl-2011-000150","20120120","PubMed","Algorithms; Artificial Intelligence; Benchmarking; Canada; Data Mining; Electronic Health Records; Humans; Natural Language Processing","As clinical text mining continues to mature, its potential as an enabling technology for innovations in patient care and clinical research is becoming a reality. A critical part of that process is rigid benchmark testing of natural language processing methods on realistic clinical narrative. In this paper, the authors describe the design and performance of three state-of-the-art text-mining applications from the National Research Council of Canada on evaluations within the 2010 i2b2 challenge. The three systems perform three key steps in clinical information extraction: (1) extraction of medical problems, tests, and treatments, from discharge summaries and progress notes; (2) classification of assertions made on the medical problems; (3) classification of relations between medical concepts. Machine learning systems performed these tasks using large-dimensional bags of features, as derived from both the text itself and from external sources: UMLS, cTAKES, and Medline. Performance was measured per subtask, using micro-averaged F-scores, as calculated by comparing system annotations with ground-truth annotations on a test set. The systems ranked high among all submitted systems in the competition, with the following F-scores: concept extraction 0.8523 (ranked first); assertion detection 0.9362 (ranked first); relationship detection 0.7313 (ranked second). For all tasks, we found that the introduction of a wide range of features was crucial to success. Importantly, our choice of machine learning algorithms allowed us to be versatile in our feature design, and to introduce a large number of features without overfitting and without encountering computing-resource bottlenecks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22149,""
"Deriving a probabilistic syntacto-semantic grammar for biomedicine based on domain-specific terminologies","Fan, Friedman","https://doi.org/10.1016/j.jbi.2011.04.006","20120419","PubMed","Information Storage and Retrieval; Semantics; Terminology as Topic; Unified Medical Language System; Vocabulary, Controlled","Biomedical natural language processing (BioNLP) is a useful technique that unlocks valuable information stored in textual data for practice and/or research. Syntactic parsing is a critical component of BioNLP applications that rely on correctly determining the sentence and phrase structure of free text. In addition to dealing with the vast amount of domain-specific terms, a robust biomedical parser needs to model the semantic grammar to obtain viable syntactic structures. With either a rule-based or corpus-based approach, the grammar engineering process requires substantial time and knowledge from experts, and does not always yield a semantically transferable grammar. To reduce the human effort and to promote semantic transferability, we propose an automated method for deriving a probabilistic grammar based on a training corpus consisting of concept strings and semantic classes from the Unified Medical Language System (UMLS), a comprehensive terminology resource widely used by the community. The grammar is designed to specify noun phrases only due to the nominal nature of the majority of biomedical terminological concepts. Evaluated on manually parsed clinical notes, the derived grammar achieved a recall of 0.644, precision of 0.737, and average cross-bracketing of 0.61, which demonstrated better performance than a control grammar with the semantic information removed. Error analysis revealed shortcomings that could be addressed to improve performance. The results indicated the feasibility of an approach which automatically incorporates terminology semantics in the building of an operational grammar. Although the current performance of the unsupervised solution does not adequately replace manual engineering, we believe once the performance issues are addressed, it could serve as an aide in a semi-supervised solution.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22150,""
"A study of machine-learning-based approaches to extract clinical entities and their assertions from discharge summaries","Jiang, Chen, Liu, Rosenbloom, Mani, Denny, Xu","https://doi.org/10.1136/amiajnl-2011-000163","20120120","PubMed","Artificial Intelligence; Data Mining; Decision Support Systems, Clinical; Electronic Health Records; Humans; Natural Language Processing; Patient Discharge; Pattern Recognition, Automated; Semantics; Vocabulary, Controlled","The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted status-from hospital discharge summaries written using natural language. This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge. The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes. Based on the results from training data, the authors developed a novel hybrid clinical entity extraction system, which integrated heuristic rule-based modules with the ML-base named entity recognition module. The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes. Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers. The overall performance for all three types of clinical entities and all six types of assertions across 477 annotated notes were considered as the primary metric in the challenge. Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied. The authors' hybrid entity extraction system achieved a maximum overall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22151,""
"Characterizing Deep Brain Stimulation effects in computationally efficient neural network models","Latteri, Arena, Mazzone","https://doi.org/10.1186/1753-4631-5-2","20110714","PubMed","","Recent studies on the medical treatment of Parkinson's disease (PD) led to the introduction of the so called Deep Brain Stimulation (DBS) technique. This particular therapy allows to contrast actively the pathological activity of various Deep Brain structures, responsible for the well known PD symptoms. This technique, frequently joined to dopaminergic drugs administration, replaces the surgical interventions implemented to contrast the activity of specific brain nuclei, called Basal Ganglia (BG). This clinical protocol gave the possibility to analyse and inspect signals measured from the electrodes implanted into the deep brain regions. The analysis of these signals led to the possibility to study the PD as a specific case of dynamical synchronization in biological neural networks, with the advantage to apply the theoretical analysis developed in such scientific field to find efficient treatments to face with this important disease. Experimental results in fact show that the PD neurological diseases are characterized by a pathological signal synchronization in BG. Parkinsonian tremor, for example, is ascribed to be caused by neuron populations of the Thalamic and Striatal structures that undergo an abnormal synchronization. On the contrary, in normal conditions, the activity of the same neuron populations do not appear to be correlated and synchronized. To study in details the effect of the stimulation signal on a pathological neural medium, efficient models of these neural structures were built, which are able to show, without any external input, the intrinsic properties of a pathological neural tissue, mimicking the BG synchronized dynamics.We start considering a model already introduced in the literature to investigate the effects of electrical stimulation on pathologically synchronized clusters of neurons. This model used Morris Lecar type neurons. This neuron model, although having a high level of biological plausibility, requires a large computational effort to simulate large scale networks. For this reason we considered a reduced order model, the Izhikevich one, which is computationally much lighter. The comparison between neural lattices built using both neuron models provided comparable results, both without traditional stimulation and in presence of all the stimulation protocols. This was a first result toward the study and simulation of the large scale neural networks involved in pathological dynamics.Using the reduced order model an inspection on the activity of two neural lattices was also carried out at the aim to analyze how the stimulation in one area could affect the dynamics in another area, like the usual medical treatment protocols require.The study of population dynamics that was carried out allowed us to investigate, through simulations, the positive effects of the stimulation signals in terms of desynchronization of the neural dynamics. The results obtained constitute a significant added value to the analysis of synchronization and desynchronization effects due to neural stimulation. This work gives the opportunity to more efficiently study the effect of stimulation in large scale yet computationally efficient neural networks. Results were compared both with the other mathematical models, using Morris Lecar and Izhikevich neurons, and with simulated Local Field Potentials (LFP).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22152,""
"Phantom headache: pain-memory-emotion hypothesis for chronic daily headache?","Prakash, Golwala","https://doi.org/10.1007/s10194-011-0307-7","20110901","PubMed","Emotions; Headache Disorders; Humans; Memory; Memory Disorders; Phantom Limb; Prevalence","The neurobiology of chronic pain, including chronic daily headache (CDH) is not completely understood. ""Pain memory"" hypothesis is one of the mechanisms for phantom limb pain. We reviewed the literature to delineate a relation of ""pain memory"" for the development of CDH. There is a direct relation of pain to memory. Patients with poor memory have less chance to develop ""pain memory"", hence less possibility to develop chronic pain. Progressive memory impairment may lead to decline in headache prevalence. A similar relation of pain is also noted with emotional or psychiatric symptoms. Literature review suggests that there is marked overlap in the neural network of pain to that of memory and emotions. We speculate that pain, memory, and emotions are interrelated in triangular pattern, and each of these three is related to other two in bidirectional pattern, i.e., stimulation of one of these will stimulate other symptoms/networks and vice versa (triangular theory for chronic pain). Longstanding or recurrent noxious stimuli will strengthen this interrelation, and this may be responsible for chronicity of pain. Reduction of both chronic pain and psychological symptoms by cognitive behavioral therapy or psychological interventions further suggests a bidirectional interrelation between pain and emotion. Longitudinal studies are warranted on the prevalence of headache and other painful conditions in patients with progressive memory impairment to delineate the relation of pain to memory. Interrelation of headache to emotional symptoms should also be explored.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22153,""
"Anaphoric relations in the clinical narrative: corpus creation","Savova, Chapman, Zheng, Crowley","https://doi.org/10.1136/amiajnl-2011-000108","20111102","PubMed","Data Mining; Electronic Health Records; Guidelines as Topic; Humans; Linguistics; Natural Language Processing; Reference Standards; Reproducibility of Results","The long-term goal of this work is the automated discovery of anaphoric relations from the clinical narrative. The creation of a gold standard set from a cross-institutional corpus of clinical notes and high-level characteristics of that gold standard are described. A standard methodology for annotation guideline development, gold standard annotations, and inter-annotator agreement (IAA) was used. The gold standard annotations resulted in 7214 markables, 5992 pairs, and 1304 chains. Each report averaged 40 anaphoric markables, 33 pairs, and seven chains. The overall IAA is high on the Mayo dataset (0.6607), and moderate on the University of Pittsburgh Medical Center (UPMC) dataset (0.4072). The IAA between each annotator and the gold standard is high (Mayo: 0.7669, 0.7697, and 0.9021; UPMC: 0.6753 and 0.7138). These results imply a quality corpus feasible for system development. They also suggest the complementary nature of the annotations performed by the experts and the importance of an annotator team with diverse knowledge backgrounds. Only one of the annotators had the linguistic background necessary for annotation of the linguistic attributes. The overall generalizability of the guidelines will be further strengthened by annotations of data from additional sites. This will increase the overall corpus size and the representation of each relation type. The first step toward the development of an anaphoric relation resolver as part of a comprehensive natural language processing system geared specifically for the clinical narrative in the electronic medical record is described. The deidentified annotated corpus will be available to researchers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22154,""
"Pilot study of semiautomated localization of the dermal/epidermal junction in reflectance confocal microscopy images of skin","Kurugol, Dy, Brooks, Rajadhyaksha","https://doi.org/10.1117/1.3549740","20110809","PubMed","Algorithms; Artificial Intelligence; Dermis; Diagnosis, Computer-Assisted; Epidermis; Humans; Image Interpretation, Computer-Assisted; Microscopy, Confocal; Optical Phenomena; Pilot Projects; Skin; Skin Neoplasms; Skin Pigmentation","Reflectance confocal microscopy (RCM) continues to be translated toward the detection of skin cancers in vivo. Automated image analysis may help clinicians and accelerate clinical acceptance of RCM. For screening and diagnosis of cancer, the dermal/epidermal junction (DEJ), at which melanomas and basal cell carcinomas originate, is an important feature in skin. In RCM images, the DEJ is marked by optically subtle changes and features and is difficult to detect purely by visual examination. Challenges for automation of DEJ detection include heterogeneity of skin tissue, high inter-, intra-subject variability, and low optical contrast. To cope with these challenges, we propose a semiautomated hybrid sequence segmentation/classification algorithm that partitions z-stacks of tiles into homogeneous segments by fitting a model of skin layer dynamics and then classifies tile segments as epidermis, dermis, or transitional DEJ region using texture features. We evaluate two different training scenarios: 1. training and testing on portions of the same stack; 2. training on one labeled stack and testing on one from a different subject with similar skin type. Initial results demonstrate the detectability of the DEJ in both scenarios with epidermis/dermis misclassification rates smaller than 10% and average distance from the expert labeled boundaries around 8.5 ÃŽÂ¼m.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22155,""
"Combined evaluation of FDG-PET and MRI improves detection and differentiation of dementia","Dukart, Mueller, Horstmann, Barthel, MÃƒÂ¶ller, Villringer, Sabri, Schroeter","https://doi.org/10.1371/journal.pone.0018111","20110705","PubMed","Algorithms; Dementia; Diagnosis, Differential; Female; Fluorodeoxyglucose F18; Humans; Magnetic Resonance Imaging; Male; Middle Aged; Positron-Emission Tomography","Various biomarkers have been reported in recent literature regarding imaging abnormalities in different types of dementia. These biomarkers have helped to significantly improve early detection and also differentiation of various dementia syndromes. In this study, we systematically applied whole-brain and region-of-interest (ROI) based support vector machine classification separately and on combined information from different imaging modalities to improve the detection and differentiation of different types of dementia. Patients with clinically diagnosed Alzheimer's disease (AD: nÃ¢â‚¬Å =Ã¢â‚¬Å 21), with frontotemporal lobar degeneration (FTLD: nÃ¢â‚¬Å =Ã¢â‚¬Å 14) and control subjects (nÃ¢â‚¬Å =Ã¢â‚¬Å 13) underwent both [F18]fluorodeoxyglucose positron emission tomography (FDG-PET) scanning and magnetic resonance imaging (MRI), together with clinical and behavioral assessment. FDG-PET and MRI data were commonly processed to get a precise overlap of all regions in both modalities. Support vector machine classification was applied with varying parameters separately for both modalities and to combined information obtained from MR and FDG-PET images. ROIs were extracted from comprehensive systematic and quantitative meta-analyses investigating both disorders. Using single-modality whole-brain and ROI information FDG-PET provided highest accuracy rates for both, detection and differentiation of AD and FTLD compared to structural information from MRI. The ROI-based multimodal classification, combining FDG-PET and MRI information, was highly superior to the unimodal approach and to the whole-brain pattern classification. With this method, accuracy rate of up to 92% for the differentiation of the three groups and an accuracy of 94% for the differentiation of AD and FTLD patients was obtained. Accuracy rate obtained using combined information from both imaging modalities is the highest reported up to now for differentiation of both types of dementia. Our results indicate a substantial gain in accuracy using combined FDG-PET and MRI information and suggest the incorporation of such approaches to clinical diagnosis and to differential diagnostic procedures of neurodegenerative disorders.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22156,""
"Cost of pneumococcal infections and cost-effectiveness analysis of pneumococcal vaccination at risk adults and elderly in Turkey","Akin, Kaya, Altinel, Durand","https://doi.org/10.4161/hv.7.4.14188","20111115","PubMed","Adolescent; Adult; Aged; Aged, 80 and over; Bacteremia; Cost-Benefit Analysis; Female; Humans; Male; Middle Aged; Pneumococcal Infections; Pneumococcal Vaccines; Pneumonia, Pneumococcal; Turkey; Vaccination; Young Adult","Pneumococcal infections have a substantial burden in Turkey, particularly in the elderly (&gt; 60 years) and at-risk adults (18-59 years). VCR are low at approximately 2%. The first aim of this study was the evaluation of the burden of pneumococcal infections (pneumonia and bacteremia) from a public payer perspective in elderly and at-risk adults. The second aim was the evaluation of cost effectiveness of implementing a large PPV program in these populations. A decision tree model was employed using demographic and epidemiological input obtained from Turkish official sources and international literature. Vaccination was assumed to protect for 5 years with 60% and 50% effectiveness against BPP in elderly and at-risk adults respectively. Vaccination effectiveness of 21% against NBPP was assumed for both populations. Costs input were obtained from a previous study conducted between 2002 and 2008 in a public university hospital in Ankara, Turkey. Univariate sensitivity analyses and Monte-Carlo simulations were performed. The vaccination program was cost effective and cost saving compared to no vaccination, pneumococcal vaccination with 60% coverage led to a mean of 4,695 LYG in the elderly and 2,134 LYG in at-risk adults with 40% coverage. Mean incremental savings reached 45.4 million YTL in the elderly and 21.8 million YTL in at-risk adults. This analysis suggests that pneumococcal vaccination of elderly and at-risk adults is associated with a positive return on investment from a public payer perspective and supports the continued recommendation of pneumococcal vaccines, as well as their full funding in Turkey.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22157,""
"MEDRank: using graph-based concept ranking to index biomedical texts","Herskovic, Cohen, Subramanian, Iyengar, Smith, Bernstam","https://doi.org/10.1016/j.ijmedinf.2011.02.008","20110927","PubMed","Abstracting and Indexing; Algorithms; Artificial Intelligence; Electronic Data Processing; Humans; Information Storage and Retrieval; MEDLINE; Medical Subject Headings; National Library of Medicine (U.S.); Software; United States","As the volume of biomedical text increases exponentially, automatic indexing becomes increasingly important. However, existing approaches do not distinguish central (or core) concepts from concepts that were mentioned in passing. We focus on the problem of indexing MEDLINE records, a process that is currently performed by highly trained humans at the National Library of Medicine (NLM). NLM indexers are assisted by a system called the Medical Text Indexer (MTI) that suggests candidate indexing terms. To improve the ability of MTI to select the core terms in MEDLINE abstracts. These core concepts are deemed to be most important and are designated as ""major headings"" by MEDLINE indexers. We introduce and evaluate a graph-based indexing methodology called MEDRank that generates concept graphs from biomedical text and then ranks the concepts within these graphs to identify the most important ones. We insert a MEDRank step into the MTI and compare MTI's output with and without MEDRank to the MEDLINE indexers' selected terms for a sample of 11,803 PubMed Central articles. We also tested whether human raters prefer terms generated by the MEDLINE indexers, MTI without MEDRank, and MTI with MEDRank for a sample of 36 PubMed Central articles. MEDRank improved recall of major headings designated by 30% over MTI without MEDRank (0.489 vs. 0.376). Overall recall was only slightly (6.5%) higher (0.490 vs. 0.460) as was F(2) (3%, 0.408 vs. 0.396). However, overall precision was 3.9% lower (0.268 vs. 0.279). Human raters preferred terms generated by MTI with MEDRank over terms generated by MTI without MEDRank (by an average of 1.00 more term per article), and preferred terms generated by MTI with MEDRank and the MEDLINE indexers at the same rate. The addition of MEDRank to MTI significantly improved the retrieval of core concepts in MEDLINE abstracts and more closely matched human expectations compared to MTI without MEDRank. In addition, MEDRank slightly improved overall recall and F(2).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22158,""
"Klinefelter syndrome as a window on the aetiology of language and communication impairments in children: the neuroligin-neurexin hypothesis","Bishop, Scerif","https://doi.org/10.1111/j.1651-2227.2011.02150.x","20110809","PubMed","Child; Child Development Disorders, Pervasive; Chromosomes, Human, X; Chromosomes, Human, Y; Humans; Klinefelter Syndrome; Language Disorders; Male; Nerve Tissue Proteins; Neural Cell Adhesion Molecules; Phenotype; Risk Factors; Sex Chromosome Disorders; Synaptic Transmission; Trisomy","To compare the phenotype in Klinefelter syndrome (KS) with (i) specific language impairment (SLI) and (ii) XXX and XYY trisomies. Phenotypes of KS, XXX and XYY were based on data from a systematic review of neurodevelopmental outcomes plus a recent parent survey. Phenotype of SLI was based on a published survey of children attending a special school. There are close similarities between the KS phenotype and SLI. Furthermore, a minority of children with KS have features of autistic spectrum disorder. Similar language and communication problems are seen in the other two sex chromosome trisomies (SCTs), XXX and XYY. We propose the neurexin-neuroligin hypothesis, based on the observation that neuroligin genes, which occur on both X and Y chromosomes, are involved in the same synaptic networks as neurexin genes with common variants that affect risk for SLI and autism. According to our hypothesis, the effect of a triple dose of neuroligin gene product will be particularly detrimental when it occurs in conjunction with specific variants of neurexin genes on other chromosomes. This speculative proposal demonstrates the potential of illuminating the aetiology of common neurodevelopmental disorders by studying children with SCTs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22159,""
"Healthcare utilization and cost of pneumococcal disease in the United States","Huang, Johnson, Ray, Wroe, Lieu, Moore, Zell, Linder, Grijalva, Metlay, Finkelstein","https://doi.org/10.1016/j.vaccine.2011.02.088","20110728","PubMed","Adolescent; Adult; Aged; Child; Child, Preschool; Delivery of Health Care; Health Care Costs; Humans; Infant; Inpatients; Middle Aged; Models, Economic; Otitis Media; Outpatients; Pneumococcal Infections; Sepsis; Sinusitis; United States; Young Adult","Streptococcus pneumoniae continues to cause a variety of common clinical syndromes, despite vaccination programs for both adults and children. The total U.S. burden of pneumococcal disease is unknown. We constructed a decision tree-based model to estimate U.S. healthcare utilization and costs of pneumococcal disease in 2004. Data were obtained from the 2004-2005 National (Hospital) Ambulatory Medical Care Surveys (outpatient visits, antibiotics) and the National Hospital Discharge Survey (hospitalization rates), and CDC surveillance data. Other assumptions regarding the incidence of each syndrome due to pneumococcus, expected health outcomes, and healthcare utilization were derived from literature and expert opinion. Healthcare and time costs used 2007 dollars. We estimate that, in 2004, pneumococcal disease caused 4.0 million illness episodes, 22,000 deaths, 445,000 hospitalizations, 774,000 emergency department visits, 5.0 million outpatient visits, and 4.1 million outpatient antibiotic prescriptions. Direct medical costs totaled $3.5 billion. Pneumonia (866,000 cases) accounted for 22% of all cases and 72% of pneumococcal costs. In contrast, acute otitis media and sinusitis (1.5 million cases each) comprised 75% of cases but only 16% of direct medical costs. Patients Ã¢â€°Â¥ 65 years old, accounted for most serious cases and the majority of direct medical costs ($1.8 billion in healthcare costs annually). In this age group, pneumonia caused 242,000 hospitalizations, 1.4 million hospital days, 194,000 emergency department visits, 374,000 outpatient visits, and 16,000 deaths. However, if work loss and productivity are considered, the cost of pneumococcal disease among younger working adults (18-&lt;50) nearly equaled those Ã¢â€°Â¥ 65. Pneumococcal disease remains a substantial cause of morbidity and mortality even in the era of routine pediatric and adult vaccination. Continued efforts are warranted to reduce serious pneumococcal disease, especially adult pneumonia.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22160,""
"Knowledge management for systems biology a general and visually driven framework applied to translational medicine","Maier, Kalus, Wolff, Kalko, Roca, Marin de Mas, Turan, Cascante, Falciani, Hernandez, VillÃƒÂ -Freixa, Losko","https://doi.org/10.1186/1752-0509-5-38","20110624","PubMed","Data Collection; Data Mining; Humans; Knowledge Bases; Pulmonary Disease, Chronic Obstructive; Software; Systems Biology","To enhance our understanding of complex biological systems like diseases we need to put all of the available data into context and use this to detect relations, pattern and rules which allow predictive hypotheses to be defined. Life science has become a data rich science with information about the behaviour of millions of entities like genes, chemical compounds, diseases, cell types and organs, which are organised in many different databases and/or spread throughout the literature. Existing knowledge such as genotype-phenotype relations or signal transduction pathways must be semantically integrated and dynamically organised into structured networks that are connected with clinical and experimental data. Different approaches to this challenge exist but so far none has proven entirely satisfactory. To address this challenge we previously developed a generic knowledge management framework, BioXMÃ¢â€žÂ¢, which allows the dynamic, graphic generation of domain specific knowledge representation models based on specific objects and their relations supporting annotations and ontologies. Here we demonstrate the utility of BioXM for knowledge management in systems biology as part of the EU FP6 BioBridge project on translational approaches to chronic diseases. From clinical and experimental data, text-mining results and public databases we generate a chronic obstructive pulmonary disease (COPD) knowledge base and demonstrate its use by mining specific molecular networks together with integrated clinical and experimental data. We generate the first semantically integrated COPD specific public knowledge base and find that for the integration of clinical and experimental data with pre-existing knowledge the configuration based set-up enabled by BioXM reduced implementation time and effort for the knowledge base compared to similar systems implemented as classical software development projects. The knowledgebase enables the retrieval of sub-networks including protein-protein interaction, pathway, gene--disease and gene--compound data which are used for subsequent data analysis, modelling and simulation. Pre-structured queries and reports enhance usability; establishing their use in everyday clinical settings requires further simplification with a browser based interface which is currently under development.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22161,""
"Predictive validity of behavioural animal models for chronic pain","Berge","https://doi.org/10.1111/j.1476-5381.2011.01300.x","20120325","PubMed","Animals; Behavior, Animal; Behavioral Research; Chronic Pain; Disease Models, Animal; Forecasting; Humans; Mice; Rats; Reproducibility of Results","Rodent models of chronic pain may elucidate pathophysiological mechanisms and identify potential drug targets, but whether they predict clinical efficacy of novel compounds is controversial. Several potential analgesics have failed in clinical trials, in spite of strong animal modelling support for efficacy, but there are also examples of successful modelling. Significant differences in how methods are implemented and results are reported means that a literature-based comparison between preclinical data and clinical trials will not reveal whether a particular model is generally predictive. Limited reports on negative outcomes prevents reliable estimate of specificity of any model. Animal models tend to be validated with standard analgesics and may be biased towards tractable pain mechanisms. But preclinical publications rarely contain drug exposure data, and drugs are usually given in high doses and as a single administration, which may lead to drug distribution and exposure deviating significantly from clinical conditions. The greatest challenge for predictive modelling is, however, the heterogeneity of the target patient populations, in terms of both symptoms and pharmacology, probably reflecting differences in pathophysiology. In well-controlled clinical trials, a majority of patients shows less than 50% reduction in pain. A model that responds well to current analgesics should therefore predict efficacy only in a subset of patients within a diagnostic group. It follows that successful translation requires several models for each indication, reflecting critical pathophysiological processes, combined with data linking exposure levels with effect on target.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22162,""
"Analyses of cerebral microdialysis in patients with traumatic brain injury: relations to intracranial pressure, cerebral perfusion pressure and catheter placement","Nelson, Thornquist, MacCallum, NystrÃƒÂ¶m, Holst, Rudehill, Wanecek, Bellander, Weitzberg","https://doi.org/10.1186/1741-7015-9-21","20110608","PubMed","Adolescent; Adult; Aged; Brain; Brain Chemistry; Brain Injuries; Catheterization; Critical Care; Humans; Intracranial Pressure; Microdialysis; Middle Aged; Perfusion; Young Adult","Cerebral microdialysis (MD) is used to monitor local brain chemistry of patients with traumatic brain injury (TBI). Despite an extensive literature on cerebral MD in the clinical setting, it remains unclear how individual levels of real-time MD data are to be interpreted. Intracranial pressure (ICP) and cerebral perfusion pressure (CPP) are important continuous brain monitors in neurointensive care. They are used as surrogate monitors of cerebral blood flow and have an established relation to outcome. The purpose of this study was to investigate the relations between MD parameters and ICP and/or CPP in patients with TBI. Cerebral MD, ICP and CPP were monitored in 90 patients with TBI. Data were extensively analyzed, using over 7,350 samples of complete (hourly) MD data sets (glucose, lactate, pyruvate and glycerol) to seek representations of ICP, CPP and MD that were best correlated. MD catheter positions were located on computed tomography scans as pericontusional or nonpericontusional. MD markers were analyzed for correlations to ICP and CPP using time series regression analysis, mixed effects models and nonlinear (artificial neural networks) computer-based pattern recognition methods. Despite much data indicating highly perturbed metabolism, MD shows weak correlations to ICP and CPP. In contrast, the autocorrelation of MD is high for all markers, even at up to 30 future hours. Consequently, subject identity alone explains 52% to 75% of MD marker variance. This indicates that the dominant metabolic processes monitored with MD are long-term, spanning days or longer. In comparison, short-term (differenced or ÃŽâ€) changes of MD vs. CPP are significantly correlated in pericontusional locations, but with less than 1% explained variance. Moreover, CPP and ICP were significantly related to outcome based on Glasgow Outcome Scale scores, while no significant relations were found between outcome and MD. The multitude of highly perturbed local chemistry seen with MD in patients with TBI predominately represents long-term metabolic patterns and is weakly correlated to ICP and CPP. This suggests that disturbances other than pressure and/or flow have a dominant influence on MD levels in patients with TBI.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22163,""
"CSI-OMIM--Clinical Synopsis Search in OMIM","Cohen, Gefen, Elhadad, Birk","https://doi.org/10.1186/1471-2105-12-65","20110525","PubMed","Computational Biology; Data Mining; Databases, Factual; Databases, Genetic; Humans; Internet; Medical Subject Headings; Natural Language Processing; Phenotype; Syndrome; Unified Medical Language System","The OMIM database is a tool used daily by geneticists. Syndrome pages include a Clinical Synopsis section containing a list of known phenotypes comprising a clinical syndrome. The phenotypes are in free text and different phrases are often used to describe the same phenotype, the differences originating in spelling variations or typing errors, varying sentence structures and terminological variants.These variations hinder searching for syndromes or using the large amount of phenotypic information for research purposes. In addition, negation forms also create false positives when searching the textual description of phenotypes and induce noise in text mining applications. Our method allows efficient and complete search of OMIM phenotypes as well as improved data-mining of the OMIM phenome. Applying natural language processing, each phrase is tagged with additional semantic information using UMLS and MESH. Using a grammar based method, annotated phrases are clustered into groups denoting similar phenotypes. These groups of synonymous expressions enable precise search, as query terms can be matched with the many variations that appear in OMIM, while avoiding over-matching expressions that include the query term in a negative context. On the basis of these clusters, we computed pair-wise similarity among syndromes in OMIM. Using this new similarity measure, we identified 79,770 new connections between syndromes, an average of 16 new connections per syndrome. Our project is Web-based and available at http://fohs.bgu.ac.il/s2g/csiomim The resulting enhanced search functionality provides clinicians with an efficient tool for diagnosis. This search application is also used for finding similar syndromes for the candidate gene prioritization tool S2G.The enhanced OMIM database we produced can be further used for bioinformatics purposes such as linking phenotypes and genes based on syndrome similarities and the known genes in Morbidmap.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22164,""
"Vascular stem cells and ischaemic retinopathies","Stitt, O'Neill, O'Doherty, Archer, Gardiner, Medina","https://doi.org/10.1016/j.preteyeres.2011.02.001","20110825","PubMed","Animals; Diabetic Retinopathy; Endothelium, Vascular; Hematopoietic Stem Cell Transplantation; Hematopoietic Stem Cells; Humans; Reperfusion Injury; Retinal Vein Occlusion; Retinal Vessels","Retinal ischaemic disorders such as diabetic retinopathy and retinal vein occlusion are common. The hypoxia-related stimuli from oxygen-deprived neural and glial networks can drive expression of growth factors and cytokines which induce leakage from the surviving vasculature and/or pre-retinal and papillary neovascularisation. If left untreated, retinal vascular stasis, hypoxia or ischaemia can lead to macular oedema or fibro-vascular scar formation which are associated with severe visual impairment, and even blindness. Current therapies for ischaemic retinopathies include laser photocoagulation, injection of corticosteroids or VEGF-antibodies and vitreoretinal surgery, however they carry significant side effects. As an alternative approach, we propose that if reparative intra-retinal angiogenesis can be harnessed at the appropriate stage, ischaemia could be contained or reversed. This review provides evidence that reperfusion of ischaemic retina and suppression of sight-threatening sequelae is possible in both experimental and clinical settings. In particular, there is emphasis on the clinical potential for endothelial progenitor cells (EPCs) to promote vascular repair and reversal of ischaemic injury in various tissues including retina. Gathering evidence from an extensive published literature, we outline the molecular and phenotypic nature of EPCs, how they are altered in disease and provide a rationale for harnessing the vascular reparative properties of various cell sub-types. When some of the remaining questions surrounding the clinical use of EPCs are addressed, they may provide an exciting new therapeutic option for treating ischaemic retinopathies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22165,""
"An automated approach to calculating the daily dose of tacrolimus in electronic health records","Xu, Doan, Birdwell, Cowan, Vincz, Haas, Basford, Denny","https://www.google.com/search?q=An+automated+approach+to+calculating+the+daily+dose+of+tacrolimus+in+electronic+health+records.","20110714","PubMed","","Clinical research often requires extracting detailed drug information, such as medication names and dosages, from Electronic Health Records (EHR). Since medication information is often recorded as both structured and unstructured formats in the EHR, extracting all the relevant drug mentions and determining the daily dose of a medication for a selected patient at a given date can be a challenging and time-consuming task. In this paper, we present an automated approach using natural language processing to calculate daily doses of medications mentioned in clinical text, using tacrolimus as a test case. We evaluated this method using data sets from four different types of unstructured clinical data. Our results showed that the system achieved precisions of 0.90-1.00 and recalls of 0.81-1.00.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22166,""
"Evaluation of an Ontology-anchored Natural Language-based Approach for Asserting Multi-scale Biomolecular Networks for Systems Medicine","Borlawsky, Li, Shagina, Crowson, Liu, Friedman, Lussier","https://www.google.com/search?q=Evaluation+of+an+Ontology-anchored+Natural+Language-based+Approach+for+Asserting+Multi-scale+Biomolecular+Networks+for+Systems+Medicine.","20110714","PubMed","","The ability to adequately and efficiently integrate unstructured, heterogeneous datasets, which are incumbent to systems biology and medicine, is one of the primary limitations to their comprehensive analysis. Natural language processing (NLP) and biomedical ontologies are automated methods for capturing, standardizing and integrating information across diverse sources, including narrative text. We have utilized the BioMedLEE NLP system to extract and encode, using standard ontologies (e.g., Cell Type Ontology, Mammalian Phenotype, Gene Ontology), biomolecular mechanisms and clinical phenotypes from the scientific literature. We subsequently applied semantic processing techniques to the structured BioMedLEE output to determine the relationships between these biomolecular and clinical phenotype concepts. We conducted an evaluation that shows an average precision and recall of BioMedLEE with respect to annotating phrases comprised of cell type, anatomy/disease, and gene/protein concepts were 86% and 78%, respectively. The precision of the asserted phenotype-molecular relationships was 75%.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22167,""
"A Comprehensive Analysis of Five Million UMLS Metathesaurus Terms Using Eighteen Million MEDLINE Citations","Xu, Musen, Shah","https://www.google.com/search?q=A+Comprehensive+Analysis+of+Five+Million+UMLS+Metathesaurus+Terms+Using+Eighteen+Million+MEDLINE+Citations.","20160422","PubMed","Information Storage and Retrieval; MEDLINE; Natural Language Processing; Unified Medical Language System","The Unified Medical Language System (UMLS) Metathesaurus is widely used for biomedical natural language processing (NLP) tasks. In this study, we systematically analyzed UMLS Metathesaurus terms by analyzing their occurrences in over 18 million MEDLINE abstracts. Our goals were: 1. analyze the frequency and syntactic distribution of Metathesaurus terms in MEDLINE; 2. create a filtered UMLS Metathesaurus based on the MEDLINE analysis; 3. augment the UMLS Metathesaurus where each term is associated with metadata on its MEDLINE frequency and syntactic distribution statistics. After MEDLINE frequency-based filtering, the augmented UMLS Metathesaurus contains 518,835 terms and is roughly 13% of its original size. We have shown that the syntactic and frequency information is useful to identify errors in the Metathesaurus. This filtered and augmented UMLS Metathesaurus can potentially be used to improve efficiency and precision of UMLS-based information retrieval and NLP tasks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22168,""
"Corpus-Based Problem Selection for EHR Note Summarization","Van Vleck, Elhadad","https://www.google.com/search?q=Corpus-Based+Problem+Selection+for+EHR+Note+Summarization.","20160422","PubMed","Electronic Health Records; Humans; Natural Language Processing; Physicians","Physicians have access to patient notes in volumes far greater than what is practical to read within the context of a standard clinical scenario. As a preliminary step toward being able to provide a longitudinal summary of patient history, methods are examined for the automated extraction of relevant patient problems from existing clinical notes. We explore a grounded approach to identifying important patient problems from patient history. Methods build on existing NLP and text-summarization methodologies and leverage features observed in a relevant corpus.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22169,""
"Classification of medication status change in clinical narratives","Sohn, Murphy, Masanz, Kocher, Savova","https://www.google.com/search?q=Classification+of+medication+status+change+in+clinical+narratives.","20160422","PubMed","Artificial Intelligence; Humans; Machine Learning; Narration; Natural Language Processing","The patient's medication history and status changes play essential roles in medical treatment. A notable amount of medication status information typically resides in unstructured clinical narratives that require a sophisticated approach to automated classification. In this paper, we investigated rule-based and machine learning methods of medication status change classification from clinical free text. We also examined the impact of balancing training data in machine learning classification when using the data from skewed class distribution.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22170,""
"Evaluating the Importance of Image-related Text for Ad-hoc and Case-based Biomedical Article Retrieval","Simpson, Demner-Fushman, Thoma","https://www.google.com/search?q=Evaluating+the+Importance+of+Image-related+Text+for+Ad-hoc+and+Case-based+Biomedical+Article+Retrieval.","20160422","PubMed","Humans; Information Storage and Retrieval","Images and their associated text are an essential source of information in biomedical articles. However, their use in providing evidence for clinical case descriptions has yet to be evaluated in the context of information retrieval. Given the complexity of case-based document retrieval, understanding the importance of images and image-related text is critical for future research into text- and content-based approaches to this problem. In this study, we compare the extent to which image-related text is useful in facilitating document retrieval for both case-based information requests and ad-hoc clinical questions in the domain of family practice. We show that case-based document retrieval is significantly improved with the use of image-related text whereas retrieval for clinical questions is largely unaffected. This suggests that visual evidence is more relevant for the case descriptions used in our study than the clinical questions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22171,""
"Discovering peripheral arterial disease cases from radiology notes using natural language processing","Savova, Fan, Ye, Murphy, Zheng, Chute, Kullo","https://www.google.com/search?q=Discovering+peripheral+arterial+disease+cases+from+radiology+notes+using+natural+language+processing.","20160422","PubMed","Algorithms; Electronic Health Records; Humans; Natural Language Processing; Peripheral Arterial Disease; Sensitivity and Specificity","As part of the Electronic Medical Records and Genomics Network, we applied, extended and evaluated an open source clinical Natural Language Processing system, Mayo's Clinical Text Analysis and Knowledge Extraction System, for the discovery of peripheral arterial disease cases from radiology reports. The manually created gold standard consisted of 223 positive, 19 negative, 63 probable and 150 unknown cases. Overall accuracy agreement between the system and the gold standard was 0.93 as compared to a named entity recognition baseline of 0.46. Sensitivity for the positive, probable and unknown cases was 0.93-0.96, and for the negative cases was 0.72. Specificity and negative predictive value for all categories were in the 90's. The positive predictive value for the positive and unknown categories was in the high 90's, for the negative category was 0.84, and for the probable category was 0.63. We outline the main sources of errors and suggest improvements.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22172,""
"Combining Structured and Free-text Data for Automatic Coding of Patient Outcomes","Saria, McElvain, Rajani, Penn, Koller","https://www.google.com/search?q=Combining+Structured+and+Free-text+Data+for+Automatic+Coding+of+Patient+Outcomes.","20160422","PubMed","Humans; Information Storage and Retrieval; Natural Language Processing","Integrating easy-to-extract structured information such as medication and treatments into current natural language processing based systems can significantly boost coding performance; in this paper, we present a system that rigorously attempts to validate this intuitive idea. Based on recent i2b2 challenge winners, we derive a strong language model baseline that extracts patient outcomes from discharge summaries. Upon incorporating additional clinical cues into this language model, we see a significant boost in performance to F1 of 88.3 and a corresponding reduction in error of 23.52%.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22173,""
"Natural language processing for lines and devices in portable chest x-rays","Rubin, Wang, Chambers, Chambers, South, Goldstein","https://www.google.com/search?q=Natural+language+processing+for+lines+and+devices+in+portable+chest+x-rays.","20160422","PubMed","Algorithms; Humans; Information Storage and Retrieval; Natural Language Processing; Radiography, Thoracic; Radiology Information Systems; X-Rays","Radiology reports are unstructured free text documents that describe abnormalities in patients that are visible via imaging modalities such as X-ray. The number of imaging examinations performed in clinical care is enormous, and mining large repositories of radiology reports connected with clinical data such as patient outcomes could enable epidemiological studies, such as correlating the frequency of infections to the presence or length of time medical devices are present in patients. We developed a natural language processing (NLP) system to recognize device mentions in radiology reports and information about their state (insertion or removal) to enable epidemiological research. We tested our system using a reference standard of reports that were annotated to indicate this information. Our system performed with high accuracy (recall and precision of 97% and 99% for device mentions and 91-96% for device insertion status). Our methods are generalizable to other types of radiology reports as well as to other information extraction tasks and could provide the foundation for tools that enable epidemiological research exploration based on mining radiology reports.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22174,""
"Extending the GuideLine Implementability Appraisal (GLIA) instrument to identify problems in control flow","Peleg, Garber","https://www.google.com/search?q=Extending+the+GuideLine+Implementability+Appraisal+(GLIA)+instrument+to+identify+problems+in+control+flow.","20160422","PubMed","Expert Systems; Guideline Adherence; Humans; Practice Guidelines as Topic","Clinical guidelines are usually written as text documents that are meant for human consumption. Implementing clinical guidelines as decision-support systems that deliver patient-specific advice at the point of care could increase the effectiveness of clinical guidelines. Several researchers studied the transition from narrative guidelines to computer-interpretable guidelines and have identified specific barriers to guideline implementation. GuideLine Implementability Appraisal (GLIA) is a comprehensive instrument for identifying such barriers, such that they could be revised. We used the GLIA instrument to appraise a historic thyroid nodule guideline that is now being reviewed by the American Association of Clinical Endocrinologists. Our analysis uncovered new guideline implementation barriers related to control-flow that we integrated into GLIA.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22175,""
"A Knowledge Intensive Approach to Mapping Clinical Narrative to LOINC","Fiszman, Shin, Sneiderman, Jin, Rindflesch","https://www.google.com/search?q=A+Knowledge+Intensive+Approach+to+Mapping+Clinical+Narrative+to+LOINC.","20160422","PubMed","Humans; Logical Observation Identifiers Names and Codes; Narration; Natural Language Processing","Many natural language processing systems are being applied to clinical text, yet clinically useful results are obtained only by honing a system to a particular context. We suggest that concentration on the information needed for this processing is crucial and present a knowledge intensive methodology for mapping clinical text to LOINC. The system takes published case reports as input and maps vital signs and body measurements and reports of diagnostic procedures to fully specified LOINC codes. Three kinds of knowledge are exploited: textual, ontological, and pragmatic (including information about physiology and the clinical process). Evaluation on 4809 sentences yielded precision of 89% and recall of 93% (F-score 0.91). Our method could form the basis for a system to provide semi-automated help to human coders.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22176,""
"Identification of early changes in specific symptoms that predict longer-term response to atypical antipsychotics in the treatment of patients with schizophrenia","Ruberg, Chen, Stauffer, Ascher-Svanum, Kollack-Walker, Conley, Kane, Kinon","https://doi.org/10.1186/1471-244X-11-23","20110520","PubMed","Adolescent; Adult; Aged; Antipsychotic Agents; Decision Trees; Diagnostic and Statistical Manual of Mental Disorders; Female; Humans; Male; Middle Aged; Probability; Psychiatric Status Rating Scales; Psychometrics; Randomized Controlled Trials as Topic; Schizophrenia; Schizophrenic Psychology; Treatment Outcome","To identify a simple decision tree using early symptom change to predict response to atypical antipsychotic therapy in patients with (Diagnostic and Statistical Manual, Fourth Edition, Text Revised) chronic schizophrenia. Data were pooled from moderately to severely ill patients (n = 1494) from 6 randomized, double-blind trials (N = 2543). Response was defined as a Ã¢â€°Â¥ 30% reduction in Positive and Negative Syndrome Scale (PANSS) Total score by Week 8 of treatment. Analyzed predictors were change in individual PANSS items at Weeks 1 and 2. A decision tree was constructed using classification and regression tree (CART) analysis to identify predictors that most effectively differentiated responders from non-responders. A 2-branch, 6-item decision tree was created, producing 3 distinct groups. First branch criterion was a 2-point score decrease in at least 2 of 5 PANSS positive items (Week 2). Second branch criterion was a 2-point score decrease in the PANSS excitement item (Week 2). ""Likely responders"" met the first branch criteria; ""likely non-responders"" did not meet first or second criterion; ""not predictable"" patients did not meet the first but did meet the second criterion. Using this approach, response to treatment could be predicted in most patients (92%) with high positive predictive value (79%) and high negative predictive value (75%). Predictive findings were confirmed through analysis of data from 2 independent trials. Using a data-driven approach, we identified decision rules using early change in the scores of selected PANSS items to accurately predict longer-term treatment response or non-response to atypical antipsychotic therapy. This could lead to development of a simple quantitative evaluation tool to help guide early treatment decisions. This is a retrospective, non-intervention study in which pooled results from 6 previously published reports were analyzed; thus, clinical trial registration is not required.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22177,""
"Robot-assisted prostatectomy: the new standard of care","Hatiboglu, Teber, Hohenfellner","https://doi.org/10.1007/s00423-011-0743-5","20120612","PubMed","Blood Loss, Surgical; Disease-Free Survival; Humans; Length of Stay; Male; Prostatectomy; Prostatic Neoplasms; Robotics; Standard of Care; Treatment Outcome","Robot-assisted radical prostatectomy (RARP) has first been performed in 2000 and has since then become a widespread and often performed therapy option for surgical treatment of prostate cancer. The purpose of this review was to highlight the current clinical concepts for radical prostatectomy. Actual literature search was performed in PubMed database and reviewed. Different surgical techniques for RARP are presented. Oncologic and functional outcomes of RARP are discussed and compared to radical retropubic prostatectomy. In conclusion, RARP has equal oncologic and functional outcome in localized prostate cancer. RARP as a less invasive treatment option for patients with localized prostate cancer should be considered as a new standard of care by now.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22178,""
"Factors associated with response to methylphenidate in advanced cancer patients","Yennurajalingam, Palmer, Chacko, Bruera","https://doi.org/10.1634/theoncologist.2010-0214","20110614","PubMed","Anorexia; Anxiety; Central Nervous System Stimulants; Depression; Drug Monitoring; Dyspnea; Fatigue; Female; Humans; Male; Methylphenidate; Middle Aged; Nausea; Neoplasm Staging; Neoplasms; Pain; Retrospective Studies; Sleep Initiation and Maintenance Disorders; Sleep Stages; Treatment Outcome","There has been increasing interest in the use of methylphenidate for cancer-related fatigue (CRF) in patients with advanced cancer. However, there is limited literature on the specific patient characteristics associated with response to methylphenidate. Our objective of this study was to identify the specific patient characteristics associated with response to methylphenidate and to compare day 1 response with day 8 response. We retrospectively reviewed the records of patients in two prospective controlled clinical trials that we had conducted who had received methylphenidate for cancer-related fatigue. Baseline patient characteristics, symptoms (as assessed by the Edmonton Symptom Assessment System [ESAS] and Functional Assessment of Chronic Illness Therapy-Fatigue [FACIT-F]), and response (change in fatigue) at the end of day 1 treatment were analyzed to determine their association with response to methylphenidate on day 8. A total of 82 patients with advanced cancer who received methylphenidate for CRF were included in our review. The median age was 55 years, 66% were female, 74% were white, and the most common cancer type was breast (37%). Fifty out of 82 patients (61%) responded to methylphenidate (Ã¢â€°Â¥ 7 points in FACIT-F). The intensity of baseline fatigue positively correlated with the response to methylphenidate (p &lt; .001). Change in fatigue in response to methylphenidate was not associated with intensity of baseline depression, anxiety, drowsiness, or daily opioid dose. Better improvement of fatigue after treatment on day 1 was associated with more improvement with fatigue on day 8 as assessed by FACIT-F (p = .0004) and ESAS (p = .0001). Day 1 response as a predictor of day 8 response had a sensitivity of 0.84, a positive predictive value of 0.67, and specificity of 0.6. Response to methylphenidate is associated with higher baseline fatigue but not with higher baseline depression or sedation. Additionally, day 1 improvement is highly sensitive as a predictor of long-term improvement.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22179,""
"Animal model integration to AutDB, a genetic database for autism","Kumar, Wadhawan, Swanwick, Kollu, Basu, Banerjee-Basu","https://doi.org/10.1186/1755-8794-4-15","20110419","PubMed","Animals; Autistic Disorder; Child; Child Development Disorders, Pervasive; Databases, Factual; Databases, Genetic; Genes; Humans; Mice; Models, Animal; Research Design","In the post-genomic era, multi-faceted research on complex disorders such as autism has generated diverse types of molecular information related to its pathogenesis. The rapid accumulation of putative candidate genes/loci for Autism Spectrum Disorders (ASD) and ASD-related animal models poses a major challenge for systematic analysis of their content. We previously created the Autism Database (AutDB) to provide a publicly available web portal for ongoing collection, manual annotation, and visualization of genes linked to ASD. Here, we describe the design, development, and integration of a new module within AutDB for ongoing collection and comprehensive cataloguing of ASD-related animal models. As with the original AutDB, all data is extracted from published, peer-reviewed scientific literature. Animal models are annotated with a new standardized vocabulary of phenotypic terms developed by our researchers which is designed to reflect the diverse clinical manifestations of ASD. The new Animal Model module is seamlessly integrated to AutDB for dissemination of diverse information related to ASD. Animal model entries within the new module are linked to corresponding candidate genes in the original ""Human Gene"" module of the resource, thereby allowing for cross-modal navigation between gene models and human gene studies. Although the current release of the Animal Model module is restricted to mouse models, it was designed with an expandable framework which can easily incorporate additional species and non-genetic etiological models of autism in the future. Importantly, this modular ASD database provides a platform from which data mining, bioinformatics, and/or computational biology strategies may be adopted to develop predictive disease models that may offer further insights into the molecular underpinnings of this disorder. It also serves as a general model for disease-driven databases curating phenotypic characteristics of corresponding animal models.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22180,""
"Bioinformatic detection of E47, E2F1 and SREBP1 transcription factors as potential regulators of genes associated to acquisition of endometrial receptivity","Tapia, Vilos, MarÃƒÂ­n, Croxatto, Devoto","https://doi.org/10.1186/1477-7827-9-14","20110429","PubMed","Computational Biology; Down-Regulation; E2F1 Transcription Factor; Embryo Implantation; Endometrium; Female; Gene Expression Profiling; Gene Expression Regulation; Humans; Oligonucleotide Array Sequence Analysis; Sterol Regulatory Element Binding Protein 1; Transcription Factor 3; Transcription Factors; Up-Regulation","The endometrium is a dynamic tissue whose changes are driven by the ovarian steroidal hormones. Its main function is to provide an adequate substrate for embryo implantation. Using microarray technology, several reports have provided the gene expression patterns of human endometrial tissue during the window of implantation. However it is required that biological connections be made across these genomic datasets to take full advantage of them. The objective of this work was to perform a research synthesis of available gene expression profiles related to acquisition of endometrial receptivity for embryo implantation, in order to gain insights into its molecular basis and regulation. Gene expression datasets were intersected to determine a consensus endometrial receptivity transcript list (CERTL). For this cluster of genes we determined their functional annotations using available web-based databases. In addition, promoter sequences were analyzed to identify putative transcription factor binding sites using bioinformatics tools and determined over-represented features. We found 40 up- and 21 down-regulated transcripts in the CERTL. Those more consistently increased were C4BPA, SPP1, APOD, CD55, CFD, CLDN4, DKK1, ID4, IL15 and MAP3K5 whereas the more consistently decreased were OLFM1, CCNB1, CRABP2, EDN3, FGFR1, MSX1 and MSX2. Functional annotation of CERTL showed it was enriched with transcripts related to the immune response, complement activation and cell cycle regulation. Promoter sequence analysis of genes revealed that DNA binding sites for E47, E2F1 and SREBP1 transcription factors were the most consistently over-represented and in both up- and down-regulated genes during the window of implantation. Our research synthesis allowed organizing and mining high throughput data to explore endometrial receptivity and focus future research efforts on specific genes and pathways. The discovery of possible new transcription factors orchestrating the CERTL opens new alternatives for understanding gene expression regulation in uterine function.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22181,""
"Automated validation of genetic variants from large databases: ensuring that variant references refer to the same genomic locations","Tong, Cassa, Kohane","https://doi.org/10.1093/bioinformatics/btr029","20110531","PubMed","Algorithms; Amino Acid Substitution; Codon; Computational Biology; Databases, Genetic; Electronic Data Processing; Humans; Molecular Sequence Annotation; Point Mutation; Sequence Analysis, DNA; Software","Accurate annotations of genomic variants are necessary to achieve full-genome clinical interpretations that are scientifically sound and medically relevant. Many disease associations, especially those reported before the completion of the HGP, are limited in applicability because of potential inconsistencies with our current standards for genomic coordinates, nomenclature and gene structure. In an effort to validate and link variants from the medical genetics literature to an unambiguous reference for each variant, we developed a software pipeline and reviewed 68 641 single amino acid mutations from Online Mendelian Inheritance in Man (OMIM), Human Gene Mutation Database (HGMD) and dbSNP. The frequency of unresolved mutation annotations varied widely among the databases, ranging from 4 to 23%. A taxonomy of primary causes for unresolved mutations was produced. This program is freely available from the web site (http://safegene.hms.harvard.edu/aa2nt/).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22182,""
"AskHERMES: An online question answering system for complex clinical questions","Cao, Liu, Simpson, Antieau, Bennett, Cimino, Ely, Yu","https://doi.org/10.1016/j.jbi.2011.01.004","20110722","PubMed","Algorithms; Clinical Medicine; Databases, Factual; Expert Systems; Information Storage and Retrieval; Natural Language Processing; Online Systems; Software","Clinical questions are often long and complex and take many forms. We have built a clinical question answering system named AskHERMES to perform robust semantic analysis on complex clinical questions and output question-focused extractive summaries as answers. This paper describes the system architecture and a preliminary evaluation of AskHERMES, which implements innovative approaches in question analysis, summarization, and answer presentation. Five types of resources were indexed in this system: MEDLINE abstracts, PubMed Central full-text articles, eMedicine documents, clinical guidelines and Wikipedia articles. We compared the AskHERMES system with Google (Google and Google Scholar) and UpToDate and asked physicians to score the three systems by ease of use, quality of answer, time spent, and overall performance. AskHERMES allows physicians to enter a question in a natural way with minimal query formulation and allows physicians to efficiently navigate among all the answer sentences to quickly meet their information needs. In contrast, physicians need to formulate queries to search for information in Google and UpToDate. The development of the AskHERMES system is still at an early stage, and the knowledge resource is limited compared with Google or UpToDate. Nevertheless, the evaluation results show that AskHERMES' performance is comparable to the other systems. In particular, when answering complex clinical questions, it demonstrates the potential to outperform both Google and UpToDate systems. AskHERMES, available at http://www.AskHERMES.org, has the potential to help physicians practice evidence-based medicine and improve the quality of patient care.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22183,""
"Disclosing ambiguous gene aliases by automatic literature profiling","Coimbra, Vanderwall, Oliveira","https://doi.org/10.1186/1471-2164-11-S5-S3","20110414","PubMed","Algorithms; Data Mining; Genes; PubMed; Semantics; Terminology as Topic; Vocabulary, Controlled","Retrieving pertinent information from biological scientific literature requires cutting-edge text mining methods which may be able to recognize the meaning of the very ambiguous names of biological entities. Aliases of a gene share a common vocabulary in their respective collections of PubMed abstracts. This may be true even when these aliases are not associated with the same subset of documents. This gene-specific vocabulary defines a unique fingerprint that can be used to disclose ambiguous aliases. The present work describes an original method for automatically assessing the ambiguity levels of gene aliases in large gene terminologies based exclusively in the content of their associated literature. The method can deal with the two major problems restricting the usage of current text mining tools: 1) different names associated with the same gene; and 2) one name associated with multiple genes, or even with non-gene entities. Important, this method does not require training examples. Aliases were considered ""ambiguous"" when their Jaccard distance to the respective official gene symbol was equal or greater than the smallest distance between the official gene symbol and one of the three internal controls (randomly picked unrelated official gene symbols). Otherwise, they were assigned the status of ""synonyms"". We evaluated the coherence of the results by comparing the frequencies of the official gene symbols in the text corpora retrieved with their respective ""synonyms"" or ""ambiguous"" aliases. Official gene symbols were mentioned in the abstract collections of 42 % (70/165) of their respective synonyms. No official gene symbol occurred in the abstract collections of any of their respective ambiguous aliases. In overall, querying PubMed with official gene symbols and ""synonym"" aliases allowed a 3.6-fold increase in the number of unique documents retrieved. These results confirm that this method is able to distinguish between synonyms and ambiguous gene aliases based exclusively on their vocabulary fingerprint. The approach we describe could be used to enhance the retrieval of relevant literature related to a gene.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22184,""
"Vitamin E and all-cause mortality: a meta-analysis","Abner, Schmitt, Mendiondo, Marcum, Kryscio","https://doi.org/10.2174/1874609811104020158","20111123","PubMed","Antioxidants; Cause of Death; Dietary Supplements; Humans; Longevity; Risk Assessment; Risk Factors; Time Factors; Treatment Outcome; Vitamin E","The current analysis reexamines the relationship between supplemental vitamin E and all-cause mortality. All randomized, controlled trials testing the treatment effect of vitamin E supplementation in adults for at least one year were sought. MEDLINE, the Cochrane Library, and Biological Abstracts databases were searched using the terms ""vitamin E,"" ""alpha-tocopherol,"" ""antioxidants,"" ""clinical trial,"" and ""controlled trial"" for studies published through April 2010; results were limited to English, German, or Spanish language articles. Studies were also obtained through reference mining. All randomized controlled trials using vitamin E, with a supplementation period of at least one year, to prevent or treat disease in adults were identified and abstracted independently by two raters. Mortality data from trials with a supplementation period of at least one year were pooled. The selected trials (n = 57) were published between 1988 and 2009. Sample sizes range from 28 to 39,876 (median = 423), yielding 246,371 subjects and 29,295 all-cause deaths. Duration of supplementation for the 57 trials range from one to 10.1 years (median = 2.6 years). A random effects meta-analysis produce an overall risk ratio of 1.00 (95% confidence interval: 0.98, 1.02); additional analyses suggest no relationship between dose and risk of mortality. Based on the present meta-analysis, supplementation with vitamin E appears to have no effect on all-cause mortality at doses up to 5,500 IU/d.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22185,""
"Data from clinical notes: a perspective on the tension between structure and flexible documentation","Rosenbloom, Denny, Xu, Lorenzi, Stead, Johnson","https://doi.org/10.1136/jamia.2010.007237","20110719","PubMed","Data Mining; Documentation; Efficiency, Organizational; Electronic Health Records; Forms and Records Control; Humans; Medical Records, Problem-Oriented; Natural Language Processing; Reference Standards; Systems Integration; Workflow","Clinical documentation is central to patient care. The success of electronic health record system adoption may depend on how well such systems support clinical documentation. A major goal of integrating clinical documentation into electronic heath record systems is to generate reusable data. As a result, there has been an emphasis on deploying computer-based documentation systems that prioritize direct structured documentation. Research has demonstrated that healthcare providers value different factors when writing clinical notes, such as narrative expressivity, amenability to the existing workflow, and usability. The authors explore the tension between expressivity and structured clinical documentation, review methods for obtaining reusable data from clinical notes, and recommend that healthcare providers be able to choose how to document patient care based on workflow and note content needs. When reusable data are needed from notes, providers can use structured documentation or rely on post-hoc text processing to produce structured data, as appropriate.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22186,""
"A magnetic resonance spectroscopy driven initialization scheme for active shape model based prostate segmentation","Toth, Tiwari, Rosen, Reed, Kurhanewicz, Kalyanpur, Pungavkar, Madabhushi","https://doi.org/10.1016/j.media.2010.09.002","20110607","PubMed","Algorithms; Artificial Intelligence; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Magnetic Resonance Spectroscopy; Male; Pattern Recognition, Automated; Prostate; Prostatic Neoplasms; Reproducibility of Results; Sensitivity and Specificity","Segmentation of the prostate boundary on clinical images is useful in a large number of applications including calculation of prostate volume pre- and post-treatment, to detect extra-capsular spread, and for creating patient-specific anatomical models. Manual segmentation of the prostate boundary is, however, time consuming and subject to inter- and intra-reader variability. T2-weighted (T2-w) magnetic resonance (MR) structural imaging (MRI) and MR spectroscopy (MRS) have recently emerged as promising modalities for detection of prostate cancer in vivo. MRS data consists of spectral signals measuring relative metabolic concentrations, and the metavoxels near the prostate have distinct spectral signals from metavoxels outside the prostate. Active Shape Models (ASM's) have become very popular segmentation methods for biomedical imagery. However, ASMs require careful initialization and are extremely sensitive to model initialization. The primary contribution of this paper is a scheme to automatically initialize an ASM for prostate segmentation on endorectal in vivo multi-protocol MRI via automated identification of MR spectra that lie within the prostate. A replicated clustering scheme is employed to distinguish prostatic from extra-prostatic MR spectra in the midgland. The spatial locations of the prostate spectra so identified are used as the initial ROI for a 2D ASM. The midgland initializations are used to define a ROI that is then scaled in 3D to cover the base and apex of the prostate. A multi-feature ASM employing statistical texture features is then used to drive the edge detection instead of just image intensity information alone. Quantitative comparison with another recent ASM initialization method by Cosio showed that our scheme resulted in a superior average segmentation performance on a total of 388 2D MRI sections obtained from 32 3D endorectal in vivo patient studies. Initialization of a 2D ASM via our MRS-based clustering scheme resulted in an average overlap accuracy (true positive ratio) of 0.60, while the scheme of Cosio yielded a corresponding average accuracy of 0.56 over 388 2D MR image sections. During an ASM segmentation, using no initialization resulted in an overlap of 0.53, using the Cosio based methodology resulted in an overlap of 0.60, and using the MRS-based methodology resulted in an overlap of 0.67, with a paired Student's t-test indicating statistical significance to a high degree for all results. We also show that the final ASM segmentation result is highly correlated (as high as 0.90) to the initialization scheme.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22187,""
"Combining network modeling and gene expression microarray analysis to explore the dynamics of Th1 and Th2 cell regulation","Pedicini, BarrenÃƒÂ¤s, Clancy, Castiglione, Hovig, Kanduri, Santoni, Benson","https://doi.org/10.1371/journal.pcbi.1001032","20110331","PubMed","Algorithms; Computational Biology; Computer Simulation; Databases, Genetic; Gene Expression Profiling; Gene Knockout Techniques; Gene Regulatory Networks; Humans; Oligonucleotide Array Sequence Analysis; Phenotype; Th1 Cells; Th2 Cells","Two T helper (Th) cell subsets, namely Th1 and Th2 cells, play an important role in inflammatory diseases. The two subsets are thought to counter-regulate each other, and alterations in their balance result in different diseases. This paradigm has been challenged by recent clinical and experimental data. Because of the large number of genes involved in regulating Th1 and Th2 cells, assessment of this paradigm by modeling or experiments is difficult. Novel algorithms based on formal methods now permit the analysis of large gene regulatory networks. By combining these algorithms with in silico knockouts and gene expression microarray data from human T cells, we examined if the results were compatible with a counter-regulatory role of Th1 and Th2 cells. We constructed a directed network model of genes regulating Th1 and Th2 cells through text mining and manual curation. We identified four attractors in the network, three of which included genes that corresponded to Th0, Th1 and Th2 cells. The fourth attractor contained a mixture of Th1 and Th2 genes. We found that neither in silico knockouts of the Th1 and Th2 attractor genes nor gene expression microarray data from patients with immunological disorders and healthy subjects supported a counter-regulatory role of Th1 and Th2 cells. By combining network modeling with transcriptomic data analysis and in silico knockouts, we have devised a practical way to help unravel complex regulatory network topology and to increase our understanding of how network actions may differ in health and disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22188,""
"An image feature-based approach to automatically find images for application to clinical decision support","Stanley, De, Demner-Fushman, Antani, Thoma","https://doi.org/10.1016/j.compmedimag.2010.11.008","20111102","PubMed","Artificial Intelligence; Cluster Analysis; Data Mining; Decision Support Systems, Clinical; Documentation; Humans; Image Interpretation, Computer-Assisted; Pattern Recognition, Automated; Radiology Information Systems; Reproducibility of Results; Sensitivity and Specificity","The illustrations in biomedical publications often provide useful information in aiding clinicians' decisions when full text searching is performed to find evidence in support of a clinical decision. In this research, image analysis and classification techniques are explored to automatically extract information for differentiating specific modalities to characterize illustrations in biomedical publications, which may assist in the evidence finding process. Global, histogram-based, and texture image illustration features were compared to basis function luminance histogram correlation features for modality-based discrimination over a set of 742 manually annotated images by modality (radiological, photo, etc.) selected from the 2004-2005 issues of the British Journal of Oral and Maxillofacial Surgery. Using a mean shifting supervised clustering technique, automatic modality-based discrimination results as high as 95.57% were obtained using the basis function features. These results compared favorably to other feature categories examined. The experimental results show that image-based features, particularly correlation-based features, can provide useful modality discrimination information.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22189,""
"The endoscopic approach to the neck: a review of the literature, and overview of the various techniques","Muenscher, Dalchow, Kutta, Knecht","https://doi.org/10.1007/s00464-010-1452-9","20110811","PubMed","Animals; Endoscopy; Humans; Minimally Invasive Surgical Procedures; Neck; Neck Dissection; Robotics; Submandibular Gland; Thyroidectomy; Video-Assisted Surgery","The endoscopic surgical approach to the neck has reached the head and neck surgeons' view with a certain delay, compared to other fields of endoscopic procedures. This may be attributed to the tight work space and plenty of vital structures in the operating field. Since study groups described first attempts with endoscopic or video assisted removals of thyroid glands in the late nineties, selective neck dissections on animal models or cadaveric dissections were performed in 2003. The review consists of a Medline Search regarding the terms of endoscopic, video- assisted neck dissections, excision of neck lesions, thyroidectomy and submandibular resection and minimal access surgery. The three main procedures (selective neck dissection, submandibular resection and thyroidectomy) are described and reviewed in the following test. Various techniques have been performed successfully and led to good clinical results. The studies described in literature other than for thyroidectomy often do not exceed the level of small series or case-reports. With a good proof of indication gasless lifting techniques, video assisted endoscopical techniques and subcutaneous approaches with gas filling procedures are feasible in neck surgery. All methods depending on the surgeons' experience describe no significantly extended operation times, a better and faster wound-healing and an optimized cosmetic outcome, compared to open approaches. Surgeons should always be aware of the limitations of the minimal invasive techniques regarding the complications or modifications during neck dissection/thyroidectomy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22190,""
"MIPS: curated databases and comprehensive secondary data resources in 2010","Mewes, Ruepp, Theis, Rattei, Walter, Frishman, Suhre, Spannagl, Mayer, StÃƒÂ¼mpflen, Antonov","https://doi.org/10.1093/nar/gkq1157","20110428","PubMed","Data Mining; Databases, Genetic; Databases, Protein; Genes, Neoplasm; Genome, Plant; Genomics; Metabolomics; MicroRNAs; Phenotype; Proteomics; Sequence Analysis, Protein; Systems Integration","The Munich Information Center for Protein Sequences (MIPS at the Helmholtz Center for Environmental Health, Neuherberg, Germany) has many years of experience in providing annotated collections of biological data. Selected data sets of high relevance, such as model genomes, are subjected to careful manual curation, while the bulk of high-throughput data is annotated by automatic means. High-quality reference resources developed in the past and still actively maintained include Saccharomyces cerevisiae, Neurospora crassa and Arabidopsis thaliana genome databases as well as several protein interaction data sets (MPACT, MPPI and CORUM). More recent projects are PhenomiR, the database on microRNA-related phenotypes, and MIPS PlantsDB for integrative and comparative plant genome research. The interlinked resources SIMAP and PEDANT provide homology relationships as well as up-to-date and consistent annotation for 38,000,000 protein sequences. PPLIPS and CCancer are versatile tools for proteomics and functional genomics interfacing to a database of compilations from gene lists extracted from literature. A novel literature-mining tool, EXCERBT, gives access to structured information on classified relations between genes, proteins, phenotypes and diseases extracted from Medline abstracts by semantic analysis. All databases described here, as well as the detailed descriptions of our projects can be accessed through the MIPS WWW server (http://mips.helmholtz-muenchen.de).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22191,""
"""Cool"" inferior frontostriatal dysfunction in attention-deficit/hyperactivity disorder versus ""hot"" ventromedial orbitofrontal-limbic dysfunction in conduct disorder: a review","Rubia","https://doi.org/10.1016/j.biopsych.2010.09.023","20110929","PubMed","Attention Deficit Disorder with Hyperactivity; Brain Mapping; Conduct Disorder; Corpus Striatum; Executive Function; Frontal Lobe; Humans; Limbic System; Models, Neurological; Neural Pathways; Psychomotor Performance; Reward","Attention-deficit/hyperactivity disorder (ADHD) and conduct disorder overlap behaviorally, clinically, and cognitively. An important question of potential future clinical relevance is whether these two overlapping disorders are mediated by similar or distinct underlying brain substrates. This article reviews the modern neuroimaging literature on brain structure, function, and connectivity in both disorders, shaping out commonalities and differences. Findings show that ADHD is characterized predominantly by abnormalities in inferior frontal, striatal, parietotemporal, and cerebellar regions and networks that mediate ""cool""-cognitive, i.e., inhibitory, attention and timing functions associated with the disorder. Conduct disorder, by contrast, has consistently been associated with abnormalities of the ""hot"" paralimbic system that regulates motivation and affect, comprising lateral orbital and ventromedial prefrontal cortices, superior temporal lobes, and underlying limbic structures, most prominently the amygdala. Direct comparisons in functional imaging show that these associations of cool inferior fronto-striato-cerebellar dysfunction in ADHD and of hot orbitofrontal-paralimbic dysfunction in conduct disorder are disorder-specific. There is, hence, evidence for dissociated underlying pathophysiologies for these two disorders that may have implications for future anatomy-based differential diagnosis and prevention and intervention.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22192,""
"Natural language processing for the development of a clinical registry: a validation study in intraductal papillary mucinous neoplasms","Al-Haddad, Friedlin, Kesterson, Waters, Aguilar-Saavedra, Schmidt","https://doi.org/10.1111/j.1477-2574.2010.00235.x","20110325","PubMed","Carcinoma, Pancreatic Ductal; Carcinoma, Papillary; Data Mining; Disease Progression; Humans; Indiana; Natural Language Processing; Neoplasms, Cystic, Mucinous, and Serous; Pancreatic Cyst; Pancreatic Neoplasms; Precancerous Conditions; Prognosis; Registries; Reproducibility of Results; Software; Time Factors","Medical natural language processing (NLP) systems have been developed to identify, extract and encode information within clinical narrative text. However, the role of NLP in clinical research and patient care remains limited. Pancreatic cysts are common. Some pancreatic cysts, such as intraductal papillary mucinous neoplasms (IPMNs), have malignant potential and require extended periods of surveillance. We seek to develop a novel NLP system that could be applied in our clinical network to develop a functional registry of IPMN patients. This study aims to validate the accuracy of our novel NLP system in the identification of surgical patients with pathologically confirmed IPMN in comparison with our pre-existing manually created surgical database (standard reference). The Regenstrief EXtraction Tool (REX) was used to extract pancreatic cyst patient data from medical text files from Indiana University Health. The system was assessed periodically by direct sampling and review of medical records. Results were compared with the standard reference. Natural language processing detected 5694 unique patients with pancreas cysts, in 215 of whom surgical pathology had confirmed IPMN. The NLP software identified all but seven patients present in the surgical database and identified an additional 37 IPMN patients not previously included in the surgical database. Using the standard reference, the sensitivity of the NLP program was 97.5% (95% confidence interval [CI] 94.8-98.9%) and its positive predictive value was 95.5% (95% CI 92.3-97.5%). Natural language processing is a reliable and accurate method for identifying selected patient cohorts and may facilitate the identification and follow-up of patients with IPMN.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22193,""
"Breast cancer biomarker discovery in the functional genomic age: a systematic review of 42 gene expression signatures","Abba, Lacunza, Butti, Aldaz","https://doi.org/10.4137/BMI.S5740","20110714","PubMed","biomarkers; breast cancer; gene expression signatures","In this review we provide a systematic analysis of transcriptomic signatures derived from 42 breast cancer gene expression studies, in an effort to identify the most relevant breast cancer biomarkers using a meta-analysis method. Meta-data revealed a set of 117 genes that were the most commonly affected ranging from 12% to 36% of overlap among breast cancer gene expression studies. Data mining analysis of transcripts and protein-protein interactions of these commonly modulated genes indicate three functional modules significantly affected among signatures, one module related with the response to steroid hormone stimulus, and two modules related to the cell cycle. Analysis of a publicly available gene expression data showed that the obtained meta-signature is capable of predicting overall survival (P &lt; 0.0001) and relapse-free survival (P &lt; 0.0001) in patients with early-stage breast carcinomas. In addition, the identified meta-signature improves breast cancer patient stratification independently of traditional prognostic factors in a multivariate Cox proportional-hazards analysis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22194,""
"The cost utility of autologous chondrocytes implantation using ChondroCelectÃ‚Â® in symptomatic knee cartilage lesions in Belgium","Gerlier, Lamotte, Wille, Kreuz, Vanlauwe, Dubois, Meurgey","https://doi.org/10.2165/11584920-000000000-00000","20110302","PubMed","Adult; Arthroplasty, Replacement, Knee; Belgium; Cartilage, Articular; Chondrocytes; Cost-Benefit Analysis; Health Care Costs; Humans; Knee Injuries; Randomized Controlled Trials as Topic; Transplantation, Autologous","Knee cartilage lesions increase the risk of developing osteoarthritis (OA), and may eventually result in a total knee replacement (TKR). There is currently no consensus on the optimal treatment of cartilage lesions. ChondroCelectÃ‚Â® (CC) is a cell-based therapy approved for use in autologous chondrocytes implantation (ACI) to treat symptomatic cartilage defects of the femoral condyle. Its capacity to safely restore good-quality cartilage was demonstrated in a randomized controlled trial (RCT) versus the surgical procedure microfracture (MFX). This study investigated the cost utility of CC used in ACI compared with MFX to treat symptomatic knee cartilage lesions in Belgium. A decision tree model comparing CC with MFX over a 40-year horizon was developed in TreeAge ProÃ¢â€žÂ¢. The key timepoints of the model were (i) clinical assessment 5 years after initial intervention (success or no success, with or without re-operation); (ii) development of OA at 15 years (yes/no); (iii) need for TKR at 20 years (yes/no); and (iv) need for prosthesis revision at 35 years (yes/no). Clinical data provided by the RCT of CC versus MFX were the clinical success (response) rate based on the Knee injury and Osteoarthritis Outcome Score (KOOS) at 36 months (82.9% vs 62.0%; p = 0.048) and the proportion of good structural repair/presence of hyaline cartilage based on International Cartilage Repair Society (ICRS II) visual item at 12 months (44.9% vs 23.2%; p = 0.023). Utility scores by surgery outcome were derived from the SF-36 questionnaire responses collected in the RCT. Conservative assumptions related to the incidences of OA, TKR and prosthesis revision relied on a literature search. A patient chart review (n = 82) provided follow-up costs by surgery outcome. National tariffs were applied to direct medical resources used (healthcare payer perspective, year 2008 costs). Annual discounting was applied to costs (3%) and effects (1.5%) as recommended by the Belgian pharmacoeconomic guidelines. The incremental cost per QALY gained for CC compared with MFX was Ã¢â€šÂ¬16,229, with a difference in costs of Ã¢â€šÂ¬20,802 and 1.282 QALYs gained. Sensitivity analyses indicated that the key model drivers were the proportion of patients with hyaline cartilage and the correlation between hyaline cartilage formation and later avoidance of OA. Probabilistic sensitivity analyses showed robustness of the results, with 80% of the simulations below the usual UK National Institute for Health and Clinical Excellence (NICE) threshold of Ã¢â€šÂ¬22,000 per QALY. Assuming a good correlation between high-quality cartilage repair and avoidance of OA at a later stage, the benefits of the cell therapy CC over MFX in terms of QALYs gained and OA-related costs avoided appear real. Further research is required to explore long-term effects of cartilage repair and reduce uncertainty on quality of life of patients with OA before and after joint replacement.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22195,""
"Constructing the HBV-human protein interaction network to understand the relationship between HBV and hepatocellular carcinoma","Wu, Zhu, Huang, Wang","https://doi.org/10.1186/1756-9966-29-146","20110318","PubMed","Carcinoma, Hepatocellular; Data Mining; Hepatitis B virus; Hepatitis B, Chronic; Humans; Liver Neoplasms; Proteins","Epidemiological studies have clearly validated the association between hepatitis B virus (HBV) infection and hepatocellular carcinoma (HCC). Patients with chronic HBV infection are at increased risk of HCC, in particular those with active liver disease and cirrhosis. We catalogued all published interactions between HBV and human proteins, identifying 250 descriptions of HBV and human protein interactions and 146 unique human proteins that interact with HBV proteins by text mining. Integration of this data set into a reconstructed human interactome showed that cellular proteins interacting with HBV are made up of core proteins that are interconnected with many pathways. A global analysis based on functional annotation highlighted the enrichment of cellular pathways targeted by HBV. By connecting the cellular proteins targeted by HBV, we have constructed a central network of proteins associated with hepatocellular carcinoma, which might be to regard as the basis of a detailed map for tracking new cellular interactions, and guiding future investigations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22196,""
"Automated ancillary cancer history classification for mesothelioma patients from free-text clinical reports","Wilson, Chapman, Defries, Becich, Chapman","https://doi.org/10.4103/2153-3539.71065","20110714","PubMed","Information extraction; cancer history classifcation; natural language processing","Clinical records are often unstructured, free-text documents that create information extraction challenges and costs. Healthcare delivery and research organizations, such as the National Mesothelioma Virtual Bank, require the aggregation of both structured and unstructured data types. Natural language processing offers techniques for automatically extracting information from unstructured, free-text documents. Five hundred and eight history and physical reports from mesothelioma patients were split into development (208) and test sets (300). A reference standard was developed and each report was annotated by experts with regard to the patient's personal history of ancillary cancer and family history of any cancer. The Hx application was developed to process reports, extract relevant features, perform reference resolution and classify them with regard to cancer history. Two methods, Dynamic-Window and ConText, for extracting information were evaluated. Hx's classification responses using each of the two methods were measured against the reference standard. The average Cohen's weighted kappa served as the human benchmark in evaluating the system. Hx had a high overall accuracy, with each method, scoring 96.2%. F-measures using the Dynamic-Window and ConText methods were 91.8% and 91.6%, which were comparable to the human benchmark of 92.8%. For the personal history classification, Dynamic-Window scored highest with 89.2% and for the family history classification, ConText scored highest with 97.6%, in which both methods were comparable to the human benchmark of 88.3% and 97.2%, respectively. We evaluated an automated application's performance in classifying a mesothelioma patient's personal and family history of cancer from clinical reports. To do so, the Hx application must process reports, identify cancer concepts, distinguish the known mesothelioma from ancillary cancers, recognize negation, perform reference resolution and determine the experiencer. Results indicated that both information extraction methods tested were dependant on the domain-specific lexicon and negation extraction. We showed that the more general method, ConText, performed as well as our task-specific method. Although Dynamic- Window could be modified to retrieve other concepts, ConText is more robust and performs better on inconclusive concepts. Hx could greatly improve and expedite the process of extracting data from free-text, clinical records for a variety of research or healthcare delivery organizations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22197,""
"Combining free text and structured electronic medical record entries to detect acute respiratory infections","DeLisle, South, Anthony, Kalp, Gundlapallli, Curriero, Glass, Samore, Perl","https://doi.org/10.1371/journal.pone.0013377","20110307","PubMed","Acute Disease; Adult; Aged; Aged, 80 and over; Algorithms; Clinical Coding; Humans; Medical Records Systems, Computerized; Middle Aged; Outpatients; Respiratory Tract Infections","The electronic medical record (EMR) contains a rich source of information that could be harnessed for epidemic surveillance. We asked if structured EMR data could be coupled with computerized processing of free-text clinical entries to enhance detection of acute respiratory infections (ARI). A manual review of EMR records related to 15,377 outpatient visits uncovered 280 reference cases of ARI. We used logistic regression with backward elimination to determine which among candidate structured EMR parameters (diagnostic codes, vital signs and orders for tests, imaging and medications) contributed to the detection of those reference cases. We also developed a computerized free-text search to identify clinical notes documenting at least two non-negated ARI symptoms. We then used heuristics to build case-detection algorithms that best combined the retained structured EMR parameters with the results of the text analysis. An adjusted grouping of diagnostic codes identified reference ARI patients with a sensitivity of 79%, a specificity of 96% and a positive predictive value (PPV) of 32%. Of the 21 additional structured clinical parameters considered, two contributed significantly to ARI detection: new prescriptions for cough remedies and elevations in body temperature to at least 38Ã‚Â°C. Together with the diagnostic codes, these parameters increased detection sensitivity to 87%, but specificity and PPV declined to 95% and 25%, respectively. Adding text analysis increased sensitivity to 99%, but PPV dropped further to 14%. Algorithms that required satisfying both a query of structured EMR parameters as well as text analysis disclosed PPVs of 52-68% and retained sensitivities of 69-73%. Structured EMR parameters and free-text analyses can be combined into algorithms that can detect ARI cases with new levels of sensitivity or precision. These results highlight potential paths by which repurposed EMR information could facilitate the discovery of epidemics before they cause mass casualties.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22198,""
"Laparoendoscopic single-site surgery in gynecology: review of literature and available technology","Uppal, Frumovitz, Escobar, Ramirez","https://doi.org/10.1016/j.jmig.2010.07.013","20110524","PubMed","Endoscopy; Gynecologic Surgical Procedures; Humans; Laparoscopy; Robotics","The objective of this article was to review the published literature on laparoendoscopic single-site surgery (LESS) in gynecology and to present current advances in instruments used in LESS surgery. Inasmuch as LESS surgery is relatively new, the current literature on use of this technique in gynecology is somewhat limited. Sixteen articles were available for the literature review: 10 case series, 2 comparative studies, 3 case reports, and 1 surgical technique demonstration. In recent years, however, improvements in traditional laparoscopic techniques and availability of more advanced instruments has made single-incision laparoscopy more feasible and safer for the patient. There is increasing interest in LESS surgery both as an alternative to traditional laparoscopy and as an adjunct to robotic surgery when performing complicated procedures through a single incision. Although LESS surgery provides another option in the arena of minimally invasive gynecologic surgery, the ultimate role of this approach remains to be determined.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22199,""
"Biomedical negation scope detection with conditional random fields","Agarwal, Yu","https://doi.org/10.1136/jamia.2010.003228","20110218","PubMed","Data Mining; Humans; Natural Language Processing","Negation is a linguistic phenomenon that marks the absence of an entity or event. Negated events are frequently reported in both biological literature and clinical notes. Text mining applications benefit from the detection of negation and its scope. However, due to the complexity of language, identifying the scope of negation in a sentence is not a trivial task. Conditional random fields (CRF), a supervised machine-learning algorithm, were used to train models to detect negation cue phrases and their scope in both biological literature and clinical notes. The models were trained on the publicly available BioScope corpus. The performance of the CRF models was evaluated on identifying the negation cue phrases and their scope by calculating recall, precision and F1-score. The models were compared with four competitive baseline systems. The best CRF-based model performed statistically better than all baseline systems and NegEx, achieving an F1-score of 98% and 95% on detecting negation cue phrases and their scope in clinical notes, and an F1-score of 97% and 85% on detecting negation cue phrases and their scope in biological literature. This approach is robust, as it can identify negation scope in both biological and clinical text. To benefit text mining applications, the system is publicly available as a Java API and as an online application at http://negscope.askhermes.org.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22200,""
"Model for comparative analysis of antigen receptor repertoires","Rempala, Seweryn, Ignatowicz","https://doi.org/10.1016/j.jtbi.2010.10.001","20110330","PubMed","Animals; CD4-Positive T-Lymphocytes; CD8-Positive T-Lymphocytes; Cluster Analysis; Confidence Intervals; Likelihood Functions; Mice; Models, Immunological; Receptors, Antigen, T-Cell; Sample Size","In modern molecular biology one of the standard ways of analyzing a vertebrate immune system is to sequence and compare the counts of specific antigen receptor clones (either immunoglobulins or T-cell receptors) derived from various tissues under different experimental or clinical conditions. The resulting statistical challenges are difficult and do not fit readily into the standard statistical framework of contingency tables primarily due to the serious under-sampling of the receptor populations. This under-sampling is caused, on one hand, by the extreme diversity of antigen receptor repertoires maintained by the immune system and, on the other, by the high cost and labor intensity of the receptor data collection process. In most of the recent immunological literature the differences across antigen receptor populations are examined via non-parametric statistical measures of the species overlap and diversity borrowed from ecological studies. While this approach is robust in a wide range of situations, it seems to provide little insight into the underlying clonal size distribution and the overall mechanism differentiating the receptor populations. As a possible alternative, the current paper presents a parametric method that adjusts for the data under-sampling as well as provides a unifying approach to a simultaneous comparison of multiple receptor groups by means of the modern statistical tools of unsupervised learning. The parametric model is based on a flexible multivariate Poisson-lognormal distribution and is seen to be a natural generalization of the univariate Poisson-lognormal models used in the ecological studies of biodiversity patterns. The procedure for evaluating a model's fit is described along with the public domain software developed to perform the necessary diagnostics. The model-driven analysis is seen to compare favorably vis a vis traditional methods when applied to the data from T-cell receptors in transgenic mice populations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22201,""
"Robot-assisted laparoscopic ureterolysis: case report and literature review of the minimally invasive surgical approach","Seixas-Mikelus, Marshall, Stephens, Blumenfeld, Arnone, Guru","https://doi.org/10.4293/108680810X12785289145088","20101105","PubMed","Aged; Humans; Laparoscopy; Male; Retroperitoneal Fibrosis; Robotics; Ureter; Ureteral Obstruction; Urologic Surgical Procedures","To evaluate our case of robot-assisted ureterolysis (RU), describe our surgical technique, and review the literature on minimally invasive ureterolysis. One patient managed with robot-assisted ureterolysis for idiopathic retroperitoneal fibrosis was identified. The chart was analyzed for demographics, operative parameters, and immediate postoperative outcome. The surgical technique was assessed and modified. Lastly, a review of the published literature on ureterolysis managed with minimally invasive surgery was performed. One patient underwent robot-assisted ureterolysis at our institution in 2 separate settings. Operative time (OR) decreased from 279 minutes to 191 minutes. Estimated blood loss (EBL) was less than 50 mL. The patient has been free of symptoms and both renal units are unobstructed. According to the published literature, 302 renal units underwent successful laparoscopic ureterolysis (LU), and 6 renal units underwent RU. There were 9 open conversions (all in LU). Mean OR in LU was 248 minutes for unilateral and 386 minutes for bilateral cases. In RU, mean OR was 220 minutes for unilateral and 390 minutes for bilateral cases. EBL averaged 200 mL in LU and 30 mL in RU. Our data reveal that robot-assisted ureterolysis is safe and feasible. Published data demonstrate the advantages of minimally invasive surgery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22202,""
"Bioinformatics analysis of Brucella vaccines and vaccine targets using VIOLIN","He, Xiang","https://doi.org/10.1186/1745-7580-6-S1-S5","20110714","PubMed","","Brucella spp. are Gram-negative, facultative intracellular bacteria that cause brucellosis, one of the commonest zoonotic diseases found worldwide in humans and a variety of animal species. While several animal vaccines are available, there is no effective and safe vaccine for prevention of brucellosis in humans. VIOLIN (http://www.violinet.org) is a web-based vaccine database and analysis system that curates, stores, and analyzes published data of commercialized vaccines, and vaccines in clinical trials or in research. VIOLIN contains information for 454 vaccines or vaccine candidates for 73 pathogens. VIOLIN also contains many bioinformatics tools for vaccine data analysis, data integration, and vaccine target prediction. To demonstrate the applicability of VIOLIN for vaccine research, VIOLIN was used for bioinformatics analysis of existing Brucella vaccines and prediction of new Brucella vaccine targets. VIOLIN contains many literature mining programs (e.g., Vaxmesh) that provide in-depth analysis of Brucella vaccine literature. As a result of manual literature curation, VIOLIN contains information for 38 Brucella vaccines or vaccine candidates, 14 protective Brucella antigens, and 68 host response studies to Brucella vaccines from 97 peer-reviewed articles. These Brucella vaccines are classified in the Vaccine Ontology (VO) system and used for different ontological applications. The web-based VIOLIN vaccine target prediction program Vaxign was used to predict new Brucella vaccine targets. Vaxign identified 14 outer membrane proteins that are conserved in six virulent strains from B. abortus, B. melitensis, and B. suis that are pathogenic in humans. Of the 14 membrane proteins, two proteins (Omp2b and Omp31-1) are not present in B. ovis, a Brucella species that is not pathogenic in humans. Brucella vaccine data stored in VIOLIN were compared and analyzed using the VIOLIN query system. Bioinformatics curation and ontological representation of Brucella vaccines promotes classification and analysis of existing Brucella vaccines and vaccine candidates. Computational prediction of Brucella vaccine targets provides more candidates for rational vaccine development. The use of VIOLIN provides a general approach that can be applied for analyses of vaccines against other pathogens and infection diseases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22203,""
"Development of a primary care-based complex care management intervention for chronically ill patients at high risk for hospitalization: a study protocol","Freund, Wensing, Mahler, Gensichen, Erler, Beyer, Gerlach, Szecsenyi, Peters-Klimm","https://doi.org/10.1186/1748-5908-5-70","20110714","PubMed","","Complex care management is seen as an approach to face the challenges of an ageing society with increasing numbers of patients with complex care needs. The Medical Research Council in the United Kingdom has proposed a framework for the development and evaluation of complex interventions that will be used to develop and evaluate a primary care-based complex care management program for chronically ill patients at high risk for future hospitalization in Germany. We present a multi-method procedure to develop a complex care management program to implement interventions aimed at reducing potentially avoidable hospitalizations for primary care patients with type 2 diabetes mellitus, chronic obstructive pulmonary disease, or chronic heart failure and a high likelihood of hospitalization. The procedure will start with reflection about underlying precipitating factors of hospitalizations and how they may be targeted by the planned intervention (pre-clinical phase). An intervention model will then be developed (phase I) based on theory, literature, and exploratory studies (phase II). Exploratory studies are planned that entail the recruitment of 200 patients from 10 general practices. Eligible patients will be identified using two ways of 'case finding': software based predictive modelling and physicians' proposal of patients based on clinical experience. The resulting subpopulations will be compared regarding healthcare utilization, care needs and resources using insurance claims data, a patient survey, and chart review. Qualitative studies with healthcare professionals and patients will be undertaken to identify potential barriers and enablers for optimal performance of the complex care management program. This multi-method procedure will support the development of a primary care-based care management program enabling the implementation of interventions that will potentially reduce avoidable hospitalizations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22204,""
"BrainKnowledge: a human brain function mapping knowledge-base system","Hsiao, Chen, Chen","https://doi.org/10.1007/s12021-010-9083-9","20110713","PubMed","Brain Mapping; Computer Systems; Data Mining; Databases as Topic; Expert Systems; Humans; MEDLINE; Magnetic Resonance Imaging; Periodicals as Topic; Systems Integration; United States","Associating fMRI image datasets with the available literature is crucial for the analysis and interpretation of fMRI data. Here, we present a human brain function mapping knowledge-base system (BrainKnowledge) that associates fMRI data analysis and literature search functions. BrainKnowledge not only contains indexed literature, but also provides the ability to compare experimental data with those derived from the literature. BrainKnowledge provides three major functions: (1) to search for brain activation models by selecting a particular brain function; (2) to query functions by brain structure; (3) to compare the fMRI data with data extracted from the literature. All these functions are based on our literature extraction and mining module developed earlier (Hsiao, Chen, Chen. Journal of Biomedical Informatics 42, 912-922, 2009), which automatically downloads and extracts information from a vast amount of fMRI literature and generates co-occurrence models and brain association patterns to illustrate the relevance of brain structures and functions. BrainKnowledge currently provides three co-occurrence models: (1) a structure-to-function co-occurrence model; (2) a function-to-structure co-occurrence model; and (3) a brain structure co-occurrence model. Each model has been generated from over 15,000 extracted Medline abstracts. In this study, we illustrate the capabilities of BrainKnowledge and provide an application example with the studies of affect. BrainKnowledge, which combines fMRI experimental results with Medline abstracts, may be of great assistance to scientists not only by freeing up resources and valuable time, but also by providing a powerful tool that collects and organizes over ten thousand abstracts into readily usable and relevant sources of information for researchers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22205,""
"Automatically detecting medications and the reason for their prescription in clinical narrative text documents","Meystre, Thibault, Shen, Hurdle, South","https://www.google.com/search?q=Automatically+detecting+medications+and+the+reason+for+their+prescription+in+clinical+narrative+text+documents.","20110415","PubMed","Drug Prescriptions; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Vocabulary, Controlled","An important proportion of the information about the medications a patient is taking is mentioned only in narrative text in the electronic health record. Automated information extraction can make this information accessible for decision support, research, or any other automated processing. In the context of the ""i2b2 medication extraction challenge,"" we have developed a new NLP application called Textractor to automatically extract medications and details about them (e.g., dosage, frequency, reason for their prescription). This application and its evaluation with part of the reference standard for this ""challenge"" are presented here, along with an analysis of the development of this reference standard. During this evaluation, Textractor reached a system-level overall F&lt;inf&gt;1&lt;/inf&gt;-measure, the reference metric for this challenge, of about 77% for exact matches. The best performance was measured with medication routes (F&lt;inf&gt;1&lt;/inf&gt;-measure 86.4%), and the worst with prescription reasons (F&lt;inf&gt;1&lt;/inf&gt;-measure 29%). These results are consistent with the agreement observed between human annotators when developing the reference standard, and with other published research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22206,""
"Cost-effectiveness analysis of combination therapies for visceral leishmaniasis in the Indian subcontinent","Meheus, Balasegaram, Olliaro, Sundar, Rijal, Faiz, Boelaert","https://doi.org/10.1371/journal.pntd.0000818","20101223","PubMed","Amphotericin B; Antiprotozoal Agents; Bangladesh; Cost-Benefit Analysis; Drug Therapy, Combination; Humans; India; Leishmaniasis, Visceral; Models, Statistical; Nepal; Paromomycin; Phosphorylcholine","Visceral leishmaniasis is a systemic parasitic disease that is fatal unless treated. We assessed the cost and cost-effectiveness of alternative strategies for the treatment of visceral leishmaniasis in the Indian subcontinent. In particular we examined whether combination therapies are a cost-effective alternative compared to monotherapies. We assessed the cost-effectiveness of all possible mono- and combination therapies for the treatment of visceral leishmaniasis in the Indian subcontinent (India, Nepal and Bangladesh) from a societal perspective using a decision analytical model based on a decision tree. Primary data collected in each country was combined with data from the literature and an expert poll (Delphi method). The cost per patient treated and average and incremental cost-effectiveness ratios expressed as cost per death averted were calculated. Extensive sensitivity analysis was done to evaluate the robustness of our estimations and conclusions. With a cost of US$92 per death averted, the combination miltefosine-paromomycin was the most cost-effective treatment strategy. The next best alternative was a combination of liposomal amphotericin B with paromomycin with an incremental cost-effectiveness of $652 per death averted. All other strategies were dominated with the exception of a single dose of 10mg per kg of liposomal amphotericin B. While strategies based on liposomal amphotericin B (AmBisome) were found to be the most effective, its current drug cost of US$20 per vial resulted in a higher average cost-effectiveness. Sensitivity analysis showed the conclusion to be robust to variations in the input parameters over their plausible range. Combination treatments are a cost-effective alternative to current monotherapy for VL. Given their expected impact on the emergence of drug resistance, a switch to combination therapy should be considered once final results from clinical trials are available.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22207,""
"Quantitative structure activity relationship for inhibition of human organic cation/carnitine transporter","Diao, Ekins, Polli","https://doi.org/10.1021/mp100226q","20110325","PubMed","Cells, Cultured; Cephaloridine; Cetirizine; Humans; Kinetics; Models, Molecular; Molecular Dynamics Simulation; Molecular Structure; Organic Cation Transport Proteins; Quantitative Structure-Activity Relationship; Solute Carrier Family 22 Member 5","Organic cation/carnitine transporter (OCTN2; SLC22A5) is an important transporter for L-carnitine homeostasis, but can be inhibited by drugs, which may cause L-carnitine deficiency and possibly other OCTN2-mediated drug-drug interactions. One objective was to develop a quantitative structure-activity relationship (QSAR) of OCTN2 inhibitors, in order to predict and identify other potential OCTN2 inhibitors and infer potential clinical interactions. A second objective was to assess two high renal clearance drugs that interact with OCTN2 in vitro (cetirizine and cephaloridine) for possible OCTN2-mediated drug-drug interactions. Using previously generated in vitro data of 22 drugs, a 3D quantitative pharmacophore model and a Bayesian machine learning model were developed. The four pharmacophore features include two hydrophobic groups, one hydrogen-bond acceptor, and one positive ionizable center. The Bayesian machine learning model was developed using simple interpretable descriptors and function class fingerprints of maximum diameter 6 (FCFP_6). An external test set of 27 molecules, including 15 newly identified OCTN2 inhibitors, and a literature test set of 22 molecules were used to validate both models. The computational models afforded good capability to identify structurally diverse OCTN2 inhibitors, providing a valuable tool to predict new inhibitors efficiently. Inhibition results confirmed our previously observed association between rhabdomyolysis and C(max)/K(i) ratio. The two high renal clearance drugs cetirizine and cephaloridine were found not to be OCTN2 substrates, and their diminished elimination by other drugs is concluded not to be mediated by OCTN2.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22208,""
"Discovering drug-drug interactions: a text-mining and reasoning approach based on properties of drug metabolism","Tari, Anwar, Liang, Cai, Baral","https://doi.org/10.1093/bioinformatics/btq382","20101026","PubMed","Data Mining; Databases, Factual; Drug Interactions; Enzymes; Feasibility Studies; Humans; Logic; Natural Language Processing; Pharmaceutical Preparations","Identifying drug-drug interactions (DDIs) is a critical process in drug administration and drug development. Clinical support tools often provide comprehensive lists of DDIs, but they usually lack the supporting scientific evidences and different tools can return inconsistent results. In this article, we propose a novel approach that integrates text mining and automated reasoning to derive DDIs. Through the extraction of various facts of drug metabolism, not only the DDIs that are explicitly mentioned in text can be extracted but also the potential interactions that can be inferred by reasoning. Our approach was able to find several potential DDIs that are not present in DrugBank. We manually evaluated these interactions based on their supporting evidences, and our analysis revealed that 81.3% of these interactions are determined to be correct. This suggests that our approach can uncover potential DDIs with scientific evidences explaining the mechanism of the interactions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22209,""
"Lancet: a high precision medication event extraction system for clinical text","Li, Liu, Antieau, Cao, Yu","https://doi.org/10.1136/jamia.2010.004077","20101115","PubMed","Artificial Intelligence; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing","This paper presents Lancet, a supervised machine-learning system that automatically extracts medication events consisting of medication names and information pertaining to their prescribed use (dosage, mode, frequency, duration and reason) from lists or narrative text in medical discharge summaries. Lancet incorporates three supervised machine-learning models: a conditional random fields model for tagging individual medication names and associated fields, an AdaBoost model with decision stump algorithm for determining which medication names and fields belong to a single medication event, and a support vector machines disambiguation model for identifying the context style (narrative or list). The authors, from the University of Wisconsin-Milwaukee, participated in the third i2b2 shared-task for challenges in natural language processing for clinical data: medication extraction challenge. With the performance metrics provided by the i2b2 challenge, the micro F1 (precision/recall) scores are reported for both the horizontal and vertical level. Among the top 10 teams, Lancet achieved the highest precision at 90.4% with an overall F1 score of 76.4% (horizontal system level with exact match), a gain of 11.2% and 12%, respectively, compared with the rule-based baseline system jMerki. By combining the two systems, the hybrid system further increased the F1 score by 3.4% from 76.4% to 79.0%. Supervised machine-learning systems with minimal external knowledge resources can achieve a high precision with a competitive overall F1 score.Lancet based on this learning framework does not rely on expensive manually curated rules. The system is available online at http://code.google.com/p/lancet/.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22210,""
"Textractor: a hybrid system for medications and reason for their prescription extraction from clinical text documents","Meystre, Thibault, Shen, Hurdle, South","https://doi.org/10.1136/jamia.2010.004028","20101115","PubMed","Artificial Intelligence; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Pattern Recognition, Automated; Pharmaceutical Preparations","OBJECTIVE To describe a new medication information extraction system-Textractor-developed for the 'i2b2 medication extraction challenge'. The development, functionalities, and official evaluation of the system are detailed. Textractor is based on the Apache Unstructured Information Management Architecture (UMIA) framework, and uses methods that are a hybrid between machine learning and pattern matching. Two modules in the system are based on machine learning algorithms, while other modules use regular expressions, rules, and dictionaries, and one module embeds MetaMap Transfer. The official evaluation was based on a reference standard of 251 discharge summaries annotated by all teams participating in the challenge. The metrics used were recall, precision, and the F(1)-measure. They were calculated with exact and inexact matches, and were averaged at the level of systems and documents. The reference metric for this challenge, the system-level overall F(1)-measure, reached about 77% for exact matches, with a recall of 72% and a precision of 83%. Performance was the best with route information (F(1)-measure about 86%), and was good for dosage and frequency information, with F(1)-measures of about 82-85%. Results were not as good for durations, with F(1)-measures of 36-39%, and for reasons, with F(1)-measures of 24-27%. The official evaluation of Textractor for the i2b2 medication extraction challenge demonstrated satisfactory performance. This system was among the 10 best performing systems in this challenge.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22211,""
"Extracting medical information from narrative patient records: the case of medication-related information","DelÃƒÂ©ger, Grouin, Zweigenbaum","https://doi.org/10.1136/jamia.2010.003962","20101115","PubMed","Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Pharmaceutical Preparations; Semantics","While essential for patient care, information related to medication is often written as free text in clinical records and, therefore, difficult to use in computerized systems. This paper describes an approach to automatically extract medication information from clinical records, which was developed to participate in the i2b2 2009 challenge, as well as different strategies to improve the extraction. Our approach relies on a semantic lexicon and extraction rules as a two-phase strategy: first, drug names are recognized and, then, the context of these names is explored to extract drug-related information (mode, dosage, etc) according to rules capturing the document structure and the syntax of each kind of information. Different configurations are tested to improve this baseline system along several dimensions, particularly drug name recognition-this step being a determining factor to extract drug-related information. Changes were tested at the level of the lexicons and of the extraction rules. The initial system participating in i2b2 achieved good results (global F-measure of 77%). Further testing of different configurations substantially improved the system (global F-measure of 81%), performing well for all types of information (eg, 84% for drug names and 88% for modes), except for durations and reasons, which remain problematic. This study demonstrates that a simple rule-based system can achieve good performance on the medication extraction task. We also showed that controlled modifications (lexicon filtering and rule refinement) were the improvements that best raised the performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22212,""
"Linguistic approach for identification of medication names and related information in clinical narratives","Hamon, Grabar","https://doi.org/10.1136/jamia.2010.004036","20101115","PubMed","Drug Therapy; Electronic Health Records; Humans; Information Storage and Retrieval; Linguistics; Natural Language Processing; Pharmaceutical Preparations; Software Design","Pharmacotherapy is an integral part of any medical care process and plays an important role in the medical history of most patients. Information on medication is crucial for several tasks such as pharmacovigilance, medical decision or biomedical research. Within a narrative text, medication-related information can be buried within other non-relevant data. Specific methods, such as those provided by text mining, must be designed for accessing them, and this is the objective of this study. The authors designed a system for analyzing narrative clinical documents to extract from them medication occurrences and medication-related information. The system also attempts to deduce medications not covered by the dictionaries used. Results provided by the system were evaluated within the framework of the I2B2 NLP challenge held in 2009. The system achieved an F-measure of 0.78 and ranked 7th out of 20 participating teams (the highest F-measure was 0.86). The system provided good results for the annotation and extraction of medication names, their frequency, dosage and mode of administration (F-measure over 0.81), while information on duration and reasons is poorly annotated and extracted (F-measure 0.36 and 0.29, respectively). The performance of the system was stable between the training and test sets.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22213,""
"Extracting Rx information from clinical narrative","Mork, Bodenreider, Demner-Fushman, Dogan, Lang, Lu, NÃƒÂ©vÃƒÂ©ol, Peters, Shooshan, Aronson","https://doi.org/10.1136/jamia.2010.003970","20101115","PubMed","Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Patient Discharge; Pharmaceutical Preparations; Software Design","The authors used the i2b2 Medication Extraction Challenge to evaluate their entity extraction methods, contribute to the generation of a publicly available collection of annotated clinical notes, and start developing methods for ontology-based reasoning using structured information generated from the unstructured clinical narrative. Extraction of salient features of medication orders from the text of de-identified hospital discharge summaries was addressed with a knowledge-based approach using simple rules and lookup lists. The entity recognition tool, MetaMap, was combined with dose, frequency, and duration modules specifically developed for the Challenge as well as a prototype module for reason identification. Evaluation metrics and corresponding results were provided by the Challenge organizers. The results indicate that robust rule-based tools achieve satisfactory results in extraction of simple elements of medication orders, but more sophisticated methods are needed for identification of reasons for the orders and durations. Owing to the time constraints and nature of the Challenge, some obvious follow-on analysis has not been completed yet. The authors plan to integrate the new modules with MetaMap to enhance its accuracy. This integration effort will provide guidance in retargeting existing tools for better processing of clinical text.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22214,""
"Integrating existing natural language processing tools for medication extraction from discharge summaries","Doan, Bastarache, Klimkowski, Denny, Xu","https://doi.org/10.1136/jamia.2010.003855","20101115","PubMed","Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Patient Discharge; Pharmaceutical Preparations; Systems Integration","To develop an automated system to extract medications and related information from discharge summaries as part of the 2009 i2b2 natural language processing (NLP) challenge. This task required accurate recognition of medication name, dosage, mode, frequency, duration, and reason for drug administration. We developed an integrated system using several existing NLP components developed at Vanderbilt University Medical Center, which included MedEx (to extract medication information), SecTag (a section identification system for clinical notes), a sentence splitter, and a spell checker for drug names. Our goal was to achieve good performance with minimal to no specific training for this document corpus; thus, evaluating the portability of those NLP tools beyond their home institution. The integrated system was developed using 17 notes that were annotated by the organizers and evaluated using 251 notes that were annotated by participating teams. The i2b2 challenge used standard measures, including precision, recall, and F-measure, to evaluate the performance of participating systems. There were two ways to determine whether an extracted textual finding is correct or not: exact matching or inexact matching. The overall performance for all six types of medication-related findings across 251 annotated notes was considered as the primary metric in the challenge. Our system achieved an overall F-measure of 0.821 for exact matching (0.839 precision; 0.803 recall) and 0.822 for inexact matching (0.866 precision; 0.782 recall). The system ranked second out of 20 participating teams on overall performance at extracting medications and related information. The results show that the existing MedEx system, together with other NLP components, can extract medication information in clinical text from institutions other than the site of algorithm development with reasonable performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22215,""
"Extracting medication information from clinical text","Uzuner, Solti, Cadag","https://doi.org/10.1136/jamia.2010.003947","20101115","PubMed","Computers, Hybrid; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Patient Dropouts; Pharmaceutical Preparations","The Third i2b2 Workshop on Natural Language Processing Challenges for Clinical Records focused on the identification of medications, their dosages, modes (routes) of administration, frequencies, durations, and reasons for administration in discharge summaries. This challenge is referred to as the medication challenge. For the medication challenge, i2b2 released detailed annotation guidelines along with a set of annotated discharge summaries. Twenty teams representing 23 organizations and nine countries participated in the medication challenge. The teams produced rule-based, machine learning, and hybrid systems targeted to the task. Although rule-based systems dominated the top 10, the best performing system was a hybrid. Of all medication-related fields, durations and reasons were the most difficult for all systems to detect. While medications themselves were identified with better than 0.75 F-measure by all of the top 10 systems, the best F-measure for durations and reasons were 0.525 and 0.459, respectively. State-of-the-art natural language processing systems go a long way toward extracting medication names, dosages, modes, and frequencies. However, they are limited in recognizing duration and reason fields and would benefit from future research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22216,""
"Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications","Savova, Masanz, Ogren, Zheng, Sohn, Kipper-Schuler, Chute","https://doi.org/10.1136/jamia.2009.001560","20101115","PubMed","Biomedical Research; Electronic Health Records; Information Storage and Retrieval; Natural Language Processing","We aim to build and evaluate an open-source natural language processing system for information extraction from electronic medical record clinical free-text. We describe and evaluate our system, the clinical Text Analysis and Knowledge Extraction System (cTAKES), released open-source at http://www.ohnlp.org. The cTAKES builds on existing open-source technologies-the Unstructured Information Management Architecture framework and OpenNLP natural language processing toolkit. Its components, specifically trained for the clinical domain, create rich linguistic and semantic annotations. Performance of individual components: sentence boundary detector accuracy=0.949; tokenizer accuracy=0.949; part-of-speech tagger accuracy=0.936; shallow parser F-score=0.924; named entity recognizer and system-level evaluation F-score=0.715 for exact and 0.824 for overlapping spans, and accuracy for concept mapping, negation, and status attributes for exact and overlapping spans of 0.957, 0.943, 0.859, and 0.580, 0.939, and 0.839, respectively. Overall performance is discussed against five applications. The cTAKES annotations are the foundation for methods and modules for higher-level semantic processing of clinical free-text.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22217,""
"New trends in minimally invasive urological surgery: what is beyond the robot?","Micali, Pini, Teber, Sighinolfi, De Stefani, Bianchi, Rassweiler","https://doi.org/10.1007/s00345-010-0588-5","20140220","PubMed","Endoscopy; Humans; Laparoscopy; Minimally Invasive Surgical Procedures; Robotics; Surgery, Computer-Assisted; Treatment Outcome; Urologic Surgical Procedures","To review the minimal-invasive development of surgical technique in urology focusing on nomenclature, history and outcomes of Laparo-Endoscopic Single-site Surgery (LESS), Natural Orifice Translumenal Endoscopic Surgery (NOTES) and Computer-Assisted Surgery (CAS). A comprehensive literature search was conducted in order to find article related to LESS, NOTES and CAS in urology. The most relevant papers over the last 10 years were selected in base to the experience from the panel of experts, journal, authorship and/or content. Seven hundred and fifty manuscripts were found. Papers on LESS describe feasibility/safety in most of the procedures with a clinical experience of more than 300 cases and five compared results to standard laparoscopy without showing significant differences. NOTES accesses have been proved their feasibility/safety in experimental study. In human, the only procedures performed are on kidney and through a hybrid-Transvaginal route. New robots overcome the main drawbacks of the DaVinciÃ‚Â® platform. The use of CAS is increasing its popularity in urology. LESS has been applied in clinical practice, but only ongoing technical and instrumental refinement will define its future role and overall benefit. The transition to a clinical application of NOTES seems at present only possible with multiple NOTES access and transvaginal access. Robot and Soft Tissue Navigation appear to be important to improve surgical skills. We are already witness to the advantages offered by the former even if costs need to be redefined based on pending long-term results. The latter will probably upgrade the quality of surgery in a near future.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22218,""
"An improved medical decision support system to identify the breast cancer using mammogram","Suganthi, Madheswaran","https://doi.org/10.1007/s10916-010-9448-5","20120426","PubMed","Algorithms; Breast Neoplasms; Decision Making, Computer-Assisted; Female; Humans; Image Processing, Computer-Assisted; Mammography; Neoplasm Staging; Neural Networks, Computer","An improved Computer Aided Clinical Decision Support System has been developed to classify the tumor and identify the stages of the cancer using neural network and presented in this paper. The texture and shape features have been extracted and the optimal feature set has been obtained using multiobjective genetic algorithm (MOGA). The multilayer back propagation neural network with Ant Colony Optimization and Particle Swarm Optimization has been used. The accuracy of the proposed system has been verified and found that the accuracy of 99.5% can be achieved. The proposed system can provide valuable information to the physicians in clinical pathology.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22219,""
"Information extraction approaches to unconventional data sources for ""Injury Surveillance System"": the case of newspapers clippings","Berchialla, Scarinzi, Snidero, Rahim, Gregori","https://doi.org/10.1007/s10916-010-9492-1","20120703","PubMed","Age Factors; Airway Obstruction; Algorithms; Child; Child, Preschool; Data Collection; Data Mining; Female; Humans; Male; Newspapers as Topic; Sentinel Surveillance; Sex Factors; Wounds and Injuries","Injury Surveillance Systems based on traditional hospital records or clinical data have the advantage of being a well established, highly reliable source of information for making an active surveillance on specific injuries, like choking in children. However, they suffer the drawback of delays in making data available to the analysis, due to inefficiencies in data collection procedures. In this sense, the integration of clinical based registries with unconventional data sources like newspaper articles has the advantage of making the system more useful for early alerting. Usage of such sources is difficult since information is only available in the form of free natural-language documents rather than structured databases as required by traditional data mining techniques. Information Extraction (IE) addresses the problem of transforming a corpus of textual documents into a more structured database. In this paper, on a corpora of Italian newspapers articles related to choking in children due to ingestion/inhalation of foreign body we compared the performance of three IE algorithms- (a) a classical rule based system which requires a manual annotation of the rules; (ii) a rule based system which allows for the automatic building of rules; (b) a machine learning method based on Support Vector Machine. Although some useful indications are extracted from the newspaper clippings, this approach is at the time far from being routinely implemented for injury surveillance purposes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22220,""
"Automatic classification of heartbeats using wavelet neural network","Benali, Bereksi Reguig, Hadj Slimane","https://doi.org/10.1007/s10916-010-9551-7","20120703","PubMed","Aged; Aged, 80 and over; Algorithms; Arrhythmias, Cardiac; Electrocardiography; Female; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Neural Networks, Computer; Wavelet Analysis","The electrocardiogram (ECG) signal is widely employed as one of the most important tools in clinical practice in order to assess the cardiac status of patients. The classification of the ECG into different pathologic disease categories is a complex pattern recognition task. In this paper, we propose a method for ECG heartbeat pattern recognition using wavelet neural network (WNN). To achieve this objective, an algorithm for QRS detection is first implemented, then a WNN Classifier is developed. The experimental results obtained by testing the proposed approach on ECG data from the MIT-BIH arrhythmia database demonstrate the efficiency of such an approach when compared with other methods existing in the literature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22221,""
"Significant cancer prevention factor extraction: an association rule discovery approach","Nahar, Tickle, Ali, Chen","https://doi.org/10.1007/s10916-009-9372-8","20110726","PubMed","Algorithms; Databases, Factual; Health Behavior; Humans; Neoplasms; Risk Assessment; Risk Factors","Cancer is increasing the total number of unexpected deaths around the world. Until now, cancer research could not significantly contribute to a proper solution for the cancer patient, and as a result, the high death rate is uncontrolled. The present research aim is to extract the significant prevention factors for particular types of cancer. To find out the prevention factors, we first constructed a prevention factor data set with an extensive literature review on bladder, breast, cervical, lung, prostate and skin cancer. We subsequently employed three association rule mining algorithms, Apriori, Predictive apriori and Tertius algorithms in order to discover most of the significant prevention factors against these specific types of cancer. Experimental results illustrate that Apriori is the most useful association rule-mining algorithm to be used in the discovery of prevention factors.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22222,""
"Validation of psoriatic arthritis diagnoses in electronic medical records using natural language processing","Love, Cai, Karlson","https://doi.org/10.1016/j.semarthrit.2010.05.002","20110719","PubMed","Aged; Algorithms; Arthritis, Psoriatic; Electronic Health Records; Female; Humans; Male; Middle Aged; Natural Language Processing; ROC Curve; Sensitivity and Specificity","To test whether data extracted from full text patient visit notes from an electronic medical record would improve the classification of psoriatic arthritis (PsA) compared with an algorithm based on codified data. From the &gt;1,350,000 adults in a large academic electronic medical record, all 2318 patients with a billing code for PsA were extracted and 550 were randomly selected for chart review and algorithm training. Using codified data and phrases extracted from narrative data using natural language processing, 31 predictors were extracted and 3 random forest algorithms were trained using coded, narrative, and combined predictors. The receiver operator curve was used to identify the optimal algorithm and a cut-point was chosen to achieve the maximum sensitivity possible at a 90% positive predictive value (PPV). The algorithm was then used to classify the remaining 1768 charts and finally validated in a random sample of 300 cases predicted to have PsA. The PPV of a single PsA code was 57% (95% CI 55%-58%). Using a combination of coded data and natural language processing (NLP), the random forest algorithm reached a PPV of 90% (95% CI 86%-93%) at a sensitivity of 87% (95% CI 83%-91%) in the training data. The PPV was 93% (95% CI 89%-96%) in the validation set. Adding NLP predictors to codified data increased the area under the receiver operator curve (P &lt; 0.001). Using NLP with text notes from electronic medical records improved the performance of the prediction algorithm significantly. Random forests were a useful tool to accurately classify psoriatic arthritis cases to enable epidemiological research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22223,""
"eGIFT: mining gene information from the literature","Tudor, Schmidt, Vijay-Shanker","https://doi.org/10.1186/1471-2105-11-418","20101013","PubMed","Data Mining; Genes; Internet; Periodicals as Topic; Software; Terminology as Topic","With the biomedical literature continually expanding, searching PubMed for information about specific genes becomes increasingly difficult. Not only can thousands of results be returned, but gene name ambiguity leads to many irrelevant hits. As a result, it is difficult for life scientists and gene curators to rapidly get an overall picture about a specific gene from documents that mention its names and synonyms. In this paper, we present eGIFT (http://biotm.cis.udel.edu/eGIFT), a web-based tool that associates informative terms, called iTerms, and sentences containing them, with genes. To associate iTerms with a gene, eGIFT ranks iTerms about the gene, based on a score which compares the frequency of occurrence of a term in the gene's literature to its frequency of occurrence in documents about genes in general. To retrieve a gene's documents (Medline abstracts), eGIFT considers all gene names, aliases, and synonyms. Since many of the gene names can be ambiguous, eGIFT applies a disambiguation step to remove matches that do not correspond to this gene. Another additional filtering process is applied to retain those abstracts that focus on the gene rather than mention it in passing. eGIFT's information for a gene is pre-computed and users of eGIFT can search for genes by using a name or an EntrezGene identifier. iTerms are grouped into different categories to facilitate a quick inspection. eGIFT also links an iTerm to sentences mentioning the term to allow users to see the relation between the iTerm and the gene. We evaluated the precision and recall of eGIFT's iTerms for 40 genes; between 88% and 94% of the iTerms were marked as salient by our evaluators, and 94% of the UniProtKB keywords for these genes were also identified by eGIFT as iTerms. Our evaluations suggest that iTerms capture highly-relevant aspects of genes. Furthermore, by showing sentences containing these terms, eGIFT can provide a quick description of a specific gene. eGIFT helps not only life scientists survey results of high-throughput experiments, but also annotators to find articles describing gene aspects and functions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22224,""
"Automatic de-identification of textual documents in the electronic health record: a review of recent research","Meystre, Friedlin, South, Shen, Samore","https://doi.org/10.1186/1471-2288-10-70","20100920","PubMed","Algorithms; Confidentiality; Electronic Health Records; Health Insurance Portability and Accountability Act; Humans; Software; United States","In the United States, the Health Insurance Portability and Accountability Act (HIPAA) protects the confidentiality of patient data and requires the informed consent of the patient and approval of the Internal Review Board to use data for research purposes, but these requirements can be waived if data is de-identified. For clinical data to be considered de-identified, the HIPAA ""Safe Harbor"" technique requires 18 data elements (called PHI: Protected Health Information) to be removed. The de-identification of narrative text documents is often realized manually, and requires significant resources. Well aware of these issues, several authors have investigated automated de-identification of narrative text documents from the electronic health record, and a review of recent research in this domain is presented here. This review focuses on recently published research (after 1995), and includes relevant publications from bibliographic queries in PubMed, conference proceedings, the ACM Digital Library, and interesting publications referenced in already included papers. The literature search returned more than 200 publications. The majority focused only on structured data de-identification instead of narrative text, on image de-identification, or described manual de-identification, and were therefore excluded. Finally, 18 publications describing automated text de-identification were selected for detailed analysis of the architecture and methods used, the types of PHI detected and removed, the external resources used, and the types of clinical documents targeted. All text de-identification systems aimed to identify and remove person names, and many included other types of PHI. Most systems used only one or two specific clinical document types, and were mostly based on two different groups of methodologies: pattern matching and machine learning. Many systems combined both approaches for different types of PHI, but the majority relied only on pattern matching, rules, and dictionaries. In general, methods based on dictionaries performed better with PHI that is rarely mentioned in clinical text, but are more difficult to generalize. Methods based on machine learning tend to perform better, especially with PHI that is not mentioned in the dictionaries used. Finally, the issues of anonymization, sufficient performance, and ""over-scrubbing"" are discussed in this publication.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22225,""
"CIG-DB: the database for human or mouse immunoglobulin and T cell receptor genes available for cancer studies","Nakamura, Komiyama, Furue, Gojobori, Akiyama","https://doi.org/10.1186/1471-2105-11-398","20101013","PubMed","Animals; Base Sequence; Databases, Genetic; Epitopes; Genes, Neoplasm; Genes, T-Cell Receptor; Humans; Immunoglobulins; Mice; Models, Molecular; Sequence Analysis","Immunoglobulin (IG or antibody) and the T-cell receptor (TR) are pivotal proteins in the immune system of higher organisms. In cancer immunotherapy, the immune responses mediated by tumor-epitope-binding IG or TR play important roles in anticancer effects. Although there are public databases specific for immunological genes, their contents have not been associated with clinical studies. Therefore, we developed an integrated database of IG/TR data reported in cancer studies (the Cancer-related Immunological Gene Database [CIG-DB]). This database is designed as a platform to explore public human and murine IG/TR genes sequenced in cancer studies. A total of 38,308 annotation entries for IG/TR proteins were collected from GenBank/DDBJ/EMBL and the Protein Data Bank, and 2,740 non-redundant corresponding MEDLINE references were appended. Next, we filtered the MEDLINE texts by MeSH terms, titles, and abstracts containing keywords related to cancer. After we performed a manual check, we classified the protein entries into two groups: 611 on cancer therapy (Group I) and 1,470 on hematological tumors (Group II). Thus, a total of 2,081 cancer-related IG and TR entries were tabularized. To effectively classify future entries, we developed a computational method based on text mining and canonical discriminant analysis by parsing MeSH/title/abstract words. We performed a leave-one-out cross validation for the method, which showed high accuracy rates: 94.6% for IG references and 94.7% for TR references. We also collected 920 epitope sequences bound with IG/TR. The CIG-DB is equipped with search engines for amino acid sequences and MEDLINE references, sequence analysis tools, and a 3D viewer. This database is accessible without charge or registration at http://www.scchr-cigdb.jp/, and the search results are freely downloadable. The CIG-DB serves as a bridge between immunological gene data and cancer studies, presenting annotation on IG, TR, and their epitopes. This database contains IG and TR data classified into two cancer-related groups and is able to automatically classify accumulating entries into these groups. The entries in Group I are particularly crucial for cancer immunotherapy, providing supportive information for genetic engineering of novel antibody medicines, tumor-specific TR, and peptide vaccines.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22226,""
"Identifying adverse drug reactions associated with drug-drug interactions: data mining of a spontaneous reporting database in Italy","Leone, Magro, Moretti, Cutroneo, Moschini, Motola, Tuccori, Conforti","https://doi.org/10.2165/11534400-000000000-00000","20110421","PubMed","Adverse Drug Reaction Reporting Systems; Aged; Data Mining; Databases, Factual; Drug Interactions; Drug-Related Side Effects and Adverse Reactions; Female; Humans; Italy; Male; Middle Aged; Time Factors","Drug-drug interactions (DDIs) are an important cause of adverse drug reactions (ADRs). Many studies have recently considered this issue, but most of them focus only on potential interactions and are often related to the hospital setting. A spontaneous reporting database could be a valuable resource for detection of ADRs associated with DDIs; however, data in the literature are limited. To detect those patients treated with potentially interacting drugs and the cases where reported adverse reactions are a possible consequence of DDIs, using an Italian spontaneous reporting database. The data were obtained from a database containing all reports of suspected ADRs from five Italian regions (January 1990 to December 2007) that are the main contributors to the Italian spontaneous reporting system. All reports containing at least two drugs, reported as being suspected of causing the ADR or as concomitant medication, were selected and a list of drug pairs was drawn up. We performed a search to verify which drug pairs are considered a potential DDI, using the Internet version of the DRUGDEX(R) system. For each report containing a potential DDI, we verified whether the description of the adverse reaction corresponded to the interaction effect. The database contained 45 315 reports, of which 17 700 (39.1%) had at least two reported drugs. We identified 5345 (30.2%) reports with potential DDIs, and in 1159 (21.7%) of these reports a related ADR was reported. The percentage of reports with potential DDIs increased in relation to the number of concomitantly administered drugs, ranging from 9.8% for two drugs to 88.3% for eight or more drugs. The percentages of serious or fatal reports of ADRs associated with a DDI were significantly higher than other reports analysed. The mean age, percentage of male patients and the mean number of drugs were also significantly higher in reports with DDIs than in other reports. In 235 of 1159 reports (20.3%), both interacting drugs were recognized as suspect by the reporter. This percentage varies in relation to the drugs involved, ranging from 2% to about 65%. The most frequently reported interaction was digoxin and diuretics, but no fatal ADRs were reported with this combination. The combination of anticoagulant and antiplatelet agents was responsible for the greatest number of serious reactions and deaths. This study validates that spontaneous reporting, despite its limitations, can be an important resource for detecting ADRs associated with the concomitant use of interacting drugs. Moreover, our data confirm that DDIs could be a real problem in clinical practice, showing that more than one in five patients exposed to a potential DDI experienced a related ADR.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22227,""
"Nearly automatic segmentation of hippocampal subfields in in vivo focal T2-weighted MRI","Yushkevich, Wang, Pluta, Das, Craige, Avants, Weiner, Mueller","https://doi.org/10.1016/j.neuroimage.2010.06.040","20110103","PubMed","Adult; Aged; Aged, 80 and over; Algorithms; Brain Mapping; Female; Hippocampus; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged","We present and evaluate a new method for automatically labeling the subfields of the hippocampal formation in focal 0.4 Ãƒâ€” 0.5 Ãƒâ€” 2.0mm(3) resolution T2-weighted magnetic resonance images that can be acquired in the routine clinical setting with under 5 min scan time. The method combines multi-atlas segmentation, similarity-weighted voting, and a novel learning-based bias correction technique to achieve excellent agreement with manual segmentation. Initial partitioning of MRI slices into hippocampal 'head', 'body' and 'tail' slices is the only input required from the user, necessitated by the nature of the underlying segmentation protocol. Dice overlap between manual and automatic segmentation is above 0.87 for the larger subfields, CA1 and dentate gyrus, and is competitive with the best results for whole-hippocampus segmentation in the literature. Intraclass correlation of volume measurements in CA1 and dentate gyrus is above 0.89. Overlap in smaller hippocampal subfields is lower in magnitude (0.54 for CA2, 0.62 for CA3, 0.77 for subiculum and 0.79 for entorhinal cortex) but comparable to overlap between manual segmentations by trained human raters. These results support the feasibility of subfield-specific hippocampal morphometry in clinical studies of memory and neurodegenerative disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22228,""
"Symbolic rule-based classification of lung cancer stages from free-text pathology reports","Nguyen, Lawley, Hansen, Bowman, Clarke, Duhig, Colquist","https://doi.org/10.1136/jamia.2010.003707","20101021","PubMed","Algorithms; Artificial Intelligence; Australia; Data Mining; Decision Support Systems, Clinical; Humans; Lung Neoplasms; Neoplasm Staging; Registries; Systematized Nomenclature of Medicine","To classify automatically lung tumor-node-metastases (TNM) cancer stages from free-text pathology reports using symbolic rule-based classification. By exploiting report substructure and the symbolic manipulation of systematized nomenclature of medicine-clinical terms (SNOMED CT) concepts in reports, statements in free text can be evaluated for relevance against factors relating to the staging guidelines. Post-coordinated SNOMED CT expressions based on templates were defined and populated by concepts in reports, and tested for subsumption by staging factors. The subsumption results were used to build logic according to the staging guidelines to calculate the TNM stage. The accuracy measure and confusion matrices were used to evaluate the TNM stages classified by the symbolic rule-based system. The system was evaluated against a database of multidisciplinary team staging decisions and a machine learning-based text classification system using support vector machines. Overall accuracy on a corpus of pathology reports for 718 lung cancer patients against a database of pathological TNM staging decisions were 72%, 78%, and 94% for T, N, and M staging, respectively. The system's performance was also comparable to support vector machine classification approaches. A system to classify lung TNM stages from free-text pathology reports was developed, and it was verified that the symbolic rule-based approach using SNOMED CT can be used for the extraction of key lung cancer characteristics from free-text reports. Future work will investigate the applicability of using the proposed methodology for extracting other cancer characteristics and types.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22229,""
"Computer-aided detection of centroblasts for follicular lymphoma grading using adaptive likelihood-based cell segmentation","Sertel, Lozanski, Shana'ah, Gurcan","https://doi.org/10.1109/TBME.2010.2055058","20110119","PubMed","Algorithms; Cells; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Immunohistochemistry; Lymphoma, Follicular","Follicular lymphoma (FL) is one of the most common lymphoid malignancies in the western world. FL has a variable clinical course, and important clinical treatment decisions for FL patients are based on histological grading, which is done by manually counting the large malignant cells called centroblasts (CB) in ten standard microscopic high-power fields from H&amp;E-stained tissue sections. This method is tedious and subjective; as a result, suffers from considerable inter and intrareader variability even when used by expert pathologists. In this paper, we present a computer-aided detection system for automated identification of CB cells from H&amp;E-stained FL tissue samples. The proposed system uses a unitone conversion to obtain a single-channel image that has the highest contrast. From the resulting image, which has a bimodal distribution due to the H&amp;E stain, a cell-likelihood image is generated. Finally, a two-step CB detection procedure is applied. In the first step, we identify evident nonCB cells based on size and shape. In the second step, the CB detection is further refined by learning and utilizing the texture distribution of nonCB cells. We evaluated the proposed approach on 100 region-of-interest images extracted from ten distinct tissue samples and obtained a promising 80.7% detection accuracy.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22230,""
"The role of epidermal growth factor receptor in photodynamic therapy: a review of the literature and proposal for future investigation","MartÃƒÂ­nez-Carpio, Trelles","https://doi.org/10.1007/s10103-010-0790-0","20110128","PubMed","Animals; Combined Modality Therapy; ErbB Receptors; Humans; Neoplasms; Photochemotherapy","The epidermal growth factor receptor (EGFR) pathway seems to be an important contributor to the antiproliferative response to photodynamic therapy (PDT), in terms of cell death, apoptosis and tumour destruction. We reviewed all preclinical investigations in the scientific literature on the role of the EGFR pathway in PDT. A systematic search of Medline-indexed references up to March 2010 using the recommended strategies for Medline information retrieval and identifying relevant studies from systematic reviews, revealed 16 full articles that were exhaustively analysed. EGFR inhibition/degradation appeared to be a major effect of PDT in all investigations. PDT was found to result in a time-dependent reduction of EGFR expression, inhibition of tyrosine phosphorylation and induction of apoptosis during the regression of tumours. Within the time period of the PDT reaction, normal and malignant cells lose their responsiveness to EGF. The ERK1/2 and EGFR-PI3K-Akt pathways seem to be involved in cellular survival after PDT. Pharmacotherapy and immunotherapy to block EGFR activity combined with PDT seem to be very effective in reducing malignant tumours in vivo. The effect of PDT is associated with inactivation of the EGFR pathway, but biochemical and cellular phenomena are important and scarcely investigated. EGFR inhibitors and PDT act synergistically, and this is highly relevant for clinical use.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22231,""
"Visual spatial cognition in neurodegenerative disease","Possin","https://doi.org/10.1080/13554791003730600","20110411","PubMed","Alzheimer Disease; Brain; Cognition; Dementia; Frontotemporal Lobar Degeneration; Humans; Lewy Body Disease; Neurodegenerative Diseases; Neuropsychological Tests; Parkinson Disease; Space Perception; Supranuclear Palsy, Progressive; Vision, Ocular; Visual Perception","Visual spatial impairment is often an early symptom of neurodegenerative disease; however, this multi-faceted domain of cognition is not well-assessed by most typical dementia evaluations. Neurodegenerative diseases cause circumscribed atrophy in distinct neural networks, and accordingly, they impact visual spatial cognition in different and characteristic ways. Anatomically-focused visual spatial assessment can assist the clinician in making an early and accurate diagnosis. This article will review the literature on visual spatial cognition in neurodegenerative disease clinical syndromes, and where research is available, by neuropathologic diagnoses. Visual spatial cognition will be organized primarily according to the following schemes: bottom-up/top-down processing, dorsal/ventral stream processing, and egocentric/allocentric frames of reference.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22232,""
"Update on mathematical modeling research to support the development of automated insulin delivery systems","Steil, Hipszer, Reifman","https://doi.org/10.1177/193229681000400334","20101116","PubMed","Blood Glucose; Diabetes Mellitus; Humans; Hypoglycemic Agents; Insulin; Insulin Infusion Systems; Models, Theoretical","One year after its initial meeting, the Glycemia Modeling Working Group reconvened during the 2009 Diabetes Technology Meeting in San Francisco, CA. The discussion, involving 39 scientists, again focused on the need for individual investigators to have access to the clinical data required to develop and refine models of glucose metabolism, the need to understand the differences among the distinct models and control algorithms, and the significance of day-to-day subject variability. The key conclusion was that model-based comparisons of different control algorithms, or the models themselves, are limited by the inability to access individual model-patient parameters. It was widely agreed that these parameters, as opposed to the average parameters that are typically reported, are necessary to perform such comparisons. However, the prevailing view was that, if investigators were to make the parameters available, it would limit their ability (and that of their institution) to benefit from the invested work in developing their models. A general agreement was reached regarding the importance of each model having an insulin pharmacokinetic/pharmacodynamic profile that is not different from profiles reported in the literature (88% of the respondents agreed that the model should have similar curves or be analyzed separately) and the importance of capturing intraday variance in insulin sensitivity (91% of the respondents indicated that this could result in changes in fasting glucose of &gt;or=15%, with 52% of the respondents believing that the variability could effect changes of &gt;or=30%). Seventy-six percent of the participants indicated that high-fat meals were thought to effect changes in other model parameters in addition to gastric emptying. There was also widespread consensus as to how a closed-loop controller should respond to day-to-day changes in model parameters (with 76% of the participants indicating that fasting glucose should be within 15% of target, with 30% of the participants believing that it should be at target). The group was evenly divided as to whether the glucose sensor per se continues to be the major obstacle in achieving closed-loop control. Finally, virtually all participants agreed that a future two-day workshop should be organized to compare, contrast, and understand the differences among the different models and control algorithms.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22233,""
"Acupuncture, the limbic system, and the anticorrelated networks of the brain","Hui, Marina, Liu, Rosen, Kwong","https://doi.org/10.1016/j.autneu.2010.03.022","20110202","PubMed","Acupuncture; Acupuncture Points; Animals; Brain Mapping; Humans; Image Processing, Computer-Assisted; Limbic System; Magnetic Resonance Imaging; Neural Pathways; Oxygen; Time Factors","The study of the mechanism of acupuncture action was revolutionized by the use of functional magnetic resonance imaging (fMRI). Over the past decade, our fMRI studies of healthy subjects have contributed substantially to elucidating the central effect of acupuncture on the human brain. These studies have shown that acupuncture stimulation, when associated with sensations comprising deqi, evokes deactivation of a limbic-paralimbic-neocortical network, which encompasses the limbic system, as well as activation of somatosensory brain regions. These networks closely match the default mode network and the anti-correlated task-positive network described in the literature. We have also shown that the effect of acupuncture on the brain is integrated at multiple levels, down to the brainstem and cerebellum. Our studies support the hypothesis that the effect of acupuncture on the brain goes beyond the effect of attention on the default mode network or the somatosensory stimulation of acupuncture needling. The amygdala and hypothalamus, in particular, show decreased activation during acupuncture stimulation that is not commonly associated with default mode network activity. At the same time, our research shows that acupuncture stimulation needs to be done carefully, limiting stimulation when the resulting sensations are very strong or when sharp pain is elicited. When acupuncture induced sharp pain, our studies show that the deactivation was attenuated or reversed in direction. Our results suggest that acupuncture mobilizes the functionally anti-correlated networks of the brain to mediate its actions, and that the effect is dependent on the psychophysical response. In this work we also discuss multiple avenues of future research, including the role of neurotransmitters, the effect of different acupuncture techniques, and the potential clinical application of our research findings to disease states including chronic pain, major depression, schizophrenia, autism, and Alzheimer's disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22234,""
"caTIES: a grid based system for coding and retrieval of surgical pathology reports and tissue specimens in support of translational research","Crowley, Castine, Mitchell, Chavan, McSherry, Feldman","https://doi.org/10.1136/jamia.2009.002295","20100804","PubMed","Biological Specimen Banks; Computer Graphics; Computer Security; Data Mining; Humans; Information Dissemination; Interinstitutional Relations; Multicenter Studies as Topic; Natural Language Processing; Neoplasms; Translational Medical Research; United States; User-Computer Interface","The authors report on the development of the Cancer Tissue Information Extraction System (caTIES)--an application that supports collaborative tissue banking and text mining by leveraging existing natural language processing methods and algorithms, grid communication and security frameworks, and query visualization methods. The system fills an important need for text-derived clinical data in translational research such as tissue-banking and clinical trials. The design of caTIES addresses three critical issues for informatics support of translational research: (1) federation of research data sources derived from clinical systems; (2) expressive graphical interfaces for concept-based text mining; and (3) regulatory and security model for supporting multi-center collaborative research. Implementation of the system at several Cancer Centers across the country is creating a potential network of caTIES repositories that could provide millions of de-identified clinical reports to users. The system provides an end-to-end application of medical natural language processing to support multi-institutional translational research programs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22235,""
"An analysis of clinical queries in an electronic health record search utility","Natarajan, Stein, Jain, Elhadad","https://doi.org/10.1016/j.ijmedinf.2010.03.004","20100930","PubMed","Data Mining; Medical Records Systems, Computerized; New York; Search Engine","While search engines have become nearly ubiquitous on the Web, electronic health records (EHRs) generally lack search functionality; furthermore, there is no knowledge on how and what healthcare providers search while using an EHR-based search utility. In this study, we sought to understand user needs as captured by their search queries. This post-implementation study analyzed user search log files for 6 months from an EHR-based, free-text search utility at our large academic institution. The search logs were de-identified and then analyzed in two steps. First, two investigators classified all the unique queries as navigational, transactional, or informational searches. Second, three physician reviewers categorized a random sample of 357 informational searches into high-level semantic types derived from the Unified Medical Language System (UMLS). The reviewers were given overlapping data sets, such that two physicians reviewed each query. We analyzed 2207 queries performed by 436 unique users over a 6-month period. Of the 2207 queries, 980 were unique queries. Users of the search utility included clinicians, researchers and administrative staff. Across the whole user population, approximately 14.5% of the user searches were navigational searches and 85.1% were informational. Within informational searches, we found that users predominantly searched for laboratory results and specific diseases. A variety of user types, ranging from clinicians to administrative staff, took advantage of the EHR-based search utility. Though these users' search behavior differed, they predominantly performed informational searches related to laboratory results and specific diseases. Additionally, a number of queries were part of words, implying the need for a free-text module to be included in any future concept-based search algorithm.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22236,""
"A comparative method for processing immunological parameters: developing an ""Immunogram""","Ortolani, Bellavite, Paiola, Martini, Marchesini, Veneri, Franchini, Chirumbolo, Tridente, Vella","https://doi.org/10.2450/2009.0096-09","20100713","PubMed","immune monitoring; immunodiagnostics; lymphocyte subsets; multiparametric analysis; systems biology; Adult; Age Factors; Antibodies, Monoclonal; Antibody Specificity; Antigens, CD; Cell Lineage; Child; Databases, Factual; Female; Flow Cytometry; Fluorescent Dyes; HLA-DR Antigens; Humans; Immunoconjugates; Lymphocyte Count; Lymphocyte Subsets; Male; Reference Values; Software","The immune system is a network of numerous cells that communicate both directly and indirectly with each other. The system is very sensitive to antigenic stimuli, which are memorised, and is closely connected with the endocrine and nervous systems. Therefore, in order to study the immune system correctly, it must be considered in all its complexity by analysing its components with multiparametric tools that take its dynamic characteristic into account. We analysed lymphocyte subpopulations by using monoclonal antibodies with six different fluorochromes; the monoclonal panel employed included CD45, CD3, CD4, CD8, CD16, CD56, CD57, CD19, CD23, CD27, CD5, and HLA-DR. This panel has enabled us to measure many lymphocyte subsets in different states and with different functions: helper, suppressor, activated, effector, naÃƒÂ¯ve, memory, and regulatory. A database was created to collect the values of immunological parameters of approximately 8,000 subjects who have undergone testing since 2000. When the distributions of the values for these parameters were compared with the medians of reference values published in the literature, we found that most of the values from the subjects included in the database were close to the medians in the literature. To process the data we used a comparative method that calculates the percentile rank of the values of a subject by comparing them with the values for others subjects of the same age. From this data processing we obtained a set of percentile ranks that represent the positions of the various parameters with regard to the data for other age-matched subjects included in the database. These positions, relative to both the absolute values and percentages, are plotted in a graph. We have called the final plot, which can be likened to that subject's immunological fingerprint, an ""Immunogram"". In order to perform the necessary calculations automatically, we developed dedicated software (Immunogramma) which provides at least two different ""pictures"" for each subject: the first is based on a comparison of the individual's data with those from all age-related subjects, while the second provides a comparison with only age and disease-related subjects. In addition, we can superimpose two fingerprints from the same subject, calculated at different times, in order to produce a dynamic picture, for instance before and after treatment. Finally, with the aim of interpreting the clinical and diagnostic meaning of a set of positions for the values of the measured parameters, we can also search the database to determine whether it contains other subjects who have a similar pattern for some selected immune parameters. This method helps to study and follow-up immune parameters over time. The software enables automation of the process and data sharing with other departments and laboratories, so the database can grow rapidly, thus expanding its informational capacity.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22237,""
"Selecting information in electronic health records for knowledge acquisition","Wang, Chase, Markatou, Hripcsak, Friedman","https://doi.org/10.1016/j.jbi.2010.03.011","20101028","PubMed","Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Information Storage and Retrieval; Models, Statistical; Natural Language Processing","Knowledge acquisition of relations between biomedical entities is critical for many automated biomedical applications, including pharmacovigilance and decision support. Automated acquisition of statistical associations from biomedical and clinical documents has shown some promise. However, acquisition of clinically meaningful relations (i.e. specific associations) remains challenging because textual information is noisy and co-occurrence does not typically determine specific relations. In this work, we focus on acquisition of two types of relations from clinical reports: disease-manifestation related symptom (MRS) and drug-adverse drug event (ADE), and explore the use of filtering by sections of the reports to improve performance. Evaluation indicated that applying the filters improved recall (disease-MRS: from 0.85 to 0.90; drug-ADE: from 0.43 to 0.75) and precision (disease-MRS: from 0.82 to 0.92; drug-ADE: from 0.16 to 0.31). This preliminary study demonstrates that selecting information in narrative electronic reports based on the sections improves the detection of disease-MRS and drug-ADE types of relations. Further investigation of complementary methods, such as more sophisticated statistical methods, more complex temporal models and use of information from other knowledge sources, is needed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22238,""
"Building a high-quality sense inventory for improved abbreviation disambiguation","Okazaki, Ananiadou, Tsujii","https://doi.org/10.1093/bioinformatics/btq129","20101022","PubMed","Algorithms; Cluster Analysis; Computational Biology; Databases, Bibliographic; Dictionaries as Topic; MEDLINE; Models, Statistical; Natural Language Processing; Polymerase Chain Reaction; Reproducibility of Results; Software; Tomography, X-Ray Computed","The ultimate goal of abbreviation management is to disambiguate every occurrence of an abbreviation into its expanded form (concept or sense). To collect expanded forms for abbreviations, previous studies have recognized abbreviations and their expanded forms in parenthetical expressions of bio-medical texts. However, expanded forms extracted by abbreviation recognition are mixtures of concepts/senses and their term variations. Consequently, a list of expanded forms should be structured into a sense inventory, which provides possible concepts or senses for abbreviation disambiguation. A sense inventory is a key to robust management of abbreviations. Therefore, we present a supervised approach for clustering expanded forms. The experimental result reports 0.915 F1 score in clustering expanded forms. We then investigate the possibility of conflicts of protein and gene names with abbreviations. Finally, an experiment of abbreviation disambiguation on the sense inventory yielded 0.984 accuracy and 0.986 F1 score using the dataset obtained from MEDLINE abstracts. The sense inventory and disambiguator of abbreviations are accessible at http://www.nactem.ac.uk/software/acromine/ and http://www.nactem.ac.uk/software/acromine_disambiguation/.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22239,""
"Uncovering and improving upon the inherent deficiencies of radiology reporting through data mining","Reiner","https://doi.org/10.1007/s10278-010-9279-4","20100607","PubMed","Clinical Competence; Database Management Systems; Forecasting; Humans; Image Interpretation, Computer-Assisted; Information Dissemination; Interprofessional Relations; Medical Records Systems, Computerized; Practice Patterns, Physicians'; Radiology; Radiology Information Systems; Sensitivity and Specificity; Total Quality Management","Uncertainty has been the perceived Achilles heel of the radiology report since the inception of the free-text report. As a measure of diagnostic confidence (or lack thereof), uncertainty in reporting has the potential to lead to diagnostic errors, delayed clinical decision making, increased cost of healthcare delivery, and adverse outcomes. Recent developments in data mining technologies, such as natural language processing (NLP), have provided the medical informatics community with an opportunity to quantify report concepts, such as uncertainty. The challenge ahead lies in taking the next step from quantification to understanding, which requires combining standardized report content, data mining, and artificial intelligence; thereby creating Knowledge Discovery Databases (KDD). The development of this database technology will expand our ability to record, track, and analyze report data, along with the potential to create data-driven and automated decision support technologies at the point of care. For the radiologist community, this could improve report content through an objective and thorough understanding of uncertainty, identifying its causative factors, and providing data-driven analysis for enhanced diagnosis and clinical outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22240,""
"Artificial neural network, genetic algorithm, and logistic regression applications for predicting renal colic in emergency settings","Eken, Bilge, Kartal, Eray","https://doi.org/10.1007/s12245-009-0103-1","20100625","PubMed","Artificial neural network; Emergency department; Genetic algorithm; Logistic regression; Renal colic","Logistic regression is the most common statistical model for processing multivariate data in the medical literature. Artificial intelligence models like an artificial neural network (ANN) and genetic algorithm (GA) may also be useful to interpret medical data. The purpose of this study was to perform artificial intelligence models on a medical data sheet and compare to logistic regression. ANN, GA, and logistic regression analysis were carried out on a data sheet of a previously published article regarding patients presenting to an emergency department with flank pain suspicious for renal colic. The study population was composed of 227 patients: 176 patients had a diagnosis of urinary stone, while 51 ultimately had no calculus. The GA found two decision rules in predicting urinary stones. Rule 1 consisted of being male, pain not spreading to back, and no fever. In rule 2, pelvicaliceal dilatation on bedside ultrasonography replaced no fever. ANN, GA rule 1, GA rule 2, and logistic regression had a sensitivity of 94.9, 67.6, 56.8, and 95.5%, a specificity of 78.4, 76.47, 86.3, and 47.1%, a positive likelihood ratio of 4.4, 2.9, 4.1, and 1.8, and a negative likelihood ratio of 0.06, 0.42, 0.5, and 0.09, respectively. The area under the curve was found to be 0.867, 0.720, 0.715, and 0.713 for all applications, respectively. Data mining techniques such as ANN and GA can be used for predicting renal colic in emergency settings and to constitute clinical decision rules. They may be an alternative to conventional multivariate analysis applications used in biostatistics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22241,""
"Differential fractional anisotropy abnormalities in adolescents with ADHD or schizophrenia","Davenport, Karatekin, White, Lim","https://doi.org/10.1016/j.pscychresns.2009.10.012","20100412","PubMed","Adolescent; Anisotropy; Attention Deficit Disorder with Hyperactivity; Brain; Brain Mapping; Child; Diffusion Magnetic Resonance Imaging; Female; Humans; Male; Nerve Fibers, Myelinated; Neural Pathways; Schizophrenia; Young Adult","Schizophrenia and Attention-Deficit/Hyperactivity Disorder (ADHD) are associated with similar deficits in working memory, attention, and inhibition. Both disorders also involve abnormalities of white matter integrity, possibly reflecting neural communication disruptions. There are likely some regional white matter abnormalities that underlie the common cognitive impairment, though also some regional abnormalities unique to each disorder. We used diffusion tensor imaging (DTI) to compare white matter integrity, as indicated by fractional anisotropy (FA), in adolescents with schizophrenia (n=15) or ADHD (n=14) and healthy controls (n=26). Schizophrenia patients had uniquely low FA, relative to the other two groups, in bilateral cerebral peduncles, anterior and posterior corpus callosum, right anterior corona radiata, and right superior longitudinal fasciculus. ADHD patients had uniquely high FA in left inferior and right superior frontal regions. Both clinical groups had lower FA than controls in left posterior fornix. The two disorders generally demonstrated distinct patterns of abnormal connectivity suggesting that common cognitive and behavioral deficits derive from distinct sources, though the posterior fornix may be involved in both disorders. Schizophrenia was associated with abnormally low FA in widespread circuitry indicative of general connectivity disruptions, whereas ADHD was associated with abnormally high FA in frontal networks that may indicate impaired branching of fibers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22242,""
"Cost effectiveness of high-dose intravenous esomeprazole for peptic ulcer bleeding","Barkun, Adam, Sung, Kuipers, MÃƒÂ¶ssner, Jensen, Stuart, Lau, NauclÃƒÂ©r, Kilhamn, Granstedt, Liljas, Lind","https://doi.org/10.2165/11531480-000000000-00000","20100503","PubMed","Administration, Oral; Anti-Ulcer Agents; Combined Modality Therapy; Cost-Benefit Analysis; Decision Support Techniques; Esomeprazole; Health Care Costs; Hemostasis, Endoscopic; Humans; Infusions, Intravenous; Models, Economic; Peptic Ulcer Hemorrhage; Randomized Controlled Trials as Topic; Spain; Sweden; Treatment Outcome; United States","Peptic ulcer bleeding (PUB) is a serious and sometimes fatal condition. The outcome of PUB strongly depends on the risk of rebleeding. A recent multinational placebo-controlled clinical trial (ClinicalTrials.gov identifier: NCT00251979) showed that high-dose intravenous (IV) esomeprazole, when administered after successful endoscopic haemostasis in patients with PUB, is effective in preventing rebleeding. From a policy perspective it is important to assess the cost efficacy of this benefit so as to enable clinicians and payers to make an informed decision regarding the management of PUB. Using a decision-tree model, we compared the cost efficacy of high-dose IV esomeprazole versus an approach of no-IV proton pump inhibitor for prevention of rebleeding in patients with PUB. The model adopted a 30-day time horizon and the perspective of third-party payers in the USA and Europe. The main efficacy variable was the number of averted rebleedings. Healthcare resource utilization costs (physician fees, hospitalizations, surgeries, pharmacotherapies) relevant for the management of PUB were also determined. Data for unit costs (prices) were primarily taken from official governmental sources, and data for other model assumptions were retrieved from the original clinical trial and the literature. After successful endoscopic haemostasis, patients received either high-dose IV esomeprazole (80 mg infusion over 30 min, then 8 mg/hour for 71.5 hours) or no-IV esomeprazole treatment, with both groups receiving oral esomeprazole 40 mg once daily from days 4 to 30. Rebleed rates at 30 days were 7.7% and 13.6%, respectively, for the high-dose IV esomeprazole and no-IV esomeprazole treatment groups (equating to a number needed to treat of 17 in order to prevent one additional patient from rebleeding). In the US setting, the average cost per patient for the high-dose IV esomeprazole strategy was $US14 290 compared with $US14 239 for the no-IV esomeprazole strategy (year 2007 values). For the European setting, Sweden and Spain were used as examples. In the Swedish setting the corresponding respective figures were Swedish kronor (SEK)67 862 ($US9220 at average 2006 interbank exchange rates) and SEK67 807 ($US9212) [year 2006 values]. Incremental cost-effectiveness ratios were $US866 and SEK938 ($US127), respectively, per averted rebleed when using IV esomeprazole. For the Spanish setting, the high-dose IV esomeprazole strategy was dominant (more effective and less costly than the no-IV esomeprazole strategy) [year 2008 values]. All results appeared robust to univariate/threshold sensitivity analysis, with high-dose IV esomeprazole becoming dominant with small variations in assumptions in the US and Swedish settings, while remaining a dominant approach in the Spanish scenario across a broad range of values. Sensitivity variables with prespecified ranges included lengths of stay and per diem assumptions, rebleeding rates and, in some cases, professional fees. In patients with PUB, high-dose IV esomeprazole after successful endoscopic haemostasis appears to improve outcomes at a modest increase in costs relative to a no-IV esomeprazole strategy from the US and Swedish third-party payer perspective. Whereas, in the Spanish setting, the high-dose IV esomeprazole strategy appeared dominant, being more effective and less costly.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22243,""
"LAITOR--Literature Assistant for Identification of Terms co-Occurrences and Relationships","Barbosa-Silva, Soldatos, MagalhÃƒÂ£es, Pavlopoulos, Fontaine, Andrade-Navarro, Schneider, Ortega","https://doi.org/10.1186/1471-2105-11-70","20100511","PubMed","Computational Biology; Data Mining; Information Storage and Retrieval; MEDLINE; Publications; Software; United States","Biological knowledge is represented in scientific literature that often describes the function of genes/proteins (bioentities) in terms of their interactions (biointeractions). Such bioentities are often related to biological concepts of interest that are specific of a determined research field. Therefore, the study of the current literature about a selected topic deposited in public databases, facilitates the generation of novel hypotheses associating a set of bioentities to a common context. We created a text mining system (LAITOR: Literature Assistant for Identification of Terms co-Occurrences and Relationships) that analyses co-occurrences of bioentities, biointeractions, and other biological terms in MEDLINE abstracts. The method accounts for the position of the co-occurring terms within sentences or abstracts. The system detected abstracts mentioning protein-protein interactions in a standard test (BioCreative II IAS test data) with a precision of 0.82-0.89 and a recall of 0.48-0.70. We illustrate the application of LAITOR to the detection of plant response genes in a dataset of 1000 abstracts relevant to the topic. Text mining tools combining the extraction of interacting bioentities and biological concepts with network displays can be helpful in developing reasonable hypotheses in different scientific backgrounds.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22244,""
"Whether robot-assisted laparoscopic fundoplication is better for gastroesophageal reflux disease in adults: a systematic review and meta-analysis","Mi, Kang, Chen, Wang, Wang","https://doi.org/10.1007/s00464-009-0873-9","20101102","PubMed","Adult; Fundoplication; Gastroesophageal Reflux; Humans; Laparoscopy; Robotics; Time Factors","Although laparoscopic fundoplication is an effective, minimally invasive surgical technique for gastroesophageal reflux disease (GERD) that failed to be treated with medicine, with wide implementation its technical limitations have become increasingly clear. Recently, robot-assisted laparoscopic fundoplication (RALF) was considered a new approach that makes up for the deficiency of conventional laparoscopic fundoplication (CLF). This systematic review aimed to assess the feasibility and efficiency of robot-assisted laparoscopic fundoplication for GERD. Two reviewers independently searched and identified seven randomized controlled trials (RCTs) and four clinical controlled trials (CCTs) of RALF versus CLF for GERD in the Cochrane database, Medline, Embase, and Science citation index between 2001 and 2009. The main outcomes were operating time, complication rate, hospital stay, and costs. The meta-analysis was performed by Review Manager 5.0 software. The effect size of the clinical outcomes was evaluated by odds ratio (OR), weighted mean difference (WMD), and standard mean difference (SMD) according to different data type. Heterogeneity and sensitivity analysis were used to account for rationality of pooling data and sources of heterogeneity. Of 483 studies found, a total of 11 trials were included in this review; among 533 patients, 198 patients underwent RALF and 335 patients underwent CLF. The results of meta-analysis showed that the postoperative complication rate (OR = 0.35, 95% CI = [0.13, 0.93], p = 0.04) is lower for RALF, but the total operating time (WMD = 24.05, 95% CI = [5.19, 42.92], p = 0.01) is longer for RALF compared with those for CLF. Statistically, there was no significant difference between the two groups with regard to perioperative complication rate (OR = 0.67, 95% CI = [0.30, 1.48], p = 1.00) and length of hospital stay (WMD = 0.00, 95% CI = [-0.25, 0.26], p = 0.04). Systematic review of the literature indicates that RALF is a feasible and safe alternative to surgical treatment of GERD. However, since it lacks obvious advantages with respect to operating time, length of hospital stay and cost, RALF has limitations for its extensive application in clinics.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22245,""
"Automatic symptom name normalization in clinical records of traditional Chinese medicine","Wang, Yu, Jiang, Xu, Chen","https://doi.org/10.1186/1471-2105-11-40","20100608","PubMed","Algorithms; China; Disease; Medical Records Systems, Computerized; Medicine, Chinese Traditional; Natural Language Processing; Pattern Recognition, Automated; Terminology as Topic","In recent years, Data Mining technology has been applied more than ever before in the field of traditional Chinese medicine (TCM) to discover regularities from the experience accumulated in the past thousands of years in China. Electronic medical records (or clinical records) of TCM, containing larger amount of information than well-structured data of prescriptions extracted manually from TCM literature such as information related to medical treatment process, could be an important source for discovering valuable regularities of TCM. However, they are collected by TCM doctors on a day to day basis without the support of authoritative editorial board, and owing to different experience and background of TCM doctors, the same concept might be described in several different terms. Therefore, clinical records of TCM cannot be used directly to Data Mining and Knowledge Discovery. This paper focuses its attention on the phenomena of ""one symptom with different names"" and investigates a series of metrics for automatically normalizing symptom names in clinical records of TCM. A series of extensive experiments were performed to validate the metrics proposed, and they have shown that the hybrid similarity metrics integrating literal similarity and remedy-based similarity are more accurate than the others which are based on literal similarity or remedy-based similarity alone, and the highest F-Measure (65.62%) of all the metrics is achieved by hybrid similarity metric VSM+TFIDF+SWD. Automatic symptom name normalization is an essential task for discovering knowledge from clinical data of TCM. The problem is introduced for the first time by this paper. The results have verified that the investigated metrics are reasonable and accurate, and the hybrid similarity metrics are much better than the metrics based on literal similarity or remedy-based similarity alone.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22246,""
"A fully automated method for quantitative cerebral hemodynamic analysis using DSC-MRI","BjÃƒÂ¸rnerud, Emblem","https://doi.org/10.1038/jcbfm.2010.4","20100527","PubMed","Adolescent; Adult; Aged; Brain; Brain Neoplasms; Cerebrovascular Circulation; Child; Cluster Analysis; Female; Glioma; Hemodynamics; Humans; Magnetic Resonance Imaging; Male; Middle Aged; Regional Blood Flow; Reproducibility of Results; Young Adult","Dynamic susceptibility contrast (DSC)-based perfusion analysis from MR images has become an established method for analysis of cerebral blood volume (CBV) in glioma patients. To date, little emphasis has, however, been placed on quantitative perfusion analysis of these patients, mainly due to the associated increased technical complexity and lack of sufficient stability in a clinical setting. The aim of our study was to develop a fully automated analysis framework for quantitative DSC-based perfusion analysis. The method presented here generates quantitative hemodynamic maps without user interaction, combined with automatic segmentation of normal-appearing cerebral tissue. Validation of 101 patients with confirmed glioma after surgery gave mean values for CBF, CBV, and MTT, extracted automatically from normal-appearing whole-brain white and gray matter, in good agreement with literature values. The measured age- and gender-related variations in the same parameters were also in agreement with those in the literature. Several established analysis methods were compared and the resulting perfusion metrics depended significantly on method and parameter choice. In conclusion, we present an accurate, fast, and automatic quantitative perfusion analysis method where all analysis steps are based on raw DSC data only.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22247,""
"Automated dermoscopy image analysis of pigmented skin lesions","Baldi, Quartulli, Murace, Dragonetti, Manganaro, Guerra, Bizzi","https://doi.org/10.3390/cancers2020262","20131127","PubMed","","Dermoscopy (dermatoscopy, epiluminescence microscopy) is a non-invasive diagnostic technique for the in vivo observation of pigmented skin lesions (PSLs), allowing a better visualization of surface and subsurface structures (from the epidermis to the papillary dermis). This diagnostic tool permits the recognition of morphologic structures not visible by the naked eye, thus opening a new dimension in the analysis of the clinical morphologic features of PSLs. In order to reduce the learning-curve of non-expert clinicians and to mitigate problems inherent in the reliability and reproducibility of the diagnostic criteria used in pattern analysis, several indicative methods based on diagnostic algorithms have been introduced in the last few years. Recently, numerous systems designed to provide computer-aided analysis of digital images obtained by dermoscopy have been reported in the literature. The goal of this article is to review these systems, focusing on the most recent approaches based on content-based image retrieval systems (CBIR). ","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22248,""
"Comparing the effectiveness of computerized adverse drug event monitoring systems to enhance clinical decision support for hospitalized patients","Petratos, Kim, Evans, Williams, Gardner","https://doi.org/10.4338/ACI-2009-11-RA-0009","20130426","PubMed","Clinical decision support; data collection; error management and prevention; pharmacy information systems; system improvement","Performance of computerized adverse drug event (ADE) monitoring of electronic health records through a prospective ADE Monitor and ICD9-coded clinical text review operating independently and simultaneously on the same patient population for a 10-year period are compared. Requirements are compiled for clinical decision support in pharmacy systems to enhance ADE detection. A large tertiary care facility in Utah, with a history of quality improvement using its advanced hospital information system, was leveraged in this study. ICD9-based review of clinical charts (ICD9 System) was compared quantitatively and qualitatively to computer-assisted pharmacist-verified ADEs (ADE Monitor). The capture-recapture statistical method was applied to the data to determine an estimated prevalence of ADEs. A total estimated ADE prevalence of 5.53% (13,420/242,599) was calculated, with the ICD9 system identifying 2,604 or 19.4%, and the ADE monitor 3,386 or 25.2% of all estimated ADEs. Both methods commonly identified 4.9% of all estimated ADEs and matched 62.0% of the time, each having its strength in detecting a slightly different domain of ADEs. 70% of the ADE documentation in the clinical notes was found in the discharge summaries. Coupled with spontaneous reporting, computerized methods account for approximately half of all ADEs that can currently be detected. To enhance ADE monitoring and patient safety in a hospitalized setting, pharmacy information systems should incorporate prospective structuring and coding of the text in clinical charts and using that data alongside computer-generated alerts of laboratory results and drug orders. Natural language processing can aid computerized detection by automating the coding, in real-time, of physician text from clinical charts so that decision support rules can be created and applied. New detection strategies and enhancements to existing systems should be researched to enhance the detection of ADEs since approximately half are not currently detected.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22249,""
"Using Amazon's Mechanical Turk for Annotating Medical Named Entities","Yetisgen-Yildiz, Solti, Xia","https://www.google.com/search?q=Using+Amazon's+Mechanical+Turk+for+Annotating+Medical+Named+Entities.","20211020","PubMed","","Amazon's Mechanical Turk (AMT) service is becoming increasingly popular in Natural Language Processing (NLP) research. In this poster, we report our findings in using AMT to annotate biomedical text extracted from clinical trial descriptions with three entity types: medical condition, medication, and laboratory test. We also describe our observations on AMT workers' annotations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22250,""
"Emerging vaccine informatics","He, Rappuoli, De Groot, Chen","https://doi.org/10.1155/2010/218590","20111114","PubMed","Algorithms; Antibodies; Clinical Trials as Topic; Computational Biology; Computer Simulation; Databases, Genetic; Drug Design; Epitopes, B-Lymphocyte; Epitopes, T-Lymphocyte; Gene Expression Profiling; Genome, Human; Host-Pathogen Interactions; Humans; Models, Theoretical; Proteome; Vaccines","Vaccine informatics is an emerging research area that focuses on development and applications of bioinformatics methods that can be used to facilitate every aspect of the preclinical, clinical, and postlicensure vaccine enterprises. Many immunoinformatics algorithms and resources have been developed to predict T- and B-cell immune epitopes for epitope vaccine development and protective immunity analysis. Vaccine protein candidates are predictable in silico from genome sequences using reverse vaccinology. Systematic transcriptomics and proteomics gene expression analyses facilitate rational vaccine design and identification of gene responses that are correlates of protection in vivo. Mathematical simulations have been used to model host-pathogen interactions and improve vaccine production and vaccination protocols. Computational methods have also been used for development of immunization registries or immunization information systems, assessment of vaccine safety and efficacy, and immunization modeling. Computational literature mining and databases effectively process, mine, and store large amounts of vaccine literature and data. Vaccine Ontology (VO) has been initiated to integrate various vaccine data and support automated reasoning.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22251,""
"A scalable architecture for incremental specification and maintenance of procedural and declarative clinical decision-support knowledge","Hatsek, Shahar, Taieb-Maimon, Shalom, Klimov, Lunenfeld","https://doi.org/10.2174/1874431101004010255","20110714","PubMed","Medical informatics; artificial intelligence; clinical guidelines; decision support systems; digital libraries; human computer interaction; information retrieval; knowledge acquisition; knowledge bases; knowledge representation; ontologies; service oriented architecture.","Clinical guidelines have been shown to improve the quality of medical care and to reduce its costs. However, most guidelines exist in a free-text representation and, without automation, are not sufficiently accessible to clinicians at the point of care. A prerequisite for automated guideline application is a machine-comprehensible representation of the guidelines. In this study, we designed and implemented a scalable architecture to support medical experts and knowledge engineers in specifying and maintaining the procedural and declarative aspects of clinical guideline knowledge, resulting in a machine comprehensible representation. The new framework significantly extends our previous work on the Digital electronic Guidelines Library (DeGeL) The current study designed and implemented a graphical framework for specification of declarative and procedural clinical knowledge, Gesher. We performed three different experiments to evaluate the functionality and usability of the major aspects of the new framework: Specification of procedural clinical knowledge, specification of declarative clinical knowledge, and exploration of a given clinical guideline. The subjects included clinicians and knowledge engineers (overall, 27 participants). The evaluations indicated high levels of completeness and correctness of the guideline specification process by both the clinicians and the knowledge engineers, although the best results, in the case of declarative-knowledge specification, were achieved by teams including a clinician and a knowledge engineer. The usability scores were high as well, although the clinicians' assessment was significantly lower than the assessment of the knowledge engineers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22252,""
"Cheminformatics analysis of assertions mined from literature that describe drug-induced liver injury in different species","Fourches, Barnes, Day, Bradley, Reed, Tropsha","https://doi.org/10.1021/tx900326k","20100325","PubMed","Animals; Chemical and Drug Induced Liver Injury; Cluster Analysis; Databases, Factual; Humans; MEDLINE; Mice; Models, Chemical; Molecular Conformation; Quantitative Structure-Activity Relationship","Drug-induced liver injury is one of the main causes of drug attrition. The ability to predict the liver effects of drug candidates from their chemical structures is critical to help guide experimental drug discovery projects toward safer medicines. In this study, we have compiled a data set of 951 compounds reported to produce a wide range of effects in the liver in different species, comprising humans, rodents, and nonrodents. The liver effects for this data set were obtained as assertional metadata, generated from MEDLINE abstracts using a unique combination of lexical and linguistic methods and ontological rules. We have analyzed this data set using conventional cheminformatics approaches and addressed several questions pertaining to cross-species concordance of liver effects, chemical determinants of liver effects in humans, and the prediction of whether a given compound is likely to cause a liver effect in humans. We found that the concordance of liver effects was relatively low (ca. 39-44%) between different species, raising the possibility that species specificity could depend on specific features of chemical structure. Compounds were clustered by their chemical similarity, and similar compounds were examined for the expected similarity of their species-dependent liver effect profiles. In most cases, similar profiles were observed for members of the same cluster, but some compounds appeared as outliers. The outliers were the subject of focused assertion regeneration from MEDLINE as well as other data sources. In some cases, additional biological assertions were identified, which were in line with expectations based on compounds' chemical similarities. The assertions were further converted to binary annotations of underlying chemicals (i.e., liver effect vs no liver effect), and binary quantitative structure-activity relationship (QSAR) models were generated to predict whether a compound would be expected to produce liver effects in humans. Despite the apparent heterogeneity of data, models have shown good predictive power assessed by external 5-fold cross-validation procedures. The external predictive power of binary QSAR models was further confirmed by their application to compounds that were retrieved or studied after the model was developed. To the best of our knowledge, this is the first study for chemical toxicity prediction that applied QSAR modeling and other cheminformatics techniques to observational data generated by the means of automated text mining with limited manual curation, opening up new opportunities for generating and modeling chemical toxicology data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22253,""
"Multimedia abstract generation of intensive care data: the automation of clinical processes through AI methodologies","Jordan, Rose","https://doi.org/10.1007/s00268-009-0319-5","20100610","PubMed","Artificial Intelligence; Cardiac Surgical Procedures; Critical Care; Decision Making, Computer-Assisted; Hospital Information Systems; Humans; Medical Informatics Applications; Medical Records Systems, Computerized; Monitoring, Physiologic; Multimedia; Surveys and Questionnaires","Medical errors from communication failures are enormous during the perioperative period of cardiac surgical patients. As caregivers change shifts or surgical patients change location within the hospital, key information is lost or misconstrued. After a baseline cognitive study of information need and caregiver workflow, we implemented an advanced clinical decision support tool of intelligent agents, medical logic modules, and text generators called the ""Inference Engine"" to summarize individual patient's raw medical data elements into procedural milestones, illness severity, and care therapies. The system generates two displays: 1) the continuum of care, multimedia abstract generation of intensive care data (MAGIC)-an expert system that would automatically generate a physician briefing of a cardiac patient's operative course in a multimodal format; and 2) the isolated point in time, ""Inference Engine""-a system that provides a real-time, high-level, summarized depiction of a patient's clinical status. In our studies, system accuracy and efficacy was judged against clinician performance in the workplace. To test the automated physician briefing, ""MAGIC,"" the patient's intraoperative course, was reviewed in the intensive care unit before patient arrival. It was then judged against the actual physician briefing and that given in a cohort of patients where the system was not used. To test the real-time representation of the patient's clinical status, system inferences were judged against clinician decisions. Changes in workflow and situational awareness were assessed by questionnaires and process evaluation. MAGIC provides 200% more information, twice the accuracy, and enhances situational awareness. This study demonstrates that the automation of clinical processes through AI methodologies yields positive results.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22254,""
"Unblocking blockbusters: using boolean text-mining to optimise clinical trial design and timeline for novel anticancer drugs","Epstein","https://doi.org/10.4137/cin.s2666","20100303","PubMed","bibliometrics; clinical trials; drug development; medical informatics; oncology","Two problems now threaten the future of anticancer drug development: (i) the information explosion has made research into new target-specific drugs more duplication-prone, and hence less cost-efficient; and (ii) high-throughput genomic technologies have failed to deliver the anticipated early windfall of novel first-in-class drugs. Here it is argued that the resulting crisis of blockbuster drug development may be remedied in part by innovative exploitation of informatic power. Using scenarios relating to oncology, it is shown that rapid data-mining of the scientific literature can refine therapeutic hypotheses and thus reduce empirical reliance on preclinical model development and early-phase clinical trials. Moreover, as personalised medicine evolves, this approach may inform biomarker-guided phase III trial strategies for noncytotoxic (antimetastatic) drugs that prolong patient survival without necessarily inducing tumor shrinkage. Though not replacing conventional gold standards, these findings suggest that this computational research approach could reduce costly 'blue skies' R&amp;D investment and time to market for new biological drugs, thereby helping to reverse unsustainable drug price inflation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22255,""
"Automated vs conventional tractography in multiple sclerosis: variability and correlation with disability","Reich, Ozturk, Calabresi, Mori","https://doi.org/10.1016/j.neuroimage.2009.11.043","20100426","PubMed","Adult; Algorithms; Diffusion Tensor Imaging; Female; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Male; Middle Aged; Movement Disorders; Multiple Sclerosis; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Statistics as Topic","Diffusion-tensor-imaging fiber tractography enables interrogation of brain white matter tracts that subserve different functions. However, tract reconstruction can be labor and time intensive and can yield variable results that may reduce the power to link imaging abnormalities with disability. Automated segmentation of these tracts would help make tract-specific imaging clinically useful, but implementation of such segmentation is problematic in the presence of diseases that alter brain structure. In this work, we investigated an automated tract-probability-mapping scheme and applied it to multiple sclerosis, comparing the results to those derived from conventional tractography. We found that the automated method has consistently lower scan-rescan variability (typically 0.7-1.5% vs. up to 3% for conventional tractography) and avoids problems related to tractography failures within and around lesions. In the corpus callosum, optic radiation, and corticospinal tract, tract-specific MRI indices calculated by the two methods were moderately to strongly correlated, though systematic, tract-specific differences were present. In these tracts, the two methods also yielded similar correlation coefficients relating tract-specific MRI indices to clinical disability scores. In the optic tract, the automated method failed. With judicious application, therefore, the automated method may be useful for studies that investigate the relationship between imaging findings and clinical outcomes in disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22256,""
"Clinical decision analysis: Incorporating the evidence with patient preferences","Aleem, Jalal, Aleem, Sheikh, Bhandari","https://doi.org/10.2147/ppa.s4549","20110714","PubMed","decision analysis; evidence-based medicine; game theory; patient preference","Decision analysis has become an increasingly popular decision-making tool with a multitude of clinical applications. Incorporating patient and expert preferences with available literature, it allows users to apply evidence-based medicine to make informed decisions when confronted with difficult clinical scenarios. A decision tree depicts potential alternatives and outcomes involved with a given decision. Probabilities and utilities are used to quantify the various options and help determine the best course of action. Sensitivity analysis allows users to explore the uncertainty of data on expected clinical outcomes. The decision maker can thereafter establish a preferred method of treatment and explore variables which influence the final clinical outcome. The present paper reviews the technique of decision analysis with particular focus on its application to clinical decision making.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22257,""
"An intelligent listening framework for capturing encounter notes from a doctor-patient dialog","Klann, Szolovits","https://doi.org/10.1186/1472-6947-9-S1-S3","20100922","PubMed","Communication; Electronic Health Records; Humans; Natural Language Processing; Physician-Patient Relations; Programming Languages; Software Design; Speech Recognition Software","Capturing accurate and machine-interpretable primary data from clinical encounters is a challenging task, yet critical to the integrity of the practice of medicine. We explore the intriguing possibility that technology can help accurately capture structured data from the clinical encounter using a combination of automated speech recognition (ASR) systems and tools for extraction of clinical meaning from narrative medical text. Our goal is to produce a displayed evolving encounter note, visible and editable (using speech) during the encounter. This is very ambitious, and so far we have taken only the most preliminary steps. We report a simple proof-of-concept system and the design of the more comprehensive one we are building, discussing both the engineering design and challenges encountered. Without a formal evaluation, we were encouraged by our initial results. The proof-of-concept, despite a few false positives, correctly recognized the proper category of single-and multi-word phrases in uncorrected ASR output. The more comprehensive system captures and transcribes speech and stores alternative phrase interpretations in an XML-based format used by a text-engineering framework. It does not yet use the framework to perform the language processing present in the proof-of-concept. The work here encouraged us that the goal is reachable, so we conclude with proposed next steps.Some challenging steps include acquiring a corpus of doctor-patient conversations, exploring a workable microphone setup, performing user interface research, and developing a multi-speaker version of our tools.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22258,""
"Interactive exploration of neuroanatomical meta-spaces","Joshi, Horn, Toga","https://doi.org/10.3389/neuro.11.038.2009","20130704","PubMed","3D visualization; meta-analysis; neuroanatomical data mining; visual data mining","Large-archives of neuroimaging data present many opportunities for re-analysis and mining that can lead to new findings of use in basic research or in the characterization of clinical syndromes. However, interaction with such archives tends to be driven textually, based on subject or image volume meta-data, not the actual neuroanatomical morphology itself, for which the imaging was performed to measure. What is needed is a content-driven approach for examining not only the image content itself but to explore brains that are anatomically similar, and identifying patterns embedded within entire sets of neuroimaging data. With the aim of visual navigation of large- scale neurodatabases, we introduce the concept of brain meta-spaces. The meta-space encodes pair-wise dissimilarities between all individuals in a population and shows the relationships between brains as a navigable framework for exploration. We employ multidimensional scaling (MDS) to implement meta-space processing for a new coordinate system that distributes all data points (brain surfaces) in a common frame-of-reference, with anatomically similar brain data located near each other. To navigate within this derived meta-space, we have developed a fully interactive 3D visualization environment that allows users to examine hundreds of brains simultaneously, visualize clusters of brains with similar characteristics, zoom in on particular instances, and examine the surface topology of an individual brain's surface in detail. The visualization environment not only displays the dissimilarities between brains, but also renders complete surface representations of individual brain structures, allowing an instant 3D view of the anatomies, as well as their differences. The data processing is implemented in a grid-based setting using the LONI Pipeline workflow environment. Additionally users can specify a range of baseline brain atlas spaces as the underlying scale for comparative analyses. The novelty in our approach lies in the user ability to simultaneously view and interact with many brains at once but doing so in a vast meta-space that encodes (dis) similarity in morphometry. We believe that the concept of brain meta-spaces has important implications for the future of how users interact with large-scale archives of primary neuroimaging data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22259,""
"Reliable intrinsic connectivity networks: test-retest evaluation using ICA and dual regression approach","Zuo, Kelly, Adelstein, Klein, Castellanos, Milham","https://doi.org/10.1016/j.neuroimage.2009.10.080","20100413","PubMed","Brain; Brain Mapping; Female; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Neural Pathways; Principal Component Analysis; Reproducibility of Results; Young Adult","Functional connectivity analyses of resting-state fMRI data are rapidly emerging as highly efficient and powerful tools for in vivo mapping of functional networks in the brain, referred to as intrinsic connectivity networks (ICNs). Despite a burgeoning literature, researchers continue to struggle with the challenge of defining computationally efficient and reliable approaches for identifying and characterizing ICNs. Independent component analysis (ICA) has emerged as a powerful tool for exploring ICNs in both healthy and clinical populations. In particular, temporal concatenation group ICA (TC-GICA) coupled with a back-reconstruction step produces participant-level resting state functional connectivity maps for each group-level component. The present work systematically evaluated the test-retest reliability of TC-GICA derived RSFC measures over the short-term (&lt;45 min) and long-term (5-16 months). Additionally, to investigate the degree to which the components revealed by TC-GICA are detectable via single-session ICA, we investigated the reproducibility of TC-GICA findings. First, we found moderate-to-high short- and long-term test-retest reliability for ICNs derived by combining TC-GICA and dual regression. Exceptions to this finding were limited to physiological- and imaging-related artifacts. Second, our reproducibility analyses revealed notable limitations for template matching procedures to accurately detect TC-GICA based components at the individual scan level. Third, we found that TC-GICA component's reliability and reproducibility ranks are highly consistent. In summary, TC-GICA combined with dual regression is an effective and reliable approach to exploratory analyses of resting state fMRI data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22260,""
"Construction of an annotated corpus to support biomedical information extraction","Thompson, Iqbal, McNaught, Ananiadou","https://doi.org/10.1186/1471-2105-10-349","20100128","PubMed","Computational Biology; Databases, Factual; Information Storage and Retrieval; Natural Language Processing; Vocabulary, Controlled","Information Extraction (IE) is a component of text mining that facilitates knowledge discovery by automatically locating instances of interesting biomedical events from huge document collections. As events are usually centred on verbs and nominalised verbs, understanding the syntactic and semantic behaviour of these words is highly important. Corpora annotated with information concerning this behaviour can constitute a valuable resource in the training of IE components and resources. We have defined a new scheme for annotating sentence-bound gene regulation events, centred on both verbs and nominalised verbs. For each event instance, all participants (arguments) in the same sentence are identified and assigned a semantic role from a rich set of 13 roles tailored to biomedical research articles, together with a biological concept type linked to the Gene Regulation Ontology. To our knowledge, our scheme is unique within the biomedical field in terms of the range of event arguments identified. Using the scheme, we have created the Gene Regulation Event Corpus (GREC), consisting of 240 MEDLINE abstracts, in which events relating to gene regulation and expression have been annotated by biologists. A novel method of evaluating various different facets of the annotation task showed that average inter-annotator agreement rates fall within the range of 66% - 90%. The GREC is a unique resource within the biomedical field, in that it annotates not only core relationships between entities, but also a range of other important details about these relationships, e.g., location, temporal, manner and environmental conditions. As such, it is specifically designed to support bio-specific tool and resource development. It has already been used to acquire semantic frames for inclusion within the BioLexicon (a lexical, terminological resource to aid biomedical text mining). Initial experiments have also shown that the corpus may viably be used to train IE components, such as semantic role labellers. The corpus and annotation guidelines are freely available for academic purposes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22261,""
"Visualizing the drug target landscape","Campbell, Gaulton, Marshall, Bichko, Martin, Brouwer, Harland","https://doi.org/10.1016/j.drudis.2009.09.011","20100427","PubMed","Data Mining; Decision Making, Computer-Assisted; Drug Discovery; Drug Industry; Humans; Information Management","Generating new therapeutic hypotheses for human disease requires the analysis and interpretation of many different experimental datasets. Assembling a holistic picture of the current landscape of drug discovery activity remains a challenge, however, because of the lack of integration between biological, chemical and clinical resources. Although tools designed to tackle the interpretation of individual data types are abundant, systems that bring together multiple elements to directly enable decision making within drug discovery programmes are rare. In this article, we review the path that led to the development of a knowledge system to tackle this problem within our organization and highlight the influences of existing technologies on its development. Central to our approach is the use of visualization to better convey the overall meaning of an integrated set of data including disease association, druggability, competitor intelligence, genomics and text mining. Organizing such data along lines of therapeutic precedence creates clearly distinct 'zones' of pharmaceutical opportunity, ranging from small-molecule repurposing to biotherapeutic prospects and gene family exploitation. Mapping content in this way also provides a visual alerting mechanism that evaluates new evidence in the context of old, reducing information overload by filtering redundant information. In addition, we argue the need for more tools in this space and highlight the role that data standards, new technologies and increased collaboration might have in achieving this aim.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22262,""
"Early over expression of messenger RNA for multiple genes, including insulin, in the Pancreatic Lymph Nodes of NOD mice is associated with Islet Autoimmunity","Regnault, Osorio Y Fortea, Miao, Eisenbarth, Melanitou","https://doi.org/10.1186/1755-8794-2-63","20100115","PubMed","Animals; Autoantibodies; Autoimmunity; Chromosome Mapping; Cluster Analysis; Diabetes Mellitus, Type 1; Female; Gene Expression Profiling; Genome; Immunohistochemistry; Insulin; Islets of Langerhans; Lymph Nodes; Male; Mice; Mice, Inbred NOD; Oligonucleotide Array Sequence Analysis; Pancreas; RNA, Messenger; Reproducibility of Results; Reverse Transcriptase Polymerase Chain Reaction; Time Factors","Autoimmune diabetes (T1D) onset is preceded by a long inflammatory process directed against the insulin-secreting beta cells of the pancreas. Deciphering the early autoimmune mechanisms represents a challenge due to the absence of clinical signs at early disease stages. The aim of this study was to identify genes implicated in the early steps of the autoimmune process, prior to inflammation, in T1D. We have previously established that insulin autoantibodies (E-IAA) predict early diabetes onset delineating an early phenotypic check point (window 1) in disease pathogenesis. We used this sub-phenotype and applied differential gene expression analysis in the pancreatic lymph nodes (PLN) of 5 weeks old Non Obese Diabetic (NOD) mice differing solely upon the presence or absence of E-IAA. Analysis of gene expression profiles has the potential to provide a global understanding of the disease and to generate novel hypothesis concerning the initiation of the autoimmune process. Animals have been screened weekly for the presence of E-IAA between 3 and 5 weeks of age. E-IAA positive or negative NOD mice at least twice were selected and RNAs isolated from the PLN were used for microarray analysis. Comparison of transcriptional profiles between positive and negative animals and functional annotations of the resulting differentially expressed genes, using software together with manual literature data mining, have been performed. The expression of 165 genes was modulated between E-IAA positive and negative PLN. In particular, genes coding for insulin and for proteins known to be implicated in tissue remodelling and Th1 immunity have been found to be highly differentially expressed. Forty one genes showed over 5 fold differences between the two sets of samples and 30 code for extracellular proteins. This class of proteins represents potential diagnostic markers and drug targets for T1D. Our data strongly suggest that the immune related mechanisms taking place at this early age in the PLN, correlate with homeostatic changes influencing tissue integrity of the adjacent pancreatic tissue. Functional analysis of the identified genes suggested that similar mechanisms might be operating during pre-inflammatory processes deployed in tissues i) hosting parasitic microorganisms and ii) experiencing unrestricted invasion by tumour cells.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22263,""
"Automatically classifying sentences in full-text biomedical articles into Introduction, Methods, Results and Discussion","Agarwal, Yu","https://doi.org/10.1093/bioinformatics/btp548","20100215","PubMed","Abstracting and Indexing; Artificial Intelligence; Computational Biology; Databases, Factual; Information Storage and Retrieval; MEDLINE; Natural Language Processing; Vocabulary, Controlled","Biomedical texts can be typically represented by four rhetorical categories: Introduction, Methods, Results and Discussion (IMRAD). Classifying sentences into these categories can benefit many other text-mining tasks. Although many studies have applied different approaches for automatically classifying sentences in MEDLINE abstracts into the IMRAD categories, few have explored the classification of sentences that appear in full-text biomedical articles. We first evaluated whether sentences in full-text biomedical articles could be reliably annotated into the IMRAD format and then explored different approaches for automatically classifying these sentences into the IMRAD categories. Our results show an overall annotation agreement of 82.14% with a Kappa score of 0.756. The best classification system is a multinomial naÃƒÂ¯ve Bayes classifier trained on manually annotated data that achieved 91.95% accuracy and an average F-score of 91.55%, which is significantly higher than baseline systems. A web version of this system is available online at-http://wood.ims.uwm.edu/full_text_classifier/.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22264,""
"Characterizing environmental and phenotypic associations using information theory and electronic health records","Wang, Hripcsak, Friedman","https://doi.org/10.1186/1471-2105-10-S9-S13","20100118","PubMed","Computational Biology; Database Management Systems; Information Storage and Retrieval; Information Theory; Medical Records Systems, Computerized; Natural Language Processing","The availability of up-to-date, executable, evidence-based medical knowledge is essential for many clinical applications, such as pharmacovigilance, but executable knowledge is costly to obtain and update. Automated acquisition of environmental and phenotypic associations in biomedical and clinical documents using text mining has showed some success. The usefulness of the association knowledge is limited, however, due to the fact that the specific relationships between clinical entities remain unknown. In particular, some associations are indirect relations due to interdependencies among the data. In this work, we develop methods using mutual information (MI) and its property, the data processing inequality (DPI), to help characterize associations that were generated based on use of natural language processing to encode clinical information in narrative patient records followed by statistical methods. Evaluation based on a random sample consisting of two drugs and two diseases indicates an overall precision of 81%. This preliminary study demonstrates that the proposed method is effective for helping to characterize phenotypic and environmental associations obtained from clinical reports.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22265,""
"Developing a manually annotated clinical document corpus to identify phenotypic information for inflammatory bowel disease","South, Shen, Jones, Garvin, Samore, Chapman, Gundlapalli","https://doi.org/10.1186/1471-2105-10-S9-S12","20100118","PubMed","Computational Biology; Humans; Inflammatory Bowel Diseases; Phenotype; Vocabulary, Controlled","Natural Language Processing (NLP) systems can be used for specific Information Extraction (IE) tasks such as extracting phenotypic data from the electronic medical record (EMR). These data are useful for translational research and are often found only in free text clinical notes. A key required step for IE is the manual annotation of clinical corpora and the creation of a reference standard for (1) training and validation tasks and (2) to focus and clarify NLP system requirements. These tasks are time consuming, expensive, and require considerable effort on the part of human reviewers. Using a set of clinical documents from the VA EMR for a particular use case of interest we identify specific challenges and present several opportunities for annotation tasks. We demonstrate specific methods using an open source annotation tool, a customized annotation schema, and a corpus of clinical documents for patients known to have a diagnosis of Inflammatory Bowel Disease (IBD). We report clinician annotator agreement at the document, concept, and concept attribute level. We estimate concept yield in terms of annotated concepts within specific note sections and document types. Annotator agreement at the document level for documents that contained concepts of interest for IBD using estimated Kappa statistic (95% CI) was very high at 0.87 (0.82, 0.93). At the concept level, F-measure ranged from 0.61 to 0.83. However, agreement varied greatly at the specific concept attribute level. For this particular use case (IBD), clinical documents producing the highest concept yield per document included GI clinic notes and primary care notes. Within the various types of notes, the highest concept yield was in sections representing patient assessment and history of presenting illness. Ancillary service documents and family history and plan note sections produced the lowest concept yield. Challenges include defining and building appropriate annotation schemas, adequately training clinician annotators, and determining the appropriate level of information to be annotated. Opportunities include narrowing the focus of information extraction to use case specific note types and sections, especially in cases where NLP systems will be used to extract information from large repositories of electronic clinical note documents.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22266,""
"Improved mutation tagging with gene identifiers applied to membrane protein stability prediction","Winnenburg, Plake, Schroeder","https://doi.org/10.1186/1471-2105-10-S8-S3","20091105","PubMed","Algorithms; Amino Acid Substitution; Animals; Computational Biology; Databases, Genetic; Genes; Genomics; Humans; Information Storage and Retrieval; Membrane Proteins; Models, Genetic; Mutation; Pattern Recognition, Automated; Periodicals as Topic; Phenotype; Point Mutation; Protein Stability; PubMed; Sequence Analysis","The automated retrieval and integration of information about protein point mutations in combination with structure, domain and interaction data from literature and databases promises to be a valuable approach to study structure-function relationships in biomedical data sets. We developed a rule- and regular expression-based protein point mutation retrieval pipeline for PubMed abstracts, which shows an F-measure of 87% for the mutation retrieval task on a benchmark dataset. In order to link mutations to their proteins, we utilize a named entity recognition algorithm for the identification of gene names co-occurring in the abstract, and establish links based on sequence checks. Vice versa, we could show that gene recognition improved from 77% to 91% F-measure when considering mutation information given in the text. To demonstrate practical relevance, we utilize mutation information from text to evaluate a novel solvation energy based model for the prediction of stabilizing regions in membrane proteins. For five G protein-coupled receptors we identified 35 relevant single mutations and associated phenotypes, of which none had been annotated in the UniProt or PDB database. In 71% reported phenotypes were in compliance with the model predictions, supporting a relation between mutations and stability issues in membrane proteins. We present a reliable approach for the retrieval of protein mutations from PubMed abstracts for any set of genes or proteins of interest. We further demonstrate how amino acid substitution information from text can be utilized for protein structure stability studies on the basis of a novel energy model.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22267,""
"The neurocircuitry of impaired insight in drug addiction","Goldstein, Craig, Bechara, Garavan, Childress, Paulus, Volkow","https://doi.org/10.1016/j.tics.2009.06.004","20091117","PubMed","Brain Mapping; Cerebral Cortex; Humans; Magnetic Resonance Imaging; Nerve Net; Neural Pathways; Substance-Related Disorders","More than 80% of addicted individuals fail to seek treatment, which might reflect impairments in recognition of severity of disorder. Considered by some as intentional deception, such 'denial' might instead reflect dysfunction of brain networks subserving insight and self-awareness. Here we review the scant literature on insight in addiction and integrate this perspective with the role of: (i) the insula in interoception, self-awareness and drug craving; (ii) the anterior cingulate in behavioral monitoring and response selection (relevant to disadvantageous choices in addiction); (iii) the dorsal striatum in automatic habit formation; and (iv) drug-related stimuli that predict emotional behavior in addicted individuals, even without conscious awareness. We discuss implications for clinical treatment including the design of interventions to improve insight into illness severity in addiction.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22268,""
"Urine proteomics for profiling of human disease using high accuracy mass spectrometry","Kentsis, Monigatti, Dorff, Campagne, Bachur, Steen","https://doi.org/10.1002/prca.200900008","20211020","PubMed","","Knowledge of the biologically relevant components of human tissues has enabled the invention of numerous clinically useful diagnostic tests, as well as non-invasive ways of monitoring disease and its response to treatment. Recent use of advanced MS-based proteomics revealed that the composition of human urine is more complex than anticipated. Here, we extend the current characterization of the human urinary proteome by extensively fractionating urine using ultra-centrifugation, gel electrophoresis, ion exchange and reverse-phase chromatography, effectively reducing mixture complexity while minimizing loss of material. By using high-accuracy mass measurements of the linear ion trap-Orbitrap mass spectrometer and LC-MS/MS of peptides generated from such extensively fractionated specimens, we identified 2362 proteins in routinely collected individual urine specimens, including more than 1000 proteins not described in previous studies. Many of these are biomedically significant molecules, including glomerularly filtered cytokines and shed cell surface molecules, as well as renally and urogenitally produced transporters and structural proteins. Annotation of the identified proteome reveals distinct patterns of enrichment, consistent with previously described specific physiologic mechanisms, including 336 proteins that appear to be expressed by a variety of distal organs and glomerularly filtered from serum. Comparison of the proteomes identified from 12 individual specimens revealed a subset of generally invariant proteins, as well as individually variable ones, suggesting that our approach may be used to study individual differences in age, physiologic state and clinical condition. Consistent with this, annotation of the identified proteome by using machine learning and text mining exposed possible associations with 27 common and more than 500 rare human diseases, establishing a widely useful resource for the study of human pathophysiology and biomarker discovery.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22269,""
"Regional white matter atrophy--based classification of multiple sclerosis in cross-sectional and longitudinal data","Sampat, Berger, Healy, Hildenbrand, Vass, Meier, Chitnis, Weiner, Bakshi, Guttmann","https://doi.org/10.3174/ajnr.A1659","20100104","PubMed","Anatomy, Cross-Sectional; Atrophy; Brain; Female; Humans; Longitudinal Studies; Magnetic Resonance Imaging; Male; Middle Aged; Multiple Sclerosis; Nerve Fibers, Myelinated","The different clinical subtypes of multiple sclerosis (MS) may reflect underlying differences in affected neuroanatomic regions. Our aim was to analyze the effectiveness of jointly using the inferior subolivary medulla oblongata volume (MOV) and the cross-sectional area of the corpus callosum in distinguishing patients with relapsing-remitting multiple sclerosis (RRMS), secondary-progressive multiple sclerosis (SPMS), and primary-progressive multiple sclerosis (PPMS). We analyzed a cross-sectional dataset of 64 patients (30 RRMS, 14 SPMS, 20 PPMS) and a separate longitudinal dataset of 25 patients (114 MR imaging examinations). Twelve patients in the longitudinal dataset had converted from RRMS to SPMS. For all images, the MOV and corpus callosum were delineated manually and the corpus callosum was parcellated into 5 segments. Patients from the cross-sectional dataset were classified as RRMS, SPMS, or PPMS by using a decision tree algorithm with the following input features: brain parenchymal fraction, age, disease duration, MOV, total corpus callosum area and areas of 5 segments of the corpus callosum. To test the robustness of the classification technique, we applied the results derived from the cross-sectional analysis to the longitudinal dataset. MOV and central corpus callosum segment area were the 2 features retained by the decision tree. Patients with MOV &gt;0.94 cm(3) were classified as having RRMS. Patients with progressive MS were further subclassified as having SPMS if the central corpus callosum segment area was &lt;55.12 mm(2), and as having PPMS otherwise. In the cross-sectional dataset, 51/64 (80%) patients were correctly classified. For the longitudinal dataset, 88/114 (77%) patient time points were correctly classified as RRMS or SPMS. Classification techniques revealed differences in affected neuroanatomic regions in subtypes of multiple sclerosis. The combination of central corpus callosum segment area and MOV provides good discrimination among patients with RRMS, SPMS, and PPMS.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22270,""
"Co-authorship network analysis: a powerful tool for strategic planning of research, development and capacity building programs on neglected diseases","Morel, Serruya, Penna, GuimarÃƒÂ£es","https://doi.org/10.1371/journal.pntd.0000501","20091218","PubMed","","New approaches and tools were needed to support the strategic planning, implementation and management of a Program launched by the Brazilian Government to fund research, development and capacity building on neglected tropical diseases with strong focus on the North, Northeast and Center-West regions of the country where these diseases are prevalent. Based on demographic, epidemiological and burden of disease data, seven diseases were selected by the Ministry of Health as targets of the initiative. Publications on these diseases by Brazilian researchers were retrieved from international databases, analyzed and processed with text-mining tools in order to standardize author- and institution's names and addresses. Co-authorship networks based on these publications were assembled, visualized and analyzed with social network analysis software packages. Network visualization and analysis generated new information, allowing better design and strategic planning of the Program, enabling decision makers to characterize network components by area of work, identify institutions as well as authors playing major roles as central hubs or located at critical network cut-points and readily detect authors or institutions participating in large international scientific collaborating networks. Traditional criteria used to monitor and evaluate research proposals or R&amp;D Programs, such as researchers' productivity and impact factor of scientific publications, are of limited value when addressing research areas of low productivity or involving institutions from endemic regions where human resources are limited. Network analysis was found to generate new and valuable information relevant to the strategic planning, implementation and monitoring of the Program. It afforded a more proactive role of the funding agencies in relation to public health and equity goals, to scientific capacity building objectives and a more consistent engagement of institutions and authors from endemic regions based on innovative criteria and parameters anchored on objective scientific data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22271,""
"Kinematic robot-based evaluation scales and clinical counterparts to measure upper limb motor performance in patients with chronic stroke","Bosecker, Dipietro, Volpe, Krebs","https://doi.org/10.1177/1545968309343214","20100304","PubMed","Arm; Biomechanical Phenomena; Chronic Disease; Disability Evaluation; Dyskinesias; Female; Humans; Kinetics; Linear Models; Male; Middle Aged; Motor Activity; Robotics; Stroke; Time Factors; Treatment Outcome","Human-administered clinical scales are the accepted standard for quantifying motor performance of stroke subjects. Although they are widely accepted, these measurement tools are limited by interrater and intrarater reliability and are time-consuming to apply. In contrast, robot-based measures are highly repeatable, have high resolution, and could potentially reduce assessment time. Although robotic and other objective metrics have proliferated in the literature, they are not as well established as clinical scales and their relationship to clinical scales is mostly unknown. To test the performance of linear regression models to estimate clinical scores for the upper extremity from systematic robot-based metrics. Twenty kinematic and kinetic metrics were derived from movement data recorded with the shoulder-and-elbow InMotion2 robot (Interactive Motion Technologies, Inc), a commercial version of the MIT-Manus. Kinematic metrics were aggregated into macro-metrics and micro-metrics and collected from 111 chronic stroke subjects. Multiple linear regression models were developed to calculate Fugl-Meyer Assessment, Motor Status Score, Motor Power, and Modified Ashworth Scale from these robot-based metrics. Best performance-complexity trade-off was achieved by the Motor Status Score model with 8 kinematic macro-metrics (R = .71 for training; R = .72 for validation). Models including kinematic micro-metrics did not achieve significantly higher performance. Performances of the Modified Ashworth Scale models were consistently low (R = .35-.42 for training; R = .08-.17 for validation). The authors identified a set of kinetic and kinematic macro-metrics that may be used for fast outcome evaluations. These metrics represent a first step toward the development of unified, automated measures of therapy outcome.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22272,""
"What can natural language processing do for clinical decision support?","Demner-Fushman, Chapman, McDonald","https://doi.org/10.1016/j.jbi.2009.08.007","20100121","PubMed","Decision Making, Computer-Assisted; Decision Support Systems, Clinical; Humans; Models, Theoretical; Natural Language Processing","Computerized clinical decision support (CDS) aims to aid decision making of health care providers and the public by providing easily accessible health-related information at the point and time it is needed. natural language processing (NLP) is instrumental in using free-text information to drive CDS, representing clinical knowledge and CDS interventions in standardized formats, and leveraging clinical narrative. The early innovative NLP research of clinical narrative was followed by a period of stable research conducted at the major clinical centers and a shift of mainstream interest to biomedical NLP. This review primarily focuses on the recently renewed interest in development of fundamental NLP methods and advances in the NLP systems for CDS. The current solutions to challenges posed by distinct sublanguages, intended user groups, and support goals are discussed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22273,""
"Definition of an automated Content-Based Image Retrieval (CBIR) system for the comparison of dermoscopic images of pigmented skin lesions","Baldi, Murace, Dragonetti, Manganaro, Guerra, Bizzi, Galli","https://doi.org/10.1186/1475-925X-8-18","20091112","PubMed","Algorithms; Artificial Intelligence; Colorimetry; Dermoscopy; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Information Storage and Retrieval; Pattern Recognition, Automated; Pigmentation Disorders; Precancerous Conditions; Radiology Information Systems; Reproducibility of Results; Sensitivity and Specificity; Skin Neoplasms","New generations of image-based diagnostic machines are based on digital technologies for data acquisition; consequently, the diffusion of digital archiving systems for diagnostic exams preservation and cataloguing is rapidly increasing. To overcome the limits of current state of art text-based access methods, we have developed a novel content-based search engine for dermoscopic images to support clinical decision making. To this end, we have enrolled, from 2004 to 2008, 3415 caucasian patients and collected 24804 dermoscopic images corresponding to 20491 pigmented lesions with known pathology. The images were acquired with a well defined dermoscopy system and stored to disk in 24-bit per pixel TIFF format using interactive software developed in C++, in order to create a digital archive. The analysis system of the images consists in the extraction of the low-level representative features which permits the retrieval of similar images in terms of colour and texture from the archive, by using a hierarchical multi-scale computation of the Bhattacharyya distance of all the database images representation with respect to the representation of user submitted (query). The system is able to locate, retrieve and display dermoscopic images similar in appearance to one that is given as a query, using a set of primitive features not related to any specific diagnostic method able to visually characterize the image. Similar search engine could find possible usage in all sectors of diagnostic imaging, or digital signals, which could be supported by the information available in medical archives.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22274,""
"Toward a microscopic model of bidirectional synaptic plasticity","Castellani, Bazzani, Cooper","https://doi.org/10.1073/pnas.0905988106","20091008","PubMed","Algorithms; Animals; Calcium; Hippocampus; Kinetics; Long-Term Potentiation; Long-Term Synaptic Depression; Models, Biological; Models, Neurological; Monte Carlo Method; Neuronal Plasticity; Phosphorylation; Probability; Rats; Receptors, AMPA","We show that a 2-step phospho/dephosphorylation cycle for the alpha-amino-3-hydroxy-5-methyl-4-isoxazole proprionic acid receptor (AMPAR), as used in in vivo learning experiments to assess long-term potentiation (LTP) induction and establishment, exhibits bistability for a wide range of parameters, consistent with values derived from biological literature. The AMPAR model we propose, hence, is a candidate for memory storage and switching behavior at a molecular-microscopic level. Furthermore, the stochastic formulation of the deterministic model leads to a mesoscopic interpretation by considering the effect of enzymatic fluctuations on the Michelis-Menten average dynamics. Under suitable hypotheses, this leads to a stochastic dynamical system with multiplicative noise whose probability density evolves according to a Fokker-Planck equation in the Stratonovich sense. In this approach, the probability density associated with each AMPAR phosphorylation state allows one to compute the probability of any concentration value, whereas the Michaelis-Menten equations consider the average concentration dynamics. We show that bistable dynamics are robust for multiplicative stochastic perturbations and that the presence of both noise and bistability simulates LTP and long-term depression (LTD) behavior. Interestingly, the LTP part of this model has been experimentally verified as a result of in vivo, one-trial inhibitory avoidance learning protocol in rats, that produced the same changes in hippocampal AMPARs phosphorylation state as observed with in vitro induction of LTP with high-frequency stimulation (HFS). A consequence of this model is the possibility of characterizing a molecular switch with a defined biochemical set of reactions showing bistability and bidirectionality. Thus, this 3-enzymes-based biophysical model can predict LTP as well as LTD and their transition rates. The theoretical results can be, in principle, validated by in vitro and in vivo experiments, such as fluorescence measurements and electrophysiological recordings at multiple scales, from molecules to neurons. A further consequence is that the bistable regime occurs only within certain parametric windows, which may simulate a ""history-dependent threshold"". This effect might be related to the Bienenstock-Cooper-Munro theory of synaptic plasticity.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22275,""
"Building disease-specific drug-protein connectivity maps from molecular interaction networks and PubMed abstracts","Li, Zhu, Chen","https://doi.org/10.1371/journal.pcbi.1000450","20091015","PubMed","Algorithms; Alzheimer Disease; Animals; Cluster Analysis; Databases, Protein; Drug Therapy; Genes; Genomics; Humans; Pharmaceutical Preparations; Pharmacology; Proteins; PubMed; ROC Curve; Reproducibility of Results; Sensitivity and Specificity; Systems Biology","The recently proposed concept of molecular connectivity maps enables researchers to integrate experimental measurements of genes, proteins, metabolites, and drug compounds under similar biological conditions. The study of these maps provides opportunities for future toxicogenomics and drug discovery applications. We developed a computational framework to build disease-specific drug-protein connectivity maps. We integrated gene/protein and drug connectivity information based on protein interaction networks and literature mining, without requiring gene expression profile information derived from drug perturbation experiments on disease samples. We described the development and application of this computational framework using Alzheimer's Disease (AD) as a primary example in three steps. First, molecular interaction networks were incorporated to reduce bias and improve relevance of AD seed proteins. Second, PubMed abstracts were used to retrieve enriched drug terms that are indirectly associated with AD through molecular mechanistic studies. Third and lastly, a comprehensive AD connectivity map was created by relating enriched drugs and related proteins in literature. We showed that this molecular connectivity map development approach outperformed both curated drug target databases and conventional information retrieval systems. Our initial explorations of the AD connectivity map yielded a new hypothesis that diltiazem and quinidine may be investigated as candidate drugs for AD treatment. Molecular connectivity maps derived computationally can help study molecular signature differences between different classes of drugs in specific disease contexts. To achieve overall good data coverage and quality, a series of statistical methods have been developed to overcome high levels of data noise in biological networks and literature mining results. Further development of computational molecular connectivity maps to cover major disease areas will likely set up a new model for drug development, in which therapeutic/toxicological profiles of candidate drugs can be checked computationally before costly clinical trials begin.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22276,""
"[Tree decision analysis of the therapeutic alternatives for Panic Disorders in Primary Care]","Navarro-Mateu, Garriga-Puerto, SÃƒÂ¡nchez-SÃƒÂ¡nchez","https://doi.org/10.1016/j.aprim.2009.05.003","20100715","PubMed","Decision Trees; Humans; Panic Disorder; Primary Health Care","To analyse the different therapeutic alternatives for Panic Disorders to make it easier to make collaborative treatment decisions between patients and doctors in a Primary Care setting. Quantitative analysis by a decision tree. Time period reviewed; 1990-2008 in Med-line, Embase, Cochrane-plus Library and Tripdatabase. Terms used ""panic disorder"", ""psychotherapy"" and ""drug therapy"". I) A decision tree was prepared with only one therapeutic option in each arm; II) The same procedure with two sequential therapeutic options; III) Sensitivity analysis to test the robustness of the model. Evidence summary, systematic reviews, meta-analysis and clinical guidelines. Cognitive-Behavioural Therapy (CBT) obtains the highest usefulness (UME=0.58), followed by the Selective serotonin reuptake inhibitors (SSRI) (UME=0.53) and by the tricyclic antidepressants (UME=0.44). CBT followed by SSRI is the therapeutic sequence with the highest usefulness (0.62). The sensitivity analysis suggests the model is not robust enough. The CBT in monotherapy or followed by SSRI in a sequential strategy would be the options with the highest usefulness. The results are not robust enough because they can clearly vary with changes in the most important variables in a reasonable range.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22277,""
"Clinical and research searching on the wild side: exploring the veterinary literature","Alpi, Stringer, Devoe, Stoskopf","https://doi.org/10.3163/1536-5050.97.3.005","20091022","PubMed","Animals; Animals, Wild; Biomedical Research; Information Storage and Retrieval; Veterinary Medicine","Zoological medicine furthers the health and well-being of captive and free-ranging wild animals. Effective information retrieval of the zoological medicine literature demands searching multiple databases, conference proceedings, and organization websites using a wide variety of keywords and controlled vocabulary. Veterinarians, residents, students, and the librarians who serve them must have patience for multiple search iterations to capture the majority of the available knowledge. The complexities of thorough literature searches are more difficult for nondomestic animal clinical cases and research reviews as demonstrated by three search requests involving poisonous snakes, a gorilla, and spiders. Expanding and better disseminating the knowledgebase of zoological medicine will make veterinary searching easier.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22278,""
"Doing time: a qualitative study of long-term incarceration and the impact of mental illness","Yang, Kadouri, RÃƒÂ©vah-LÃƒÂ©vy, Mulvey, Falissard","https://doi.org/10.1016/j.ijlp.2009.06.003","20091211","PubMed","Adaptation, Psychological; Adult; Anxiety Disorders; Attitude; Criminals; Dangerous Behavior; Emotions; France; Humans; Length of Stay; Long-Term Care; Male; Mental Disorders; Middle Aged; Mood Disorders; Natural Language Processing; Prisons; Psychotic Disorders; Recurrence; Social Identification; Suicide; Time Perception","Once convicted, the perpetrator of serious crime embarks upon a new journey: the challenge of adjusting to long-term imprisonment. Prisoners' views of incarceration and the meaning of this experience may affect their later adjustment to life in the community. On the basis of brief narrative responses collected during an epidemiological survey of the psychological health of prisoners in France, this study examined the impact of incarceration on psychological state in a group of 59 inmates serving long sentences. Qualitative content analysis and computer-assisted linguistic analysis (using ALCESTE software) were performed on the textual data of open responses to three standard questions. Using a combination of these two approaches, seven categories of the subjective experience of prisoners in the sample were identified: the Outside World, Others, Punishment, Time, Affects and Impulses, Self-Concept, and Speech. Further qualitative analyses were then performed to compare the responses of Severely Mentally Ill (SMI) subjects and subjects with no psychiatric disorder. These analyses revealed contrasting attitudes towards incarceration. SMI subjects spoke in more hostile and persecutory terms about their experience in prison, attributing suffering to external circumstances, while subjects with no psychiatric disorder evoked similar themes, but with an introspective attitude. The themes evoked by mentally ill individuals in our sample suggest that their reactions to the prison environment arise in part from aspects of their psychiatric symptoms, and this may have relevance to future mental health policy and practices in criminal corrections.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22279,""
"Current trends in initial management of laryngeal cancer: the declining use of open surgery","Silver, Beitler, Shaha, Rinaldo, Ferlito","https://doi.org/10.1007/s00405-009-1028-2","20091027","PubMed","Combined Modality Therapy; Humans; Laryngeal Neoplasms; Laryngectomy; Laryngoscopy; Laser Therapy; Neoadjuvant Therapy; Quality of Life; Robotics; Salvage Therapy; Voice Quality","The role of open surgery for management of laryngeal cancer has been greatly diminished during the past decade. The development of transoral endoscopic laser microsurgery (TLS), improvements in delivery of radiation therapy (RT) and the advent of multimodality protocols, particularly concomitant chemoradiotherapy (CCRT) have supplanted the previously standard techniques of open partial laryngectomy for early cancer and total laryngectomy followed by adjuvant RT for advanced cancer. A review of the recent literature revealed virtually no new reports of conventional conservation surgery as initial treatment for early stage glottic and supraglottic cancer. TLS and RT, with or without laser surgery or CCRT, have become the standard initial treatments for T1, T2 and selected T3 laryngeal cancer. Photodynamic therapy (PDT) may have an emerging role in the treatment of early laryngeal cancer. Anterior commissure involvement presents particular difficulties in application of TLS, although no definitive conclusions have been reached with regard to optimal treatment of these lesions. Results of TLS are equivalent to those obtained by conventional conservation surgery, with considerably less morbidity, less hospital time and better postoperative function. Oncologic results of TLS and RT are equivalent for glottic cancer, but with better voice results for RT in patients who require more extensive cordectomy. The preferred treatment for early supraglottic cancer, particularly for bulkier or T3 lesions is TLS, with or without postoperative RT. The Veterans Administration Study published in 1991 established the fact that the response to neoadjuvant CT predicts the response of a tumor to RT. Patients with advanced tumors that responded either partially or completely to CT were treated with RT, and total laryngectomy was reserved for non-responders. This resulted in the ability to preserve the larynx in a significant number of patients with locally advanced laryngeal cancer, while achieving local control and overall survival results equivalent to those achieved with initial total laryngectomy. Following this report, similar ""organ preservation"" protocols were employed in many centers. By 2003, results of the RTOG 93-11 trial, utilizing CCRT as initial treatment, were published, demonstrating a higher rate of laryngeal preservation with this protocol. Surgery was reserved for treatment failures. This concept changed the paradigm for management of advanced laryngeal cancer, greatly reducing the number of laryngectomies performed. While supracricoid laryngectomy has been employed for selected patients, total laryngectomy is the usual procedure for salvage of failure after non-surgical treatment.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22280,""
"Robotic surgery in ear nose and throat","Parmar, Grant, Loizou","https://doi.org/10.1007/s00405-009-1022-8","20100520","PubMed","Humans; Otolaryngology; Robotics","The arrival of a commercial surgical robotic platform at our institution has raised the question of its application and usefulness within the department of otolaryngology head and neck surgery. In order to answer this question, we sought to perform a qualitative review to examine the evolution of commercial surgical robotics and examine present and future applications of this emerging technology within our specialty. The main objective of this study is to examine the development and application of robotic surgery in otolaryngology, head and neck surgery. The study includes a qualitative systematic review. We have reviewed research papers and studies that specifically relate to the use of robots in otorhinolaryngology. More specifically, we have attempted to review those studies that have significantly added to the development of this field. In summary, we have examined eight animal studies, six cadaveric studies, nine human trials. Robotic surgery in ENT is a safe and feasible option. In certain procedures, it offers significant benefits over conventional surgery. Instrument and robotic arm size, and costs are limiting factors that prevent the use of robots being applied to many additional ENT procedures. We feel the development of new speciality-specific robots will yield a new era in the common use of robotics in ENT.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22281,""
"Annotation and retrieval of clinically relevant images","Demner-Fushman, Antani, Simpson, Thoma","https://doi.org/10.1016/j.ijmedinf.2009.05.003","20100126","PubMed","Artificial Intelligence; Diagnostic Imaging; Humans; Image Interpretation, Computer-Assisted; Information Storage and Retrieval; Pattern Recognition, Automated","Medical images are a significant information source for clinical decision-making. Currently available information retrieval and decision support systems rely primarily on the text of scientific publications to find evidence in support of clinical information needs. The images and illustrations are available only within the full text of a scientific publication and do not directly contribute evidence to such systems. Our first goal is to explore whether image features facilitate finding relevant images that appear in publications. Our second goal is to find promising approaches for providing clinical evidence at the point of service, leveraging information contained in the text and images. We studied two approaches to finding illustrative evidence: a supervised machine-learning approach, in which images are classified as being relevant to an information need or not, and a pipeline information retrieval approach, in which images were retrieved using associated text and then re-ranked using content-based image retrieval (CBIR) techniques. Our information retrieval approach did not benefit from combining textual and image information. However, given sufficient training data for the machine-learning approach, we achieved 56% average precision at 94% recall using textual features, and 27% average precision at 86% recall using image features. Combining these classifiers resulted in improvement up to 81% precision at 96% recall (74% recall at 85% precision, on average) for the requests with over 180 positive training examples. Our supervised machine-learning methods that combine information from image and text are capable of achieving image annotation and retrieval accuracy acceptable for providing clinical evidence, given sufficient training data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22282,""
"Building a semantically annotated corpus of clinical texts","Roberts, Gaizauskas, Hepple, Demetriou, Guo, Roberts, Setzer","https://doi.org/10.1016/j.jbi.2008.12.013","20100121","PubMed","Abstracting and Indexing; Biomedical Research; Guidelines as Topic; Humans; Information Storage and Retrieval; Internet; Medical Records; Models, Statistical; Natural Language Processing; Neoplasms; Semantics; Terminology as Topic; User-Computer Interface","In this paper, we describe the construction of a semantically annotated corpus of clinical texts for use in the development and evaluation of systems for automatically extracting clinically significant information from the textual component of patient records. The paper details the sampling of textual material from a collection of 20,000 cancer patient records, the development of a semantic annotation scheme, the annotation methodology, the distribution of annotations in the final corpus, and the use of the corpus for development of an adaptive information extraction system. The resulting corpus is the most richly semantically annotated resource for clinical text processing built to date, whose value has been demonstrated through its use in developing an effective information extraction system. The detailed presentation of our corpus construction and annotation methodology will be of value to others seeking to build high-quality semantically annotated corpora in biomedical domains.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22283,""
"Integration of prostate cancer clinical data using an ontology","Min, Manion, Goralczyk, Wong, Ross, Beck","https://doi.org/10.1016/j.jbi.2009.05.007","20100125","PubMed","Computational Biology; Database Management Systems; Databases, Factual; Humans; Information Storage and Retrieval; Male; Prostatic Neoplasms; Semantics; Terminology as Topic; User-Computer Interface","It is increasingly important for investigators to efficiently and effectively access, interpret, and analyze the data from diverse biological, literature, and annotation sources in a unified way. The heterogeneity of biomedical data and the lack of metadata are the primary sources of the difficulty for integration, presenting major challenges to effective search and retrieval of the information. As a proof of concept, the Prostate Cancer Ontology (PCO) is created for the development of the Prostate Cancer Information System (PCIS). PCIS is applied to demonstrate how the ontology is utilized to solve the semantic heterogeneity problem from the integration of two prostate cancer related database systems at the Fox Chase Cancer Center. As the results of the integration process, the semantic query language SPARQL is applied to perform the integrated queries across the two database systems based on PCO.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22284,""
"Discerning tumor status from unstructured MRI reports--completeness of information in existing reports and utility of automated natural language processing","Cheng, Zheng, Savova, Erickson","https://doi.org/10.1007/s10278-009-9215-7","20100607","PubMed","Electronic Data Processing; Female; Humans; Information Storage and Retrieval; Magnetic Resonance Imaging; Male; Medical Records Systems, Computerized; Natural Language Processing; Neoplasms; Radiology Information Systems; Reproducibility of Results; Sensitivity and Specificity","Information in electronic medical records is often in an unstructured free-text format. This format presents challenges for expedient data retrieval and may fail to convey important findings. Natural language processing (NLP) is an emerging technique for rapid and efficient clinical data retrieval. While proven in disease detection, the utility of NLP in discerning disease progression from free-text reports is untested. We aimed to (1) assess whether unstructured radiology reports contained sufficient information for tumor status classification; (2) develop an NLP-based data extraction tool to determine tumor status from unstructured reports; and (3) compare NLP and human tumor status classification outcomes. Consecutive follow-up brain tumor magnetic resonance imaging reports (2000--2007) from a tertiary center were manually annotated using consensus guidelines on tumor status. Reports were randomized to NLP training (70%) or testing (30%) groups. The NLP tool utilized a support vector machines model with statistical and rule-based outcomes. Most reports had sufficient information for tumor status classification, although 0.8% did not describe status despite reference to prior examinations. Tumor size was unreported in 68.7% of documents, while 50.3% lacked data on change magnitude when there was detectable progression or regression. Using retrospective human classification as the gold standard, NLP achieved 80.6% sensitivity and 91.6% specificity for tumor status determination (mean positive predictive value, 82.4%; negative predictive value, 92.0%). In conclusion, most reports contained sufficient information for tumor status determination, though variable features were used to describe status. NLP demonstrated good accuracy for tumor status classification and may have novel application for automated disease status classification from electronic databases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22285,""
"Text-based over-representation analysis of microarray gene lists with annotation bias","Leong, Kipling","https://doi.org/10.1093/nar/gkp310","20090722","PubMed","Animals; Computational Biology; Gene Expression Profiling; Genes; Information Storage and Retrieval; Interferons; Oligonucleotide Array Sequence Analysis; PubMed; Software; Vocabulary, Controlled","A major challenge in microarray data analysis is the functional interpretation of gene lists. A common approach to address this is over-representation analysis (ORA), which uses the hypergeometric test (or its variants) to evaluate whether a particular functionally defined group of genes is represented more than expected by chance within a gene list. Existing applications of ORA have been largely limited to pre-defined terminologies such as GO and KEGG. We report our explorations of whether ORA can be applied to a wider mining of free-text. We found that a hitherto underappreciated feature of experimentally derived gene lists is that the constituents have substantially more annotation associated with them, as they have been researched upon for a longer period of time. This bias, a result of patterns of research activity within the biomedical community, is a major problem for classical hypergeometric test-based ORA approaches, which cannot account for such bias. We have therefore developed three approaches to overcome this bias, and demonstrate their usability in a wide range of published datasets covering different species. A comparison with existing tools that use GO terms suggests that mining PubMed abstracts can reveal additional biological insight that may not be possible by mining pre-defined ontologies alone.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22286,""
"The economic impact of S-100B as a pre-head CT screening test on emergency department management of adult patients with mild traumatic brain injury","Ruan, Noyes, Bazarian","https://doi.org/10.1089/neu.2009.0928","20100125","PubMed","Adult; Axons; Biomarkers; Blood Chemical Analysis; Brain; Brain Injuries; Cost-Benefit Analysis; Decision Trees; Diffuse Axonal Injury; Emergency Medical Services; Emergency Service, Hospital; False Negative Reactions; Female; Hospital Costs; Humans; Male; Mass Screening; Nerve Growth Factors; Predictive Value of Tests; S100 Calcium Binding Protein beta Subunit; S100 Proteins; Sensitivity and Specificity; Time Factors; Tomography, X-Ray Computed","Recent research suggests that serum S-100B may serve as a good pre-head computed tomography (CT) screening test because of its high sensitivity for abnormal head CT scans. The potential economic impact of using S-100B in the emergency department setting for management of adult patients with isolated mild traumatic brain injury (mTBI) has not been evaluated despite its clinical implementation in Europe. Using evidence from the literature, we constructed a decision tree to compare the average cost per patient of using S-100B as a pre-head CT screening test to the current practice of ordering CT scans based on patients' presenting symptoms without the aid of S-100B. When compared to scanning 45-77% of isolated mTBI patients based upon their presenting symptoms, using S-100B as a pre-head CT screen does not lower hospital costs ($281 versus $160), primarily due to its low specificity for abnormal head CT scans. Sensitivity analyses showed, however, that S-100B becomes cost-lowering when the proportion of mTBI patients being scanned exceeds 78%, or when final CT scan results require 96 min or more than the wait for blood test results. Generally speaking, if blood test results require less time than imaging, and if head CT scan rates for patients with isolated mTBI are relatively high, using S-100B will lower costs. Recommendations for using S-100B as a screening tool should account for setting-specific characteristics and their consequent economic impacts. Despite its high sensitivity and excellent negative predictive value, serum S-100B has low specificity and low positive predictive value, limiting its ability to reduce numbers of CT scans and hospital costs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22287,""
"MIARS: a medical image retrieval system","Mueen, Zainuddin, Baba","https://doi.org/10.1007/s10916-009-9300-y","20101215","PubMed","Artificial Intelligence; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Information Storage and Retrieval; User-Computer Interface","The next generation of medical information system will integrate multimedia data to assist physicians in clinical decision-making, diagnoses, teaching, and research. This paper describes MIARS (Medical Image Annotation and Retrieval System). MIARS not only provides automatic annotation, but also supports text based as well as image based retrieval strategies, which play important roles in medical training, research, and diagnostics. The system utilizes three trained classifiers, which are trained using training images. The goal of these classifiers is to provide multi-level automatic annotation. Another main purpose of the MIARS system is to study image semantic retrieval strategy by which images can be retrieved according to different levels of annotation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22288,""
"Prediction of malignant breast lesions from MRI features: a comparison of artificial neural network and logistic regression techniques","McLaren, Chen, Nie, Su","https://doi.org/10.1016/j.acra.2009.01.029","20090819","PubMed","Algorithms; Breast Neoplasms; Computer Simulation; Female; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Logistic Models; Magnetic Resonance Imaging; Middle Aged; Models, Biological; Neural Networks, Computer; Pattern Recognition, Automated; Regression Analysis; Reproducibility of Results; Sensitivity and Specificity","Dynamic contrast-enhanced magnetic resonance imaging is a clinical imaging modality for the detection and diagnosis of breast lesions. Analytic methods were compared for diagnostic feature selection and the performance of lesion classification to differentiate between malignant and benign lesions in patients. The study included 43 malignant and 28 benign histologically proved lesions. Eight morphologic parameters, 10 gray-level co-occurrence matrix texture features, and 14 Laws texture features were obtained using automated lesion segmentation and quantitative feature extraction. Artificial neural network (ANN) and logistic regression analysis were compared for the selection of the best predictors of malignant lesions among the normalized features. Using ANN, the final four selected features were compactness, energy, homogeneity, and Law_LS, with an area under the receiver-operating characteristic curve (AUC) of 0.82 and accuracy of 0.76. The diagnostic performance of these four features computed on the basis of logistic regression yielded an AUC of 0.80 (95% confidence interval [CI], 0.688-0.905), similar to that of ANN. The analysis also showed that the odds of a malignant lesion decreased by 48% (95% CI, 25%-92%) for every increase of 1 standard deviation in the Law_LS feature, adjusted for differences in compactness, energy, and homogeneity. Using logistic regression with z-score transformation, a model composed of compactness, normalized radial length entropy, and gray-level sum average was selected, and it had the highest overall accuracy, 0.75, among all models, with an AUC of 0.77 (95% CI, 0.660-0.880). When logistic modeling of transformations using the Box-Cox method was performed, the most parsimonious model with predictors compactness and Law_LS had an AUC of 0.79 (95% CI, 0.672-0.898). The diagnostic performance of models selected by ANN and logistic regression was similar. The analytic methods were found to be roughly equivalent in terms of predictive ability when a small number of variables were chosen. The robust ANN methodology uses a sophisticated nonlinear model, while logistic regression analysis provides insightful information to enhance the interpretation of the model features.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22289,""
"Description of a rule-based system for the i2b2 challenge in natural language processing for clinical data","Childs, Enelow, Simonsen, Heintzelman, Kowalski, Taylor","https://doi.org/10.1197/jamia.M3083","20090903","PubMed","Algorithms; Comorbidity; Expert Systems; Humans; Information Storage and Retrieval; Knowledge Bases; Medical Records Systems, Computerized; Natural Language Processing; Obesity; Pattern Recognition, Automated","The Obesity Challenge, sponsored by Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing, asked participants to build software systems that could ""read"" a patient's clinical discharge summary and replicate the judgments of physicians in evaluating presence or absence of obesity and 15 comorbidities. The authors describe their methodology and discuss the results of applying Lockheed Martin's rule-based natural language processing (NLP) capability, ClinREAD. We tailored ClinREAD with medical domain expertise to create assigned default judgments based on the most probable results as defined in the ground truth. It then used rules to collect evidence similar to the evidence that the human judges likely relied upon, and applied a logic module to weigh the strength of all evidence collected to arrive at final judgments. The Challenge results suggest that rule-based systems guided by human medical expertise are capable of solving complex problems in machine processing of medical text.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22290,""
"Semantic classification of diseases in discharge summaries using a context-aware rule-based classifier","Solt, Tikk, GÃƒÂ¡l, KardkovÃƒÂ¡cs","https://doi.org/10.1197/jamia.M3087","20090903","PubMed","Artificial Intelligence; Classification; Comorbidity; Disease; Humans; Natural Language Processing; Obesity; Patient Discharge; Semantics","OBJECTIVE Automated and disease-specific classification of textual clinical discharge summaries is of great importance in human life science, as it helps physicians to make medical studies by providing statistically relevant data for analysis. This can be further facilitated if, at the labeling of discharge summaries, semantic labels are also extracted from text, such as whether a given disease is present, absent, questionable in a patient, or is unmentioned in the document. The authors present a classification technique that successfully solves the semantic classification task. DESIGN The authors introduce a context-aware rule-based semantic classification technique for use on clinical discharge summaries. The classification is performed in subsequent steps. First, some misleading parts are removed from the text; then the text is partitioned into positive, negative, and uncertain context segments, then a sequence of binary classifiers is applied to assign the appropriate semantic labels. Measurement For evaluation the authors used the documents of the i2b2 Obesity Challenge and adopted its evaluation measures: F(1)-macro and F(1)-micro for measurements. RESULTS On the two subtasks of the Obesity Challenge (textual and intuitive classification) the system performed very well, and achieved a F(1)-macro = 0.80 for the textual and F(1)-macro = 0.67 for the intuitive tasks, and obtained second place at the textual and first place at the intuitive subtasks of the challenge. CONCLUSIONS The authors show in the paper that a simple rule-based classifier can tackle the semantic classification task more successfully than machine learning techniques, if the training data are limited and some semantic labels are very sparse.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22291,""
"Natural language processing framework to assess clinical conditions","Ware, Mullett, Jagannathan","https://doi.org/10.1197/jamia.M3091","20090903","PubMed","Comorbidity; Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Natural Language Processing; Obesity","OBJECTIVE The authors developed a natural language processing (NLP) framework that could be used to extract clinical findings and diagnoses from dictated physician documentation. DESIGN De-identified documentation was made available by i2b2 Bio-informatics research group as a part of their NLP challenge focusing on obesity and its co-morbidities. The authors describe their approach, which used a combination of concept detection, context validation, and the application of a variety of rules to conclude patient diagnoses. RESULTS The framework was successful at correctly identifying diagnoses as judged by NLP challenge organizers when compared with a gold standard of physician annotations. The authors overall kappa values for agreement with the gold standard were 0.92 for explicit textual results and 0.91 for intuited results. The NLP framework compared favorably with those of the other entrants, placing third in textual results and fourth in intuited results in the i2b2 competition. CONCLUSIONS The framework and approach used to detect clinical conditions was reasonably successful at extracting 16 diagnoses related to obesity. The system and methodology merits further development, targeting clinically useful applications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22292,""
"A system for classifying disease comorbidity status from medical discharge summaries using automated hotspot and negated concept detection","Ambert, Cohen","https://doi.org/10.1197/jamia.M3095","20090903","PubMed","Classification; Comorbidity; Disease; Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Natural Language Processing; Obesity; Patient Discharge","OBJECTIVE Free-text clinical reports serve as an important part of patient care management and clinical documentation of patient disease and treatment status. Free-text notes are commonplace in medical practice, but remain an under-used source of information for clinical and epidemiological research, as well as personalized medicine. The authors explore the challenges associated with automatically extracting information from clinical reports using their submission to the Integrating Informatics with Biology and the Bedside (i2b2) 2008 Natural Language Processing Obesity Challenge Task. DESIGN A text mining system for classifying patient comorbidity status, based on the information contained in clinical reports. The approach of the authors incorporates a variety of automated techniques, including hot-spot filtering, negated concept identification, zero-vector filtering, weighting by inverse class-frequency, and error-correcting of output codes with linear support vector machines. MEASUREMENTS Performance was evaluated in terms of the macroaveraged F1 measure. RESULTS The automated system performed well against manual expert rule-based systems, finishing fifth in the Challenge's intuitive task, and 13(th) in the textual task. CONCLUSIONS The system demonstrates that effective comorbidity status classification by an automated system is possible.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22293,""
"A text mining approach to the prediction of disease status from clinical discharge summaries","Yang, Spasic, Keane, Nenadic","https://doi.org/10.1197/jamia.M3096","20090903","PubMed","Comorbidity; Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Natural Language Processing; Obesity; Patient Discharge; Software","OBJECTIVE The authors present a system developed for the Challenge in Natural Language Processing for Clinical Data-the i2b2 obesity challenge, whose aim was to automatically identify the status of obesity and 15 related co-morbidities in patients using their clinical discharge summaries. The challenge consisted of two tasks, textual and intuitive. The textual task was to identify explicit references to the diseases, whereas the intuitive task focused on the prediction of the disease status when the evidence was not explicitly asserted. DESIGN The authors assembled a set of resources to lexically and semantically profile the diseases and their associated symptoms, treatments, etc. These features were explored in a hybrid text mining approach, which combined dictionary look-up, rule-based, and machine-learning methods. MEASUREMENTS The methods were applied on a set of 507 previously unseen discharge summaries, and the predictions were evaluated against a manually prepared gold standard. The overall ranking of the participating teams was primarily based on the macro-averaged F-measure. RESULTS The implemented method achieved the macro-averaged F-measure of 81% for the textual task (which was the highest achieved in the challenge) and 63% for the intuitive task (ranked 7(th) out of 28 teams-the highest was 66%). The micro-averaged F-measure showed an average accuracy of 97% for textual and 96% for intuitive annotations. CONCLUSIONS The performance achieved was in line with the agreement between human annotators, indicating the potential of text mining for accurate and efficient prediction of disease statuses from clinical discharge summaries.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22294,""
"Semi-automated construction of decision rules to predict morbidities from clinical texts","Farkas, Szarvas, Hegedus, AlmÃƒÂ¡si, Vincze, OrmÃƒÂ¡ndi, Busa-Fekete","https://doi.org/10.1197/jamia.M3097","20090903","PubMed","Comorbidity; Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Natural Language Processing; Obesity; Patient Discharge; Statistics as Topic","OBJECTIVE In this study the authors describe the system submitted by the team of University of Szeged to the second i2b2 Challenge in Natural Language Processing for Clinical Data. The challenge focused on the development of automatic systems that analyzed clinical discharge summary texts and addressed the following question: ""Who's obese and what co-morbidities do they (definitely/most likely) have?"". Target diseases included obesity and its 15 most frequent comorbidities exhibited by patients, while the target labels corresponded to expert judgments based on textual evidence and intuition (separately). DESIGN The authors applied statistical methods to preselect the most common and confident terms and evaluated outlier documents by hand to discover infrequent spelling variants. The authors expected a system with dictionaries gathered semi-automatically to have a good performance with moderate development costs (the authors examined just a small proportion of the records manually). MEASUREMENTS Following the standard evaluation method of the second Workshop on challenges in Natural Language Processing for Clinical Data, the authors used both macro- and microaveraged Fbeta=1 measure for evaluation. RESULTS The authors submission achieved a microaverage F(beta=1) score of 97.29% for classification based on textual evidence (macroaverage F(beta=1) = 76.22%) and 96.42% for intuitive judgments (macroaverage F(beta=1) = 67.27%). CONCLUSIONS The results demonstrate the feasibility of the authors approach and show that even very simple systems with a shallow linguistic analysis can achieve remarkable accuracy scores for classifying clinical records on a limited set of concepts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22295,""
"Recognizing obesity and comorbidities in sparse data","Uzuner","https://doi.org/10.1197/jamia.M3115","20090903","PubMed","Comorbidity; Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Natural Language Processing; Obesity; Patient Discharge","In order to survey, facilitate, and evaluate studies of medical language processing on clinical narratives, i2b2 (Informatics for Integrating Biology to the Bedside) organized its second challenge and workshop. This challenge focused on automatically extracting information on obesity and fifteen of its most common comorbidities from patient discharge summaries. For each patient, obesity and any of the comorbidities could be Present, Absent, or Questionable (i.e., possible) in the patient, or Unmentioned in the discharge summary of the patient. i2b2 provided data for, and invited the development of, automated systems that can classify obesity and its comorbidities into these four classes based on individual discharge summaries. This article refers to obesity and comorbidities as diseases. It refers to the categories Present, Absent, Questionable, and Unmentioned as classes. The task of classifying obesity and its comorbidities is called the Obesity Challenge. The data released by i2b2 was annotated for textual judgments reflecting the explicitly reported information on diseases, and intuitive judgments reflecting medical professionals' reading of the information presented in discharge summaries. There were very few examples of some disease classes in the data. The Obesity Challenge paid particular attention to the performance of systems on these less well-represented classes. A total of 30 teams participated in the Obesity Challenge. Each team was allowed to submit two sets of up to three system runs for evaluation, resulting in a total of 136 submissions. The submissions represented a combination of rule-based and machine learning approaches. Evaluation of system runs shows that the best predictions of textual judgments come from systems that filter the potentially noisy portions of the narratives, project dictionaries of disease names onto the remaining text, apply negation extraction, and process the text through rules. Information on disease-related concepts, such as symptoms and medications, and general medical knowledge help systems infer intuitive judgments on the diseases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22296,""
"Bayesian inference of protein-protein interactions from biological literature","Chowdhary, Zhang, Liu","https://doi.org/10.1093/bioinformatics/btp245","20090721","PubMed","Bayes Theorem; Binding Sites; Computational Biology; Databases, Protein; Information Storage and Retrieval; Protein Interaction Mapping; Proteins","Protein-protein interaction (PPI) extraction from published biological articles has attracted much attention because of the importance of protein interactions in biological processes. Despite significant progress, mining PPIs from literatures still rely heavily on time- and resource-consuming manual annotations. In this study, we developed a novel methodology based on Bayesian networks (BNs) for extracting PPI triplets (a PPI triplet consists of two protein names and the corresponding interaction word) from unstructured text. The method achieved an overall accuracy of 87% on a cross-validation test using manually annotated dataset. We also showed, through extracting PPI triplets from a large number of PubMed abstracts, that our method was able to complement human annotations to extract large number of new PPIs from literature. Programs/scripts we developed/used in the study are available at http://stat.fsu.edu/~jinfeng/datasets/Bio-SI-programs-Bayesian-chowdhary-zhang-liu.zip. Supplementary data are available at Bioinformatics online.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22297,""
"Occupational exposure to diesel engine exhaust: a literature review","Pronk, Coble, Stewart","https://doi.org/10.1038/jes.2009.21","20090901","PubMed","Humans; Occupational Exposure; Vehicle Emissions","Diesel exhaust (DE) is classified as a probable human carcinogen. Aims were to describe the major occupational uses of diesel engines and give an overview of personal DE exposure levels and determinants of exposure as reported in the published literature. Measurements representative of personal DE exposure were abstracted from the literature for the following agents: elemental carbon (EC), particulate matter (PM), carbon monoxide (CO), nitrogen oxide (NO), and nitrogen dioxide (NO(2)). Information on determinants of exposure was abstracted. In total, 3528 EC, 4166 PM, 581 CO, 322 NO, and 1404 NO(2) measurements were abstracted. From the 10,001 measurements, 32% represented exposure from on-road vehicles and 68% from off-road vehicles (30% mining, 15% railroad, and 22% others). Highest levels were reported for enclosed underground work sites in which heavy equipment is used: mining, mine maintenance, and construction (EC: 27-658 microg/m(3)). Intermediate exposure levels were generally reported for above-ground (semi-) enclosed areas in which smaller equipment was run: mechanics in a shop, emergency workers in fire stations, distribution workers at a dock, and workers loading/unloading inside a ferry (generally: EC&lt;50 microg/m(3)). Lowest levels were reported for enclosed areas separated from the source, such as drivers and train crew, or outside, such as surface mining, parking attendants, vehicle testers, utility service workers, surface construction and airline ground personnel (EC&lt;25 microg/m(3)). The other agents showed a similar pattern. Determinants of exposure reported for enclosed situations were ventilation and exhaust after treatment devices. Reported DE exposure levels were highest for underground mining and construction, intermediate for working in above-ground (semi-) enclosed areas and lowest for working outside or separated from the source. The presented data can be used as a basis for assessing occupational exposure in population-based epidemiological studies and guide future exposure assessment efforts for industrial hygiene and epidemiological studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22298,""
"Comparison of information content of structured and narrative text data sources on the example of medication intensification","Turchin, Shubina, Breydo, Pendergrass, Einbinder","https://doi.org/10.1197/jamia.M2777","20090804","PubMed","Aged; Analysis of Variance; Antihypertensive Agents; Diabetes Complications; Female; Humans; Hypertension; Male; Medical Records Systems, Computerized; Middle Aged; Multivariate Analysis; Natural Language Processing; Physicians, Family","OBJECTIVE To compare information obtained from narrative and structured electronic sources using anti-hypertensive medication intensification as an example clinical issue of interest. DESIGN A retrospective cohort study of 5,634 hypertensive patients with diabetes from 2000 to 2005. MEASUREMENTS The authors determined the fraction of medication intensification events documented in both narrative and structured data in the electronic medical record. The authors analyzed the relationship between provider characteristics and concordance between intensifications in narrative and structured data. As there is no gold standard data source for medication information, the authors clinically validated medication intensification information by assessing the relationship between documented medication intensification and the patients' blood pressure in univariate and multivariate models. RESULTS Overall, 5,627 (30.9%) of 18,185 medication intensification events were documented in both sources. For a medication intensification event documented in narrative notes the probability of a concordant entry in structured records increased by 11% for each study year (p &lt; 0.0001) and decreased by 19% for each decade of provider age (p = 0.035). In a multivariate model that adjusted for patient demographics and intraphysician correlations, an increase of one medication intensification per month documented in either narrative or structured data were associated with a 5-8 mm Hg monthly decrease in systolic and 1.5-4 mm Hg decrease in diastolic blood pressure (p &lt; 0.0001 for all). CONCLUSION Narrative and structured electronic data sources provide complementary information on anti-hypertensive medication intensification. Clinical validity of information in both sources was demonstrated by correlation with changes in blood pressure.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22299,""
"BioProspecting: novel marker discovery obtained by mining the bibleome","Elkin, Tuttle, Trusko, Brown","https://doi.org/10.1186/1471-2105-10-S2-S9","20090327","PubMed","Computational Biology; Database Management Systems; Databases, Genetic; Genetic Markers; Genome, Human; Humans; Internet; Proteins; Software; Systematized Nomenclature of Medicine; Vocabulary, Controlled","BioProspecting is a novel approach that enabled our team to mine data related to genetic markers from the New England Journal of Medicine (NEJM) utilizing SNOMED CT and the Human Gene Onotology (HUGO). The Biomedical Informatics Research Collaborative was able to link genes and disorders using the Multi-threaded Clinical Vocabulary Server (MCVS) and natural language processing engine, whose output creates an ontology-network using the semantic encodings of the literature that is organized by these two terminologies. We identified relationships between (genes or proteins) and (diseases or drugs) as linked by metabolic functions and identified potentially novel functional relationships between, for example, genes and diseases (e.g. Article #1 ([Gene - IL27] = &gt; {Enzyme - Dipeptidyl Carboxypeptidase 1}) and Article #2 ({Enzyme - Dipeptidyl Carboxypeptidase 1} &lt; = [Disorder - Type II DM]) showing a metabolic link between IL27 and Type II DM). In this manuscript we describe our method for developing the database and its content as well as its potential to assist in the discovery of novel markers and drugs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22300,""
"PhenoGO: an integrated resource for the multiscale mining of clinical and biological data","Sam, MendonÃƒÂ§a, Li, Blake, Friedman, Lussier","https://doi.org/10.1186/1471-2105-10-S2-S8","20090327","PubMed","Animals; Computational Biology; Databases, Genetic; Humans; Information Storage and Retrieval; Mice; Natural Language Processing; Phenotype; Software; Unified Medical Language System","The evolving complexity of genome-scale experiments has increasingly centralized the role of a highly computable, accurate, and comprehensive resource spanning multiple biological scales and viewpoints. To provide a resource to meet this need, we have significantly extended the PhenoGO database with gene-disease specific annotations and included an additional ten species. This a computationally-derived resource is primarily intended to provide phenotypic context (cell type, tissue, organ, and disease) for mining existing associations between gene products and GO terms specified in the Gene Ontology Databases Automated natural language processing (BioMedLEE) and computational ontology (PhenOS) methods were used to derive these relationships from the literature, expanding the database with information from ten additional species to include over 600,000 phenotypic contexts spanning eleven species from five GO annotation databases. A comprehensive evaluation evaluating the mappings (n = 300) found precision (positive predictive value) at 85%, and recall (sensitivity) at 76%. Phenotypes are encoded in general purpose ontologies such as Cell Ontology, the Unified Medical Language System, and in specialized ontologies such as the Mouse Anatomy and the Mammalian Phenotype Ontology. A web portal has also been developed, allowing for advanced filtering and querying of the database as well as download of the entire dataset http://www.phenogo.org.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22301,""
"The diagnostic role of gut feelings in general practice A focus group study of the concept and its determinants","Stolper, van Bokhoven, Houben, Van Royen, van de Wiel, van der Weijden, Jan Dinant","https://doi.org/10.1186/1471-2296-10-17","20090604","PubMed","Adult; Diagnosis; Emotions; Family Practice; Female; Focus Groups; Humans; Male; Middle Aged; Physicians; Practice Patterns, Physicians'; Surveys and Questionnaires","General practitioners sometimes base clinical decisions on gut feelings alone, even though there is little evidence of their diagnostic and prognostic value in daily practice. Research into these aspects and the use of the concept in medical education require a practical and valid description of gut feelings. The goal of our study was therefore to describe the concept of gut feelings in general practice and to identify their main determinants Qualitative research including 4 focus group discussions. A heterogeneous sample of 28 GPs. Text analysis of the focus group discussions, using a grounded theory approach. Gut feelings are familiar to most GPs in the Netherlands and play a substantial role in their everyday routine. The participants distinguished two types of gut feelings, a sense of reassurance and a sense of alarm. In the former case, a GP is sure about prognosis and therapy, although they may not always have a clear diagnosis in mind. A sense of alarm means that a GP has the feeling that something is wrong even though objective arguments are lacking. GPs in the focus groups experienced gut feelings as a compass in situations of uncertainty and the majority of GPs trusted this guide. We identified the main determinants of gut feelings: fitting, alerting and interfering factors, sensation, contextual knowledge, medical education, experience and personality. The role of gut feelings in general practice has become much clearer, but we need more research into the contributions of individual determinants and into the test properties of gut feelings to make the concept suitable for medical education.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22302,""
"Predictive modelling in hormone-refractory prostate cancer (HRPC)","Bellmunt, Carles, Albanell","https://doi.org/10.1007/s12094-009-0318-x","20090618","PubMed","Antineoplastic Agents; Disease Progression; Docetaxel; Drug Resistance, Neoplasm; Humans; Kinetics; Male; Predictive Value of Tests; Prognosis; Prostatic Neoplasms; Randomized Controlled Trials as Topic; Taxoids","Because the evidence is not yet solid enough to strongly recommend whether or not to treat hormone-refractory prostate cancer (HRPC) patients at certain stages of the disease, predictive models might help in decision making. The importance of prognostic models lies in their ability to capture clinically relevant and measurable variables for routine use by clinicians to inform patients, and improve palliation and treatment decisions. Basically this allows for the creation of homogeneous prognostic strata for randomised comparative trials of therapeutic agents. In the last few years different models to predict patient outcome in HRPC have been published in the literature. Recently, based on the phase III randomised trial of docetaxel, a multivariate prognostic model incorporating PSA kinetics has been developed to predict survival at 1, 2 and 5 years in metastatic HRPC men treated with chemotherapy. This novel model includes new independent clinical prognostic factors in addition to PSA-DT such as baseline pain, type of progression at baseline (measurable disease or bone scan compared with PSA only), presence of liver metastases and the number of metastatic disease sites. This nomogram will be a helpful tool to stratify patients for further docetaxel-based trials and could also help us to delineate the potential benefits of chemotherapy at certain points during the natural history of HRPC.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22303,""
"Improving the efficiency of biomarker identification using biological knowledge","Phan, Yin-Goen, Young, Wang","https://www.google.com/search?q=Improving+the+efficiency+of+biomarker+identification+using+biological+knowledge.","20090312","PubMed","Biomarkers; Biomarkers, Tumor; Biometry; Databases, Genetic; Genetic Markers; Humans; Kidney Neoplasms; Knowledge Bases; Neoplasms; Oligonucleotide Array Sequence Analysis; Reverse Transcriptase Polymerase Chain Reaction","Identifying and validating biomarkers from high-throughput gene expression data is important for understanding and treating cancer. Typically, we identify candidate biomarkers as features that are differentially expressed between two or more classes of samples. Many feature selection metrics rely on ranking by some measure of differential expression. However, interpreting these results is difficult due to the large variety of existing algorithms and metrics, each of which may produce different results. Consequently, a feature ranking metric may work well on some datasets but perform considerably worse on others. We propose a method to choose an optimal feature ranking metric on an individual dataset basis. A metric is optimal if, for a particular dataset, it favorably ranks features that are known to be relevant biomarkers. Extensive knowledge of biomarker candidates is available in public databases and literature. Using this knowledge, we can choose a ranking metric that produces the most biologically meaningful results. In this paper, we first describe a framework for assessing the ability of a ranking metric to detect known relevant biomarkers. We then apply this method to clinical renal cancer microarray data to choose an optimal metric and identify several candidate biomarkers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22304,""
"SciMiner: web-based literature mining tool for target identification and functional enrichment analysis","Hur, Schuyler, States, Feldman","https://doi.org/10.1093/bioinformatics/btp049","20090508","PubMed","Computational Biology; Genes; Information Storage and Retrieval; Internet; MEDLINE; Proteins; PubMed; Publications; Software; United States","SciMiner is a web-based literature mining and functional analysis tool that identifies genes and proteins using a context specific analysis of MEDLINE abstracts and full texts. SciMiner accepts a free text query (PubMed Entrez search) or a list of PubMed identifiers as input. SciMiner uses both regular expression patterns and dictionaries of gene symbols and names compiled from multiple sources. Ambiguous acronyms are resolved by a scoring scheme based on the co-occurrence of acronyms and corresponding description terms, which incorporates optional user-defined filters. Functional enrichment analyses are used to identify highly relevant targets (genes and proteins), GO (Gene Ontology) terms, MeSH (Medical Subject Headings) terms, pathways and protein-protein interaction networks by comparing identified targets from one search result with those from other searches or to the full HGNC [HUGO (Human Genome Organization) Gene Nomenclature Committee] gene set. The performance of gene/protein name identification was evaluated using the BioCreAtIvE (Critical Assessment of Information Extraction systems in Biology) version 2 (Year 2006) Gene Normalization Task as a gold standard. SciMiner achieved 87.1% recall, 71.3% precision and 75.8% F-measure. SciMiner's literature mining performance coupled with functional enrichment analyses provides an efficient platform for retrieval and summary of rich biological information from corpora of users' interests. http://jdrf.neurology.med.umich.edu/SciMiner/. A server version of the SciMiner is also available for download and enables users to utilize their institution's journal subscriptions. Supplementary data are available at Bioinformatics online.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22305,""
"Arrowsmith two-node search interface: a tutorial on finding meaningful links between two disparate sets of articles in MEDLINE","Smalheiser, Torvik, Zhou","https://doi.org/10.1016/j.cmpb.2008.12.006","20090813","PubMed","Abstracting and Indexing; Algorithms; Information Storage and Retrieval; Internet; MEDLINE; Natural Language Processing; Pattern Recognition, Automated; PubMed; Software; User-Computer Interface","The Arrowsmith two-node search is a strategy that is designed to assist biomedical investigators in formulating and assessing scientific hypotheses. More generally, it allows users to identify biologically meaningful links between any two sets of articles A and C in PubMed, even when these share no articles or authors in common and represent disparate topics or disciplines. The key idea is to relate the two sets of articles via title words and phrases (B-terms) that they share. We have created a free, public web-based version of the two-node search tool (http://arrowsmith.psych.uic.edu), have described its development and implementation, and have presented analyses of individual two-node searches. In this paper, we provide an updated tutorial intended for end-users, that covers the use of the tool for a variety of potential scientific use case scenarios. For example, one can assess a recent experimental, clinical or epidemiologic finding that connects two disparate fields of inquiry--identifying likely mechanisms to explain the finding, and choosing promising follow-up lines of investigation. Alternatively, one can assess whether the existing scientific literature lends indirect support to a hypothesis posed by the user that has not yet been investigated. One can also employ two-node searches to search for novel hypotheses. Arrowsmith provides a service that cannot be carried out feasibly via standard PubMed searches or by other available text mining tools.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22306,""
"Extracranial radiosurgery--applications in the management of benign intradural spinal neoplasms","Saraceni, Ashman, Harrop","https://doi.org/10.1007/s10143-008-0183-z","20090729","PubMed","Dose-Response Relationship, Radiation; Dura Mater; Humans; Radiation Tolerance; Radiosurgery; Robotics; Spinal Cord; Spinal Cord Neoplasms","Stereotactic radiosurgery has enabled the delivery of higher doses of radiation and decreased fractionation due to improved accuracy. Spinal radiosurgery has been increasingly utilized for the management of metastatic extradural spinal disease. However, surgical resection remains the primary treatment strategy for intradural spinal tumors. Preliminary evidence suggests that radiosurgical ablation with stereotactic radiation for intradural spinal lesions may be efficacious in certain clinical scenarios. Local tumor control, pain relief, and improvement in neurologic function with minimal morbidity have been reported in short-term follow-up. However, long-term efficacy of radiosurgery in the management of intradural spinal neoplasms necessitates further validation. As extracranial radiosurgery is a newly evolving modality, a continuative review of the current literature is appropriate. Until a standardized therapeutic window of safety and efficacy can be determined, the recommendation of radiosurgical applications for benign spinal tumors should be reserved for carefully selected cases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22307,""
"PathMiner: a Web-based tool for computer-assisted diagnostics in pathology","Yang, Tuzel, Chen, Meer, Salaru, Goodell, Foran","https://doi.org/10.1109/TITB.2008.2008801","20090908","PubMed","Algorithms; Artificial Intelligence; Blood Cells; Computer Communication Networks; Diagnosis, Computer-Assisted; Humans; Image Interpretation, Computer-Assisted; Information Storage and Retrieval; Internet; Models, Statistical; Reproducibility of Results; User-Computer Interface","Large-scale, multisite collaboration has become indispensable for a wide range of research and clinical activities that rely on the capacity of individuals to dynamically acquire, share, and assess images and correlated data. In this paper, we report the development of a Web-based system, PathMiner , for interactive telemedicine, intelligent archiving, and automated decision support in pathology. The PathMiner system supports network-based submission of queries and can automatically locate and retrieve digitized pathology specimens along with correlated molecular studies of cases from ""ground-truth"" databases that exhibit spectral and spatial profiles consistent with a given query image. The statistically most probable diagnosis is provided to the individual who is seeking decision support. To test the system under real-case scenarios, a pipeline infrastructure was developed and a network-based test laboratory was established at strategic sites at the University of Medicine and Dentistry of New Jersey-Robert Wood Johnson Medical School, Robert Wood Johnson University Hospital, the University of Pennsylvania School of Medicine, Hospital of the University of Pennsylvania, The Cancer Institute of New Jersey, and Rutgers University. The average five-class classification accuracy of the system was 93.18% based on a tenfold cross validation on a close dataset containing 3691 imaged specimens. We also conducted prospective performance studies with the PathMiner system in real applications in which the specimens exhibited large variations in staining characters compared with the training data. The average five-class classification accuracy in this open-set experiment was 87.22%. We also provide the comparative results with the previous literature and the PathMiner system shows superior performance.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22308,""
"Problem-centric organization and visualization of patient imaging and clinical data","Bashyam, Hsu, Watt, Bui, Kangarloo, Taira","https://doi.org/10.1148/rg.292085098","20090529","PubMed","Algorithms; Computer Graphics; Database Management Systems; Image Enhancement; Image Interpretation, Computer-Assisted; Information Storage and Retrieval; Radiology Information Systems; Reproducibility of Results; Sensitivity and Specificity; Software; United States; User-Computer Interface","A patient's electronic medical record contains a large amount of unstructured textual information. As patient records become increasingly dense owing to an aging population and increased occurrence of chronic diseases, a tool is needed to help organize and navigate patient data in a way that facilitates a clinician's ability to understand this information and that improves efficiency. A system has been developed for physicians that summarizes clinical information from a patient record. This system provides a gestalt view of the patient's record by organizing information about each disease along four dimensions (axes): time (eg, disease progression over time), space (eg, tumor in left frontal lobe), existence (eg, certainty of existence of a finding), and causality (eg, response to treatment). A display is generated from information provided by radiology reports and discharge summaries. Natural language processing is used to identify clinical abnormalities (problems, symptoms, findings) from these reports as well as associated properties and relationships. This information is presented in an integrated format that organizes extracted findings into a problem list, depicts the information on a timeline grid, and provides direct access to relevant reports and images. The goal of this system is to improve the structure of clinical information and its presentation to the physician, thereby simplifying the information retrieval and knowledge discovery necessary to bridge the gap between acquiring raw data and making an informed diagnosis.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22309,""
"Functional outcomes and health-related quality of life after robot-assisted anterior cruciate ligament reconstruction with patellar tendon grafts","Stengel, KlufmÃƒÂ¶ller, Rademacher, Mutze, Bauwens, ButenschÃƒÂ¶n, Seifert, Wich, Ekkernkamp","https://doi.org/10.1007/s00167-008-0700-1","20090731","PubMed","Adult; Anterior Cruciate Ligament; Arthroscopy; Bone-Patellar Tendon-Bone Grafting; Female; Follow-Up Studies; Humans; Joint Instability; Knee Joint; Male; Patellar Ligament; Patient Satisfaction; Postoperative Complications; Quality of Life; Reconstructive Surgical Procedures; Recovery of Function; Robotics; Treatment Outcome","During a short period of time, surgical robots had been propagated for automated tunnel placement in anterior cruciate ligament (ACL) reconstruction. Clinical outcome data are currently unavailable. Between 2000 and 2003, 152 patients underwent ACL replacement with the assistance of the Computer Assisted Surgical Planning and Robotics system (CASPAR, OrtoMaquet, Germany) at our hospital. After minimal invasive pin placement in both the tibia and femur, computed tomography was used to register anatomical landmarks and to plan graft tunnel alignment. The robot was used to drill tibial and femoral tunnels in an outside-in fashion according to pre-operative planning. There was one procedure-specific Serious Adverse Event (i.e., an intraoperative transection of the posterior cruciate ligament). After IRB approval, all patients were invited for a follow-up examination. Data from 100 patients (35 women, 65 men, mean age 35 [SD 11] years, median follow-up 61 [range 42-77] months) form the basis of this report. Side-to-side differences in anterior laxity were measured with the KT-1000 arthrometer. Patient-centered outcomes included the Lysholm-Score, the lower extremity functional scale (LEFS), and the Short Form 36 (SF36). The mean KT-1000 side-to-side difference was 0.89 [95% confidence interval (CI) 0.52-1.26] mm. Eight and five patients had a positive Lachman and pivot shift test, respectively. The Lysholm-Score averaged 86 (95% CI 83-89) points. Excellent, good, fair, and poor outcomes were reported by 38, 32, 20, and 10 patients. The LEFS averaged 85 (95% CI 82-88) points. The mean SF36 Physical Component Score was 48.4 (95% CI 46.5-50.3), indicating residual deficits compared to the population norm. All tibial graft tunnels did not cross the Blumensaat line, but were placed slightly anterior to the optimal center of 42% reported in previous studies. Compared to literature data, robot-assisted ACL reconstruction with BTB grafts may lead to higher knee stability, but poorer functional outcomes. The immense additional efforts with the procedure did not pay off in a benefit to patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22310,""
"The value of haptic feedback in conventional and robot-assisted minimal invasive surgery and virtual reality training: a current review","van der Meijden, Schijven","https://doi.org/10.1007/s00464-008-0298-x","20090818","PubMed","Clinical Competence; Education, Medical, Continuing; Humans; Minimally Invasive Surgical Procedures; Psychomotor Performance; Robotics; User-Computer Interface","Virtual reality (VR) as surgical training tool has become a state-of-the-art technique in training and teaching skills for minimally invasive surgery (MIS). Although intuitively appealing, the true benefits of haptic (VR training) platforms are unknown. Many questions about haptic feedback in the different areas of surgical skills (training) need to be answered before adding costly haptic feedback in VR simulation for MIS training. This study was designed to review the current status and value of haptic feedback in conventional and robot-assisted MIS and training by using virtual reality simulation. A systematic review of the literature was undertaken using PubMed and MEDLINE. The following search terms were used: Haptic feedback OR Haptics OR Force feedback AND/OR Minimal Invasive Surgery AND/OR Minimal Access Surgery AND/OR Robotics AND/OR Robotic Surgery AND/OR Endoscopic Surgery AND/OR Virtual Reality AND/OR Simulation OR Surgical Training/Education. The results were assessed according to level of evidence as reflected by the Oxford Centre of Evidence-based Medicine Levels of Evidence. In the current literature, no firm consensus exists on the importance of haptic feedback in performing minimally invasive surgery. Although the majority of the results show positive assessment of the benefits of force feedback, results are ambivalent and not unanimous on the subject. Benefits are least disputed when related to surgery using robotics, because there is no haptic feedback in currently used robotics. The addition of haptics is believed to reduce surgical errors resulting from a lack of it, especially in knot tying. Little research has been performed in the area of robot-assisted endoscopic surgical training, but results seem promising. Concerning VR training, results indicate that haptic feedback is important during the early phase of psychomotor skill acquisition.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22311,""
"Information Extraction for Clinical Data Mining: A Mammography Case Study","Nassif, Woods, Burnside, Ayvaci, Shavlik, Page","https://doi.org/10.1109/icdmw.2009.63","20211021","PubMed","BI-RADS; clinical data mining; free text; lexicon; mammography","Breast cancer is the leading cause of cancer mortality in women between the ages of 15 and 54. During mammography screening, radiologists use a strict lexicon (BI-RADS) to describe and report their findings. Mammography records are then stored in a well-defined database format (NMD). Lately, researchers have applied data mining and machine learning techniques to these databases. They successfully built breast cancer classifiers that can help in early detection of malignancy. However, the validity of these models depends on the quality of the underlying databases. Unfortunately, most databases suffer from inconsistencies, missing data, inter-observer variability and inappropriate term usage. In addition, many databases are not compliant with the NMD format and/or solely consist of text reports. BI-RADS feature extraction from free text and consistency checks between recorded predictive variables and text reports are crucial to addressing this problem. We describe a general scheme for concept information retrieval from free text given a lexicon, and present a BI-RADS features extraction algorithm for clinical data mining. It consists of a syntax analyzer, a concept finder and a negation detector. The syntax analyzer preprocesses the input into individual sentences. The concept finder uses a semantic grammar based on the BI-RADS lexicon and the experts' input. It parses sentences detecting BI-RADS concepts. Once a concept is located, a lexical scanner checks for negation. Our method can handle multiple latent concepts within the text, filtering out ultrasound concepts. On our dataset, our algorithm achieves 97.7% precision, 95.5% recall and an <i>F</i><sub>1</sub>-score of 0.97. It outperforms manual feature extraction at the 5% statistical significance level.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22312,""
"Using the weighted keyword model to improve information retrieval for answering biomedical questions","Yu, Cao","https://www.google.com/search?q=Using+the+weighted+keyword+model+to+improve+information+retrieval+for+answering+biomedical+questions.","20110714","PubMed","","Physicians ask many complex questions during the patient encounter. Information retrieval systems that can provide immediate and relevant answers to these questions can be invaluable aids to the practice of evidence-based medicine. In this study, we first automatically identify topic keywords from ad hoc clinical questions with a Condition Random Field model that is trained over thousands of manually annotated clinical questions. We then report on a linear model that assigns query weights based on their automatically identified semantic roles: topic keywords, domain specific terms, and their synonyms. Our evaluation shows that this weighted keyword model improves information retrieval from the Text Retrieval Conference Genomics track data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22313,""
"Unsupervised method for extracting machine understandable medical knowledge from a large free text collection","Xu, Das, Garber","https://www.google.com/search?q=Unsupervised+method+for+extracting+machine+understandable+medical+knowledge+from+a+large+free+text+collection.","20110411","PubMed","Abstracting and Indexing; Algorithms; Information Storage and Retrieval; Natural Language Processing; Pattern Recognition, Automated; Randomized Controlled Trials as Topic","Definitions of medical concepts (e.g diseases, drugs) are essential background knowledge for researchers, clinicians and health care consumers. However, the rapid growth of biomedical research requires that such knowledge continually needs updating. To address this problem, we have developed an unsupervised pattern learning approach that extracts disease and drug definitions from automatically structured randomized clinical trial (RCT) abstracts. In addition, each extracted definition is semantically classified without relying on external medical knowledge. When used to identify definitions from 100 manually annotated RCT abstracts, our medical definition knowledge base has precision of 0.97, recall of 0.93, F1 of 0.94 and semantic classification accuracy of 0.96.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22314,""
"Mayo clinic smoking status classification system: extensions and improvements","Sohn, Savova","https://www.google.com/search?q=Mayo+clinic+smoking+status+classification+system:+extensions+and+improvements.","20110411","PubMed","Classification; Humans; Natural Language Processing; Smoking","This paper describes improvements of and extensions to the Mayo Clinic 2006 smoking status classification system. The new system aims at addressing some of the limitations of the previous one. The performance improvements were mainly achieved through remodeling the negation detection for non-smoker, temporal resolution to distinguish a past and current smoker, and improved detection of the smoking status category of unknown. In addition, we introduced a rule-based component for patient-level smoking status assignments in which the individual smoking statuses of all clinical documents for a given patient are aggregated and analyzed to produce the final patient smoking status. The enhanced system builds upon components from Mayo's clinical Text Analysis and Knowledge Extraction System developed within IBM's Unstructured Information Management Architecture framework. This reusability minimized the development effort. The extended system is in use to identify smoking status risk factors for a peripheral artery disease NHGRI study.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22315,""
"Towards temporal relation discovery from the clinical narrative","Savova, Bethard, Styler, Martin, Palmer, Masanz, Ward","https://www.google.com/search?q=Towards+temporal+relation+discovery+from+the+clinical+narrative.","20110411","PubMed","Disease Progression; Humans; Methods; Narration; Natural Language Processing; Semantics; Time","Disease progression and understanding relies on temporal concepts. Discovery of automated temporal relations and timelines from the clinical narrative allows for mining large data sets of clinical text to uncover patterns at the disease and patient level. Our overall goal is the complex task of building a system for automated temporal relation discovery. As a first step, we evaluate enabling methods from the general natural language processing domain - deep parsing and semantic role labeling in predicate-argument structures - to explore their portability to the clinical domain. As a second step, we develop an annotation schema for temporal relations based on TimeML. In this paper we report results and findings from these first steps. Our next efforts will scale up the data collection to develop domain-specific modules for the enabling technologies within Mayo's open-source clinical Text Analysis and Knowledge Extraction System.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22316,""
"Using a pipeline to improve de-identification performance","Morrison, Sengupta, Hripcsak","https://www.google.com/search?q=Using+a+pipeline+to+improve+de-identification+performance.","20110411","PubMed","Confidentiality; Electronic Health Records; Humans; Methods; Natural Language Processing","Effective de-identification methods are needed to support reuse of electronic health record data for research and other purposes. We investigated using two different text-processing systems in tandem as a strategy for de-identification of clinical notes. We ran 100 outpatient notes through deid.pl, from MIT's PhysioToolkit, followed by MedLEE, and we manually compared the output with original notes to determine the amount of protected health information (PHI) retained. Pipelining resulted in an overall error rate of 2%, with 2 personal names retained in output: one initial and a commonly used English term used in medicine. All retained PHI was transformed into standardized medical concepts, making re-identification less likely. Pipelining using deid.pl improved performance of MedLEE in excluding PHI from output and may be a useful strategy for de-identifying clinical data while providing computer-readable output.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22317,""
"Inductive creation of an annotation schema and a reference standard for de-identification of VA electronic clinical notes","Mayer, Shen, South, Meystre, Friedlin, Ray, Samore","https://www.google.com/search?q=Inductive+creation+of+an+annotation+schema+and+a+reference+standard+for+de-identification+of+VA+electronic+clinical+notes.","20110411","PubMed","Confidentiality; Health Insurance Portability and Accountability Act; Hospitals, Veterans; Humans; Medical Records Systems, Computerized; Natural Language Processing; United States","Accessing both structured and unstructured clinical data is a high priority for research efforts. However, HIPAA requires that data meet or exceed a deidentification standard to assure that protected health information (PHI) is removed. This is a particularly difficult problem in the case of unstructured clinical free text and natural language processing (NLP) systems can be trained to automatically de-identify clinical text. Moreover, manual human annotation of clinical note documents for the purpose of building reference standards to evaluate NLP systems is a costly and time consuming process. Annotation schema must be created that can be used to build reliable and valid reference standards to evaluate NLP systems for the deidentification task. We describe the inductive creation of an annotation schema and subsequent reference standard. We also provide estimates of the accuracy of human annotators for this particular task.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22318,""
"Using a statistical natural language Parser augmented with the UMLS specialist lexicon to assign SNOMED CT codes to anatomic sites and pathologic diagnoses in full text pathology reports","Lowe, Huang, Regula","https://www.google.com/search?q=Using+a+statistical+natural+language+Parser+augmented+with+the+UMLS+specialist+lexicon+to+assign+SNOMED+CT+codes+to+anatomic+sites+and+pathologic+diagnoses+in+full+text+pathology+reports.","20110411","PubMed","Clinical Coding; Electronic Health Records; Humans; Natural Language Processing; Pathology, Surgical; Systematized Nomenclature of Medicine; Unified Medical Language System","To address the problem of extracting structured information from pathology reports for research purposes in the STRIDE Clinical Data Warehouse, we adapted the ChartIndex Medical Language Processing system to automatically identify and map anatomic and diagnostic noun phrases found in full-text pathology reports to SNOMED CT concept descriptors. An evaluation of the system's performance showed a positive predictive value for anatomic concepts of 92.3% and positive predictive value for diagnostic concepts of 84.4%. The experiment also suggested strategies for improving ChartIndex's performance coding pathology reports.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22319,""
"Methodology to develop and evaluate a semantic representation for NLP","Irwin, Harkema, Christensen, Schleyer, Haug, Chapman","https://www.google.com/search?q=Methodology+to+develop+and+evaluate+a+semantic+representation+for+NLP.","20110411","PubMed","Dental Records; Electronic Health Records; Evaluation Studies as Topic; Humans; Natural Language Processing; Semantics","Natural language processing applications that extract information from text rely on semantic representations. The objective of this paper is to describe a methodology for creating a semantic representation for information that will be automatically extracted from textual clinical records. We illustrate two of the four steps of the methodology in this paper using the case study of encoding information from dictated dental exams: (1) develop an initial representation from a set of training documents and (2) iteratively evaluate and evolve the representation while developing annotation guidelines. Our approach for developing and evaluating a semantic representation is based on standard principles and approaches that are not dependent on any particular domain or type of semantic representation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22320,""
"Automating quality measurement: a system for scalable, comprehensive, and routine care quality assessment","Hazlehurst, McBurnie, Mularski, Puro, Chauvie","https://www.google.com/search?q=Automating+quality+measurement:+a+system+for+scalable,+comprehensive,+and+routine+care+quality+assessment.","20110411","PubMed","Ambulatory Care; Asthma; Electronic Data Processing; Electronic Health Records; Humans; Medical Records Systems, Computerized; Quality Assurance, Health Care; United States","Electronic medical records (EMRs) hold the promise of making routine comprehensive measurement of care quality a reality. However, there are many informatics challenges that stand in the way of this goal. Guidelines are rarely stated in precise enough language for automated measurement of clinical practices and the data necessary for that measurement often reside in the text notes of EMRs. We designed a technology platform for scalable and routine measurement of care quality using comprehensive EMR data, including providers' freetext notes documenting clinical encounters. We are in the process of implementing this system to assess the quality of ambulatory asthma care in two diverse healthcare systems: a mid-size HMO and a consortium of Federally Qualified Healthcare Center (FQHC) clinics on the west coast of the United States.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22321,""
"Tailoring vocabularies for NLP in sub-domains: a method to detect unused word sense","Figueroa, Zeng-Treitler, Goryachev, Wiechmann","https://www.google.com/search?q=Tailoring+vocabularies+for+NLP+in+sub-domains:+a+method+to+detect+unused+word+sense.","20110411","PubMed","Area Under Curve; Artificial Intelligence; Natural Language Processing; ROC Curve; Semantics; Unified Medical Language System; Vocabulary, Controlled","We developed a method to help tailor a comprehensive vocabulary system (e.g. the UMLS) for a sub-domain (e.g. clinical reports) in support of natural language processing (NLP). The method detects unused sense in a sub-domain by comparing the relational neighborhood of a word/term in the vocabulary with the semantic neighborhood of the word/term in the sub-domain. The semantic neighborhood of the word/term in the sub-domain is determined using latent semantic analysis (LSA). We trained and tested the unused sense detection on two clinical text corpora: one contains discharge summaries and the other outpatient visit notes. We were able to detect unused senses with precision from 79% to 87%, recall from 48% to 74%, and an area under receiver operation curve (AUC) of 72% to 87%.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22322,""
"Laying the groundwork for enterprise-wide medical language processing services: architecture and process","Chen, Maloney, Shilmayster, Goldberg","https://www.google.com/search?q=Laying+the+groundwork+for+enterprise-wide+medical+language+processing+services:+architecture+and+process.","20110411","PubMed","Data Mining; Electronic Health Records; Natural Language Processing; Software; Vocabulary, Controlled","A systematic and standard process for capturing information within free-text clinical documents could facilitate opportunities for improving quality and safety of patient care, enhancing decision support, and advancing data warehousing across an enterprise setting. At Partners HealthCare System, the Medical Language Processing (MLP) services project was initiated to establish a component-based architectural model and processes to facilitate putting MLP functionality into production for enterprise consumption, promote sharing of components, and encourage reuse. Key objectives included exploring the use of an open-source framework called the Unstructured Information Management Architecture (UIMA) and leveraging existing MLP-related efforts, terminology, and document standards. This paper describes early experiences in defining the infrastructure and standards for extracting, encoding, and structuring clinical observations from a variety of clinical documents to serve enterprise-wide needs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22323,""
"Robotic surgery for cervical cancer","Magrina, Zanagnolo","https://doi.org/10.3349/ymj.2008.49.6.879","20090303","PubMed","Female; Gynecologic Surgical Procedures; Humans; Hysterectomy; Lymph Node Excision; Minimally Invasive Surgical Procedures; Pelvic Exenteration; Robotics; Uterine Cervical Neoplasms","The development of robotic technology has facilitated the application of minimally invasive techniques for the treatment and evaluation of patients with early, advanced, and recurrent cervical cancer. The application of robotic technology for selected patients with cervical cancer and the data available in the literature are addressed in the present review paper. The robotic radical hysterectomy technique developed at the Mayo Clinic Arizona is presented with data comparing 27 patients who underwent the robotic procedure with 2 matched groups of patients treated by laparoscopic (N = 31), and laparotomic radical hysterectomy (N = 35). A few other studies confirmed the feasibility and safety of robotic radical hysterectomy and comparisons to either to the laparoscopic or open approach were discussed. Based on data from the literature, minimally invasive techniques including laparoscopy and robotics are preferable to laparotomy for patients requiring radical hysterectomy, with some advantages noted for robotics over laparoscopy. A prospective randomised trial is currently being performed under the auspices of the American Association of Gyneoclogic Laparoscopists comparing minimally invasive radical hysterectomy (laparoscopy or robotics) with laparotomy. For early cervical cancer radical parametrectomy and fertility preserving trachelectomy have been performed using robotic technology and been shown to be feasible, safe, and easier to perform when compared to the laparoscopic approach. Similar benefits have been noted in the treatment of advanced and recurrent cervical cancer where complex procedures such as extraperitoneal paraortic lymphadenectomy and pelvic exenteration have been required. Robotic technology better facilitates the surgical approach as compared to laparoscopy for technically challenging operations performed to treat primary, early or advanced, and recurrent cervical cancer. Although patient advantages are similar or slightly improved with robotics, there are multiple advantages for surgeons.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22324,""
"Using empiric semantic correlation to interpret temporal assertions in clinical texts","Hripcsak, Elhadad, Chen, Zhou, Morrison","https://doi.org/10.1197/jamia.M3007","20090403","PubMed","Humans; Linear Models; Medical Records; Natural Language Processing; Patient Discharge; Semantics; Time","To measure the uncertainty of temporal assertions like ""3 weeks ago"" in clinical texts. Temporal assertions extracted from narrative clinical reports were compared to facts extracted from a structured clinical database for the same patients. The authors correlated the assertions and the facts to determine the dependence of the uncertainty of the assertions on the semantic and lexical properties of the assertions. The observed deviation between the stated duration and actual duration averaged about 20% of the stated deviation. Linear regression revealed that assertions about events further in the past tend to be more uncertain, smaller numeric values tend to be more uncertain (1 mo v. 30 d), and round numbers tend to be more uncertain (10 versus 11 yrs). The authors empirically derived semantics behind statements of duration using ""ago,"" and verified intuitions about how numbers are used.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22325,""
"The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes","Vincze, Szarvas, Farkas, MÃƒÂ³ra, Csirik","https://doi.org/10.1186/1471-2105-9-S11-S9","20090728","PubMed","Abstracting and Indexing; Artificial Intelligence; Database Management Systems; Databases, Bibliographic; Information Storage and Retrieval; Natural Language Processing; Vocabulary, Controlled","Detecting uncertain and negative assertions is essential in most BioMedical Text Mining tasks where, in general, the aim is to derive factual knowledge from textual data. This article reports on a corpus annotation project that has produced a freely available resource for research on handling negation and uncertainty in biomedical texts (we call this corpus the BioScope corpus). The corpus consists of three parts, namely medical free texts, biological full papers and biological scientific abstracts. The dataset contains annotations at the token level for negative and speculative keywords and at the sentence level for their linguistic scope. The annotation process was carried out by two independent linguist annotators and a chief linguist--also responsible for setting up the annotation guidelines --who resolved cases where the annotators disagreed. The resulting corpus consists of more than 20.000 sentences that were considered for annotation and over 10% of them actually contain one (or more) linguistic annotation suggesting negation or uncertainty. Statistics are reported on corpus size, ambiguity levels and the consistency of annotations. The corpus is accessible for academic purposes and is free of charge. Apart from the intended goal of serving as a common resource for the training, testing and comparing of biomedical Natural Language Processing systems, the corpus is also a good resource for the linguistic analysis of scientific and clinical texts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22326,""
"Mining clinical relationships from patient narratives","Roberts, Gaizauskas, Hepple, Guo","https://doi.org/10.1186/1471-2105-9-S11-S3","20090728","PubMed","Algorithms; Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Natural Language Processing","The Clinical E-Science Framework (CLEF) project has built a system to extract clinically significant information from the textual component of medical records in order to support clinical research, evidence-based healthcare and genotype-meets-phenotype informatics. One part of this system is the identification of relationships between clinically important entities in the text. Typical approaches to relationship extraction in this domain have used full parses, domain-specific grammars, and large knowledge bases encoding domain knowledge. In other areas of biomedical NLP, statistical machine learning (ML) approaches are now routinely applied to relationship extraction. We report on the novel application of these statistical techniques to the extraction of clinical relationships. We have designed and implemented an ML-based system for relation extraction, using support vector machines, and trained and tested it on a corpus of oncology narratives hand-annotated with clinically important relationships. Over a class of seven relation types, the system achieves an average F1 score of 72%, only slightly behind an indicative measure of human inter annotator agreement on the same task. We investigate the effectiveness of different features for this task, how extraction performance varies between inter- and intra-sentential relationships, and examine the amount of training data needed to learn various relationships. We have shown that it is possible to extract important clinical relationships from text, using supervised statistical ML techniques, at levels of accuracy approaching those of human annotators. Given the importance of relation extraction as an enabling technology for text mining and given also the ready adaptability of systems based on our supervised learning approach to other clinical relationship extraction tasks, this result has significance for clinical text mining more generally, though further work to confirm our encouraging results should be carried out on a larger sample of narratives and relationship types.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22327,""
"The current status of robotic pelvic surgery: results of a multinational interdisciplinary consensus conference","Wexner, Bergamaschi, Lacy, Udo, BrÃƒÂ¶lmann, Kennedy, John","https://doi.org/10.1007/s00464-008-0202-8","20090423","PubMed","Female; Humans; Laparoscopes; Laparoscopy; Male; Prostatic Neoplasms; Rectal Neoplasms; Robotics; Uterine Neoplasms","Despite the significant benefits of laparoscopic surgery, limitations still exist. One of these limitations is the loss of several degrees of freedom. Robotic surgery has allowed surgeons to regain the two lost degrees of freedom by introducing wristed laparoscopic instruments. At the first Pelvic Surgery Meeting held in Brescia in June 2007, the participants focused on the role of robotic surgery in pelvic operations surgery for malignancy including prostate, rectal, uterine, and cervical carcinoma. All members of the interdisciplinary panel were asked to define the role of robotic surgery in prostate, rectal, and uterine carcinoma. All key statements were reformulated until a consensus within the group was achieved (Murphy et al., Health Technol Assess 2(i-v):1-88, 1998). For the systematic review, a comprehensive literature search was performed in Medline and the Cochrane Library from January 1997 to June 2007. The keywords used were Da Vinci, telemonitoring, laparoscopy, neoplasms for urology, colorectal, gynecology, visceral surgery, and minimally invasive surgery. The pelvic surgery meeting was supported by Olympus Medical Systems Europa. As of December 31, 2007, there were 795 unit shipments worldwide of the Da Vinci((R)): 595 in North America, 136 in Europe, and 64 in the rest of the world (http://investor.intuitivesurgical.com/phoenix.zhtml?c=122359&amp;p=irol-faq#22324 ). It was estimated that, during 2007, approximately 50,000 radical prostatectomies were performed with the Da Vinci robot system in the USA, reflecting market penetration of 60% of radical prostatectomies in the USA. This utilization represents 50% growth as in 2006 only 42% of all radical prostatectomies performed in the USA employed robotics. While robotic prostatectomy has become the most widely accepted method of prostatectomy, robotic hysterectomy and proctectomy remain far less widely accepted. The theoretical benefits of the increased degrees of freedom and three-dimensional visualization may be outweighed in these areas by the loss of haptic feedback, increased operative times, and increased cost.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22328,""
"Cefepime-induced nonconvulsive status epilepticus: case report and review","Thabet, Al Maghrabi, Al Barraq, Tabarki","https://doi.org/10.1007/s12028-008-9166-8","20090917","PubMed","Adolescent; Anti-Bacterial Agents; Cefepime; Cephalosporins; Female; Humans; Kidney Failure, Chronic; Status Epilepticus","A case of cefepime-induced nonconvulsive status epilepticus in a 15-year-old child with end stage renal disease on hemodialysis is reported. Clinical symptoms and EEG dramatically improved 48 h after discontinuation of cefepime. Twenty-five cases of nonconvulsive status epilepticus associated with cefepime that have been reported in the literature are reviewed. The average age was 60 years [15-86], our patient is the second pediatric patient reported, and 56% of cases occurred in women. The cefepime dosage was adjusted to the renal function in 5 cases. All except 1 patient have impaired renal function (CRF: 17 cases, ARF: 7 cases). The symptoms start 1-15 days after starting cefepime, mean 6 days. The outcome was good after discontinuation of cefepime therapy and anticonvulsant treatment, but lethal outcome was also reported in 2 cases. One fatality was related to status epilepticus. The clinicians' awareness must be increased about cefepime-induced nonconvulsive status epilepticus.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22329,""
"Automatic medical encoding with SNOMED categories","Ruch, Gobeill, Lovis, GeissbÃƒÂ¼hler","https://doi.org/10.1186/1472-6947-8-S1-S6","20090127","PubMed","Algorithms; Automation; Efficiency, Organizational; Episode of Care; Forms and Records Control; MEDLINE; Systematized Nomenclature of Medicine","In this paper, we describe the design and preliminary evaluation of a new type of tools to speed up the encoding of episodes of care using the SNOMED CT terminology. The proposed system can be used either as a search tool to browse the terminology or as a categorization tool to support automatic annotation of textual contents with SNOMED concepts. The general strategy is similar for both tools and is based on the fusion of two complementary retrieval strategies with thesaural resources. The first classification module uses a traditional vector-space retrieval engine which has been fine-tuned for the task, while the second classifier is based on regular variations of the term list. For evaluating the system, we use a sample of MEDLINE. SNOMED CT categories have been restricted to Medical Subject Headings (MeSH) using the SNOMED-MeSH mapping provided by the UMLS (version 2006). Consistent with previous investigations applied on biomedical terminologies, our results show that performances of the hybrid system are significantly improved as compared to each single module. For top returned concepts, a precision at high ranks (P0) of more than 80% is observed. In addition, a manual and qualitative evaluation on a dozen of MEDLINE abstracts suggests that SNOMED CT could represent an improvement compared to existing medical terminologies such as MeSH. Although the precision of the SNOMED categorizer seems sufficient to help professional encoders, it is concluded that clinical benchmarks as well as usability studies are needed to assess the impact of our SNOMED encoding method in real settings. AVAILABILITIES: The system is available for research purposes on: http://eagl.unige.ch/SNOCat.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22330,""
"Automatic summarization of MEDLINE citations for evidence-based medical treatment: a topic-oriented evaluation","Fiszman, Demner-Fushman, Kilicoglu, Rindflesch","https://doi.org/10.1016/j.jbi.2008.10.002","20100121","PubMed","Artificial Intelligence; Disease; Drug Therapy; Electronic Data Processing; Evidence-Based Medicine; Humans; Information Storage and Retrieval; Internet; MEDLINE; Medical Informatics; Natural Language Processing; Semantics; User-Computer Interface; Vocabulary, Controlled","As the number of electronic biomedical textual resources increases, it becomes harder for physicians to find useful answers at the point of care. Information retrieval applications provide access to databases; however, little research has been done on using automatic summarization to help navigate the documents returned by these systems. After presenting a semantic abstraction automatic summarization system for MEDLINE citations, we concentrate on evaluating its ability to identify useful drug interventions for 53 diseases. The evaluation methodology uses existing sources of evidence-based medicine as surrogates for a physician-annotated reference standard. Mean average precision (MAP) and a clinical usefulness score developed for this study were computed as performance metrics. The automatic summarization system significantly outperformed the baseline in both metrics. The MAP gain was 0.17 (p&lt;0.01) and the increase in the overall score of clinical usefulness was 0.39 (p&lt;0.05).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22331,""
"Medication therapy management goes hi-tech: implementing automated software improves pharmacy efficiency","Giordano, Holden, Misquitta","https://www.google.com/search?q=Medication+therapy+management+goes+hi-tech:+implementing+automated+software+improves+pharmacy+efficiency.","20140815","PubMed","","With the Centers for Medicare &amp; Medicaid Services mandate that all Medicare Part D benefit sponsors must offer members a medication therapy management program, pharmacists were facing new challenges of data collecting using software applications that had limited use for the new program. Health Net pharmacists initiated an automated software application to increase the efficiency of the medication therapy management program, the integrity of the member profiles, and the ability to provide accurate reporting of drug-related issues. Pharmacists were integral contributors to the automated software program; they developed the clinical algorithms, screen layout and transitions, and program functionality. Together with a programming company-Cognizant Technology Solutions-they created a web-based software application to accommodate an increasing number of eligible members and ensure accuracy of the information; they also performed testing of the final product. The new program includes member demographics and qualifying parameters that are uploaded monthly. All drug-related problems are now displayed and updated automatically by the software application. Assessment questions are answered and saved within the software, and reporting functions allow for quick and accurate results. Consequently, the number of drug regimen reviews and drug problems identified has increased by more than 300%. The automated software application is capable of maintaining and updating medication claims, sending and receiving faxes to physicians and pharmacies, and allows for documentation of patient-specific freeform text. Each profile is extensive and allows the pharmacist to get all necessary information from a single source.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22332,""
"Exhaustive prediction of disease susceptibility to coding base changes in the human genome","Kulkarni, Errami, Barber, Garner","https://doi.org/10.1186/1471-2105-9-S9-S3","20081017","PubMed","Algorithms; Base Sequence; Chromosome Mapping; DNA Mutational Analysis; Genetic Predisposition to Disease; Genetic Testing; Genome, Human; Humans; Molecular Sequence Data; Open Reading Frames; Polymorphism, Single Nucleotide; Quantitative Trait, Heritable; Sequence Analysis, DNA","Single Nucleotide Polymorphisms (SNPs) are the most abundant form of genomic variation and can cause phenotypic differences between individuals, including diseases. Bases are subject to various levels of selection pressure, reflected in their inter-species conservation. We propose a method that is not dependant on transcription information to score each coding base in the human genome reflecting the disease probability associated with its mutation. Twelve factors likely to be associated with disease alleles were chosen as the input for a support vector machine prediction algorithm. The analysis yielded 83% sensitivity and 84% specificity in segregating disease like alleles as found in the Human Gene Mutation Database from non-disease like alleles as found in the Database of Single Nucleotide Polymorphisms. This algorithm was subsequently applied to each base within all known human genes, exhaustively confirming that interspecies conservation is the strongest factor for disease association. For each gene, the length normalized average disease potential score was calculated. Out of the 30 genes with the highest scores, 21 are directly associated with a disease. In contrast, out of the 30 genes with the lowest scores, only one is associated with a disease as found in published literature. The results strongly suggest that the highest scoring genes are enriched for those that might contribute to disease, if mutated. This method provides valuable information to researchers to identify sensitive positions in genes that have a high disease probability, enabling them to optimize experimental designs and interpret data emerging from genetic and epidemiological studies.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22333,""
"Identification and analysis of co-occurrence networks with NetCutter","MÃƒÂ¼ller, Mancuso","https://doi.org/10.1371/journal.pone.0003178","20081125","PubMed","Algorithms; Cluster Analysis; Computational Biology; Data Interpretation, Statistical; Genomics; Humans; Models, Statistical; Neoplasms; Poisson Distribution; Polymorphism, Single Nucleotide; Probability; Software; Time Factors","Co-occurrence analysis is a technique often applied in text mining, comparative genomics, and promoter analysis. The methodologies and statistical models used to evaluate the significance of association between co-occurring entities are quite diverse, however. We present a general framework for co-occurrence analysis based on a bipartite graph representation of the data, a novel co-occurrence statistic, and software performing co-occurrence analysis as well as generation and analysis of co-occurrence networks. We show that the overall stringency of co-occurrence analysis depends critically on the choice of the null-model used to evaluate the significance of co-occurrence and find that random sampling from a complete permutation set of the bipartite graph permits co-occurrence analysis with optimal stringency. We show that the Poisson-binomial distribution is the most natural co-occurrence probability distribution when vertex degrees of the bipartite graph are variable, which is usually the case. Calculation of Poisson-binomial P-values is difficult, however. Therefore, we propose a fast bi-binomial approximation for calculation of P-values and show that this statistic is superior to other measures of association such as the Jaccard coefficient and the uncertainty coefficient. Furthermore, co-occurrence analysis of more than two entities can be performed using the same statistical model, which leads to increased signal-to-noise ratios, robustness towards noise, and the identification of implicit relationships between co-occurring entities. Using NetCutter, we identify a novel protein biosynthesis related set of genes that are frequently coordinately deregulated in human cancer related gene expression studies. NetCutter is available at http://bio.ifom-ieo-campus.it/NetCutter/). Our approach can be applied to any set of categorical data where co-occurrence analysis might reveal functional relationships such as clinical parameters associated with cancer subtypes or SNPs associated with disease phenotypes. The stringency of our approach is expected to offer an advantage in a variety of applications.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22334,""
"Modeling the management of a flexor sheath ganglion","Xu, Lan, McCabe","https://doi.org/10.1007/s11552-007-9060-4","20081112","PubMed","","In a published cost analysis of the management of flexor sheath ganglia, it was found that two attempts at aspiration, followed by surgical removal for those who failed, was the least costly alternative. We used this report as a template to create a model of the management that could be used in decision analysis. Using the published cohort study as a guide, a decision tree and Markov model of the management of flexor sheath ganglia were created. When compared to the results of a large cohort of patients reported in the literature, we accurately modeled the management of flexor sheath ganglia using both approaches. Creating a model of the management of a disease provides the opportunity to understand and explore questions efficiently and inexpensively. Many disorders of the upper extremity have commonality in their management, making the modeling approach attractive and potentially very valuable. This simple example illustrates two common methods used and is important because it builds confidence in the method by accurately modeling actual clinical experience.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22335,""
"Quantifying data quality for clinical trials using electronic data capture","Nahm, Pieper, Cunningham","https://doi.org/10.1371/journal.pone.0003049","20081218","PubMed","Clinical Audit; Clinical Trials as Topic; Commission on Professional and Hospital Activities; Electronic Data Processing; Humans; National Institute on Drug Abuse (U.S.); National Institutes of Health (U.S.); Organizational Case Studies; Research Design; United States","Historically, only partial assessments of data quality have been performed in clinical trials, for which the most common method of measuring database error rates has been to compare the case report form (CRF) to database entries and count discrepancies. Importantly, errors arising from medical record abstraction and transcription are rarely evaluated as part of such quality assessments. Electronic Data Capture (EDC) technology has had a further impact, as paper CRFs typically leveraged for quality measurement are not used in EDC processes. The National Institute on Drug Abuse Treatment Clinical Trials Network has developed, implemented, and evaluated methodology for holistically assessing data quality on EDC trials. We characterize the average source-to-database error rate (14.3 errors per 10,000 fields) for the first year of use of the new evaluation method. This error rate was significantly lower than the average of published error rates for source-to-database audits, and was similar to CRF-to-database error rates reported in the published literature. We attribute this largely to an absence of medical record abstraction on the trials we examined, and to an outpatient setting characterized by less acute patient conditions. Historically, medical record abstraction is the most significant source of error by an order of magnitude, and should be measured and managed during the course of clinical trials. Source-to-database error rates are highly dependent on the amount of structured data collection in the clinical setting and on the complexity of the medical record, dependencies that should be considered when developing data quality benchmarks.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22336,""
"Making texts in electronic health records comprehensible to consumers: a prototype translator","Zeng-Treitler, Goryachev, Kim, Keselman, Rosendale","https://www.google.com/search?q=Making+texts+in+electronic+health+records+comprehensible+to+consumers:+a+prototype+translator.","20081118","PubMed","Comprehension; Consumer Health Information; Feasibility Studies; Humans; Medical Records; Medical Records Systems, Computerized; Natural Language Processing; Translating; Unified Medical Language System; Vocabulary, Controlled","Narrative reports from electronic health records are a major source of content for personal health records. We designed and implemented a prototype text translator to make these reports more comprehensible to consumers. The translator identifies difficult terms, replaces them with easier synonyms, and generates and inserts explanatory texts for them. In feasibility testing, the application was used to translate 9 clinical reports. Majority (68.8%) of text replacements and insertions were deemed correct and helpful by expert review. User evaluation demonstrated a non-statistically significant trend toward better comprehension when translation is provided (p=0.15).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22337,""
"Automatic summarization of mouse gene information by clustering and sentence extraction from MEDLINE abstracts","Yang, Cohen, Hersh","https://www.google.com/search?q=Automatic+summarization+of+mouse+gene+information+by+clustering+and+sentence+extraction+from+MEDLINE+abstracts.","20081118","PubMed","Abstracting and Indexing; Algorithms; Animals; Gene Expression; Genes; Genome; Genomics; MEDLINE; Medical Subject Headings; Mice; Natural Language Processing; Oligonucleotide Array Sequence Analysis; Software","Tools to automatically summarize gene information from the literature have the potential to help genomics researchers better interpret gene expression data and investigate biological pathways. The task of finding information on sets of genes is common for genomic researchers, and PubMed is still the first choice because the most recent and original information can only be found in the unstructured, free text biomedical literature. However, finding information on a set of genes by manually searching and scanning the literature is a time-consuming and daunting task for scientists. We built and evaluated a query-based automatic summarizer of information on mouse genes studied in microarray experiments. The system clusters a set of genes by MeSH, GO and free text features and presents summaries for each gene by ranked sentences extracted from MEDLINE abstracts. Evaluation showed that the system seems to provide meaningful clusters and informative sentences are ranked higher by the algorithm.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22338,""
"Enriching knowledge domain visualizations: analysis of a record linkage and information fusion approach to citation data","Synnestvedt","https://www.google.com/search?q=Enriching+knowledge+domain+visualizations:+analysis+of+a+record+linkage+and+information+fusion+approach+to+citation+data.","20081118","PubMed","Algorithms; Bibliometrics; Data Display; Databases, Bibliographic; Information Storage and Retrieval; Internet; MEDLINE; Medical Subject Headings; Models, Statistical","This article presents a study of the use of data preparation for data mining methodology to prepare biomedical citation data for visualization. Deterministic record linkage models were compared with probabilistic record linkage in a situation for which the truth is known through the use of gold standard or truth datasets. The linkages are evaluated on data from the Web of Science (WOS) and Medline citation databases. Sensitivity, specificity, and overall performance of record linkage models were empirically compared with ROC analysis. Data quality and visualization metrics are presented for datasets prepared with and without probabilistic record linkage and information fusion of Medline abstracts and MESH terms into WOS citation records. The major contributions of this work are to specifically develop a novel model of record linkage for biomedical citation databases, with the objective of improving and enriching biomedical knowledge domain visualizations.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22339,""
"Are random forests better than support vector machines for microarray-based cancer classification?","Statnikov, Aliferis","https://www.google.com/search?q=Are+random+forests+better+than+support+vector+machines+for+microarray-based+cancer+classification?","20081118","PubMed","Algorithms; Computational Biology; Decision Making, Computer-Assisted; Decision Trees; Gene Expression Profiling; Humans; Neoplasms; Oligonucleotide Array Sequence Analysis; Pattern Recognition, Automated","Cancer diagnosis and clinical outcome prediction are among the most important emerging applications of gene expression microarray technology with several molecular signatures on their way toward clinical deployment. Use of the most accurate decision support algorithms available for microarray gene expression data is a critical ingredient in order to develop the best possible molecular signatures for patient care. As suggested by a large body of literature to-date, support vector machines can be considered ""best of class"" algorithms for classification of such data. Recent work however found that random forest classifiers outperform support vector machines. In the present paper we point to several biases of this prior work and conduct a new unbiased evaluation of the two algorithms. Our experiments using 18 diagnostic and prognostic datasets show that support vector machines outperform random forests often by a large margin.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22340,""
"The CLEF corpus: semantic annotation of clinical text","Roberts, Gaizauskas, Hepple, Davis, Demetriou, Guo, Kola, Roberts, Setzer, Tapuria, Wheeldin","https://www.google.com/search?q=The+CLEF+corpus:+semantic+annotation+of+clinical+text.","20081118","PubMed","Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Natural Language Processing; Semantics","The Clinical E-Science Framework (CLEF) project is building a framework for the capture, integration and presentation of clinical information: for clinical research, evidence-based health care and genotype-meets-phenotype informatics. A significant portion of the information required by such a framework originates as text, even in EHR-savvy organizations. CLEF uses Information Extraction (IE) to make this unstructured information available. An important part of IE is the identification of semantic entities and relationships. Typical approaches require human annotated documents to provide both evaluation standards and material for system development. CLEF has a corpus of clinical narratives, histopathology reports and imaging reports from 20 thousand patients. We describe the selection of a subset of this corpus for manual annotation of clinical entities and relationships. We describe an annotation methodology and report encouraging initial results of inter-annotator agreement. Comparisons are made between different text sub-genres, and between annotators with different skills.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22341,""
"Modeling participant-related clinical research events using conceptual knowledge acquisition techniques","Payne, Mendonca, Starren","https://www.google.com/search?q=Modeling+participant-related+clinical+research+events+using+conceptual+knowledge+acquisition+techniques.","20081118","PubMed","Abstracting and Indexing; Algorithms; Artificial Intelligence; Clinical Protocols; Clinical Trials as Topic; Humans; Subject Headings; Unified Medical Language System","The active phase of a clinical trial is defined by a protocol schema consisting of participant-related events organized into multiple visits. Current efforts to model protocol schemas in a computable format have focused on high-level abstractions, such as the temporal relationships between visits. However, such approaches do not address the need for a more granular computational model of the individual events that comprise each visit. To address the preceding gap in knowledge, this paper will describe a study in which conceptual knowledge acquisition (CKA) techniques were applied to a corpus of 32 clinical trials protocol documents in order to develop a knowledge collection of common participant-related clinical research events. These techniques identified 7 high-level concepts that could be used as organizing principles in the resulting knowledge collection. Such results confirm the utility of CKA methods in the clinical research domain.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22342,""
"Extraction and mapping of drug names from free text to a standardized nomenclature","Levin, Krol, Doshi, Reich","https://www.google.com/search?q=Extraction+and+mapping+of+drug+names+from+free+text+to+a+standardized+nomenclature.","20081118","PubMed","Abstracting and Indexing; Algorithms; Anesthesiology; Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Natural Language Processing; Pharmaceutical Preparations; Terminology as Topic","Free text fields are often used to store clinical drug data in electronic health records. The use of free text facilitates rapid data entry by the clinician. Errors in spelling, abbreviations, and jargon, however, limit the utility of these data. We designed and implemented an algorithm, using open source tools and RxNorm, to extract and normalize drug data stored in free text fields of an anesthesia electronic health record. The algorithm was developed using a training set containing drug data from 49,518 cases, and validated using a validation set containing data from 14,655 cases. Overall sensitivity and specificity for the validation set were 92.2% and 95.7% respectively. The mains sources of error were misspellings and unknown but valid drug names. These preliminary results demonstrate that free text clinical drug data can be efficiently extracted and mapped to a controlled drug nomenclature.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22343,""
"The @neurIST ontology of intracranial aneurysms: providing terminological services for an integrated IT infrastructure","Boeker, Stenzhorn, Kumpf, Bijlenga, Schulz, Hanser","https://www.google.com/search?q=The+@neurIST+ontology+of+intracranial+aneurysms:+providing+terminological+services+for+an+integrated+IT+infrastructure.","20081118","PubMed","Databases as Topic; Europe; Humans; Internet; Intracranial Aneurysm; Medical Informatics Applications; Subarachnoid Hemorrhage; Systems Integration; Terminology as Topic; Vocabulary, Controlled","The @neurIST ontology is currently under development within the scope of the European project @neurIST intended to serve as a module in a complex architecture aiming at providing a better understanding and management of intracranial aneurysms and subarachnoid hemorrhages. Due to the integrative structure of the project the ontology needs to represent entities from various disciplines on a large spatial and temporal scale. Initial term acquisition was performed by exploiting a database scaffold, literature analysis and communications with domain experts. The ontology design is based on the DOLCE upper ontology and other existing domain ontologies were linked or partly included whenever appropriate (e.g., the FMA for anatomical entities and the UMLS for definitions and lexical information). About 2300 predominantly medical entities were represented but also a multitude of biomolecular, epidemiological, and hemodynamic entities. The usage of the ontology in the project comprises terminological control, text mining, annotation, and data mediation.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22344,""
"Agreement between patient-reported symptoms and their documentation in the medical record","Pakhomov, Jacobsen, Chute, Roger","https://www.google.com/search?q=Agreement+between+patient-reported+symptoms+and+their+documentation+in+the+medical+record.","20080923","PubMed","Adolescent; Adult; Aged; Angina Pectoris; Chest Pain; Cough; Documentation; Dyspnea; Female; Group Practice; Humans; Male; Medical Audit; Medical History Taking; Medical Records Systems, Computerized; Middle Aged; Minnesota; Natural Language Processing; Self Disclosure","To determine the agreement between patient-reported symptoms of chest pain, dyspnea, and cough and the documentation of these symptoms by physicians in the electronic medical record. Symptoms reported on patient-provided information forms between January 1, 2006, and June 30, 2006, were compared with those identified by natural language processing of the text of clinical notes from care providers. Terms that represent the 3 symptoms were used to search clinical notes electronically with subsequent manual identification of the context (eg, affirmative, negated, family history) in which they occurred. Results were reported using positive and negative agreement, and kappa statistics. Symptoms reported by 1119 patients age 18 years or older were compared with the nonnegated terms identified in their clinical notes. Positive agreement was 74, 70, and 63 for chest pain, dyspnea, and cough, while negative agreement was 78, 76, and 75, respectively. Kappa statistics were 0.52 (95% confidence interval [CI] = 0.44, 0.60) for chest pain, 0.46 (95% CI = 0.37, 0.54) for dyspnea, and 0.38 (95% CI = 0.28, 0.48) for cough. Positive agreement was higher for older men (P &gt;.05), and negative agreement was higher for younger women (P &gt;.05). We found discordance between patient self-report and documentation of symptoms in the medical record. This discordance has important implications for research studies that rely on symptom information for patient identification and may have clinical implications that must be evaluated for potential impact on quality of care, patient safety, and outcomes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22345,""
"An inexpensive and automated method for presenting olfactory or tactile stimuli to rats in a two-choice discrimination task","Iversen","https://doi.org/10.1901/jeab.2008.90-113","20080904","PubMed","Animals; Automation; Behavior, Animal; Choice Behavior; Discrimination Learning; Equipment Design; Female; Physical Stimulation; Psychology, Experimental; Rats; Rats, Long-Evans; Smell; Touch","An inexpensive and automated method for presentation of olfactory or tactile stimuli in a two-choice task for rats was implemented with the use of a computer-controlled bidirectional motor. The motor rotated a disk that presented two stimuli of different texture for tactile discrimination, or different odor for olfactory discrimination. Because the solid olfactory stimuli were placed outside the chamber in metal pods with a mesh at front for odor sampling, ""washout"" of odors between trials was not necessary. To avoid differential auditory cues from motor rotation, the stimuli were arranged such that on each trial the motor always rotated exactly one quarter revolution (in 1 s), left or right, to present the next stimulus at trial start. To illustrate the use of the equipment, 2 rats were trained on tactile discrimination and 2 rats on olfactory discrimination. The rats sampled the stimulus on the disk through a port on the back wall by sniffing at it (olfactory) or touching it (tactile). The task was a go-left/go-right discrimination with the stimulus on the disk being discriminative for which lever provided reinforcement. The rats reached a stable level above 90% correct after 21 and 32 training sessions for tactile and olfactory discrimination, respectively. The article outlines how the equipment was constructed from low-cost components. Inputs from and outputs to the equipment were implemented through the parallel port of a personal computer without the use of a commercial interface board. The method of automated and low-cost presentation of olfactory or tactile stimuli should be of use for a variety of experimental situations such as matching-to-sample and cross-modal discrimination.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22346,""
"Accessing and integrating data and knowledge for biomedical research","Burgun, Bodenreider","https://www.google.com/search?q=Accessing+and+integrating+data+and+knowledge+for+biomedical+research.","20080903","PubMed","Biomedical Research; Computational Biology; Computer Communication Networks; Databases as Topic; Information Management; Medical Informatics Applications; Systems Integration; Vocabulary, Controlled","To review the issues that have arisen with the advent of translational research in terms of integration of data and knowledge, and survey current efforts to address these issues. Using examples form the biomedical literature, we identified new trends in biomedical research and their impact on bioinformatics. We analyzed the requirements for effective knowledge repositories and studied issues in the integration of biomedical knowledge. New diagnostic and therapeutic approaches based on gene expression patterns have brought about new issues in the statistical analysis of data, and new workflows are needed are needed to support translational research. Interoperable data repositories based on standard annotations, infrastructures and services are needed to support the pooling and meta-analysis of data, as well as their comparison to earlier experiments. High-quality, integrated ontologies and knowledge bases serve as a source of prior knowledge used in combination with traditional data mining techniques and contribute to the development of more effective data analysis strategies. As biomedical research evolves from traditional clinical and biological investigations towards omics sciences and translational research, specific needs have emerged, including integrating data collected in research studies with patient clinical data, linking omics knowledge with medical knowledge, modeling the molecular basis of diseases, and developing tools that support in-depth analysis of research data. As such, translational research illustrates the need to bridge the gap between bioinformatics and medical informatics, and opens new avenues for biomedical informatics research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22347,""
"A comprehensive comparison of random forests and support vector machines for microarray-based cancer classification","Statnikov, Wang, Aliferis","https://doi.org/10.1186/1471-2105-9-319","20080903","PubMed","Algorithms; Artificial Intelligence; Biomarkers, Tumor; Computational Biology; Databases, Genetic; Decision Trees; Gene Expression Profiling; Humans; Neoplasms; Oligonucleotide Array Sequence Analysis; Pattern Recognition, Automated; Random Allocation; Validation Studies as Topic","Cancer diagnosis and clinical outcome prediction are among the most important emerging applications of gene expression microarray technology with several molecular signatures on their way toward clinical deployment. Use of the most accurate classification algorithms available for microarray gene expression data is a critical ingredient in order to develop the best possible molecular signatures for patient care. As suggested by a large body of literature to date, support vector machines can be considered ""best of class"" algorithms for classification of such data. Recent work, however, suggests that random forest classifiers may outperform support vector machines in this domain. In the present paper we identify methodological biases of prior work comparing random forests and support vector machines and conduct a new rigorous evaluation of the two algorithms that corrects these limitations. Our experiments use 22 diagnostic and prognostic datasets and show that support vector machines outperform random forests, often by a large margin. Our data also underlines the importance of sound research design in benchmarking and comparison of bioinformatics algorithms. We found that both on average and in the majority of microarray datasets, random forests are outperformed by support vector machines both in the settings when no gene selection is performed and when several popular gene selection methods are used.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22348,""
"Can bibliographic pointers for known biological data be found automatically? Protein interactions as a case study","Blaschke, Valencia","https://doi.org/10.1002/cfg.91","20100609","PubMed","","The Dictionary of Interacting Proteins (DIP) (Xenarios et al., 2000) is a large repository of protein interactions: its March 2000 release included 2379 protein pairs whose interactions have been detected by experimental methods. Even if many of these correspond to poorly characterized proteins, the result of massive yeast two-hybrid screenings, as many as 851 correspond to interactions detected using direct biochemical methods.We used information retrieval technology to search automatically for sentences in Medline abstracts that support these 851 DIP interactions. Surprisingly, we found correspondence between DIP protein pairs and Medline sentences describing their interactions in only 30% of the cases. This low coverage has interesting consequences regarding the quality of annotations (references) introduced in the database and the limitations of the application of information extraction (IE) technology to Molecular Biology. It is clear that the limitation of analyzing abstracts rather than full papers and the lack of standard protein names are difficulties of considerably more importance than the limitations of the IE methodology employed. A positive finding is the capacity of the IE system to identify new relations between proteins, even in a set of proteins previously characterized by human experts. These identifications are made with a considerable degree of precision. This is, to our knowledge, the first large scale assessment of IE capacity to detect previously known interactions: we thus propose the use of the DIP data set as a biological reference to benchmark IE systems.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22349,""
"Classification of parenchymal abnormality in scleroderma lung using a novel approach to denoise images collected via a multicenter study","Kim, Li, Gjertson, Elashoff, Shah, Ochs, Vasunilashorn, Abtin, Brown, Goldin","https://doi.org/10.1016/j.acra.2008.03.011","20081217","PubMed","Algorithms; Humans; Lung Diseases; Radiography; Scleroderma, Diffuse","Computerized classification techniques have been developed to offer accurate and robust pattern recognition in interstitial lung disease using texture features. However, these techniques still present challenges when analyzing computed tomographic (CT) image data from multiprotocols because of disparate acquisition protocols or from standardized, multicenter clinical trials because of noise variability. Our objective is to investigate the utility of denoising thin section CT image data to improve the classification of scleroderma disease patterns. The patterns are lung fibrosis (LF), groundglass (GG), honeycomb (HC), or normal lung (NL) within small regions of interest (ROIs). High-resolution CT images were scanned in a multicenter clinical trial for the Scleroderma Lung Study. A thoracic radiologist contoured a training set (38 patients) consisting of 148 ROIs with 46 LF, 85 GG, 4 HC, and 13 NL patterns and contoured a test set (33 new patients) consisting of 132 ROIs with 44 LF, 72 GG, 4 HC, and 12 NL patterns. The corresponding CT slices of a contoured ROI were denoised using Aujol's mathematic partial differential equation algorithm. The algorithm's noise parameter was estimated as the standard deviation of grey-level signal (in Hounsfield units) in a homogeneous, non-lung region: the aorta. Within each contoured ROI, every pixel within a 4 x 4 neighborhood was sampled (4 x 4 grid sampling). All sampled pixels from a contoured ROI were assumed to be the same disease pattern as labeled by the radiologist. 5,690 pixels (3,009 LF, 1,994 GG, 348 HC, and 339 NL) and 5,045 pixels (2,665 LF, 1,753 GG, 291 HC, and 336 NL) were sampled in training and test sets, respectively. Next, 58 texture features from the original and denoised image were calculated for each pixel. Using a multinomial logistic model, subsets of features (one from original and another from denoised images) were selected to classify disease patterns. Finally, pixels were classified into disease patterns using a support vector machine procedure. From the training set, multinomial logistic model selected 45 features from the original images and 38 features from denoised images to classify disease patterns. Using the test set, the overall pixel classification rate by SVM increased from 87.8% to 89.5% with denoising. The specific classification rates (original/denoised) were 96.3/96.4% for LF, 88.8/89.4% for GG, 21.3/28.9% for HC, and 73.5/88.4% for NL. Denoising significantly improved the NL and overall classification rates (P = .037 and P = .047 respectively) at ROI level. Analyzing multicenter data using a denoising approach led to more parsimonious classification models with increasing accuracy. This approach offers a novel alternate classification strategy for heterogeneous technical and disease components. Furthermore, the model offers the potential to discriminate the multiple patterns of scleroderma disease correctly.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22350,""
"Literature-aided meta-analysis of microarray data: a compendium study on muscle development and disease","Jelier, 't Hoen, Sterrenburg, den Dunnen, van Ommen, Kors, Mons","https://doi.org/10.1186/1471-2105-9-291","20080903","PubMed","Animals; Artificial Intelligence; Cluster Analysis; Gene Expression Profiling; Humans; MEDLINE; Meta-Analysis as Topic; Models, Animal; Muscle Development; Muscular Diseases; Natural Language Processing; Oligonucleotide Array Sequence Analysis; Pattern Recognition, Automated; Publications; Reproducibility of Results; Vocabulary, Controlled","Comparative analysis of expression microarray studies is difficult due to the large influence of technical factors on experimental outcome. Still, the identified differentially expressed genes may hint at the same biological processes. However, manually curated assignment of genes to biological processes, such as pursued by the Gene Ontology (GO) consortium, is incomplete and limited. We hypothesised that automatic association of genes with biological processes through thesaurus-controlled mining of Medline abstracts would be more effective. Therefore, we developed a novel algorithm (LAMA: Literature-Aided Meta-Analysis) to quantify the similarity between transcriptomics studies. We evaluated our algorithm on a large compendium of 102 microarray studies published in the field of muscle development and disease, and compared it to similarity measures based on gene overlap and over-representation of biological processes assigned by GO. While the overlap in both genes and overrepresented GO-terms was poor, LAMA retrieved many more biologically meaningful links between studies, with substantially lower influence of technical factors. LAMA correctly grouped muscular dystrophy, regeneration and myositis studies, and linked patient and corresponding mouse model studies. LAMA also retrieves the connecting biological concepts. Among other new discoveries, we associated cullin proteins, a class of ubiquitinylation proteins, with genes down-regulated during muscle regeneration, whereas ubiquitinylation was previously reported to be activated during the inverse process: muscle atrophy. Our literature-based association analysis is capable of finding hidden common biological denominators in microarray studies, and circumvents the need for raw data analysis or curated gene annotation databases.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22351,""
"Neuropsychological impairment in systemic lupus erythematosus: a comparison with multiple sclerosis","Benedict, Shucard, Zivadinov, Shucard","https://doi.org/10.1007/s11065-008-9061-2","20080826","PubMed","Brain; Cognition Disorders; Humans; Lupus Erythematosus, Systemic; Magnetic Resonance Imaging; Multiple Sclerosis; Neuropsychological Tests","In this manuscript, we review literature describing the neuropsychological and brain imaging characteristics of systemic lupus erythematosus (SLE) patients. The findings are compared and contrasted with multiple sclerosis (MS) studies, revealing similarities and differences of interest to clinicians and researchers. While cognitive impairment is somewhat less common in SLE than MS, the diseases share a similar cognitive profile with deficits most prominent on tests emphasizing the speed of information processing, working memory, and visual/spatial learning, and memory. In early or more mildly affected patients, diffuse white matter damage, which may not be apparent on conventional brain imaging, plays a major role in clinical presentation and cognitive testing. The causes of white matter damage are very different, however, and in later stages of the disease MS and SLE appear to give rise to different forms of cerebral pathology. MS may be characterized by increasing brain atrophy affecting especially the cortical and deep gray matter, at least after conversion to secondary progressive course. There is less evidence for neurodegenerative changes in SLE, but patients are increasingly at risk for cerebrovascular disease. We conclude by offering some suggestions for future clinical and imaging research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22352,""
"Syntactical negation detection in clinical practice guidelines","Gindl, Kaiser, Miksch","https://www.google.com/search?q=Syntactical+negation+detection+in+clinical+practice+guidelines.","20080930","PubMed","Algorithms; Artificial Intelligence; Humans; Medical Oncology; Medical Records Systems, Computerized; Natural Language Processing; Practice Guidelines as Topic; Semantics; Software; Unified Medical Language System","In clinical practice guidelines (CPGs) the medical information is stored in a narrative way. A large part of this information occurs in a negated form. The detection of negation in CPGs is an important task since it helps medical personnel to identify not occurring symptoms and diseases as well as treatment actions that should not be accomplished. We developed algorithms capable of Negation Detection in this kind of medical documents. According to our results, we are convinced that the involvement of syntactical methods can improve Negation Detection, not only in medical writings but also in arbitrary narrative texts.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22353,""
"Lesion identification using unified segmentation-normalisation models and fuzzy clustering","Seghier, Ramlackhansingh, Crinion, Leff, Price","https://doi.org/10.1016/j.neuroimage.2008.03.028","20080829","PubMed","Algorithms; Brain; Brain Diseases; Brain Edema; Cerebral Ventricles; Data Interpretation, Statistical; Fuzzy Logic; Humans; Image Processing, Computer-Assisted; Models, Statistical; ROC Curve","In this paper, we propose a new automated procedure for lesion identification from single images based on the detection of outlier voxels. We demonstrate the utility of this procedure using artificial and real lesions. The scheme rests on two innovations: First, we augment the generative model used for combined segmentation and normalization of images, with an empirical prior for an atypical tissue class, which can be optimised iteratively. Second, we adopt a fuzzy clustering procedure to identify outlier voxels in normalised gray and white matter segments. These two advances suppress misclassification of voxels and restrict lesion identification to gray/white matter lesions respectively. Our analyses show a high sensitivity for detecting and delineating brain lesions with different sizes, locations, and textures. Our approach has important implications for the generation of lesion overlap maps of a given population and the assessment of lesion-deficit mappings. From a clinical perspective, our method should help to compute the total volume of lesion or to trace precisely lesion boundaries that might be pertinent for surgical or diagnostic purposes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22354,""
"Assessment and classification of mechanical strength components of human femur trabecular bone using texture analysis and neural network","Christopher, Ramakrishnan","https://doi.org/10.1007/s10916-007-9114-8","20080730","PubMed","Adult; Algorithms; Biomechanical Phenomena; Bone Density; Compressive Strength; Female; Femur; Humans; Male; Pelvis; Radiography; Tensile Strength","In this work the mechanical strength components of human femur trabecular bone are analyzed and classified using planar radiographic images and neural network. The mechanical strength regions such as Primary Compressive, Primary Tensile, Secondary Tensile and Ward Triangle in femur trabecular bone images (N = 100) are delineated by semi-automatic image processing procedure. First and higher order texture parameters and parameters such as apparent mineralization and total area associated with the strength regions are derived for normal and abnormal images. The statistically derived significant parameters corresponding to the primary strength regions are fed to the neural network for training and validation. The classifications are carried out using feed forward network that is trained with standard back propagation algorithm. Results demonstrate that the apparent mineralization of normal samples is always high as (71%) compared to abnormal samples (64%). Entropy shows a high value (7.3) for normal samples and variation between the mean intensity and apparent mineralization for the primary strength zone is statistically significant (p &lt; 0.0005). The classified outputs are validated by sensitivity and specificity measurements and are found to be 66.66% and 80% respectively. Further it appears that it is possible to differentiate normal and abnormal samples from the conventional radiographic images. As trabecular architecture in the human femur is an important factor contributing to bone strength, the procedure adopted here could be a useful supplement to the clinical observations for bone loss and fracture risk.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22355,""
"Ontology-based, Tissue MicroArray oriented, image centered tissue bank","Viti, Merelli, Caprera, Lazzari, Stella, Milanesi","https://doi.org/10.1186/1471-2105-9-S4-S4","20080606","PubMed","Algorithms; Database Management Systems; Databases, Factual; Italy; Medical Records Systems, Computerized; Natural Language Processing; Semantics; Software; Terminology as Topic; Tissue Array Analysis","Tissue MicroArray technique is becoming increasingly important in pathology for the validation of experimental data from transcriptomic analysis. This approach produces many images which need to be properly managed, if possible with an infrastructure able to support tissue sharing between institutes. Moreover, the available frameworks oriented to Tissue MicroArray provide good storage for clinical patient, sample treatment and block construction information, but their utility is limited by the lack of data integration with biomolecular information. In this work we propose a Tissue MicroArray web oriented system to support researchers in managing bio-samples and, through the use of ontologies, enables tissue sharing aimed at the design of Tissue MicroArray experiments and results evaluation. Indeed, our system provides ontological description both for pre-analysis tissue images and for post-process analysis image results, which is crucial for information exchange. Moreover, working on well-defined terms it is then possible to query web resources for literature articles to integrate both pathology and bioinformatics data. Using this system, users associate an ontology-based description to each image uploaded into the database and also integrate results with the ontological description of biosequences identified in every tissue. Moreover, it is possible to integrate the ontological description provided by the user with a full compliant gene ontology definition, enabling statistical studies about correlation between the analyzed pathology and the most commonly related biological processes.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22356,""
"Automatic construction of rule-based ICD-9-CM coding systems","Farkas, Szarvas","https://doi.org/10.1186/1471-2105-9-S3-S10","20080606","PubMed","Algorithms; Artificial Intelligence; Decision Support Systems, Clinical; International Classification of Diseases; Natural Language Processing; Pattern Recognition, Automated; Radiology; Terminology as Topic; Vocabulary, Controlled","In this paper we focus on the problem of automatically constructing ICD-9-CM coding systems for radiology reports. ICD-9-CM codes are used for billing purposes by health institutes and are assigned to clinical records manually following clinical treatment. Since this labeling task requires expert knowledge in the field of medicine, the process itself is costly and is prone to errors as human annotators have to consider thousands of possible codes when assigning the right ICD-9-CM labels to a document. In this study we use the datasets made available for training and testing automated ICD-9-CM coding systems by the organisers of an International Challenge on Classifying Clinical Free Text Using Natural Language Processing in spring 2007. The challenge itself was dominated by entirely or partly rule-based systems that solve the coding task using a set of hand crafted expert rules. Since the feasibility of the construction of such systems for thousands of ICD codes is indeed questionable, we decided to examine the problem of automatically constructing similar rule sets that turned out to achieve a remarkable accuracy in the shared task challenge. Our results are very promising in the sense that we managed to achieve comparable results with purely hand-crafted ICD-9-CM classifiers. Our best model got a 90.26% F measure on the training dataset and an 88.93% F measure on the challenge test dataset, using the micro-averaged F beta=1 measure, the official evaluation metric of the International Challenge on Classifying Clinical Free Text Using Natural Language Processing. This result would have placed second in the challenge, with a hand-crafted system achieving slightly better results. Our results demonstrate that hand-crafted systems - which proved to be successful in ICD-9-CM coding - can be reproduced by replacing several laborious steps in their construction with machine learning models. These hybrid systems preserve the favourable aspects of rule-based classifiers like good performance, and their development can be achieved rapidly and requires less human effort. Hence the construction of such hybrid systems can be feasible for a set of labels one magnitude bigger, and with more labeled data.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22357,""
"Simulating expert clinical comprehension: adapting latent semantic analysis to accurately extract clinical concepts from psychiatric narrative","Cohen, Blatter, Patel","https://doi.org/10.1016/j.jbi.2008.03.008","20090212","PubMed","Humans; Mental Disorders; Narration; Semantics","Cognitive studies reveal that less-than-expert clinicians are less able to recognize meaningful patterns of data in clinical narratives. Accordingly, psychiatric residents early in training fail to attend to information that is relevant to diagnosis and the assessment of dangerousness. This manuscript presents cognitively motivated methodology for the simulation of expert ability to organize relevant findings supporting intermediate diagnostic hypotheses. Latent Semantic Analysis is used to generate a semantic space from which meaningful associations between psychiatric terms are derived. Diagnostically meaningful clusters are modeled as geometric structures within this space and compared to elements of psychiatric narrative text using semantic distance measures. A learning algorithm is defined that alters components of these geometric structures in response to labeled training data. Extraction and classification of relevant text segments is evaluated against expert annotation, with system-rater agreement approximating rater-rater agreement. A range of biomedical informatics applications for these methods are suggested.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22358,""
"MedEvi: retrieving textual evidence of relations between biomedical concepts from Medline","Kim, Pezik, Rebholz-Schuhmann","https://doi.org/10.1093/bioinformatics/btn117","20080610","PubMed","Abstracting and Indexing; Artificial Intelligence; Database Management Systems; Information Storage and Retrieval; MEDLINE; Natural Language Processing; Vocabulary, Controlled","Search engines running on MEDLINE abstracts have been widely used by biologists to find publications that are related to their research. The existing search engines such as PubMed, however, have limitations when applied for the task of seeking textual evidence of relations between given concepts. The limitations are mainly due to the problem that the search engines do not effectively deal with multi-term queries which may imply semantic relations between the terms. To address this problem, we present MedEvi, a novel search engine that imposes positional restriction on occurrences matching multi-term queries, based on the observation that terms with semantic relations which are explicitly stated in text are not found too far from each other. MedEvi further identifies additional keywords of biological and statistical significance from local context of matching occurrences in order to help users reformulate their queries for better results. http://www.ebi.ac.uk/tc-test/textmining/medevi/","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22359,""
"Development of a Google-based search engine for data mining radiology reports","Erinjeri, Picus, Prior, Rubin, Koppel","https://doi.org/10.1007/s10278-008-9110-7","20090930","PubMed","Humans; Information Storage and Retrieval; Radiology; Radiology Information Systems; United States; User-Computer Interface","The aim of this study is to develop a secure, Google-based data-mining tool for radiology reports using free and open source technologies and to explore its use within an academic radiology department. A Health Insurance Portability and Accountability Act (HIPAA)-compliant data repository, search engine and user interface were created to facilitate treatment, operations, and reviews preparatory to research. The Institutional Review Board waived review of the project, and informed consent was not required. Comprising 7.9 GB of disk space, 2.9 million text reports were downloaded from our radiology information system to a fileserver. Extensible markup language (XML) representations of the reports were indexed using Google Desktop Enterprise search engine software. A hypertext markup language (HTML) form allowed users to submit queries to Google Desktop, and Google's XML response was interpreted by a practical extraction and report language (PERL) script, presenting ranked results in a web browser window. The query, reason for search, results, and documents visited were logged to maintain HIPAA compliance. Indexing averaged approximately 25,000 reports per hour. Keyword search of a common term like ""pneumothorax"" yielded the first ten most relevant results of 705,550 total results in 1.36 s. Keyword search of a rare term like ""hemangioendothelioma"" yielded the first ten most relevant results of 167 total results in 0.23 s; retrieval of all 167 results took 0.26 s. Data mining tools for radiology reports will improve the productivity of academic radiologists in clinical, educational, research, and administrative tasks. By leveraging existing knowledge of Google's interface, radiologists can quickly perform useful searches.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22360,""
"Key issues in bioheat transfer simulations for the application of cryosurgery planning","Rabin","https://doi.org/10.1016/j.cryobiol.2008.02.004","20080701","PubMed","Algorithms; Automation; Cryosurgery; Humans; Imaging, Three-Dimensional; Minimally Invasive Surgical Procedures; Planning Techniques; Surgery, Computer-Assisted; Thermal Conductivity; Time Factors","The bioheat transfer simulation is undoubtedly the foundation for developing computerized tools for cryosurgery planning and analysis. While a large variety of techniques for bioheat transfer simulations are available in the literature of the past several decades, it is only their integration with clinical criteria and constraints which can make computerized planning a practical reality. This brief communication outlines (in the opinion of this author) the key issues that must be addressed in the application of bioheat transfer to cryosurgery planning and analysis, while drawing attention to recent and relevant publications in other journals, with reference to the most recent publication on the topic in the Journal of Cryobiology [Z. Magalov, A. Shitzer, D. Degani, Isothermal volume contours generated in a freezing gel by embedded cryo-needles with applications to cryo-surgery, Cryobiology 55 (2) (2007) 127-137].","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22361,""
"The Changing ""Face"" of Aphasia Therapy","Lee, Cherney","https://doi.org/10.1044/nnsld18.1.15","20211020","PubMed","","A growing literature suggests that with intensive treatment, individuals with chronic aphasia continue to demonstrate language recovery for years post stroke. For example, Bhogal and colleagues conducted a literature review which suggests that intensive speech language therapy delivered over a short period of time (average of 8.8 hours per week for 11.2 weeks) resulted in significant improvements, while lower-intensity therapy provided over a longer period of time (average of 2 hours per week over 22.9 weeks) did not result in positive change (Bhogal, Teasell, Speechley, &amp; Albert, 2003). Similarly, the constraint induced aphasia therapy data emphasize the importance of massed-practice in the improvement of language skills of individuals with chronic aphasia (Pulvermuller et al., 2001; Maher et al., 2006). However, providing intensive treatment to individuals with chronic aphasia can be costly, and the current healthcare environment in the United States is one which does not recognize its value. As a result, clinicians and researchers in the field are left searching for cost effective ways to deliver aphasia treatment. One method of providing less costly but intensive treatment is via the computer.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22362,""
"What is a clinical decision analysis study?","Aleem, Schemitsch, Hanson","https://doi.org/10.4103/0019-5413.40248","20100630","PubMed","Clinical trials; critical appraisal; decision analysis; evidence-based medicine; hierarchy of evidence","Decision making in clinical practice often involves the need to make complex and intricate decisions with important long-term consequences. Decision analysis is a tool that allows users to apply evidence-based medicine to make informed and objective clinical decisions when faced with complex situations. A Decision Tree, together with literature-derived probabilities and defined outcome values, is used to model a given problem and help determine the best course of action. Sensitivity analysis allows an exploration of important variables on final clinical outcomes. A decision-maker can thereafter establish a preferred method of treatment and explore variables which influence the final outcome. The present paper is intended to give an overview of decision analysis and its application in clinical decision making.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22363,""
"Regression tree boosting to adjust health care cost predictions for diagnostic mix","Robinson","https://doi.org/10.1111/j.1475-6773.2007.00761.x","20080603","PubMed","Adolescent; Adult; Algorithms; Child; Child, Preschool; Demography; Diagnosis-Related Groups; Female; Health Care Costs; Humans; Infant; Infant, Newborn; Insurance Claim Review; Insurance, Health; Male; Risk Adjustment","To assess the ability of regression tree boosting to risk-adjust health care cost predictions, using diagnostic groups and demographic variables as inputs. Systems for risk-adjusting health care cost, described in the literature, have consistently employed deterministic models to account for interactions among diagnostic groups, simplifying their statistical representation, but sacrificing potentially useful information. An alternative is to use a statistical learning algorithm such as regression tree boosting that systematically searches the data for consequential interactions, which it automatically incorporates into a risk-adjustment model that is customized to the population under study. Administrative data for over 2 million enrollees in indemnity, preferred provider organization (PPO), and point-of-service (POS) plans from Thomson Medstat's Commercial Claims and Encounters database. The Agency for Healthcare Research and Quality's Clinical Classification Software (CCS) was used to sort 2001 diagnoses into 260 diagnosis categories (DCs). For each plan type (indemnity, PPO, and POS), boosted regression trees and main effects linear models were fitted to predict concurrent (2001) and prospective (2002) total health care cost per patient, given DCs and demographic variables. Regression tree boosting explained 49.7-52.1 percent of concurrent cost variance and 15.2-17.7 percent of prospective cost variance in independent test samples. Corresponding results for main effects linear models were 42.5-47.6 percent and 14.2-16.6 percent. The combination of regression tree boosting and a diagnostic grouping scheme, such as CCS, represents a competitive alternative to risk-adjustment systems that use complex deterministic models to account for interactions among diagnostic groups.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22364,""
"Efficacy of a liver resection for hepatocellular carcinoma in patients with chronic renal failure","Orii, Takayama, Haga, Fukumori, Amada","https://doi.org/10.1007/s00595-007-3634-1","20080828","PubMed","Carcinoma, Hepatocellular; Disease-Free Survival; Female; Follow-Up Studies; Hepatectomy; Humans; Japan; Kidney Failure, Chronic; Liver Neoplasms; Male; Middle Aged; Neoplasm Recurrence, Local; Retrospective Studies; Survival Rate; Time Factors; Treatment Outcome","As there is still little information available on hepatic resection in patients with chronic renal failure (CRF) in the literature, it is believed that a liver resection for HCC in CRF patients with various related complications is always risky. We retrospectively reviewed the clinical and pathological records of 17 patients with CRF who had undergone hepatectomy for HCC, and of 51 non-CRF patients subjected to hepatectomy for HCC during the same period. The operative and pathological findings were comparable between the two groups. Postoperative circulatory insufficiency occurred more frequently in the CRF group (P = 0.013). Although the disease-free survival rates were comparable between the two groups, the overall survival rates were significantly lower in the CRF group than in the non-CRF group (P = 0.031). A hepatectomy for HCC should be considered even for CRF patients with various complications if careful perioperative management and suitable multidisciplinary treatment for recurrent disease are provided.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22365,""
"Estimating hepatitis C prevalence in England and Wales by synthesizing evidence from multiple data sources Assessing data conflict and model fit","Sweeting, De Angelis, Hickman, Ades","https://doi.org/10.1093/biostatistics/kxn004","20081202","PubMed","Age Factors; Algorithms; Bayes Theorem; Bias; Blood Donors; Databases, Factual; England; Female; Hepatitis C; Humans; Likelihood Functions; Male; Markov Chains; Models, Biological; Models, Statistical; Monte Carlo Method; Odds Ratio; Pregnancy; Prevalence; Regression Analysis; Seroepidemiologic Studies; Sex Factors; Substance Abuse, Intravenous; Wales","Multiparameter evidence synthesis is becoming widely used as a way of combining evidence from multiple and often disparate sources of information concerning a number of parameters. Synthesizing data in one encompassing model allows propagation of evidence and learning. We demonstrate the use of such an approach in estimating the number of people infected with the hepatitis C virus (HCV) in England and Wales. Data are obtained from seroprevalence studies conducted in different subpopulations. Each subpopulation is modeled as a composition of 3 main HCV risk groups (current injecting drug users (IDUs), ex-IDUs, and non-IDUs). Further, data obtained on the prevalence (size) of each risk group provide an estimate of the prevalence of HCV in the whole population. We simultaneously estimate all model parameters through the use of Bayesian Markov chain Monte Carlo techniques. The main emphasis of this paper is the assessment of evidence consistency and investigation of the main drivers for model inferences. We consider a cross-validation technique to reveal data conflict and leverage when each data source is in turn removed from the model.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22366,""
"Computer-aided prostate cancer detection using texture features and clinical features in ultrasound image","Han, Lee, Choi","https://doi.org/10.1007/s10278-008-9106-3","20090211","PubMed","Decision Support Techniques; Diagnosis, Computer-Assisted; Fuzzy Logic; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Male; Pattern Recognition, Automated; Prostatic Neoplasms; Sensitivity and Specificity; Ultrasonography, Doppler","In this paper, we propose a new prostate detection method using multiresolution autocorrelation texture features and clinical features such as location and shape of tumor. With the proposed method, we can detect cancerous tissues efficiently with high specificity (about 90-95%)and high sensitivity (about 92-96%) by the measurement of the number of correctly classified pixels. Multiresolution autocorrelation can detect cancerous tissues efficiently, and clinical knowledge helps to discriminate the cancer region by location and shape of the region and increases specificity. The support vector machine is used to classify tissues based on those features. The proposed method will be helpful in formulating a more reliable diagnosis, increasing diagnosis efficiency.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22367,""
"Glutamatergic abnormalities of the thalamus in schizophrenia: a systematic review","Watis, Chen, Chua, Chong, Sim","https://doi.org/10.1007/s00702-007-0859-5","20080701","PubMed","Amino Acid Transport System X-AG; Animals; Glutamic Acid; Humans; Receptors, Glutamate; Schizophrenia; Thalamus","The thalamus, a key information processing centre in facilitating sensory discrimination and cognitive processes, has been implicated in schizophrenia due to the increasing evidence showing structural and functional thalamic abnormalities. Glutamatergic abnormalities, in particular, have been examined since glutamate is one of the main neurotransmitters found in the thalamus. We aimed to review the existing literature (1978 till 2007) on post-mortem and in vivo studies of the various components of glutamatergic neurotransmission as well as studies of the glutamate receptor genes within the thalamus in schizophrenia. The literature search was done using multiple databases including Scopus, Web of Science, EBSCO host, Pubmed and ScienceDirect. Keywords used were ""glutamate"", ""thalamus"", ""schizophrenia"", ""abnormalities"", and ""glutamatergic"". Further searches were made using the bibliographies in the main journals and related papers were obtained. The extant data suggest that abnormalities of the glutamate receptors as well as other molecules involved in glutamatergic neurotransmission (including glutamate transporters and associated proteins, N-methyl D-aspartate (NMDA) receptor-associated intracellular signaling proteins, and glutamatergic enzymes) are found within the thalamus in schizophrenia. There is a pressing need for more rapid replication of findings from post mortem and genetic studies as well as the promotion of multi-component or multi-modality assessments of glutamatergic anomalies within the thalamus in order to allow a better appreciation of disruptions in these molecular networks in schizophrenia. These and future findings may represent potential novel targets for antipsychotic drugs to ameliorate the symptoms of schizophrenia.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22368,""
"Tight glycaemic control by an automated algorithm with time-variant sampling in medical ICU patients","Pachler, Plank, Weinhandl, Chassin, Wilinska, Kulnik, Kaufmann, Smolle, Pilger, Pieber, Ellmerer, Hovorka","https://doi.org/10.1007/s00134-008-1033-8","20081216","PubMed","APACHE; Algorithms; Blood Glucose; Critical Care; Diabetes Mellitus, Type 1; Drug Therapy, Computer-Assisted; Female; Glycemic Index; Humans; Hypoglycemic Agents; Insulin; Insulin Resistance; Intensive Care Units; Male; Middle Aged; Time Factors","Tight glycaemic control (TGC) in critically ill patients improves clinical outcome, but is difficult to establish The primary objective of the present study was to compare glucose control in medical ICU patients applying a computer-based enhanced model predictive control algorithm (eMPC) extended to include time-variant sampling against an implemented glucose management protocol. Open randomised controlled trial. Nine-bed medical intensive care unit (ICU) in a tertiary teaching hospital. Fifty mechanically ventilated medical ICU patients. Patients were included for a study period of up to 72 h. Patients were randomised to the control group (n = 25), treated by an implemented insulin algorithm, or to the eMPC group (n = 25), using the laptop-based algorithm. Target range for blood glucose (BG) was 4.4-6.1 mM. Efficacy was assessed by mean BG, hyperglycaemic index (HGI) and BG sampling interval. Safety was assessed by the number of hypoglycaemic-episodes &lt; 2.2 mM. Each participating nurse filled-in a questionnaire regarding the usability of the algorithm. BG and HGI were significantly lower in the eMPC group [BG 5.9 mM (5.5-6.3), median (IQR); HGI 0.4 mM (0.2-0.9)] than in control patients [BG 7.4 mM (6.9-8.6), p &lt; 0.001; HGI 1.6 mM (1.1-2.4), p &lt; 0.001]. One hypoglycaemic episode was detected in the eMPC group; no such episodes in the control group. Sampling interval was significantly shorter in the eMPC group [eMPC 117[Symbol: see text]min (+/- 34), mean (+/- SD), vs 174 min (+/- 27); p &lt; 0.001]. Thirty-four nurses filled-in the questionnaire. Thirty answered the question of whether the algorithm could be applied in daily routine in the affirmative. The eMPC algorithm was effective in maintaining tight glycaemic control in severely ill medical ICU patients.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22369,""
"Ontology of gaps in content-based image retrieval","Deserno, Antani, Long","https://doi.org/10.1007/s10278-007-9092-x","20090707","PubMed","Databases, Factual; Diagnostic Imaging; Information Storage and Retrieval; Radiology Information Systems; Terminology as Topic; User-Computer Interface","Content-based image retrieval (CBIR) is a promising technology to enrich the core functionality of picture archiving and communication systems (PACS). CBIR has a potential for making a strong impact in diagnostics, research, and education. Research as reported in the scientific literature, however, has not made significant inroads as medical CBIR applications incorporated into routine clinical medicine or medical research. The cause is often attributed (without supporting analysis) to the inability of these applications in overcoming the ""semantic gap."" The semantic gap divides the high-level scene understanding and interpretation available with human cognitive capabilities from the low-level pixel analysis of computers, based on mathematical processing and artificial intelligence methods. In this paper, we suggest a more systematic and comprehensive view of the concept of ""gaps"" in medical CBIR research. In particular, we define an ontology of 14 gaps that addresses the image content and features, as well as system performance and usability. In addition to these gaps, we identify seven system characteristics that impact CBIR applicability and performance. The framework we have created can be used a posteriori to compare medical CBIR systems and approaches for specific biomedical image domains and goals and a priori during the design phase of a medical CBIR application, as the systematic analysis of gaps provides detailed insight in system comparison and helps to direct future research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22370,""
"The strength of co-authorship in gene name disambiguation","Farkas","https://doi.org/10.1186/1471-2105-9-69","20080423","PubMed","Authorship; Classification; Databases, Genetic; Decision Trees; Genes; MEDLINE; Natural Language Processing; Semantics","A biomedical entity mention in articles and other free texts is often ambiguous. For example, 13% of the gene names (aliases) might refer to more than one gene. The task of Gene Symbol Disambiguation (GSD) - a special case of Word Sense Disambiguation (WSD) - is to assign a unique gene identifier for all identified gene name aliases in biology-related articles. Supervised and unsupervised machine learning WSD techniques have been applied in the biomedical field with promising results. We examine here the utilisation potential of the fact - one of the special features of biological articles - that the authors of the documents are known through graph-based semi-supervised methods for the GSD task. Our key hypothesis is that a biologist refers to each particular gene by a fixed gene alias and this holds for the co-authors as well. To make use of the co-authorship information we decided to build the inverse co-author graph on MedLine abstracts. The nodes of the inverse co-author graph are articles and there is an edge between two nodes if and only if the two articles have a mutual author. We introduce here two methods using distances (based on the graph) of abstracts for the GSD task. We found that a disambiguation decision can be made in 85% of cases with an extremely high (99.5%) precision rate just by using information obtained from the inverse co-author graph. We incorporated the co-authorship information into two GSD systems in order to attain full coverage and in experiments our procedure achieved precision of 94.3%, 98.85%, 96.05% and 99.63% on the human, mouse, fly and yeast GSD evaluation sets, respectively. Based on the promising results obtained so far we suggest that the co-authorship information and the circumstances of the articles' release (like the title of the journal, the year of publication) can be a crucial building block of any sophisticated similarity measure among biological articles and hence the methods introduced here should be useful for other biomedical natural language processing tasks (like organism or target disease detection) as well.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22371,""
"Enabling integrative genomic analysis of high-impact human diseases through text mining","Dudley, Butte","https://www.google.com/search?q=Enabling+integrative+genomic+analysis+of+high-impact+human+diseases+through+text+mining.","20080312","PubMed","Computational Biology; Databases, Genetic; Genetic Diseases, Inborn; Genomics; Humans; Information Storage and Retrieval; Oligonucleotide Array Sequence Analysis; PubMed; Unified Medical Language System","Our limited ability to perform large-scale translational discovery and analysis of disease characterizations from public genomic data repositories remains a major bottleneck in efforts to translate genomics experiments to medicine. Through comprehensive, integrative genomic analysis of all available human disease characterizations we gain crucial insight into the molecular phenomena underlying pathogenesis as well as intra- and inter-disease differentiation. Such knowledge is crucial in the development of improved clinical diagnostics and the identification of molecular targets for novel therapeutics. In this study we build on our previous work to realize the next important step in large-scale translational discovery and analysis, which is to automatically identify those genomic experiments in which a disease state is compared to a normal control state. We present an automated text mining method that employs Natural Language Processing (NLP) techniques to automatically identify disease-related experiments in the NCBI Gene Expression Omnibus (GEO) that include measurements for both disease and normal control states. In this manner, we find that 62% of disease-related experiments contain sample subsets that can be automatically identified as normal controls. Furthermore, we calculate that the identified experiments characterize diseases that contribute to 30% of all human disease-related mortality in the United States. This work demonstrates that we now have the necessary tools and methods to initiate large-scale translational bioinformatics inquiry across the broad spectrum of high-impact human disease.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22372,""
"Compassion in jewish, christian and secular nursing A systematic comparison of a key concept of nursing (part I)","KÃƒÂ¤ppeli","https://www.google.com/search?q=Compassion+in+jewish,+christian+and+secular+nursing.+A+systematic+comparison+of+a+key+concept+of+nursing+(part+I).","20130805","PubMed","Caring; Compassion; Nursing ethics; Religious and secular nursing","The topos of the Compassionate God is a dominant motive of the Jewish and Christian traditions. It is relevant for nursing because it asks the nurse to imitate God so as to become God-like. Also, to think that God suffers with the suffering believers is thought to give comfort to them. Because in the western world the topos of the Compassionate God represents the basis of the ethics of compassion/caring, this piece of basic research is important for clinical practice. This study explores to what extent Jewish and Christian nursing adhered to the biblical topos of the Compassionate God at different periods and in different cultural contexts. A mixed methods approach was used. It included variations of hermeneutical text analysis as used in historical, philosophical, theological, science of religion, and nursing research. The analysis of the literary sources shows that the topos of the Compassionate God was interpreted differently in different cultural contexts. However, at all times it directed religious and secular nursing. Since the beginning of the 21(st) century it builds the core of ""compassionate caring"" as propagated by North American nursing science. The topos of the Compassionate God laid the foundation of the tradition of the ethics of compassion in nursing. More research is required to learn whether it also plays a role in Islamic nursing.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22373,""
"AUTOMATED COMPARISON OF PROTEIN SUBCELLULAR LOCATION PATTERNS BETWEEN IMAGES OF NORMAL AND CANCEROUS TISSUES","Glory, Newberg, Murphy","https://doi.org/10.1109/ISBI.2008.4540993","20211020","PubMed","","Early cancer diagnosis and evaluation of cancer progression during treatment are two important factors for clinical therapy. In this study we propose a novel approach which automatically compares the subcellular location of proteins between normal and cancerous tissues in order to identify proteins whose distribution is modified by oncogenesis. This study analyzes 258 proteins in 14 different cancer tissues and their corresponding normal tissues using images provided by the tissue microarray collection of the Human Protein Atlas. Using texture features automatically extracted from the tissue images, 14 machine classifiers were trained to recognize the patterns of eight major organelles in each tissue. For each tissue-protein combination, the results of the classifier for normal and cancerous tissues were compared. Eleven proteins were identified as showing differences in location; these proteins may have potential as biomarkers.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22374,""
"Automatic classification of foot examination findings using clinical notes and machine learning","Pakhomov, Hanson, Bjornsen, Smith","https://doi.org/10.1197/jamia.M2585","20080429","PubMed","Artificial Intelligence; Data Collection; Diabetes Complications; Feasibility Studies; Foot; Foot Diseases; Humans; Medical Records Systems, Computerized; Physical Examination; Quality Assurance, Health Care; Reproducibility of Results; Subject Headings","We examine the feasibility of a machine learning approach to identification of foot examination (FE) findings from the unstructured text of clinical reports. A Support Vector Machine (SVM) based system was constructed to process the text of physical examination sections of in- and out-patient clinical notes to identify if the findings of structural, neurological, and vascular components of a FE revealed normal or abnormal findings or were not assessed. The system was tested on 145 randomly selected patients for each FE component using 10-fold cross validation. The accuracy was 80%, 87% and 88% for structural, neurological, and vascular component classifiers, respectively. Our results indicate that using machine learning to identify FE findings from clinical reports is a viable alternative to manual review and warrants further investigation. This application may improve quality and safety by providing inexpensive and scalable methodology for quality and risk factor assessments at the point of care.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22375,""
"A de-identifier for medical discharge summaries","Uzuner, Sibanda, Luo, Szolovits","https://doi.org/10.1016/j.artmed.2007.10.001","20080610","PubMed","Biomedical Research; Confidentiality; Humans; Medical Records Systems, Computerized; Natural Language Processing; Patient Discharge; Pattern Recognition, Automated; Semantics","Clinical records contain significant medical information that can be useful to researchers in various disciplines. However, these records also contain personal health information (PHI) whose presence limits the use of the records outside of hospitals. The goal of de-identification is to remove all PHI from clinical records. This is a challenging task because many records contain foreign and misspelled PHI; they also contain PHI that are ambiguous with non-PHI. These complications are compounded by the linguistic characteristics of clinical records. For example, medical discharge summaries, which are studied in this paper, are characterized by fragmented, incomplete utterances and domain-specific language; they cannot be fully processed by tools designed for lay language. In this paper, we show that we can de-identify medical discharge summaries using a de-identifier, Stat De-id, based on support vector machines and local context (F-measure=97% on PHI). Our representation of local context aids de-identification even when PHI include out-of-vocabulary words and even when PHI are ambiguous with non-PHI within the same corpus. Comparison of Stat De-id with a rule-based approach shows that local context contributes more to de-identification than dictionaries combined with hand-tailored heuristics (F-measure=85%). Comparison with two well-known named entity recognition (NER) systems, SNoW (F-measure=94%) and IdentiFinder (F-measure=36%), on five representative corpora show that when the language of documents is fragmented, a system with a relatively thorough representation of local context can be a more effective de-identifier than systems that combine (relatively simpler) local context with global context. Comparison with a Conditional Random Field De-identifier (CRFD), which utilizes global context in addition to the local context of Stat De-id, confirms this finding (F-measure=88%) and establishes that strengthening the representation of local context may be more beneficial for de-identification than complementing local with global context.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22376,""
"Evaluation of automated and semi-automated scoring of polysomnographic recordings from a clinical trial using zolpidem in the treatment of insomnia","Svetnik, Ma, Soper, Doran, Renger, Deacon, Koblan","https://doi.org/10.1093/sleep/30.11.1562","20080219","PubMed","Adolescent; Adult; Double-Blind Method; Electroencephalography; Electronic Data Processing; Female; Humans; Hypnotics and Sedatives; Male; Middle Aged; Polysomnography; Pyridines; Sleep Initiation and Maintenance Disorders; Sleep, REM; Zolpidem","To evaluate the performance of 2 automated systems, Morpheus and Somnolyzer24X7, with various levels of human review/editing, in scoring polysomnographic (PSG) recordings from a clinical trial using zolpidem in a model of transient insomnia. 164 all-night PSG recordings from 82 subjects collected during 2 nights of sleep, one under placebo and one under zolpidem (10 mg) treatment were used. For each recording, 6 different methods were used to provide sleep stage scores based on Rechtschaffen &amp; Kales criteria: 1) full manual scoring, 2) automated scoring by Morpheus 3) automated scoring by Somnolyzer24X7, 4) automated scoring by Morpheus with full manual review, 5) automated scoring by Morpheus with partial manual review, 6) automated scoring by Somnolyzer24X7 with partial manual review. Ten traditional clinical efficacy measures of sleep initiation, maintenance, and architecture were calculated. Pair-wise epoch-by-epoch agreements between fully automated and manual scores were in the range of intersite manual scoring agreements reported in the literature (70%-72%). Pair-wise epoch-by-epoch agreements between automated scores manually reviewed were higher (73%-76%). The direction and statistical significance of treatment effect sizes using traditional efficacy endpoints were essentially the same whichever method was used. As the degree of manual review increased, the magnitude of the effect size approached those estimated with fully manual scoring. Automated or semi-automated sleep PSG scoring offers valuable alternatives to costly, time consuming, and intrasite and intersite variable manual scoring, especially in large multicenter clinical trials. Reduction in scoring variability may also reduce the sample size of a clinical trial.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22377,""
"VIOLIN: vaccine investigation and online information network","Xiang, Todd, Ku, Kovacic, Larson, Chen, Hodges, Tian, Olenzek, Zhao, Colby, Rush, Gilsdorf, Jourdian, He","https://doi.org/10.1093/nar/gkm1039","20080317","PubMed","Animals; Databases, Factual; Humans; Information Services; Internet; PubMed; Sequence Alignment; User-Computer Interface; Vaccines","Vaccines are among the most efficacious and cost-effective tools for reducing morbidity and mortality caused by infectious diseases. The vaccine investigation and online information network (VIOLIN) is a web-based central resource, allowing easy curation, comparison and analysis of vaccine-related research data across various human pathogens (e.g. Haemophilus influenzae, human immunodeficiency virus (HIV) and Plasmodium falciparum) of medical importance and across humans, other natural hosts and laboratory animals. Vaccine-related peer-reviewed literature data have been downloaded into the database from PubMed and are searchable through various literature search programs. Vaccine data are also annotated, edited and submitted to the database through a web-based interactive system that integrates efficient computational literature mining and accurate manual curation. Curated information includes general microbial pathogenesis and host protective immunity, vaccine preparation and characteristics, stimulated host responses after vaccination and protection efficacy after challenge. Vaccine-related pathogen and host genes are also annotated and available for searching through customized BLAST programs. All VIOLIN data are available for download in an eXtensible Markup Language (XML)-based data exchange format. VIOLIN is expected to become a centralized source of vaccine information and to provide investigators in basic and clinical sciences with curated data and bioinformatics tools for vaccine research and development. VIOLIN is publicly available at http://www.violinet.org.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22378,""
"A multi-level model of information seeking in the clinical domain","Hung, Johnson, Kaufman, MendonÃƒÂ§a","https://doi.org/10.1016/j.jbi.2007.09.005","20080416","PubMed","Clinical Medicine; Computer Simulation; Database Management Systems; Databases, Factual; Decision Support Systems, Clinical; Information Storage and Retrieval; Models, Theoretical; User-Computer Interface","Clinicians often have difficulty translating information needs into effective search strategies to find appropriate answers. Information retrieval systems employing an intelligent search agent that generates adaptive search strategies based on human search expertise could be helpful in meeting clinician information needs. A prerequisite for creating such systems is an information seeking model that facilitates the representation of human search expertise. The purpose of developing such a model is to provide guidance to information seeking system development and to shape an empirical research program. The information seeking process was modeled as a complex problem-solving activity. After considering how similarly complex activities had been modeled in other domains, we determined that modeling context-initiated information seeking across multiple problem spaces allows the abstraction of search knowledge into functionally consistent layers. The knowledge layers were identified in the information science literature and validated through our observations of searches performed by health science librarians. A hierarchical multi-level model of context-initiated information seeking is proposed. Each level represents (1) a problem space that is traversed during the online search process, and (2) a distinct layer of knowledge that is required to execute a successful search. Grand strategy determines what information resources will be searched, for what purpose, and in what order. The strategy level represents an overall approach for searching a single resource. Tactics are individual moves made to further a strategy. Operations are mappings of abstract intentions to information resource-specific concrete input. Assessment is the basis of interaction within the strategic hierarchy, influencing the direction of the search. The described multi-level model provides a framework for future research and the foundation for development of an automated information retrieval system that uses an intelligent search agent to bridge clinician information needs and human search expertise.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22379,""
"Predicting combinatorial binding of transcription factors to regulatory elements in the human genome by association rule mining","Morgan, Ni, Miranker, Iyer","https://doi.org/10.1186/1471-2105-8-445","20080207","PubMed","Algorithms; Binding Sites; Databases, Factual; Electronic Data Processing; Forecasting; Gene Expression Profiling; Genome, Human; Humans; Microarray Analysis; Models, Biological; Protein Binding; Regulatory Elements, Transcriptional; Transcription Factors","Cis-acting transcriptional regulatory elements in mammalian genomes typically contain specific combinations of binding sites for various transcription factors. Although some cis-regulatory elements have been well studied, the combinations of transcription factors that regulate normal expression levels for the vast majority of the 20,000 genes in the human genome are unknown. We hypothesized that it should be possible to discover transcription factor combinations that regulate gene expression in concert by identifying over-represented combinations of sequence motifs that occur together in the genome. In order to detect combinations of transcription factor binding motifs, we developed a data mining approach based on the use of association rules, which are typically used in market basket analysis. We scored each segment of the genome for the presence or absence of each of 83 transcription factor binding motifs, then used association rule mining algorithms to mine this dataset, thus identifying frequently occurring pairs of distinct motifs within a segment. Support for most pairs of transcription factor binding motifs was highly correlated across different chromosomes although pair significance varied. Known true positive motif pairs showed higher association rule support, confidence, and significance than background. Our subsets of high-confidence, high-significance mined pairs of transcription factors showed enrichment for co-citation in PubMed abstracts relative to all pairs, and the predicted associations were often readily verifiable in the literature. Functional elements in the genome where transcription factors bind to regulate expression in a combinatorial manner are more likely to be predicted by identifying statistically and biologically significant combinations of transcription factor binding motifs than by simply scanning the genome for the occurrence of binding sites for a single transcription factor.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22380,""
"An electronic health record based on structured narrative","Johnson, Bakken, Dine, Hyun, MendonÃƒÂ§a, Morrison, Bright, Van Vleck, Wrenn, Stetson","https://doi.org/10.1197/jamia.M2131","20080205","PubMed","Documentation; Humans; Information Storage and Retrieval; Medical History Taking; Medical Records Systems, Computerized; Natural Language Processing; Software; Systems Integration; User-Computer Interface; Vocabulary, Controlled","To develop an electronic health record that facilitates rapid capture of detailed narrative observations from clinicians, with partial structuring of narrative information for integration and reuse. We propose a design in which unstructured text and coded data are fused into a single model called structured narrative. Each major clinical event (e.g., encounter or procedure) is represented as a document that is marked up to identify gross structure (sections, fields, paragraphs, lists) as well as fine structure within sentences (concepts, modifiers, relationships). Marked up items are associated with standardized codes that enable linkage to other events, as well as efficient reuse of information, which can speed up data entry by clinicians. Natural language processing is used to identify fine structure, which can reduce the need for form-based entry. The model is validated through an example of use by a clinician, with discussion of relevant aspects of the user interface, data structures and processing rules. The proposed model represents all patient information as documents with standardized gross structure (templates). Clinicians enter their data as free text, which is coded by natural language processing in real time making it immediately usable for other computation, such as alerts or critiques. In addition, the narrative data annotates and augments structured data with temporal relations, severity and degree modifiers, causal connections, clinical explanations and rationale. Structured narrative has potential to facilitate capture of data directly from clinicians by allowing freedom of expression, giving immediate feedback, supporting reuse of clinical information and structuring data for subsequent processing, such as quality assurance and clinical research.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22381,""
"Identifying patient smoking status from medical discharge records","Uzuner, Goldstein, Luo, Kohane","https://doi.org/10.1197/jamia.M2408","20080205","PubMed","Classification; Humans; Medical Records; Medical Records Systems, Computerized; Natural Language Processing; Patient Discharge; Smoking","The authors organized a Natural Language Processing (NLP) challenge on automatically determining the smoking status of patients from information found in their discharge records. This challenge was issued as a part of the i2b2 (Informatics for Integrating Biology to the Bedside) project, to survey, facilitate, and examine studies in medical language understanding for clinical narratives. This article describes the smoking challenge, details the data and the annotation process, explains the evaluation metrics, discusses the characteristics of the systems developed for the challenge, presents an analysis of the results of received system runs, draws conclusions about the state of the art, and identifies directions for future research. A total of 11 teams participated in the smoking challenge. Each team submitted up to three system runs, providing a total of 23 submissions. The submitted system runs were evaluated with microaveraged and macroaveraged precision, recall, and F-measure. The systems submitted to the smoking challenge represented a variety of machine learning and rule-based algorithms. Despite the differences in their approaches to smoking status identification, many of these systems provided good results. There were 12 system runs with microaveraged F-measures above 0.84. Analysis of the results highlighted the fact that discharge summaries express smoking status using a limited number of textual features (e.g., ""smok"", ""tobac"", ""cigar"", Social History, etc.). Many of the effective smoking status identifiers benefit from these features.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22382,""
"Mayo clinic NLP system for patient smoking status identification","Savova, Ogren, Duffy, Buntrock, Chute","https://doi.org/10.1197/jamia.M2437","20080205","PubMed","Classification; Databases, Factual; Humans; Medical Records Systems, Computerized; Natural Language Processing; Smoking","This article describes our system entry for the 2006 I2B2 contest ""Challenges in Natural Language Processing for Clinical Data"" for the task of identifying the smoking status of patients. Our system makes the simplifying assumption that patient-level smoking status determination can be achieved by accurately classifying individual sentences from a patient's record. We created our system with reusable text analysis components built on the Unstructured Information Management Architecture and Weka. This reuse of code minimized the development effort related specifically to our smoking status classifier. We report precision, recall, F-score, and 95% exact confidence intervals for each metric. Recasting the classification task for the sentence level and reusing code from other text analysis projects allowed us to quickly build a classification system that performs with a system F-score of 92.64 based on held-out data tests and of 85.57 on the formal evaluation data. Our general medical natural language engine is easily adaptable to a real-world medical informatics application. Some of the limitations as applied to the use-case are negation detection and temporal resolution.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22383,""
"Medical i2b2 NLP smoking challenge: the A-Life system architecture and methodology","Heinze, Morsch, Potter, Sheffer","https://doi.org/10.1197/jamia.M2438","20080205","PubMed","Classification; Humans; Medical Records Systems, Computerized; Natural Language Processing; Smoking; Software","We describe the architecture of LifeCode (A-Life Medical, Inc.), a natural language processing system for free-text clinical information extraction, our methodology in applying LifeCode to the i2b2 smoking challenge, and statistical measures for performance evaluation. Due to the limited test size and the coefficient of variation in the test standard, it is difficult to draw conclusions regarding the relative efficacy of approaches that were applied to this challenge.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22384,""
"The evaluation of a temporal reasoning system in processing clinical discharge summaries","Zhou, Parsons, Hripcsak","https://doi.org/10.1197/jamia.M2467","20080205","PubMed","Forms and Records Control; Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Natural Language Processing; Patient Discharge; Time","TimeText is a temporal reasoning system designed to represent, extract, and reason about temporal information in clinical text. To measure the accuracy of the TimeText for processing clinical discharge summaries. Six physicians with biomedical informatics training served as domain experts. Twenty discharge summaries were randomly selected for the evaluation. For each of the first 14 reports, 5 to 8 clinically important medical events were chosen. The temporal reasoning system generated temporal relations about the endpoints (start or finish) of pairs of medical events. Two experts (subjects) manually generated temporal relations for these medical events. The system and expert-generated results were assessed by four other experts (raters). All of the twenty discharge summaries were used to assess the system's accuracy in answering time-oriented clinical questions. For each report, five to ten clinically plausible temporal questions about events were generated. Two experts generated answers to the questions to serve as the gold standard. We wrote queries to retrieve answers from system's output. Correctness of generated temporal relations, recall of clinically important relations, and accuracy in answering temporal questions. The raters determined that 97% of subjects' 295 generated temporal relations were correct and that 96.5% of the system's 995 generated temporal relations were correct. The system captured 79% of 307 temporal relations determined to be clinically important by the subjects and raters. The system answered 84% of the temporal questions correctly. The system encoded the majority of information identified by experts, and was able to answer simple temporal questions.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22385,""
"Health economic evaluation of ferucarbotran-enhanced MRI in the diagnosis of liver metastases in colorectal cancer patients","Annemans, Lencioni, Warie, Bartolozzi, Ciceri, MÃƒÂ¼ller","https://doi.org/10.1007/s00384-007-0350-7","20090109","PubMed","Colorectal Neoplasms; Contrast Media; Cost Savings; Cost-Benefit Analysis; Decision Trees; Dextrans; Europe; Ferrosoferric Oxide; Health Care Costs; Humans; Injections, Intravenous; Iron; Life Expectancy; Liver Neoplasms; Magnetic Resonance Imaging; Magnetite Nanoparticles; Models, Economic; Oxides; Predictive Value of Tests; Tomography, Spiral Computed; Treatment Outcome; Unnecessary Procedures","The objective of our study was to analyze the health economic impact of ferucarbotran-enhanced magnetic resonance imaging (MRI) in the diagnosis of hepatic colorectal cancer metastases based on observed changes in medical management. A decision tree simulating a patient's medical management was designed, comparing two scenarios: contrast-enhanced spiral computed tomography-based vs ferucarbotran-enhanced MRI-based (Resovist, Bayer Schering Pharma AG, Germany) diagnosis. A clinical trial in patients with presumed liver metastases (n=36) provided data on clinical decisions regarding the medical management options in relation to diagnostic outcomes: resection, chemotherapy, or best supportive care. A ""gold standard"" was established afterward, combining all the available clinical, imaging, laboratory, and pathology findings. A multidisciplinary panel formed by a hepatologist, a liver surgeon, and an interventional radiologist decided on the recommended medical management for each patient. Costs of medical resources associated with each management option (all expressed in Euro) were obtained from the public health insurance (average European values). Life expectancies for the different options were obtained from literature. Despite an initial extra cost of 338 Euro, a significant net saving of 1,443 Euro was obtained with ferucarbotran-enhanced MRI mainly because of avoiding unnecessary surgery. There was no significant difference in the predicted life expectancy between both arms, despite the large difference in medical decision. In this comparative medical decision analysis, it was shown that ferucarbotran-enhanced MRI has the potential to improve medical management and save health care costs.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22386,""
"Assessing the difficulty and time cost of de-identification in clinical narratives","Dorr, Phillips, Phansalkar, Sims, Hurdle","https://www.google.com/search?q=Assessing+the+difficulty+and+time+cost+of+de-identification+in+clinical+narratives.","20060705","PubMed","Confidentiality; Costs and Cost Analysis; Health Insurance Portability and Accountability Act; Humans; Medical Record Linkage; Narration; Natural Language Processing; United States; Utah","To characterize the difficulty confronting investigators in removing protected health information (PHI) from cross-discipline, free-text clinical notes, an important challenge to clinical informatics research as recalibrated by the introduction of the US Health Insurance Portability and Accountability Act (HIPAA) and similar regulations. Randomized selection of clinical narratives from complete admissions written by diverse providers, reviewed using a two-tiered rater system and simple automated regular expression tools. For manual review, two independent reviewers used simple search and replace algorithms and visual scanning to find PHI as defined by HIPAA, followed by an independent second review to detect any missed PHI. Simple automated review was also performed for the ""easy"" PHI that are number- or date-based. From 262 notes, 2074 PHI, or 7.9 +/- 6.1 per note, were found. The average recall (or sensitivity) was 95.9% while precision was 99.6% for single reviewers. Agreement between individual reviewers was strong (ICC = 0.99), although some asymmetry in errors was seen between reviewers (p = 0.001). The automated technique had better recall (98.5%) but worse precision (88.4%) for its subset of identifiers. Manually de-identifying a note took 87.3 +/- 61 seconds on average. Manual de-identification of free-text notes is tedious and time-consuming, but even simple PHI is difficult to automatically identify with the exactitude required under HIPAA.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22387,""
"Progressive increase of frontostriatal brain activation from childhood to adulthood during event-related tasks of cognitive control","Rubia, Smith, Woolley, Nosarti, Heyman, Taylor, Brammer","https://doi.org/10.1002/hbm.20237","20070123","PubMed","Adolescent; Adult; Age Factors; Analysis of Variance; Attention; Brain; Brain Mapping; Child; Choice Behavior; Cognition; Corpus Striatum; Functional Laterality; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Nerve Net; Neuropsychological Tests; Oxygen","Higher cognitive inhibitory and attention functions have been shown to develop throughout adolescence, presumably concurrent with anatomical brain maturational changes. The relatively scarce developmental functional imaging literature on cognitive control, however, has been inconsistent with respect to the neurofunctional substrates of this cognitive development, finding either increased or decreased executive prefrontal function in the progression from childhood to adulthood. Such inconsistencies may be due to small subject numbers or confounds from age-related performance differences in block design functional MRI (fMRI). In this study, rapid, randomized, mixed-trial event-related fMRI was used to investigate developmental differences of the neural networks mediating a range of motor and cognitive inhibition functions in a sizeable number of adolescents and adults. Functional brain activation was compared between adolescents and adults during three different executive tasks measuring selective motor response inhibition (Go/no-go task), cognitive interference inhibition (Simon task), and attentional set shifting (Switch task). Adults compared with children showed increased brain activation in task-specific frontostriatal networks, including right orbital and mesial prefrontal cortex and caudate during the Go/no-go task, right mesial and inferior prefrontal cortex, parietal lobe, and putamen during the Switch task and left dorsolateral and inferior frontotemporoparietal regions and putamen during the Simon task. Whole-brain regression analyses with age across all subjects showed progressive age-related changes in similar and extended clusters of task-specific frontostriatal, frontotemporal, and frontoparietal networks. The findings suggest progressive maturation of task-specific frontostriatal and frontocortical networks for cognitive control functions in the transition from childhood to mid-adulthood.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22388,""
"Primary histologic diagnosis using automated whole slide imaging: a validation study","Gilbertson, Ho, Anthony, Jukic, Yagi, Parwani","https://doi.org/10.1186/1472-6890-6-4","20070618","PubMed","","Only prototypes 5 years ago, high-speed, automated whole slide imaging (WSI) systems (also called digital slide systems, virtual microscopes or wide field imagers) are becoming increasingly capable and robust. Modern devices can capture a slide in 5 minutes at spatial sampling periods of less than 0.5 micron/pixel. The capacity to rapidly digitize large numbers of slides should eventually have a profound, positive impact on pathology. It is important, however, that pathologists validate these systems during development, not only to identify their limitations but to guide their evolution. Three pathologists fully signed out 25 cases representing 31 parts. The laboratory information system was used to simulate real-world sign-out conditions including entering a full diagnostic field and comment (when appropriate) and ordering special stains and recuts. For each case, discrepancies between diagnoses were documented by committee and a ""consensus"" report was formed and then compared with the microscope-based, sign-out report from the clinical archive. In 17 of 25 cases there were no discrepancies between the individual study pathologist reports. In 8 of the remaining cases, there were 12 discrepancies, including 3 in which image quality could be at least partially implicated. When the WSI consensus diagnoses were compared with the original sign-out diagnoses, no significant discrepancies were found. Full text of the pathologist reports, the WSI consensus diagnoses, and the original sign-out diagnoses are available as an attachment to this publication. The results indicated that the image information contained in current whole slide images is sufficient for pathologists to make reliable diagnostic decisions and compose complex diagnostic reports. This is a very positive result; however, this does not mean that WSI is as good as a microscope. Virtually every slide had focal areas in which image quality (focus and dynamic range) was less than perfect. In some cases, there was evidence of over-compression and regions made ""soft"" by less than perfect focus. We expect systems will continue to get better, image quality and speed will continue to improve, but that further validation studies will be needed to guide development of this promising technology.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22389,""
"Postural instability and consequent falls and hip fractures associated with use of hypnotics in the elderly: a comparative review","Allain, BentuÃƒÂ©-Ferrer, Polard, Akwa, Patat","https://doi.org/10.2165/00002512-200522090-00004","20060321","PubMed","Accidental Falls; Acetamides; Aged; Aged, 80 and over; Azabicyclo Compounds; Benzodiazepines; Case-Control Studies; Hip Fractures; Humans; Hypnotics and Sedatives; Pharmacoepidemiology; Piperazines; Postural Balance; Posture; Prospective Studies; Pyridines; Pyrimidines; Retrospective Studies; Risk Assessment; Sleep Initiation and Maintenance Disorders; Zolpidem","The aim of this review is to establish the relationship between treatment with hypnotics and the risk of postural instability and as a consequence, falls and hip fractures, in the elderly. A review of the literature was performed through a search of the MEDLINE, Ingenta and PASCAL databases from 1975 to 2005. We considered as hypnotics only those drugs approved for treating insomnia, i.e. some benzodiazepines and the more recently launched 'Z'-compounds, i.e. zopiclone, zolpidem and zaleplon. Large-scale surveys consistently report increases in the frequency of falls and hip fractures when hypnotics are used in the elderly (2-fold risk). Benzodiazepines are the major class of hypnotics involved in this context; falls and fractures in patients taking Z-compounds are less frequently reported, and in this respect, zolpidem is considered as at risk in only one study. It is important to note, however, that drug adverse effect relationships are difficult to establish with this type of epidemiological data-mining. On the other hand, data obtained in laboratory settings, where confounding factors can be eliminated, prove that benzodiazepines are the most deleterious hypnotics at least in terms of their effects on body sway. Z-compounds are considered safer, probably because of their pharmacokinetic properties as well as their selective pharmacological activities at benzodiazepine-1 (BZ(1)) receptors. The effects of hypnotics on balance, gait and equilibrium are the consequence of differential negative impacts on vigilance and cognitive functions, and are highly dose- and time-dependent. Z-compounds have short half-lives and have less cognitive and residual effects than older medications. Some practical rules need to be followed when prescribing hypnotics in order to prevent falls and hip fractures as much as possible in elderly insomniacs, whether institutionalised or not. These are: (i) establish a clear diagnosis of the sleep disorder; (ii) take into account chronic conditions leading to balance and gait difficulties (motor and cognitive status); (iii) search for concomitant prescription of psychotropics and sedatives; (iv) use half the recommended adult dosage; and (v) declare any adverse effect to pharmacovigilance centres. Comparative pharmacovigilance studies focused on the impact of hypnotics on postural stability are very much needed.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22390,""
"Epidemiology of human pulmonary infection with nontuberculous mycobacteria","Marras, Daley","https://doi.org/10.1016/s0272-5231(02)00019-9","20030128","PubMed","Global Health; Humans; Mycobacterium Infections, Nontuberculous; Nontuberculous Mycobacteria; Risk Factors; Tuberculosis, Pulmonary","A great deal of study has gone into the assessment of the epidemiology of NTM infection and disease in many different parts of the world. Review of the available studies provides insight into the frequency of this clinical problem as well as important limitations in current data. Study methods have varied greatly, undoubtedly leading to differing biases. In general, reported rates of infection and disease are likely underestimates, with the former probably less accurate than the latter, given that people without significant symptoms are not likely to have intensive investigations to detect infection. Pulmonary NTM is a problem with differing rates in various parts of the world. North American rates of infection and disease have been reported to range from approximately 1-15 per 100,000 and 0.1-2 per 100,000, respectively (see Table 1). Rates have been observed to increase with coincident decreases in TB. MAC has been reported most commonly, followed by rapid growers and M kansasii. Generally similar rates have been reported in European studies, with the exception of extremely high rates in an area of the Czech Republic where mining is the dominant industry (see Table 2). These studies have also shown marked geographic variability in prevalence. The only available population-based studies have been in South Africa and report extremely high rates of infection, three orders of magnitude greater than studies from other parts of the world (see Table 3). This undoubtedly reflects the select population with an extremely high rate of TB and resultant bronchiectasis leading to NTM infection. Rates in Japan and Australia were similar to those reported in Europe and North America and also show significant increases over time (see Table 3). Specific risk factors have been identified in several studies. CF and HIV, mentioned above, are two important high-risk groups. Other important factors include underlying chronic lung disease, work in the mining industry, warm climate, advancing age, and male sex. Aside from HIV and CF, mining with associated high rates of pneumoconiosis and previous TB may be the most important historically, reported in studies worldwide [63]. A recurring observation is the increase in rates of infection and disease. The reason for this is unclear but may be caused by any of several contributing factors. The possibility exists that the apparent increase is either spurious or less significant than studies would suggest. Changes in clinician awareness leading to increased investigations, or laboratory methods leading to isolation and identification of previously unnoticed organisms, could play a role in this trend, and studies have been published that support [67] and refute [31] this argument. We believe such factors may contribute to but do not explain the significant increases that have been observed. A true increase could be related to the host, the pathogen, or some interaction between the two. Host changes leading to increased susceptibility could play an important role, with increased numbers of patients with inadequate defenses from diseases such as HIV infection, malignancy, or simply advanced age [31]. An increase in susceptibility could also relate to the decrease in infection with two other mycobacteria. It has been speculated that infection with TB [29,38] and Bacillus Calmette-Guerin (BCG) [19,68] may provide cross-immunity protecting against NTM infection. Many investigations have observed decreasing rates of TB concomitant with the increases in NTM. In addition, studies from Sweden [68] and the Czech Republic [19] have found that children who were not vaccinated with BCG had a far higher rate of extrapulmonary NTM infection. Potential changes in the pathogens include increases in NTM virulence, and it has been argued that this should be considered as a possible contributing factor [69]. Finally, an interaction between the host and pathogen could involve a major increase in pathogen exposure or potential inoculum size. This may be occurring secondary to the increase in popularity of showering as a form of bathing [66], a habit that greatly increases respiratory exposure to water contaminants. Several limitations of our review should be noted. We reviewed English-language reports and abstracts, probably leading to fewer data from non-English speaking regions, which may explain the paucity of studies from Africa, Eastern Europe, and most Asian nations. The heterogeneity of study methods in identifying cases and the lack of a uniformly applied definition of disease makes it difficult to compare rates between studies. Finally, the lack of systematic reporting of NTM infection in most nations limits the ability to derive accurate estimates of infection and disease. Regardless, there are more than adequate data to conclude that NTM disease rates vary widely depending on population and geographic location. NTM disease is clearly a major problem in certain groups, including patients with underlying lung disease and also in individuals with impaired immunity. The rates of NTM infection and disease are increasing, so the problem will likely continue to grow and become a far more important issue than current rates suggest.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22391,""
"Guglielmi detachable coil embolization for unruptured aneurysms in nonsurgical candidates: a cost-effectiveness exploration","Kallmes, Kallmes, Cloft, Dion","https://www.google.com/search?q=Guglielmi+detachable+coil+embolization+for+unruptured+aneurysms+in+nonsurgical+candidates:+a+cost-effectiveness+exploration.","19980320","PubMed","Cost-Benefit Analysis; Decision Trees; Embolization, Therapeutic; Humans; Intracranial Aneurysm; Life Expectancy; Markov Chains; Quality of Life","We calculated the incremental cost-utility ratio for Guglielmi detachable coil (GDC) embolization versus no therapy for unruptured intracranial aneurysms considered inappropriate for surgical clipping procedures. Decision tree and Markov analyses that employ cohort simulation were applied to determine the incremental cost-utility ratio of GDC embolization versus no therapy for unruptured cerebral aneurysms. Clinical values required as input data were estimated from the literature for the following variables: relative frequencies of complete aneurysmal occlusion, partial aneurysmal occlusion, and attempted coiling (no coils detached); morbidity and mortality of GDC embolization; frequency, morbidity, and mortality of spontaneous aneurysmal rupture in untreated and GDC-embolized aneurysms; annual rate of recanalization of GDC-embolized aneurysms; quality of life when knowingly living with untreated or GDG-embolized aneurysms and of living with fixed neurologic deficit; costs of GDC embolization, spontaneous aneurysmal rupture, stroke, and rehabilitation; and discount rate. Cost-utility ratios below $50000 per quality-adjusted life year saved were considered acceptable. Sensitivity analyses were performed for all relevant input variables. Baseline input values resulted in acceptable cost-utility ratios for GDC embolization of unruptured intracranial aneurysms. These ratios remained within acceptable limits across wide ranges of various input parameters. Cost-effectiveness was markedly affected by the natural course of unruptured, untreated aneurysms; rates of spontaneous rupture greater than 2% per year resulted in favorable cost-utility ratios that were relatively unaffected by variation in GDC efficacy, while rates of rupture less than 1% per year resulted in unfavorable ratios that were highly dependent on GDC efficacy. Many of the GDC efficacy indexes, such as rate of failed coiling, early recanalization, and progressive aneurysmal thrombosis, have mild effects on the cost-utility ratios. GDC complication rate as well as life expectancy had moderate effects on the analysis. The influence of late aneurysmal recanalization was mild unless high rates of rupture for partially coiled aneurysms were applied. Suboptimal clip placement resulting from the presence of GDC coils within a ruptured aneurysm had no demonstrable consequence on cost-utility ratios. The single most influential variable determining the cost-effectiveness of GDC embolization in our analysis was the natural course of untreated aneurysms. Other important variables included GDC-related morbidity and life expectancy at the time of GDC embolization.","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22392,""
"Decision support in healthcare","Clayton, Hripcsak","https://doi.org/10.1016/0020-7101(94)01080-k","19950810","PubMed","Decision Making, Computer-Assisted; Decision Support Techniques; Diagnosis, Computer-Assisted; Expert Systems; Humans; Information Systems; MEDLINE; Therapy, Computer-Assisted","To address the recognized problems associated with information overload and limited human memory, computer-based systems which help healthcare providers use information to make better decisions have been developed and implemented. These decision aids are designed to improve the quality and reduce the cost of healthcare. Currently, the most widely used computer application is to simply provide needed facts about the patient in an organized and timely fashion. Additionally, healthcare workers can access literature, ask questions of aggregates of patient data for clinical or administrative decisions, receive warnings or suggestions when the patient's data satisfy certain logical rules receive critiques when proposing therapies or ordering diagnostic tests, receive guidelines for standards of care, access programs which analyze tradeoffs and likelihoods of alternative outcomes (decision analysis) and receive lists of differential diagnoses. Given this wonderful panoply of capabilities, the question becomes 'why aren't more people using these aids and what are the demonstrated benefits of such capabilities?' In this paper we review the types of decision aids which have been successfully implemented and the challenges to implementation (knowledge representation, connections to databases, need for comprehensive, coded databases and evaluation of benefits).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22393,""
"Home Appliance Review Research Via Adversarial Reptile","Kan, Tai-Jung; Chang, Chia-Hui; Chuang, Hsiu-Min","https://aclanthology.org/2021.rocling-1.24","2021","ACL","","For manufacturers of home appliances, the Studying discussion of products on social media can help manufacturers improve their products. Opinions provided through online reviews can immediately reflect whether the product is accepted by people, and which aspect of the product are most discussed . In this article, we divide the analysis of home appliances into three tasks, including named entity recognition (NER), aspect category extraction (ACE), and aspect category sentiment classification (ACSC). To improve the performance of ACSC, we combine the Reptile algorithm in meta learning with the concept of domain adversarial training to form the concept of the Adversarial Reptile algorithm. We find show that the macro-f1 is improved from 68.6% (BERT fine tuned model) to 70.3% (p-value 0.04).","Undecided","","","","","","","","","","","","","False","False","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021-11-03","",22394,""
